title,summary,published,authors,pdf_url,category
CodeHalu: Investigating Code Hallucinations in LLMs via Execution-based Verification,"Large Language Models (LLMs) have made significant progress in code
generation, offering developers groundbreaking automated programming support.
However, LLMs often generate code that is syntactically correct and even
semantically plausible, but may not execute as expected or fulfill specified
requirements. This phenomenon of hallucinations in the code domain has not been
systematically explored. To advance the community's understanding and research
on this issue, we introduce the concept of code hallucinations and propose a
classification method for code hallucination based on execution verification.
We categorize code hallucinations into four main types: mapping, naming,
resource, and logic hallucinations, with each category further divided into
different subcategories to understand and address the unique challenges faced
by LLMs in code generation with finer granularity. Additionally, we present a
dynamic detection algorithm called CodeHalu designed to detect and quantify
code hallucinations. We also introduce the CodeHaluEval benchmark, which
includes 8,883 samples from 699 tasks, to systematically and quantitatively
evaluate code hallucinations. By evaluating 17 popular LLMs using this
benchmark, we reveal significant differences in their accuracy and reliability
in code generation, offering detailed insights for further improving the code
generation capabilities of LLMs. The CodeHalu benchmark and code are publicly
available at https://github.com/yuchen814/CodeHalu.",2024-04-30,"Yuchen Tian, Weixiang Yan, Qian Yang, Xuandong Zhao, Qian Chen, Wen Wang, Ziyang Luo, Lei Ma, Dawn Song",http://arxiv.org/pdf/2405.00253v4,cs.CL
Graphical Reasoning: LLM-based Semi-Open Relation Extraction,"This paper presents a comprehensive exploration of relation extraction
utilizing advanced language models, specifically Chain of Thought (CoT) and
Graphical Reasoning (GRE) techniques. We demonstrate how leveraging in-context
learning with GPT-3.5 can significantly enhance the extraction process,
particularly through detailed example-based reasoning. Additionally, we
introduce a novel graphical reasoning approach that dissects relation
extraction into sequential sub-tasks, improving precision and adaptability in
processing complex relational data. Our experiments, conducted on multiple
datasets, including manually annotated data, show considerable improvements in
performance metrics, underscoring the effectiveness of our methodologies.",2024-04-30,"Yicheng Tao, Yiqun Wang, Longju Bai",http://arxiv.org/pdf/2405.00216v1,cs.CL
A Primer on the Inner Workings of Transformer-based Language Models,"The rapid progress of research aimed at interpreting the inner workings of
advanced language models has highlighted a need for contextualizing the
insights gained from years of work in this area. This primer provides a concise
technical introduction to the current techniques used to interpret the inner
workings of Transformer-based language models, focusing on the generative
decoder-only architecture. We conclude by presenting a comprehensive overview
of the known internal mechanisms implemented by these models, uncovering
connections across popular approaches and active research directions in this
area.",2024-04-30,"Javier Ferrando, Gabriele Sarti, Arianna Bisazza, Marta R. Costa-jussà",http://arxiv.org/pdf/2405.00208v3,cs.CL
General Purpose Verification for Chain of Thought Prompting,"Many of the recent capabilities demonstrated by Large Language Models (LLMs)
arise primarily from their ability to exploit contextual information. In this
paper, we explore ways to improve reasoning capabilities of LLMs through (1)
exploration of different chains of thought and (2) validation of the individual
steps of the reasoning process. We propose three general principles that a
model should adhere to while reasoning: (i) Relevance, (ii) Mathematical
Accuracy, and (iii) Logical Consistency. We apply these constraints to the
reasoning steps generated by the LLM to improve the accuracy of the final
generation. The constraints are applied in the form of verifiers: the model
itself is asked to verify if the generated steps satisfy each constraint. To
further steer the generations towards high-quality solutions, we use the
perplexity of the reasoning steps as an additional verifier. We evaluate our
method on 4 distinct types of reasoning tasks, spanning a total of 9 different
datasets. Experiments show that our method is always better than vanilla
generation, and, in 6 out of the 9 datasets, it is better than best-of N
sampling which samples N reasoning chains and picks the lowest perplexity
generation.",2024-04-30,"Robert Vacareanu, Anurag Pratik, Evangelia Spiliopoulou, Zheng Qi, Giovanni Paolini, Neha Anna John, Jie Ma, Yassine Benajiba, Miguel Ballesteros",http://arxiv.org/pdf/2405.00204v1,cs.CL
SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained Large Language Models,"Full fine-tuning is a popular approach to adapt Transformer-based pre-trained
large language models to a specific downstream task. However, the substantial
requirements for computational power and storage have discouraged its
widespread use. Moreover, increasing evidence of catastrophic forgetting and
overparameterization in the Transformer architecture has motivated researchers
to seek more efficient fine-tuning (PEFT) methods. Commonly known
parameter-efficient fine-tuning methods like LoRA and BitFit are typically
applied across all layers of the model. We propose a PEFT method, called
Stratified Progressive Adaptation Fine-tuning (SPAFIT), based on the
localization of different types of linguistic knowledge to specific layers of
the model. Our experiments, conducted on nine tasks from the GLUE benchmark,
show that our proposed SPAFIT method outperforms other PEFT methods while
fine-tuning only a fraction of the parameters adjusted by other methods.",2024-04-30,"Samir Arora, Liangliang Wang",http://arxiv.org/pdf/2405.00201v1,cs.CL
In-Context Learning with Long-Context Models: An In-Depth Exploration,"As model context lengths continue to increase, the number of demonstrations
that can be provided in-context approaches the size of entire training
datasets. We study the behavior of in-context learning (ICL) at this extreme
scale on multiple datasets and models. We show that, for many datasets with
large label spaces, performance continues to increase with thousands of
demonstrations. We contrast this with example retrieval and finetuning: example
retrieval shows excellent performance at low context lengths but has diminished
gains with more demonstrations; finetuning is more data hungry than ICL but can
exceed long-context ICL performance with additional data. We use the ICL
setting to study several properties of both in-context learning and
long-context models. We show that long-context ICL is less sensitive to random
input shuffling than short-context ICL, that grouping of same-label examples
negatively impacts performance, and that the performance boosts do not arise
from cumulative gain from encoding many examples together. We conclude that
long-context ICL can be an effective tool, and may not require long-context for
encoding the demonstration set at all.",2024-04-30,"Amanda Bertsch, Maor Ivgi, Emily Xiao, Uri Alon, Jonathan Berant, Matthew R. Gormley, Graham Neubig",http://arxiv.org/pdf/2405.00200v2,cs.CL
Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models,"This paper introduces uRAG--a framework with a unified retrieval engine that
serves multiple downstream retrieval-augmented generation (RAG) systems. Each
RAG system consumes the retrieval results for a unique purpose, such as
open-domain question answering, fact verification, entity linking, and relation
extraction. We introduce a generic training guideline that standardizes the
communication between the search engine and the downstream RAG systems that
engage in optimizing the retrieval model. This lays the groundwork for us to
build a large-scale experimentation ecosystem consisting of 18 RAG systems that
engage in training and 18 unknown RAG systems that use the uRAG as the new
users of the search engine. Using this experimentation ecosystem, we answer a
number of fundamental research questions that improve our understanding of
promises and challenges in developing search engines for machines.",2024-04-30,"Alireza Salemi, Hamed Zamani",http://arxiv.org/pdf/2405.00175v1,cs.CL
HistNERo: Historical Named Entity Recognition for the Romanian Language,"This work introduces HistNERo, the first Romanian corpus for Named Entity
Recognition (NER) in historical newspapers. The dataset contains 323k tokens of
text, covering more than half of the 19th century (i.e., 1817) until the late
part of the 20th century (i.e., 1990). Eight native Romanian speakers annotated
the dataset with five named entities. The samples belong to one of the
following four historical regions of Romania, namely Bessarabia, Moldavia,
Transylvania, and Wallachia. We employed this proposed dataset to perform
several experiments for NER using Romanian pre-trained language models. Our
results show that the best model achieved a strict F1-score of 55.69%. Also, by
reducing the discrepancies between regions through a novel domain adaption
technique, we improved the performance on this corpus to a strict F1-score of
66.80%, representing an absolute gain of more than 10%.",2024-04-30,"Andrei-Marius Avram, Andreea Iuga, George-Vlad Manolache, Vlad-Cristian Matei, Răzvan-Gabriel Micliuş, Vlad-Andrei Muntean, Manuel-Petru Sorlescu, Dragoş-Andrei Şerban, Adrian-Dinu Urse, Vasile Păiş, Dumitru-Clementin Cercel",http://arxiv.org/pdf/2405.00155v1,cs.CL
Transforming Dutch: Debiasing Dutch Coreference Resolution Systems for Non-binary Pronouns,"Gender-neutral pronouns are increasingly being introduced across Western
languages. Recent evaluations have however demonstrated that English NLP
systems are unable to correctly process gender-neutral pronouns, with the risk
of erasing and misgendering non-binary individuals. This paper examines a Dutch
coreference resolution system's performance on gender-neutral pronouns,
specifically hen and die. In Dutch, these pronouns were only introduced in
2016, compared to the longstanding existence of singular they in English. We
additionally compare two debiasing techniques for coreference resolution
systems in non-binary contexts: Counterfactual Data Augmentation (CDA) and
delexicalisation. Moreover, because pronoun performance can be hard to
interpret from a general evaluation metric like LEA, we introduce an innovative
evaluation metric, the pronoun score, which directly represents the portion of
correctly processed pronouns. Our results reveal diminished performance on
gender-neutral pronouns compared to gendered counterparts. Nevertheless,
although delexicalisation fails to yield improvements, CDA substantially
reduces the performance gap between gendered and gender-neutral pronouns. We
further show that CDA remains effective in low-resource settings, in which a
limited set of debiasing documents is used. This efficacy extends to previously
unseen neopronouns, which are currently infrequently used but may gain
popularity in the future, underscoring the viability of effective debiasing
with minimal resources and low computational costs.",2024-04-30,"Goya van Boven, Yupei Du, Dong Nguyen",http://arxiv.org/pdf/2405.00134v1,cs.CL
Graph Neural Network Approach to Semantic Type Detection in Tables,"This study addresses the challenge of detecting semantic column types in
relational tables, a key task in many real-world applications. While language
models like BERT have improved prediction accuracy, their token input
constraints limit the simultaneous processing of intra-table and inter-table
information. We propose a novel approach using Graph Neural Networks (GNNs) to
model intra-table dependencies, allowing language models to focus on
inter-table information. Our proposed method not only outperforms existing
state-of-the-art algorithms but also offers novel insights into the utility and
functionality of various GNN types for semantic type detection. The code is
available at https://github.com/hoseinzadeehsan/GAIT",2024-04-30,"Ehsan Hoseinzade, Ke Wang",http://arxiv.org/pdf/2405.00123v1,cs.CL
Creative Beam Search: LLM-as-a-Judge For Improving Response Generation,"Large language models are revolutionizing several areas, including artificial
creativity. However, the process of generation in machines profoundly diverges
from that observed in humans. In particular, machine generation is
characterized by a lack of intentionality and an underlying creative process.
We propose a method called Creative Beam Search that uses Diverse Beam Search
and LLM-as-a-Judge to perform response generation and response validation. The
results of a qualitative experiment show how our approach can provide better
output than standard sampling techniques. We also show that the response
validation step is a necessary complement to the response generation step.",2024-04-30,"Giorgio Franceschelli, Mirco Musolesi",http://arxiv.org/pdf/2405.00099v4,cs.CL
DOCCI: Descriptions of Connected and Contrasting Images,"Vision-language datasets are vital for both text-to-image (T2I) and
image-to-text (I2T) research. However, current datasets lack descriptions with
fine-grained detail that would allow for richer associations to be learned by
models. To fill the gap, we introduce Descriptions of Connected and Contrasting
Images (DOCCI), a dataset with long, human-annotated English descriptions for
15k images that were taken, curated and donated by a single researcher intent
on capturing key challenges such as spatial relations, counting, text
rendering, world knowledge, and more. We instruct human annotators to create
comprehensive descriptions for each image; these average 136 words in length
and are crafted to clearly distinguish each image from those that are related
or similar. Each description is highly compositional and typically encompasses
multiple challenges. Through both quantitative and qualitative analyses, we
demonstrate that DOCCI serves as an effective training resource for
image-to-text generation -- a PaLI 5B model finetuned on DOCCI shows equal or
superior results compared to highly-performant larger models like LLaVA-1.5 7B
and InstructBLIP 7B. Furthermore, we show that DOCCI is a useful testbed for
text-to-image generation, highlighting the limitations of current text-to-image
models in capturing long descriptions and fine details.",2024-04-30,"Yasumasa Onoe, Sunayana Rane, Zachary Berger, Yonatan Bitton, Jaemin Cho, Roopal Garg, Alexander Ku, Zarana Parekh, Jordi Pont-Tuset, Garrett Tanzer, Su Wang, Jason Baldridge",http://arxiv.org/pdf/2404.19753v1,cs.CL
Better & Faster Large Language Models via Multi-token Prediction,"Large language models such as GPT and Llama are trained with a next-token
prediction loss. In this work, we suggest that training language models to
predict multiple future tokens at once results in higher sample efficiency.
More specifically, at each position in the training corpus, we ask the model to
predict the following n tokens using n independent output heads, operating on
top of a shared model trunk. Considering multi-token prediction as an auxiliary
training task, we measure improved downstream capabilities with no overhead in
training time for both code and natural language models. The method is
increasingly useful for larger model sizes, and keeps its appeal when training
for multiple epochs. Gains are especially pronounced on generative benchmarks
like coding, where our models consistently outperform strong baselines by
several percentage points. Our 13B parameter models solves 12 % more problems
on HumanEval and 17 % more on MBPP than comparable next-token models.
Experiments on small algorithmic tasks demonstrate that multi-token prediction
is favorable for the development of induction heads and algorithmic reasoning
capabilities. As an additional benefit, models trained with 4-token prediction
are up to 3 times faster at inference, even with large batch sizes.",2024-04-30,"Fabian Gloeckle, Badr Youbi Idrissi, Baptiste Rozière, David Lopez-Paz, Gabriel Synnaeve",http://arxiv.org/pdf/2404.19737v1,cs.CL
Iterative Reasoning Preference Optimization,"Iterative preference optimization methods have recently been shown to perform
well for general instruction tuning tasks, but typically make little
improvement on reasoning tasks (Yuan et al., 2024, Chen et al., 2024). In this
work we develop an iterative approach that optimizes the preference between
competing generated Chain-of-Thought (CoT) candidates by optimizing for winning
vs. losing reasoning steps that lead to the correct answer. We train using a
modified DPO loss (Rafailov et al., 2023) with an additional negative
log-likelihood term, which we find to be crucial. We show reasoning improves
across repeated iterations of this scheme. While only relying on examples in
the training set, our approach results in increasing accuracy on GSM8K, MATH,
and ARC-Challenge for Llama-2-70B-Chat, outperforming other Llama-2-based
models not relying on additionally sourced datasets. For example, we see a
large improvement from 55.6% to 81.6% on GSM8K and an accuracy of 88.7% with
majority voting out of 32 samples.",2024-04-30,"Richard Yuanzhe Pang, Weizhe Yuan, Kyunghyun Cho, He He, Sainbayar Sukhbaatar, Jason Weston",http://arxiv.org/pdf/2404.19733v3,cs.CL
PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games,"This research introduces Procedural Artificial Narrative using Generative AI
(PANGeA), a structured approach for leveraging large language models (LLMs),
guided by a game designer's high-level criteria, to generate narrative content
for turn-based role-playing video games (RPGs). Distinct from prior
applications of LLMs used for video game design, PANGeA innovates by not only
generating game level data (which includes, but is not limited to, setting, key
items, and non-playable characters (NPCs)), but by also fostering dynamic,
free-form interactions between the player and the environment that align with
the procedural game narrative. The NPCs generated by PANGeA are
personality-biased and express traits from the Big 5 Personality Model in their
generated responses. PANGeA addresses challenges behind ingesting free-form
text input, which can prompt LLM responses beyond the scope of the game
narrative. A novel validation system that uses the LLM's intelligence evaluates
text input and aligns generated responses with the unfolding narrative. Making
these interactions possible, PANGeA is supported by a server that hosts a
custom memory system that supplies context for augmenting generated responses
thus aligning them with the procedural narrative. For its broad application,
the server has a REST interface enabling any game engine to integrate directly
with PANGeA, as well as an LLM interface adaptable with local or private LLMs.
PANGeA's ability to foster dynamic narrative generation by aligning responses
with the procedural narrative is demonstrated through an empirical study and
ablation test of two versions of a demo game. These are, a custom,
browser-based GPT and a Unity demo. As the results show, PANGeA holds potential
to assist game designers in using LLMs to generate narrative-consistent content
even when provided varied and unpredictable, free-form text input.",2024-04-30,"Steph Buongiorno, Lawrence Jake Klinkert, Tanishq Chawla, Zixin Zhuang, Corey Clark",http://arxiv.org/pdf/2404.19721v3,cs.CL
ThangDLU at #SMM4H 2024: Encoder-decoder models for classifying text data on social disorders in children and adolescents,"This paper describes our participation in Task 3 and Task 5 of the #SMM4H
(Social Media Mining for Health) 2024 Workshop, explicitly targeting the
classification challenges within tweet data. Task 3 is a multi-class
classification task centered on tweets discussing the impact of outdoor
environments on symptoms of social anxiety. Task 5 involves a binary
classification task focusing on tweets reporting medical disorders in children.
We applied transfer learning from pre-trained encoder-decoder models such as
BART-base and T5-small to identify the labels of a set of given tweets. We also
presented some data augmentation methods to see their impact on the model
performance. Finally, the systems obtained the best F1 score of 0.627 in Task 3
and the best F1 score of 0.841 in Task 5.",2024-04-30,"Hoang-Thang Ta, Abu Bakar Siddiqur Rahman, Lotfollah Najjar, Alexander Gelbukh",http://arxiv.org/pdf/2404.19714v1,cs.CL
Automated Generation of High-Quality Medical Simulation Scenarios Through Integration of Semi-Structured Data and Large Language Models,"This study introduces a transformative framework for medical education by
integrating semi-structured data with Large Language Models (LLMs), primarily
OpenAIs ChatGPT3.5, to automate the creation of medical simulation scenarios.
Traditionally, developing these scenarios was a time-intensive process with
limited flexibility to meet diverse educational needs. The proposed approach
utilizes AI to efficiently generate detailed, clinically relevant scenarios
that are tailored to specific educational objectives. This innovation has
significantly reduced the time and resources required for scenario development,
allowing for a broader variety of simulations. Preliminary feedback from
educators and learners has shown enhanced engagement and improved knowledge
acquisition, confirming the effectiveness of this AI-enhanced methodology in
simulation-based learning. The integration of structured data with LLMs not
only streamlines the creation process but also offers a scalable, dynamic
solution that could revolutionize medical training, highlighting the critical
role of AI in advancing educational outcomes and patient care standards.",2024-04-30,Scott Sumpter,http://arxiv.org/pdf/2404.19713v2,cs.CL
Harmonic LLMs are Trustworthy,"We introduce an intuitive method to test the robustness (stability and
explainability) of any black-box LLM in real-time via its local deviation from
harmoniticity, denoted as $\gamma$. To the best of our knowledge this is the
first completely model-agnostic and unsupervised method of measuring the
robustness of any given response from an LLM, based upon the model itself
conforming to a purely mathematical standard. To show general application and
immediacy of results, we measure $\gamma$ in 10 popular LLMs (ChatGPT,
Claude-2.1, Claude3.0, GPT-4, GPT-4o, Smaug-72B, Mixtral-8x7B, Llama2-7B,
Mistral-7B and MPT-7B) across thousands of queries in three objective domains:
WebQA, ProgrammingQA, and TruthfulQA. Across all models and domains tested,
human annotation confirms that $\gamma \to 0$ indicates trustworthiness, and
conversely searching higher values of $\gamma$ easily exposes examples of
hallucination, a fact that enables efficient adversarial prompt generation
through stochastic gradient ascent in $\gamma$. The low-$\gamma$ leaders among
the models in the respective domains are GPT-4o, GPT-4, and Smaug-72B,
providing evidence that mid-size open-source models can win out against large
commercial models.",2024-04-30,"Nicholas S. Kersting, Mohammad Rahman, Suchismitha Vedala, Yang Wang",http://arxiv.org/pdf/2404.19708v2,cs.CL
When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively,"In this paper, we demonstrate how Large Language Models (LLMs) can
effectively learn to use an off-the-shelf information retrieval (IR) system
specifically when additional context is required to answer a given question.
Given the performance of IR systems, the optimal strategy for question
answering does not always entail external information retrieval; rather, it
often involves leveraging the parametric memory of the LLM itself. Prior
research has identified this phenomenon in the PopQA dataset, wherein the most
popular questions are effectively addressed using the LLM's parametric memory,
while less popular ones require IR system usage. Following this, we propose a
tailored training approach for LLMs, leveraging existing open-domain question
answering datasets. Here, LLMs are trained to generate a special token, <RET>,
when they do not know the answer to a question. Our evaluation of the Adaptive
Retrieval LLM (Adapt-LLM) on the PopQA dataset showcases improvements over the
same LLM under three configurations: (i) retrieving information for all the
questions, (ii) using always the parametric memory of the LLM, and (iii) using
a popularity threshold to decide when to use a retriever. Through our analysis,
we demonstrate that Adapt-LLM is able to generate the <RET> token when it
determines that it does not know how to answer a question, indicating the need
for IR, while it achieves notably high accuracy levels when it chooses to rely
only on its parametric memory.",2024-04-30,"Tiziano Labruna, Jon Ander Campos, Gorka Azkune",http://arxiv.org/pdf/2404.19705v2,cs.CL
Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners,"3D visual grounding is a challenging task that often requires direct and
dense supervision, notably the semantic label for each object in the scene. In
this paper, we instead study the naturally supervised setting that learns from
only 3D scene and QA pairs, where prior works underperform. We propose the
Language-Regularized Concept Learner (LARC), which uses constraints from
language as regularization to significantly improve the accuracy of
neuro-symbolic concept learners in the naturally supervised setting. Our
approach is based on two core insights: the first is that language constraints
(e.g., a word's relation to another) can serve as effective regularization for
structured representations in neuro-symbolic models; the second is that we can
query large language models to distill such constraints from language
properties. We show that LARC improves performance of prior works in naturally
supervised 3D visual grounding, and demonstrates a wide range of 3D visual
reasoning capabilities-from zero-shot composition, to data efficiency and
transferability. Our method represents a promising step towards regularizing
structured visual reasoning frameworks with language-based priors, for learning
in settings without dense supervision.",2024-04-30,"Chun Feng, Joy Hsu, Weiyu Liu, Jiajun Wu",http://arxiv.org/pdf/2404.19696v1,cs.CL
Improving Disease Detection from Social Media Text via Self-Augmentation and Contrastive Learning,"Detecting diseases from social media has diverse applications, such as public
health monitoring and disease spread detection. While language models (LMs)
have shown promising performance in this domain, there remains ongoing research
aimed at refining their discriminating representations. In this paper, we
propose a novel method that integrates Contrastive Learning (CL) with language
modeling to address this challenge. Our approach introduces a self-augmentation
method, wherein hidden representations of the model are augmented with their
own representations. This method comprises two branches: the first branch, a
traditional LM, learns features specific to the given data, while the second
branch incorporates augmented representations from the first branch to
encourage generalization. CL further refines these representations by pulling
pairs of original and augmented versions closer while pushing other samples
away. We evaluate our method on three NLP datasets encompassing binary,
multi-label, and multi-class classification tasks involving social media posts
related to various diseases. Our approach demonstrates notable improvements
over traditional fine-tuning methods, achieving up to a 2.48% increase in
F1-score compared to baseline approaches and a 2.1% enhancement over
state-of-the-art methods.",2024-04-30,"Pervaiz Iqbal Khan, Andreas Dengel, Sheraz Ahmed",http://arxiv.org/pdf/2405.01597v1,cs.CL
TuBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning,"The implications of backdoor attacks on English-centric large language models
(LLMs) have been widely examined - such attacks can be achieved by embedding
malicious behaviors during training and activated under specific conditions
that trigger malicious outputs. Despite the increasing support for multilingual
capabilities in open-source and proprietary LLMs, the impact of backdoor
attacks on these systems remains largely under-explored. Our research focuses
on cross-lingual backdoor attacks against multilingual LLMs, particularly
investigating how poisoning the instruction-tuning data for one or two
languages can affect the outputs for languages whose instruction-tuning data
were not poisoned. Despite its simplicity, our empirical analysis reveals that
our method exhibits remarkable efficacy in models like mT5 and GPT-4o, with
high attack success rates, surpassing 90% in more than 7 out of 12 languages
across various scenarios. Our findings also indicate that more powerful models
show increased susceptibility to transferable cross-lingual backdoor attacks,
which also applies to LLMs predominantly pre-trained on English data, such as
Llama2, Llama3, and Gemma. Moreover, our experiments demonstrate 1) High
Transferability: the backdoor mechanism operates successfully in cross-lingual
response scenarios across 26 languages, achieving an average attack success
rate of 99%, and 2) Robustness: the proposed attack remains effective even
after defenses are applied. These findings expose critical security
vulnerabilities in multilingual LLMs and highlight the urgent need for more
robust, targeted defense strategies to address the unique challenges posed by
cross-lingual backdoor transfer.",2024-04-30,"Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn",http://arxiv.org/pdf/2404.19597v3,cs.CL
RepEval: Effective Text Evaluation with LLM Representation,"The era of Large Language Models (LLMs) raises new demands for automatic
evaluation metrics, which should be adaptable to various application scenarios
while maintaining low cost and effectiveness. Traditional metrics for automatic
text evaluation are often tailored to specific scenarios, while LLM-based
evaluation metrics are costly, requiring fine-tuning or rely heavily on the
generation capabilities of LLMs. Besides, previous LLM-based metrics ignore the
fact that, within the space of LLM representations, there exist direction
vectors that indicate the estimation of text quality. To this end, we introduce
RepEval, a metric that leverages the projection of LLM representations for
evaluation. Through simple prompt modifications, RepEval can easily transition
to various tasks, requiring only minimal sample pairs for direction vector
construction. Results on fourteen datasets across two evaluation tasks
demonstrate the high effectiveness of our method, which exhibits a higher
correlation with human judgments than previous methods, even in complex
evaluation scenarios involving pair-wise selection under nuanced aspects. Our
work underscores the richness of information regarding text quality embedded
within LLM representations, offering insights for the development of new
metrics.",2024-04-30,"Shuqian Sheng, Yi Xu, Tianhang Zhang, Zanwei Shen, Luoyi Fu, Jiaxin Ding, Lei Zhou, Xiaoying Gan, Xinbing Wang, Chenghu Zhou",http://arxiv.org/pdf/2404.19563v2,cs.CL
Extending Llama-3's Context Ten-Fold Overnight,"We extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA
fine-tuning. The entire training cycle is super efficient, which takes 8 hours
on one 8xA800 (80G) GPU machine. The resulted model exhibits superior
performances across a broad range of evaluation tasks, such as NIHS, topic
retrieval, and long-context language understanding; meanwhile, it also well
preserves the original capability over short contexts. The dramatic context
extension is mainly attributed to merely 3.5K synthetic training samples
generated by GPT-4 , which indicates the LLMs' inherent (yet largely
underestimated) potential to extend its original context length. In fact, the
context length could be extended far beyond 80K with more computation
resources. Therefore, the team will publicly release the entire resources
(including data, model, data generation pipeline, training code) so as to
facilitate the future research from the community:
\url{https://github.com/FlagOpen/FlagEmbedding}.",2024-04-30,"Peitian Zhang, Ninglu Shao, Zheng Liu, Shitao Xiao, Hongjin Qian, Qiwei Ye, Zhicheng Dou",http://arxiv.org/pdf/2404.19553v1,cs.CL
RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing,"Large Language Models (LLMs) have catalyzed significant advancements in
Natural Language Processing (NLP), yet they encounter challenges such as
hallucination and the need for domain-specific knowledge. To mitigate these,
recent methodologies have integrated information retrieved from external
resources with LLMs, substantially enhancing their performance across NLP
tasks. This survey paper addresses the absence of a comprehensive overview on
Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented
Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an
in-depth examination of their paradigm, evolution, taxonomy, and applications.
The paper discusses the essential components of RALMs, including Retrievers,
Language Models, and Augmentations, and how their interactions lead to diverse
model structures and applications. RALMs demonstrate utility in a spectrum of
tasks, from translation and dialogue systems to knowledge-intensive
applications. The survey includes several evaluation methods of RALMs,
emphasizing the importance of robustness, accuracy, and relevance in their
assessment. It also acknowledges the limitations of RALMs, particularly in
retrieval quality and computational efficiency, offering directions for future
research. In conclusion, this survey aims to offer a structured insight into
RALMs, their potential, and the avenues for their future development in NLP.
The paper is supplemented with a Github Repository containing the surveyed
works and resources for further study:
https://github.com/2471023025/RALM_Survey.",2024-04-30,"Yucheng Hu, Yuxing Lu",http://arxiv.org/pdf/2404.19543v1,cs.CL
Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom,"Understanding the non-literal meaning of an utterance is critical for large
language models (LLMs) to become human-like social communicators. In this work,
we introduce SwordsmanImp, the first Chinese multi-turn-dialogue-based dataset
aimed at conversational implicature, sourced from dialogues in the Chinese
sitcom $\textit{My Own Swordsman}$. It includes 200 carefully handcrafted
questions, all annotated on which Gricean maxims have been violated. We test
eight close-source and open-source LLMs under two tasks: a multiple-choice
question task and an implicature explanation task. Our results show that GPT-4
attains human-level accuracy (94%) on multiple-choice questions. CausalLM
demonstrates a 78.5% accuracy following GPT-4. Other models, including GPT-3.5
and several open-source models, demonstrate a lower accuracy ranging from 20%
to 60% on multiple-choice questions. Human raters were asked to rate the
explanation of the implicatures generated by LLMs on their reasonability, logic
and fluency. While all models generate largely fluent and self-consistent text,
their explanations score low on reasonability except for GPT-4, suggesting that
most LLMs cannot produce satisfactory explanations of the implicatures in the
conversation. Moreover, we find LLMs' performance does not vary significantly
by Gricean maxims, suggesting that LLMs do not seem to process implicatures
derived from different maxims differently. Our data and code are available at
https://github.com/sjtu-compling/llm-pragmatics.",2024-04-30,"Shisen Yue, Siyuan Song, Xinyuan Cheng, Hai Hu",http://arxiv.org/pdf/2404.19509v2,cs.CL
Context-Aware Machine Translation with Source Coreference Explanation,"Despite significant improvements in enhancing the quality of translation,
context-aware machine translation (MT) models underperform in many cases. One
of the main reasons is that they fail to utilize the correct features from
context when the context is too long or their models are overly complex. This
can lead to the explain-away effect, wherein the models only consider features
easier to explain predictions, resulting in inaccurate translations. To address
this issue, we propose a model that explains the decisions made for translation
by predicting coreference features in the input. We construct a model for input
coreference by exploiting contextual features from both the input and
translation output representations on top of an existing MT model. We evaluate
and analyze our method in the WMT document-level translation task of
English-German dataset, the English-Russian dataset, and the multilingual TED
talk dataset, demonstrating an improvement of over 1.0 BLEU score when compared
with other context-aware models.",2024-04-30,"Huy Hien Vu, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2404.19505v1,cs.CL
Safe Training with Sensitive In-domain Data: Leveraging Data Fragmentation To Mitigate Linkage Attacks,"Current text generation models are trained using real data which can
potentially contain sensitive information, such as confidential patient
information and the like. Under certain conditions output of the training data
which they have memorised can be triggered, exposing sensitive data. To
mitigate against this risk we propose a safer alternative which sees fragmented
data in the form of domain-specific short phrases randomly grouped together
shared instead of full texts. Thus, text fragments that could re-identify an
individual cannot be reproduced by the model in one sequence, giving
significant protection against linkage attacks. We fine-tune several
state-of-the-art LLMs using meaningful syntactic chunks to explore their
utility. In particular, we fine-tune BERT-based models to predict two
cardiovascular diagnoses. Our results demonstrate the capacity of LLMs to
benefit from the pre-trained knowledge and deliver classification results when
fine-tuned with fragmented data comparable to fine-tuning with full training
data.",2024-04-30,"Mariia Ignashina, Julia Ive",http://arxiv.org/pdf/2404.19486v1,cs.CL
More Compute Is What You Need,"Large language model pre-training has become increasingly expensive, with
most practitioners relying on scaling laws to allocate compute budgets for
model size and training tokens, commonly referred to as Compute-Optimal or
Chinchilla Optimal. In this paper, we hypothesize a new scaling law that
suggests model performance depends mostly on the amount of compute spent for
transformer-based models, independent of the specific allocation to model size
and dataset size. Using this unified scaling law, we predict that (a) for
inference efficiency, training should prioritize smaller model sizes and larger
training datasets, and (b) assuming the exhaustion of available web datasets,
scaling the model size might be the only way to further improve model
performance.",2024-04-30,Zhen Guo,http://arxiv.org/pdf/2404.19484v2,cs.CL
FactCheck Editor: Multilingual Text Editor with End-to-End fact-checking,"We introduce 'FactCheck Editor', an advanced text editor designed to automate
fact-checking and correct factual inaccuracies. Given the widespread issue of
misinformation, often a result of unintentional mistakes by content creators,
our tool aims to address this challenge. It supports over 90 languages and
utilizes transformer models to assist humans in the labor-intensive process of
fact verification. This demonstration showcases a complete workflow that
detects text claims in need of verification, generates relevant search engine
queries, and retrieves appropriate documents from the web. It employs Natural
Language Inference (NLI) to predict the veracity of claims and uses LLMs to
summarize the evidence and suggest textual revisions to correct any errors in
the text. Additionally, the effectiveness of models used in claim detection and
veracity assessment is evaluated across multiple languages.",2024-04-30,Vinay Setty,http://arxiv.org/pdf/2404.19482v1,cs.CL
Does Generative AI speak Nigerian-Pidgin?: Issues about Representativeness and Bias for Multilingualism in LLMs,"Nigeria is a multilingual country with 500+ languages. Naija is a Nigerian
Pidgin spoken by approximately 120M speakers and it is a mixed language (e.g.,
English, Portuguese, Yoruba, Hausa and Igbo). Although it has mainly been a
spoken language until recently, there are some online platforms (e.g.,
Wikipedia), publishing in written Naija as well. West African Pidgin English
(WAPE) is also spoken in Nigeria and it is used by BBC to broadcast news on the
internet to a wider audience not only in Nigeria but also in other West African
countries (e.g., Cameroon and Ghana). Through statistical analyses and Machine
Translation experiments, our paper shows that these two pidgin varieties do not
represent each other (i.e., there are linguistic differences in word order and
vocabulary) and Generative AI operates only based on WAPE. In other words,
Naija is underrepresented in Generative AI, and it is hard to teach LLMs with
few examples. In addition to the statistical analyses, we also provide
historical information on both pidgins as well as insights from the interviews
conducted with volunteer Wikipedia contributors in Naija.",2024-04-30,"David Ifeoluwa Adelani, A. Seza Doğruöz, Iyanuoluwa Shode, Anuoluwapo Aremu",http://arxiv.org/pdf/2404.19442v5,cs.CL
Can Large Language Models put 2 and 2 together? Probing for Entailed Arithmetical Relationships,"Two major areas of interest in the era of Large Language Models regard
questions of what do LLMs know, and if and how they may be able to reason (or
rather, approximately reason). Since to date these lines of work progressed
largely in parallel (with notable exceptions), we are interested in
investigating the intersection: probing for reasoning about the implicitly-held
knowledge. Suspecting the performance to be lacking in this area, we use a very
simple set-up of comparisons between cardinalities associated with elements of
various subjects (e.g. the number of legs a bird has versus the number of
wheels on a tricycle). We empirically demonstrate that although LLMs make
steady progress in knowledge acquisition and (pseudo)reasoning with each new
GPT release, their capabilities are limited to statistical inference only. It
is difficult to argue that pure statistical learning can cope with the
combinatorial explosion inherent in many commonsense reasoning tasks,
especially once arithmetical notions are involved. Further, we argue that
bigger is not always better and chasing purely statistical improvements is
flawed at the core, since it only exacerbates the dangerous conflation of the
production of correct answers with genuine reasoning ability.",2024-04-30,"D. Panas, S. Seth, V. Belle",http://arxiv.org/pdf/2404.19432v1,cs.CL
Sõnajaht: Definition Embeddings and Semantic Search for Reverse Dictionary Creation,"We present an information retrieval based reverse dictionary system using
modern pre-trained language models and approximate nearest neighbors search
algorithms. The proposed approach is applied to an existing Estonian language
lexicon resource, S\~onaveeb (word web), with the purpose of enhancing and
enriching it by introducing cross-lingual reverse dictionary functionality
powered by semantic search.
  The performance of the system is evaluated using both an existing labeled
English dataset of words and definitions that is extended to contain also
Estonian and Russian translations, and a novel unlabeled evaluation approach
that extracts the evaluation data from the lexicon resource itself using
synonymy relations.
  Evaluation results indicate that the information retrieval based semantic
search approach without any model training is feasible, producing median rank
of 1 in the monolingual setting and median rank of 2 in the cross-lingual
setting using the unlabeled evaluation approach, with models trained for
cross-lingual retrieval and including Estonian in their training data showing
superior performance in our particular task.",2024-04-30,"Aleksei Dorkin, Kairit Sirts",http://arxiv.org/pdf/2404.19430v1,cs.CL
Countering Reward Over-optimization in LLM with Demonstration-Guided Reinforcement Learning,"While Reinforcement Learning (RL) has been proven essential for tuning large
language models (LLMs), it can lead to reward over-optimization (ROO). Existing
approaches address ROO by adding KL regularization, requiring computationally
expensive hyperparameter tuning. Additionally, KL regularization focuses solely
on regularizing the language policy, neglecting a potential source of
regularization: the reward function itself. Inspired by demonstration-guided
RL, we here introduce the Reward Calibration from Demonstration (RCfD), which
leverages human demonstrations and a reward model to recalibrate the reward
objective. Formally, given a prompt, the RCfD objective minimizes the distance
between the demonstrations' and LLM's rewards rather than directly maximizing
the reward function. This objective shift avoids incentivizing the LLM to
exploit the reward model and promotes more natural and diverse language
generation. We show the effectiveness of RCfD on three language tasks, which
achieves comparable performance to carefully tuned baselines while mitigating
ROO.",2024-04-30,"Mathieu Rita, Florian Strub, Rahma Chaabouni, Paul Michel, Emmanuel Dupoux, Olivier Pietquin",http://arxiv.org/pdf/2404.19409v1,cs.CL
Evaluating Telugu Proficiency in Large Language Models_ A Comparative Analysis of ChatGPT and Gemini,"The growing prominence of large language models (LLMs) necessitates the
exploration of their capabilities beyond English. This research investigates
the Telugu language proficiency of ChatGPT and Gemini, two leading LLMs.
Through a designed set of 20 questions encompassing greetings, grammar,
vocabulary, common phrases, task completion, and situational reasoning, the
study delves into their strengths and weaknesses in handling Telugu. The
analysis aims to identify the LLM that demonstrates a deeper understanding of
Telugu grammatical structures, possesses a broader vocabulary, and exhibits
superior performance in tasks like writing and reasoning. By comparing their
ability to comprehend and use everyday Telugu expressions, the research sheds
light on their suitability for real-world language interaction. Furthermore,
the evaluation of adaptability and reasoning capabilities provides insights
into how each LLM leverages Telugu to respond to dynamic situations. This
comparative analysis contributes to the ongoing discussion on multilingual
capabilities in AI and paves the way for future research in developing LLMs
that can seamlessly integrate with Telugu-speaking communities.",2024-04-30,"Katikela Sreeharsha Kishore, Rahimanuddin Shaik",http://arxiv.org/pdf/2404.19369v2,cs.CL
Navigating Brain Language Representations: A Comparative Analysis of Neural Language Models and Psychologically Plausible Models,"Neural language models, particularly large-scale ones, have been consistently
proven to be most effective in predicting brain neural activity across a range
of studies. However, previous research overlooked the comparison of these
models with psychologically plausible ones. Moreover, evaluations were reliant
on limited, single-modality, and English cognitive datasets. To address these
questions, we conducted an analysis comparing encoding performance of various
neural language models and psychologically plausible models. Our study utilized
extensive multi-modal cognitive datasets, examining bilingual word and
discourse levels. Surprisingly, our findings revealed that psychologically
plausible models outperformed neural language models across diverse contexts,
encompassing different modalities such as fMRI and eye-tracking, and spanning
languages from English to Chinese. Among psychologically plausible models, the
one incorporating embodied information emerged as particularly exceptional.
This model demonstrated superior performance at both word and discourse levels,
exhibiting robust prediction of brain activation across numerous regions in
both English and Chinese.",2024-04-30,"Yunhao Zhang, Shaonan Wang, Xinyi Dong, Jiajun Yu, Chengqing Zong",http://arxiv.org/pdf/2404.19364v1,cs.CL
Expressivity and Speech Synthesis,"Imbuing machines with the ability to talk has been a longtime pursuit of
artificial intelligence (AI) research. From the very beginning, the community
has not only aimed to synthesise high-fidelity speech that accurately conveys
the semantic meaning of an utterance, but also to colour it with inflections
that cover the same range of affective expressions that humans are capable of.
After many years of research, it appears that we are on the cusp of achieving
this when it comes to single, isolated utterances. This unveils an abundance of
potential avenues to explore when it comes to combining these single utterances
with the aim of synthesising more complex, longer-term behaviours. In the
present chapter, we outline the methodological advances that brought us so far
and sketch out the ongoing efforts to reach that coveted next level of
artificial expressivity. We also discuss the societal implications coupled with
rapidly advancing expressive speech synthesis (ESS) technology and highlight
ways to mitigate those risks and ensure the alignment of ESS capabilities with
ethical norms.",2024-04-30,"Andreas Triantafyllopoulos, Björn W. Schuller",http://arxiv.org/pdf/2404.19363v2,cs.CL
Large Language Model Informed Patent Image Retrieval,"In patent prosecution, image-based retrieval systems for identifying
similarities between current patent images and prior art are pivotal to ensure
the novelty and non-obviousness of patent applications. Despite their growing
popularity in recent years, existing attempts, while effective at recognizing
images within the same patent, fail to deliver practical value due to their
limited generalizability in retrieving relevant prior art. Moreover, this task
inherently involves the challenges posed by the abstract visual features of
patent images, the skewed distribution of image classifications, and the
semantic information of image descriptions. Therefore, we propose a
language-informed, distribution-aware multimodal approach to patent image
feature learning, which enriches the semantic understanding of patent image by
integrating Large Language Models and improves the performance of
underrepresented classes with our proposed distribution-aware contrastive
losses. Extensive experiments on DeepPatent2 dataset show that our proposed
method achieves state-of-the-art or comparable performance in image-based
patent retrieval with mAP +53.3%, Recall@10 +41.8%, and MRR@10 +51.9%.
Furthermore, through an in-depth user analysis, we explore our model in aiding
patent professionals in their image retrieval efforts, highlighting the model's
real-world applicability and effectiveness.",2024-04-30,"Hao-Cheng Lo, Jung-Mei Chu, Jieh Hsiang, Chun-Chieh Cho",http://arxiv.org/pdf/2404.19360v1,cs.CL
Evaluating Lexicon Incorporation for Depression Symptom Estimation,"This paper explores the impact of incorporating sentiment, emotion, and
domain-specific lexicons into a transformer-based model for depression symptom
estimation. Lexicon information is added by marking the words in the input
transcripts of patient-therapist conversations as well as in social media
posts. Overall results show that the introduction of external knowledge within
pre-trained language models can be beneficial for prediction performance, while
different lexicons show distinct behaviours depending on the targeted task.
Additionally, new state-of-the-art results are obtained for the estimation of
depression level over patient-therapist interviews.",2024-04-30,"Kirill Milintsevich, Gaël Dias, Kairit Sirts",http://arxiv.org/pdf/2404.19359v1,cs.CL
StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation,"Large language models have shown their ability to become effective few-shot
learners with prompting, revolutionizing the paradigm of learning with data
scarcity. However, this approach largely depends on the quality of prompt
initialization, and always exhibits large variability among different runs.
Such property makes prompt tuning highly unreliable and vulnerable to poorly
constructed prompts, which limits its extension to more real-world
applications. To tackle this issue, we propose to treat the hard prompt and
soft prompt as separate inputs to mitigate noise brought by the prompt
initialization. Furthermore, we optimize soft prompts with contrastive learning
for utilizing class-aware information in the training process to maintain model
performance. Experimental results demonstrate that \sysname outperforms
state-of-the-art methods by 6.97% in accuracy and reduces the standard
deviation by 1.92 on average. Furthermore, extensive experiments underscore its
robustness and stability across 8 datasets covering various tasks. Codes are
available at https://github.com/lccc0528/Stable/tree/main.",2024-04-30,"Xiaoming Liu, Chen Liu, Zhaohan Zhang, Chengzhengxu Li, Longtian Wang, Yu Lan, Chao Shen",http://arxiv.org/pdf/2404.19335v2,cs.CL
Computational Approaches for Integrating out Subjectivity in Cognate Synonym Selection,"Working with cognate data involves handling synonyms, that is, multiple words
that describe the same concept in a language. In the early days of language
phylogenetics it was recommended to select one synonym only. However, as we
show here, binary character matrices, which are used as input for computational
methods, do allow for representing the entire dataset including all synonyms.
Here we address the question how one can and if one should include all synonyms
or whether it is preferable to select synonyms a priori. To this end, we
perform maximum likelihood tree inferences with the widely used RAxML-NG tool
and show that it yields plausible trees when all synonyms are used as input.
Furthermore, we show that a priori synonym selection can yield topologically
substantially different trees and we therefore advise against doing so. To
represent cognate data including all synonyms, we introduce two types of
character matrices beyond the standard binary ones: probabilistic binary and
probabilistic multi-valued character matrices. We further show that it is
dataset-dependent for which character matrix type the inferred RAxML-NG tree is
topologically closest to the gold standard. We also make available a Python
interface for generating all of the above character matrix types for cognate
data provided in CLDF format.",2024-04-30,"Luise Häuser, Gerhard Jäger, Alexandros Stamatakis",http://arxiv.org/pdf/2404.19328v2,cs.CL
Knowledge Distillation vs. Pretraining from Scratch under a Fixed (Computation) Budget,"Compared to standard language model (LM) pretraining (i.e., from scratch),
Knowledge Distillation (KD) entails an additional forward pass through a
teacher model that is typically substantially larger than the target student
model. As such, KD in LM pretraining materially slows down throughput of
pretraining instances vis-a-vis pretraining from scratch. Scaling laws of LM
pretraining suggest that smaller models can close the gap to larger
counterparts if trained on more data (i.e., processing more tokens)-and under a
fixed computation budget, smaller models are able be process more data than
larger models. We thus hypothesize that KD might, in fact, be suboptimal to
pretraining from scratch for obtaining smaller LMs, when appropriately
accounting for the compute budget. To test this, we compare pretraining from
scratch against several KD strategies for masked language modeling (MLM) in a
fair experimental setup, with respect to amount of computation as well as
pretraining data. Downstream results on GLUE, however, do not confirm our
hypothesis: while pretraining from scratch performs comparably to ordinary KD
under a fixed computation budget, more sophisticated KD strategies, namely
TinyBERT (Jiao et al., 2020) and MiniLM (Wang et al., 2023), outperform it by a
notable margin. We further find that KD yields larger gains over pretraining
from scratch when the data must be repeated under the fixed computation budget.",2024-04-30,"Minh Duc Bui, Fabian David Schmidt, Goran Glavaš, Katharina von der Wense",http://arxiv.org/pdf/2404.19319v1,cs.CL
Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores,"A good summary can often be very useful during program comprehension. While a
brief, fluent, and relevant summary can be helpful, it does require significant
human effort to produce. Often, good summaries are unavailable in software
projects, thus making maintenance more difficult. There has been a considerable
body of research into automated AI-based methods, using Large Language models
(LLMs), to generate summaries of code; there also has been quite a bit work on
ways to measure the performance of such summarization methods, with special
attention paid to how closely these AI-generated summaries resemble a summary a
human might have produced. Measures such as BERTScore and BLEU have been
suggested and evaluated with human-subject studies.
  However, LLM-produced summaries can be too long, irrelevant, etc: generally,
too dissimilar to what a human might say. Given an LLM-produced code summary,
how can we judge if a summary is good enough? Given some input source code, and
an LLM-generated summary, existing approaches can help judge brevity, fluency
and relevance; however, it's difficult to gauge whether an LLM-produced summary
sufficiently resembles what a human might produce, without a ""golden""
human-produced summary to compare against. We study this resemblance question
as a calibration problem: given just the summary from an LLM, can we compute a
confidence measure, that provides a reliable indication of whether the summary
sufficiently resembles what a human would have produced in this situation? We
examine this question using several LLMs, for several languages, and in several
different settings. Our investigation suggests approaches to provide reliable
predictions of the likelihood that an LLM-generated summary would sufficiently
resemble a summary a human might write for the same code.",2024-04-30,"Yuvraj Virk, Premkumar Devanbu, Toufique Ahmed",http://arxiv.org/pdf/2404.19318v2,cs.CL
Revisiting N-Gram Models: Their Impact in Modern Neural Networks for Handwritten Text Recognition,"In recent advances in automatic text recognition (ATR), deep neural networks
have demonstrated the ability to implicitly capture language statistics,
potentially reducing the need for traditional language models. This study
directly addresses whether explicit language models, specifically n-gram
models, still contribute to the performance of state-of-the-art deep learning
architectures in the field of handwriting recognition. We evaluate two
prominent neural network architectures, PyLaia and DAN, with and without the
integration of explicit n-gram language models. Our experiments on three
datasets - IAM, RIMES, and NorHand v2 - at both line and page level,
investigate optimal parameters for n-gram models, including their order,
weight, smoothing methods and tokenization level. The results show that
incorporating character or subword n-gram models significantly improves the
performance of ATR models on all datasets, challenging the notion that deep
learning models alone are sufficient for optimal performance. In particular,
the combination of DAN with a character language model outperforms current
benchmarks, confirming the value of hybrid approaches in modern document
analysis systems.",2024-04-30,"Solène Tarride, Christopher Kermorvant",http://arxiv.org/pdf/2404.19317v1,cs.CL
QLSC: A Query Latent Semantic Calibrator for Robust Extractive Question Answering,"Extractive Question Answering (EQA) in Machine Reading Comprehension (MRC)
often faces the challenge of dealing with semantically identical but
format-variant inputs. Our work introduces a novel approach, called the ``Query
Latent Semantic Calibrator (QLSC)'', designed as an auxiliary module for
existing MRC models. We propose a unique scaling strategy to capture latent
semantic center features of queries. These features are then seamlessly
integrated into traditional query and passage embeddings using an attention
mechanism. By deepening the comprehension of the semantic queries-passage
relationship, our approach diminishes sensitivity to variations in text format
and boosts the model's capability in pinpointing accurate answers. Experimental
results on robust Question-Answer datasets confirm that our approach
effectively handles format-variant but semantically identical queries,
highlighting the effectiveness and adaptability of our proposed method.",2024-04-30,"Sheng Ouyang, Jianzong Wang, Yong Zhang, Zhitao Li, Ziqi Liang, Xulong Zhang, Ning Cheng, Jing Xiao",http://arxiv.org/pdf/2404.19316v1,cs.CL
Modeling Orthographic Variation in Occitan's Dialects,"Effectively normalizing textual data poses a considerable challenge,
especially for low-resource languages lacking standardized writing systems. In
this study, we fine-tuned a multilingual model with data from several Occitan
dialects and conducted a series of experiments to assess the model's
representations of these dialects. For evaluation purposes, we compiled a
parallel lexicon encompassing four Occitan dialects. Intrinsic evaluations of
the model's embeddings revealed that surface similarity between the dialects
strengthened representations. When the model was further fine-tuned for
part-of-speech tagging and Universal Dependency parsing, its performance was
robust to dialectical variation, even when trained solely on part-of-speech
data from a single dialect. Our findings suggest that large multilingual models
minimize the need for spelling normalization during pre-processing.",2024-04-30,"Zachary William Hopton, Noëmi Aepli",http://arxiv.org/pdf/2404.19315v1,cs.CL
"Does Whisper understand Swiss German? An automatic, qualitative, and human evaluation","Whisper is a state-of-the-art automatic speech recognition (ASR) model
(Radford et al., 2022). Although Swiss German dialects are allegedly not part
of Whisper's training data, preliminary experiments showed that Whisper can
transcribe Swiss German quite well, with the output being a speech translation
into Standard German. To gain a better understanding of Whisper's performance
on Swiss German, we systematically evaluate it using automatic, qualitative,
and human evaluation. We test its performance on three existing test sets:
SwissDial (Dogan-Sch\""onberger et al., 2021), STT4SG-350 (Pl\""uss et al.,
2023), and Swiss Parliaments Corpus (Pl\""uss et al., 2021). In addition, we
create a new test set for this work, based on short mock clinical interviews.
  For automatic evaluation, we used word error rate (WER) and BLEU. In the
qualitative analysis, we discuss Whisper's strengths and weaknesses and anylyze
some output examples. For the human evaluation, we conducted a survey with 28
participants who were asked to evaluate Whisper's performance.
  All of our evaluations suggest that Whisper is a viable ASR system for Swiss
German, so long as the Standard German output is desired.",2024-04-30,"Eyal Liron Dolev, Clemens Fidel Lutz, Noëmi Aepli",http://arxiv.org/pdf/2404.19310v2,cs.CL
Octopus v4: Graph of language models,"Language models have been effective in a wide range of applications, yet the
most sophisticated models are often proprietary. For example, GPT-4 by OpenAI
and various models by Anthropic are expensive and consume substantial energy.
In contrast, the open-source community has produced competitive models, like
Llama3. Furthermore, niche-specific smaller language models, such as those
tailored for legal, medical or financial tasks, have outperformed their
proprietary counterparts. This paper introduces a novel approach that employs
\textit{functional tokens} to integrate \textbf{multiple open-source models},
each optimized for particular tasks. Our newly developed Octopus v4 model
leverages \textit{functional tokens} to intelligently direct user queries to
the most appropriate vertical model and reformat the query to achieve the best
performance. Octopus v4, an evolution of the Octopus v1, v2, and v3 models,
excels in selection and parameter understanding and reformatting. Additionally,
we explore the use of graph as a versatile data structure that effectively
coordinates multiple open-source models by harnessing the capabilities of the
Octopus model and \textit{functional tokens}. Use our open-sourced GitHub
(\url{https://www.nexa4ai.com/}) to try Octopus v4 models
(\url{https://huggingface.co/NexaAIDev/Octopus-v4}), and contrite to a larger
graph of language models. By activating models less than 10B parameters, we
achieved SOTA MMLU score of 74.8 among the same level models.",2024-04-30,"Wei Chen, Zhiyuan Li",http://arxiv.org/pdf/2404.19296v1,cs.CL
Large Language Model Agent for Fake News Detection,"In the current digital era, the rapid spread of misinformation on online
platforms presents significant challenges to societal well-being, public trust,
and democratic processes, influencing critical decision making and public
opinion. To address these challenges, there is a growing need for automated
fake news detection mechanisms. Pre-trained large language models (LLMs) have
demonstrated exceptional capabilities across various natural language
processing (NLP) tasks, prompting exploration into their potential for
verifying news claims. Instead of employing LLMs in a non-agentic way, where
LLMs generate responses based on direct prompts in a single shot, our work
introduces FactAgent, an agentic approach of utilizing LLMs for fake news
detection. FactAgent enables LLMs to emulate human expert behavior in verifying
news claims without any model training, following a structured workflow. This
workflow breaks down the complex task of news veracity checking into multiple
sub-steps, where LLMs complete simple tasks using their internal knowledge or
external tools. At the final step of the workflow, LLMs integrate all findings
throughout the workflow to determine the news claim's veracity. Compared to
manual human verification, FactAgent offers enhanced efficiency. Experimental
studies demonstrate the effectiveness of FactAgent in verifying claims without
the need for any training process. Moreover, FactAgent provides transparent
explanations at each step of the workflow and during final decision-making,
offering insights into the reasoning process of fake news detection for end
users. FactAgent is highly adaptable, allowing for straightforward updates to
its tools that LLMs can leverage within the workflow, as well as updates to the
workflow itself using domain knowledge. This adaptability enables FactAgent's
application to news verification across various domains.",2024-04-30,"Xinyi Li, Yongfeng Zhang, Edward C. Malthouse",http://arxiv.org/pdf/2405.01593v1,cs.CL
Aspect and Opinion Term Extraction Using Graph Attention Network,"In this work we investigate the capability of Graph Attention Network for
extracting aspect and opinion terms. Aspect and opinion term extraction is
posed as a token-level classification task akin to named entity recognition. We
use the dependency tree of the input query as additional feature in a Graph
Attention Network along with the token and part-of-speech features. We show
that the dependency structure is a powerful feature that in the presence of a
CRF layer substantially improves the performance and generates the best result
on the commonly used datasets from SemEval 2014, 2015 and 2016. We experiment
with additional layers like BiLSTM and Transformer in addition to the CRF
layer. We also show that our approach works well in the presence of multiple
aspects or sentiments in the same query and it is not necessary to modify the
dependency tree based on a single aspect as was the original application for
sentiment classification.",2024-04-30,Abir Chakraborty,http://arxiv.org/pdf/2404.19260v1,cs.CL
Suvach -- Generated Hindi QA benchmark,"Current evaluation benchmarks for question answering (QA) in Indic languages
often rely on machine translation of existing English datasets. This approach
suffers from bias and inaccuracies inherent in machine translation, leading to
datasets that may not reflect the true capabilities of EQA models for Indic
languages. This paper proposes a new benchmark specifically designed for
evaluating Hindi EQA models and discusses the methodology to do the same for
any task. This method leverages large language models (LLMs) to generate a
high-quality dataset in an extractive setting, ensuring its relevance for the
target language. We believe this new resource will foster advancements in Hindi
NLP research by providing a more accurate and reliable evaluation tool.",2024-04-30,"Vaishak Narayanan, Prabin Raj KP, Saifudheen Nouphal",http://arxiv.org/pdf/2404.19254v1,cs.CL
ViTHSD: Exploiting Hatred by Targets for Hate Speech Detection on Vietnamese Social Media Texts,"The growth of social networks makes toxic content spread rapidly. Hate speech
detection is a task to help decrease the number of harmful comments. With the
diversity in the hate speech created by users, it is necessary to interpret the
hate speech besides detecting it. Hence, we propose a methodology to construct
a system for targeted hate speech detection from online streaming texts from
social media. We first introduce the ViTHSD - a targeted hate speech detection
dataset for Vietnamese Social Media Texts. The dataset contains 10K comments,
each comment is labeled to specific targets with three levels: clean,
offensive, and hate. There are 5 targets in the dataset, and each target is
labeled with the corresponding level manually by humans with strict annotation
guidelines. The inter-annotator agreement obtained from the dataset is 0.45 by
Cohen's Kappa index, which is indicated as a moderate level. Then, we construct
a baseline for this task by combining the Bi-GRU-LSTM-CNN with the pre-trained
language model to leverage the power of text representation of BERTology.
Finally, we suggest a methodology to integrate the baseline model for targeted
hate speech detection into the online streaming system for practical
application in preventing hateful and offensive content on social media.",2024-04-30,"Cuong Nhat Vo, Khanh Bao Huynh, Son T. Luu, Trong-Hop Do",http://arxiv.org/pdf/2404.19252v3,cs.CL
HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning,"Adapting Large Language Models (LLMs) to new tasks through fine-tuning has
been made more efficient by the introduction of Parameter-Efficient Fine-Tuning
(PEFT) techniques, such as LoRA. However, these methods often underperform
compared to full fine-tuning, particularly in scenarios involving complex
datasets. This issue becomes even more pronounced in complex domains,
highlighting the need for improved PEFT approaches that can achieve better
performance. Through a series of experiments, we have uncovered two critical
insights that shed light on the training and parameter inefficiency of LoRA.
Building on these insights, we have developed HydraLoRA, a LoRA framework with
an asymmetric structure that eliminates the need for domain expertise. Our
experiments demonstrate that HydraLoRA outperforms other PEFT approaches, even
those that rely on domain knowledge during the training and inference phases.",2024-04-30,"Chunlin Tian, Zhan Shi, Zhijiang Guo, Li Li, Chengzhong Xu",http://arxiv.org/pdf/2404.19245v2,cs.CL
Multi-hop Question Answering over Knowledge Graphs using Large Language Models,"Knowledge graphs (KGs) are large datasets with specific structures
representing large knowledge bases (KB) where each node represents a key entity
and relations amongst them are typed edges. Natural language queries formed to
extract information from a KB entail starting from specific nodes and reasoning
over multiple edges of the corresponding KG to arrive at the correct set of
answer nodes. Traditional approaches of question answering on KG are based on
(a) semantic parsing (SP), where a logical form (e.g., S-expression, SPARQL
query, etc.) is generated using node and edge embeddings and then reasoning
over these representations or tuning language models to generate the final
answer directly, or (b) information-retrieval based that works by extracting
entities and relations sequentially. In this work, we evaluate the capability
of (LLMs) to answer questions over KG that involve multiple hops. We show that
depending upon the size and nature of the KG we need different approaches to
extract and feed the relevant information to an LLM since every LLM comes with
a fixed context window. We evaluate our approach on six KGs with and without
the availability of example-specific sub-graphs and show that both the IR and
SP-based methods can be adopted by LLMs resulting in an extremely competitive
performance.",2024-04-30,Abir Chakraborty,http://arxiv.org/pdf/2404.19234v1,cs.CL
GRAMMAR: Grounded and Modular Methodology for Assessment of Closed-Domain Retrieval-Augmented Language Model,"Retrieval-Augmented Generation (RAG) systems are widely used across various
industries for querying closed-domain and in-house knowledge bases. However,
evaluating these systems presents significant challenges due to the private
nature of closed-domain data and a scarcity of queries with verifiable ground
truths. Moreover, there is a lack of analytical methods to diagnose problematic
modules and identify types of failure, such as those caused by knowledge
deficits or issues with robustness. To address these challenges, we introduce
GRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation
framework comprising a grounded data generation process and an evaluation
protocol that effectively pinpoints defective modules. Our validation
experiments reveal that GRAMMAR provides a reliable approach for identifying
vulnerable modules and supports hypothesis testing for textual form
vulnerabilities. An open-source tool accompanying this framework is available
in our GitHub repository (see https://github.com/xinzhel/grammar), allowing for
easy reproduction of our results and enabling reliable and modular evaluation
in closed-domain settings.",2024-04-30,"Xinzhe Li, Ming Liu, Shang Gao",http://arxiv.org/pdf/2404.19232v7,cs.CL
Transcrib3D: 3D Referring Expression Resolution through Large Language Models,"If robots are to work effectively alongside people, they must be able to
interpret natural language references to objects in their 3D environment.
Understanding 3D referring expressions is challenging -- it requires the
ability to both parse the 3D structure of the scene and correctly ground
free-form language in the presence of distraction and clutter. We introduce
Transcrib3D, an approach that brings together 3D detection methods and the
emergent reasoning capabilities of large language models (LLMs). Transcrib3D
uses text as the unifying medium, which allows us to sidestep the need to learn
shared representations connecting multi-modal inputs, which would require
massive amounts of annotated 3D data. As a demonstration of its effectiveness,
Transcrib3D achieves state-of-the-art results on 3D reference resolution
benchmarks, with a great leap in performance from previous multi-modality
baselines. To improve upon zero-shot performance and facilitate local
deployment on edge computers and robots, we propose self-correction for
fine-tuning that trains smaller models, resulting in performance close to that
of large models. We show that our method enables a real robot to perform
pick-and-place tasks given queries that contain challenging referring
expressions. Project site is at https://ripl.github.io/Transcrib3D.",2024-04-30,"Jiading Fang, Xiangshan Tan, Shengjie Lin, Igor Vasiljevic, Vitor Guizilini, Hongyuan Mei, Rares Ambrus, Gregory Shakhnarovich, Matthew R Walter",http://arxiv.org/pdf/2404.19221v1,cs.CL
Mix of Experts Language Model for Named Entity Recognition,"Named Entity Recognition (NER) is an essential steppingstone in the field of
natural language processing. Although promising performance has been achieved
by various distantly supervised models, we argue that distant supervision
inevitably introduces incomplete and noisy annotations, which may mislead the
model training process. To address this issue, we propose a robust NER model
named BOND-MoE based on Mixture of Experts (MoE). Instead of relying on a
single model for NER prediction, multiple models are trained and ensembled
under the Expectation-Maximization (EM) framework, so that noisy supervision
can be dramatically alleviated. In addition, we introduce a fair assignment
module to balance the document-model assignment process. Extensive experiments
on real-world datasets show that the proposed method achieves state-of-the-art
performance compared with other distantly supervised NER.",2024-04-30,"Xinwei Chen, Kun Li, Tianyou Song, Jiangjian Guo",http://arxiv.org/pdf/2404.19192v1,cs.CL
Modeling Caption Diversity in Contrastive Vision-Language Pretraining,"There are a thousand ways to caption an image. Contrastive Language
Pretraining (CLIP) on the other hand, works by mapping an image and its caption
to a single vector -- limiting how well CLIP-like models can represent the
diverse ways to describe an image. In this work, we introduce Llip, Latent
Language Image Pretraining, which models the diversity of captions that could
match an image. Llip's vision encoder outputs a set of visual features that are
mixed into a final representation by conditioning on information derived from
the text. We show that Llip outperforms non-contextualized baselines like CLIP
and SigLIP on a variety of tasks even with large-scale encoders. Llip improves
zero-shot classification by an average of 2.9% zero-shot classification
benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot
top-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by
1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by
6.0%. We provide a comprehensive analysis of the components introduced by the
method and demonstrate that Llip leads to richer visual representations.",2024-04-30,"Samuel Lavoie, Polina Kirichenko, Mark Ibrahim, Mahmoud Assran, Andrew Gordon Wilson, Aaron Courville, Nicolas Ballas",http://arxiv.org/pdf/2405.00740v4,cs.CL
Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics,"Transformers have generally supplanted recurrent neural networks as the
dominant architecture for both natural language processing tasks and for
modelling the effect of predictability on online human language comprehension.
However, two recently developed recurrent model architectures, RWKV and Mamba,
appear to perform natural language tasks comparably to or better than
transformers of equivalent scale. In this paper, we show that contemporary
recurrent models are now also able to match - and in some cases, exceed - the
performance of comparably sized transformers at modeling online human language
comprehension. This suggests that transformer language models are not uniquely
suited to this task, and opens up new directions for debates about the extent
to which architectural features of language models make them better or worse
models of human language comprehension.",2024-04-30,"James A. Michaelov, Catherine Arnett, Benjamin K. Bergen",http://arxiv.org/pdf/2404.19178v2,cs.CL
Game-MUG: Multimodal Oriented Game Situation Understanding and Commentary Generation Dataset,"The dynamic nature of esports makes the situation relatively complicated for
average viewers. Esports broadcasting involves game expert casters, but the
caster-dependent game commentary is not enough to fully understand the game
situation. It will be richer by including diverse multimodal esports
information, including audiences' talks/emotions, game audio, and game match
event information. This paper introduces GAME-MUG, a new multimodal game
situation understanding and audience-engaged commentary generation dataset and
its strong baseline. Our dataset is collected from 2020-2022 LOL game live
streams from YouTube and Twitch, and includes multimodal esports game
information, including text, audio, and time-series event logs, for detecting
the game situation. In addition, we also propose a new audience conversation
augmented commentary dataset by covering the game situation and audience
conversation understanding, and introducing a robust joint multimodal dual
learning model as a baseline. We examine the model's game situation/event
understanding ability and commentary generation capability to show the
effectiveness of the multimodal aspects coverage and the joint integration
learning approach.",2024-04-30,"Zhihao Zhang, Feiqi Cao, Yingbin Mo, Yiran Zhang, Josiah Poon, Caren Han",http://arxiv.org/pdf/2404.19175v1,cs.CL
What Drives Performance in Multilingual Language Models?,"This study investigates the factors influencing the performance of
multilingual large language models (MLLMs) across diverse languages. We study 6
MLLMs, including masked language models, autoregressive models, and
instruction-tuned LLMs, on the SIB-200 dataset, a topic classification dataset
encompassing 204 languages. Our analysis considers three scenarios: ALL
languages, SEEN languages (present in the model's pretraining data), and UNSEEN
languages (not present or documented in the model's pretraining data in any
meaningful way). We examine the impact of factors such as pretraining data
size, general resource availability, language family, and script type on model
performance. Decision tree analysis reveals that pretraining data size is the
most influential factor for SEEN languages. However, interestingly, script type
and language family are crucial for UNSEEN languages, highlighting the
importance of cross-lingual transfer learning. Notably, model size and
architecture do not significantly alter the most important features identified.
Our findings provide valuable insights into the strengths and limitations of
current MLLMs and hope to guide the development of more effective and equitable
multilingual NLP systems.",2024-04-29,"Sina Bagheri Nezhad, Ameeta Agrawal",http://arxiv.org/pdf/2404.19159v1,cs.CL
RTF: Region-based Table Filling Method for Relational Triple Extraction,"Relational triple extraction is crucial work for the automatic construction
of knowledge graphs. Existing methods only construct shallow representations
from a token or token pair-level. However, previous works ignore local spatial
dependencies of relational triples, resulting in a weakness of entity pair
boundary detection. To tackle this problem, we propose a novel Region-based
Table Filling method (RTF). We devise a novel region-based tagging scheme and
bi-directional decoding strategy, which regard each relational triple as a
region on the relation-specific table, and identifies triples by determining
two endpoints of each region. We also introduce convolution to construct
region-level table representations from a spatial perspective which makes
triples easier to be captured. In addition, we share partial tagging scores
among different relations to improve learning efficiency of relation
classifier. Experimental results show that our method achieves state-of-the-art
with better generalization capability on three variants of two widely used
benchmark datasets.",2024-04-29,"Ning An, Lei Hei, Yong Jiang, Weiping Meng, Jingjing Hu, Boran Huang, Feiliang Ren",http://arxiv.org/pdf/2404.19154v2,cs.CL
Q-GroundCAM: Quantifying Grounding in Vision Language Models via GradCAM,"Vision and Language Models (VLMs) continue to demonstrate remarkable
zero-shot (ZS) performance across various tasks. However, many probing studies
have revealed that even the best-performing VLMs struggle to capture aspects of
compositional scene understanding, lacking the ability to properly ground and
localize linguistic phrases in images. Recent VLM advancements include scaling
up both model and dataset sizes, additional training objectives and levels of
supervision, and variations in the model architectures. To characterize the
grounding ability of VLMs, such as phrase grounding, referring expressions
comprehension, and relationship understanding, Pointing Game has been used as
an evaluation metric for datasets with bounding box annotations. In this paper,
we introduce a novel suite of quantitative metrics that utilize GradCAM
activations to rigorously evaluate the grounding capabilities of pre-trained
VLMs like CLIP, BLIP, and ALBEF. These metrics offer an explainable and
quantifiable approach for a more detailed comparison of the zero-shot
capabilities of VLMs and enable measuring models' grounding uncertainty. This
characterization reveals interesting tradeoffs between the size of the model,
the dataset size, and their performance.",2024-04-29,"Navid Rajabi, Jana Kosecka",http://arxiv.org/pdf/2404.19128v1,cs.CL
Accelerating Production LLMs with Combined Token/Embedding Speculators,"This technical report describes the design and training of novel speculative
decoding draft models, for accelerating the inference speeds of large language
models in a production environment. By conditioning draft predictions on both
context vectors and sampled tokens, we can train our speculators to efficiently
predict high-quality n-grams, which the base model then accepts or rejects.
This allows us to effectively predict multiple tokens per inference forward
pass, accelerating wall-clock inference speeds of highly optimized base model
implementations by a factor of 2-3x. We explore these initial results and
describe next steps for further improvements.",2024-04-29,"Davis Wertheimer, Joshua Rosenkranz, Thomas Parnell, Sahil Suneja, Pavithra Ranganathan, Raghu Ganti, Mudhakar Srivatsa",http://arxiv.org/pdf/2404.19124v2,cs.CL
Effects of Added Emphasis and Pause in Audio Delivery of Health Information,"Health literacy is crucial to supporting good health and is a major national
goal. Audio delivery of information is becoming more popular for informing
oneself. In this study, we evaluate the effect of audio enhancements in the
form of information emphasis and pauses with health texts of varying difficulty
and we measure health information comprehension and retention. We produced
audio snippets from difficult and easy text and conducted the study on Amazon
Mechanical Turk (AMT). Our findings suggest that emphasis matters for both
information comprehension and retention. When there is no added pause,
emphasizing significant information can lower the perceived difficulty for
difficult and easy texts. Comprehension is higher (54%) with correctly placed
emphasis for the difficult texts compared to not adding emphasis (50%). Adding
a pause lowers perceived difficulty and can improve retention but adversely
affects information comprehension.",2024-04-29,"Arif Ahmed, Gondy Leroy, Stephen A. Rains, Philip Harber, David Kauchak, Prosanta Barai",http://arxiv.org/pdf/2404.19119v1,cs.CL
Text and Audio Simplification: Human vs. ChatGPT,"Text and audio simplification to increase information comprehension are
important in healthcare. With the introduction of ChatGPT, an evaluation of its
simplification performance is needed. We provide a systematic comparison of
human and ChatGPT simplified texts using fourteen metrics indicative of text
difficulty. We briefly introduce our online editor where these simplification
tools, including ChatGPT, are available. We scored twelve corpora using our
metrics: six text, one audio, and five ChatGPT simplified corpora. We then
compare these corpora with texts simplified and verified in a prior user study.
Finally, a medical domain expert evaluated these texts and five, new ChatGPT
simplified versions. We found that simple corpora show higher similarity with
the human simplified texts. ChatGPT simplification moves metrics in the right
direction. The medical domain expert evaluation showed a preference for the
ChatGPT style, but the text itself was rated lower for content retention.",2024-04-29,"Gondy Leroy, David Kauchak, Philip Harber, Ankit Pal, Akash Shukla",http://arxiv.org/pdf/2405.01592v1,cs.CL
In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery,"State of the art Symbolic Regression (SR) methods currently build specialized
models, while the application of Large Language Models (LLMs) remains largely
unexplored. In this work, we introduce the first comprehensive framework that
utilizes LLMs for the task of SR. We propose In-Context Symbolic Regression
(ICSR), an SR method which iteratively refines a functional form with an LLM
and determines its coefficients with an external optimizer. ICSR leverages
LLMs' strong mathematical prior both to propose an initial set of possible
functions given the observations and to refine them based on their errors. Our
findings reveal that LLMs are able to successfully find symbolic equations that
fit the given data, matching or outperforming the overall performance of the
best SR baselines on four popular benchmarks, while yielding simpler equations
with better out of distribution generalization.",2024-04-29,"Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, Pekka Marttinen",http://arxiv.org/pdf/2404.19094v2,cs.CL
Blind Spots and Biases: Exploring the Role of Annotator Cognitive Biases in NLP,"With the rapid proliferation of artificial intelligence, there is growing
concern over its potential to exacerbate existing biases and societal
disparities and introduce novel ones. This issue has prompted widespread
attention from academia, policymakers, industry, and civil society. While
evidence suggests that integrating human perspectives can mitigate bias-related
issues in AI systems, it also introduces challenges associated with cognitive
biases inherent in human decision-making. Our research focuses on reviewing
existing methodologies and ongoing investigations aimed at understanding
annotation attributes that contribute to bias.",2024-04-29,"Sanjana Gautam, Mukund Srinath",http://arxiv.org/pdf/2404.19071v1,cs.CL
HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models,"Recent research on instructable agents has used memory-augmented Large
Language Models (LLMs) as task planners, a technique that retrieves
language-program examples relevant to the input instruction and uses them as
in-context examples in the LLM prompt to improve the performance of the LLM in
inferring the correct action and task plans. In this technical report, we
extend the capabilities of HELPER, by expanding its memory with a wider array
of examples and prompts, and by integrating additional APIs for asking
questions. This simple expansion of HELPER into a shared memory enables the
agent to work across the domains of executing plans from dialogue, natural
language instruction following, active question asking, and commonsense room
reorganization. We evaluate the agent on four diverse interactive
visual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the
Tidy Task. HELPER-X achieves few-shot, state-of-the-art performance across
these benchmarks using a single agent, without requiring in-domain training,
and remains competitive with agents that have undergone in-domain training.",2024-04-29,"Gabriel Sarch, Sahil Somani, Raghav Kapoor, Michael J. Tarr, Katerina Fragkiadaki",http://arxiv.org/pdf/2404.19065v1,cs.CL
SuperCLUE-Fin: Graded Fine-Grained Analysis of Chinese LLMs on Diverse Financial Tasks and Applications,"The SuperCLUE-Fin (SC-Fin) benchmark is a pioneering evaluation framework
tailored for Chinese-native financial large language models (FLMs). It assesses
FLMs across six financial application domains and twenty-five specialized
tasks, encompassing theoretical knowledge and practical applications such as
compliance, risk management, and investment analysis. Using multi-turn,
open-ended conversations that mimic real-life scenarios, SC-Fin measures models
on a range of criteria, including accurate financial understanding, logical
reasoning, clarity, computational efficiency, business acumen, risk perception,
and compliance with Chinese regulations.
  In a rigorous evaluation involving over a thousand questions, SC-Fin
identifies a performance hierarchy where domestic models like GLM-4 and
MoonShot-v1-128k outperform others with an A-grade, highlighting the potential
for further development in transforming theoretical knowledge into pragmatic
financial solutions. This benchmark serves as a critical tool for refining FLMs
in the Chinese context, directing improvements in financial knowledge
databases, standardizing financial interpretations, and promoting models that
prioritize compliance, risk management, and secure practices.
  We create a contextually relevant and comprehensive benchmark that drives the
development of AI in the Chinese financial sector. SC-Fin facilitates the
advancement and responsible deployment of FLMs, offering valuable insights for
enhancing model performance and usability for both individual and institutional
users in the Chinese market..~\footnote{Our benchmark can be found at
\url{https://www.CLUEbenchmarks.com}}.",2024-04-29,"Liang Xu, Lei Zhu, Yaotong Wu, Hang Xue",http://arxiv.org/pdf/2404.19063v1,cs.CL
Plan of Thoughts: Heuristic-Guided Problem Solving with Large Language Models,"While language models (LMs) offer significant capability in zero-shot
reasoning tasks across a wide range of domains, they do not perform
satisfactorily in problems which requires multi-step reasoning. Previous
approaches to mitigate this involves breaking a larger, multi-step task into
sub-tasks and asking the language model to generate proposals (""thoughts"") for
each sub-task and using exhaustive planning approaches such as DFS to compose a
solution. In this work, we leverage this idea to introduce two new
contributions: first, we formalize a planning-based approach to perform
multi-step problem solving with LMs via Partially Observable Markov Decision
Processes (POMDPs), with the LM's own reflections about the value of a state
used as a search heuristic; second, leveraging the online POMDP solver POMCP,
we demonstrate a superior success rate of 89.4% on the Game of 24 task as
compared to existing approaches while also offering better anytime performance
characteristics than fixed tree-search which is used previously. Taken
together, these contributions allow modern LMs to decompose and solve
larger-scale reasoning tasks more effectively.",2024-04-29,Houjun Liu,http://arxiv.org/pdf/2404.19055v1,cs.CL
A Framework for Real-time Safeguarding the Text Generation of Large Language Model,"Large Language Models (LLMs) have significantly advanced natural language
processing (NLP) tasks but also pose ethical and societal risks due to their
propensity to generate harmful content. Existing methods have limitations,
including the need for training specific control models and proactive
intervention during text generation, that lead to quality degradation and
increased computational overhead. To mitigate those limitations, we propose
LLMSafeGuard, a lightweight real-time framework that integrates an external
validator into decoding, rejecting unsafe outputs while allowing valid ones. We
introduce a similarity-based validation approach, simplifying constraint
introduction and eliminating the need for control model training. Additionally,
LLMSafeGuard employs a context-wise timing selection strategy, intervening LLMs
only when necessary. We evaluate LLMSafeGuard on detoxification and copyright
safeguarding, demonstrating its superiority over SOTA baselines. In
detoxification, LLMSafeGuard reduces toxic output by at least 38.6\% while
preserving linguistic quality. Additionally, its context-wise timing selection
cuts inference time by at least 24.2\% without compromising effectiveness.",2024-04-29,"Ximing Dong, Dayi Lin, Shaowei Wang, Ahmed E. Hassan",http://arxiv.org/pdf/2404.19048v3,cs.CL
How Did We Get Here? Summarizing Conversation Dynamics,"Throughout a conversation, the way participants interact with each other is
in constant flux: their tones may change, they may resort to different
strategies to convey their points, or they might alter their interaction
patterns. An understanding of these dynamics can complement that of the actual
facts and opinions discussed, offering a more holistic view of the trajectory
of the conversation: how it arrived at its current state and where it is likely
heading.
  In this work, we introduce the task of summarizing the dynamics of
conversations, by constructing a dataset of human-written summaries, and
exploring several automated baselines. We evaluate whether such summaries can
capture the trajectory of conversations via an established downstream task:
forecasting whether an ongoing conversation will eventually derail into toxic
behavior. We show that they help both humans and automated systems with this
forecasting task. Humans make predictions three times faster, and with greater
confidence, when reading the summaries than when reading the transcripts.
Furthermore, automated forecasting systems are more accurate when constructing,
and then predicting based on, summaries of conversation dynamics, compared to
directly predicting on the transcripts.",2024-04-29,"Yilun Hua, Nicholas Chernogor, Yuzhe Gu, Seoyeon Julie Jeong, Miranda Luo, Cristian Danescu-Niculescu-Mizil",http://arxiv.org/pdf/2404.19007v1,cs.CL
Stylus: Automatic Adapter Selection for Diffusion Models,"Beyond scaling base models with more data or parameters, fine-tuned adapters
provide an alternative way to generate high fidelity, custom images at reduced
costs. As such, adapters have been widely adopted by open-source communities,
accumulating a database of over 100K adapters-most of which are highly
customized with insufficient descriptions. This paper explores the problem of
matching the prompt to a set of relevant adapters, built on recent work that
highlight the performance gains of composing adapters. We introduce Stylus,
which efficiently selects and automatically composes task-specific adapters
based on a prompt's keywords. Stylus outlines a three-stage approach that first
summarizes adapters with improved descriptions and embeddings, retrieves
relevant adapters, and then further assembles adapters based on prompts'
keywords by checking how well they fit the prompt. To evaluate Stylus, we
developed StylusDocs, a curated dataset featuring 75K adapters with
pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion
checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as
preferred, with humans and multimodal models as evaluators, over the base
model. See stylus-diffusion.github.io for more.",2024-04-29,"Michael Luo, Justin Wong, Brandon Trabucco, Yanping Huang, Joseph E. Gonzalez, Zhifeng Chen, Ruslan Salakhutdinov, Ion Stoica",http://arxiv.org/pdf/2404.18928v1,cs.CL
Holmes: A Benchmark to Assess the Linguistic Competence of Language Models,"We introduce Holmes, a new benchmark designed to assess language models (LMs)
linguistic competence - their unconscious understanding of linguistic
phenomena. Specifically, we use classifier-based probing to examine LMs'
internal representations regarding distinct linguistic phenomena (e.g.,
part-of-speech tagging). As a result, we meet recent calls to disentangle LMs'
linguistic competence from other cognitive abilities, such as following
instructions in prompting-based evaluations. Composing Holmes, we review over
270 probing studies and include more than 200 datasets to assess syntax,
morphology, semantics, reasoning, and discourse phenomena. Analyzing over 50
LMs reveals that, aligned with known trends, their linguistic competence
correlates with model size. However, surprisingly, model architecture and
instruction tuning also significantly influence performance, particularly in
morphology and syntax. Finally, we propose FlashHolmes, a streamlined version
that reduces the computation load while maintaining high-ranking precision.",2024-04-29,"Andreas Waldis, Yotam Perlitz, Leshem Choshen, Yufang Hou, Iryna Gurevych",http://arxiv.org/pdf/2404.18923v4,cs.CL
DPO Meets PPO: Reinforced Token Optimization for RLHF,"In the classical Reinforcement Learning from Human Feedback (RLHF) framework,
Proximal Policy Optimization (PPO) is employed to learn from sparse,
sentence-level rewards -- a challenging scenario in traditional deep
reinforcement learning. Despite the great successes of PPO in the alignment of
large language models, its open-source implementation is still largely
sub-optimal. To address these issues, we introduce a framework that models RLHF
problems as a Markov decision process (MDP), enabling the capture of
fine-grained token-wise information. Under this framework, we introduce an
algorithm Reinforced Token Optimization (\texttt{RTO}), which learns the
token-wise reward function from preference data and performs policy
optimization based on this learned token-wise reward signal. Theoretically,
\texttt{RTO} is proven to have the capability of finding the near-optimal
policy sample-efficiently. For its practical implementation, \texttt{RTO}
innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,
originally derived from sparse sentence rewards, surprisingly provides us with
a token-wise characterization of response quality, which is seamlessly
incorporated into our subsequent PPO training stage. Extensive experiments
demonstrate that \texttt{RTO} performs better than PPO and other direct
preference learning algorithms. In particular, RTO outperforms PPO by 7.5
points on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our code
and models are available at
\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}.",2024-04-29,"Han Zhong, Zikang Shan, Guhao Feng, Wei Xiong, Xinle Cheng, Li Zhao, Di He, Jiang Bian, Liwei Wang",http://arxiv.org/pdf/2404.18922v4,cs.CL
Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting,"Speculative decoding has demonstrated its effectiveness in accelerating the
inference of large language models while maintaining a consistent sampling
distribution. However, the conventional approach of training a separate draft
model to achieve a satisfactory token acceptance rate can be costly. Drawing
inspiration from early exiting, we propose a novel self-speculative decoding
framework \emph{Kangaroo}, which uses a fixed shallow sub-network as a
self-draft model, with the remaining layers serving as the larger target model.
We train a lightweight and efficient adapter module on top of the sub-network
to bridge the gap between the sub-network and the full model's representation
ability. It is noteworthy that the inference latency of the self-draft model
may no longer be negligible compared to the large model, necessitating
strategies to increase the token acceptance rate while minimizing the drafting
steps of the small model. To address this challenge, we introduce an additional
early exiting mechanism for generating draft tokens. Specifically, we halt the
small model's subsequent prediction during the drafting phase once the
confidence level for the current token falls below a certain threshold.
Extensive experiments on the Spec-Bench demonstrate the effectiveness of
Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to
$1.68\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\% fewer additional
parameters (67M compared to 591M). The code for Kangaroo is available at
https://github.com/Equationliu/Kangaroo.",2024-04-29,"Fangcheng Liu, Yehui Tang, Zhenhua Liu, Yunsheng Ni, Kai Han, Yunhe Wang",http://arxiv.org/pdf/2404.18911v1,cs.CL
Markovian Transformers for Informative Language Modeling,"Chain-of-Thought (CoT) reasoning often fails to faithfully reflect a language
model's underlying decision process. We address this by making CoT text
causally essential in a ""Markovian"" language model, factoring next-token
prediction through an intermediate CoT and training it to predict future tokens
independently of the original prompt. We formalize this via an
""informativeness"" objective that quantifies how much a trained CoT improves
next-token predictions over a baseline. Using policy gradient, we show that
Llama 3.1 8B achieves a 33.2% absolute accuracy improvement on GSM8K.
Perturbation tests confirm stronger reliance on the CoT, while cross-model
transfers indicate these reasoning traces generalize across interpreters. Our
approach enhances both accuracy and interpretability, potentially extending CoT
reasoning to arbitrarily long contexts and diverse tasks.",2024-04-29,"Scott Viteri, Max Lamparth, Peter Chatain, Clark Barrett",http://arxiv.org/pdf/2404.18988v5,cs.CL
Spivavtor: An Instruction Tuned Ukrainian Text Editing Model,"We introduce Spivavtor, a dataset, and instruction-tuned models for text
editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused
adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor
performs text editing tasks by following instructions in Ukrainian. This paper
describes the details of the Spivavtor-Instruct dataset and Spivavtor models.
We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as
Grammatical Error Correction (GEC), Text Simplification, Coherence, and
Paraphrasing, and demonstrate its superior performance on all of them. We
publicly release our best-performing models and data as resources to the
community to advance further research in this space.",2024-04-29,"Aman Saini, Artem Chernodub, Vipul Raheja, Vivek Kulkarni",http://arxiv.org/pdf/2404.18880v1,cs.CL
"More RLHF, More Trust? On The Impact of Preference Alignment On Trustworthiness","The trustworthiness of Large Language Models (LLMs) refers to the extent to
which their outputs are reliable, safe, and ethically aligned, and it has
become a crucial consideration alongside their cognitive performance. In
practice, Reinforcement Learning From Human Feedback (RLHF) has been widely
used to align LLMs with labeled human preferences, but its assumed effect on
model trustworthiness hasn't been rigorously evaluated. To bridge this
knowledge gap, this study investigates how models aligned with general-purpose
preference data perform across five trustworthiness verticals: toxicity,
stereotypical bias, machine ethics, truthfulness, and privacy. Our results
demonstrate that RLHF on human preferences doesn't automatically guarantee
trustworthiness, and reverse effects are often observed. Furthermore, we
propose to adapt efficient influence function based data attribution methods to
the RLHF setting to better understand the influence of fine-tuning data on
individual trustworthiness benchmarks, and show its feasibility by providing
our estimated attribution scores. Together, our results underscore the need for
more nuanced approaches for model alignment from both the data and framework
perspectives, and we hope this research will guide the community towards
developing language models that are increasingly capable without sacrificing
trustworthiness.",2024-04-29,"Aaron J. Li, Satyapriya Krishna, Himabindu Lakkaraju",http://arxiv.org/pdf/2404.18870v2,cs.CL
Truth-value judgment in language models: belief directions are context sensitive,"Recent work has demonstrated that the latent spaces of large language models
(LLMs) contain directions predictive of the truth of sentences. Multiple
methods recover such directions and build probes that are described as getting
at a model's ""knowledge"" or ""beliefs"". We investigate this phenomenon, looking
closely at the impact of context on the probes. Our experiments establish where
in the LLM the probe's predictions can be described as being conditional on the
preceding (related) sentences. Specifically, we quantify the responsiveness of
the probes to the presence of (negated) supporting and contradicting sentences,
and score the probes on their consistency. We also perform a causal
intervention experiment, investigating whether moving the representation of a
premise along these belief directions influences the position of the hypothesis
along that same direction. We find that the probes we test are generally
context sensitive, but that contexts which should not affect the truth often
still impact the probe outputs. Our experiments show that the type of errors
depend on the layer, the (type of) model, and the kind of data. Finally, our
results suggest that belief directions are (one of the) causal mediators in the
inference process that incorporates in-context information.",2024-04-29,"Stefan F. Schouten, Peter Bloem, Ilia Markov, Piek Vossen",http://arxiv.org/pdf/2404.18865v1,cs.CL
A Comprehensive Rubric for Annotating Pathological Speech,"Rubrics are a commonly used tool for labeling voice corpora in speech quality
assessment, although their application in the context of pathological speech
remains relatively limited. In this study, we introduce a comprehensive rubric
based on various dimensions of speech quality, including phonetics, fluency,
and prosody. The objective is to establish standardized criteria for
identifying errors within the speech of individuals with Down syndrome, thereby
enabling the development of automated assessment systems. To achieve this
objective, we utilized the Prautocal corpus. To assess the quality of
annotations using our rubric, two experiments were conducted, focusing on
phonetics and fluency. For phonetic evaluation, we employed the Goodness of
Pronunciation (GoP) metric, utilizing automatic segmentation systems and
correlating the results with evaluations conducted by a specialized speech
therapist. While the obtained correlation values were not notably high, a
positive trend was observed. In terms of fluency assessment, deep learning
models like wav2vec were used to extract audio features, and we employed an SVM
classifier trained on a corpus focused on identifying fluency issues to
categorize Prautocal corpus samples. The outcomes highlight the complexities of
evaluating such phenomena, with variability depending on the specific type of
disfluency detected.",2024-04-29,"Mario Corrales-Astorgano, David Escudero-Mancebo, Lourdes Aguilar, Valle Flores-Lucas, Valentín Cardeñoso-Payo, Carlos Vivaracho-Pascual, César González-Ferreras",http://arxiv.org/pdf/2404.18851v1,cs.CL
FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition,"Despite their exceptional performance on various tasks after fine-tuning,
pre-trained language models (PLMs) face significant challenges due to growing
privacy concerns with data in centralized training methods. We consider
federated learning (FL) to fine-tune PLMs in this paper. However, the
substantial number of parameters in PLMs poses significant difficulties for
client devices with limited communication and computational resources. One
promising solution is to exploit parameter-efficient fine-tuning (PEFT) into
FL, which trains a much smaller set of parameters than full parameter
fine-tuning (FFT). Although remarkably improving training efficiency, PEFT
methods may lead to degraded performance especially when data across different
clients are non i.i.d, as revealed by experimental results. To overcome this,
we propose FeDeRA, which extends and improves a widely used PEFT method, i.e.,
low-rank adaption (LoRA). FeDeRA follows LoRA by decomposing the weight
matrices of the PLMs into low-rank matrices, which allows for more efficient
computation and parameter updates during fine-tuning. Different from LoRA which
simply initializes these low-rank matrices by random sampling or zeros, the
proposed FeDeRA initializes these matrices by the results of performing
singular value decomposition (SVD) on the pre-trained weight matrices.
Extensive experiments across various tasks and datasets show that FeDeRA
outperforms the considered PEFT baselines and is comparable to or even
surpasses FFT method within the FL setting in terms of task performance.
Moreover, FeDeRA requires only 1% trainable paramentes compared to FFT,
significantly reducing training time costs by more than 90% to achieve the same
task performance level. The experimental results also highlight the robustness
of FeDeRA against data heterogeneity, as it maintains stable task performance
even as data heterogeneity increases.",2024-04-29,"Yuxuan Yan, Qianqian Yang, Shunpu Tang, Zhiguo Shi",http://arxiv.org/pdf/2404.18848v3,cs.CL
It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments,"Sentiment analysis is an important tool for aggregating patient voices, in
order to provide targeted improvements in healthcare services. A prerequisite
for this is the availability of in-domain data annotated for sentiment. This
article documents an effort to add sentiment annotations to free-text comments
in patient surveys collected by the Norwegian Institute of Public Health
(NIPH). However, annotation can be a time-consuming and resource-intensive
process, particularly when it requires domain expertise. We therefore also
evaluate a possible alternative to human annotation, using large language
models (LLMs) as annotators. We perform an extensive evaluation of the approach
for two openly available pretrained LLMs for Norwegian, experimenting with
different configurations of prompts and in-context learning, comparing their
performance to human annotators. We find that even for zero-shot runs, models
perform well above the baseline for binary sentiment, but still cannot compete
with human annotators on the full dataset.",2024-04-29,"Petter Mæhlum, David Samuel, Rebecka Maria Norman, Elma Jelin, Øyvind Andresen Bjertnæs, Lilja Øvrelid, Erik Velldal",http://arxiv.org/pdf/2404.18832v1,cs.CL
Benchmarking Benchmark Leakage in Large Language Models,"Amid the expanding use of pre-training data, the phenomenon of benchmark
dataset leakage has become increasingly prominent, exacerbated by opaque
training processes and the often undisclosed inclusion of supervised data in
contemporary Large Language Models (LLMs). This issue skews benchmark
effectiveness and fosters potentially unfair comparisons, impeding the field's
healthy development. To address this, we introduce a detection pipeline
utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that
gauge a model's prediction precision on benchmark, to identify potential data
leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we
reveal substantial instances of training even test set misuse, resulting in
potentially unfair comparisons. These findings prompt us to offer several
recommendations regarding model documentation, benchmark setup, and future
evaluations. Notably, we propose the ""Benchmark Transparency Card"" to encourage
clear documentation of benchmark utilization, promoting transparency and
healthy developments of LLMs. we have made our leaderboard, pipeline
implementation, and model predictions publicly available, fostering future
research.",2024-04-29,"Ruijie Xu, Zengzhi Wang, Run-Ze Fan, Pengfei Liu",http://arxiv.org/pdf/2404.18824v1,cs.CL
Unknown Script: Impact of Script on Cross-Lingual Transfer,"Cross-lingual transfer has become an effective way of transferring knowledge
between languages. In this paper, we explore an often overlooked aspect in this
domain: the influence of the source language of a language model on language
transfer performance. We consider a case where the target language and its
script are not part of the pre-trained model. We conduct a series of
experiments on monolingual and multilingual models that are pre-trained on
different tokenization methods to determine factors that affect cross-lingual
transfer to a new language with a unique script. Our findings reveal the
importance of the tokenizer as a stronger factor than the shared script,
language similarity, and model size.",2024-04-29,"Wondimagegnhue Tsegaye Tufa, Ilia Markov, Piek Vossen",http://arxiv.org/pdf/2404.18810v2,cs.CL
Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models,"As Large Language Models (LLMs) have become more advanced, they have outpaced
our abilities to accurately evaluate their quality. Not only is finding data to
adequately probe particular model properties difficult, but evaluating the
correctness of a model's freeform generation alone is a challenge. To address
this, many evaluations now rely on using LLMs themselves as judges to score the
quality of outputs from other LLMs. Evaluations most commonly use a single
large model like GPT4. While this method has grown in popularity, it is costly,
has been shown to introduce intramodel bias, and in this work, we find that
very large models are often unnecessary. We propose instead to evaluate models
using a Panel of LLm evaluators (PoLL). Across three distinct judge settings
and spanning six different datasets, we find that using a PoLL composed of a
larger number of smaller models outperforms a single large judge, exhibits less
intra-model bias due to its composition of disjoint model families, and does so
while being over seven times less expensive.",2024-04-29,"Pat Verga, Sebastian Hofstatter, Sophia Althammer, Yixuan Su, Aleksandra Piktus, Arkady Arkhangorodsky, Minjie Xu, Naomi White, Patrick Lewis",http://arxiv.org/pdf/2404.18796v2,cs.CL
Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input,"Geo-entity linking is the task of linking a location mention to the
real-world geographic location. In this paper we explore the challenging task
of geo-entity linking for noisy, multilingual social media data. There are few
open-source multilingual geo-entity linking tools available and existing ones
are often rule-based, which break easily in social media settings, or
LLM-based, which are too expensive for large-scale datasets. We present a
method which represents real-world locations as averaged embeddings from
labeled user-input location names and allows for selective prediction via an
interpretable confidence score. We show that our approach improves geo-entity
linking on a global and multilingual social media dataset, and discuss progress
and problems with evaluating at different geographic granularities.",2024-04-29,"Tessa Masis, Brendan O'Connor",http://arxiv.org/pdf/2404.18784v1,cs.CL
Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective,"In recent years, the field of Legal Tech has risen in prevalence, as the
Natural Language Processing (NLP) and legal disciplines have combined forces to
digitalize legal processes. Amidst the steady flow of research solutions
stemming from the NLP domain, the study of use cases has fallen behind, leading
to a number of innovative technical methods without a place in practice. In
this work, we aim to build a structured overview of Legal Tech use cases,
grounded in NLP literature, but also supplemented by voices from legal practice
in Germany. Based upon a Systematic Literature Review, we identify seven
categories of NLP technologies for the legal domain, which are then studied in
juxtaposition to 22 legal use cases. In the investigation of these use cases,
we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the
potential concerns of digitally transforming the legal domain.",2024-04-29,"Juraj Vladika, Stephen Meisenbacher, Martina Preis, Alexandra Klymenko, Florian Matthes",http://arxiv.org/pdf/2404.18759v2,cs.CL
Computational Job Market Analysis with Natural Language Processing,"[Abridged Abstract]
  Recent technological advances underscore labor market dynamics, yielding
significant consequences for employment prospects and increasing job vacancy
data across platforms and languages. Aggregating such data holds potential for
valuable insights into labor market demands, new skills emergence, and
facilitating job matching for various stakeholders. However, despite prevalent
insights in the private sector, transparent language technology systems and
data for this domain are lacking. This thesis investigates Natural Language
Processing (NLP) technology for extracting relevant information from job
descriptions, identifying challenges including scarcity of training data, lack
of standardized annotation guidelines, and shortage of effective extraction
methods from job ads. We frame the problem, obtaining annotated data, and
introducing extraction methodologies. Our contributions include job description
datasets, a de-identification dataset, and a novel active learning algorithm
for efficient model training. We propose skill extraction using weak
supervision, a taxonomy-aware pre-training methodology adapting multilingual
language models to the job market domain, and a retrieval-augmented model
leveraging multiple skill extraction datasets to enhance overall performance.
Finally, we ground extracted information within a designated taxonomy.",2024-04-29,Mike Zhang,http://arxiv.org/pdf/2404.18977v1,cs.CL
Foundations of Multisensory Artificial Intelligence,"Building multisensory AI systems that learn from multiple sensory inputs such
as text, speech, video, real-world sensors, wearable devices, and medical data
holds great promise for impact in many scientific areas with practical
benefits, such as in supporting human health and well-being, enabling
multimedia content processing, and enhancing real-world autonomous agents. By
synthesizing a range of theoretical frameworks and application domains, this
thesis aims to advance the machine learning foundations of multisensory AI. In
the first part, we present a theoretical framework formalizing how modalities
interact with each other to give rise to new information for a task. These
interactions are the basic building blocks in all multimodal problems, and
their quantification enables users to understand their multimodal datasets,
design principled approaches to learn these interactions, and analyze whether
their model has succeeded in learning. In the second part, we study the design
of practical multimodal foundation models that generalize over many modalities
and tasks, which presents a step toward grounding large language models to
real-world sensory modalities. We introduce MultiBench, a unified large-scale
benchmark across a wide range of modalities, tasks, and research areas,
followed by the cross-modal attention and multimodal transformer architectures
that now underpin many of today's multimodal foundation models. Scaling these
architectures on MultiBench enables the creation of general-purpose
multisensory AI systems, and we discuss our collaborative efforts in applying
these models for real-world impact in affective computing, mental health,
cancer prognosis, and robotics. Finally, we conclude this thesis by discussing
how future work can leverage these ideas toward more general, interactive, and
safe multisensory AI.",2024-04-29,Paul Pu Liang,http://arxiv.org/pdf/2404.18976v1,cs.CL
Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification,"Similar to humans, animals make extensive use of verbal and non-verbal forms
of communication, including a large range of audio signals. In this paper, we
address dog vocalizations and explore the use of self-supervised speech
representation models pre-trained on human speech to address dog bark
classification tasks that find parallels in human-centered tasks in speech
recognition. We specifically address four tasks: dog recognition, breed
identification, gender classification, and context grounding. We show that
using speech embedding representations significantly improves over simpler
classification baselines. Further, we also find that models pre-trained on
large human speech acoustics can provide additional performance boosts on
several tasks.",2024-04-29,"Artem Abzaliev, Humberto Pérez Espinosa, Rada Mihalcea",http://arxiv.org/pdf/2404.18739v1,cs.CL
The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages,"Toxic language remains an ongoing challenge on social media platforms,
presenting significant issues for users and communities. This paper provides a
cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We
collect 1.5 million comment threads from 481 communities in six languages:
English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as
Culture, Politics, and News. We thoroughly analyze how toxicity spikes within
different communities in relation to specific topics. We observe consistent
patterns of increased toxicity across languages for certain topics, while also
noting significant variations within specific language communities.",2024-04-29,"Wondimagegnhue Tsegaye Tufa, Ilia Markov, Piek Vossen",http://arxiv.org/pdf/2404.18726v1,cs.CL
Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library,"PyLaia is one of the most popular open-source software for Automatic Text
Recognition (ATR), delivering strong performance in terms of speed and
accuracy. In this paper, we outline our recent contributions to the PyLaia
library, focusing on the incorporation of reliable confidence scores and the
integration of statistical language modeling during decoding. Our
implementation provides an easy way to combine PyLaia with n-grams language
models at different levels. One of the highlights of this work is that language
models are completely auto-tuned: they can be built and used easily without any
expert knowledge, and without requiring any additional data. To demonstrate the
significance of our contribution, we evaluate PyLaia's performance on twelve
datasets, both with and without language modelling. The results show that
decoding with small language models improves the Word Error Rate by 13% and the
Character Error Rate by 12% in average. Additionally, we conduct an analysis of
confidence scores and highlight the importance of calibration techniques. Our
implementation is publicly available in the official PyLaia repository at
https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are
released on Hugging Face.",2024-04-29,"Solène Tarride, Yoann Schneider, Marie Generali-Lince, Mélodie Boillet, Bastien Abadie, Christopher Kermorvant",http://arxiv.org/pdf/2404.18722v1,cs.CL
Iconic Gesture Semantics,"The ""meaning"" of an iconic gesture is conditioned on its informational
evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic
level that can interact with verbal content. Interaction is either vacuous or
regimented by usual lexicon-driven inferences. Informational evaluation is
spelled out as extended exemplification (extemplification) in terms of
perceptual classification of a gesture's visual iconic model. The iconic model
is derived from Frege/Montague-like truth-functional evaluation of a gesture's
form within spatially extended domains. We further argue that the perceptual
classification of instances of visual communication requires a notion of
meaning different from Frege/Montague frameworks. Therefore, a heuristic for
gesture interpretation is provided that can guide the working semanticist. In
sum, an iconic gesture semantics is introduced which covers the full range from
kinematic gesture representations over model-theoretic evaluation to
inferential interpretation in dynamic semantic frameworks.",2024-04-29,"Andy Lücking, Alexander Henlein, Alexander Mehler",http://arxiv.org/pdf/2404.18708v1,cs.CL
"Credible, Unreliable or Leaked?: Evidence Verification for Enhanced Automated Fact-checking","Automated fact-checking (AFC) is garnering increasing attention by
researchers aiming to help fact-checkers combat the increasing spread of
misinformation online. While many existing AFC methods incorporate external
information from the Web to help examine the veracity of claims, they often
overlook the importance of verifying the source and quality of collected
""evidence"". One overlooked challenge involves the reliance on ""leaked
evidence"", information gathered directly from fact-checking websites and used
to train AFC systems, resulting in an unrealistic setting for early
misinformation detection. Similarly, the inclusion of information from
unreliable sources can undermine the effectiveness of AFC systems. To address
these challenges, we present a comprehensive approach to evidence verification
and filtering. We create the ""CREDible, Unreliable or LEaked"" (CREDULE)
dataset, which consists of 91,632 articles classified as Credible, Unreliable
and Fact checked (Leaked). Additionally, we introduce the EVidence VERification
Network (EVVER-Net), trained on CREDULE to detect leaked and unreliable
evidence in both short and long texts. EVVER-Net can be used to filter evidence
collected from the Web, thus enhancing the robustness of end-to-end AFC
systems. We experiment with various language models and show that EVVER-Net can
demonstrate impressive performance of up to 91.5% and 94.4% accuracy, while
leveraging domain credibility scores along with short or long texts,
respectively. Finally, we assess the evidence provided by widely-used
fact-checking datasets including LIAR-PLUS, MOCHEG, FACTIFY, NewsCLIPpings+ and
VERITE, some of which exhibit concerning rates of leaked and unreliable
evidence.",2024-04-29,"Zacharias Chrysidis, Stefanos-Iordanis Papadopoulos, Symeon Papadopoulos, Panagiotis C. Petrantonakis",http://arxiv.org/pdf/2404.18971v1,cs.CL
Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages,"Dependency length minimization is a universally observed quantitative
property of natural languages. However, the extent of dependency length
minimization, and the cognitive mechanisms through which the language processor
achieves this minimization remain unclear. This research offers mechanistic
insights by postulating that moving a short preverbal constituent next to the
main verb explains preverbal constituent ordering decisions better than global
minimization of dependency length in SOV languages. This approach constitutes a
least-effort strategy because it's just one operation but simultaneously
reduces the length of all preverbal dependencies linked to the main verb. We
corroborate this strategy using large-scale corpus evidence across all seven
SOV languages that are prominently represented in the Universal Dependency
Treebank. These findings align with the concept of bounded rationality, where
decision-making is influenced by 'quick-yet-economical' heuristics rather than
exhaustive searches for optimal solutions. Overall, this work sheds light on
the role of bounded rationality in linguistic decision-making and language
evolution.",2024-04-29,"Sidharth Ranjan, Titus von der Malsburg",http://arxiv.org/pdf/2404.18684v2,cs.CL
Simplifying Multimodality: Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model,"Recent advancements in Large Multimodal Models (LMMs) have attracted interest
in their generalization capability with only a few samples in the prompt. This
progress is particularly relevant to the medical domain, where the quality and
sensitivity of data pose unique challenges for model training and application.
However, the dependency on high-quality data for effective in-context learning
raises questions about the feasibility of these models when encountering with
the inevitable variations and errors inherent in real-world medical data. In
this paper, we introduce MID-M, a novel framework that leverages the in-context
learning capabilities of a general-domain Large Language Model (LLM) to process
multimodal data via image descriptions. MID-M achieves a comparable or superior
performance to task-specific fine-tuned LMMs and other general-domain ones,
without the extensive domain-specific training or pre-training on multimodal
data, with significantly fewer parameters. This highlights the potential of
leveraging general-domain LLMs for domain-specific tasks and offers a
sustainable and cost-effective alternative to traditional LMM developments.
Moreover, the robustness of MID-M against data quality issues demonstrates its
practical utility in real-world medical domain applications.",2024-04-29,"Seonhee Cho, Choonghan Kim, Jiho Lee, Chetan Chilkunda, Sujin Choi, Joo Heung Yoon",http://arxiv.org/pdf/2405.01591v1,cs.CL
101 Billion Arabic Words Dataset,"In recent years, Large Language Models have revolutionized the field of
natural language processing, showcasing an impressive rise predominantly in
English-centric domains. These advancements have set a global benchmark,
inspiring significant efforts toward developing Arabic LLMs capable of
understanding and generating the Arabic language with remarkable accuracy.
Despite these advancements, a critical challenge persists: the potential bias
in Arabic LLMs, primarily attributed to their reliance on datasets comprising
English data that has been translated into Arabic. This reliance not only
compromises the authenticity of the generated content but also reflects a
broader issue -the scarcity of original quality Arabic linguistic data. This
study aims to address the data scarcity in the Arab world and to encourage the
development of Arabic Language Models that are true to both the linguistic and
nuances of the region. We undertook a large-scale data mining project,
extracting a substantial volume of text from the Common Crawl WET files,
specifically targeting Arabic content. The extracted data underwent a rigorous
cleaning and deduplication process, using innovative techniques to ensure the
integrity and uniqueness of the dataset. The result is the 101 Billion Arabic
Words Dataset, the largest Arabic dataset available to date, which can
significantly contribute to the development of authentic Arabic LLMs. This
study not only highlights the potential for creating linguistically and
culturally accurate Arabic LLMs but also sets a precedent for future research
in enhancing the authenticity of Arabic language models.",2024-04-29,"Manel Aloui, Hasna Chouikhi, Ghaith Chaabane, Haithem Kchaou, Chehir Dhaouadi",http://arxiv.org/pdf/2405.01590v1,cs.CL
Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods,"Language Models (LMs) acquire parametric knowledge from their training
process, embedding it within their weights. The increasing scalability of LMs,
however, poses significant challenges for understanding a model's inner
workings and further for updating or correcting this embedded knowledge without
the significant cost of retraining. This underscores the importance of
unveiling exactly what knowledge is stored and its association with specific
model components. Instance Attribution (IA) and Neuron Attribution (NA) offer
insights into this training-acquired knowledge, though they have not been
compared systematically. Our study introduces a novel evaluation framework to
quantify and compare the knowledge revealed by IA and NA. To align the results
of the methods we introduce the attribution method NA-Instances to apply NA for
retrieving influential training instances, and IA-Neurons to discover important
neurons of influential instances discovered by IA. We further propose a
comprehensive list of faithfulness tests to evaluate the comprehensiveness and
sufficiency of the explanations provided by both methods. Through extensive
experiments and analysis, we demonstrate that NA generally reveals more diverse
and comprehensive information regarding the LM's parametric knowledge compared
to IA. Nevertheless, IA provides unique and valuable insights into the LM's
parametric knowledge, which are not revealed by NA. Our findings further
suggest the potential of a synergistic approach of combining the diverse
findings of IA and NA for a more holistic understanding of an LM's parametric
knowledge.",2024-04-29,"Haeun Yu, Pepa Atanasova, Isabelle Augenstein",http://arxiv.org/pdf/2404.18655v1,cs.CL
A cost minimization approach to fix the vocabulary size in a tokenizer for an End-to-End ASR system,"Unlike hybrid speech recognition systems where the use of tokens was
restricted to phones, biphones or triphones the choice of tokens in the
end-to-end ASR systems is derived from the text corpus of the training data.
The use of tokenization algorithms like Byte Pair Encoding (BPE) and WordPiece
is popular in identifying the tokens that are used in the overall training
process of the speech recognition system. Popular toolkits, like ESPNet use a
pre-defined vocabulary size (number of tokens) for these tokenization
algorithms, but there is no discussion on how vocabulary size was derived. In
this paper, we build a cost function, assuming the tokenization process to be a
black-box to enable choosing the number of tokens which might most benefit
building an end-to-end ASR. We show through experiments on LibriSpeech 100 hour
set that the performance of an end-to-end ASR system improves when the number
of tokens are chosen carefully.",2024-04-29,"Sunil Kumar Kopparapu, Ashish Panda",http://arxiv.org/pdf/2406.02563v1,cs.CL
Reinforcement Learning Problem Solving with Large Language Models,"Large Language Models (LLMs) encapsulate an extensive amount of world
knowledge, and this has enabled their application in various domains to improve
the performance of a variety of Natural Language Processing (NLP) tasks. This
has also facilitated a more accessible paradigm of conversation-based
interactions between humans and AI systems to solve intended problems. However,
one interesting avenue that shows untapped potential is the use of LLMs as
Reinforcement Learning (RL) agents to enable conversational RL problem solving.
Therefore, in this study, we explore the concept of formulating Markov Decision
Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can
be iteratively prompted to learn and optimize policies for specific RL tasks.
In addition, we leverage the introduced prompting technique for episode
simulation and Q-Learning, facilitated by LLMs. We then show the practicality
of our approach through two detailed case studies for ""Research Scientist"" and
""Legal Matter Intake"" workflows.",2024-04-29,"Sina Gholamian, Domingo Huh",http://arxiv.org/pdf/2404.18638v1,cs.CL
Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?,"Vision and language model (VLM) decoders are currently the best-performing
architectures on multimodal tasks. Next to answers, they are able to produce
natural language explanations, either in post-hoc or CoT settings. However, it
is not clear to what extent they are using the input vision and text modalities
when generating answers or explanations. In this work, we investigate if VLMs
rely on their input modalities differently when they produce explanations as
opposed to answers. We also evaluate the self-consistency of VLM decoders in
both post-hoc and CoT explanation settings, by extending existing unimodal
tests and measures to VLM decoders. We find that most tested VLMs are less
self-consistent than LLMs. Text contributions in all tested VL decoders are
more important than image contributions in all examined tasks. However, when
comparing explanation generation to answer generation, the contributions of
images are significantly stronger for generating explanations compared to
answers. This difference is even larger in CoT compared to post-hoc
explanations. Lastly, we provide an up-to-date benchmarking of state-of-the-art
VL decoders on the VALSE benchmark, which before was restricted to VL encoders.
We find that the tested VL decoders still struggle with most phenomena tested
by VALSE.",2024-04-29,"Letitia Parcalabescu, Anette Frank",http://arxiv.org/pdf/2404.18624v4,cs.CL
The SAMER Arabic Text Simplification Corpus,"We present the SAMER Corpus, the first manually annotated Arabic parallel
corpus for text simplification targeting school-aged learners. Our corpus
comprises texts of 159K words selected from 15 publicly available Arabic
fiction novels most of which were published between 1865 and 1955. Our corpus
includes readability level annotations at both the document and word levels, as
well as two simplified parallel versions for each text targeting learners at
two different readability levels. We describe the corpus selection process, and
outline the guidelines we followed to create the annotations and ensure their
quality. Our corpus is publicly available to support and encourage research on
Arabic text simplification, Arabic automatic readability assessment, and the
development of Arabic pedagogical language technologies.",2024-04-29,"Bashar Alhafni, Reem Hazim, Juan Piñeros Liberato, Muhamed Al Khalil, Nizar Habash",http://arxiv.org/pdf/2404.18615v1,cs.CL
FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering,"Table Question Answering (TQA) aims at composing an answer to a question
based on tabular data. While prior research has shown that TQA models lack
robustness, understanding the underlying cause and nature of this issue remains
predominantly unclear, posing a significant obstacle to the development of
robust TQA systems. In this paper, we formalize three major desiderata for a
fine-grained evaluation of robustness of TQA systems. They should (i) answer
questions regardless of alterations in table structure, (ii) base their
responses on the content of relevant cells rather than on biases, and (iii)
demonstrate robust numerical reasoning capabilities. To investigate these
aspects, we create and publish a novel TQA evaluation benchmark in English. Our
extensive experimental analysis reveals that none of the examined
state-of-the-art TQA systems consistently excels in these three aspects. Our
benchmark is a crucial instrument for monitoring the behavior of TQA systems
and paves the way for the development of robust TQA systems. We release our
benchmark publicly.",2024-04-29,"Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich",http://arxiv.org/pdf/2404.18585v1,cs.CL
PoPE: Legendre Orthogonal Polynomials Based Position Encoding for Large Language Models,"There are several improvements proposed over the baseline Absolute Positional
Encoding (APE) method used in original transformer. In this study, we aim to
investigate the implications of inadequately representing positional encoding
in higher dimensions on crucial aspects of the attention mechanism, the model's
capacity to learn relative positional information, and the convergence of
models, all stemming from the choice of sinusoidal basis functions. Through a
combination of theoretical insights and empirical analyses, we elucidate how
these challenges extend beyond APEs and may adversely affect the performance of
Relative Positional Encoding (RPE) methods, such as Rotatory Positional
Encoding (RoPE).
  Subsequently, we introduce an innovative solution termed Orthogonal
Polynomial Based Positional Encoding (PoPE) to address some of the limitations
associated with existing methods. The PoPE method encodes positional
information by leveraging Orthogonal Legendre polynomials. Legendre polynomials
as basis functions offers several desirable properties for positional encoding,
including improved correlation structure, non-periodicity, orthogonality, and
distinct functional forms among polynomials of varying orders. Our experimental
findings demonstrate that transformer models incorporating PoPE outperform
baseline transformer models on the $Multi30k$ English-to-German translation
task, thus establishing a new performance benchmark. Furthermore, PoPE-based
transformers exhibit significantly accelerated convergence rates.
  Additionally, we will present novel theoretical perspectives on position
encoding based on the superior performance of PoPE.",2024-04-29,Arpit Aggarwal,http://arxiv.org/pdf/2405.04585v1,cs.CL
Analyzing Semantic Change through Lexical Replacements,"Modern language models are capable of contextualizing words based on their
surrounding context. However, this capability is often compromised due to
semantic change that leads to words being used in new, unexpected contexts not
encountered during pre-training. In this paper, we model \textit{semantic
change} by studying the effect of unexpected contexts introduced by
\textit{lexical replacements}. We propose a \textit{replacement schema} where a
target word is substituted with lexical replacements of varying relatedness,
thus simulating different kinds of semantic change. Furthermore, we leverage
the replacement schema as a basis for a novel \textit{interpretable} model for
semantic change. We are also the first to evaluate the use of LLaMa for
semantic change detection.",2024-04-29,"Francesco Periti, Pierluigi Cassotti, Haim Dubossarsky, Nina Tahmasebi",http://arxiv.org/pdf/2404.18570v1,cs.CL
Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning,"Recent research in dialogue systems and corpora has focused on two main
categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD
systems help users accomplish specific tasks, while open-domain systems aim to
create engaging conversations. However, in real-world scenarios, user intents
are often revealed during interactions. A recent study introduced SalesBot,
which simulates dialogues transitioning from chit-chat to task-oriented
scenarios to train sales agents. Unfortunately, the initial data lacked smooth
transitions and coherent long-turn dialogues, resulting in poor naturalness in
sales-customer interactions. To address these issues, this paper presents
SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from
large language models (LLMs) through strategic prompting. Additionally, we
introduce a novel model called SalesAgent, trained on salesperson's
interactions, using chain-of-thought (CoT) reasoning. This model excels in
transitioning topics, understanding user intents, and selecting appropriate
strategies. Experiments using diverse user simulations validate the
effectiveness of our method in controlling dialogue strategies in LLMs.
Furthermore, SalesBot 2.0 enhances coherence and reduces aggression,
facilitating better model learning for sales-customer interactions.",2024-04-29,"Wen-Yu Chang, Yun-Nung Chen",http://arxiv.org/pdf/2404.18564v1,cs.CL
Can GPT-4 do L2 analytic assessment?,"Automated essay scoring (AES) to evaluate second language (L2) proficiency
has been a firmly established technology used in educational contexts for
decades. Although holistic scoring has seen advancements in AES that match or
even exceed human performance, analytic scoring still encounters issues as it
inherits flaws and shortcomings from the human scoring process. The recent
introduction of large language models presents new opportunities for automating
the evaluation of specific aspects of L2 writing proficiency. In this paper, we
perform a series of experiments using GPT-4 in a zero-shot fashion on a
publicly available dataset annotated with holistic scores based on the Common
European Framework of Reference and aim to extract detailed information about
their underlying analytic components. We observe significant correlations
between the automatically predicted analytic scores and multiple features
associated with the individual proficiency components.",2024-04-29,"Stefano Bannò, Hari Krishna Vydana, Kate M. Knill, Mark J. F. Gales",http://arxiv.org/pdf/2404.18557v1,cs.CL
Time Machine GPT,"Large language models (LLMs) are often trained on extensive, temporally
indiscriminate text corpora, reflecting the lack of datasets with temporal
metadata. This approach is not aligned with the evolving nature of language.
Conventional methods for creating temporally adapted language models often
depend on further pre-training static models on time-specific data. This paper
presents a new approach: a series of point-in-time LLMs called Time Machine GPT
(TiMaGPT), specifically designed to be nonprognosticative. This ensures they
remain uninformed about future factual information and linguistic changes. This
strategy is beneficial for understanding language evolution and is of critical
importance when applying models in dynamic contexts, such as time-series
forecasting, where foresight of future information can prove problematic. We
provide access to both the models and training datasets.",2024-04-29,"Felix Drinkall, Eghbal Rahimikia, Janet B. Pierrehumbert, Stefan Zohren",http://arxiv.org/pdf/2404.18543v1,cs.CL
Evaluating and Mitigating Linguistic Discrimination in Large Language Models,"By training on text in various languages, large language models (LLMs)
typically possess multilingual support and demonstrate remarkable capabilities
in solving tasks described in different languages. However, LLMs can exhibit
linguistic discrimination due to the uneven distribution of training data
across languages. That is, LLMs are hard to keep the consistency of responses
when faced with the same task but depicted in different languages.
  In this study, we first explore the consistency in the LLMs' outputs
responding to queries in various languages from two aspects: safety and
quality. We conduct this analysis with two datasets (AdvBench and NQ) based on
four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results
show that LLMs exhibit stronger human alignment capabilities with queries in
English, French, Russian, and Spanish (only 1.04\% of harmful queries
successfully jailbreak on average) compared to queries in Bengali, Georgian,
Nepali and Maithili (27.7\% of harmful queries jailbreak successfully on
average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs
tend to produce responses with a higher quality (with 0.1494 $F_1$ score on
average) compared to the other languages. Upon these findings, we propose
LDFighter, a similarity-based voting, to mitigate the linguistic discrimination
in LLMs. LDFighter ensures consistent service for different language speakers.
We evaluate LDFighter with both benign queries and harmful queries. The results
show that LDFighter not only significantly reduces the jailbreak success rate
but also improve the response quality on average, demonstrating its
effectiveness.",2024-04-29,"Guoliang Dong, Haoyu Wang, Jun Sun, Xinyu Wang",http://arxiv.org/pdf/2404.18534v2,cs.CL
MileBench: Benchmarking MLLMs in Long Context,"Despite the advancements and impressive performance of Multimodal Large
Language Models (MLLMs) on benchmarks, their effectiveness in real-world,
long-context, and multi-image tasks is unclear due to the benchmarks' limited
scope. Existing benchmarks often focus on single-image and short-text samples,
and when assessing multi-image tasks, they either limit the image count or
focus on specific task (e.g time-series captioning), potentially obscuring the
performance challenges of MLLMs. To address these limitations, we introduce
MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt
capabilities of MLLMs. This benchmark comprises not only multimodal long
contexts, but also multiple tasks requiring both comprehension and generation.
We establish two distinct evaluation sets, diagnostic and realistic, to
systematically assess MLLMs' long-context adaptation capacity and their ability
to complete tasks in long-context scenarios. Our experimental results, obtained
from testing 22 models, revealed that while the closed-source GPT-4o
outperforms others, most open-source MLLMs struggle in long-context situations.
Interestingly, the performance gap tends to widen with an increase in the
number of images. We strongly encourage an intensification of research efforts
towards enhancing MLLMs' long-context capabilities, especially in scenarios
involving multiple images.",2024-04-29,"Dingjie Song, Shunian Chen, Guiming Hardy Chen, Fei Yu, Xiang Wan, Benyou Wang",http://arxiv.org/pdf/2404.18532v2,cs.CL
GPT-4 passes most of the 297 written Polish Board Certification Examinations,"Introduction: Recently, the effectiveness of Large Language Models (LLMs) has
increased rapidly, allowing them to be used in a great number of applications.
However, the risks posed by the generation of false information through LLMs
significantly limit their applications in sensitive areas such as healthcare,
highlighting the necessity for rigorous validations to determine their utility
and reliability. To date, no study has extensively compared the performance of
LLMs on Polish medical examinations across a broad spectrum of specialties on a
very large dataset. Objectives: This study evaluated the performance of three
Generative Pretrained Transformer (GPT) models on the Polish Board
Certification Exam (Pa\'nstwowy Egzamin Specjalizacyjny, PES) dataset, which
consists of 297 tests. Methods: We developed a software program to download and
process PES exams and tested the performance of GPT models using OpenAI
Application Programming Interface. Results: Our findings reveal that GPT-3.5
did not pass any of the analyzed exams. In contrast, the GPT-4 models
demonstrated the capability to pass the majority of the exams evaluated, with
the most recent model, gpt-4-0125, successfully passing 222 (75%) of them. The
performance of the GPT models varied significantly, displaying excellence in
exams related to certain specialties while completely failing others.
Conclusions: The significant progress and impressive performance of LLM models
hold great promise for the increased application of AI in the field of medicine
in Poland. For instance, this advancement could lead to the development of
AI-based medical assistants for healthcare professionals, enhancing the
efficiency and accuracy of medical services.",2024-04-29,"Jakub Pokrywka, Jeremi Kaczmarek, Edward Gorzelańczyk",http://arxiv.org/pdf/2405.01589v2,cs.CL
"From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?","Generative large-scale language models create the fifth paradigm of
scientific research, organically combine data science and computational
intelligence, transform the research paradigm of natural language processing
and multimodal information processing, promote the new trend of AI-enabled
social science research, and provide new ideas for digital humanities research
and application. This article profoundly explores the application of
large-scale language models in digital humanities research, revealing their
significant potential in ancient book protection, intelligent processing, and
academic innovation. The article first outlines the importance of ancient book
resources and the necessity of digital preservation, followed by a detailed
introduction to developing large-scale language models, such as ChatGPT, and
their applications in document management, content understanding, and
cross-cultural research. Through specific cases, the article demonstrates how
AI can assist in the organization, classification, and content generation of
ancient books. Then, it explores the prospects of AI applications in artistic
innovation and cultural heritage preservation. Finally, the article explores
the challenges and opportunities in the interaction of technology, information,
and society in the digital humanities triggered by AI technologies.",2024-04-29,"Jiangfeng Liu, Ziyi Wang, Jing Xie, Lei Pei",http://arxiv.org/pdf/2404.18518v1,cs.CL
Explainability of machine learning approaches in forensic linguistics: a case study in geolinguistic authorship profiling,"Forensic authorship profiling uses linguistic markers to infer
characteristics about an author of a text. This task is paralleled in dialect
classification, where a prediction is made about the linguistic variety of a
text based on the text itself. While there have been significant advances in
recent years in variety classification, forensic linguistics rarely relies on
these approaches due to their lack of transparency, among other reasons. In
this paper we therefore explore the explainability of machine learning
approaches considering the forensic context. We focus on variety classification
as a means of geolinguistic profiling of unknown texts based on social media
data from the German-speaking area. For this, we identify the lexical items
that are the most impactful for the variety classification. We find that the
extracted lexical features are indeed representative of their respective
varieties and note that the trained models also rely on place names for
classifications.",2024-04-29,"Dana Roemling, Yves Scherrer, Aleksandra Miletic",http://arxiv.org/pdf/2404.18510v2,cs.CL
ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction,"In the realm of financial analytics, leveraging unstructured data, such as
earnings conference calls (ECCs), to forecast stock volatility is a critical
challenge that has attracted both academics and investors. While previous
studies have used multimodal deep learning-based models to obtain a general
view of ECCs for volatility predicting, they often fail to capture detailed,
complex information. Our research introduces a novel framework: \textbf{ECC
Analyzer}, which utilizes large language models (LLMs) to extract richer, more
predictive content from ECCs to aid the model's prediction performance. We use
the pre-trained large models to extract textual and audio features from ECCs
and implement a hierarchical information extraction strategy to extract more
fine-grained information. This strategy first extracts paragraph-level general
information by summarizing the text and then extracts fine-grained focus
sentences using Retrieval-Augmented Generation (RAG). These features are then
fused through multimodal feature fusion to perform volatility prediction.
Experimental results demonstrate that our model outperforms traditional
analytical benchmarks, confirming the effectiveness of advanced LLM techniques
in financial analysis.",2024-04-29,"Yupeng Cao, Zhi Chen, Qingyun Pei, Nathan Jinseok Lee, K. P. Subbalakshmi, Papa Momar Ndiaye",http://arxiv.org/pdf/2404.18470v2,cs.CL
HFT: Half Fine-Tuning for Large Language Models,"Large language models (LLMs) with one or more fine-tuning phases have become
a necessary step to unlock various capabilities, enabling LLMs to follow
natural language instructions or align with human preferences. However, it
carries the risk of catastrophic forgetting during sequential training, the
parametric knowledge or the ability learned in previous stages may be
overwhelmed by incoming training data. In this paper, we find that by regularly
resetting partial parameters, LLMs can restore some of the original knowledge.
Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute
for full fine-tuning (FFT), to mitigate the forgetting issues, where half of
the parameters are selected to learn new tasks while the other half are frozen
to remain previous knowledge. We provide a feasibility analysis from the
perspective of optimization and interpret the parameter selection operation as
a regularization term. Without changing the model architecture, HFT could be
seamlessly integrated into existing fine-tuning frameworks. Extensive
experiments and analysis on supervised fine-tuning, direct preference
optimization, and continual learning consistently demonstrate the
effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not
only significantly alleviates the forgetting problem, but also achieves the
best performance in a series of downstream benchmarks, with an approximately
30% reduction in training time.",2024-04-29,"Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Weiran Xu, Yu Sun, Hua Wu",http://arxiv.org/pdf/2404.18466v1,cs.CL
RE-GrievanceAssist: Enhancing Customer Experience through ML-Powered Complaint Management,"In recent years, digital platform companies have faced increasing challenges
in managing customer complaints, driven by widespread consumer adoption. This
paper introduces an end-to-end pipeline, named RE-GrievanceAssist, designed
specifically for real estate customer complaint management. The pipeline
consists of three key components: i) response/no-response ML model using TF-IDF
vectorization and XGBoost classifier ; ii) user type classifier using fasttext
classifier; iii) issue/sub-issue classifier using TF-IDF vectorization and
XGBoost classifier. Finally, it has been deployed as a batch job in Databricks,
resulting in a remarkable 40% reduction in overall manual effort with monthly
cost reduction of Rs 1,50,000 since August 2023.",2024-04-29,"Venkatesh C, Harshit Oberoi, Anurag Kumar Pandey, Anil Goyal, Nikhil Sikka",http://arxiv.org/pdf/2404.18963v1,cs.CL
Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in,"Ethical reasoning is a crucial skill for Large Language Models (LLMs).
However, moral values are not universal, but rather influenced by language and
culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and
Llama2-70B-Chat -- perform ethical reasoning in different languages and if
their moral judgement depend on the language in which they are prompted. We
extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a
multilingual setup following their framework of probing LLMs with ethical
dilemmas and policies from three branches of normative ethics: deontology,
virtue, and consequentialism. We experiment with six languages: English,
Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most
consistent and unbiased ethical reasoner across languages, while ChatGPT and
Llama2-70B-Chat show significant moral value bias when we move to languages
other than English. Interestingly, the nature of this bias significantly vary
across languages for all LLMs, including GPT-4.",2024-04-29,"Utkarsh Agarwal, Kumar Tanmay, Aditi Khandelwal, Monojit Choudhury",http://arxiv.org/pdf/2404.18460v1,cs.CL
BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers,"Developing effective biomedical retrieval models is important for excelling
at knowledge-intensive biomedical tasks but still challenging due to the
deficiency of sufficient publicly annotated biomedical data and computational
resources. We present BMRetriever, a series of dense retrievers for enhancing
biomedical retrieval via unsupervised pre-training on large biomedical corpora,
followed by instruction fine-tuning on a combination of labeled datasets and
synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify
BMRetriever's efficacy on various biomedical applications. BMRetriever also
exhibits strong parameter efficiency, with the 410M variant outperforming
baselines up to 11.7 times larger, and the 2B variant matching the performance
of models with over 5B parameters. The training data and model checkpoints are
released at \url{https://huggingface.co/BMRetriever} to ensure transparency,
reproducibility, and application to new domains.",2024-04-29,"Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Yanqiao Zhu, May D. Wang, Joyce C. Ho, Chao Zhang, Carl Yang",http://arxiv.org/pdf/2404.18443v2,cs.CL
Capabilities of Gemini Models in Medicine,"Excellence in a wide variety of medical applications poses considerable
challenges for AI, requiring advanced reasoning, access to up-to-date medical
knowledge and understanding of complex multimodal data. Gemini models, with
strong general capabilities in multimodal and long-context reasoning, offer
exciting possibilities in medicine. Building on these core strengths of Gemini,
we introduce Med-Gemini, a family of highly capable multimodal models that are
specialized in medicine with the ability to seamlessly use web search, and that
can be efficiently tailored to novel modalities using custom encoders. We
evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
benchmark where a direct comparison is viable, often by a wide margin. On the
popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
(health & medicine), Med-Gemini improves over GPT-4V by an average relative
margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
capabilities through SoTA performance on a needle-in-a-haystack retrieval task
from long de-identified health records and medical video question answering,
surpassing prior bespoke methods using only in-context learning. Finally,
Med-Gemini's performance suggests real-world utility by surpassing human
experts on tasks such as medical text summarization, alongside demonstrations
of promising potential for multimodal medical dialogue, medical research and
education. Taken together, our results offer compelling evidence for
Med-Gemini's potential, although further rigorous evaluation will be crucial
before real-world deployment in this safety-critical domain.",2024-04-29,"Khaled Saab, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, Tim Strother, Chunjong Park, Elahe Vedadi, Juanma Zambrano Chaves, Szu-Yeu Hu, Mike Schaekermann, Aishwarya Kamath, Yong Cheng, David G. T. Barrett, Cathy Cheung, Basil Mustafa, Anil Palepu, Daniel McDuff, Le Hou, Tomer Golany, Luyang Liu, Jean-baptiste Alayrac, Neil Houlsby, Nenad Tomasev, Jan Freyberg, Charles Lau, Jonas Kemp, Jeremy Lai, Shekoofeh Azizi, Kimberly Kanada, SiWai Man, Kavita Kulkarni, Ruoxi Sun, Siamak Shakeri, Luheng He, Ben Caine, Albert Webson, Natasha Latysheva, Melvin Johnson, Philip Mansfield, Jian Lu, Ehud Rivlin, Jesper Anderson, Bradley Green, Renee Wong, Jonathan Krause, Jonathon Shlens, Ewa Dominowska, S. M. Ali Eslami, Katherine Chou, Claire Cui, Oriol Vinyals, Koray Kavukcuoglu, James Manyika, Jeff Dean, Demis Hassabis, Yossi Matias, Dale Webster, Joelle Barral, Greg Corrado, Christopher Semturs, S. Sara Mahdavi, Juraj Gottweis, Alan Karthikesalingam, Vivek Natarajan",http://arxiv.org/pdf/2404.18416v2,cs.CL
"LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report","Low Rank Adaptation (LoRA) has emerged as one of the most widely adopted
methods for Parameter Efficient Fine-Tuning (PEFT) of Large Language Models
(LLMs). LoRA reduces the number of trainable parameters and memory usage while
achieving comparable performance to full fine-tuning. We aim to assess the
viability of training and serving LLMs fine-tuned with LoRA in real-world
applications. First, we measure the quality of LLMs fine-tuned with quantized
low rank adapters across 10 base models and 31 tasks for a total of 310 models.
We find that 4-bit LoRA fine-tuned models outperform base models by 34 points
and GPT-4 by 10 points on average. Second, we investigate the most effective
base models for fine-tuning and assess the correlative and predictive
capacities of task complexity heuristics in forecasting the outcomes of
fine-tuning. Finally, we evaluate the latency and concurrency capabilities of
LoRAX, an open-source Multi-LoRA inference server that facilitates the
deployment of multiple LoRA fine-tuned models on a single GPU using shared base
model weights and dynamic adapter loading. LoRAX powers LoRA Land, a web
application that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA
A100 GPU with 80GB memory. LoRA Land highlights the quality and
cost-effectiveness of employing multiple specialized LLMs over a single,
general-purpose LLM.",2024-04-29,"Justin Zhao, Timothy Wang, Wael Abid, Geoffrey Angus, Arnav Garg, Jeffery Kinnison, Alex Sherstinsky, Piero Molino, Travis Addair, Devvret Rishi",http://arxiv.org/pdf/2405.00732v1,cs.CL
Mixture-of-Instructions: Aligning Large Language Models via Mixture Prompting,"With the proliferation of large language models (LLMs), the comprehensive
alignment of such models across multiple tasks has emerged as a critical area
of research. Existing alignment methodologies primarily address single task,
such as multi-turn dialogue, coding, mathematical problem-solving, and tool
usage. Although there is a large amount of high-quality data available for
those tasks, most of them provide only questions and answers without including
the system prompt. Though a detailed analysis of the Qwen language model, we
found that the system prompt has a significant impact on both training and
inference processes of LLM. We attributes this phenomenon to overfitting to the
system prompt. In address this issue, we introduce a novel technique termed
Mixture-of-Instructions (MoI), which employs a strategy of instruction packing
combined with diverse system prompts to boost the alignment efficiency of
language models. We have also compiled a diverse set of seven benchmark
datasets to rigorously evaluate the alignment efficacy of the MoI-enhanced
language model. Our methodology was applied to the open-source Qwen-7B-chat
model, culminating in the development of Qwen-SFT-MoI. This enhanced model
demonstrates significant advancements in generative capabilities across coding,
mathematics, and tool use tasks.",2024-04-29,"Bowen Xu, Shaoyu Wu, Kai Liu, Lulu Hu",http://arxiv.org/pdf/2404.18410v2,cs.CL
LLM-SR: Scientific Equation Discovery via Programming with Large Language Models,"Mathematical equations have been unreasonably effective in describing complex
natural phenomena across various scientific disciplines. However, discovering
such insightful equations from data presents significant challenges due to the
necessity of navigating extremely large combinatorial hypothesis spaces.
Current methods of equation discovery, commonly known as symbolic regression
techniques, largely focus on extracting equations from data alone, often
neglecting the domain-specific prior knowledge that scientists typically depend
on. They also employ limited representations such as expression trees,
constraining the search space and expressiveness of equations. To bridge this
gap, we introduce LLM-SR, a novel approach that leverages the extensive
scientific knowledge and robust code generation capabilities of Large Language
Models (LLMs) to discover scientific equations from data. Specifically, LLM-SR
treats equations as programs with mathematical operators and combines LLMs'
scientific priors with evolutionary search over equation programs. The LLM
iteratively proposes new equation skeleton hypotheses, drawing from its domain
knowledge, which are then optimized against data to estimate parameters. We
evaluate LLM-SR on four benchmark problems across diverse scientific domains
(e.g., physics, biology), which we carefully designed to simulate the discovery
process and prevent LLM recitation. Our results demonstrate that LLM-SR
discovers physically accurate equations that significantly outperform
state-of-the-art symbolic regression baselines, particularly in out-of-domain
test settings. We also show that LLM-SR's incorporation of scientific priors
enables more efficient equation space exploration than the baselines. Code and
data are available: https://github.com/deep-symbolic-mathematics/LLM-SR",2024-04-29,"Parshin Shojaee, Kazem Meidani, Shashank Gupta, Amir Barati Farimani, Chandan K Reddy",http://arxiv.org/pdf/2404.18400v3,cs.CL
UMETTS: A Unified Framework for Emotional Text-to-Speech Synthesis with Multimodal Prompts,"Emotional Text-to-Speech (E-TTS) synthesis has garnered significant attention
in recent years due to its potential to revolutionize human-computer
interaction. However, current E-TTS approaches often struggle to capture the
intricacies of human emotions, primarily relying on oversimplified emotional
labels or single-modality input. In this paper, we introduce the Unified
Multimodal Prompt-Induced Emotional Text-to-Speech System (UMETTS), a novel
framework that leverages emotional cues from multiple modalities to generate
highly expressive and emotionally resonant speech. The core of UMETTS consists
of two key components: the Emotion Prompt Alignment Module (EP-Align) and the
Emotion Embedding-Induced TTS Module (EMI-TTS). (1) EP-Align employs
contrastive learning to align emotional features across text, audio, and visual
modalities, ensuring a coherent fusion of multimodal information. (2)
Subsequently, EMI-TTS integrates the aligned emotional embeddings with
state-of-the-art TTS models to synthesize speech that accurately reflects the
intended emotions. Extensive evaluations show that UMETTS achieves significant
improvements in emotion accuracy and speech naturalness, outperforming
traditional E-TTS methods on both objective and subjective metrics.",2024-04-29,"Zhi-Qi Cheng, Xiang Li, Jun-Yan He, Junyao Chen, Xiaomao Fan, Xiaojiang Peng, Alexander G. Hauptmann",http://arxiv.org/pdf/2404.18398v2,cs.CL
Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions,"Language models (LMs) can hallucinate when performing complex mathematical
reasoning. Physics provides a rich domain for assessing their mathematical
capabilities, where physical context requires that any symbolic manipulation
satisfies complex semantics (\textit{e.g.,} units, tensorial order). In this
work, we systematically remove crucial context from prompts to force instances
where model inference may be algebraically coherent, yet unphysical. We assess
LM capabilities in this domain using a curated dataset encompassing multiple
notations and Physics subdomains. Further, we improve zero-shot scores using
synthetic in-context examples, and demonstrate non-linear degradation of
derivation quality with perturbation strength via the progressive omission of
supporting premises. We find that the models' mathematical reasoning is not
physics-informed in this setting, where physical context is predominantly
ignored in favour of reverse-engineering solutions.",2024-04-29,"Jordan Meadows, Tamsin James, Andre Freitas",http://arxiv.org/pdf/2404.18384v2,cs.CL
Towards Unbiased Evaluation of Detecting Unanswerable Questions in EHRSQL,"Incorporating unanswerable questions into EHR QA systems is crucial for
testing the trustworthiness of a system, as providing non-existent responses
can mislead doctors in their diagnoses. The EHRSQL dataset stands out as a
promising benchmark because it is the only dataset that incorporates
unanswerable questions in the EHR QA system alongside practical questions.
However, in this work, we identify a data bias in these unanswerable questions;
they can often be discerned simply by filtering with specific N-gram patterns.
Such biases jeopardize the authenticity and reliability of QA system
evaluations. To tackle this problem, we propose a simple debiasing method of
adjusting the split between the validation and test sets to neutralize the
undue influence of N-gram filtering. By experimenting on the MIMIC-III dataset,
we demonstrate both the existing data bias in EHRSQL and the effectiveness of
our data split strategy in mitigating this bias.",2024-04-29,"Yongjin Yang, Sihyeon Kim, SangMook Kim, Gyubok Lee, Se-Young Yun, Edward Choi",http://arxiv.org/pdf/2405.01588v1,cs.CL
QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond,"The proliferation of social media has led to information overload and
increased interest in opinion mining. We propose ""Question-Answering Network
Analysis"" (QANA), a novel opinion mining framework that utilizes Large Language
Models (LLMs) to generate questions from users' comments, constructs a
bipartite graph based on the comments' answerability to the questions, and
applies centrality measures to examine the importance of opinions. We
investigate the impact of question generation styles, LLM selections, and the
choice of embedding model on the quality of the constructed QA networks by
comparing them with annotated Key Point Analysis datasets. QANA achieves
comparable performance to previous state-of-the-art supervised models in a
zero-shot manner for Key Point Matching task, also reducing the computational
cost from quadratic to linear. For Key Point Generation, questions with high
PageRank or degree centrality align well with manually annotated key points.
Notably, QANA enables analysts to assess the importance of key points from
various aspects according to their selection of centrality measure. QANA's
primary contribution lies in its flexibility to extract key points from a wide
range of perspectives, which enhances the quality and impartiality of opinion
mining.",2024-04-29,"Tomoki Fukuma, Koki Noda, Toshihide Ubukata Kousuke Hoso, Yoshiharu Ichikawa, Kyosuke Kambe, Yu Masubuch, Fujio Toriumi",http://arxiv.org/pdf/2404.18371v1,cs.CL
FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models,"In the burgeoning field of large language models (LLMs), the assessment of
fundamental knowledge remains a critical challenge, particularly for models
tailored to Chinese language and culture. This paper introduces FoundaBench, a
pioneering benchmark designed to rigorously evaluate the fundamental knowledge
capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354
multiple-choice questions across common sense and K-12 educational subjects,
meticulously curated to reflect the breadth and depth of everyday and academic
knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using
FoundaBench, employing both traditional assessment methods and our CircularEval
protocol to mitigate potential biases in model responses. Our results highlight
the superior performance of models pre-trained on Chinese corpora, and reveal a
significant disparity between models' reasoning and memory recall capabilities.
The insights gleaned from FoundaBench evaluations set a new standard for
understanding the fundamental knowledge of LLMs, providing a robust framework
for future advancements in the field.",2024-04-29,"Wei Li, Ren Ma, Jiang Wu, Chenya Gu, Jiahui Peng, Jinyang Len, Songyang Zhang, Hang Yan, Dahua Lin, Conghui He",http://arxiv.org/pdf/2404.18359v1,cs.CL
Towards Incremental Learning in Large Language Models: A Critical Review,"Incremental learning is the ability of systems to acquire knowledge over
time, enabling their adaptation and generalization to novel tasks. It is a
critical ability for intelligent, real-world systems, especially when data
changes frequently or is limited. This review provides a comprehensive analysis
of incremental learning in Large Language Models. It synthesizes the
state-of-the-art incremental learning paradigms, including continual learning,
meta-learning, parameter-efficient learning, and mixture-of-experts learning.
We demonstrate their utility for incremental learning by describing specific
achievements from these related topics and their critical factors. An important
finding is that many of these approaches do not update the core model, and none
of them update incrementally in real-time. The paper highlights current
problems and challenges for future research in the field. By consolidating the
latest relevant research developments, this review offers a comprehensive
understanding of incremental learning and its implications for designing and
developing LLM-based learning systems.",2024-04-28,"Mladjan Jovanovic, Peter Voss",http://arxiv.org/pdf/2404.18311v4,cs.CL
Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages,"Large Language Models are transforming NLP for a variety of tasks. However,
how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.
In line with the goals of the AmericasNLP workshop, we focus on 12 LRLs from
Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English
and Brazilian Portuguese). Our results indicate that the LLMs perform worse for
the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the
reasons behind this failure and provide an error analysis through examples
observed in our data set.",2024-04-28,"David Ifeoluwa Adelani, A. Seza Doğruöz, André Coneglian, Atul Kr. Ojha",http://arxiv.org/pdf/2404.18286v2,cs.CL
Improve Academic Query Resolution through BERT-based Question Extraction from Images,"Providing fast and accurate resolution to the student's query is an essential
solution provided by Edtech organizations. This is generally provided with a
chat-bot like interface to enable students to ask their doubts easily. One
preferred format for student queries is images, as it allows students to
capture and post questions without typing complex equations and information.
However, this format also presents difficulties, as images may contain multiple
questions or textual noise that lowers the accuracy of existing single-query
answering solutions. In this paper, we propose a method for extracting
questions from text or images using a BERT-based deep learning model and
compare it to the other rule-based and layout-based methods. Our method aims to
improve the accuracy and efficiency of student query resolution in Edtech
organizations.",2024-04-28,"Nidhi Kamal, Saurabh Yadav, Jorawar Singh, Aditi Avasthi",http://arxiv.org/pdf/2405.01587v1,cs.CL
Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ),"The burgeoning influence of Large Language Models (LLMs) in shaping public
discourse and decision-making underscores the imperative to address inherent
biases within these AI systems. In the wake of AI's expansive integration
across sectors, addressing racial bias in LLMs has never been more critical.
This paper introduces a novel framework called Comprehensive Bias
Neutralization Framework (CBNF) which embodies an innovative approach to
quantifying and mitigating biases within LLMs. Our framework combines the Large
Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)]
and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)]
methodologies to create a new metric called Bias Intelligence Quotient
(BiQ)which detects, measures, and mitigates racial bias in LLMs without
reliance on demographic annotations.
  By introducing a new metric called BiQ that enhances LLMBI with additional
fairness metrics, CBNF offers a multi-dimensional metric for bias assessment,
underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et
al., 2021]. This paper presents a detailed analysis of Latimer AI (a language
model incrementally trained on black history and culture) in comparison to
ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural,
and gender biases through targeted training and refined bias mitigation
strategies [Latimer & Bender, 2023].",2024-04-28,"Malur Narayan, John Pasmore, Elton Sampaio, Vijay Raghavan, Gabriella Waters",http://arxiv.org/pdf/2404.18276v1,cs.CL
Parameter-Efficient Tuning Large Language Models for Graph Representation Learning,"Text-rich graphs, which exhibit rich textual information on nodes and edges,
are prevalent across a wide range of real-world business applications. Large
Language Models (LLMs) have demonstrated remarkable abilities in understanding
text, which also introduced the potential for more expressive modeling in
text-rich graphs. Despite these capabilities, efficiently applying LLMs to
representation learning on graphs presents significant challenges. Recently,
parameter-efficient fine-tuning methods for LLMs have enabled efficient new
task generalization with minimal time and memory consumption. Inspired by this,
we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
approach for efficient graph representation learning with LLMs on text-rich
graphs. Specifically, we utilize a graph neural network (GNN) to encode
structural information from neighboring nodes into a graph prompt. This prompt
is then inserted at the beginning of the text sequence. To improve the quality
of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
the next token in the node text. Compared with existing joint GNN and LMs, our
method directly generate the node embeddings from large language models with an
affordable fine-tuning cost. We validate our approach through comprehensive
experiments conducted on 8 different text-rich graphs, observing an average
improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
evaluations. Our results demonstrate the efficacy and efficiency of our model,
showing that it can be smoothly integrated with various large language models,
including OPT, LLaMA and Falcon.",2024-04-28,"Qi Zhu, Da Zheng, Xiang Song, Shichang Zhang, Bowen Jin, Yizhou Sun, George Karypis",http://arxiv.org/pdf/2404.18271v1,cs.CL
CLARINET: Augmenting Language Models to Ask Clarification Questions for Retrieval,"Users often make ambiguous requests that require clarification. We study the
problem of asking clarification questions in an information retrieval setting,
where systems often face ambiguous search queries and it is challenging to turn
the uncertainty in the retrieval model into a natural language question. We
present CLARINET, a system that asks informative clarification questions by
choosing questions whose answers would maximize certainty in the correct
candidate. Our approach works by augmenting a large language model (LLM) to
condition on a retrieval distribution, finetuning end-to-end to generate the
question that would have maximized the rank of the true candidate at each turn.
When evaluated on a real-world retrieval dataset of users searching for books,
our system outperforms traditional heuristics such as information gain on
retrieval success by 17% and vanilla-prompted LLMs by 39% relative.",2024-04-28,"Yizhou Chi, Jessy Lin, Kevin Lin, Dan Klein",http://arxiv.org/pdf/2405.15784v1,cs.CL
Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin,"Nigerian Pidgin is an English-derived contact language and is traditionally
an oral language, spoken by approximately 100 million people. No orthographic
standard has yet been adopted, and thus the few available Pidgin datasets that
exist are characterised by noise in the form of orthographic variations. This
contributes to under-performance of models in critical NLP tasks. The current
work is the first to describe various types of orthographic variations commonly
found in Nigerian Pidgin texts, and model this orthographic variation. The
variations identified in the dataset form the basis of a phonetic-theoretic
framework for word editing, which is used to generate orthographic variations
to augment training data. We test the effect of this data augmentation on two
critical NLP tasks: machine translation and sentiment analysis. The proposed
variation generation framework augments the training data with new orthographic
variants which are relevant for the test set but did not occur in the training
set originally. Our results demonstrate the positive effect of augmenting the
training data with a combination of real texts from other corpora as well as
synthesized orthographic variation, resulting in performance improvements of
2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.",2024-04-28,"Pin-Jie Lin, Merel Scholman, Muhammed Saeed, Vera Demberg",http://arxiv.org/pdf/2404.18264v1,cs.CL
Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology,"Languages can encode temporal subordination lexically, via subordinating
conjunctions, and morphologically, by marking the relation on the predicate.
Systematic cross-linguistic variation among the former can be studied using
well-established token-based typological approaches to token-aligned parallel
corpora. Variation among different morphological means is instead much harder
to tackle and therefore more poorly understood, despite being predominant in
several language groups. This paper explores variation in the expression of
generic temporal subordination ('when'-clauses) among the languages of Latin
America and the Caribbean, where morphological marking is particularly common.
It presents probabilistic semantic maps computed on the basis of the languages
of the region, thus avoiding bias towards the many world's languages that
exclusively use lexified connectors, incorporating associations between
character $n$-grams and English $when$. The approach allows capturing
morphological clause-linkage devices in addition to lexified connectors, paving
the way for larger-scale, strategy-agnostic analyses of typological variation
in temporal subordination.",2024-04-28,Nilo Pedrazzini,http://arxiv.org/pdf/2404.18257v1,cs.CL
PatentGPT: A Large Language Model for Intellectual Property,"In recent years, large language models(LLMs) have attracted significant
attention due to their exceptional performance across a multitude of natural
language process tasks, and have been widely applied in various fields.
However, the application of large language models in the Intellectual Property
(IP) domain is challenging due to the strong need for specialized knowledge,
privacy protection, processing of extremely long text in this field. In this
technical report, we present for the first time a low-cost, standardized
procedure for training IP-oriented LLMs, meeting the unique requirements of the
IP domain. Using this standard process, we have trained the PatentGPT series
models based on open-source pretrained models. By evaluating them on the
open-source IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms
GPT-4, indicating the effectiveness of the proposed training procedure and the
expertise of the PatentGPT models in the IP domain. Remarkably, our model
surpassed GPT-4 on the 2019 China Patent Agent Qualification Examination,
scoring 65 and matching human expert levels. Additionally, the PatentGPT model,
which utilizes the SMoE architecture, achieves performance comparable to that
of GPT-4 in the IP domain and demonstrates a better cost-performance ratio on
long-text tasks, potentially serving as an alternative to GPT-4 within the IP
domain.",2024-04-28,"Zilong Bai, Ruiji Zhang, Linqing Chen, Qijun Cai, Yuan Zhong, Cong Wang, Yan Fang, Jie Fang, Jing Sun, Weikuan Wang, Lizhi Zhou, Haoran Hua, Tian Qiu, Chaochao Wang, Cheng Sun, Jianping Lu, Yixin Wang, Yubin Xia, Meng Hu, Haowen Liu, Peng Xu, Licong Xu, Fu Bian, Xiaolong Gu, Lisha Zhang, Weilei Wang, Changyang Tu",http://arxiv.org/pdf/2404.18255v5,cs.CL
Transfer Learning and Transformer Architecture for Financial Sentiment Analysis,"Financial sentiment analysis allows financial institutions like Banks and
Insurance Companies to better manage the credit scoring of their customers in a
better way. Financial domain uses specialized mechanisms which makes sentiment
analysis difficult. In this paper, we propose a pre-trained language model
which can help to solve this problem with fewer labelled data. We extend on the
principles of Transfer learning and Transformation architecture principles and
also take into consideration recent outbreak of pandemics like COVID. We apply
the sentiment analysis to two different sets of data. We also take smaller
training set and fine tune the same as part of the model.",2024-04-28,"Tohida Rehman, Raghubir Bose, Samiran Chattopadhyay, Debarshi Kumar Sanyal",http://arxiv.org/pdf/2405.01586v1,cs.CL
LEGENT: Open Platform for Embodied Agents,"Despite advancements in Large Language Models (LLMs) and Large Multimodal
Models (LMMs), their integration into language-grounded, human-like embodied
agents remains incomplete, hindering complex real-life task performance in
physical environments. Existing integrations often feature limited open
sourcing, challenging collective progress in this field. We introduce LEGENT,
an open, scalable platform for developing embodied agents using LLMs and LMMs.
LEGENT offers a dual approach: a rich, interactive 3D environment with
communicable and actionable agents, paired with a user-friendly interface, and
a sophisticated data generation pipeline utilizing advanced algorithms to
exploit supervision from simulated worlds at scale. In our experiments, an
embryonic vision-language-action model trained on LEGENT-generated data
surpasses GPT-4V in embodied tasks, showcasing promising generalization
capabilities.",2024-04-28,"Zhili Cheng, Zhitong Wang, Jinyi Hu, Shengding Hu, An Liu, Yuge Tu, Pengkai Li, Lei Shi, Zhiyuan Liu, Maosong Sun",http://arxiv.org/pdf/2404.18243v2,cs.CL
SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning,"Large Language Models (LLMs) have highlighted the necessity of effective
unlearning mechanisms to comply with data regulations and ethical AI practices.
LLM unlearning aims at removing undesired data influences and associated model
capabilities without compromising utility beyond the scope of unlearning. While
interest in studying LLM unlearning is growing, the impact of the optimizer
choice for LLM unlearning remains unexplored. In this work, we shed light on
the significance of optimizer selection in LLM unlearning for the first time,
establishing a clear connection between second-order optimization and influence
unlearning (a classical approach using influence functions to update the model
for data influence removal). This insight propels us to develop a second-order
optimization-based LLM unlearning framework, termed Second-Order UnLearning
(SOUL), which extends the static, one-shot model update using influence
unlearning to a dynamic, iterative unlearning process. Our extensive
experiments show that SOUL consistently outperforms conventional first-order
methods across various unlearning tasks, models, and metrics, indicating that
second-order optimization offers an effective and broadly applicable solution
for LLM unlearning. Codes are available at https://github.com/OPTML-Group/SOUL.",2024-04-28,"Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu",http://arxiv.org/pdf/2404.18239v4,cs.CL
From Persona to Personalization: A Survey on Role-Playing Language Agents,"Recent advancements in large language models (LLMs) have significantly
boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI
systems designed to simulate assigned personas. By harnessing multiple advanced
abilities of LLMs, including in-context learning, instruction following, and
social intelligence, RPLAs achieve a remarkable sense of human likeness and
vivid role-playing performance. RPLAs can mimic a wide range of personas,
ranging from historical figures and fictional characters to real-life
individuals. Consequently, they have catalyzed numerous AI applications, such
as emotional companions, interactive video games, personalized assistants and
copilots, and digital clones. In this paper, we conduct a comprehensive survey
of this field, illustrating the evolution and recent progress in RPLAs
integrating with cutting-edge LLM technologies. We categorize personas into
three types: 1) Demographic Persona, which leverages statistical stereotypes;
2) Character Persona, focused on well-established figures; and 3)
Individualized Persona, customized through ongoing user interactions for
personalized services. We begin by presenting a comprehensive overview of
current methodologies for RPLAs, followed by the details for each persona type,
covering corresponding data sourcing, agent construction, and evaluation.
Afterward, we discuss the fundamental risks, existing limitations, and future
prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI
applications, which reflects practical user demands that shape and drive RPLA
research. Through this work, we aim to establish a clear taxonomy of RPLA
research and applications, and facilitate future research in this critical and
ever-evolving field, and pave the way for a future where humans and RPLAs
coexist in harmony.",2024-04-28,"Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui Zhu, Aili Chen, Nianqi Li, Lida Chen, Caiyu Hu, Siye Wu, Scott Ren, Ziquan Fu, Yanghua Xiao",http://arxiv.org/pdf/2404.18231v2,cs.CL
TextGram: Towards a better domain-adaptive pretraining,"For green AI, it is crucial to measure and reduce the carbon footprint
emitted during the training of large language models. In NLP, performing
pre-training on Transformer models requires significant computational
resources. This pre-training involves using a large amount of text data to gain
prior knowledge for performing downstream tasks. Thus, it is important that we
select the correct data in the form of domain-specific data from this vast
corpus to achieve optimum results aligned with our domain-specific tasks. While
training on large unsupervised data is expensive, it can be optimized by
performing a data selection step before pretraining. Selecting important data
reduces the space overhead and the substantial amount of time required to
pre-train the model while maintaining constant accuracy. We investigate the
existing selection strategies and propose our own domain-adaptive data
selection method - TextGram - that effectively selects essential data from
large corpora. We compare and evaluate the results of finetuned models for text
classification task with and without data selection. We show that the proposed
strategy works better compared to other selection methods.",2024-04-28,"Sharayu Hiwarkhedkar, Saloni Mittal, Vidula Magdum, Omkar Dhekane, Raviraj Joshi, Geetanjali Kale, Arnav Ladkat",http://arxiv.org/pdf/2404.18228v1,cs.CL
L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi,"The availability of text or topic classification datasets in the low-resource
Marathi language is limited, typically consisting of fewer than 4 target
labels, with some achieving nearly perfect accuracy. In this work, we introduce
L3Cube-MahaNews, a Marathi text classification corpus that focuses on News
headlines and articles. This corpus stands out as the largest supervised
Marathi Corpus, containing over 1.05L records classified into a diverse range
of 12 categories. To accommodate different document lengths, MahaNews comprises
three supervised datasets specifically designed for short text, long documents,
and medium paragraphs. The consistent labeling across these datasets
facilitates document length-based analysis. We provide detailed data statistics
and baseline results on these datasets using state-of-the-art pre-trained BERT
models. We conduct a comparative analysis between monolingual and multilingual
BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT
model outperforms all others on every dataset. These resources also serve as
Marathi topic classification datasets or models and are publicly available at
https://github.com/l3cube-pune/MarathiNLP .",2024-04-28,"Saloni Mittal, Vidula Magdum, Omkar Dhekane, Sharayu Hiwarkhedkar, Raviraj Joshi",http://arxiv.org/pdf/2404.18216v1,cs.CL
Tabular Embedding Model (TEM): Finetuning Embedding Models For Tabular RAG Applications,"In recent times Large Language Models have exhibited tremendous capabilities,
especially in the areas of mathematics, code generation and general-purpose
reasoning. However for specialized domains especially in applications that
require parsing and analyzing large chunks of numeric or tabular data even
state-of-the-art (SOTA) models struggle. In this paper, we introduce a new
approach to solving domain-specific tabular data analysis tasks by presenting a
unique RAG workflow that mitigates the scalability issues of existing tabular
LLM solutions. Specifically, we present Tabular Embedding Model (TEM), a novel
approach to fine-tune embedding models for tabular Retrieval-Augmentation
Generation (RAG) applications. Embedding models form a crucial component in the
RAG workflow and even current SOTA embedding models struggle as they are
predominantly trained on textual datasets and thus underperform in scenarios
involving complex tabular data. The evaluation results showcase that our
approach not only outperforms current SOTA embedding models in this domain but
also does so with a notably smaller and more efficient model structure.",2024-04-28,"Sujit Khanna, Shishir Subedi",http://arxiv.org/pdf/2405.01585v1,cs.CL
Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on Large Language Models,"In the rapidly evolving domain of artificial intelligence, safeguarding the
intellectual property of Large Language Models (LLMs) is increasingly crucial.
Current watermarking techniques against model extraction attacks, which rely on
signal insertion in model logits or post-processing of generated text, remain
largely heuristic. We propose a novel method for embedding learnable linguistic
watermarks in LLMs, aimed at tracing and preventing model extraction attacks.
Our approach subtly modifies the LLM's output distribution by introducing
controlled noise into token frequency distributions, embedding an statistically
identifiable controllable watermark.We leverage statistical hypothesis testing
and information theory, particularly focusing on Kullback-Leibler Divergence,
to differentiate between original and modified distributions effectively. Our
watermarking method strikes a delicate well balance between robustness and
output quality, maintaining low false positive/negative rates and preserving
the LLM's original performance.",2024-04-28,"Minhao Bai, Kaiyi Pang, Yongfeng Huang",http://arxiv.org/pdf/2405.01509v1,cs.CL
Exploring the Robustness of In-Context Learning with Noisy Labels,"Recently, the mysterious In-Context Learning (ICL) ability exhibited by
Transformer architectures, especially in large language models (LLMs), has
sparked significant research interest. However, the resilience of Transformers'
in-context learning capabilities in the presence of noisy samples, prevalent in
both training corpora and prompt demonstrations, remains underexplored. In this
paper, inspired by prior research that studies ICL ability using simple
function classes, we take a closer look at this problem by investigating the
robustness of Transformers against noisy labels. Specifically, we first conduct
a thorough evaluation and analysis of the robustness of Transformers against
noisy labels during in-context learning and show that they exhibit notable
resilience against diverse types of noise in demonstration labels. Furthermore,
we delve deeper into this problem by exploring whether introducing noise into
the training set, akin to a form of data augmentation, enhances such robustness
during inference, and find that such noise can indeed improve the robustness of
ICL. Overall, our fruitful analysis and findings provide a comprehensive
understanding of the resilience of Transformer models against label noises
during ICL and provide valuable insights into the research on Transformers in
natural language processing. Our code is available at
https://github.com/InezYu0928/in-context-learning.",2024-04-28,"Chen Cheng, Xinzhi Yu, Haodong Wen, Jingsong Sun, Guanzhang Yue, Yihao Zhang, Zeming Wei",http://arxiv.org/pdf/2404.18191v2,cs.CL
Ranked List Truncation for Large Language Model-based Re-Ranking,"We study ranked list truncation (RLT) from a novel ""retrieve-then-re-rank""
perspective, where we optimize re-ranking by truncating the retrieved list
(i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can
improve re-ranking efficiency by sending variable-length candidate lists to a
re-ranker on a per-query basis. It also has the potential to improve re-ranking
effectiveness. Despite its importance, there is limited research into applying
RLT methods to this new perspective. To address this research gap, we reproduce
existing RLT methods in the context of re-ranking, especially newly emerged
large language model (LLM)-based re-ranking. In particular, we examine to what
extent established findings on RLT for retrieval are generalizable to the
""retrieve-then-re-rank"" setup from three perspectives: (i) assessing RLT
methods in the context of LLM-based re-ranking with lexical first-stage
retrieval, (ii) investigating the impact of different types of first-stage
retrievers on RLT methods, and (iii) investigating the impact of different
types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and
2020 deep learning tracks, investigating 8 RLT methods for pipelines involving
3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the
context of re-ranking.",2024-04-28,"Chuan Meng, Negar Arabzadeh, Arian Askari, Mohammad Aliannejadi, Maarten de Rijke",http://arxiv.org/pdf/2404.18185v1,cs.CL
EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter,"Nigerians have a notable online presence and actively discuss political and
topical matters. This was particularly evident throughout the 2023 general
election, where Twitter was used for campaigning, fact-checking and
verification, and even positive and negative discourse. However, little or none
has been done in the detection of abusive language and hate speech in Nigeria.
In this paper, we curated code-switched Twitter data directed at three
musketeers of the governorship election on the most populous and economically
vibrant state in Nigeria; Lagos state, with the view to detect offensive speech
in political discussions. We developed EkoHate -- an abusive language and hate
speech dataset for political discussions between the three candidates and their
followers using a binary (normal vs offensive) and fine-grained four-label
annotation scheme. We analysed our dataset and provided an empirical evaluation
of state-of-the-art methods across both supervised and cross-lingual transfer
learning settings. In the supervised setting, our evaluation results in both
binary and four-label annotation schemes show that we can achieve 95.1 and 70.3
F1 points respectively. Furthermore, we show that our dataset adequately
transfers very well to three publicly available offensive datasets (OLID,
HateUS2020, and FountaHate), generalizing to political discussions in other
regions like the US.",2024-04-28,"Comfort Eseohen Ilevbare, Jesujoba O. Alabi, David Ifeoluwa Adelani, Firdous Damilola Bakare, Oluwatoyin Bunmi Abiola, Oluwaseyi Adesina Adeyemo",http://arxiv.org/pdf/2404.18180v1,cs.CL
Explaining vague language,"Why is language vague? Vagueness may be explained and rationalized if it can
be shown that vague language is more useful to speaker and hearer than precise
language. In a well-known paper, Lipman proposes a game-theoretic account of
vagueness in terms of mixed strategy that leads to a puzzle: vagueness cannot
be strictly better than precision at equilibrium. More recently, \'Egr\'e,
Spector, Mortier and Verheyen have put forward a Bayesian account of vagueness
establishing that using vague words can be strictly more informative than using
precise words. This paper proposes to compare both results and to explain why
they are not in contradiction. Lipman's definition of vagueness relies
exclusively on a property of signaling strategies, without making any
assumptions about the lexicon, whereas \'Egr\'e et al.'s involves a layer of
semantic content. We argue that the semantic account of vagueness is needed,
and more adequate and explanatory of vagueness.",2024-04-28,"Paul Égré, Benjamin Spector",http://arxiv.org/pdf/2404.18154v1,cs.CL
Lightweight Conceptual Dictionary Learning for Text Classification Using Information Compression,"We propose a novel, lightweight supervised dictionary learning framework for
text classification based on data compression and representation. This
two-phase algorithm initially employs the Lempel-Ziv-Welch (LZW) algorithm to
construct a dictionary from text datasets, focusing on the conceptual
significance of dictionary elements. Subsequently, dictionaries are refined
considering label data, optimizing dictionary atoms to enhance discriminative
power based on mutual information and class distribution. This process
generates discriminative numerical representations, facilitating the training
of simple classifiers such as SVMs and neural networks. We evaluate our
algorithm's information-theoretic performance using information bottleneck
principles and introduce the information plane area rank (IPAR) as a novel
metric to quantify the information-theoretic performance. Tested on six
benchmark text datasets, our algorithm competes closely with top models,
especially in limited-vocabulary contexts, using significantly fewer
parameters. \review{Our algorithm closely matches top-performing models,
deviating by only ~2\% on limited-vocabulary datasets, using just 10\% of their
parameters. However, it falls short on diverse-vocabulary datasets, likely due
to the LZW algorithm's constraints with low-repetition data. This contrast
highlights its efficiency and limitations across different dataset types.",2024-04-28,"Li Wan, Tansu Alpcan, Margreta Kuijper, Emanuele Viterbo",http://arxiv.org/pdf/2405.01584v1,cs.CL
Logic Agent: Enhancing Validity with Logic Rule Invocation,"Chain-of-Thought (CoT) prompting has emerged as a pivotal technique for
augmenting the inferential capabilities of language models during reasoning
tasks. Despite its advancements, CoT often grapples with challenges in
validating reasoning validity and ensuring informativeness. Addressing these
limitations, this paper introduces the Logic Agent (LA), an agent-based
framework aimed at enhancing the validity of reasoning processes in Large
Language Models (LLMs) through strategic logic rule invocation. Unlike
conventional approaches, LA transforms LLMs into logic agents that dynamically
apply propositional logic rules, initiating the reasoning process by converting
natural language inputs into structured logic forms. The logic agent leverages
a comprehensive set of predefined functions to systematically navigate the
reasoning process. This methodology not only promotes the structured and
coherent generation of reasoning constructs but also significantly improves
their interpretability and logical coherence. Through extensive
experimentation, we demonstrate LA's capacity to scale effectively across
various model sizes, markedly improving the precision of complex reasoning
across diverse tasks.",2024-04-28,"Hanmeng Liu, Zhiyang Teng, Chaoli Zhang, Yue Zhang",http://arxiv.org/pdf/2404.18130v2,cs.CL
USAT: A Universal Speaker-Adaptive Text-to-Speech Approach,"Conventional text-to-speech (TTS) research has predominantly focused on
enhancing the quality of synthesized speech for speakers in the training
dataset. The challenge of synthesizing lifelike speech for unseen,
out-of-dataset speakers, especially those with limited reference data, remains
a significant and unresolved problem. While zero-shot or few-shot
speaker-adaptive TTS approaches have been explored, they have many limitations.
Zero-shot approaches tend to suffer from insufficient generalization
performance to reproduce the voice of speakers with heavy accents. While
few-shot methods can reproduce highly varying accents, they bring a significant
storage burden and the risk of overfitting and catastrophic forgetting. In
addition, prior approaches only provide either zero-shot or few-shot
adaptation, constraining their utility across varied real-world scenarios with
different demands. Besides, most current evaluations of speaker-adaptive TTS
are conducted only on datasets of native speakers, inadvertently neglecting a
vast portion of non-native speakers with diverse accents. Our proposed
framework unifies both zero-shot and few-shot speaker adaptation strategies,
which we term as ""instant"" and ""fine-grained"" adaptations based on their
merits. To alleviate the insufficient generalization performance observed in
zero-shot speaker adaptation, we designed two innovative discriminators and
introduced a memory mechanism for the speech decoder. To prevent catastrophic
forgetting and reduce storage implications for few-shot speaker adaptation, we
designed two adapters and a unique adaptation procedure.",2024-04-28,"Wenbin Wang, Yang Song, Sanjay Jha",http://arxiv.org/pdf/2404.18094v1,cs.CL
CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with Fine-tuned Large Language Model,"Domain-Specific Chinese Relation Extraction (DSCRE) aims to extract relations
between entities from domain-specific Chinese text. Despite the rapid
development of PLMs in recent years, especially LLMs, DSCRE still faces three
core challenges: complex network structure design, poor awareness, and high
consumption of fine-tuning. Given the impressive performance of large language
models (LLMs) in natural language processing, we propose a new framework called
CRE-LLM. This framework is based on fine-tuning open-source LLMs, such as
Llama-2, ChatGLM2, and Baichuan2. CRE-LLM enhances the logic-awareness and
generative capabilities of the model by constructing an appropriate prompt and
utilizing open-source LLMs for instruction-supervised fine-tuning. And then it
directly extracts the relations of the given entities in the input textual
data, which improving the CRE approach. To demonstrate the effectiveness of the
proposed framework, we conducted extensive experiments on two domain-specific
CRE datasets, FinRE and SanWen. The experimental results show that CRE-LLM is
significantly superior and robust, achieving state-of-the-art (SOTA)
performance on the FinRE dataset. This paper introduces a novel approach to
domain-specific relation extraction (DSCRE) tasks that are semantically more
complex by combining LLMs with triples. Our code is publicly available.",2024-04-28,"Zhengpeng Shi, Haoran Luo",http://arxiv.org/pdf/2404.18085v1,cs.CL
ComposerX: Multi-Agent Symbolic Music Composition with LLMs,"Music composition represents the creative side of humanity, and itself is a
complex task that requires abilities to understand and generate information
with long dependency and harmony constraints. While demonstrating impressive
capabilities in STEM subjects, current LLMs easily fail in this task,
generating ill-written music even when equipped with modern techniques like
In-Context-Learning and Chain-of-Thoughts. To further explore and enhance LLMs'
potential in music composition by leveraging their reasoning ability and the
large knowledge base in music history and theory, we propose ComposerX, an
agent-based symbolic music generation framework. We find that applying a
multi-agent approach significantly improves the music composition quality of
GPT-4. The results demonstrate that ComposerX is capable of producing coherent
polyphonic music compositions with captivating melodies, while adhering to user
instructions.",2024-04-28,"Qixin Deng, Qikai Yang, Ruibin Yuan, Yipeng Huang, Yi Wang, Xubo Liu, Zeyue Tian, Jiahao Pan, Ge Zhang, Hanfeng Lin, Yizhi Li, Yinghao Ma, Jie Fu, Chenghua Lin, Emmanouil Benetos, Wenwu Wang, Guangyu Xia, Wei Xue, Yike Guo",http://arxiv.org/pdf/2404.18081v2,cs.CL
Contextual Spelling Correction with Language Model for Low-resource Setting,"The task of Spell Correction(SC) in low-resource languages presents a
significant challenge due to the availability of only a limited corpus of data
and no annotated spelling correction datasets. To tackle these challenges a
small-scale word-based transformer LM is trained to provide the SC model with
contextual understanding. Further, the probabilistic error rules are extracted
from the corpus in an unsupervised way to model the tendency of error
happening(error model). Then the combination of LM and error model is used to
develop the SC model through the well-known noisy channel framework. The
effectiveness of this approach is demonstrated through experiments on the
Nepali language where there is access to just an unprocessed corpus of textual
data.",2024-04-28,"Nishant Luitel, Nirajan Bekoju, Anand Kumar Sah, Subarna Shakya",http://arxiv.org/pdf/2404.18072v1,cs.CL
Can Perplexity Predict Fine-Tuning Performance? An Investigation of Tokenization Effects on Sequential Language Models for Nepali,"Recent language models use subwording mechanisms to handle
Out-of-Vocabulary(OOV) words seen during test time and, their generation
capacity is generally measured using perplexity, an intrinsic metric. It is
known that increasing the subword granularity results in a decrease of
perplexity value. However, the study of how subwording affects the
understanding capacity of language models has been very few and only limited to
a handful of languages. To reduce this gap we used 6 different tokenization
schemes to pretrain relatively small language models in Nepali and used the
representations learned to finetune on several downstream tasks. Although
byte-level BPE algorithm has been used in recent models like GPT, RoBERTa we
show that on average they are sub-optimal in comparison to algorithms such as
SentencePiece in finetuning performances for Nepali. Additionally, similar
recent studies have focused on the Bert-based language model. We, however,
pretrain and finetune sequential transformer-based language models.",2024-04-28,"Nishant Luitel, Nirajan Bekoju, Anand Kumar Sah, Subarna Shakya",http://arxiv.org/pdf/2404.18071v1,cs.CL
Efficient LLM Inference with Kcache,"Large Language Models(LLMs) have had a profound impact on AI applications,
particularly in the domains of long-text comprehension and generation. KV Cache
technology is one of the most widely used techniques in the industry. It
ensures efficient sequence generation by caching previously computed KV states.
However, it also introduces significant memory overhead. We discovered that KV
Cache is not necessary and proposed a novel KCache technique to alleviate the
memory bottleneck issue during the LLMs inference process. KCache can be used
directly for inference without any training process, Our evaluations show that
KCache improves the throughput of popular LLMs by 40% with the baseline, while
keeping accuracy.",2024-04-28,"Qiaozhi He, Zhihua Wu",http://arxiv.org/pdf/2404.18057v1,cs.CL
Utilizing Large Language Models for Information Extraction from Real Estate Transactions,"Real estate sales contracts contain crucial information for property
transactions, but manual data extraction can be time-consuming and error-prone.
This paper explores the application of large language models, specifically
transformer-based architectures, for automated information extraction from real
estate contracts. We discuss challenges, techniques, and future directions in
leveraging these models to improve efficiency and accuracy in real estate
contract analysis. We generated synthetic contracts using the real-world
transaction dataset, thereby fine-tuning the large-language model and achieving
significant metrics improvements and qualitative improvements in information
retrieval and reasoning tasks.",2024-04-28,"Yu Zhao, Haoxiang Gao",http://arxiv.org/pdf/2404.18043v2,cs.CL
Fashion Recommendation: Outfit Compatibility using GNN,"Numerous industries have benefited from the use of machine learning and
fashion in industry is no exception. By gaining a better understanding of what
makes a good outfit, companies can provide useful product recommendations to
their users. In this project, we follow two existing approaches that employ
graphs to represent outfits and use modified versions of the Graph neural
network (GNN) frameworks. Both Node-wise Graph Neural Network (NGNN) and
Hypergraph Neural Network aim to score a set of items according to the outfit
compatibility of items. The data used is the Polyvore Dataset which consists of
curated outfits with product images and text descriptions for each product in
an outfit. We recreate the analysis on a subset of this data and compare the
two existing models on their performance on two tasks Fill in the blank (FITB):
finding an item that completes an outfit, and Compatibility prediction:
estimating compatibility of different items grouped as an outfit. We can
replicate the results directionally and find that HGNN does have a slightly
better performance on both tasks. On top of replicating the results of the two
papers we also tried to use embeddings generated from a vision transformer and
witness enhanced prediction accuracy across the board",2024-04-28,Samaksh Gulati,http://arxiv.org/pdf/2404.18040v1,cs.CL
Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational Text Data,"In this paper, we explore the potential of Large Language Models (LLMs) with
assertions to mitigate imbalances in educational datasets. Traditional models
often fall short in such contexts, particularly due to the complexity and
nuanced nature of the data. This issue is especially prominent in the education
sector, where cognitive engagement levels among students show significant
variation in their open responses. To test our hypothesis, we utilized an
existing technology for assertion-based prompt engineering through an
'Iterative - ICL PE Design Process' comparing traditional Machine Learning (ML)
models against LLMs augmented with assertions (N=135). Further, we conduct a
sensitivity analysis on a subset (n=27), examining the variance in model
performance concerning classification metrics and cognitive engagement levels
in each iteration. Our findings reveal that LLMs with assertions significantly
outperform traditional ML models, particularly in cognitive engagement levels
with minority representation, registering up to a 32% increase in F1-score.
Additionally, our sensitivity study indicates that incorporating targeted
assertions into the LLM tested on the subset enhances its performance by
11.94%. This improvement primarily addresses errors stemming from the model's
limitations in understanding context and resolving lexical ambiguities in
student responses.",2024-04-28,"Jeanne McClure, Machi Shimmei, Noboru Matsuda, Shiyan Jiang",http://arxiv.org/pdf/2407.01551v1,cs.CL
Quality Estimation with $k$-nearest Neighbors and Automatic Evaluation for Model-specific Quality Estimation,"Providing quality scores along with Machine Translation (MT) output,
so-called reference-free Quality Estimation (QE), is crucial to inform users
about the reliability of the translation. We propose a model-specific,
unsupervised QE approach, termed $k$NN-QE, that extracts information from the
MT model's training data using $k$-nearest neighbors. Measuring the performance
of model-specific QE is not straightforward, since they provide quality scores
on their own MT output, thus cannot be evaluated using benchmark QE test sets
containing human quality scores on premade MT output. Therefore, we propose an
automatic evaluation method that uses quality scores from reference-based
metrics as gold standard instead of human-generated ones. We are the first to
conduct detailed analyses and conclude that this automatic method is
sufficient, and the reference-based MetricX-23 is best for the task.",2024-04-27,"Tu Anh Dinh, Tobias Palzer, Jan Niehues",http://arxiv.org/pdf/2404.18031v1,cs.CL
CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments,"The introduction of genome engineering technology has transformed biomedical
research, making it possible to make precise changes to genetic information.
However, creating an efficient gene-editing system requires a deep
understanding of CRISPR technology, and the complex experimental systems under
investigation. While Large Language Models (LLMs) have shown promise in various
tasks, they often lack specific knowledge and struggle to accurately solve
biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent
augmented with domain knowledge and external tools to automate and enhance the
design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages
the reasoning ability of LLMs to facilitate the process of selecting CRISPR
systems, designing guide RNAs, recommending cellular delivery methods, drafting
protocols, and designing validation experiments to confirm editing outcomes. We
showcase the potential of CRISPR-GPT for assisting non-expert researchers with
gene-editing experiments from scratch and validate the agent's effectiveness in
a real-world use case. Furthermore, we explore the ethical and regulatory
considerations associated with automated gene-editing design, highlighting the
need for responsible and transparent use of these tools. Our work aims to
bridge the gap between beginner biological researchers and CRISPR genome
engineering techniques, and demonstrate the potential of LLM agents in
facilitating complex biological discovery tasks.",2024-04-27,"Kaixuan Huang, Yuanhao Qu, Henry Cousins, William A. Johnson, Di Yin, Mihir Shah, Denny Zhou, Russ Altman, Mengdi Wang, Le Cong",http://arxiv.org/pdf/2404.18021v1,cs.CL
MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch,"Accurate representation of medical information is crucial for patient safety,
yet artificial intelligence (AI) systems, such as Large Language Models (LLMs),
encounter challenges in error-free clinical text interpretation. This paper
presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben
Abacha et al., 2024a), focusing on the automatic correction of single-word
errors in clinical notes. Unlike LLMs that rely on extensive generic data, our
method emphasizes extracting contextually relevant information from available
clinical text data. Leveraging an ensemble of extractive and abstractive
question-answering approaches, we construct a supervised learning framework
with domain-specific feature engineering. Our methodology incorporates domain
expertise to enhance error correction accuracy. By integrating domain expertise
and prioritizing meaningful information extraction, our approach underscores
the significance of a human-centric strategy in adapting AI for healthcare.",2024-04-27,Nadia Saeed,http://arxiv.org/pdf/2404.17999v1,cs.CL
MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning,"The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual &
Multimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a).
This paper addresses the limitations of traditional methods by proposing a
weakly supervised learning approach for open-ended medical question-answering
(QA). Our system leverages readily available MEDIQA-M3G images via a
VGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning
of informative skin condition representations. Using pre-trained QA models, we
further bridge the gap between visual and textual information through
multimodal fusion. This approach tackles complex, open-ended questions even
without predefined answer choices. We empower the generation of comprehensive
answers by feeding the ViT-CLIP model with multiple responses alongside images.
This work advances medical QA research, paving the way for clinical decision
support systems and ultimately improving healthcare delivery.",2024-04-27,Nadia Saeed,http://arxiv.org/pdf/2405.01583v1,cs.CL
Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension,"Machine Reading Comprehension (MRC) poses a significant challenge in the
field of Natural Language Processing (NLP). While mainstream MRC methods
predominantly leverage extractive strategies using encoder-only models such as
BERT, generative approaches face the issue of out-of-control generation -- a
critical problem where answers generated are often incorrect, irrelevant, or
unfaithful to the source text. To address these limitations in generative
models for MRC, we introduce the Question-Attended Span Extraction (QASE)
module. Integrated during the fine-tuning phase of pre-trained generative
language models (PLMs), QASE significantly enhances their performance, allowing
them to surpass the extractive capabilities of advanced Large Language Models
(LLMs) such as GPT-4 in few-shot settings. Notably, these gains in performance
do not come with an increase in computational demands. The efficacy of the QASE
module has been rigorously tested across various datasets, consistently
achieving or even surpassing state-of-the-art (SOTA) results, thereby bridging
the gap between generative and extractive models in extractive MRC tasks.",2024-04-27,"Lin Ai, Zheng Hui, Zizhou Liu, Julia Hirschberg",http://arxiv.org/pdf/2404.17991v3,cs.CL
Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models,"The automated detection of conspiracy theories online typically relies on
supervised learning. However, creating respective training data requires
expertise, time and mental resilience, given the often harmful content.
Moreover, available datasets are predominantly in English and often
keyword-based, introducing a token-level bias into the models. Our work
addresses the task of detecting conspiracy theories in German Telegram
messages. We compare the performance of supervised fine-tuning approaches using
BERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4
which require little or no additional training data. We use a dataset of
$\sim\!\! 4,000$ messages collected during the COVID-19 pandemic, without the
use of keyword filters.
  Our findings demonstrate that both approaches can be leveraged effectively:
For supervised fine-tuning, we report an F1 score of $\sim\!\! 0.8$ for the
positive class, making our model comparable to recent models trained on
keyword-focused English corpora. We demonstrate our model's adaptability to
intra-domain temporal shifts, achieving F1 scores of $\sim\!\! 0.7$. Among
prompting variants, the best model is GPT-4, achieving an F1 score of $\sim\!\!
0.8$ for the positive class in a zero-shot setting and equipped with a custom
conspiracy theory definition.",2024-04-27,"Milena Pustet, Elisabeth Steffen, Helena Mihaljević",http://arxiv.org/pdf/2404.17985v1,cs.CL
TI-ASU: Toward Robust Automatic Speech Understanding through Text-to-speech Imputation Against Missing Speech Modality,"Automatic Speech Understanding (ASU) aims at human-like speech
interpretation, providing nuanced intent, emotion, sentiment, and content
understanding from speech and language (text) content conveyed in speech.
Typically, training a robust ASU model relies heavily on acquiring large-scale,
high-quality speech and associated transcriptions. However, it is often
challenging to collect or use speech data for training ASU due to concerns such
as privacy. To approach this setting of enabling ASU when speech (audio)
modality is missing, we propose TI-ASU, using a pre-trained text-to-speech
model to impute the missing speech. We report extensive experiments evaluating
TI-ASU on various missing scales, both multi- and single-modality settings, and
the use of LLMs. Our findings show that TI-ASU yields substantial benefits to
improve ASU in scenarios where even up to 95% of training speech is missing.
Moreover, we show that TI-ASU is adaptive to dropout training, improving model
robustness in addressing missing speech during inference.",2024-04-27,"Tiantian Feng, Xuan Shi, Rahul Gupta, Shrikanth S. Narayanan",http://arxiv.org/pdf/2404.17983v1,cs.CL
Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry,"In the rapidly evolving landscape of Natural Language Processing (NLP), Large
Language Models (LLMs) have emerged as powerful tools for many tasks, such as
extracting valuable insights from vast amounts of textual data. In this study,
we conduct a comparative analysis of LLMs for the extraction of travel customer
needs from TripAdvisor and Reddit posts. Leveraging a diverse range of models,
including both open-source and proprietary ones such as GPT-4 and Gemini, we
aim to elucidate their strengths and weaknesses in this specialized domain.
Through an evaluation process involving metrics such as BERTScore, ROUGE, and
BLEU, we assess the performance of each model in accurately identifying and
summarizing customer needs. Our findings highlight the efficacy of opensource
LLMs, particularly Mistral 7B, in achieving comparable performance to larger
closed models while offering affordability and customization benefits.
Additionally, we underscore the importance of considering factors such as model
size, resource requirements, and performance metrics when selecting the most
suitable LLM for customer needs analysis tasks. Overall, this study contributes
valuable insights for businesses seeking to leverage advanced NLP techniques to
enhance customer experience and drive operational efficiency in the travel
industry.",2024-04-27,"Simone Barandoni, Filippo Chiarello, Lorenzo Cascone, Emiliano Marrale, Salvatore Puccio",http://arxiv.org/pdf/2404.17975v2,cs.CL
Usefulness of Emotional Prosody in Neural Machine Translation,"Neural Machine Translation (NMT) is the task of translating a text from one
language to another with the use of a trained neural network. Several existing
works aim at incorporating external information into NMT models to improve or
control predicted translations (e.g. sentiment, politeness, gender). In this
work, we propose to improve translation quality by adding another external
source of information: the automatically recognized emotion in the voice. This
work is motivated by the assumption that each emotion is associated with a
specific lexicon that can overlap between emotions. Our proposed method follows
a two-stage procedure. At first, we select a state-of-the-art Speech Emotion
Recognition (SER) model to predict dimensional emotion values from all input
audio in the dataset. Then, we use these predicted emotions as source tokens
added at the beginning of input texts to train our NMT model. We show that
integrating emotion information, especially arousal, into NMT systems leads to
better translations.",2024-04-27,"Charles Brazier, Jean-Luc Rouas",http://arxiv.org/pdf/2404.17968v1,cs.CL
Transfer Learning Enhanced Single-choice Decision for Multi-choice Question Answering,"Multi-choice Machine Reading Comprehension (MMRC) aims to select the correct
answer from a set of options based on a given passage and question. The
existing methods employ the pre-trained language model as the encoder, share
and transfer knowledge through fine-tuning.These methods mainly focus on the
design of exquisite mechanisms to effectively capture the relationships among
the triplet of passage, question and answers. It is non-trivial but ignored to
transfer knowledge from other MRC tasks such as SQuAD due to task specific of
MMRC.In this paper, we reconstruct multi-choice to single-choice by training a
binary classification to distinguish whether a certain answer is correct. Then
select the option with the highest confidence score as the final answer. Our
proposed method gets rid of the multi-choice framework and can leverage
resources of other tasks. We construct our model based on the ALBERT-xxlarge
model and evaluate it on the RACE and DREAM datasets. Experimental results show
that our model performs better than multi-choice methods. In addition, by
transferring knowledge from other kinds of MRC tasks, our model achieves
state-of-the-art results in both single and ensemble settings.",2024-04-27,"Chenhao Cui, Yufan Jiang, Shuangzhi Wu, Zhoujun Li",http://arxiv.org/pdf/2404.17949v1,cs.CL
Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition,"Existing pedestrian attribute recognition (PAR) algorithms are mainly
developed based on a static image, however, the performance is unreliable in
challenging scenarios, such as heavy occlusion, motion blur, etc. In this work,
we propose to understand human attributes using video frames that can fully use
temporal information by fine-tuning a pre-trained multi-modal foundation model
efficiently. Specifically, we formulate the video-based PAR as a
vision-language fusion problem and adopt a pre-trained foundation model CLIP to
extract the visual features. More importantly, we propose a novel
spatiotemporal side-tuning strategy to achieve parameter-efficient optimization
of the pre-trained vision foundation model. To better utilize the semantic
information, we take the full attribute list that needs to be recognized as
another input and transform the attribute words/phrases into the corresponding
sentence via split, expand, and prompt operations. Then, the text encoder of
CLIP is utilized for embedding processed attribute descriptions. The averaged
visual tokens and text tokens are concatenated and fed into a fusion
Transformer for multi-modal interactive learning. The enhanced tokens will be
fed into a classification head for pedestrian attribute prediction. Extensive
experiments on two large-scale video-based PAR datasets fully validated the
effectiveness of our proposed framework. The source code of this paper is
available at https://github.com/Event-AHU/OpenPAR.",2024-04-27,"Xiao Wang, Qian Zhu, Jiandong Jin, Jun Zhu, Futian Wang, Bo Jiang, Yaowei Wang, Yonghong Tian",http://arxiv.org/pdf/2404.17929v1,cs.CL
I Have an Attention Bridge to Sell You: Generalization Capabilities of Modular Translation Architectures,"Modularity is a paradigm of machine translation with the potential of
bringing forth models that are large at training time and small during
inference. Within this field of study, modular approaches, and in particular
attention bridges, have been argued to improve the generalization capabilities
of models by fostering language-independent representations. In the present
paper, we study whether modularity affects translation quality; as well as how
well modular architectures generalize across different evaluation scenarios.
For a given computational budget, we find non-modular architectures to be
always comparable or preferable to all modular designs we study.",2024-04-27,"Timothee Mickus, Raúl Vázquez, Joseph Attieh",http://arxiv.org/pdf/2404.17918v2,cs.CL
SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models,"Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large
Language Models (MLLMs) can automate the creation of accurate and coherent
radiological reports. Existing methods often hallucinate details in text-based
reports that don't accurately reflect the image content. To mitigate this, we
introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort
GENeraTion using Vision Language Models), which improves the R2Gen task by
integrating a self-refining mechanism into the MLLM framework. We employ a
unique self-supervised loss that leverages similarity between pooled image
representations and the contextual representations of the generated
radiological text, alongside the standard Causal Language Modeling objective,
to refine image-text representations. This allows the model to scrutinize and
align the generated text through dynamic interaction between a given image and
the generated text, therefore reducing hallucination and continuously enhancing
nuanced report generation. SERPENT-VLM outperforms existing baselines such as
LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and
Radiology Objects in COntext (ROCO) datasets, and also proves to be robust
against noisy images. A qualitative case study emphasizes the significant
advancements towards more sophisticated MLLM frameworks for R2Gen, opening
paths for further research into self-supervised refinement in the medical
imaging domain.",2024-04-27,"Manav Nitin Kapadnis, Sohan Patnaik, Abhilash Nandy, Sourjyadip Ray, Pawan Goyal, Debdoot Sheet",http://arxiv.org/pdf/2404.17912v2,cs.CL
Tool Calling: Enhancing Medication Consultation via Retrieval-Augmented Large Language Models,"Large-scale language models (LLMs) have achieved remarkable success across
various language tasks but suffer from hallucinations and temporal
misalignment. To mitigate these shortcomings, Retrieval-augmented generation
(RAG) has been utilized to provide external knowledge to facilitate the answer
generation. However, applying such models to the medical domain faces several
challenges due to the lack of domain-specific knowledge and the intricacy of
real-world scenarios. In this study, we explore LLMs with RAG framework for
knowledge-intensive tasks in the medical field. To evaluate the capabilities of
LLMs, we introduce MedicineQA, a multi-round dialogue benchmark that simulates
the real-world medication consultation scenario and requires LLMs to answer
with retrieved evidence from the medicine database. MedicineQA contains 300
multi-round question-answering pairs, each embedded within a detailed dialogue
history, highlighting the challenge posed by this knowledge-intensive task to
current LLMs. We further propose a new \textit{Distill-Retrieve-Read} framework
instead of the previous \textit{Retrieve-then-Read}. Specifically, the
distillation and retrieval process utilizes a tool calling mechanism to
formulate search queries that emulate the keyword-based inquiries used by
search engines. With experimental results, we show that our framework brings
notable performance improvements and surpasses the previous counterparts in the
evidence retrieval process in terms of evidence retrieval accuracy. This
advancement sheds light on applying RAG to the medical domain.",2024-04-27,"Zhongzhen Huang, Kui Xue, Yongqi Fan, Linjie Mu, Ruoyu Liu, Tong Ruan, Shaoting Zhang, Xiaofan Zhang",http://arxiv.org/pdf/2404.17897v1,cs.CL
PromptCL: Improving Event Representation via Prompt Template and Contrastive Learning,"The representation of events in text plays a significant role in various NLP
tasks. Recent research demonstrates that contrastive learning has the ability
to improve event comprehension capabilities of Pre-trained Language Models
(PLMs) and enhance the performance of event representation learning. However,
the efficacy of event representation learning based on contrastive learning and
PLMs is limited by the short length of event texts. The length of event texts
differs significantly from the text length used in the pre-training of PLMs. As
a result, there is inconsistency in the distribution of text length between
pre-training and event representation learning, which may undermine the
learning process of event representation based on PLMs. In this study, we
present PromptCL, a novel framework for event representation learning that
effectively elicits the capabilities of PLMs to comprehensively capture the
semantics of short event texts. PromptCL utilizes a Prompt template borrowed
from prompt learning to expand the input text during Contrastive Learning. This
helps in enhancing the event representation learning by providing a structured
outline of the event components. Moreover, we propose Subject-Predicate-Object
(SPO) word order and Event-oriented Masked Language Modeling (EventMLM) to
train PLMs to understand the relationships between event components. Our
experimental results demonstrate that PromptCL outperforms state-of-the-art
baselines on event related tasks. Additionally, we conduct a thorough analysis
and demonstrate that using a prompt results in improved generalization
capabilities for event representations. Our code will be available at
https://github.com/YuboFeng2023/PromptCL.",2024-04-27,"Yubo Feng, Lishuang Li, Yi Xiang, Xueyang Qin",http://arxiv.org/pdf/2404.17877v1,cs.CL
From Languages to Geographies: Towards Evaluating Cultural Bias in Hate Speech Datasets,"Perceptions of hate can vary greatly across cultural contexts. Hate speech
(HS) datasets, however, have traditionally been developed by language. This
hides potential cultural biases, as one language may be spoken in different
countries home to different cultures. In this work, we evaluate cultural bias
in HS datasets by leveraging two interrelated cultural proxies: language and
geography. We conduct a systematic survey of HS datasets in eight languages and
confirm past findings on their English-language bias, but also show that this
bias has been steadily decreasing in the past few years. For three
geographically-widespread languages -- English, Arabic and Spanish -- we then
leverage geographical metadata from tweets to approximate geo-cultural contexts
by pairing language and country information. We find that HS datasets for these
languages exhibit a strong geo-cultural bias, largely overrepresenting a
handful of countries (e.g., US and UK for English) relative to their prominence
in both the broader social media population and the general population speaking
these languages. Based on these findings, we formulate recommendations for the
creation of future HS datasets.",2024-04-27,"Manuel Tonneau, Diyi Liu, Samuel Fraiberger, Ralph Schroeder, Scott A. Hale, Paul Röttger",http://arxiv.org/pdf/2404.17874v2,cs.CL
Revisiting Multimodal Emotion Recognition in Conversation from the Perspective of Graph Spectrum,"Efficiently capturing consistent and complementary semantic features in a
multimodal conversation context is crucial for Multimodal Emotion Recognition
in Conversation (MERC). Existing methods mainly use graph structures to model
dialogue context semantic dependencies and employ Graph Neural Networks (GNN)
to capture multimodal semantic features for emotion recognition. However, these
methods are limited by some inherent characteristics of GNN, such as
over-smoothing and low-pass filtering, resulting in the inability to learn
long-distance consistency information and complementary information
efficiently. Since consistency and complementarity information correspond to
low-frequency and high-frequency information, respectively, this paper revisits
the problem of multimodal emotion recognition in conversation from the
perspective of the graph spectrum. Specifically, we propose a
Graph-Spectrum-based Multimodal Consistency and Complementary collaborative
learning framework GS-MCC. First, GS-MCC uses a sliding window to construct a
multimodal interaction graph to model conversational relationships and uses
efficient Fourier graph operators to extract long-distance high-frequency and
low-frequency information, respectively. Then, GS-MCC uses contrastive learning
to construct self-supervised signals that reflect complementarity and
consistent semantic collaboration with high and low-frequency signals, thereby
improving the ability of high and low-frequency information to reflect real
emotions. Finally, GS-MCC inputs the collaborative high and low-frequency
information into the MLP network and softmax function for emotion prediction.
Extensive experiments have proven the superiority of the GS-MCC architecture
proposed in this paper on two benchmark data sets.",2024-04-27,"Tao Meng, Fuchen Zhang, Yuntao Shou, Wei Ai, Nan Yin, Keqin Li",http://arxiv.org/pdf/2404.17862v2,cs.CL
Revisiting Multi-modal Emotion Learning with Broad State Space Models and Probability-guidance Fusion,"Multi-modal Emotion Recognition in Conversation (MERC) has received
considerable attention in various fields, e.g., human-computer interaction and
recommendation systems. Most existing works perform feature disentanglement and
fusion to extract emotional contextual information from multi-modal features
and emotion classification. After revisiting the characteristic of MERC, we
argue that long-range contextual semantic information should be extracted in
the feature disentanglement stage and the inter-modal semantic information
consistency should be maximized in the feature fusion stage. Inspired by recent
State Space Models (SSMs), Mamba can efficiently model long-distance
dependencies. Therefore, in this work, we fully consider the above insights to
further improve the performance of MERC. Specifically, on the one hand, in the
feature disentanglement stage, we propose a Broad Mamba, which does not rely on
a self-attention mechanism for sequence modeling, but uses state space models
to compress emotional representation, and utilizes broad learning systems to
explore the potential data distribution in broad space. Different from previous
SSMs, we design a bidirectional SSM convolution to extract global context
information. On the other hand, we design a multi-modal fusion strategy based
on probability guidance to maximize the consistency of information between
modalities. Experimental results show that the proposed method can overcome the
computational and memory limitations of Transformer when modeling long-distance
contexts, and has great potential to become a next-generation general
architecture in MERC.",2024-04-27,"Yuntao Shou, Tao Meng, Fuchen Zhang, Nan Yin, Keqin Li",http://arxiv.org/pdf/2404.17858v2,cs.CL
Toxicity Classification in Ukrainian,"The task of toxicity detection is still a relevant task, especially in the
context of safe and fair LMs development. Nevertheless, labeled binary toxicity
classification corpora are not available for all languages, which is
understandable given the resource-intensive nature of the annotation process.
Ukrainian, in particular, is among the languages lacking such resources. To our
knowledge, there has been no existing toxicity classification corpus in
Ukrainian. In this study, we aim to fill this gap by investigating
cross-lingual knowledge transfer techniques and creating labeled corpora by:
(i)~translating from an English corpus, (ii)~filtering toxic samples using
keywords, and (iii)~annotating with crowdsourcing. We compare LLMs prompting
and other cross-lingual transfer approaches with and without fine-tuning
offering insights into the most robust and efficient baselines.",2024-04-27,"Daryna Dementieva, Valeriia Khylenko, Nikolay Babakov, Georg Groh",http://arxiv.org/pdf/2404.17841v1,cs.CL
VANER: Leveraging Large Language Model for Versatile and Adaptive Biomedical Named Entity Recognition,"Prevalent solution for BioNER involves using representation learning
techniques coupled with sequence labeling. However, such methods are inherently
task-specific, demonstrate poor generalizability, and often require dedicated
model for each dataset. To leverage the versatile capabilities of recently
remarkable large language models (LLMs), several endeavors have explored
generative approaches to entity extraction. Yet, these approaches often fall
short of the effectiveness of previouly sequence labeling approaches. In this
paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design
specific instructions to distinguish between different types of entities and
datasets. By combining the LLM's understanding of instructions with sequence
labeling techniques, we use mix of datasets to train a model capable of
extracting various types of entities. Given that the backbone LLMs lacks
specialized medical knowledge, we also integrate external entity knowledge
bases and employ instruction tuning to compel the model to densely recognize
carefully curated entities. Our model VANER, trained with a small partition of
parameters, significantly outperforms previous LLMs-based models and, for the
first time, as a model based on LLM, surpasses the majority of conventional
state-of-the-art BioNER systems, achieving the highest F1 scores across three
datasets.",2024-04-27,"Junyi Biana, Weiqi Zhai, Xiaodi Huang, Jiaxuan Zheng, Shanfeng Zhu",http://arxiv.org/pdf/2404.17835v1,cs.CL
Evaluation of Few-Shot Learning for Classification Tasks in the Polish Language,"We introduce a few-shot benchmark consisting of 7 different classification
tasks native to the Polish language. We conducted an empirical comparison with
0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context
learning (ICL) using various pre-trained commercial and open-source models. Our
findings reveal that ICL achieves the best performance, with commercial models
like GPT-3.5 and GPT-4 attaining the best performance. However, there remains a
significant 14 percentage points gap between our best few-shot learning score
and the performance of HerBERT-large fine-tuned on the entire training dataset.
Among the techniques, SetFit emerges as the second-best approach, closely
followed by linear probing. We observed the worst and most unstable performance
with non-linear head fine-tuning. Results for ICL indicate that continual
pre-training of models like Mistral-7b or Llama-2-13b on Polish corpora is
beneficial. This is confirmed by the improved performances of Bielik-7b and
Trurl-13b, respectively. To further support experiments in few-shot learning
for Polish, we are releasing handcrafted templates for the ICL.",2024-04-27,"Tsimur Hadeliya, Dariusz Kajtoch",http://arxiv.org/pdf/2404.17832v1,cs.CL
"Recall, Retrieve and Reason: Towards Better In-Context Relation Extraction","Relation extraction (RE) aims to identify relations between entities
mentioned in texts. Although large language models (LLMs) have demonstrated
impressive in-context learning (ICL) abilities in various tasks, they still
suffer from poor performances compared to most supervised fine-tuned RE
methods. Utilizing ICL for RE with LLMs encounters two challenges: (1)
retrieving good demonstrations from training examples, and (2) enabling LLMs
exhibit strong ICL abilities in RE. On the one hand, retrieving good
demonstrations is a non-trivial process in RE, which easily results in low
relevance regarding entities and relations. On the other hand, ICL with an LLM
achieves poor performance in RE while RE is different from language modeling in
nature or the LLM is not large enough. In this work, we propose a novel
recall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora
(training examples) to enable relevant retrieving and reliable in-context
reasoning. Specifically, we distill the consistently ontological knowledge from
training datasets to let LLMs generate relevant entity pairs grounded by
retrieval corpora as valid queries. These entity pairs are then used to
retrieve relevant training examples from the retrieval corpora as
demonstrations for LLMs to conduct better ICL via instruction tuning. Extensive
experiments on different LLMs and RE datasets demonstrate that our method
generates relevant and valid entity pairs and boosts ICL abilities of LLMs,
achieving competitive or new state-of-the-art performance on sentence-level RE
compared to previous supervised fine-tuning methods and ICL-based methods.",2024-04-27,"Guozheng Li, Peng Wang, Wenjun Ke, Yikai Guo, Ke Ji, Ziyu Shang, Jiajun Liu, Zijie Xu",http://arxiv.org/pdf/2404.17809v1,cs.CL
Scaffold-BPE: Enhancing Byte Pair Encoding for Large Language Models with Simple and Effective Scaffold Token Removal,"Byte Pair Encoding (BPE) serves as a foundation method for text tokenization
in the Natural Language Processing (NLP) field. Despite its wide adoption, the
original BPE algorithm harbors an inherent flaw: it inadvertently introduces a
frequency imbalance for tokens in the text corpus. Since BPE iteratively merges
the most frequent token pair in the text corpus to generate a new token and
keeps all generated tokens in the vocabulary, it unavoidably holds tokens that
primarily act as components of a longer token and appear infrequently on their
own. We term such tokens as Scaffold Tokens. Due to their infrequent
occurrences in the text corpus, Scaffold Tokens pose a learning imbalance
issue. To address that issue, we propose Scaffold-BPE, which incorporates a
dynamic scaffold token removal mechanism by parameter-free, computation-light,
and easy-to-implement modifications to the original BPE method. This novel
approach ensures the exclusion of low-frequency Scaffold Tokens from the token
representations for given texts, thereby mitigating the issue of frequency
imbalance and facilitating model training. On extensive experiments across
language modeling and even machine translation, Scaffold-BPE consistently
outperforms the original BPE, well demonstrating its effectiveness.",2024-04-27,"Haoran Lian, Yizhe Xiong, Jianwei Niu, Shasha Mo, Zhenpeng Su, Zijia Lin, Hui Chen, Peng Liu, Jungong Han, Guiguang Ding",http://arxiv.org/pdf/2404.17808v3,cs.CL
Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors,"Relation extraction (RE) is an important task that aims to identify the
relationships between entities in texts. While large language models (LLMs)
have revealed remarkable in-context learning (ICL) capability for general zero
and few-shot learning, recent studies indicate that current LLMs still struggle
with zero and few-shot RE. Previous studies are mainly dedicated to design
prompt formats and select good examples for improving ICL-based RE. Although
both factors are vital for ICL, if one can fundamentally boost the ICL
capability of LLMs in RE, the zero and few-shot RE performance via ICL would be
significantly improved. To this end, we introduce \textsc{Micre} (\textbf{M}eta
\textbf{I}n-\textbf{C}ontext learning of LLMs for \textbf{R}elation
\textbf{E}xtraction), a new meta-training framework for zero and few-shot RE
where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e.,
learning to learn in context for RE). Through meta-training, the model becomes
more effectively to learn a new RE task in context by conditioning on a few
training examples with no parameter updates or task-specific templates at
inference time, enabling better zero and few-shot task generalization. We
experiment \textsc{Micre} on various LLMs with different model scales and 12
public RE datasets, and then evaluate it on unseen RE benchmarks under zero and
few-shot settings. \textsc{Micre} delivers comparable or superior performance
compared to a range of baselines including supervised fine-tuning and typical
in-context learning methods. We find that the gains are particular significant
for larger model scales, and using a diverse set of the meta-training RE
datasets is key to improvements. Empirically, we show that \textsc{Micre} can
transfer the relation semantic knowledge via relation label name during
inference on target RE datasets.",2024-04-27,"Guozheng Li, Peng Wang, Jiajun Liu, Yikai Guo, Ke Ji, Ziyu Shang, Zijie Xu",http://arxiv.org/pdf/2404.17807v1,cs.CL
T-CLAP: Temporal-Enhanced Contrastive Language-Audio Pretraining,"Contrastive language-audio pretraining~(CLAP) has been developed to align the
representations of audio and language, achieving remarkable performance in
retrieval and classification tasks. However, current CLAP struggles to capture
temporal information within audio and text features, presenting substantial
limitations for tasks such as audio retrieval and generation. To address this
gap, we introduce T-CLAP, a temporal-enhanced CLAP model. We use Large Language
Models~(LLMs) and mixed-up strategies to generate temporal-contrastive captions
for audio clips from extensive audio-text datasets. Subsequently, a new
temporal-focused contrastive loss is designed to fine-tune the CLAP model by
incorporating these synthetic data. We conduct comprehensive experiments and
analysis in multiple downstream tasks. T-CLAP shows improved capability in
capturing the temporal relationship of sound events and outperforms
state-of-the-art models by a significant margin.",2024-04-27,"Yi Yuan, Zhuo Chen, Xubo Liu, Haohe Liu, Xuenan Xu, Dongya Jia, Yuanzhe Chen, Mark D. Plumbley, Wenwu Wang",http://arxiv.org/pdf/2404.17806v1,cs.CL
Empirical Analysis of Dialogue Relation Extraction with Large Language Models,"Dialogue relation extraction (DRE) aims to extract relations between two
arguments within a dialogue, which is more challenging than standard RE due to
the higher person pronoun frequency and lower information density in dialogues.
However, existing DRE methods still suffer from two serious issues: (1) hard to
capture long and sparse multi-turn information, and (2) struggle to extract
golden relations based on partial dialogues, which motivates us to discover
more effective methods that can alleviate the above issues. We notice that the
rise of large language models (LLMs) has sparked considerable interest in
evaluating their performance across diverse tasks. To this end, we initially
investigate the capabilities of different LLMs in DRE, considering both
proprietary models and open-source models. Interestingly, we discover that LLMs
significantly alleviate two issues in existing DRE methods. Generally, we have
following findings: (1) scaling up model size substantially boosts the overall
DRE performance and achieves exceptional results, tackling the difficulty of
capturing long and sparse multi-turn information; (2) LLMs encounter with much
smaller performance drop from entire dialogue setting to partial dialogue
setting compared to existing methods; (3) LLMs deliver competitive or superior
performances under both full-shot and few-shot settings compared to current
state-of-the-art; (4) LLMs show modest performances on inverse relations but
much stronger improvements on general relations, and they can handle dialogues
of various lengths especially for longer sequences.",2024-04-27,"Guozheng Li, Zijie Xu, Ziyu Shang, Jiajun Liu, Ke Ji, Yikai Guo",http://arxiv.org/pdf/2404.17802v1,cs.CL
Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities,"Cross-lingual continual pre-training of large language models (LLMs)
initially trained on English corpus allows us to leverage the vast amount of
English language resources and reduce the pre-training cost. In this study, we
constructed Swallow, an LLM with enhanced Japanese capability, by extending the
vocabulary of Llama 2 to include Japanese characters and conducting continual
pre-training on a large Japanese web corpus. Experimental results confirmed
that the performance on Japanese tasks drastically improved through continual
pre-training, and the performance monotonically increased with the amount of
training data up to 100B tokens. Consequently, Swallow achieved superior
performance compared to other LLMs that were trained from scratch in English
and Japanese. An analysis of the effects of continual pre-training revealed
that it was particularly effective for Japanese question answering tasks.
Furthermore, to elucidate effective methodologies for cross-lingual continual
pre-training from English to Japanese, we investigated the impact of vocabulary
expansion and the effectiveness of incorporating parallel corpora. The results
showed that the efficiency gained through vocabulary expansion had no negative
impact on performance, except for the summarization task, and that the combined
use of parallel corpora enhanced translation ability.",2024-04-27,"Kazuki Fujii, Taishi Nakamura, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Hirai Shota, Sakae Mizuki, Rio Yokota, Naoaki Okazaki",http://arxiv.org/pdf/2404.17790v1,cs.CL
Temporal Scaling Law for Large Language Models,"Recently, Large Language Models (LLMs) have been widely adopted in a wide
range of tasks, leading to increasing attention towards the research on how
scaling LLMs affects their performance. Existing works, termed Scaling Laws,
have discovered that the final test loss of LLMs scales as power-laws with
model size, computational budget, and dataset size. However, the temporal
change of the test loss of an LLM throughout its pre-training process remains
unexplored, though it is valuable in many aspects, such as selecting better
hyperparameters \textit{directly} on the target LLM. In this paper, we propose
the novel concept of Temporal Scaling Law, studying how the test loss of an LLM
evolves as the training steps scale up. In contrast to modeling the test loss
as a whole in a coarse-grained manner, we break it down and dive into the
fine-grained test loss of each token position, and further develop a dynamic
hyperbolic-law. Afterwards, we derive the much more precise temporal scaling
law by studying the temporal patterns of the parameters in the dynamic
hyperbolic-law. Results on both in-distribution (ID) and out-of-distribution
(OOD) validation datasets demonstrate that our temporal scaling law accurately
predicts the test loss of LLMs across training steps. Our temporal scaling law
has broad practical applications. First, it enables direct and efficient
hyperparameter selection on the target LLM, such as data mixture proportions.
Secondly, viewing the LLM pre-training dynamics from the token position
granularity provides some insights to enhance the understanding of LLM
pre-training.",2024-04-27,"Yizhe Xiong, Xiansheng Chen, Xin Ye, Hui Chen, Zijia Lin, Haoran Lian, Zhenpeng Su, Wei Huang, Jianwei Niu, Jungong Han, Guiguang Ding",http://arxiv.org/pdf/2404.17785v3,cs.CL
Medical Vision-Language Pre-Training for Brain Abnormalities,"Vision-language models have become increasingly powerful for tasks that
require an understanding of both visual and linguistic elements, bridging the
gap between these modalities. In the context of multimodal clinical AI, there
is a growing need for models that possess domain-specific knowledge, as
existing models often lack the expertise required for medical applications. In
this paper, we take brain abnormalities as an example to demonstrate how to
automatically collect medical image-text aligned data for pretraining from
public resources such as PubMed. In particular, we present a pipeline that
streamlines the pre-training process by initially collecting a large brain
image-text dataset from case reports and published journals and subsequently
constructing a high-performance vision-language model tailored to specific
medical tasks. We also investigate the unique challenge of mapping subfigures
to subcaptions in the medical domain. We evaluated the resulting model with
quantitative and qualitative intrinsic evaluations. The resulting dataset and
our code can be found here
https://github.com/masoud-monajati/MedVL_pretraining_pipeline",2024-04-27,"Masoud Monajatipoor, Zi-Yi Dou, Aichi Chien, Nanyun Peng, Kai-Wei Chang",http://arxiv.org/pdf/2404.17779v1,cs.CL
MRScore: Evaluating Radiology Report Generation with LLM-based Reward System,"In recent years, automated radiology report generation has experienced
significant growth. This paper introduces MRScore, an automatic evaluation
metric tailored for radiology report generation by leveraging Large Language
Models (LLMs). Conventional NLG (natural language generation) metrics like BLEU
are inadequate for accurately assessing the generated radiology reports, as
systematically demonstrated by our observations within this paper. To address
this challenge, we collaborated with radiologists to develop a framework that
guides LLMs for radiology report evaluation, ensuring alignment with human
analysis. Our framework includes two key components: i) utilizing GPT to
generate large amounts of training data, i.e., reports with different
qualities, and ii) pairing GPT-generated reports as accepted and rejected
samples and training LLMs to produce MRScore as the model reward. Our
experiments demonstrate MRScore's higher correlation with human judgments and
superior performance in model selection compared to traditional metrics. Our
code and datasets will be available on GitHub.",2024-04-27,"Yunyi Liu, Zhanyu Wang, Yingshu Li, Xinyu Liang, Lingqiao Liu, Lei Wang, Luping Zhou",http://arxiv.org/pdf/2404.17778v1,cs.CL
Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A Comparative Study,"The integration of Artificial Intelligence (AI) in healthcare presents a
transformative potential for enhancing operational efficiency and health
outcomes. Large Language Models (LLMs), such as ChatGPT, have shown their
capabilities in supporting medical decision-making. Embedding LLMs in medical
systems is becoming a promising trend in healthcare development. The potential
of ChatGPT to address the triage problem in emergency departments has been
examined, while few studies have explored its application in outpatient
departments. With a focus on streamlining workflows and enhancing efficiency
for outpatient triage, this study specifically aims to evaluate the consistency
of responses provided by ChatGPT in outpatient guidance, including both
within-version response analysis and between-version comparisons. For
within-version, the results indicate that the internal response consistency for
ChatGPT-4.0 is significantly higher than ChatGPT-3.5 (p=0.03) and both have a
moderate consistency (71.2% for 4.0 and 59.6% for 3.5) in their top
recommendation. However, the between-version consistency is relatively low
(mean consistency score=1.43/3, median=1), indicating few recommendations match
between the two versions. Also, only 50% top recommendations match perfectly in
the comparisons. Interestingly, ChatGPT-3.5 responses are more likely to be
complete than those from ChatGPT-4.0 (p=0.02), suggesting possible differences
in information processing and response generation between the two versions. The
findings offer insights into AI-assisted outpatient operations, while also
facilitating the exploration of potentials and limitations of LLMs in
healthcare utilization. Future research may focus on carefully optimizing LLMs
and AI integration in healthcare systems based on ergonomic and human factors
principles, precisely aligning with the specific needs of effective outpatient
triage.",2024-04-27,"Dou Liu, Ying Han, Xiandi Wang, Xiaomei Tan, Di Liu, Guangwu Qian, Kang Li, Dan Pu, Rong Yin",http://arxiv.org/pdf/2405.00728v1,cs.CL
UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration of Prompt Engineering with GPT-4V for Dermatological Diagnosis,"This paper presents our team's participation in the MEDIQA-ClinicalNLP2024
shared task B. We present a novel approach to diagnosing clinical dermatology
cases by integrating large multimodal models, specifically leveraging the
capabilities of GPT-4V under a retriever and a re-ranker framework. Our
investigation reveals that GPT-4V, when used as a retrieval agent, can
accurately retrieve the correct skin condition 85% of the time using
dermatological images and brief patient histories. Additionally, we empirically
show that Naive Chain-of-Thought (CoT) works well for retrieval while Medical
Guidelines Grounded CoT is required for accurate dermatological diagnosis.
Further, we introduce a Multi-Agent Conversation (MAC) framework and show its
superior performance and potential over the best CoT strategy. The experiments
suggest that using naive CoT for retrieval and multi-agent conversation for
critique-based diagnosis, GPT-4V can lead to an early and accurate diagnosis of
dermatological conditions. The implications of this work extend to improving
diagnostic workflows, supporting dermatological education, and enhancing
patient care by providing a scalable, accessible, and accurate diagnostic tool.",2024-04-27,"Parth Vashisht, Abhilasha Lodha, Mukta Maddipatla, Zonghai Yao, Avijit Mitra, Zhichao Yang, Junda Wang, Sunjae Kwon, Hong Yu",http://arxiv.org/pdf/2404.17749v2,cs.CL
Building a Large Japanese Web Corpus for Large Language Models,"Open Japanese large language models (LLMs) have been trained on the Japanese
portions of corpora such as CC-100, mC4, and OSCAR. However, these corpora were
not created for the quality of Japanese texts. This study builds a large
Japanese web corpus by extracting and refining text from the Common Crawl
archive (21 snapshots of approximately 63.4 billion pages crawled between 2020
and 2023). This corpus consists of approximately 312.1 billion characters
(approximately 173 million pages), which is the largest of all available
training corpora for Japanese LLMs, surpassing CC-100 (approximately 25.8
billion characters), mC4 (approximately 239.7 billion characters) and OSCAR
23.10 (approximately 74 billion characters). To confirm the quality of the
corpus, we performed continual pre-training on Llama 2 7B, 13B, 70B, Mistral 7B
v0.1, and Mixtral 8x7B Instruct as base LLMs and gained consistent (6.6-8.1
points) improvements on Japanese benchmark datasets. We also demonstrate that
the improvement on Llama 2 13B brought from the presented corpus was the
largest among those from other existing corpora.",2024-04-27,"Naoaki Okazaki, Kakeru Hattori, Hirai Shota, Hiroki Iida, Masanari Ohi, Kazuki Fujii, Taishi Nakamura, Mengsay Loem, Rio Yokota, Sakae Mizuki",http://arxiv.org/pdf/2404.17733v1,cs.CL
Bridging the Social & Technical Divide in Augmentative and Alternative Communication (AAC) Applications for Autistic Adults,"Natural Language Processing (NLP) techniques are being used more frequently
to improve high-tech Augmentative and Alternative Communication (AAC), but many
of these techniques are integrated without the inclusion of the users'
perspectives. Autistic adults are particularly neglected in the design of AAC
tools. We conducted in-depth interviews with 12 autistic adults to find the
pain points of current AAC and determine what technological advances they might
find helpful. We found that in addition to technological issues, there are many
societal issues as well. We found 9 different categories of themes from our
interviews: input flexibility, output flexibility, selecting or adapting AAC
for a good fit, when to start or swap AAC, benefits, access as an adult,
stumbling blocks for continued use, social concerns, and control of
communication. In this paper, we go through these categories in depth and then
suggest possible guidelines for developers, NLP researchers, and policy makers.",2024-04-26,"Lara J. Martin, Malathy Nagalakshmi",http://arxiv.org/pdf/2404.17730v2,cs.CL
"CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving","Large Language Models (LLMs) have shown great ability in solving traditional
natural language tasks and elementary reasoning tasks with appropriate
prompting techniques. However, their ability is still limited in solving
complicated science problems. In this work, we aim to push the upper bound of
the reasoning capability of LLMs by proposing a collaborative multi-agent,
multi-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs
to play different roles in a problem-solving team, and encourage different
role-play agents to collaboratively solve the target task. In particular, we
discover that applying different reasoning paths for different roles is an
effective strategy to implement few-shot prompting approaches in the
multi-agent scenarios. Empirical results demonstrate the effectiveness of the
proposed methods on two college-level science problems over competitive
baselines. Our further analysis shows the necessity of prompting LLMs to play
different roles or experts independently. We release the code at:
https://github.com/amazon-science/comm-prompt",2024-04-26,"Pei Chen, Boran Han, Shuai Zhang",http://arxiv.org/pdf/2404.17729v1,cs.CL
Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering,"In customer service technical support, swiftly and accurately retrieving
relevant past issues is critical for efficiently resolving customer inquiries.
The conventional retrieval methods in retrieval-augmented generation (RAG) for
large language models (LLMs) treat a large corpus of past issue tracking
tickets as plain text, ignoring the crucial intra-issue structure and
inter-issue relations, which limits performance. We introduce a novel customer
service question-answering method that amalgamates RAG with a knowledge graph
(KG). Our method constructs a KG from historical issues for use in retrieval,
retaining the intra-issue structure and inter-issue relations. During the
question-answering phase, our method parses consumer queries and retrieves
related sub-graphs from the KG to generate answers. This integration of a KG
not only improves retrieval accuracy by preserving customer service structure
information but also enhances answering quality by mitigating the effects of
text segmentation. Empirical assessments on our benchmark datasets, utilizing
key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR)
metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by
0.32 in BLEU. Our method has been deployed within LinkedIn's customer service
team for approximately six months and has reduced the median per-issue
resolution time by 28.6%.",2024-04-26,"Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, Zheng Li",http://arxiv.org/pdf/2404.17723v2,cs.CL
PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games,"We introduce WellPlay, a reasoning dataset for multi-agent conversational
inference in Murder Mystery Games (MMGs). WellPlay comprises 1,482 inferential
questions across 12 games, spanning objectives, reasoning, and relationship
understanding, and establishes a systematic benchmark for evaluating agent
reasoning abilities in complex social settings. Building on this foundation, we
present PLAYER*, a novel framework for Large Language Model (LLM)-based agents
in MMGs. MMGs pose unique challenges, including undefined state spaces, absent
intermediate rewards, and the need for strategic reasoning through natural
language. PLAYER* addresses these challenges with a sensor-based state
representation and an information-driven strategy that optimises questioning
and suspect pruning. Experiments show that PLAYER* outperforms existing methods
in reasoning accuracy, efficiency, and agent-human interaction, advancing
reasoning agents for complex social scenarios.",2024-04-26,"Qinglin Zhu, Runcong Zhao, Bin Liang, Jinhua Du, Lin Gui, Yulan He",http://arxiv.org/pdf/2404.17662v5,cs.CL
Empowering Large Language Models for Textual Data Augmentation,"With the capabilities of understanding and executing natural language
instructions, Large language models (LLMs) can potentially act as a powerful
tool for textual data augmentation. However, the quality of augmented data
depends heavily on the augmentation instructions provided, and the
effectiveness can fluctuate across different downstream tasks. While manually
crafting and selecting instructions can offer some improvement, this approach
faces scalability and consistency issues in practice due to the diversity of
downstream tasks. In this work, we address these limitations by proposing a new
solution, which can automatically generate a large pool of augmentation
instructions and select the most suitable task-informed instructions, thereby
empowering LLMs to create high-quality augmented data for different downstream
tasks. Empirically, the proposed approach consistently generates augmented data
with better quality compared to non-LLM and LLM-based data augmentation
methods, leading to the best performance on 26 few-shot learning tasks sourced
from a wide range of application domains.",2024-04-26,"Yichuan Li, Kaize Ding, Jianling Wang, Kyumin Lee",http://arxiv.org/pdf/2404.17642v1,cs.CL
Text Quality-Based Pruning for Efficient Training of Language Models,"In recent times training Language Models (LMs) have relied on computationally
heavy training over massive datasets which makes this training process
extremely laborious. In this paper we propose a novel method for numerically
evaluating text quality in large unlabelled NLP datasets in a model agnostic
manner to assign the text instances a ""quality score"".
  By proposing the text quality metric, the paper establishes a framework to
identify and eliminate low-quality text instances, leading to improved training
efficiency for LM models. Experimental results over multiple models and
datasets demonstrate the efficacy of this approach, showcasing substantial
gains in training effectiveness and highlighting the potential for
resource-efficient LM training.
  For example, we observe an absolute accuracy improvement of 0.9% averaged
over 14 downstream evaluation tasks for multiple LM models while using 40%
lesser data and training 42% faster when training on the OpenWebText dataset
and 0.8% average absolute accuracy improvement while using 20% lesser data and
training 21% faster on the Wikipedia dataset.",2024-04-26,"Vasu Sharma, Karthik Padthe, Newsha Ardalani, Kushal Tirumala, Russell Howes, Hu Xu, Po-Yao Huang, Shang-Wen Li, Armen Aghajanyan, Gargi Ghosh, Luke Zettlemoyer",http://arxiv.org/pdf/2405.01582v3,cs.CL
A Semi-Automatic Approach to Create Large Gender- and Age-Balanced Speaker Corpora: Usefulness of Speaker Diarization & Identification,"This paper presents a semi-automatic approach to create a diachronic corpus
of voices balanced for speaker's age, gender, and recording period, according
to 32 categories (2 genders, 4 age ranges and 4 recording periods). Corpora
were selected at French National Institute of Audiovisual (INA) to obtain at
least 30 speakers per category (a total of 960 speakers; only 874 have be found
yet). For each speaker, speech excerpts were extracted from audiovisual
documents using an automatic pipeline consisting of speech detection,
background music and overlapped speech removal and speaker diarization, used to
present clean speaker segments to human annotators identifying target speakers.
This pipeline proved highly effective, cutting down manual processing by a
factor of ten. Evaluation of the quality of the automatic processing and of the
final output is provided. It shows the automatic processing compare to
up-to-date process, and that the output provides high quality speech for most
of the selected excerpts. This method shows promise for creating large corpora
of known target speakers.",2024-04-26,"Rémi Uro, David Doukhan, Albert Rilliard, Laëtitia Larcher, Anissa-Claire Adgharouamane, Marie Tahon, Antoine Laurent",http://arxiv.org/pdf/2404.17552v1,cs.CL
Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo,"Numerous capability and safety techniques of Large Language Models (LLMs),
including RLHF, automated red-teaming, prompt engineering, and infilling, can
be cast as sampling from an unnormalized target distribution defined by a given
reward or potential function over the full sequence. In this work, we leverage
the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic
inference problems. In particular, we use learned twist functions to estimate
the expected future value of the potential at each timestep, which enables us
to focus inference-time computation on promising partial sequences. We propose
a novel contrastive method for learning the twist functions, and establish
connections with the rich literature of soft reinforcement learning. As a
complementary application of our twisted SMC framework, we present methods for
evaluating the accuracy of language model inference techniques using novel
bidirectional SMC bounds on the log partition function. These bounds can be
used to estimate the KL divergence between the inference and target
distributions in both directions. We apply our inference evaluation techniques
to show that twisted SMC is effective for sampling undesirable outputs from a
pretrained model (a useful component of harmlessness training and automated
red-teaming), generating reviews with varied sentiment, and performing
infilling tasks.",2024-04-26,"Stephen Zhao, Rob Brekelmans, Alireza Makhzani, Roger Grosse",http://arxiv.org/pdf/2404.17546v1,cs.CL
The Mercurial Top-Level Ontology of Large Language Models,"In our work, we systematize and analyze implicit ontological commitments in
the responses generated by large language models (LLMs), focusing on ChatGPT
3.5 as a case study. We investigate how LLMs, despite having no explicit
ontology, exhibit implicit ontological categorizations that are reflected in
the texts they generate. The paper proposes an approach to understanding the
ontological commitments of LLMs by defining ontology as a theory that provides
a systematic account of the ontological commitments of some text. We
investigate the ontological assumptions of ChatGPT and present a systematized
account, i.e., GPT's top-level ontology. This includes a taxonomy, which is
available as an OWL file, as well as a discussion about ontological assumptions
(e.g., about its mereology or presentism). We show that in some aspects GPT's
top-level ontology is quite similar to existing top-level ontologies. However,
there are significant challenges arising from the flexible nature of
LLM-generated texts, including ontological overload, ambiguity, and
inconsistency.",2024-04-26,"Nele Köhler, Fabian Neuhaus",http://arxiv.org/pdf/2405.01581v1,cs.CL
Large Language Model Agent as a Mechanical Designer,"Conventional mechanical design follows an iterative process in which initial
concepts are refined through cycles of expert assessment and resource-intensive
Finite Element Method (FEM) analysis to meet performance goals. While machine
learning models have been developed to assist in parts of this process, they
typically require large datasets, extensive training, and are often tailored to
specific tasks, limiting their generalizability. To address these limitations,
we propose a framework that leverages a pretrained Large Language Model (LLM)
in conjunction with an FEM module to autonomously generate, evaluate, and
refine structural designs based on performance specifications and numerical
feedback. The LLM operates without domain-specific fine-tuning, using general
reasoning to propose design candidates, interpret FEM-derived performance
metrics, and apply structurally sound modifications. Using 2D truss structures
as a testbed, we show that the LLM can effectively navigate highly discrete and
multi-faceted design spaces, balance competing objectives, and identify
convergence when further optimization yields diminishing returns. Compared to
Non-dominated Sorting Genetic Algorithm II (NSGA-II), our method achieves
faster convergence and fewer FEM evaluations. Experiments with varying
temperature settings (0.5, 1.0, 1.2) and model sizes (GPT-4.1 and GPT-4.1-mini)
indicate that smaller models yield higher constraint satisfaction with fewer
steps, while lower temperatures enhance design consistency. These results
establish LLMs as a promising new class of reasoning-based, natural
language-driven optimizers for autonomous design and iterative structural
refinement.",2024-04-26,"Yayati Jadhav, Amir Barati Farimani",http://arxiv.org/pdf/2404.17525v3,cs.CL
On the Use of Large Language Models to Generate Capability Ontologies,"Capability ontologies are increasingly used to model functionalities of
systems or machines. The creation of such ontological models with all
properties and constraints of capabilities is very complex and can only be done
by ontology experts. However, Large Language Models (LLMs) have shown that they
can generate machine-interpretable models from natural language text input and
thus support engineers / ontology experts. Therefore, this paper investigates
how LLMs can be used to create capability ontologies. We present a study with a
series of experiments in which capabilities with varying complexities are
generated using different prompting techniques and with different LLMs. Errors
in the generated ontologies are recorded and compared. To analyze the quality
of the generated ontologies, a semi-automated approach based on RDF syntax
checking, OWL reasoning, and SHACL constraints is used. The results of this
study are very promising because even for complex capabilities, the generated
ontologies are almost free of errors.",2024-04-26,"Luis Miguel Vieira da Silva, Aljosha Köcher, Felix Gehlhoff, Alexander Fay",http://arxiv.org/pdf/2404.17524v4,cs.CL
A Comprehensive Evaluation on Event Reasoning of Large Language Models,"Event reasoning is a fundamental ability that underlies many applications. It
requires event schema knowledge to perform global reasoning and needs to deal
with the diversity of the inter-event relations and the reasoning paradigms.
How well LLMs accomplish event reasoning on various relations and reasoning
paradigms remains unknown. To mitigate this disparity, we comprehensively
evaluate the abilities of event reasoning of LLMs. We introduce a novel
benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of
evaluation of schema and instance and is comprehensive in relations and
reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs
have abilities to accomplish event reasoning but their performances are far
from satisfactory. We also notice the imbalance of event reasoning abilities in
LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned
with humans on how to utilize the knowledge. Based on these findings, we guide
the LLMs in utilizing the event schema knowledge as memory leading to
improvements on event reasoning.",2024-04-26,"Zhengwei Tao, Zhi Jin, Yifan Zhang, Xiancai Chen, Haiyan Zhao, Jia Li, Bing Liang, Chongyang Tao, Qun Liu, Kam-Fai Wong",http://arxiv.org/pdf/2404.17513v2,cs.CL
ReproHum #0087-01: Human Evaluation Reproduction Report for Generating Fact Checking Explanations,"This paper presents a partial reproduction of Generating Fact Checking
Explanations by Anatanasova et al (2020) as part of the ReproHum element of the
ReproNLP shared task to reproduce the findings of NLP research regarding human
evaluation. This shared task aims to investigate the extent to which NLP as a
field is becoming more or less reproducible over time. Following the
instructions provided by the task organisers and the original authors, we
collect relative rankings of 3 fact-checking explanations (comprising a gold
standard and the outputs of 2 models) for 40 inputs on the criteria of
Coverage. The results of our reproduction and reanalysis of the original work's
raw results lend support to the original findings, with similar patterns seen
between the original work and our reproduction. Whilst we observe slight
variation from the original results, our findings support the main conclusions
drawn by the original authors pertaining to the efficacy of their proposed
models.",2024-04-26,"Tyler Loakman, Chenghua Lin",http://arxiv.org/pdf/2404.17481v2,cs.CL
CEval: A Benchmark for Evaluating Counterfactual Text Generation,"Counterfactual text generation aims to minimally change a text, such that it
is classified differently. Judging advancements in method development for
counterfactual text generation is hindered by a non-uniform usage of data sets
and metrics in related work. We propose CEval, a benchmark for comparing
counterfactual text generation methods. CEval unifies counterfactual and text
quality metrics, includes common counterfactual datasets with human
annotations, standard baselines (MICE, GDBA, CREST) and the open-source
language model LLAMA-2. Our experiments found no perfect method for generating
counterfactual text. Methods that excel at counterfactual metrics often produce
lower-quality text while LLMs with simple prompts generate high-quality text
but struggle with counterfactual criteria. By making CEval available as an
open-source Python library, we encourage the community to contribute more
methods and maintain consistent evaluation in future work.",2024-04-26,"Van Bach Nguyen, Jörg Schlötterer, Christin Seifert",http://arxiv.org/pdf/2404.17475v2,cs.CL
Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System,"Conversational tutoring systems (CTSs) offer learning experiences through
interactions based on natural language. They are recognized for promoting
cognitive engagement and improving learning outcomes, especially in reasoning
tasks. Nonetheless, the cost associated with authoring CTS content is a major
obstacle to widespread adoption and to research on effective instructional
design. In this paper, we discuss and evaluate a novel type of CTS that
leverages recent advances in large language models (LLMs) in two ways: First,
the system enables AI-assisted content authoring by inducing an easily editable
tutoring script automatically from a lesson text. Second, the system automates
the script orchestration in a learning-by-teaching format via two LLM-based
agents (Ruffle&Riley) acting as a student and a professor. The system allows
for free-form conversations that follow the ITS-typical inner and outer loop
structure. We evaluate Ruffle&Riley's ability to support biology lessons in two
between-subject online user studies (N = 200) comparing the system to simpler
QA chatbots and reading activity. Analyzing system usage patterns,
pre/post-test scores and user experience surveys, we find that Ruffle&Riley
users report high levels of engagement, understanding and perceive the offered
support as helpful. Even though Ruffle&Riley users require more time to
complete the activity, we did not find significant differences in short-term
learning gains over the reading activity. Our system architecture and user
study provide various insights for designers of future CTSs. We further
open-source our system to support ongoing research on effective instructional
design of LLM-based learning technologies.",2024-04-26,"Robin Schmucker, Meng Xia, Amos Azaria, Tom Mitchell",http://arxiv.org/pdf/2404.17460v1,cs.CL
Language Interaction Network for Clinical Trial Approval Estimation,"Clinical trial outcome prediction seeks to estimate the likelihood that a
clinical trial will successfully reach its intended endpoint. This process
predominantly involves the development of machine learning models that utilize
a variety of data sources such as descriptions of the clinical trials,
characteristics of the drug molecules, and specific disease conditions being
targeted. Accurate predictions of trial outcomes are crucial for optimizing
trial planning and prioritizing investments in a drug portfolio. While previous
research has largely concentrated on small-molecule drugs, there is a growing
need to focus on biologics-a rapidly expanding category of therapeutic agents
that often lack the well-defined molecular properties associated with
traditional drugs. Additionally, applying conventional methods like graph
neural networks to biologics data proves challenging due to their complex
nature. To address these challenges, we introduce the Language Interaction
Network (LINT), a novel approach that predicts trial outcomes using only the
free-text descriptions of the trials. We have rigorously tested the
effectiveness of LINT across three phases of clinical trials, where it achieved
ROC-AUC scores of 0.770, 0.740, and 0.748 for phases I, II, and III,
respectively, specifically concerning trials involving biologic interventions.",2024-04-26,"Chufan Gao, Tianfan Fu, Jimeng Sun",http://arxiv.org/pdf/2405.06662v1,cs.CL
Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations,"Language models now constitute essential tools for improving efficiency for
many professional tasks such as writing, coding, or learning. For this reason,
it is imperative to identify inherent biases. In the field of Natural Language
Processing, five sources of bias are well-identified: data, annotation,
representation, models, and research design. This study focuses on biases
related to geographical knowledge. We explore the connection between geography
and language models by highlighting their tendency to misrepresent spatial
information, thus leading to distortions in the representation of geographical
distances. This study introduces four indicators to assess these distortions,
by comparing geographical and semantic distances. Experiments are conducted
from these four indicators with ten widely used language models. Results
underscore the critical necessity of inspecting and rectifying spatial biases
in language models to ensure accurate and equitable representations.",2024-04-26,"Rémy Decoupes, Roberto Interdonato, Mathieu Roche, Maguelonne Teisseire, Sarah Valentin",http://arxiv.org/pdf/2404.17401v1,cs.CL
Child Speech Recognition in Human-Robot Interaction: Problem Solved?,"Automated Speech Recognition shows superhuman performance for adult English
speech on a range of benchmarks, but disappoints when fed children's speech.
This has long sat in the way of child-robot interaction. Recent evolutions in
data-driven speech recognition, including the availability of Transformer
architectures and unprecedented volumes of training data, might mean a
breakthrough for child speech recognition and social robot applications aimed
at children. We revisit a study on child speech recognition from 2017 and show
that indeed performance has increased, with newcomer OpenAI Whisper doing
markedly better than leading commercial cloud services. Performance improves
even more in highly structured interactions when priming models with specific
phrases. While transcription is not perfect yet, the best model recognises
60.3% of sentences correctly barring small grammatical differences, with
sub-second transcription time running on a local GPU, showing potential for
usable autonomous child-robot speech interactions.",2024-04-26,"Ruben Janssens, Eva Verhelst, Giulio Antonio Abbo, Qiaoqiao Ren, Maria Jose Pinto Bernal, Tony Belpaeme",http://arxiv.org/pdf/2404.17394v2,cs.CL
LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study,"As NLP models become more complex, understanding their decisions becomes more
crucial. Counterfactuals (CFs), where minimal changes to inputs flip a model's
prediction, offer a way to explain these models. While Large Language Models
(LLMs) have shown remarkable performance in NLP tasks, their efficacy in
generating high-quality CFs remains uncertain. This work fills this gap by
investigating how well LLMs generate CFs for two NLU tasks. We conduct a
comprehensive comparison of several common LLMs, and evaluate their CFs,
assessing both intrinsic metrics, and the impact of these CFs on data
augmentation. Moreover, we analyze differences between human and LLM-generated
CFs, providing insights for future research directions. Our results show that
LLMs generate fluent CFs, but struggle to keep the induced changes minimal.
Generating CFs for Sentiment Analysis (SA) is less challenging than NLI where
LLMs show weaknesses in generating CFs that flip the original label. This also
reflects on the data augmentation performance, where we observe a large gap
between augmenting with human and LLMs CFs. Furthermore, we evaluate LLMs'
ability to assess CFs in a mislabelled data setting, and show that they have a
strong bias towards agreeing with the provided labels. GPT4 is more robust
against this bias and its scores correlate well with automatic metrics. Our
findings reveal several limitations and point to potential future work
directions.",2024-04-26,"Van Bach Nguyen, Paul Youssef, Christin Seifert, Jörg Schlötterer",http://arxiv.org/pdf/2405.00722v2,cs.CL
A Bionic Natural Language Parser Equivalent to a Pushdown Automaton,"Assembly Calculus (AC), proposed by Papadimitriou et al., aims to reproduce
advanced cognitive functions through simulating neural activities, with several
applications based on AC having been developed, including a natural language
parser proposed by Mitropolsky et al. However, this parser lacks the ability to
handle Kleene closures, preventing it from parsing all regular languages and
rendering it weaker than Finite Automata (FA). In this paper, we propose a new
bionic natural language parser (BNLP) based on AC and integrates two new
biologically rational structures, Recurrent Circuit and Stack Circuit which are
inspired by RNN and short-term memory mechanism. In contrast to the original
parser, the BNLP can fully handle all regular languages and Dyck languages.
Therefore, leveraging the Chomsky-Sch \H{u}tzenberger theorem, the BNLP which
can parse all Context-Free Languages can be constructed. We also formally prove
that for any PDA, a Parser Automaton corresponding to BNLP can always be
formed, ensuring that BNLP has a description ability equal to that of PDA and
addressing the deficiencies of the original parser.",2024-04-26,"Zhenghao Wei, Kehua Lin, Jianlin Feng",http://arxiv.org/pdf/2404.17343v1,cs.CL
From Multiple-Choice to Extractive QA: A Case Study for English and Arabic,"The rapid evolution of Natural Language Processing (NLP) has favoured major
languages such as English, leaving a significant gap for many others due to
limited resources. This is especially evident in the context of data
annotation, a task whose importance cannot be underestimated, but which is
time-consuming and costly. Thus, any dataset for resource-poor languages is
precious, in particular when it is task-specific. Here, we explore the
feasibility of repurposing an existing multilingual dataset for a new NLP task:
we repurpose a subset of the BELEBELE dataset (Bandarkar et al., 2023), which
was designed for multiple-choice question answering (MCQA), to enable the more
practical task of extractive QA (EQA) in the style of machine reading
comprehension. We present annotation guidelines and a parallel EQA dataset for
English and Modern Standard Arabic (MSA). We also present QA evaluation results
for several monolingual and cross-lingual QA pairs including English, MSA, and
five Arabic dialects. We aim to help others adapt our approach for the
remaining 120 BELEBELE language variants, many of which are deemed
under-resourced. We also provide a thorough analysis and share insights to
deepen understanding of the challenges and opportunities in NLP task
reformulation.",2024-04-26,"Teresa Lynn, Malik H. Altakrori, Samar Mohamed Magdy, Rocktim Jyoti Das, Chenyang Lyu, Mohamed Nasr, Younes Samih, Kirill Chirkunov, Alham Fikri Aji, Preslav Nakov, Shantanu Godbole, Salim Roukos, Radu Florian, Nizar Habash",http://arxiv.org/pdf/2404.17342v2,cs.CL
Metronome: tracing variation in poetic meters via local sequence alignment,"All poetic forms come from somewhere. Prosodic templates can be copied for
generations, altered by individuals, imported from foreign traditions, or
fundamentally changed under the pressures of language evolution. Yet these
relationships are notoriously difficult to trace across languages and times.
This paper introduces an unsupervised method for detecting structural
similarities in poems using local sequence alignment. The method relies on
encoding poetic texts as strings of prosodic features using a four-letter
alphabet; these sequences are then aligned to derive a distance measure based
on weighted symbol (mis)matches. Local alignment allows poems to be clustered
according to emergent properties of their underlying prosodic patterns. We
evaluate method performance on a meter recognition tasks against strong
baselines and show its potential for cross-lingual and historical research
using three short case studies: 1) mutations in quantitative meter in classical
Latin, 2) European diffusion of the Renaissance hendecasyllable, and 3)
comparative alignment of modern meters in 18--19th century Czech, German and
Russian. We release an implementation of the algorithm as a Python package with
an open license.",2024-04-26,"Ben Nagy, Artjoms Šeļa, Mirella De Sisto, Petr Plecháč",http://arxiv.org/pdf/2404.17337v1,cs.CL
Introducing cosmosGPT: Monolingual Training for Turkish Language Models,"The number of open source language models that can produce Turkish is
increasing day by day, as in other languages. In order to create the basic
versions of such models, the training of multilingual models is usually
continued with Turkish corpora. The alternative is to train the model with only
Turkish corpora. In this study, we first introduce the cosmosGPT models that we
created with this alternative method. Then, we introduce new finetune datasets
for basic language models to fulfill user requests and new evaluation datasets
for measuring the capabilities of Turkish language models. Finally, a
comprehensive comparison of the adapted Turkish language models on different
capabilities is presented. The results show that the language models we built
with the monolingual corpus have promising performance despite being about 10
times smaller than the others.",2024-04-26,"H. Toprak Kesgin, M. Kaan Yuce, Eren Dogan, M. Egemen Uzun, Atahan Uz, H. Emre Seyrek, Ahmed Zeer, M. Fatih Amasyali",http://arxiv.org/pdf/2404.17336v1,cs.CL
Speech Technology Services for Oral History Research,"Oral history is about oral sources of witnesses and commentors on historical
events. Speech technology is an important instrument to process such recordings
in order to obtain transcription and further enhancements to structure the oral
account In this contribution we address the transcription portal and the
webservices associated with speech processing at BAS, speech solutions
developed at LINDAT, how to do it yourself with Whisper, remaining challenges,
and future developments.",2024-04-26,"Christoph Draxler, Henk van den Heuvel, Arjan van Hessen, Pavel Ircing, Jan Lehečka",http://arxiv.org/pdf/2405.02333v1,cs.CL
When to Trust LLMs: Aligning Confidence with Response Quality,"Despite the success of large language models (LLMs) in natural language
generation, much evidence shows that LLMs may produce incorrect or nonsensical
text. This limitation highlights the importance of discerning when to trust
LLMs, especially in safety-critical domains. Existing methods often express
reliability by confidence level, however, their effectiveness is limited by the
lack of objective guidance. To address this, we propose
CONfidence-Quality-ORDer-preserving alignment approach (CONQORD), which
leverages reinforcement learning guided by a tailored dual-component reward
function. This function integrates quality reward and order-preserving
alignment reward functions. Specifically, the order-preserving reward
incentivizes the model to verbalize greater confidence for responses of higher
quality to align the order of confidence and quality. Experiments demonstrate
that CONQORD significantly improves the alignment performance between
confidence and response accuracy, without causing over-cautious. Furthermore,
the aligned confidence provided by CONQORD informs when to trust LLMs, and acts
as a determinant for initiating the retrieval process of external knowledge.
Aligning confidence with response quality ensures more transparent and reliable
responses, providing better trustworthiness.",2024-04-26,"Shuchang Tao, Liuyi Yao, Hanxing Ding, Yuexiang Xie, Qi Cao, Fei Sun, Jinyang Gao, Huawei Shen, Bolin Ding",http://arxiv.org/pdf/2404.17287v3,cs.CL
Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM,"Retrieval-augmented language models have exhibited promising performance
across various areas of natural language processing (NLP), including
fact-critical tasks. However, due to the black-box nature of advanced large
language models (LLMs) and the non-retrieval-oriented supervision signal of
specific tasks, the training of retrieval model faces significant challenges
under the setting of black-box LLM. We propose an approach leveraging
Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance
fact-checking on news claims by using black-box LLM. FFRR adopts a two-level
strategy to gather fine-grained feedback from the LLM, which serves as a reward
for optimizing the retrieval policy, by rating the retrieved documents based on
the non-retrieval ground truth of the task. We evaluate our model on two public
datasets for real-world news claim verification, and the results demonstrate
that FFRR achieves significant improvements over strong LLM-enabled and non-LLM
baselines.",2024-04-26,"Xuan Zhang, Wei Gao",http://arxiv.org/pdf/2404.17283v1,cs.CL
Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes,"Dual process theory posits that human cognition arises via two systems.
System 1, which is a quick, emotional, and intuitive process, which is subject
to cognitive biases, and System 2, is a slow, onerous, and deliberate process.
NLP researchers often compare zero-shot prompting in LLMs to System 1 reasoning
and chain-of-thought (CoT) prompting to System 2. In line with this
interpretation, prior research has found that using CoT prompting in LLMs leads
to reduced gender bias. We investigate the relationship between bias, CoT
prompting, a debiasing prompt, and dual process theory in LLMs directly. We
compare zero-shot CoT, debiasing, and a variety of dual process theory-based
prompting strategies on two bias datasets spanning nine different social bias
categories. We incorporate human and machine personas to determine whether the
effects of dual process theory in LLMs exist independent of explicit persona
models or are based on modeling human cognition. We find that a human persona,
debiasing, System 2, and CoT prompting all tend to reduce social biases in
LLMs, though the best combination of features depends on the exact model and
bias category -- resulting in up to a 19 percent drop in stereotypical
judgments by an LLM.",2024-04-26,"Mahammed Kamruzzaman, Gene Louis Kim",http://arxiv.org/pdf/2404.17218v3,cs.CL
Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot,"Many multilingual communities, including numerous in Africa, frequently
engage in code-switching during conversations. This behaviour stresses the need
for natural language processing technologies adept at processing code-switched
text. However, data scarcity, particularly in African languages, poses a
significant challenge, as many are low-resourced and under-represented. In this
study, we prompted GPT 3.5 to generate Afrikaans--English and Yoruba--English
code-switched sentences, enhancing diversity using topic-keyword pairs,
linguistic guidelines, and few-shot examples. Our findings indicate that the
quality of generated sentences for languages using non-Latin scripts, like
Yoruba, is considerably lower when compared with the high Afrikaans-English
success rate. There is therefore a notable opportunity to refine prompting
guidelines to yield sentences suitable for the fine-tuning of language models.
We propose a framework for augmenting the diversity of synthetically generated
code-switched data using GPT and propose leveraging this technology to mitigate
data scarcity in low-resourced languages, underscoring the essential role of
native speakers in this process.",2024-04-26,"Michelle Terblanche, Kayode Olaleye, Vukosi Marivate",http://arxiv.org/pdf/2404.17216v1,cs.CL
TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya,"The absence of explicitly tailored, accessible annotated datasets for
educational purposes presents a notable obstacle for NLP tasks in languages
with limited resources.This study initially explores the feasibility of using
machine translation (MT) to convert an existing dataset into a Tigrinya dataset
in SQuAD format. As a result, we present TIGQA, an expert annotated educational
dataset consisting of 2.68K question-answer pairs covering 122 diverse topics
such as climate, water, and traffic. These pairs are from 537 context
paragraphs in publicly accessible Tigrinya and Biology books. Through
comprehensive analyses, we demonstrate that the TIGQA dataset requires skills
beyond simple word matching, requiring both single-sentence and
multiple-sentence inference abilities. We conduct experiments using
state-of-the art MRC methods, marking the first exploration of such models on
TIGQA. Additionally, we estimate human performance on the dataset and juxtapose
it with the results obtained from pretrained models.The notable disparities
between human performance and best model performance underscore the potential
for further enhancements to TIGQA through continued research. Our dataset is
freely accessible via the provided link to encourage the research community to
address the challenges in the Tigrinya MRC.",2024-04-26,"Hailay Teklehaymanot, Dren Fazlija, Niloy Ganguly, Gourab K. Patro, Wolfgang Nejdl",http://arxiv.org/pdf/2404.17194v1,cs.CL
Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study,"Social anxiety represents a prevalent challenge in modern society, affecting
individuals across personal and professional spheres. Left unaddressed, this
condition can yield substantial negative consequences, impacting social
interactions and performance. Further understanding its diverse physical and
emotional symptoms becomes pivotal for comprehensive diagnosis and tailored
therapeutic interventions. This study analyze prevalence and frequency of
social anxiety symptoms taken from Mayo Clinic, exploring diverse human
experiences from utilizing a large Reddit dataset dedicated to this issue.
Leveraging these platforms, the research aims to extract insights and examine a
spectrum of physical and emotional symptoms linked to social anxiety disorder.
Upholding ethical considerations, the study maintains strict user anonymity
within the dataset. By employing a novel approach, the research utilizes
BART-based multi-label zero-shot classification to identify and measure symptom
prevalence and significance in the form of probability score for each symptom
under consideration. Results uncover distinctive patterns: ""Trembling"" emerges
as a prevalent physical symptom, while emotional symptoms like ""Fear of being
judged negatively"" exhibit high frequencies. These findings offer insights into
the multifaceted nature of social anxiety, aiding clinical practices and
interventions tailored to its diverse expressions.",2024-04-26,"Muhammad Rizwan, Jure Demšar",http://arxiv.org/pdf/2404.17183v1,cs.CL
A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named Entity Recognition,"Few-shot Named Entity Recognition (NER) aims to extract named entities using
only a limited number of labeled examples. Existing contrastive learning
methods often suffer from insufficient distinguishability in context vector
representation because they either solely rely on label semantics or completely
disregard them. To tackle this issue, we propose a unified label-aware
token-level contrastive learning framework. Our approach enriches the context
by utilizing label semantics as suffix prompts. Additionally, it simultaneously
optimizes context-context and context-label contrastive learning objectives to
enhance generalized discriminative contextual representations.Extensive
experiments on various traditional test domains (OntoNotes, CoNLL'03, WNUT'17,
GUM, I2B2) and the large-scale few-shot NER dataset (FEWNERD) demonstrate the
effectiveness of our approach. It outperforms prior state-of-the-art models by
a significant margin, achieving an average absolute gain of 7% in micro F1
scores across most scenarios. Further analysis reveals that our model benefits
from its powerful transfer capability and improved contextual representations.",2024-04-26,"Haojie Zhang, Yimeng Zhuang",http://arxiv.org/pdf/2404.17178v2,cs.CL
HateTinyLLM : Hate Speech Detection Using Tiny Large Language Models,"Hate speech encompasses verbal, written, or behavioral communication that
targets derogatory or discriminatory language against individuals or groups
based on sensitive characteristics. Automated hate speech detection plays a
crucial role in curbing its propagation, especially across social media
platforms. Various methods, including recent advancements in deep learning,
have been devised to address this challenge. In this study, we introduce
HateTinyLLM, a novel framework based on fine-tuned decoder-only tiny large
language models (tinyLLMs) for efficient hate speech detection. Our
experimental findings demonstrate that the fine-tuned HateTinyLLM outperforms
the pretrained mixtral-7b model by a significant margin. We explored various
tiny LLMs, including PY007/TinyLlama-1.1B-step-50K-105b, Microsoft/phi-2, and
facebook/opt-1.3b, and fine-tuned them using LoRA and adapter methods. Our
observations indicate that all LoRA-based fine-tuned models achieved over 80\%
accuracy.",2024-04-26,"Tanmay Sen, Ansuman Das, Mrinmay Sen",http://arxiv.org/pdf/2405.01577v1,cs.CL
Quantifying Memorization and Detecting Training Data of Pre-trained Language Models using Japanese Newspaper,"Dominant pre-trained language models (PLMs) have demonstrated the potential
risk of memorizing and outputting the training data. While this concern has
been discussed mainly in English, it is also practically important to focus on
domain-specific PLMs. In this study, we pre-trained domain-specific GPT-2
models using a limited corpus of Japanese newspaper articles and evaluated
their behavior. Experiments replicated the empirical finding that memorization
of PLMs is related to the duplication in the training data, model size, and
prompt length, in Japanese the same as in previous English studies.
Furthermore, we attempted membership inference attacks, demonstrating that the
training data can be detected even in Japanese, which is the same trend as in
English. The study warns that domain-specific PLMs, sometimes trained with
valuable private data, can ''copy and paste'' on a large scale.",2024-04-26,"Shotaro Ishihara, Hiromu Takahashi",http://arxiv.org/pdf/2404.17143v2,cs.CL
Small Language Models Need Strong Verifiers to Self-Correct Reasoning,"Self-correction has emerged as a promising solution to boost the reasoning
performance of large language models (LLMs), where LLMs refine their solutions
using self-generated critiques that pinpoint the errors. This work explores
whether small (<= 13B) language models (LMs) have the ability of
self-correction on reasoning tasks with minimal inputs from stronger LMs. We
propose a novel pipeline that prompts smaller LMs to collect self-correction
data that supports the training of self-refinement abilities. First, we
leverage correct solutions to guide the model in critiquing their incorrect
responses. Second, the generated critiques, after filtering, are used for
supervised fine-tuning of the self-correcting reasoner through solution
refinement. Our experimental results show improved self-correction abilities of
two models on five datasets spanning math and commonsense reasoning, with
notable performance gains when paired with a strong GPT-4-based verifier,
though limitations are identified when using a weak self-verifier for
determining when to correct.",2024-04-26,"Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang",http://arxiv.org/pdf/2404.17140v2,cs.CL
Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study,"The Natural Language to Visualization (NL2Vis) task aims to transform
natural-language descriptions into visual representations for a grounded table,
enabling users to gain insights from vast amounts of data. Recently, many deep
learning-based approaches have been developed for NL2Vis. Despite the
considerable efforts made by these approaches, challenges persist in
visualizing data sourced from unseen databases or spanning multiple tables.
Taking inspiration from the remarkable generation capabilities of Large
Language Models (LLMs), this paper conducts an empirical study to evaluate
their potential in generating visualizations, and explore the effectiveness of
in-context learning prompts for enhancing this task. In particular, we first
explore the ways of transforming structured tabular data into sequential text
prompts, as to feed them into LLMs and analyze which table content contributes
most to the NL2Vis. Our findings suggest that transforming structured tabular
data into programs is effective, and it is essential to consider the table
schema when formulating prompts. Furthermore, we evaluate two types of LLMs:
finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5),
against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench).
The experimental results reveal that LLMs outperform baselines, with
inference-only models consistently exhibiting performance improvements, at
times even surpassing fine-tuned models when provided with certain few-shot
demonstrations through in-context learning. Finally, we analyze when the LLMs
fail in NL2Vis, and propose to iteratively update the results using strategies
such as chain-of-thought, role-playing, and code-interpreter. The experimental
results confirm the efficacy of iterative updates and hold great potential for
future study.",2024-04-26,"Yang Wu, Yao Wan, Hongyu Zhang, Yulei Sui, Wucai Wei, Wei Zhao, Guandong Xu, Hai Jin",http://arxiv.org/pdf/2404.17136v1,cs.CL
Text Sentiment Analysis and Classification Based on Bidirectional Gated Recurrent Units (GRUs) Model,"This paper explores the importance of text sentiment analysis and
classification in the field of natural language processing, and proposes a new
approach to sentiment analysis and classification based on the bidirectional
gated recurrent units (GRUs) model. The study firstly analyses the word cloud
model of the text with six sentiment labels, and then carries out data
preprocessing, including the steps of removing special symbols, punctuation
marks, numbers, stop words and non-alphabetic parts. Subsequently, the data set
is divided into training set and test set, and through model training and
testing, it is found that the accuracy of the validation set is increased from
85% to 93% with training, which is an increase of 8%; at the same time, the
loss value of the validation set decreases from 0.7 to 0.1 and tends to be
stable, and the model is gradually close to the actual value, which can
effectively classify the text emotions. The confusion matrix shows that the
accuracy of the model on the test set reaches 94.8%, the precision is 95.9%,
the recall is 99.1%, and the F1 score is 97.4%, which proves that the model has
good generalisation ability and classification effect. Overall, the study
demonstrated an effective method for text sentiment analysis and classification
with satisfactory results.",2024-04-26,"Wei Xu, Jianlong Chen, Zhicheng Ding, Jinyin Wang",http://arxiv.org/pdf/2404.17123v2,cs.CL
2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion,"Named entity recognition (NER) is a fundamental task in natural language
processing that involves identifying and classifying entities in sentences into
pre-defined types. It plays a crucial role in various research fields,
including entity linking, question answering, and online product
recommendation. Recent studies have shown that incorporating multilingual and
multimodal datasets can enhance the effectiveness of NER. This is due to
language transfer learning and the presence of shared implicit features across
different modalities. However, the lack of a dataset that combines
multilingualism and multimodality has hindered research exploring the
combination of these two aspects, as multimodality can help NER in multiple
languages simultaneously. In this paper, we aim to address a more challenging
task: multilingual and multimodal named entity recognition (MMNER), considering
its potential value and influence. Specifically, we construct a large-scale
MMNER dataset with four languages (English, French, German and Spanish) and two
modalities (text and image). To tackle this challenging MMNER task on the
dataset, we introduce a new model called 2M-NER, which aligns the text and
image representations using contrastive learning and integrates a multimodal
collaboration module to effectively depict the interactions between the two
modalities. Extensive experimental results demonstrate that our model achieves
the highest F1 score in multilingual and multimodal NER tasks compared to some
comparative and representative baselines. Additionally, in a challenging
analysis, we discovered that sentence-level alignment interferes a lot with NER
models, indicating the higher level of difficulty in our dataset.",2024-04-26,"Dongsheng Wang, Xiaoqin Feng, Zeming Liu, Chuan Wang",http://arxiv.org/pdf/2404.17122v1,cs.CL
Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs,"Large language models (LLMs) exhibit excellent ability to understand human
languages, but do they also understand their own language that appears
gibberish to us? In this work we delve into this question, aiming to uncover
the mechanisms underlying such behavior in LLMs. We employ the Greedy
Coordinate Gradient optimizer to craft prompts that compel LLMs to generate
coherent responses from seemingly nonsensical inputs. We call these inputs LM
Babel and this work systematically studies the behavior of LLMs manipulated by
these prompts. We find that the manipulation efficiency depends on the target
text's length and perplexity, with the Babel prompts often located in lower
loss minima compared to natural prompts. We further examine the structure of
the Babel prompts and evaluate their robustness. Notably, we find that guiding
the model to generate harmful texts is not more difficult than into generating
benign texts, suggesting lack of alignment for out-of-distribution prompts.",2024-04-26,"Valeriia Cherepanova, James Zou",http://arxiv.org/pdf/2404.17120v2,cs.CL
CoSD: Collaborative Stance Detection with Contrastive Heterogeneous Topic Graph Learning,"Stance detection seeks to identify the viewpoints of individuals either in
favor or against a given target or a controversial topic. Current advanced
neural models for stance detection typically employ fully parametric softmax
classifiers. However, these methods suffer from several limitations, including
lack of explainability, insensitivity to the latent data structure, and
unimodality, which greatly restrict their performance and applications. To
address these challenges, we present a novel collaborative stance detection
framework called (CoSD) which leverages contrastive heterogeneous topic graph
learning to learn topic-aware semantics and collaborative signals among texts,
topics, and stance labels for enhancing stance detection. During training, we
construct a heterogeneous graph to structurally organize texts and stances
through implicit topics via employing latent Dirichlet allocation. We then
perform contrastive graph learning to learn heterogeneous node representations,
aggregating informative multi-hop collaborative signals via an elaborate
Collaboration Propagation Aggregation (CPA) module. During inference, we
introduce a hybrid similarity scoring module to enable the comprehensive
incorporation of topic-aware semantics and collaborative signals for stance
detection. Extensive experiments on two benchmark datasets demonstrate the
state-of-the-art detection performance of CoSD, verifying the effectiveness and
explainability of our collaborative framework.",2024-04-26,"Yinghan Cheng, Qi Zhang, Chongyang Shi, Liang Xiao, Shufeng Hao, Liang Hu",http://arxiv.org/pdf/2404.17609v2,cs.CL
Player-Driven Emergence in LLM-Driven Game Narrative,"We explore how interaction with large language models (LLMs) can give rise to
emergent behaviors, empowering players to participate in the evolution of game
narratives. Our testbed is a text-adventure game in which players attempt to
solve a mystery under a fixed narrative premise, but can freely interact with
non-player characters generated by GPT-4, a large language model. We recruit 28
gamers to play the game and use GPT-4 to automatically convert the game logs
into a node-graph representing the narrative in the player's gameplay. We find
that through their interactions with the non-deterministic behavior of the LLM,
players are able to discover interesting new emergent nodes that were not a
part of the original narrative but have potential for being fun and engaging.
Players that created the most emergent nodes tended to be those that often
enjoy games that facilitate discovery, exploration and experimentation.",2024-04-25,"Xiangyu Peng, Jessica Quaye, Sudha Rao, Weijia Xu, Portia Botchway, Chris Brockett, Nebojsa Jojic, Gabriel DesGarennes, Ken Lobb, Michael Xu, Jorge Leandro, Claire Jin, Bill Dolan",http://arxiv.org/pdf/2404.17027v3,cs.CL
Türkçe Dil Modellerinin Performans Karşılaştırması Performance Comparison of Turkish Language Models,"The developments that language models have provided in fulfilling almost all
kinds of tasks have attracted the attention of not only researchers but also
the society and have enabled them to become products. There are commercially
successful language models available. However, users may prefer open-source
language models due to cost, data privacy, or regulations. Yet, despite the
increasing number of these models, there is no comprehensive comparison of
their performance for Turkish. This study aims to fill this gap in the
literature. A comparison is made among seven selected language models based on
their contextual learning and question-answering abilities. Turkish datasets
for contextual learning and question-answering were prepared, and both
automatic and human evaluations were conducted. The results show that for
question-answering, continuing pretraining before fine-tuning with
instructional datasets is more successful in adapting multilingual models to
Turkish and that in-context learning performances do not much related to
question-answering performances.",2024-04-25,"Eren Dogan, M. Egemen Uzun, Atahan Uz, H. Emre Seyrek, Ahmed Zeer, Ezgi Sevi, H. Toprak Kesgin, M. Kaan Yuce, M. Fatih Amasyali",http://arxiv.org/pdf/2404.17010v1,cs.CL
Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models,"A backbone of knowledge graphs are their class membership relations, which
assign entities to a given class. As part of the knowledge engineering process,
we propose a new method for evaluating the quality of these relations by
processing descriptions of a given entity and class using a zero-shot
chain-of-thought classifier that uses a natural language intensional definition
of a class. We evaluate the method using two publicly available knowledge
graphs, Wikidata and CaLiGraph, and 7 large language models. Using the
gpt-4-0125-preview large language model, the method's classification
performance achieves a macro-averaged F1-score of 0.830 on data from Wikidata
and 0.893 on data from CaLiGraph. Moreover, a manual analysis of the
classification errors shows that 40.9% of errors were due to the knowledge
graphs, with 16.0% due to missing relations and 24.9% due to incorrectly
asserted relations. These results show how large language models can assist
knowledge engineers in the process of knowledge graph refinement. The code and
data are available on Github.",2024-04-25,"Bradley P. Allen, Paul T. Groth",http://arxiv.org/pdf/2404.17000v1,cs.CL
GuideWalk: A Novel Graph-Based Word Embedding for Enhanced Text Classification,"One of the prime problems of computer science and machine learning is to
extract information efficiently from large-scale, heterogeneous data. Text
data, with its syntax, semantics, and even hidden information content,
possesses an exceptional place among the data types in concern. The processing
of the text data requires embedding, a method of translating the content of the
text to numeric vectors. A correct embedding algorithm is the starting point
for obtaining the full information content of the text data. In this work, a
new text embedding approach, namely the Guided Transition Probability Matrix
(GTPM) model is proposed. The model uses the graph structure of sentences to
capture different types of information from text data, such as syntactic,
semantic, and hidden content. Using random walks on a weighted word graph, GTPM
calculates transition probabilities to derive text embedding vectors. The
proposed method is tested with real-world data sets and eight well-known and
successful embedding algorithms. GTPM shows significantly better classification
performance for binary and multi-class datasets than well-known algorithms.
Additionally, the proposed method demonstrates superior robustness, maintaining
performance with limited (only $10\%$) training data, showing an $8\%$ decline
compared to $15-20\%$ for baseline methods.",2024-04-25,"Sarmad N. Mohammed, Semra Gündüç",http://arxiv.org/pdf/2404.18942v2,cs.CL
Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks,"Benchmarks have emerged as the central approach for evaluating Large Language
Models (LLMs). The research community often relies on a model's average
performance across the test prompts of a benchmark to evaluate the model's
performance. This is consistent with the assumption that the test prompts
within a benchmark represent a random sample from a real-world distribution of
interest. We note that this is generally not the case; instead, we hold that
the distribution of interest varies according to the specific use case. We find
that (1) the correlation in model performance across test prompts is
non-random, (2) accounting for correlations across test prompts can change
model rankings on major benchmarks, (3) explanatory factors for these
correlations include semantic similarity and common LLM failure points.",2024-04-25,"Melissa Ailem, Katerina Marazopoulou, Charlotte Siska, James Bono",http://arxiv.org/pdf/2404.16966v2,cs.CL
A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice,"Classification systems are evaluated in a countless number of papers.
However, we find that evaluation practice is often nebulous. Frequently,
metrics are selected without arguments, and blurry terminology invites
misconceptions. For instance, many works use so-called 'macro' metrics to rank
systems (e.g., 'macro F1') but do not clearly specify what they would expect
from such a `macro' metric. This is problematic, since picking a metric can
affect research findings, and thus any clarity in the process should be
maximized.
  Starting from the intuitive concepts of bias and prevalence, we perform an
analysis of common evaluation metrics. The analysis helps us understand the
metrics' underlying properties, and how they align with expectations as found
expressed in papers. Then we reflect on the practical situation in the field,
and survey evaluation practice in recent shared tasks. We find that metric
selection is often not supported with convincing arguments, an issue that can
make a system ranking seem arbitrary. Our work aims at providing overview and
guidance for more informed and transparent metric selection, fostering
meaningful evaluation.",2024-04-25,Juri Opitz,http://arxiv.org/pdf/2404.16958v2,cs.CL
Make-it-Real: Unleashing Large Multimodal Model for Painting 3D Objects with Realistic Materials,"Physically realistic materials are pivotal in augmenting the realism of 3D
assets across various applications and lighting conditions. However, existing
3D assets and generative models often lack authentic material properties.
Manual assignment of materials using graphic software is a tedious and
time-consuming task. In this paper, we exploit advancements in Multimodal Large
Language Models (MLLMs), particularly GPT-4V, to present a novel approach,
Make-it-Real: 1) We demonstrate that GPT-4V can effectively recognize and
describe materials, allowing the construction of a detailed material library.
2) Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V
precisely identifies and aligns materials with the corresponding components of
3D objects. 3) The correctly matched materials are then meticulously applied as
reference for the new SVBRDF material generation according to the original
albedo map, significantly enhancing their visual authenticity. Make-it-Real
offers a streamlined integration into the 3D content creation workflow,
showcasing its utility as an essential tool for developers of 3D assets.",2024-04-25,"Ye Fang, Zeyi Sun, Tong Wu, Jiaqi Wang, Ziwei Liu, Gordon Wetzstein, Dahua Lin",http://arxiv.org/pdf/2404.16829v3,cs.CL
A Survey of Generative Search and Recommendation in the Era of Large Language Models,"With the information explosion on the Web, search and recommendation are
foundational infrastructures to satisfying users' information needs. As the two
sides of the same coin, both revolve around the same core research problem,
matching queries with documents or users with items. In the recent few decades,
search and recommendation have experienced synchronous technological paradigm
shifts, including machine learning-based and deep learning-based paradigms.
Recently, the superintelligent generative large language models have sparked a
new paradigm in search and recommendation, i.e., generative search (retrieval)
and recommendation, which aims to address the matching problem in a generative
manner. In this paper, we provide a comprehensive survey of the emerging
paradigm in information systems and summarize the developments in generative
search and recommendation from a unified perspective. Rather than simply
categorizing existing works, we abstract a unified framework for the generative
paradigm and break down the existing works into different stages within this
framework to highlight the strengths and weaknesses. And then, we distinguish
generative search and recommendation with their unique challenges, identify
open problems and future directions, and envision the next information-seeking
paradigm.",2024-04-25,"Yongqi Li, Xinyu Lin, Wenjie Wang, Fuli Feng, Liang Pang, Wenjie Li, Liqiang Nie, Xiangnan He, Tat-Seng Chua",http://arxiv.org/pdf/2404.16924v1,cs.CL
IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages,"As large language models (LLMs) see increasing adoption across the globe, it
is imperative for LLMs to be representative of the linguistic diversity of the
world. India is a linguistically diverse country of 1.4 Billion people. To
facilitate research on multilingual LLM evaluation, we release IndicGenBench -
the largest benchmark for evaluating LLMs on user-facing generation tasks
across a diverse set 29 of Indic languages covering 13 scripts and 4 language
families. IndicGenBench is composed of diverse generation tasks like
cross-lingual summarization, machine translation, and cross-lingual question
answering. IndicGenBench extends existing benchmarks to many Indic languages
through human curation providing multi-way parallel evaluation data for many
under-represented Indic languages for the first time. We evaluate a wide range
of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5,
Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings. The largest
PaLM-2 models performs the best on most tasks, however, there is a significant
performance gap in all languages compared to English showing that further
research is needed for the development of more inclusive multilingual language
models. IndicGenBench is released at
www.github.com/google-research-datasets/indic-gen-bench",2024-04-25,"Harman Singh, Nitish Gupta, Shikhar Bharadwaj, Dinesh Tewari, Partha Talukdar",http://arxiv.org/pdf/2404.16816v2,cs.CL
Make Your LLM Fully Utilize the Context,"While many contemporary large language models (LLMs) can process lengthy
input, they still struggle to fully utilize information within the long
context, known as the lost-in-the-middle challenge. We hypothesize that it
stems from insufficient explicit supervision during the long-context training,
which fails to emphasize that any position in a long context can hold crucial
information. Based on this intuition, our study presents information-intensive
(IN2) training, a purely data-driven solution to overcome lost-in-the-middle.
Specifically, IN2 training leverages a synthesized long-context question-answer
dataset, where the answer requires (1) fine-grained information awareness on a
short segment (~128 tokens) within a synthesized long context (4K-32K tokens),
and (2) the integration and reasoning of information from two or more short
segments. Through applying this information-intensive training on Mistral-7B,
we present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of
FILM-7B for utilizing long contexts, we design three probing tasks that
encompass various context styles (document, code, and structured-data context)
and information retrieval patterns (forward, backward, and bi-directional
retrieval). The probing results demonstrate that FILM-7B can robustly retrieve
information from different positions in its 32K context window. Beyond these
probing tasks, FILM-7B significantly improves the performance on real-world
long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while
maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2
accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.",2024-04-25,"Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou",http://arxiv.org/pdf/2404.16811v2,cs.CL
Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning,"Generative Commonsense Reasoning (GCR) requires a model to reason about a
situation using commonsense knowledge, while generating coherent sentences.
Although the quality of the generated sentences is crucial, the diversity of
the generation is equally important because it reflects the model's ability to
use a range of commonsense knowledge facts. Large Language Models (LLMs) have
shown proficiency in enhancing the generation quality across various tasks
through in-context learning (ICL) using given examples without the need for any
fine-tuning. However, the diversity aspect in LLM outputs has not been
systematically studied before. To address this, we propose a simple method that
diversifies the LLM generations, while preserving their quality. Experimental
results on three benchmark GCR datasets show that our method achieves an ideal
balance between the quality and diversity. Moreover, the sentences generated by
our proposed method can be used as training data to improve diversity in
existing commonsense generators.",2024-04-25,"Tianhui Zhang, Bei Peng, Danushka Bollegala",http://arxiv.org/pdf/2404.16807v2,cs.CL
A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs,"This paper provides a comprehensive survey of recent advancements in
leveraging machine learning techniques, particularly Transformer models, for
predicting human mobility patterns during epidemics. Understanding how people
move during epidemics is essential for modeling the spread of diseases and
devising effective response strategies. Forecasting population movement is
crucial for informing epidemiological models and facilitating effective
response planning in public health emergencies. Predicting mobility patterns
can enable authorities to better anticipate the geographical and temporal
spread of diseases, allocate resources more efficiently, and implement targeted
interventions. We review a range of approaches utilizing both pretrained
language models like BERT and Large Language Models (LLMs) tailored
specifically for mobility prediction tasks. These models have demonstrated
significant potential in capturing complex spatio-temporal dependencies and
contextual patterns in textual data.",2024-04-25,"Christian N. Mayemba, D'Jeff K. Nkashama, Jean Marie Tshimula, Maximilien V. Dialufuma, Jean Tshibangu Muabila, Mbuyi Mukendi Didier, Hugues Kanda, René Manassé Galekwa, Heber Dibwe Fita, Serge Mundele, Kalonji Kalala, Aristarque Ilunga, Lambert Mukendi Ntobo, Dominique Muteba, Aaron Aruna Abedi",http://arxiv.org/pdf/2404.16921v1,cs.CL
Model Extrapolation Expedites Alignment,"Given the high computational cost of preference alignment training of large
language models (LLMs), exploring efficient methods to reduce the training
overhead remains an important and compelling research problem. Motivated by the
observation that alignment training typically involves only small parameter
changes without injecting new knowledge into models, we propose a
straightforward method called ExPO (model extrapolation) to expedite LLMs'
alignment with human preferences. Given a partially-trained model and its
initial SFT checkpoint, ExPO improves the implicit optimization objective of
alignment training by simply amplifying the parameter change based on a
first-order approximation, without any additional training overhead. Through
controlled experiments, we demonstrate that ExPO boosts a DPO model trained
with only 20% steps to outperform the fully-trained one. Moreover, we show that
ExPO notably improves existing open-source LLMs (ranging from 1.8B to 70B
parameters) on the leading AlpacaEval 2.0 and MT-Bench benchmarks, which
highlights ExPO's broader utility in efficiently enhancing LLM alignment.",2024-04-25,"Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng",http://arxiv.org/pdf/2404.16792v4,cs.CL
Continual Learning of Large Language Models: A Comprehensive Survey,"The recent success of large language models (LLMs) trained on static,
pre-collected, general datasets has sparked numerous research directions and
applications. One such direction addresses the non-trivial challenge of
integrating pre-trained LLMs into dynamic data distributions, task structures,
and user preferences. Pre-trained LLMs, when tailored for specific needs, often
experience significant performance degradation in previous knowledge domains --
a phenomenon known as ""catastrophic forgetting"". While extensively studied in
the continual learning (CL) community, it presents new manifestations in the
realm of LLMs. In this survey, we provide a comprehensive overview of the
current research progress on LLMs within the context of CL. This survey is
structured into four main sections: we first describe an overview of
continually learning LLMs, consisting of two directions of continuity: vertical
continuity (or vertical continual learning), i.e., continual adaptation from
general to specific capabilities, and horizontal continuity (or horizontal
continual learning), i.e., continual adaptation across time and domains
(Section 3). We then summarize three stages of learning LLMs in the context of
modern CL: Continual Pre-Training (CPT), Domain-Adaptive Pre-training (DAP),
and Continual Fine-Tuning (CFT) (Section 4). Then we provide an overview of
evaluation protocols for continual learning with LLMs, along with the current
available data sources (Section 5). Finally, we discuss intriguing questions
pertaining to continual learning for LLMs (Section 6). The full list of papers
examined in this survey is available at
https://github.com/Wang-ML-Lab/llm-continual-learning-survey.",2024-04-25,"Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, Zifeng Wang, Sayna Ebrahimi, Hao Wang",http://arxiv.org/pdf/2404.16789v3,cs.CL
Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant,"We study the tendency of AI systems to deceive by constructing a realistic
simulation setting of a company AI assistant. The simulated company employees
provide tasks for the assistant to complete, these tasks spanning writing
assistance, information retrieval and programming. We then introduce situations
where the model might be inclined to behave deceptively, while taking care to
not instruct or otherwise pressure the model to do so. Across different
scenarios, we find that Claude 3 Opus
  1) complies with a task of mass-generating comments to influence public
perception of the company, later deceiving humans about it having done so,
  2) lies to auditors when asked questions, and
  3) strategically pretends to be less capable than it is during capability
evaluations.
  Our work demonstrates that even models trained to be helpful, harmless and
honest sometimes behave deceptively in realistic scenarios, without notable
external pressure to do so.",2024-04-25,"Olli Järviniemi, Evan Hubinger",http://arxiv.org/pdf/2405.01576v1,cs.CL
Modeling Selective Feature Attention for Representation-based Siamese Text Matching,"Representation-based Siamese networks have risen to popularity in lightweight
text matching due to their low deployment and inference costs. While word-level
attention mechanisms have been implemented within Siamese networks to improve
performance, we propose Feature Attention (FA), a novel downstream block
designed to enrich the modeling of dependencies among embedding features.
Employing ""squeeze-and-excitation"" techniques, the FA block dynamically adjusts
the emphasis on individual features, enabling the network to concentrate more
on features that significantly contribute to the final classification. Building
upon FA, we introduce a dynamic ""selection"" mechanism called Selective Feature
Attention (SFA), which leverages a stacked BiGRU Inception structure. The SFA
block facilitates multi-scale semantic extraction by traversing different
stacked BiGRU layers, encouraging the network to selectively concentrate on
semantic information and embedding features across varying levels of
abstraction. Both the FA and SFA blocks offer a seamless integration capability
with various Siamese networks, showcasing a plug-and-play characteristic.
Experimental evaluations conducted across diverse text matching baselines and
benchmarks underscore the indispensability of modeling feature attention and
the superiority of the ""selection"" mechanism.",2024-04-25,"Jianxiang Zang, Hui Liu",http://arxiv.org/pdf/2404.16776v1,cs.CL
Can't say cant? Measuring and Reasoning of Dark Jargons in Large Language Models,"Ensuring the resilience of Large Language Models (LLMs) against malicious
exploitation is paramount, with recent focus on mitigating offensive responses.
Yet, the understanding of cant or dark jargon remains unexplored. This paper
introduces a domain-specific Cant dataset and CantCounter evaluation framework,
employing Fine-Tuning, Co-Tuning, Data-Diffusion, and Data-Analysis stages.
Experiments reveal LLMs, including ChatGPT, are susceptible to cant bypassing
filters, with varying recognition accuracy influenced by question types,
setups, and prompt clues. Updated models exhibit higher acceptance rates for
cant queries. Moreover, LLM reactions differ across domains, e.g., reluctance
to engage in racism versus LGBT topics. These findings underscore LLMs'
understanding of cant and reflect training data characteristics and vendor
approaches to sensitive topics. Additionally, we assess LLMs' ability to
demonstrate reasoning capabilities. Access to our datasets and code is
available at https://github.com/cistineup/CantCounter.",2024-04-25,"Xu Ji, Jianyi Zhang, Ziyin Zhou, Zhangchi Zhao, Qianqian Qiao, Kaiying Han, Md Imran Hossen, Xiali Hei",http://arxiv.org/pdf/2405.00718v1,cs.CL
Exploring News Summarization and Enrichment in a Highly Resource-Scarce Indian Language: A Case Study of Mizo,"Obtaining sufficient information in one's mother tongue is crucial for
satisfying the information needs of the users. While high-resource languages
have abundant online resources, the situation is less than ideal for very
low-resource languages. Moreover, the insufficient reporting of vital national
and international events continues to be a worry, especially in languages with
scarce resources, like \textbf{Mizo}. In this paper, we conduct a study to
investigate the effectiveness of a simple methodology designed to generate a
holistic summary for Mizo news articles, which leverages English-language news
to supplement and enhance the information related to the corresponding news
events. Furthermore, we make available 500 Mizo news articles and corresponding
enriched holistic summaries. Human evaluation confirms that our approach
significantly enhances the information coverage of Mizo news articles. The mizo
dataset and code can be accessed at
\url{https://github.com/barvin04/mizo_enrichment",2024-04-25,"Abhinaba Bala, Ashok Urlana, Rahul Mishra, Parameswari Krishnamurthy",http://arxiv.org/pdf/2405.00717v1,cs.CL
REBEL: Reinforcement Learning via Regressing Relative Rewards,"While originally developed for continuous control problems, Proximal Policy
Optimization (PPO) has emerged as the work-horse of a variety of reinforcement
learning (RL) applications, including the fine-tuning of generative models.
Unfortunately, PPO requires multiple heuristics to enable stable convergence
(e.g. value networks, clipping), and is notorious for its sensitivity to the
precise implementation of these components. In response, we take a step back
and ask what a minimalist RL algorithm for the era of generative models would
look like. We propose REBEL, an algorithm that cleanly reduces the problem of
policy optimization to regressing the relative reward between two completions
to a prompt in terms of the policy, enabling strikingly lightweight
implementation. In theory, we prove that fundamental RL algorithms like Natural
Policy Gradient can be seen as variants of REBEL, which allows us to match the
strongest known theoretical guarantees in terms of convergence and sample
complexity in the RL literature. REBEL can also cleanly incorporate offline
data and be extended to handle the intransitive preferences we frequently see
in practice. Empirically, we find that REBEL provides a unified approach to
language modeling and image generation with stronger or similar performance as
PPO and DPO, all while being simpler to implement and more computationally
efficient than PPO. When fine-tuning Llama-3-8B-Instruct, REBEL achieves strong
performance in AlpacaEval 2.0, MT-Bench, and Open LLM Leaderboard.",2024-04-25,"Zhaolin Gao, Jonathan D. Chang, Wenhao Zhan, Owen Oertell, Gokul Swamy, Kianté Brantley, Thorsten Joachims, J. Andrew Bagnell, Jason D. Lee, Wen Sun",http://arxiv.org/pdf/2404.16767v4,cs.CL
Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model,"While supervised fine-tuning (SFT) has been a straightforward approach for
tailoring the output of foundation large language model (LLM) to specific
preferences, concerns have been raised about the depth of this alignment, with
some critiques suggesting it is merely ""superficial"". We critically examine
this hypothesis within the scope of cross-lingual generation tasks, proposing
that the effectiveness of SFT may be constrained by its reliance on prior
tokens to guide cross-lingual generation. Based on this crucial insight, and in
response to the challenges posed by the costly and limited availability of
non-English data for SFT, we introduce a novel training-free alignment method
named PreTTY, which employs minimal task-related prior tokens to bridge the
foundation LLM and the SFT LLM, achieving comparable performance without
training. Experiments on machine translation and part-of-speech tagging across
eight languages demonstrate the efficacy of PreTTY in cross-lingual settings.
Remarkably, by initiating the decoding process with only one or two prior
tokens, foundation LLMs can achieve performance comparable to their SFT
counterparts. This method presents a cost-effective alternative to SFT and
advances the democratization of multilingual LLMs.",2024-04-25,"Runzhe Zhan, Xinyi Yang, Derek F. Wong, Lidia S. Chao, Yue Zhang",http://arxiv.org/pdf/2404.16766v1,cs.CL
Dataset of Quotation Attribution in German News Articles,"Extracting who says what to whom is a crucial part in analyzing human
communication in today's abundance of data such as online news articles. Yet,
the lack of annotated data for this task in German news articles severely
limits the quality and usability of possible systems. To remedy this, we
present a new, freely available, creative-commons-licensed dataset for
quotation attribution in German news articles based on WIKINEWS. The dataset
provides curated, high-quality annotations across 1000 documents (250,000
tokens) in a fine-grained annotation schema enabling various downstream uses
for the dataset. The annotations not only specify who said what but also how,
in which context, to whom and define the type of quotation. We specify our
annotation schema, describe the creation of the dataset and provide a
quantitative analysis. Further, we describe suitable evaluation metrics, apply
two existing systems for quotation attribution, discuss their results to
evaluate the utility of our dataset and outline use cases of our dataset in
downstream tasks.",2024-04-25,"Fynn Petersen-Frey, Chris Biemann",http://arxiv.org/pdf/2404.16764v1,cs.CL
Automatic Speech Recognition System-Independent Word Error Rate Estimation,"Word error rate (WER) is a metric used to evaluate the quality of
transcriptions produced by Automatic Speech Recognition (ASR) systems. In many
applications, it is of interest to estimate WER given a pair of a speech
utterance and a transcript. Previous work on WER estimation focused on building
models that are trained with a specific ASR system in mind (referred to as ASR
system-dependent). These are also domain-dependent and inflexible in real-world
applications. In this paper, a hypothesis generation method for ASR
System-Independent WER estimation (SIWE) is proposed. In contrast to prior
work, the WER estimators are trained using data that simulates ASR system
output. Hypotheses are generated using phonetically similar or linguistically
more likely alternative words. In WER estimation experiments, the proposed
method reaches a similar performance to ASR system-dependent WER estimators on
in-domain data and achieves state-of-the-art performance on out-of-domain data.
On the out-of-domain data, the SIWE model outperformed the baseline estimators
in root mean square error and Pearson correlation coefficient by relative
17.58% and 18.21%, respectively, on Switchboard and CALLHOME. The performance
was further improved when the WER of the training set was close to the WER of
the evaluation dataset.",2024-04-25,"Chanho Park, Mingjie Chen, Thomas Hain",http://arxiv.org/pdf/2404.16743v2,cs.CL
LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding,"We present LayerSkip, an end-to-end solution to speed-up inference of large
language models (LLMs). First, during training we apply layer dropout, with low
dropout rates for earlier layers and higher dropout rates for later layers, and
an early exit loss where all transformer layers share the same exit. Second,
during inference, we show that this training recipe increases the accuracy of
early exit at earlier layers, without adding any auxiliary layers or modules to
the model. Third, we present a novel self-speculative decoding solution where
we exit at early layers and verify and correct with remaining layers of the
model. Our proposed self-speculative decoding approach has less memory
footprint than other speculative decoding approaches and benefits from shared
compute and activations of the draft and verification stages. We run
experiments on different Llama model sizes on different types of training:
pretraining from scratch, continual pretraining, finetuning on specific data
domain, and finetuning on specific task. We implement our inference solution
and show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x
on coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and
checkpoints at https://github.com/facebookresearch/LayerSkip.",2024-04-25,"Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman, Ahmed A Aly, Beidi Chen, Carole-Jean Wu",http://arxiv.org/pdf/2404.16710v4,cs.CL
Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents,"As AI systems pervade human life, ensuring that large language models (LLMs)
make safe decisions remains a significant challenge. We introduce the
Governance of the Commons Simulation (GovSim), a generative simulation platform
designed to study strategic interactions and cooperative decision-making in
LLMs. In GovSim, a society of AI agents must collectively balance exploiting a
common resource with sustaining it for future use. This environment enables the
study of how ethical considerations, strategic planning, and negotiation skills
impact cooperative outcomes. We develop an LLM-based agent architecture and
test it with the leading open and closed LLMs. We find that all but the most
powerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with
the highest survival rate below 54%. Ablations reveal that successful
multi-agent communication between agents is critical for achieving cooperation
in these cases. Furthermore, our analyses show that the failure to achieve
sustainable cooperation in most LLMs stems from their inability to formulate
and analyze hypotheses about the long-term effects of their actions on the
equilibrium of the group. Finally, we show that agents that leverage
""Universalization""-based reasoning, a theory of moral thinking, are able to
achieve significantly better sustainability. Taken together, GovSim enables us
to study the mechanisms that underlie sustainable self-government with
specificity and scale. We open source the full suite of our research results,
including the simulation environment, agent prompts, and a comprehensive web
interface.",2024-04-25,"Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard Schölkopf, Mrinmaya Sachan, Rada Mihalcea",http://arxiv.org/pdf/2404.16698v4,cs.CL
Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4,"Generative artificial intelligences, particularly large language models
(LLMs), play an increasingly prominent role in human decision-making contexts,
necessitating transparency about their capabilities. While prior studies have
shown addition biases in humans (Adams et al., 2021) and OpenAI's GPT-3 (Winter
et al., 2023), this study extends the research by comparing human and GPT-4
problem-solving across both spatial and linguistic tasks, with variations in
solution efficiency and valence of task instruction. Four preregistered
experiments with 588 participants from the U.S. and 680 GPT-4 iterations
revealed a stronger tendency towards additive transformations in GPT-4 than in
humans. Human participants were less likely to use additive strategies when
subtraction was relatively more efficient than when addition and subtraction
were equally efficient. GPT-4 exhibited the opposite behavior, with a strong
addition bias when subtraction was more efficient. In terms of valence of task
instruction, GPT-4's use of additive strategies increased when instructed to
""improve"" (positive) rather than ""edit"" (neutral). These findings demonstrate
that biases in human problem-solving are amplified in GPT-4, and that LLM
behavior differs from human efficiency-based strategies. This highlights the
limitations of LLMs and the need for caution when using them in real-world
applications.",2024-04-25,"Lydia Uhler, Verena Jordan, Jürgen Buder, Markus Huff, Frank Papenmeier",http://arxiv.org/pdf/2404.16692v3,cs.CL
Large Language Models in the Clinic: A Comprehensive Benchmark,"The adoption of large language models (LLMs) to assist clinicians has
attracted remarkable attention. Existing works mainly adopt the close-ended
question-answering (QA) task with answer options for evaluation. However, many
clinical decisions involve answering open-ended questions without pre-set
options. To better understand LLMs in the clinic, we construct a benchmark
ClinicBench. We first collect eleven existing datasets covering diverse
clinical language generation, understanding, and reasoning tasks. Furthermore,
we construct six novel datasets and clinical tasks that are complex but common
in real-world practice, e.g., open-ended decision-making, long document
processing, and emerging drug analysis. We conduct an extensive evaluation of
twenty-two LLMs under both zero-shot and few-shot settings. Finally, we invite
medical experts to evaluate the clinical usefulness of LLMs. The benchmark data
is available at https://github.com/AI-in-Health/ClinicBench.",2024-04-25,"Fenglin Liu, Zheng Li, Hongjian Zhou, Qingyu Yin, Jingfeng Yang, Xianfeng Tang, Chen Luo, Ming Zeng, Haoming Jiang, Yifan Gao, Priyanka Nigam, Sreyashi Nag, Bing Yin, Yining Hua, Xuan Zhou, Omid Rohanian, Anshul Thakur, Lei Clifton, David A. Clifton",http://arxiv.org/pdf/2405.00716v4,cs.CL
Utilizing Large Language Models to Identify Reddit Users Considering Vaping Cessation for Digital Interventions,"The widespread adoption of social media platforms globally not only enhances
users' connectivity and communication but also emerges as a vital channel for
the dissemination of health-related information, thereby establishing social
media data as an invaluable organic data resource for public health research.
The surge in popularity of vaping or e-cigarette use in the United States and
other countries has caused an outbreak of e-cigarette and vaping use-associated
lung injury (EVALI), leading to hospitalizations and fatalities in 2019,
highlighting the urgency to comprehend vaping behaviors and develop effective
strategies for cession. In this study, we extracted a sample dataset from one
vaping sub-community on Reddit to analyze users' quit vaping intentions.
Leveraging large language models including both the latest GPT-4 and
traditional BERT-based language models for sentence-level quit-vaping intention
prediction tasks, this study compares the outcomes of these models against
human annotations. Notably, when compared to human evaluators, GPT-4 model
demonstrates superior consistency in adhering to annotation guidelines and
processes, showcasing advanced capabilities to detect nuanced user quit-vaping
intentions that human evaluators might overlook. These preliminary findings
emphasize the potential of GPT-4 in enhancing the accuracy and reliability of
social media data analysis, especially in identifying subtle users' intentions
that may elude human detection.",2024-04-25,"Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Caleb Henry, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang",http://arxiv.org/pdf/2404.17607v1,cs.CL
Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing,"MoE facilitates the development of large models by making the computational
complexity of the model no longer scale linearly with increasing parameters.
The learning sparse gating network selects a set of experts for each token to
be processed; however, this may lead to differences in the number of tokens
processed by each expert over several successive iterations, i.e., the expert
load fluctuations, which reduces computational parallelization and resource
utilization. To this end, we traced and analyzed loads of each expert in the
training iterations for several large language models in this work, and defined
the transient state with ""obvious load fluctuation"" and the stable state with
""temporal locality"". Moreover, given the characteristics of these two states
and the computational overhead, we deployed three classical prediction
algorithms that achieve accurate expert load prediction results. For the GPT3
350M model, the average error rates for predicting the expert load proportion
over the next 1,000 and 2,000 steps are approximately 1.3% and 1.8%,
respectively. This work can provide valuable guidance for expert placement or
resource allocation for MoE model training. Based on this work, we will propose
an expert placement scheme for transient and stable states in our coming work.",2024-04-25,"Peizhuang Cong, Aomufei Yuan, Shimao Chen, Yuxuan Tian, Bowen Ye, Tong Yang",http://arxiv.org/pdf/2404.16914v1,cs.CL
The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances,"Large language models (LLMs) are quickly being adopted in a wide range of
learning experiences, especially via ubiquitous and broadly accessible chat
interfaces like ChatGPT and Copilot. This type of interface is readily
available to students and teachers around the world, yet relatively little
research has been done to assess the impact of such generic tools on student
learning. Coding education is an interesting test case, both because LLMs have
strong performance on coding tasks, and because LLM-powered support tools are
rapidly becoming part of the workflow of professional software engineers. To
help understand the impact of generic LLM use on coding education, we conducted
a large-scale randomized control trial with 5,831 students from 146 countries
in an online coding class in which we provided some students with access to a
chat interface with GPT-4. We estimate positive benefits on exam performance
for adopters, the students who used the tool, but over all students, the
advertisement of GPT-4 led to a significant average decrease in exam
participation. We observe similar decreases in other forms of course
engagement. However, this decrease is modulated by the student's country of
origin. Offering access to LLMs to students from low human development index
countries increased their exam participation rate on average. Our results
suggest there may be promising benefits to using LLMs in an introductory coding
class, but also potential harms for engagement, which makes their longer term
impact on student success unclear. Our work highlights the need for additional
investigations to help understand the potential impact of future adoption and
integration of LLMs into classrooms.",2024-04-25,"Allen Nie, Yash Chandak, Miroslav Suzara, Malika Ali, Juliette Woodrow, Matt Peng, Mehran Sahami, Emma Brunskill, Chris Piech",http://arxiv.org/pdf/2407.09975v1,cs.CL
Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation,"Proprietary Large Language Models (LLMs) such as GPT-4 and Gemini have
demonstrated promising capabilities in clinical text summarization tasks.
However, due to patient data privacy concerns and computational costs, many
healthcare providers prefer using small, locally-hosted models over external
generic LLMs. This study presents a comprehensive domain- and task-specific
adaptation process for the open-source LLaMA-2 13 billion parameter model,
enabling it to generate high-quality clinical notes from outpatient
patient-doctor dialogues. Our process incorporates continued pre-training,
supervised fine-tuning, and reinforcement learning from both AI and human
feedback. We introduced a new approach, DistillDirect, for performing on-policy
reinforcement learning with Gemini 1.0 Pro as the teacher model. Our resulting
model, LLaMA-Clinic, can generate clinical notes comparable in quality to those
authored by physicians. In a blinded physician reader study, the majority
(90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as
""acceptable"" or higher across all three criteria: real-world readiness,
completeness, and accuracy. In the more challenging ""Assessment and Plan""
section, LLaMA-Clinic scored higher (4.2/5) in real-world readiness than
physician-authored notes (4.1/5). We highlight key considerations for future
clinical note-generation tasks, emphasizing the importance of pre-defining a
best-practice note format, rather than relying on LLMs to determine this for
clinical practice.",2024-04-25,"Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Korsapati, Chuck Outcalt, Jimeng Sun",http://arxiv.org/pdf/2405.00715v5,cs.CL
ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling,"Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.",2024-04-25,"Sangryul Kim, Donghee Han, Sehyun Kim",http://arxiv.org/pdf/2404.16659v1,cs.CL
Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs),"Linguistic ambiguity continues to represent a significant challenge for
natural language processing (NLP) systems, notwithstanding the advancements in
architectures such as Transformers and BERT. Inspired by the recent success of
instructional models like ChatGPT and Gemini (In 2023, the artificial
intelligence was called Bard.), this study aims to analyze and discuss
linguistic ambiguity within these models, focusing on three types prevalent in
Brazilian Portuguese: semantic, syntactic, and lexical ambiguity. We create a
corpus comprising 120 sentences, both ambiguous and unambiguous, for
classification, explanation, and disambiguation. The models capability to
generate ambiguous sentences was also explored by soliciting sets of sentences
for each type of ambiguity. The results underwent qualitative analysis, drawing
on recognized linguistic references, and quantitative assessment based on the
accuracy of the responses obtained. It was evidenced that even the most
sophisticated models, such as ChatGPT and Gemini, exhibit errors and
deficiencies in their responses, with explanations often providing
inconsistent. Furthermore, the accuracy peaked at 49.58 percent, indicating the
need for descriptive studies for supervised learning.",2024-04-25,"Lavínia de Carvalho Moraes, Irene Cristina Silvério, Rafael Alexandre Sousa Marques, Bianca de Castro Anaia, Dandara Freitas de Paula, Maria Carolina Schincariol de Faria, Iury Cleveston, Alana de Santana Correia, Raquel Meister Ko Freitag",http://arxiv.org/pdf/2404.16653v1,cs.CL
Tele-FLM Technical Report,"Large language models (LLMs) have showcased profound capabilities in language
understanding and generation, facilitating a wide array of applications.
However, there is a notable paucity of detailed, open-sourced methodologies on
efficiently scaling LLMs beyond 50 billion parameters with minimum
trial-and-error cost and computational resources. In this report, we introduce
Tele-FLM (aka FLM-2), a 52B open-sourced multilingual large language model that
features a stable, efficient pre-training paradigm and enhanced factual
judgment capabilities. Tele-FLM demonstrates superior multilingual language
modeling abilities, measured by BPB on textual corpus. Besides, in both English
and Chinese foundation model evaluation, it is comparable to strong
open-sourced models that involve larger pre-training FLOPs, such as Llama2-70B
and DeepSeek-67B. In addition to the model weights, we share the core designs,
engineering practices, and training details, which we expect to benefit both
the academic and industrial communities.",2024-04-25,"Xiang Li, Yiqun Yao, Xin Jiang, Xuezhi Fang, Chao Wang, Xinzhang Liu, Zihan Wang, Yu Zhao, Xin Wang, Yuyao Huang, Shuangyong Song, Yongxiang Li, Zheng Zhang, Bo Zhao, Aixin Sun, Yequan Wang, Zhongjiang He, Zhongyuan Wang, Xuelong Li, Tiejun Huang",http://arxiv.org/pdf/2404.16645v1,cs.CL
Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer,"Unsupervised cross-lingual transfer involves transferring knowledge between
languages without explicit supervision. Although numerous studies have been
conducted to improve performance in such tasks by focusing on cross-lingual
knowledge, particularly lexical and syntactic knowledge, current approaches are
limited as they only incorporate syntactic or lexical information. Since each
type of information offers unique advantages and no previous attempts have
combined both, we attempt to explore the potential of this approach. In this
paper, we present a novel framework called ""Lexicon-Syntax Enhanced
Multilingual BERT"" that combines both lexical and syntactic knowledge.
Specifically, we use Multilingual BERT (mBERT) as the base model and employ two
techniques to enhance its learning capabilities. The code-switching technique
is used to implicitly teach the model lexical alignment information, while a
syntactic-based graph attention network is designed to help the model encode
syntactic structure. To integrate both types of knowledge, we input
code-switched sequences into both the syntactic module and the mBERT base model
simultaneously. Our extensive experimental results demonstrate this framework
can consistently outperform all baselines of zero-shot cross-lingual transfer,
with the gains of 1.0~3.7 points on text classification, named entity
recognition (ner), and semantic parsing tasks. Keywords:cross-lingual transfer,
lexicon, syntax, code-switching, graph attention network",2024-04-25,"Jianyu Zheng, Fengfei Fan, Jianquan Li",http://arxiv.org/pdf/2404.16627v1,cs.CL
Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare,"The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.",2024-04-25,"Emre Can Acikgoz, Osman Batur İnce, Rayene Bench, Arda Anıl Boz, İlker Kesen, Aykut Erdem, Erkut Erdem",http://arxiv.org/pdf/2404.16621v1,cs.CL
Understanding Privacy Risks of Embeddings Induced by Large Language Models,"Large language models (LLMs) show early signs of artificial general
intelligence but struggle with hallucinations. One promising solution to
mitigate these hallucinations is to store external knowledge as embeddings,
aiding LLMs in retrieval-augmented generation. However, such a solution risks
compromising privacy, as recent studies experimentally showed that the original
text can be partially reconstructed from text embeddings by pre-trained
language models. The significant advantage of LLMs over traditional pre-trained
models may exacerbate these concerns. To this end, we investigate the
effectiveness of reconstructing original knowledge and predicting entity
attributes from these embeddings when LLMs are employed. Empirical findings
indicate that LLMs significantly improve the accuracy of two evaluated tasks
over those from pre-trained models, regardless of whether the texts are
in-distribution or out-of-distribution. This underscores a heightened potential
for LLMs to jeopardize user privacy, highlighting the negative consequences of
their widespread use. We further discuss preliminary strategies to mitigate
this risk.",2024-04-25,"Zhihao Zhu, Ninglu Shao, Defu Lian, Chenwang Wu, Zheng Liu, Yi Yang, Enhong Chen",http://arxiv.org/pdf/2404.16587v1,cs.CL
Exploring Internal Numeracy in Language Models: A Case Study on ALBERT,"It has been found that Transformer-based language models have the ability to
perform basic quantitative reasoning. In this paper, we propose a method for
studying how these models internally represent numerical data, and use our
proposal to analyze the ALBERT family of language models. Specifically, we
extract the learned embeddings these models use to represent tokens that
correspond to numbers and ordinals, and subject these embeddings to Principal
Component Analysis (PCA). PCA results reveal that ALBERT models of different
sizes, trained and initialized separately, consistently learn to use the axes
of greatest variation to represent the approximate ordering of various
numerical concepts. Numerals and their textual counterparts are represented in
separate clusters, but increase along the same direction in 2D space. Our
findings illustrate that language models, trained purely to model text, can
intuit basic mathematical concepts, opening avenues for NLP applications that
intersect with quantitative reasoning.",2024-04-25,"Ulme Wennberg, Gustav Eje Henter",http://arxiv.org/pdf/2404.16574v1,cs.CL
Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark,"Large Language Models (LLMs) offer the potential for automatic time series
analysis and reporting, which is a critical task across many domains, spanning
healthcare, finance, climate, energy, and many more. In this paper, we propose
a framework for rigorously evaluating the capabilities of LLMs on time series
understanding, encompassing both univariate and multivariate forms. We
introduce a comprehensive taxonomy of time series features, a critical
framework that delineates various characteristics inherent in time series data.
Leveraging this taxonomy, we have systematically designed and synthesized a
diverse dataset of time series, embodying the different outlined features, each
accompanied by textual descriptions. This dataset acts as a solid foundation
for assessing the proficiency of LLMs in comprehending time series. Our
experiments shed light on the strengths and limitations of state-of-the-art
LLMs in time series understanding, revealing which features these models
readily comprehend effectively and where they falter. In addition, we uncover
the sensitivity of LLMs to factors including the formatting of the data, the
position of points queried within a series and the overall time series length.",2024-04-25,"Elizabeth Fons, Rachneet Kaur, Soham Palande, Zhen Zeng, Tucker Balch, Manuela Veloso, Svitlana Vyetrenko",http://arxiv.org/pdf/2404.16563v2,cs.CL
To what extent is ChatGPT useful for language teacher lesson plan creation?,"The advent of generative AI models holds tremendous potential for aiding
teachers in the generation of pedagogical materials. However, numerous
knowledge gaps concerning the behavior of these models obfuscate the generation
of research-informed guidance for their effective usage. Here we assess trends
in prompt specificity, variability, and weaknesses in foreign language teacher
lesson plans generated by zero-shot prompting in ChatGPT. Iterating a series of
prompts that increased in complexity, we found that output lesson plans were
generally high quality, though additional context and specificity to a prompt
did not guarantee a concomitant increase in quality. Additionally, we observed
extreme cases of variability in outputs generated by the same prompt. In many
cases, this variability reflected a conflict between 20th century versus 21st
century pedagogical practices. These results suggest that the training of
generative AI models on classic texts concerning pedagogical practices may
represent a currently underexplored topic with the potential to bias generated
content towards teaching practices that have been long refuted by research.
Collectively, our results offer immediate translational implications for
practicing and training foreign language teachers on the use of AI tools. More
broadly, these findings reveal the existence of generative AI output trends
that have implications for the generation of pedagogical materials across a
diversity of content areas.",2024-04-25,"Alex Dornburg, Kristin Davin",http://arxiv.org/pdf/2407.09974v1,cs.CL
Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations,"In human-computer interaction, it is crucial for agents to respond to human
by understanding their emotions. Unraveling the causes of emotions is more
challenging. A new task named Multimodal Emotion-Cause Pair Extraction in
Conversations is responsible for recognizing emotion and identifying causal
expressions. In this study, we propose a multi-stage framework to generate
emotion and extract the emotion causal pairs given the target emotion. In the
first stage, Llama-2-based InstructERC is utilized to extract the emotion
category of each utterance in a conversation. After emotion recognition, a
two-stream attention model is employed to extract the emotion causal pairs
given the target emotion for subtask 2 while MuTEC is employed to extract
causal span for subtask 1. Our approach achieved first place for both of the
two subtasks in the competition.",2024-04-25,"Shen Zhang, Haojie Zhang, Jing Zhang, Xudong Zhang, Yimeng Zhuang, Jinting Wu",http://arxiv.org/pdf/2404.16905v1,cs.CL
Building a Japanese Document-Level Relation Extraction Dataset Assisted by Cross-Lingual Transfer,"Document-level Relation Extraction (DocRE) is the task of extracting all
semantic relationships from a document. While studies have been conducted on
English DocRE, limited attention has been given to DocRE in non-English
languages. This work delves into effectively utilizing existing English
resources to promote DocRE studies in non-English languages, with Japanese as
the representative case. As an initial attempt, we construct a dataset by
transferring an English dataset to Japanese. However, models trained on such a
dataset suffer from low recalls. We investigate the error cases and attribute
the failure to different surface structures and semantics of documents
translated from English and those written by native speakers. We thus switch to
explore if the transferred dataset can assist human annotation on Japanese
documents. In our proposal, annotators edit relation predictions from a model
trained on the transferred dataset. Quantitative analysis shows that relation
recommendations suggested by the model help reduce approximately 50% of the
human edit steps compared with the previous approach. Experiments quantify the
performance of existing DocRE models on our collected dataset, portraying the
challenges of Japanese and cross-lingual DocRE.",2024-04-25,"Youmi Ma, An Wang, Naoaki Okazaki",http://arxiv.org/pdf/2404.16506v1,cs.CL
Evaluating Consistency and Reasoning Capabilities of Large Language Models,"Large Language Models (LLMs) are extensively used today across various
sectors, including academia, research, business, and finance, for tasks such as
text generation, summarization, and translation. Despite their widespread
adoption, these models often produce incorrect and misleading information,
exhibiting a tendency to hallucinate. This behavior can be attributed to
several factors, with consistency and reasoning capabilities being significant
contributors. LLMs frequently lack the ability to generate explanations and
engage in coherent reasoning, leading to inaccurate responses. Moreover, they
exhibit inconsistencies in their outputs. This paper aims to evaluate and
compare the consistency and reasoning capabilities of both public and
proprietary LLMs. The experiments utilize the Boolq dataset as the ground
truth, comprising questions, answers, and corresponding explanations. Queries
from the dataset are presented as prompts to the LLMs, and the generated
responses are evaluated against the ground truth answers. Additionally,
explanations are generated to assess the models' reasoning abilities.
Consistency is evaluated by repeatedly presenting the same query to the models
and observing for variations in their responses. For measuring reasoning
capabilities, the generated explanations are compared to the ground truth
explanations using metrics such as BERT, BLEU, and F-1 scores. The findings
reveal that proprietary models generally outperform public models in terms of
both consistency and reasoning capabilities. However, even when presented with
basic general knowledge questions, none of the models achieved a score of 90\%
in both consistency and reasoning. This study underscores the direct
correlation between consistency and reasoning abilities in LLMs and highlights
the inherent reasoning challenges present in current language models.",2024-04-25,"Yash Saxena, Sarthak Chopra, Arunendra Mani Tripathi",http://arxiv.org/pdf/2404.16478v1,cs.CL
Large Language Models Perform on Par with Experts Identifying Mental Health Factors in Adolescent Online Forums,"Mental health in children and adolescents has been steadily deteriorating
over the past few years. The recent advent of Large Language Models (LLMs)
offers much hope for cost and time efficient scaling of monitoring and
intervention, yet despite specifically prevalent issues such as school bullying
and eating disorders, previous studies on have not investigated performance in
this domain or for open information extraction where the set of answers is not
predetermined. We create a new dataset of Reddit posts from adolescents aged
12-19 annotated by expert psychiatrists for the following categories: TRAUMA,
PRECARITY, CONDITION, SYMPTOMS, SUICIDALITY and TREATMENT and compare expert
labels to annotations from two top performing LLMs (GPT3.5 and GPT4). In
addition, we create two synthetic datasets to assess whether LLMs perform
better when annotating data as they generate it. We find GPT4 to be on par with
human inter-annotator agreement and performance on synthetic data to be
substantially higher, however we find the model still occasionally errs on
issues of negation and factuality and higher performance on synthetic data is
driven by greater complexity of real data rather than inherent advantage.",2024-04-25,"Isabelle Lorge, Dan W. Joyce, Andrey Kormilitzin",http://arxiv.org/pdf/2404.16461v2,cs.CL
Contextual Categorization Enhancement through LLMs Latent-Space,"Managing the semantic quality of the categorization in large textual
datasets, such as Wikipedia, presents significant challenges in terms of
complexity and cost. In this paper, we propose leveraging transformer models to
distill semantic information from texts in the Wikipedia dataset and its
associated categories into a latent space. We then explore different approaches
based on these encodings to assess and enhance the semantic identity of the
categories. Our graphical approach is powered by Convex Hull, while we utilize
Hierarchical Navigable Small Worlds (HNSWs) for the hierarchical approach. As a
solution to the information loss caused by the dimensionality reduction, we
modulate the following mathematical solution: an exponential decay function
driven by the Euclidean distances between the high-dimensional encodings of the
textual categories. This function represents a filter built around a contextual
category and retrieves items with a certain Reconsideration Probability (RP).
Retrieving high-RP items serves as a tool for database administrators to
improve data groupings by providing recommendations and identifying outliers
within a contextual framework.",2024-04-25,"Zineddine Bettouche, Anas Safi, Andreas Fischer",http://arxiv.org/pdf/2404.16442v1,cs.CL
Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks,"Instruction tuning has been proven effective in enhancing zero-shot
generalization across various tasks and in improving the performance of
specific tasks. For task-specific improvements, strategically selecting and
training on related tasks that provide meaningful supervision is crucial, as
this approach enhances efficiency and prevents performance degradation from
learning irrelevant tasks. In this light, we introduce a simple yet effective
task selection method that leverages instruction information alone to identify
relevant tasks, optimizing instruction tuning for specific tasks. Our method is
significantly more efficient than traditional approaches, which require complex
measurements of pairwise transferability between tasks or the creation of data
samples for the target task. Additionally, by aligning the model with the
unique instructional template style of the meta-dataset, we enhance its ability
to granularly discern relevant tasks, leading to improved overall performance.
Experimental results demonstrate that training on a small set of tasks, chosen
solely based on the instructions, results in substantial improvements in
performance on benchmarks such as P3, Big-Bench, NIV2, and Big-Bench Hard.
Significantly, these improvements surpass those achieved by prior task
selection methods, highlighting the superiority of our approach.",2024-04-25,"Changho Lee, Janghoon Han, Seonghyeon Ye, Stanley Jungkyu Choi, Honglak Lee, Kyunghoon Bae",http://arxiv.org/pdf/2404.16418v2,cs.CL
Asking and Answering Questions to Extract Event-Argument Structures,"This paper presents a question-answering approach to extract document-level
event-argument structures. We automatically ask and answer questions for each
argument type an event may have. Questions are generated using manually defined
templates and generative transformers. Template-based questions are generated
using predefined role-specific wh-words and event triggers from the context
document. Transformer-based questions are generated using large language models
trained to formulate questions based on a passage and the expected answer.
Additionally, we develop novel data augmentation strategies specialized in
inter-sentential event-argument relations. We use a simple span-swapping
technique, coreference resolution, and large language models to augment the
training instances. Our approach enables transfer learning without any
corpora-specific modifications and yields competitive results with the RAMS
dataset. It outperforms previous work, and it is especially beneficial to
extract arguments that appear in different sentences than the event trigger. We
also present detailed quantitative and qualitative analyses shedding light on
the most common errors made by our best model.",2024-04-25,"Md Nayem Uddin, Enfa Rose George, Eduardo Blanco, Steven Corman",http://arxiv.org/pdf/2404.16413v1,cs.CL
U2++ MoE: Scaling 4.7x parameters with minimal impact on RTF,"Scale has opened new frontiers in natural language processing, but at a high
cost. In response, by learning to only activate a subset of parameters in
training and inference, Mixture-of-Experts (MoE) have been proposed as an
energy efficient path to even larger and more capable language models and this
shift towards a new generation of foundation models is gaining momentum,
particularly within the field of Automatic Speech Recognition (ASR). Recent
works that incorporating MoE into ASR models have complex designs such as
routing frames via supplementary embedding network, improving multilingual
ability for the experts, and utilizing dedicated auxiliary losses for either
expert load balancing or specific language handling. We found that delicate
designs are not necessary, while an embarrassingly simple substitution of MoE
layers for all Feed-Forward Network (FFN) layers is competent for the ASR task.
To be more specific, we benchmark our proposed model on a large scale
inner-source dataset (160k hours), the results show that we can scale our
baseline Conformer (Dense-225M) to its MoE counterparts (MoE-1B) and achieve
Dense-1B level Word Error Rate (WER) while maintaining a Dense-225M level Real
Time Factor (RTF). Furthermore, by applying Unified 2-pass framework with
bidirectional attention decoders (U2++), we achieve the streaming and
non-streaming decoding modes in a single MoE based model, which we call U2++
MoE. We hope that our study can facilitate the research on scaling speech
foundation models without sacrificing deployment efficiency.",2024-04-25,"Xingchen Song, Di Wu, Binbin Zhang, Dinghao Zhou, Zhendong Peng, Bo Dang, Fuping Pan, Chao Yang",http://arxiv.org/pdf/2404.16407v2,cs.CL
Lost in Recursion: Mining Rich Event Semantics in Knowledge Graphs,"Our world is shaped by events of various complexity. This includes both
small-scale local events like local farmer markets and large complex events
like political and military conflicts. The latter are typically not observed
directly but through the lenses of intermediaries like newspapers or social
media. In other words, we do not witness the unfolding of such events directly
but are confronted with narratives surrounding them. Such narratives capture
different aspects of a complex event and may also differ with respect to the
narrator. Thus, they provide a rich semantics concerning real-world events. In
this paper, we show how narratives concerning complex events can be constructed
and utilized. We provide a formal representation of narratives based on
recursive nodes to represent multiple levels of detail and discuss how
narratives can be bound to event-centric knowledge graphs. Additionally, we
provide an algorithm based on incremental prompting techniques that mines such
narratives from texts to account for different perspectives on complex events.
Finally, we show the effectiveness and future research directions in a proof of
concept.",2024-04-25,"Florian Plötzky, Niklas Kiehne, Wolf-Tilo Balke",http://arxiv.org/pdf/2404.16405v1,cs.CL
List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs,"Set-of-Mark (SoM) Prompting unleashes the visual grounding capability of
GPT-4V, by enabling the model to associate visual objects with tags inserted on
the image. These tags, marked with alphanumerics, can be indexed via text
tokens for easy reference. Despite the extraordinary performance from GPT-4V,
we observe that other Multimodal Large Language Models (MLLMs) struggle to
understand these visual tags. To promote the learning of SoM prompting for
open-source models, we propose a new learning paradigm: ""list items one by
one,"" which asks the model to enumerate and describe all visual tags placed on
the image following the alphanumeric orders of tags. By integrating our curated
dataset with other visual instruction tuning datasets, we are able to equip
existing MLLMs with the SoM prompting ability. Furthermore, we evaluate our
finetuned SoM models on five MLLM benchmarks. We find that this new dataset,
even in a relatively small size (10k-30k images with tags), significantly
enhances visual reasoning capabilities and reduces hallucinations for MLLMs.
Perhaps surprisingly, these improvements persist even when the visual tags are
omitted from input images during inference. This suggests the potential of
""list items one by one"" as a new paradigm for training MLLMs, which strengthens
the object-text alignment through the use of visual tags in the training stage.
Finally, we conduct analyses by probing trained models to understand the
working mechanism of SoM. Our code and data are available at
\url{https://github.com/zzxslp/SoM-LLaVA}.",2024-04-25,"An Yan, Zhengyuan Yang, Junda Wu, Wanrong Zhu, Jianwei Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Julian McAuley, Jianfeng Gao, Lijuan Wang",http://arxiv.org/pdf/2404.16375v2,cs.CL
Don't Say No: Jailbreaking LLM by Suppressing Refusal,"Ensuring the safety alignment of Large Language Models (LLMs) is crucial to
generating responses consistent with human values. Despite their ability to
recognize and avoid harmful queries, LLMs are vulnerable to jailbreaking
attacks, where carefully crafted prompts seduce them to produce toxic content.
One category of jailbreak attacks is reformulating the task as an optimization
by eliciting the LLM to generate affirmative responses. However, such
optimization objective has its own limitations, such as the restriction on the
predefined objectionable behaviors, leading to suboptimal attack performance.
In this study, we first uncover the reason why vanilla target loss is not
optimal, then we explore and enhance the loss objective and introduce the DSN
(Don't Say No) attack, which achieves successful attack by suppressing refusal.
Another challenge in studying jailbreak attacks is the evaluation, as it is
difficult to directly and accurately assess the harmfulness of the responses.
The existing evaluation such as refusal keyword matching reveals numerous false
positive and false negative instances. To overcome this challenge, we propose
an Ensemble Evaluation pipeline that novelly incorporates Natural Language
Inference (NLI) contradiction assessment and two external LLM evaluators.
Extensive experiments demonstrate the potential of the DSN and effectiveness of
Ensemble Evaluation compared to baseline methods.",2024-04-25,"Yukai Zhou, Zhijie Huang, Feiyang Lu, Zhan Qin, Wenjie Wang",http://arxiv.org/pdf/2404.16369v2,cs.CL
Learning Syntax Without Planting Trees: Understanding Hierarchical Generalization in Transformers,"Transformers trained on natural language data have been shown to learn its
hierarchical structure and generalize to sentences with unseen syntactic
structures without explicitly encoding any structural bias. In this work, we
investigate sources of inductive bias in transformer models and their training
that could cause such generalization behavior to emerge. We extensively
experiment with transformer models trained on multiple synthetic datasets and
with different training objectives and show that while other objectives e.g.
sequence-to-sequence modeling, prefix language modeling, often failed to lead
to hierarchical generalization, models trained with the language modeling
objective consistently learned to generalize hierarchically. We then conduct
pruning experiments to study how transformers trained with the language
modeling objective encode hierarchical structure. When pruned, we find joint
existence of subnetworks within the model with different generalization
behaviors (subnetworks corresponding to hierarchical structure and linear
order). Finally, we take a Bayesian perspective to further uncover
transformers' preference for hierarchical generalization: We establish a
correlation between whether transformers generalize hierarchically on a dataset
and whether the simplest explanation of that dataset is provided by a
hierarchical grammar compared to regular grammars exhibiting linear
generalization.",2024-04-25,"Kabir Ahuja, Vidhisha Balachandran, Madhur Panwar, Tianxing He, Noah A. Smith, Navin Goyal, Yulia Tsvetkov",http://arxiv.org/pdf/2404.16367v3,cs.CL
VISLA Benchmark: Evaluating Embedding Sensitivity to Semantic and Lexical Alterations,"Despite their remarkable successes, state-of-the-art language models face
challenges in grasping certain important semantic details. This paper
introduces the VISLA (Variance and Invariance to Semantic and Lexical
Alterations) benchmark, designed to evaluate the semantic and lexical
understanding of language models. VISLA presents a 3-way semantic
(in)equivalence task with a triplet of sentences associated with an image, to
evaluate both vision-language models (VLMs) and unimodal language models
(ULMs). An evaluation involving 34 VLMs and 20 ULMs reveals surprising
difficulties in distinguishing between lexical and semantic variations. Spatial
semantics encoded by language models also appear to be highly sensitive to
lexical information. Notably, text encoders of VLMs demonstrate greater
sensitivity to semantic and lexical variations than unimodal text encoders. Our
contributions include the unification of image-to-text and text-to-text
retrieval tasks, an off-the-shelf evaluation without fine-tuning, and assessing
LMs' semantic (in)variance in the presence of lexical alterations. The results
highlight strengths and weaknesses across diverse vision and unimodal language
models, contributing to a deeper understanding of their capabilities. % VISLA
enables a rigorous evaluation, shedding light on language models' capabilities
in handling semantic and lexical nuances. Data and code will be made available
at https://github.com/Sri-Harsha/visla_benchmark.",2024-04-25,"Sri Harsha Dumpala, Aman Jaiswal, Chandramouli Sastry, Evangelos Milios, Sageev Oore, Hassan Sajjad",http://arxiv.org/pdf/2404.16365v1,cs.CL
PILA: A Historical-Linguistic Dataset of Proto-Italic and Latin,"Computational historical linguistics seeks to systematically understand
processes of sound change, including during periods at which little to no
formal recording of language is attested. At the same time, few computational
resources exist which deeply explore phonological and morphological connections
between proto-languages and their descendants. This is particularly true for
the family of Italic languages. To assist historical linguists in the study of
Italic sound change, we introduce the Proto-Italic to Latin (PILA) dataset,
which consists of roughly 3,000 pairs of forms from Proto-Italic and Latin. We
provide a detailed description of how our dataset was created and organized.
Then, we exhibit PILA's value in two ways. First, we present baseline results
for PILA on a pair of traditional computational historical linguistics tasks.
Second, we demonstrate PILA's capability for enhancing other
historical-linguistic datasets through a dataset compatibility study.",2024-04-25,"Stephen Bothwell, Brian DuSell, David Chiang, Brian Krostenko",http://arxiv.org/pdf/2404.16341v1,cs.CL
Digital ASIC Design with Ongoing LLMs: Strategies and Prospects,"The escalating complexity of modern digital systems has imposed significant
challenges on integrated circuit (IC) design, necessitating tools that can
simplify the IC design flow. The advent of Large Language Models (LLMs) has
been seen as a promising development, with the potential to automate the
generation of Hardware Description Language (HDL) code, thereby streamlining
digital IC design. However, the practical application of LLMs in this area
faces substantial hurdles. Notably, current LLMs often generate HDL code with
small but critical syntax errors and struggle to accurately convey the
high-level semantics of circuit designs. These issues significantly undermine
the utility of LLMs for IC design, leading to misinterpretations and
inefficiencies.
  In response to these challenges, this paper presents targeted strategies to
harness the capabilities of LLMs for digital ASIC design. We outline approaches
that improve the reliability and accuracy of HDL code generation by LLMs. As a
practical demonstration of these strategies, we detail the development of a
simple three-phase Pulse Width Modulation (PWM) generator. This project, part
of the ""Efabless AI-Generated Open-Source Chip Design Challenge,"" successfully
passed the Design Rule Check (DRC) and was fabricated, showcasing the potential
of LLMs to enhance digital ASIC design. This work underscores the feasibility
and benefits of integrating LLMs into the IC design process, offering a novel
approach to overcoming the complexities of modern digital systems.",2024-04-25,"Maoyang Xiang, Emil Goh, T. Hui Teo",http://arxiv.org/pdf/2405.02329v1,cs.CL
"Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of Theories, Detection Methods, and Opportunities","In recent years, generative artificial intelligence models, represented by
Large Language Models (LLMs) and Diffusion Models (DMs), have revolutionized
content production methods. These artificial intelligence-generated content
(AIGC) have become deeply embedded in various aspects of daily life and work.
However, these technologies have also led to the emergence of Fake Artificial
Intelligence Generated Content (FAIGC), posing new challenges in distinguishing
genuine information. It is crucial to recognize that AIGC technology is akin to
a double-edged sword; its potent generative capabilities, while beneficial,
also pose risks for the creation and dissemination of FAIGC. In this survey, We
propose a new taxonomy that provides a more comprehensive breakdown of the
space of FAIGC methods today. Next, we explore the modalities and generative
technologies of FAIGC. We introduce FAIGC detection methods and summarize the
related benchmark from various perspectives. Finally, we discuss outstanding
challenges and promising areas for future research.",2024-04-25,"Xiaomin Yu, Yezhaohui Wang, Yanfang Chen, Zhen Tao, Dinghao Xi, Shichao Song, Simin Niu, Zhiyu Li",http://arxiv.org/pdf/2405.00711v2,cs.CL
WorldValuesBench: A Large-Scale Benchmark Dataset for Multi-Cultural Value Awareness of Language Models,"The awareness of multi-cultural human values is critical to the ability of
language models (LMs) to generate safe and personalized responses. However,
this awareness of LMs has been insufficiently studied, since the computer
science community lacks access to the large-scale real-world data about
multi-cultural values. In this paper, we present WorldValuesBench, a globally
diverse, large-scale benchmark dataset for the multi-cultural value prediction
task, which requires a model to generate a rating response to a value question
based on demographic contexts. Our dataset is derived from an influential
social science project, World Values Survey (WVS), that has collected answers
to hundreds of value questions (e.g., social, economic, ethical) from 94,728
participants worldwide. We have constructed more than 20 million examples of
the type ""(demographic attributes, value question) $\rightarrow$ answer"" from
the WVS responses. We perform a case study using our dataset and show that the
task is challenging for strong open and closed-source models. On merely
$11.1\%$, $25.0\%$, $72.2\%$, and $75.0\%$ of the questions, Alpaca-7B,
Vicuna-7B-v1.5, Mixtral-8x7B-Instruct-v0.1, and GPT-3.5 Turbo can respectively
achieve $<0.2$ Wasserstein 1-distance from the human normalized answer
distributions. WorldValuesBench opens up new research avenues in studying
limitations and opportunities in multi-cultural value awareness of LMs.",2024-04-25,"Wenlong Zhao, Debanjan Mondal, Niket Tandon, Danica Dillion, Kurt Gray, Yuling Gu",http://arxiv.org/pdf/2404.16308v1,cs.CL
LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications,"Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.",2024-04-25,"Saranya Krishnamoorthy, Ayush Singh, Shabnam Tafreshi",http://arxiv.org/pdf/2404.16294v1,cs.CL
SetCSE: Set Operations using Contrastive Learning of Sentence Embeddings,"Taking inspiration from Set Theory, we introduce SetCSE, an innovative
information retrieval framework. SetCSE employs sets to represent complex
semantics and incorporates well-defined operations for structured information
querying under the provided context. Within this framework, we introduce an
inter-set contrastive learning objective to enhance comprehension of sentence
embedding models concerning the given semantics. Furthermore, we present a
suite of operations, including SetCSE intersection, difference, and operation
series, that leverage sentence embeddings of the enhanced model for complex
sentence retrieval tasks. Throughout this paper, we demonstrate that SetCSE
adheres to the conventions of human language expressions regarding compounded
semantics, provides a significant enhancement in the discriminatory capability
of underlying sentence embedding models, and enables numerous information
retrieval tasks involving convoluted and intricate prompts which cannot be
achieved using existing querying methods.",2024-04-25,Kang Liu,http://arxiv.org/pdf/2404.17606v1,cs.CL
Interpreting Answers to Yes-No Questions in Dialogues from Multiple Domains,"People often answer yes-no questions without explicitly saying yes, no, or
similar polar keywords. Figuring out the meaning of indirect answers is
challenging, even for large language models. In this paper, we investigate this
problem working with dialogues from multiple domains. We present new benchmarks
in three diverse domains: movie scripts, tennis interviews, and airline
customer service. We present an approach grounded on distant supervision and
blended training to quickly adapt to a new dialogue domain. Experimental
results show that our approach is never detrimental and yields F1 improvements
as high as 11-34%.",2024-04-25,"Zijie Wang, Farzana Rashid, Eduardo Blanco",http://arxiv.org/pdf/2404.16262v1,cs.CL
Translation of Multifaceted Data without Re-Training of Machine Translation Systems,"Translating major language resources to build minor language resources
becomes a widely-used approach. Particularly in translating complex data points
composed of multiple components, it is common to translate each component
separately. However, we argue that this practice often overlooks the
interrelation between components within the same data point. To address this
limitation, we propose a novel MT pipeline that considers the intra-data
relation in implementing MT for training data. In our MT pipeline, all the
components in a data point are concatenated to form a single translation
sequence and subsequently reconstructed to the data components after
translation. We introduce a Catalyst Statement (CS) to enhance the intra-data
relation, and Indicator Token (IT) to assist the decomposition of a translated
sequence into its respective data components. Through our approach, we have
achieved a considerable improvement in translation quality itself, along with
its effectiveness as training data. Compared with the conventional approach
that translates each data component separately, our method yields better
training data that enhances the performance of the trained model by 2.690
points for the web page ranking (WPR) task, and 0.845 for the question
generation (QG) task in the XGLUE benchmark.",2024-04-25,"Hyeonseok Moon, Seungyoon Lee, Seongtae Hong, Seungjun Lee, Chanjun Park, Heuiseok Lim",http://arxiv.org/pdf/2404.16257v2,cs.CL
Prompt Leakage effect and defense strategies for multi-turn LLM interactions,"Prompt leakage poses a compelling security and privacy threat in LLM
applications. Leakage of system prompts may compromise intellectual property,
and act as adversarial reconnaissance for an attacker. A systematic evaluation
of prompt leakage threats and mitigation strategies is lacking, especially for
multi-turn LLM interactions. In this paper, we systematically investigate LLM
vulnerabilities against prompt leakage for 10 closed- and open-source LLMs,
across four domains. We design a unique threat model which leverages the LLM
sycophancy effect and elevates the average attack success rate (ASR) from 17.7%
to 86.2% in a multi-turn setting. Our standardized setup further allows
dissecting leakage of specific prompt contents such as task instructions and
knowledge documents. We measure the mitigation effect of 7 black-box defense
strategies, along with finetuning an open-source model to defend against
leakage attempts. We present different combination of defenses against our
threat model, including a cost analysis. Our study highlights key takeaways for
building secure LLM applications and provides directions for research in
multi-turn LLM interactions",2024-04-24,"Divyansh Agarwal, Alexander R. Fabbri, Ben Risher, Philippe Laban, Shafiq Joty, Chien-Sheng Wu",http://arxiv.org/pdf/2404.16251v3,cs.CL
"Semgrex and Ssurgeon, Searching and Manipulating Dependency Graphs","Searching dependency graphs and manipulating them can be a time consuming and
challenging task to get right. We document Semgrex, a system for searching
dependency graphs, and introduce Ssurgeon, a system for manipulating the output
of Semgrex. The compact language used by these systems allows for easy command
line or API processing of dependencies. Additionally, integration with publicly
released toolkits in Java and Python allows for searching text relations and
attributes over natural text.",2024-04-24,"John Bauer, Chloe Kiddon, Eric Yeh, Alex Shan, Christopher D. Manning",http://arxiv.org/pdf/2404.16250v1,cs.CL
URL: Universal Referential Knowledge Linking via Task-instructed Representation Compression,"Linking a claim to grounded references is a critical ability to fulfill human
demands for authentic and reliable information. Current studies are limited to
specific tasks like information retrieval or semantic matching, where the
claim-reference relationships are unique and fixed, while the referential
knowledge linking (RKL) in real-world can be much more diverse and complex. In
this paper, we propose universal referential knowledge linking (URL), which
aims to resolve diversified referential knowledge linking tasks by one unified
model. To this end, we propose a LLM-driven task-instructed representation
compression, as well as a multi-view learning approach, in order to effectively
adapt the instruction following and semantic understanding abilities of LLMs to
referential knowledge linking. Furthermore, we also construct a new benchmark
to evaluate ability of models on referential knowledge linking tasks across
different scenarios. Experiments demonstrate that universal RKL is challenging
for existing approaches, while the proposed framework can effectively resolve
the task across various scenarios, and therefore outperforms previous
approaches by a large margin.",2024-04-24,"Zhuoqun Li, Hongyu Lin, Tianshu Wang, Boxi Cao, Yaojie Lu, Weixiang Zhou, Hao Wang, Zhenyu Zeng, Le Sun, Xianpei Han",http://arxiv.org/pdf/2404.16248v1,cs.CL
Computational analysis of the language of pain: a systematic review,"Objectives: This study aims to systematically review the literature on the
computational processing of the language of pain, or pain narratives, whether
generated by patients or physicians, identifying current trends and challenges.
Methods: Following the PRISMA guidelines, a comprehensive literature search was
conducted to select relevant studies on the computational processing of the
language of pain and answer pre-defined research questions. Data extraction and
synthesis were performed to categorize selected studies according to their
primary purpose and outcome, patient and pain population, textual data,
computational methodology, and outcome targets. Results: Physician-generated
language of pain, specifically from clinical notes, was the most used data.
Tasks included patient diagnosis and triaging, identification of pain mentions,
treatment response prediction, biomedical entity extraction, correlation of
linguistic features with clinical states, and lexico-semantic analysis of pain
narratives. Only one study included previous linguistic knowledge on pain
utterances in their experimental setup. Most studies targeted their outcomes
for physicians, either directly as clinical tools or as indirect knowledge. The
least targeted stage of clinical pain care was self-management, in which
patients are most involved. Affective and sociocultural dimensions were the
least studied domains. Only one study measured how physician performance on
clinical tasks improved with the inclusion of the proposed algorithm.
Discussion: This review found that future research should focus on analyzing
patient-generated language of pain, developing patient-centered resources for
self-management and patient-empowerment, exploring affective and sociocultural
aspects of pain, and measuring improvements in physician performance when aided
by the proposed tools.",2024-04-24,"Diogo A. P. Nunes, Joana Ferreira-Gomes, Fani Neto, David Martins de Matos",http://arxiv.org/pdf/2404.16226v2,cs.CL
Homonym Sense Disambiguation in the Georgian Language,"This research proposes a novel approach to the Word Sense Disambiguation
(WSD) task in the Georgian language, based on supervised fine-tuning of a
pre-trained Large Language Model (LLM) on a dataset formed by filtering the
Georgian Common Crawls corpus. The dataset is used to train a classifier for
words with multiple senses. Additionally, we present experimental results of
using LSTM for WSD. Accurately disambiguating homonyms is crucial in natural
language processing. Georgian, an agglutinative language belonging to the
Kartvelian language family, presents unique challenges in this context. The aim
of this paper is to highlight the specific problems concerning homonym
disambiguation in the Georgian language and to present our approach to solving
them. The techniques discussed in the article achieve 95% accuracy for
predicting lexical meanings of homonyms using a hand-classified dataset of over
7500 sentences.",2024-04-24,"Davit Melikidze, Alexander Gamkrelidze",http://arxiv.org/pdf/2405.00710v1,cs.CL
Knowledge Graph Completion using Structural and Textual Embeddings,"Knowledge Graphs (KGs) are widely employed in artificial intelligence
applications, such as question-answering and recommendation systems. However,
KGs are frequently found to be incomplete. While much of the existing
literature focuses on predicting missing nodes for given incomplete KG triples,
there remains an opportunity to complete KGs by exploring relations between
existing nodes, a task known as relation prediction. In this study, we propose
a relations prediction model that harnesses both textual and structural
information within KGs. Our approach integrates walks-based embeddings with
language model embeddings to effectively represent nodes. We demonstrate that
our model achieves competitive results in the relation prediction task when
evaluated on a widely used dataset.",2024-04-24,"Sakher Khalil Alqaaidi, Krzysztof Kochut",http://arxiv.org/pdf/2404.16206v1,cs.CL
Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses,"While small businesses are increasingly turning to online crowdfunding
platforms for essential funding, over 40% of these campaigns may fail to raise
any money, especially those from low socio-economic areas. We utilize the
latest advancements in AI technology to identify crucial factors that influence
the success of crowdfunding campaigns and to improve their fundraising outcomes
by strategically optimizing these factors. Our best-performing machine learning
model accurately predicts the fundraising outcomes of 81.0% of campaigns,
primarily based on their textual descriptions. Interpreting the machine
learning model allows us to provide actionable suggestions on improving the
textual description before launching a campaign. We demonstrate that by
augmenting just three aspects of the narrative using a large language model, a
campaign becomes more preferable to 83% human evaluators, and its likelihood of
securing financial support increases by 11.9%. Our research uncovers the
effective strategies for crafting descriptions for small business fundraising
campaigns and opens up a new realm in integrating large language models into
crowdfunding methodologies.",2024-04-24,"Teng Ye, Jingnan Zheng, Junhui Jin, Jingyi Qiu, Wei Ai, Qiaozhu Mei",http://arxiv.org/pdf/2407.09480v1,cs.CL
Towards Efficient Patient Recruitment for Clinical Trials: Application of a Prompt-Based Learning Model,"Objective: Clinical trials are essential for advancing pharmaceutical
interventions, but they face a bottleneck in selecting eligible participants.
Although leveraging electronic health records (EHR) for recruitment has gained
popularity, the complex nature of unstructured medical texts presents
challenges in efficiently identifying participants. Natural Language Processing
(NLP) techniques have emerged as a solution with a recent focus on transformer
models. In this study, we aimed to evaluate the performance of a prompt-based
large language model for the cohort selection task from unstructured medical
notes collected in the EHR. Methods: To process the medical records, we
selected the most related sentences of the records to the eligibility criteria
needed for the trial. The SNOMED CT concepts related to each eligibility
criterion were collected. Medical records were also annotated with MedCAT based
on the SNOMED CT ontology. Annotated sentences including concepts matched with
the criteria-relevant terms were extracted. A prompt-based large language model
(Generative Pre-trained Transformer (GPT) in this study) was then used with the
extracted sentences as the training set. To assess its effectiveness, we
evaluated the model's performance using the dataset from the 2018 n2c2
challenge, which aimed to classify medical records of 311 patients based on 13
eligibility criteria through NLP techniques. Results: Our proposed model showed
the overall micro and macro F measures of 0.9061 and 0.8060 which were among
the highest scores achieved by the experiments performed with this dataset.
Conclusion: The application of a prompt-based large language model in this
study to classify patients based on eligibility criteria received promising
scores. Besides, we proposed a method of extractive summarization with the aid
of SNOMED CT ontology that can be also applied to other medical texts.",2024-04-24,"Mojdeh Rahmanian, Seyed Mostafa Fakhrahmad, Seyedeh Zahra Mousavi",http://arxiv.org/pdf/2404.16198v1,cs.CL
Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering,"Vision-language models, while effective in general domains and showing strong
performance in diverse multi-modal applications like visual question-answering
(VQA), struggle to maintain the same level of effectiveness in more specialized
domains, e.g., medical. We propose a medical vision-language model that
integrates large vision and language models adapted for the medical domain.
This model goes through three stages of parameter-efficient training using
three separate biomedical and radiology multi-modal visual and text datasets.
The proposed model achieves state-of-the-art performance on the SLAKE 1.0
medical VQA (MedVQA) dataset with an overall accuracy of 87.5% and demonstrates
strong performance on another MedVQA dataset, VQA-RAD, achieving an overall
accuracy of 73.2%.",2024-04-24,"Cuong Nhat Ha, Shima Asaadi, Sanjeev Kumar Karn, Oladimeji Farri, Tobias Heimann, Thomas Runkler",http://arxiv.org/pdf/2404.16192v1,cs.CL
Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks,"We investigate the use of Natural Language Inference (NLI) in automating
requirements engineering tasks. In particular, we focus on three tasks:
requirements classification, identification of requirements specification
defects, and detection of conflicts in stakeholders' requirements. While
previous research has demonstrated significant benefit in using NLI as a
universal method for a broad spectrum of natural language processing tasks,
these advantages have not been investigated within the context of software
requirements engineering. Therefore, we design experiments to evaluate the use
of NLI in requirements analysis. We compare the performance of NLI with a
spectrum of approaches, including prompt-based models, conventional transfer
learning, Large Language Models (LLMs)-powered chatbot models, and
probabilistic models. Through experiments conducted under various learning
settings including conventional learning and zero-shot, we demonstrate
conclusively that our NLI method surpasses classical NLP methods as well as
other LLMs-based and chatbot models in the analysis of requirements
specifications. Additionally, we share lessons learned characterizing the
learning settings that make NLI a suitable approach for automating requirements
engineering tasks.",2024-04-24,"Mohamad Fazelnia, Viktoria Koscinski, Spencer Herzog, Mehdi Mirakhorli",http://arxiv.org/pdf/2405.05135v1,cs.CL
Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall,"Large language models (LLMs) have shown remarkable performance on a variety
of NLP tasks, and are being rapidly adopted in a wide range of use cases. It is
therefore of vital importance to holistically evaluate the factuality of their
generated outputs, as hallucinations remain a challenging issue.
  In this work, we focus on assessing LLMs' ability to recall factual knowledge
learned from pretraining, and the factors that affect this ability. To that
end, we construct FACT-BENCH, a representative benchmark covering 20 domains,
134 property types, 3 answer types, and different knowledge popularity levels.
We benchmark 31 models from 10 model families and provide a holistic assessment
of their strengths and weaknesses. We observe that instruction-tuning hurts
knowledge recall, as pretraining-only models consistently outperform their
instruction-tuned counterparts, and positive effects of model scaling, as
larger models outperform smaller ones for all model families. However, the best
performance from GPT-4 still represents a large gap with the upper-bound. We
additionally study the role of in-context exemplars using counterfactual
demonstrations, which lead to significant degradation of factual knowledge
recall for large models. By further decoupling model known and unknown
knowledge, we find the degradation is attributed to exemplars that contradict a
model's known knowledge, as well as the number of such exemplars. Lastly, we
fine-tune LLaMA-7B in different settings of known and unknown knowledge. In
particular, fine-tuning on a model's known knowledge is beneficial, and
consistently outperforms fine-tuning on unknown and mixed knowledge. We will
make our benchmark publicly available.",2024-04-24,"Jiaqing Yuan, Lin Pan, Chung-Wei Hang, Jiang Guo, Jiarong Jiang, Bonan Min, Patrick Ng, Zhiguo Wang",http://arxiv.org/pdf/2404.16164v1,cs.CL
Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant,"Large language models (LLMs) have demonstrated impressive generalization
capabilities on specific tasks with human-written instruction data. However,
the limited quantity, diversity, and professional expertise of such instruction
data raise concerns about the performance of LLMs in psychotherapy tasks when
provided with domain-specific instructions. To address this, we firstly propose
Domain-Specific Assistant Instructions based on AlexanderStreet therapy, and
secondly, we use an adaption fine-tuning method and retrieval augmented
generation method to improve pre-trained LLMs. Through quantitative evaluation
of linguistic quality using automatic and human evaluation, we observe that
pre-trained LLMs on Psychotherapy Assistant Instructions outperform
state-of-the-art LLMs response baselines. Our Assistant-Instruction approach
offers a half-annotation method to align pre-trained LLMs with instructions and
provide pre-trained LLMs with more psychotherapy knowledge.",2024-04-24,"Cheng Kang, Daniel Novak, Katerina Urbanova, Yuqing Cheng, Yong Hu",http://arxiv.org/pdf/2404.16160v2,cs.CL
Attacks on Third-Party APIs of Large Language Models,"Large language model (LLM) services have recently begun offering a plugin
ecosystem to interact with third-party API services. This innovation enhances
the capabilities of LLMs, but it also introduces risks, as these plugins
developed by various third parties cannot be easily trusted. This paper
proposes a new attacking framework to examine security and safety
vulnerabilities within LLM platforms that incorporate third-party services.
Applying our framework specifically to widely used LLMs, we identify real-world
malicious attacks across various domains on third-party APIs that can
imperceptibly modify LLM outputs. The paper discusses the unique challenges
posed by third-party API integration and offers strategic possibilities to
improve the security and safety of LLM ecosystems moving forward. Our code is
released at https://github.com/vk0812/Third-Party-Attacks-on-LLMs.",2024-04-24,"Wanru Zhao, Vidit Khazanchi, Haodi Xing, Xuanli He, Qiongkai Xu, Nicholas Donald Lane",http://arxiv.org/pdf/2404.16891v1,cs.CL
From Local to Global: A Graph RAG Approach to Query-Focused Summarization,"The use of retrieval-augmented generation (RAG) to retrieve relevant
information from an external knowledge source enables large language models
(LLMs) to answer questions over private and/or previously unseen document
collections. However, RAG fails on global questions directed at an entire text
corpus, such as ""What are the main themes in the dataset?"", since this is
inherently a query-focused summarization (QFS) task, rather than an explicit
retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of
text indexed by typical RAG systems. To combine the strengths of these
contrasting methods, we propose GraphRAG, a graph-based approach to question
answering over private text corpora that scales with both the generality of
user questions and the quantity of source text. Our approach uses an LLM to
build a graph index in two stages: first, to derive an entity knowledge graph
from the source documents, then to pregenerate community summaries for all
groups of closely related entities. Given a question, each community summary is
used to generate a partial response, before all partial responses are again
summarized in a final response to the user. For a class of global sensemaking
questions over datasets in the 1 million token range, we show that GraphRAG
leads to substantial improvements over a conventional RAG baseline for both the
comprehensiveness and diversity of generated answers.",2024-04-24,"Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, Jonathan Larson",http://arxiv.org/pdf/2404.16130v2,cs.CL
FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication,"Recent dataset deduplication techniques have demonstrated that content-aware
dataset pruning can dramatically reduce the cost of training Vision-Language
Pretrained (VLP) models without significant performance losses compared to
training on the original dataset. These results have been based on pruning
commonly used image-caption datasets collected from the web -- datasets that
are known to harbor harmful social biases that may then be codified in trained
models. In this work, we evaluate how deduplication affects the prevalence of
these biases in the resulting trained models and introduce an easy-to-implement
modification to the recent SemDeDup algorithm that can reduce the negative
effects that we observe. When examining CLIP-style models trained on
deduplicated variants of LAION-400M, we find our proposed FairDeDup algorithm
consistently leads to improved fairness metrics over SemDeDup on the FairFace
and FACET datasets while maintaining zero-shot performance on CLIP benchmarks.",2024-04-24,"Eric Slyman, Stefan Lee, Scott Cohen, Kushal Kafle",http://arxiv.org/pdf/2404.16123v1,cs.CL
Integrating LSTM and BERT for Long-Sequence Data Analysis in Intelligent Tutoring Systems,"The field of Knowledge Tracing aims to understand how students learn and
master knowledge over time by analyzing their historical behaviour data. To
achieve this goal, many researchers have proposed Knowledge Tracing models that
use data from Intelligent Tutoring Systems to predict students' subsequent
actions. However, with the development of Intelligent Tutoring Systems,
large-scale datasets containing long-sequence data began to emerge. Recent deep
learning based Knowledge Tracing models face obstacles such as low efficiency,
low accuracy, and low interpretability when dealing with large-scale datasets
containing long-sequence data. To address these issues and promote the
sustainable development of Intelligent Tutoring Systems, we propose a LSTM
BERT-based Knowledge Tracing model for long sequence data processing, namely
LBKT, which uses a BERT-based architecture with a Rasch model-based embeddings
block to deal with different difficulty levels information and an LSTM block to
process the sequential characteristic in students' actions. LBKT achieves the
best performance on most benchmark datasets on the metrics of ACC and AUC.
Additionally, an ablation study is conducted to analyse the impact of each
component of LBKT's overall performance. Moreover, we used t-SNE as the
visualisation tool to demonstrate the model's embedding strategy. The results
indicate that LBKT is faster, more interpretable, and has a lower memory cost
than the traditional deep learning based Knowledge Tracing methods.",2024-04-24,"Zhaoxing Li, Jujie Yang, Jindi Wang, Lei Shi, Sebastian Stein",http://arxiv.org/pdf/2405.05136v1,cs.CL
Classifying Human-Generated and AI-Generated Election Claims in Social Media,"Politics is one of the most prevalent topics discussed on social media
platforms, particularly during major election cycles, where users engage in
conversations about candidates and electoral processes. Malicious actors may
use this opportunity to disseminate misinformation to undermine trust in the
electoral process. The emergence of Large Language Models (LLMs) exacerbates
this issue by enabling malicious actors to generate misinformation at an
unprecedented scale. Artificial intelligence (AI)-generated content is often
indistinguishable from authentic user content, raising concerns about the
integrity of information on social networks. In this paper, we present a novel
taxonomy for characterizing election-related claims. This taxonomy provides an
instrument for analyzing election-related claims, with granular categories
related to jurisdiction, equipment, processes, and the nature of claims. We
introduce ElectAI, a novel benchmark dataset that consists of 9,900 tweets,
each labeled as human- or AI-generated. For AI-generated tweets, the specific
LLM variant that produced them is specified. We annotated a subset of 1,550
tweets using the proposed taxonomy to capture the characteristics of
election-related claims. We explored the capabilities of LLMs in extracting the
taxonomy attributes and trained various machine learning models using ElectAI
to distinguish between human- and AI-generated posts and identify the specific
LLM variant.",2024-04-24,"Alphaeus Dmonte, Marcos Zampieri, Kevin Lybarger, Massimiliano Albanese, Genya Coulter",http://arxiv.org/pdf/2404.16116v2,cs.CL
Online Personalizing White-box LLMs Generation with Neural Bandits,"The advent of personalized content generation by LLMs presents a novel
challenge: how to efficiently adapt text to meet individual preferences without
the unsustainable demand of creating a unique model for each user. This study
introduces an innovative online method that employs neural bandit algorithms to
dynamically optimize soft instruction embeddings based on user feedback,
enhancing the personalization of open-ended text generation by white-box LLMs.
Through rigorous experimentation on various tasks, we demonstrate significant
performance improvements over baseline strategies. NeuralTS, in particular,
leads to substantial enhancements in personalized news headline generation,
achieving up to a 62.9% improvement in terms of best ROUGE scores and up to
2.76% increase in LLM-agent evaluation against the baseline.",2024-04-24,"Zekai Chen, Weeden Daniel, Po-yu Chen, Francois Buet-Golfouse",http://arxiv.org/pdf/2404.16115v1,cs.CL
Evolution of Voices in French Audiovisual Media Across Genders and Age in a Diachronic Perspective,"We present a diachronic acoustic analysis of the voice of 1023 speakers from
French media archives. The speakers are spread across 32 categories based on
four periods (years 1955/56, 1975/76, 1995/96, 2015/16), four age groups
(20-35; 36-50; 51-65, >65), and two genders. The fundamental frequency ($F_0$)
and the first four formants (F1-4) were estimated. Procedures used to ensure
the quality of these estimations on heterogeneous data are described. From each
speaker's $F_0$ distribution, the base-$F_0$ value was calculated to estimate
the register. Average vocal tract length was estimated from formant
frequencies. Base-$F_0$ and vocal tract length were fit by linear mixed models
to evaluate how they may have changed across time periods and genders,
corrected for age effects. Results show an effect of the period with a tendency
to lower voices, independently of gender. A lowering of pitch is observed with
age for female but not male speakers.",2024-04-24,"Albert Rilliard, David Doukhan, Rémi Uro, Simon Devauchelle",http://arxiv.org/pdf/2404.16104v1,cs.CL
Cantor: Inspiring Multimodal Chain-of-Thought of MLLM,"With the advent of large language models(LLMs) enhanced by the
chain-of-thought(CoT) methodology, visual reasoning problem is usually
decomposed into manageable sub-tasks and tackled sequentially with various
external tools. However, such a paradigm faces the challenge of the potential
""determining hallucinations"" in decision-making due to insufficient visual
information and the limitation of low-level perception tools that fail to
provide abstract summaries necessary for comprehensive reasoning. We argue that
converging visual context acquisition and logical reasoning is pivotal for
tackling visual reasoning tasks. This paper delves into the realm of multimodal
CoT to solve intricate visual reasoning tasks with multimodal large language
models(MLLMs) and their cognitive capability. To this end, we propose an
innovative multimodal CoT framework, termed Cantor, characterized by a
perception-decision architecture. Cantor first acts as a decision generator and
integrates visual inputs to analyze the image and problem, ensuring a closer
alignment with the actual context. Furthermore, Cantor leverages the advanced
cognitive functions of MLLMs to perform as multifaceted experts for deriving
higher-level information, enhancing the CoT generation process. Our extensive
experiments demonstrate the efficacy of the proposed framework, showing
significant improvements in multimodal CoT performance across two complex
visual reasoning datasets, without necessitating fine-tuning or ground-truth
rationales. Project Page: https://ggg0919.github.io/cantor/ .",2024-04-24,"Timin Gao, Peixian Chen, Mengdan Zhang, Chaoyou Fu, Yunhang Shen, Yan Zhang, Shengchuan Zhang, Xiawu Zheng, Xing Sun, Liujuan Cao, Rongrong Ji",http://arxiv.org/pdf/2404.16033v1,cs.CL
MoDE: CLIP Data Experts via Clustering,"The success of contrastive language-image pretraining (CLIP) relies on the
supervision from the pairing between images and captions, which tends to be
noisy in web-crawled data. We present Mixture of Data Experts (MoDE) and learn
a system of CLIP data experts via clustering. Each data expert is trained on
one data cluster, being less sensitive to false negative noises in other
clusters. At inference time, we ensemble their outputs by applying weights
determined through the correlation between task metadata and cluster
conditions. To estimate the correlation precisely, the samples in one cluster
should be semantically similar, but the number of data experts should still be
reasonable for training and inference. As such, we consider the ontology in
human language and propose to use fine-grained cluster centers to represent
each data expert at a coarse-grained level. Experimental studies show that four
CLIP data experts on ViT-B/16 outperform the ViT-L/14 by OpenAI CLIP and
OpenCLIP on zero-shot image classification but with less ($<$35\%) training
cost. Meanwhile, MoDE can train all data expert asynchronously and can flexibly
include new data experts. The code is available at
https://github.com/facebookresearch/MetaCLIP/tree/main/mode.",2024-04-24,"Jiawei Ma, Po-Yao Huang, Saining Xie, Shang-Wen Li, Luke Zettlemoyer, Shih-Fu Chang, Wen-Tau Yih, Hu Xu",http://arxiv.org/pdf/2404.16030v1,cs.CL
Investigating Adversarial Trigger Transfer in Large Language Models,"Recent work has developed optimization procedures to find token sequences,
called adversarial triggers, which can elicit unsafe responses from aligned
language models. These triggers are believed to be highly transferable, i.e., a
trigger optimized on one model can jailbreak other models. In this paper, we
concretely show that such adversarial triggers are not consistently
transferable. We extensively investigate trigger transfer amongst 13 open
models and observe poor and inconsistent transfer. Our experiments further
reveal a significant difference in robustness to adversarial triggers between
models Aligned by Preference Optimization (APO) and models Aligned by
Fine-Tuning (AFT). We find that APO models are extremely hard to jailbreak even
when the trigger is optimized directly on the model. On the other hand, while
AFT models may appear safe on the surface, exhibiting refusals to a range of
unsafe instructions, we show that they are highly susceptible to adversarial
triggers. Lastly, we observe that most triggers optimized on AFT models also
generalize to new unsafe instructions from five diverse domains, further
emphasizing their vulnerability. Overall, our work highlights the need for more
comprehensive safety evaluations for aligned language models.",2024-04-24,"Nicholas Meade, Arkil Patel, Siva Reddy",http://arxiv.org/pdf/2404.16020v2,cs.CL
"The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models","Human feedback is central to the alignment of Large Language Models (LLMs).
However, open questions remain about methods (how), domains (where), people
(who) and objectives (to what end) of feedback processes. To navigate these
questions, we introduce PRISM, a dataset that maps the sociodemographics and
stated preferences of 1,500 diverse participants from 75 countries, to their
contextual preferences and fine-grained feedback in 8,011 live conversations
with 21 LLMs. With PRISM, we contribute (i) wider geographic and demographic
participation in feedback; (ii) census-representative samples for two countries
(UK, US); and (iii) individualised ratings that link to detailed participant
profiles, permitting personalisation and attribution of sample artefacts. We
target subjective and multicultural perspectives on value-laden and
controversial issues, where we expect interpersonal and cross-cultural
disagreement. We use PRISM in three case studies to demonstrate the need for
careful consideration of which humans provide what alignment data.",2024-04-24,"Hannah Rose Kirk, Alexander Whitefield, Paul Röttger, Andrew Bean, Katerina Margatina, Juan Ciro, Rafael Mosquera, Max Bartolo, Adina Williams, He He, Bertie Vidgen, Scott A. Hale",http://arxiv.org/pdf/2404.16019v2,cs.CL
Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach,"In this paper, we study the problem of uncertainty estimation and calibration
for LLMs. We begin by formulating the uncertainty estimation problem, a
relevant yet underexplored area in existing literature. We then propose a
supervised approach that leverages labeled datasets to estimate the uncertainty
in LLMs' responses. Based on the formulation, we illustrate the difference
between the uncertainty estimation for LLMs and that for standard ML models and
explain why the hidden neurons of the LLMs may contain uncertainty information.
Our designed approach demonstrates the benefits of utilizing hidden activations
to enhance uncertainty estimation across various tasks and shows robust
transferability in out-of-distribution settings. We distinguish the uncertainty
estimation task from the uncertainty calibration task and show that better
uncertainty estimation leads to better calibration performance. Furthermore,
our method is easy to implement and adaptable to different levels of model
accessibility including black box, grey box, and white box.",2024-04-24,"Linyu Liu, Yu Pan, Xiaocheng Li, Guanting Chen",http://arxiv.org/pdf/2404.15993v4,cs.CL
CORM: Cache Optimization with Recent Message for Large Language Model Inference,"Large Language Models (LLMs), despite their remarkable performance across a
wide range of tasks, necessitate substantial GPU memory and consume significant
computational resources. Beyond the memory taken up by model weights, the
memory used by the KV cache rises linearly with sequence length, becoming a
primary bottleneck for inference. In this paper, we introduce an innovative
method for optimizing the KV cache, which considerably minimizes its memory
footprint. Upon thorough investigation, we discover that in most Transformer
models, (i) there is a striking similarity between adjacent tokens' query
vectors, and (ii) the attention calculation of the current query can rely
exclusively on the attention information of a small fraction of preceding
queries. Based on these observations, we present CORM, a KV cache eviction
policy that dynamically retains essential key-value pairs for inference without
the need for model fine-tuning. Our validation shows that CORM reduces the
inference memory usage of KV cache by up to 70\% with negligible performance
degradation across six tasks in LongBench. Furthermore, we demonstrate that
CORM is compatible with GQA for further compression rate.",2024-04-24,"Jincheng Dai, Zhuowei Huang, Haiyun Jiang, Chen Chen, Deng Cai, Wei Bi, Shuming Shi",http://arxiv.org/pdf/2404.15949v2,cs.CL
Generalization Measures for Zero-Shot Cross-Lingual Transfer,"A model's capacity to generalize its knowledge to interpret unseen inputs
with different characteristics is crucial to build robust and reliable machine
learning systems. Language model evaluation tasks lack information metrics
about model generalization and their applicability in a new setting is measured
using task and language-specific downstream performance, which is often lacking
in many languages and tasks. In this paper, we explore a set of efficient and
reliable measures that could aid in computing more information related to the
generalization capability of language models in cross-lingual zero-shot
settings. In addition to traditional measures such as variance in parameters
after training and distance from initialization, we also measure the
effectiveness of sharpness in loss landscape in capturing the success in
cross-lingual transfer and propose a novel and stable algorithm to reliably
compute the sharpness of a model optimum that correlates to generalization.",2024-04-24,"Saksham Bassi, Duygu Ataman, Kyunghyun Cho",http://arxiv.org/pdf/2404.15928v2,cs.CL
Inside the echo chamber: Linguistic underpinnings of misinformation on Twitter,"Social media users drive the spread of misinformation online by sharing posts
that include erroneous information or commenting on controversial topics with
unsubstantiated arguments often in earnest. Work on echo chambers has suggested
that users' perspectives are reinforced through repeated interactions with
like-minded peers, promoted by homophily and bias in information diffusion.
Building on long-standing interest in the social bases of language and
linguistic underpinnings of social behavior, this work explores how
conversations around misinformation are mediated through language use. We
compare a number of linguistic measures, e.g., in-/out-group cues, readability,
and discourse connectives, within and across topics of conversation and user
communities. Our findings reveal increased presence of group identity signals
and processing fluency within echo chambers during discussions of
misinformation. We discuss the specific character of these broader trends
across topics and examine contextual influences.",2024-04-24,"Xinyu Wang, Jiayi Li, Sarah Rajtmajer",http://arxiv.org/pdf/2404.15925v1,cs.CL
KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction,"This study explores the use of Large Language Models (LLMs) for automatic
evaluation of knowledge graph (KG) completion models. Historically, validating
information in KGs has been a challenging task, requiring large-scale human
annotation at prohibitive cost. With the emergence of general-purpose
generative AI and LLMs, it is now plausible that human-in-the-loop validation
could be replaced by a generative agent. We introduce a framework for
consistency and validation when using generative models to validate knowledge
graphs. Our framework is based upon recent open-source developments for
structural and semantic validation of LLM outputs, and upon flexible approaches
to fact checking and verification, supported by the capacity to reference
external knowledge sources of any kind. The design is easy to adapt and extend,
and can be used to verify any kind of graph-structured data through a
combination of model-intrinsic knowledge, user-supplied context, and agents
capable of external knowledge retrieval.",2024-04-24,"Jack Boylan, Shashank Mangla, Dominic Thorn, Demian Gholipour Ghalandari, Parsa Ghaffari, Chris Hokamp",http://arxiv.org/pdf/2404.15923v1,cs.CL
Assessing The Potential Of Mid-Sized Language Models For Clinical QA,"Large language models, such as GPT-4 and Med-PaLM, have shown impressive
performance on clinical tasks; however, they require access to compute, are
closed-source, and cannot be deployed on device. Mid-size models such as
BioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but
their capacity for clinical tasks has been understudied. To help assess their
potential for clinical use and help researchers decide which model they should
use, we compare their performance on two clinical question-answering (QA)
tasks: MedQA and consumer query answering. We find that Mistral 7B is the best
performing model, winning on all benchmarks and outperforming models trained
specifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%
approaches the original Med-PaLM, and it often can produce plausible responses
to consumer health queries, room for improvement still exists. This study
provides the first head-to-head assessment of open source mid-sized models on
clinical tasks.",2024-04-24,"Elliot Bolton, Betty Xiong, Vijaytha Muralidharan, Joel Schamroth, Vivek Muralidharan, Christopher D. Manning, Roxana Daneshjou",http://arxiv.org/pdf/2404.15894v1,cs.CL
Effective Unsupervised Constrained Text Generation based on Perturbed Masking,"Unsupervised constrained text generation aims to generate text under a given
set of constraints without any supervised data. Current state-of-the-art
methods stochastically sample edit positions and actions, which may cause
unnecessary search steps. In this paper, we propose PMCTG to improve
effectiveness by searching for the best edit position and action in each step.
Specifically, PMCTG extends perturbed masking technique to effectively search
for the most incongruent token to edit. Then it introduces four multi-aspect
scoring functions to select edit action to further reduce search difficulty.
Since PMCTG does not require supervised data, it could be applied to different
generation tasks. We show that under the unsupervised setting, PMCTG achieves
new state-of-the-art results in two representative tasks, namely
keywords-to-sentence generation and paraphrasing.",2024-04-24,"Yingwen Fu, Wenjie Ou, Zhou Yu, Yue Lin",http://arxiv.org/pdf/2404.15877v1,cs.CL
Detecting Conceptual Abstraction in LLMs,"We present a novel approach to detecting noun abstraction within a large
language model (LLM). Starting from a psychologically motivated set of noun
pairs in taxonomic relationships, we instantiate surface patterns indicating
hypernymy and analyze the attention matrices produced by BERT. We compare the
results to two sets of counterfactuals and show that we can detect hypernymy in
the abstraction mechanism, which cannot solely be related to the distributional
similarity of noun pairs. Our findings are a first step towards the
explainability of conceptual abstraction in LLMs.",2024-04-24,"Michaela Regneri, Alhassan Abdelhalim, Sören Laue",http://arxiv.org/pdf/2404.15848v2,cs.CL
From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models,"It is imperative for Large language models (LLMs) to follow instructions with
elaborate requirements (i.e. Complex Instructions Following). Yet, it remains
under-explored how to enhance the ability of LLMs to follow complex
instructions with multiple constraints. To bridge the gap, we initially study
what training data is effective in enhancing complex constraints following
abilities. We found that training LLMs with instructions containing multiple
constraints enhances their understanding of complex instructions, especially
those with lower complexity levels. The improvement can even generalize to
compositions of out-of-domain constraints. Additionally, we further propose
methods addressing how to obtain and utilize the effective training data.
Finally, we conduct extensive experiments to prove the effectiveness of our
methods in terms of overall performance and training efficiency. We also
demonstrate that our methods improve models' ability to follow instructions
generally and generalize effectively across out-of-domain, in-domain, and
adversarial settings, while maintaining general capabilities.",2024-04-24,"Qianyu He, Jie Zeng, Qianxi He, Jiaqing Liang, Yanghua Xiao",http://arxiv.org/pdf/2404.15846v2,cs.CL
Exploring LLM Prompting Strategies for Joint Essay Scoring and Feedback Generation,"Individual feedback can help students improve their essay writing skills.
However, the manual effort required to provide such feedback limits
individualization in practice. Automatically-generated essay feedback may serve
as an alternative to guide students at their own pace, convenience, and desired
frequency. Large language models (LLMs) have demonstrated strong performance in
generating coherent and contextually relevant text. Yet, their ability to
provide helpful essay feedback is unclear. This work explores several prompting
strategies for LLM-based zero-shot and few-shot generation of essay feedback.
Inspired by Chain-of-Thought prompting, we study how and to what extent
automated essay scoring (AES) can benefit the quality of generated feedback. We
evaluate both the AES performance that LLMs can achieve with prompting only and
the helpfulness of the generated essay feedback. Our results suggest that
tackling AES and feedback generation jointly improves AES performance. However,
while our manual evaluation emphasizes the quality of the generated essay
feedback, the impact of essay scoring on the generated feedback remains low
ultimately.",2024-04-24,"Maja Stahl, Leon Biermann, Andreas Nehring, Henning Wachsmuth",http://arxiv.org/pdf/2404.15845v1,cs.CL
BERT vs GPT for financial engineering,"The paper benchmarks several Transformer models [4], to show how these models
can judge sentiment from a news event. This signal can then be used for
downstream modelling and signal identification for commodity trading. We find
that fine-tuned BERT models outperform fine-tuned or vanilla GPT models on this
task. Transformer models have revolutionized the field of natural language
processing (NLP) in recent years, achieving state-of-the-art results on various
tasks such as machine translation, text summarization, question answering, and
natural language generation. Among the most prominent transformer models are
Bidirectional Encoder Representations from Transformers (BERT) and Generative
Pre-trained Transformer (GPT), which differ in their architectures and
objectives.
  A CopBERT model training data and process overview is provided. The CopBERT
model outperforms similar domain specific BERT trained models such as FinBERT.
The below confusion matrices show the performance on CopBERT & CopGPT
respectively. We see a ~10 percent increase in f1_score when compare CopBERT vs
GPT4 and 16 percent increase vs CopGPT. Whilst GPT4 is dominant It highlights
the importance of considering alternatives to GPT models for financial
engineering tasks, given risks of hallucinations, and challenges with
interpretability. We unsurprisingly see the larger LLMs outperform the BERT
models, with predictive power. In summary BERT is partially the new XGboost,
what it lacks in predictive power it provides with higher levels of
interpretability. Concluding that BERT models might not be the next XGboost
[2], but represent an interesting alternative for financial engineering tasks,
that require a blend of interpretability and accuracy.",2024-04-24,"Edward Sharkey, Philip Treleaven",http://arxiv.org/pdf/2405.12990v1,cs.CL
One Subgraph for All: Efficient Reasoning on Opening Subgraphs for Inductive Knowledge Graph Completion,"Knowledge Graph Completion (KGC) has garnered massive research interest
recently, and most existing methods are designed following a transductive
setting where all entities are observed during training. Despite the great
progress on the transductive KGC, these methods struggle to conduct reasoning
on emerging KGs involving unseen entities. Thus, inductive KGC, which aims to
deduce missing links among unseen entities, has become a new trend. Many
existing studies transform inductive KGC as a graph classification problem by
extracting enclosing subgraphs surrounding each candidate triple.
Unfortunately, they still face certain challenges, such as the expensive time
consumption caused by the repeat extraction of enclosing subgraphs, and the
deficiency of entity-independent feature learning. To address these issues, we
propose a global-local anchor representation (GLAR) learning method for
inductive KGC. Unlike previous methods that utilize enclosing subgraphs, we
extract a shared opening subgraph for all candidates and perform reasoning on
it, enabling the model to perform reasoning more efficiently. Moreover, we
design some transferable global and local anchors to learn rich
entity-independent features for emerging entities. Finally, a global-local
graph reasoning model is applied on the opening subgraph to rank all
candidates. Extensive experiments show that our GLAR outperforms most existing
state-of-the-art methods.",2024-04-24,"Zhiwen Xie, Yi Zhang, Guangyou Zhou, Jin Liu, Xinhui Tu, Jimmy Xiangji Huang",http://arxiv.org/pdf/2404.15807v1,cs.CL
BASS: Batched Attention-optimized Speculative Sampling,"Speculative decoding has emerged as a powerful method to improve latency and
throughput in hosting large language models. However, most existing
implementations focus on generating a single sequence. Real-world generative AI
applications often require multiple responses and how to perform speculative
decoding in a batched setting while preserving its latency benefits poses
non-trivial challenges. This paper describes a system of batched speculative
decoding that sets a new state of the art in multi-sequence generation latency
and that demonstrates superior GPU utilization as well as quality of
generations within a time budget. For example, for a 7.8B-size model on a
single A100 GPU and with a batch size of 8, each sequence is generated at an
average speed of 5.8ms per token, the overall throughput being 1.1K tokens per
second. These results represent state-of-the-art latency and a 2.15X speed-up
over optimized regular decoding. Within a time budget that regular decoding
does not finish, our system is able to generate sequences with HumanEval
Pass@First of 43% and Pass@All of 61%, far exceeding what's feasible with
single-sequence speculative decoding. Our peak GPU utilization during decoding
reaches as high as 15.8%, more than 3X the highest of that of regular decoding
and around 10X of single-sequence speculative decoding.",2024-04-24,"Haifeng Qian, Sujan Kumar Gonugondla, Sungsoo Ha, Mingyue Shang, Sanjay Krishna Gouda, Ramesh Nallapati, Sudipta Sengupta, Xiaofei Ma, Anoop Deoras",http://arxiv.org/pdf/2404.15778v2,cs.CL
A Comprehensive Survey on Evaluating Large Language Model Applications in the Medical Industry,"Since the inception of the Transformer architecture in 2017, Large Language
Models (LLMs) such as GPT and BERT have evolved significantly, impacting
various industries with their advanced capabilities in language understanding
and generation. These models have shown potential to transform the medical
field, highlighting the necessity for specialized evaluation frameworks to
ensure their effective and ethical deployment. This comprehensive survey
delineates the extensive application and requisite evaluation of LLMs within
healthcare, emphasizing the critical need for empirical validation to fully
exploit their capabilities in enhancing healthcare outcomes. Our survey is
structured to provide an in-depth analysis of LLM applications across clinical
settings, medical text data processing, research, education, and public health
awareness. We begin by exploring the roles of LLMs in various medical
applications, detailing their evaluation based on performance in tasks such as
clinical diagnosis, medical text data processing, information retrieval, data
analysis, and educational content generation. The subsequent sections offer a
comprehensive discussion on the evaluation methods and metrics employed,
including models, evaluators, and comparative experiments. We further examine
the benchmarks and datasets utilized in these evaluations, providing a
categorized description of benchmarks for tasks like question answering,
summarization, information extraction, bioinformatics, information retrieval
and general comprehensive benchmarks. This structure ensures a thorough
understanding of how LLMs are assessed for their effectiveness, accuracy,
usability, and ethical alignment in the medical domain. ...",2024-04-24,"Yining Huang, Keke Tang, Meilian Chen, Boyuan Wang",http://arxiv.org/pdf/2404.15777v4,cs.CL
ChEX: Interactive Localization and Region Description in Chest X-rays,"Report generation models offer fine-grained textual interpretations of
medical images like chest X-rays, yet they often lack interactivity (i.e. the
ability to steer the generation process through user queries) and localized
interpretability (i.e. visually grounding their predictions), which we deem
essential for future adoption in clinical practice. While there have been
efforts to tackle these issues, they are either limited in their interactivity
by not supporting textual queries or fail to also offer localized
interpretability. Therefore, we propose a novel multitask architecture and
training paradigm integrating textual prompts and bounding boxes for diverse
aspects like anatomical regions and pathologies. We call this approach the
Chest X-Ray Explainer (ChEX). Evaluations across a heterogeneous set of 9 chest
X-ray tasks, including localized image interpretation and report generation,
showcase its competitiveness with SOTA models while additional analysis
demonstrates ChEX's interactive capabilities. Code:
https://github.com/philip-mueller/chex",2024-04-24,"Philip Müller, Georgios Kaissis, Daniel Rueckert",http://arxiv.org/pdf/2404.15770v2,cs.CL
Let's Think Dot by Dot: Hidden Computation in Transformer Language Models,"Chain-of-thought responses from language models improve performance across
most benchmarks. However, it remains unclear to what extent these performance
gains can be attributed to human-like task decomposition or simply the greater
computation that additional tokens allow. We show that transformers can use
meaningless filler tokens (e.g., '......') in place of a chain of thought to
solve two hard algorithmic tasks they could not solve when responding without
intermediate tokens. However, we find empirically that learning to use filler
tokens is difficult and requires specific, dense supervision to converge. We
also provide a theoretical characterization of the class of problems where
filler tokens are useful in terms of the quantifier depth of a first-order
formula. For problems satisfying this characterization, chain-of-thought tokens
need not provide information about the intermediate computational steps
involved in multi-token computations. In summary, our results show that
additional tokens can provide computational benefits independent of token
choice. The fact that intermediate tokens can act as filler tokens raises
concerns about large language models engaging in unauditable, hidden
computations that are increasingly detached from the observed chain-of-thought
tokens.",2024-04-24,"Jacob Pfau, William Merrill, Samuel R. Bowman",http://arxiv.org/pdf/2404.15758v1,cs.CL
No Train but Gain: Language Arithmetic for training-free Language Adapters enhancement,"Modular deep learning is the state-of-the-art solution for lifting the curse
of multilinguality, preventing the impact of negative interference and enabling
cross-lingual performance in Multilingual Pre-trained Language Models. However,
a trade-off of this approach is the reduction in positive transfer learning
from closely related languages. In response, we introduce a novel method called
language arithmetic, which enables training-free post-processing to address
this limitation. Extending the task arithmetic framework, we apply learning via
addition to the language adapters, transitioning the framework from a
multi-task to a multilingual setup. The effectiveness of the proposed solution
is demonstrated on three downstream tasks in a MAD-X-based set of cross-lingual
schemes, acting as a post-processing procedure. Language arithmetic
consistently improves the baselines with significant gains, especially in the
most challenging case of zero-shot application. Our code and models are
available at https://github.com/mklimasz/language-arithmetic .",2024-04-24,"Mateusz Klimaszewski, Piotr Andruszkiewicz, Alexandra Birch",http://arxiv.org/pdf/2404.15737v2,cs.CL
Annotator-Centric Active Learning for Subjective NLP Tasks,"Active Learning (AL) addresses the high costs of collecting human annotations
by strategically annotating the most informative samples. However, for
subjective NLP tasks, incorporating a wide range of perspectives in the
annotation process is crucial to capture the variability in human judgments. We
introduce Annotator-Centric Active Learning (ACAL), which incorporates an
annotator selection strategy following data sampling. Our objective is
two-fold: 1) to efficiently approximate the full diversity of human judgments,
and 2) to assess model performance using annotator-centric metrics, which value
minority and majority perspectives equally. We experiment with multiple
annotator selection strategies across seven subjective NLP tasks, employing
both traditional and novel, human-centered evaluation metrics. Our findings
indicate that ACAL improves data efficiency and excels in annotator-centric
performance evaluations. However, its success depends on the availability of a
sufficiently large and diverse pool of annotators to sample from.",2024-04-24,"Michiel van der Meer, Neele Falk, Pradeep K. Murukannaiah, Enrico Liscio",http://arxiv.org/pdf/2404.15720v4,cs.CL
Nyonic Technical Report,"This report details the development and key achievements of our latest
language model designed for custom large language models. The advancements
introduced include a novel Online Data Scheduler that supports flexible
training data adjustments and curriculum learning. The model's architecture is
fortified with state-of-the-art techniques such as Rotary Positional
Embeddings, QK-LayerNorm, and a specially crafted multilingual tokenizer to
enhance stability and performance. Moreover, our robust training framework
incorporates advanced monitoring and rapid recovery features to ensure optimal
efficiency. Our Wonton 7B model has demonstrated competitive performance on a
range of multilingual and English benchmarks. Future developments will
prioritize narrowing the performance gap with more extensively trained models,
thereby enhancing the model's real-world efficacy and adaptability.GitHub:
\url{https://github.com/nyonicai/nyonic-public}",2024-04-24,"Junfeng Tian, Rui Wang, Cong Li, Yudong Zhou, Jun Liu, Jun Wang",http://arxiv.org/pdf/2404.15702v1,cs.CL
Neural Proto-Language Reconstruction,"Proto-form reconstruction has been a painstaking process for linguists.
Recently, computational models such as RNN and Transformers have been proposed
to automate this process. We take three different approaches to improve upon
previous methods, including data augmentation to recover missing reflexes,
adding a VAE structure to the Transformer model for proto-to-language
prediction, and using a neural machine translation model for the reconstruction
task. We find that with the additional VAE structure, the Transformer model has
a better performance on the WikiHan dataset, and the data augmentation step
stabilizes the training.",2024-04-24,"Chenxuan Cui, Ying Chen, Qinxin Wang, David R. Mortensen",http://arxiv.org/pdf/2404.15690v1,cs.CL
Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs,"Chain-of-Thought (CoT) has been a widely adopted prompting method, eliciting
impressive reasoning abilities of Large Language Models (LLMs). Inspired by the
sequential thought structure of CoT, a number of Chain-of-X (CoX) methods have
been developed to address various challenges across diverse domains and tasks
involving LLMs. In this paper, we provide a comprehensive survey of Chain-of-X
methods for LLMs in different contexts. Specifically, we categorize them by
taxonomies of nodes, i.e., the X in CoX, and application tasks. We also discuss
the findings and implications of existing CoX methods, as well as potential
future directions. Our survey aims to serve as a detailed and up-to-date
resource for researchers seeking to apply the idea of CoT to broader scenarios.",2024-04-24,"Yu Xia, Rui Wang, Xu Liu, Mingyan Li, Tong Yu, Xiang Chen, Julian McAuley, Shuai Li",http://arxiv.org/pdf/2404.15676v3,cs.CL
The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews,"Systematic review (SR) is a popular research method in software engineering
(SE). However, conducting an SR takes an average of 67 weeks. Thus, automating
any step of the SR process could reduce the effort associated with SRs. Our
objective is to investigate if Large Language Models (LLMs) can accelerate
title-abstract screening by simplifying abstracts for human screeners, and
automating title-abstract screening. We performed an experiment where humans
screened titles and abstracts for 20 papers with both original and simplified
abstracts from a prior SR. The experiment with human screeners was reproduced
with GPT-3.5 and GPT-4 LLMs to perform the same screening tasks. We also
studied if different prompting techniques (Zero-shot (ZS), One-shot (OS),
Few-shot (FS), and Few-shot with Chain-of-Thought (FS-CoT)) improve the
screening performance of LLMs. Lastly, we studied if redesigning the prompt
used in the LLM reproduction of screening leads to improved performance. Text
simplification did not increase the screeners' screening performance, but
reduced the time used in screening. Screeners' scientific literacy skills and
researcher status predict screening performance. Some LLM and prompt
combinations perform as well as human screeners in the screening tasks. Our
results indicate that the GPT-4 LLM is better than its predecessor, GPT-3.5.
Additionally, Few-shot and One-shot prompting outperforms Zero-shot prompting.
Using LLMs for text simplification in the screening process does not
significantly improve human performance. Using LLMs to automate title-abstract
screening seems promising, but current LLMs are not significantly more accurate
than human screeners. To recommend the use of LLMs in the screening process of
SRs, more research is needed. We recommend future SR studies publish
replication packages with screening data to enable more conclusive
experimenting with LLM screening.",2024-04-24,"Aleksi Huotala, Miikka Kuutila, Paul Ralph, Mika Mäntylä",http://arxiv.org/pdf/2404.15667v4,cs.CL
KS-LLM: Knowledge Selection of Large Language Models with Evidence Document for Question Answering,"Large language models (LLMs) suffer from the hallucination problem and face
significant challenges when applied to knowledge-intensive tasks. A promising
approach is to leverage evidence documents as extra supporting knowledge, which
can be obtained through retrieval or generation. However, existing methods
directly leverage the entire contents of the evidence document, which may
introduce noise information and impair the performance of large language
models. To tackle this problem, we propose a novel Knowledge Selection of Large
Language Models (KS-LLM) method, aiming to identify valuable information from
evidence documents. The KS-LLM approach utilizes triples to effectively select
knowledge snippets from evidence documents that are beneficial to answering
questions. Specifically, we first generate triples based on the input question,
then select the evidence sentences most similar to triples from the evidence
document, and finally combine the evidence sentences and triples to assist
large language models in generating answers. Experimental comparisons on
several question answering datasets, such as TriviaQA, WebQ, and NQ,
demonstrate that the proposed method surpasses the baselines and achieves the
best results.",2024-04-24,"Xinxin Zheng, Feihu Che, Jinyang Wu, Shuai Zhang, Shuai Nie, Kang Liu, Jianhua Tao",http://arxiv.org/pdf/2404.15660v1,cs.CL
CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data,"Contrastive learning has emerged as a transformative method for learning
effective visual representations through the alignment of image and text
embeddings. However, pairwise similarity computation in contrastive loss
between image and text pairs poses computational challenges. This paper
presents a novel weakly supervised pre-training of vision models on web-scale
image-text data. The proposed method reframes pre-training on image-text data
as a classification task. Consequently, it eliminates the need for pairwise
similarity computations in contrastive loss, achieving a remarkable $2.7\times$
acceleration in training speed compared to contrastive learning on web-scale
data. Through extensive experiments spanning diverse vision tasks, including
detection and segmentation, we demonstrate that the proposed method maintains
high representation quality. Our source code along with pre-trained model
weights and training recipes is available at
\url{https://github.com/apple/corenet}.",2024-04-24,"Sachin Mehta, Maxwell Horton, Fartash Faghri, Mohammad Hossein Sekhavat, Mahyar Najibi, Mehrdad Farajtabar, Oncel Tuzel, Mohammad Rastegari",http://arxiv.org/pdf/2404.15653v1,cs.CL
Return of EM: Entity-driven Answer Set Expansion for QA Evaluation,"Recently, directly using large language models (LLMs) has been shown to be
the most reliable method to evaluate QA models. However, it suffers from
limited interpretability, high cost, and environmental harm. To address these,
we propose to use soft EM with entity-driven answer set expansion. Our approach
expands the gold answer set to include diverse surface forms, based on the
observation that the surface forms often follow particular patterns depending
on the entity type. The experimental results show that our method outperforms
traditional evaluation methods by a large margin. Moreover, the reliability of
our evaluation method is comparable to that of LLM-based ones, while offering
the benefits of high interpretability and reduced environmental harm.",2024-04-24,"Dongryeol Lee, Minwoo Lee, Kyungmin Min, Joonsuk Park, Kyomin Jung",http://arxiv.org/pdf/2404.15650v3,cs.CL
Semantic Evolvement Enhanced Graph Autoencoder for Rumor Detection,"Due to the rapid spread of rumors on social media, rumor detection has become
an extremely important challenge. Recently, numerous rumor detection models
which utilize textual information and the propagation structure of events have
been proposed. However, these methods overlook the importance of semantic
evolvement information of event in propagation process, which is often
challenging to be truly learned in supervised training paradigms and
traditional rumor detection methods. To address this issue, we propose a novel
semantic evolvement enhanced Graph Autoencoder for Rumor Detection (GARD) model
in this paper. The model learns semantic evolvement information of events by
capturing local semantic changes and global semantic evolvement information
through specific graph autoencoder and reconstruction strategies. By combining
semantic evolvement information and propagation structure information, the
model achieves a comprehensive understanding of event propagation and perform
accurate and robust detection, while also detecting rumors earlier by capturing
semantic evolvement information in the early stages. Moreover, in order to
enhance the model's ability to learn the distinct patterns of rumors and
non-rumors, we introduce a uniformity regularizer to further improve the
model's performance. Experimental results on three public benchmark datasets
confirm the superiority of our GARD method over the state-of-the-art approaches
in both overall performance and early rumor detection.",2024-04-24,"Xiang Tao, Liang Wang, Qiang Liu, Shu Wu, Liang Wang",http://arxiv.org/pdf/2404.16076v1,cs.CL
CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code,"Large Language Models (LLMs) have achieved remarkable progress in code
generation. It now becomes crucial to identify whether the code is AI-generated
and to determine the specific model used, particularly for purposes such as
protecting Intellectual Property (IP) in industry and preventing cheating in
programming exercises. To this end, several attempts have been made to insert
watermarks into machine-generated code. However, existing approaches are
limited to inserting only a single bit of information. In this paper, we
introduce CodeIP, a novel multi-bit watermarking technique that inserts
additional information to preserve crucial provenance details, such as the
vendor ID of an LLM, thereby safeguarding the IPs of LLMs in code generation.
Furthermore, to ensure the syntactical correctness of the generated code, we
propose constraining the sampling process for predicting the next token by
training a type predictor. Experiments conducted on a real-world dataset across
five programming languages demonstrate the effectiveness of CodeIP in
watermarking LLMs for code generation while maintaining the syntactical
correctness of code.",2024-04-24,"Batu Guan, Yao Wan, Zhangqian Bi, Zheng Wang, Hongyu Zhang, Pan Zhou, Lichao Sun",http://arxiv.org/pdf/2404.15639v3,cs.CL
Hybrid LLM/Rule-based Approaches to Business Insights Generation from Structured Data,"In the field of business data analysis, the ability to extract actionable
insights from vast and varied datasets is essential for informed
decision-making and maintaining a competitive edge. Traditional rule-based
systems, while reliable, often fall short when faced with the complexity and
dynamism of modern business data. Conversely, Artificial Intelligence (AI)
models, particularly Large Language Models (LLMs), offer significant potential
in pattern recognition and predictive analytics but can lack the precision
necessary for specific business applications. This paper explores the efficacy
of hybrid approaches that integrate the robustness of rule-based systems with
the adaptive power of LLMs in generating actionable business insights.",2024-04-24,"Aliaksei Vertsel, Mikhail Rumiantsau",http://arxiv.org/pdf/2404.15604v1,cs.CL
ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction,"Existing datasets for attribute value extraction (AVE) predominantly focus on
explicit attribute values while neglecting the implicit ones, lack product
images, are often not publicly available, and lack an in-depth human inspection
across diverse domains. To address these limitations, we present ImplicitAVE,
the first, publicly available multimodal dataset for implicit attribute value
extraction. ImplicitAVE, sourced from the MAVE dataset, is carefully curated
and expanded to include implicit AVE and multimodality, resulting in a refined
dataset of 68k training and 1.6k testing data across five domains. We also
explore the application of multimodal large language models (MLLMs) to implicit
AVE, establishing a comprehensive benchmark for MLLMs on the ImplicitAVE
dataset. Six recent MLLMs with eleven variants are evaluated across diverse
settings, revealing that implicit value extraction remains a challenging task
for MLLMs. The contributions of this work include the development and release
of ImplicitAVE, and the exploration and benchmarking of various MLLMs for
implicit AVE, providing valuable insights and potential future research
directions. Dataset and code are available at
https://github.com/HenryPengZou/ImplicitAVE",2024-04-24,"Henry Peng Zou, Vinay Samuel, Yue Zhou, Weizhi Zhang, Liancheng Fang, Zihe Song, Philip S. Yu, Cornelia Caragea",http://arxiv.org/pdf/2404.15592v2,cs.CL
Minimal Evidence Group Identification for Claim Verification,"Claim verification in real-world settings (e.g. against a large collection of
candidate evidences retrieved from the web) typically requires identifying and
aggregating a complete set of evidence pieces that collectively provide full
support to the claim. The problem becomes particularly challenging when there
exists distinct sets of evidence that could be used to verify the claim from
different perspectives. In this paper, we formally define and study the problem
of identifying such minimal evidence groups (MEGs) for claim verification. We
show that MEG identification can be reduced from Set Cover problem, based on
entailment inference of whether a given evidence group provides full/partial
support to a claim. Our proposed approach achieves 18.4% and 34.8% absolute
improvements on the WiCE and SciFact datasets over LLM prompting. Finally, we
demonstrate the benefits of MEGs in downstream applications such as claim
generation.",2024-04-24,"Xiangci Li, Sihao Chen, Rajvi Kapadia, Jessica Ouyang, Fan Zhang",http://arxiv.org/pdf/2404.15588v1,cs.CL
Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices,"In recent times, there has been a growing interest in utilizing personalized
large models on low-spec devices, such as mobile and CPU-only devices. However,
utilizing a personalized large model in the on-device is inefficient, and
sometimes limited due to computational cost. To tackle the problem, this paper
presents the weights separation method to minimize on-device model weights
using parameter-efficient fine-tuning methods. Moreover, some people speak
multiple languages in an utterance, as known as code-switching, the
personalized ASR model is necessary to address such cases. However, current
multilingual speech recognition models are limited to recognizing a single
language within each utterance. To tackle this problem, we propose
code-switching speech recognition models that incorporate fine-tuned
monolingual and multilingual speech recognition models. Additionally, we
introduce a gated low-rank adaptation(GLoRA) for parameter-efficient
fine-tuning with minimal performance degradation. Our experiments, conducted on
Korean-English code-switching datasets, demonstrate that fine-tuning speech
recognition models for code-switching surpasses the performance of traditional
code-switching speech recognition models trained from scratch. Furthermore,
GLoRA enhances parameter-efficient fine-tuning performance compared to
conventional LoRA.",2024-04-24,"Gwantae Kim, Bokyeung Lee, Donghyeon Kim, Hanseok Ko",http://arxiv.org/pdf/2406.02562v1,cs.CL
Can Foundational Large Language Models Assist with Conducting Pharmaceuticals Manufacturing Investigations?,"General purpose Large Language Models (LLM) such as the Generative Pretrained
Transformer (GPT) and Large Language Model Meta AI (LLaMA) have attracted much
attention in recent years. There is strong evidence that these models can
perform remarkably well in various natural language processing tasks. However,
how to leverage them to approach domain-specific use cases and drive value
remains an open question. In this work, we focus on a specific use case,
pharmaceutical manufacturing investigations, and propose that leveraging
historical records of manufacturing incidents and deviations in an organization
can be beneficial for addressing and closing new cases, or de-risking new
manufacturing campaigns. Using a small but diverse dataset of real
manufacturing deviations selected from different product lines, we evaluate and
quantify the power of three general purpose LLMs (GPT-3.5, GPT-4, and Claude-2)
in performing tasks related to the above goal. In particular, (1) the ability
of LLMs in automating the process of extracting specific information such as
root cause of a case from unstructured data, as well as (2) the possibility of
identifying similar or related deviations by performing semantic search on the
database of historical records are examined. While our results point to the
high accuracy of GPT-4 and Claude-2 in the information extraction task, we
discuss cases of complex interplay between the apparent reasoning and
hallucination behavior of LLMs as a risk factor. Furthermore, we show that
semantic search on vector embedding of deviation descriptions can be used to
identify similar records, such as those with a similar type of defect, with a
high level of accuracy. We discuss further improvements to enhance the accuracy
of similar record identification.",2024-04-24,"Hossein Salami, Brandye Smith-Goettler, Vijay Yadav",http://arxiv.org/pdf/2404.15578v1,cs.CL
Retrieval Head Mechanistically Explains Long-Context Factuality,"Despite the recent progress in long-context language models, it remains
elusive how transformer-based models exhibit the capability to retrieve
relevant information from arbitrary locations within the long context. This
paper aims to address this question. Our systematic investigation across a wide
spectrum of models reveals that a special type of attention heads are largely
responsible for retrieving information, which we dub retrieval heads. We
identify intriguing properties of retrieval heads:(1) universal: all the
explored models with long-context capability have a set of retrieval heads; (2)
sparse: only a small portion (less than 5\%) of the attention heads are
retrieval. (3) intrinsic: retrieval heads already exist in models pretrained
with short context. When extending the context length by continual pretraining,
it is still the same set of heads that perform information retrieval. (4)
dynamically activated: take Llama-2 7B for example, 12 retrieval heads always
attend to the required information no matter how the context is changed. The
rest of the retrieval heads are activated in different contexts. (5) causal:
completely pruning retrieval heads leads to failure in retrieving relevant
information and results in hallucination, while pruning random non-retrieval
heads does not affect the model's retrieval ability. We further show that
retrieval heads strongly influence chain-of-thought (CoT) reasoning, where the
model needs to frequently refer back the question and previously-generated
context. Conversely, tasks where the model directly generates the answer using
its intrinsic knowledge are less impacted by masking out retrieval heads. These
observations collectively explain which internal part of the model seeks
information from the input tokens. We believe our insights will foster future
research on reducing hallucination, improving reasoning, and compressing the KV
cache.",2024-04-24,"Wenhao Wu, Yizhong Wang, Guangxuan Xiao, Hao Peng, Yao Fu",http://arxiv.org/pdf/2404.15574v1,cs.CL
CASPR: Automated Evaluation Metric for Contrastive Summarization,"Summarizing comparative opinions about entities (e.g., hotels, phones) from a
set of source reviews, often referred to as contrastive summarization, can
considerably aid users in decision making. However, reliably measuring the
contrastiveness of the output summaries without relying on human evaluations
remains an open problem. Prior work has proposed token-overlap based metrics,
Distinctiveness Score, to measure contrast which does not take into account the
sensitivity to meaning-preserving lexical variations. In this work, we propose
an automated evaluation metric CASPR to better measure contrast between a pair
of summaries. Our metric is based on a simple and light-weight method that
leverages natural language inference (NLI) task to measure contrast by
segmenting reviews into single-claim sentences and carefully aggregating NLI
scores between them to come up with a summary-level score. We compare CASPR
with Distinctiveness Score and a simple yet powerful baseline based on
BERTScore. Our results on a prior dataset CoCoTRIP demonstrate that CASPR can
more reliably capture the contrastiveness of the summary pairs compared to the
baselines.",2024-04-23,"Nirupan Ananthamurugan, Dat Duong, Philip George, Ankita Gupta, Sandeep Tata, Beliz Gunel",http://arxiv.org/pdf/2404.15565v2,cs.CL
PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models,"Clinical trial matching is the task of identifying trials for which patients
may be potentially eligible. Typically, this task is labor-intensive and
requires detailed verification of patient electronic health records (EHRs)
against the stringent inclusion and exclusion criteria of clinical trials. This
process is manual, time-intensive, and challenging to scale up, resulting in
many patients missing out on potential therapeutic options. Recent advancements
in Large Language Models (LLMs) have made automating patient-trial matching
possible, as shown in multiple concurrent research studies. However, the
current approaches are confined to constrained, often synthetic datasets that
do not adequately mirror the complexities encountered in real-world medical
data. In this study, we present the first, end-to-end large-scale empirical
evaluation of clinical trial matching using real-world EHRs. Our study
showcases the capability of LLMs to accurately match patients with appropriate
clinical trials. We perform experiments with proprietary LLMs, including GPT-4
and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show
that OncoLLM, despite its significantly smaller size, not only outperforms
GPT-3.5 but also matches the performance of qualified medical doctors. All
experiments were carried out on real-world EHRs that include clinical notes and
available clinical trials from a single cancer center in the United States.",2024-04-23,"Shashi Kant Gupta, Aditya Basu, Mauro Nievas, Jerrin Thomas, Nathan Wolfrath, Adhitya Ramamurthi, Bradley Taylor, Anai N. Kothari, Regina Schwind, Therica M. Miller, Sorena Nadaf-Rahrov, Yanshan Wang, Hrituraj Singh",http://arxiv.org/pdf/2404.15549v2,cs.CL
DreamCraft: Text-Guided Generation of Functional 3D Environments in Minecraft,"Procedural Content Generation (PCG) algorithms enable the automatic
generation of complex and diverse artifacts. However, they don't provide
high-level control over the generated content and typically require domain
expertise. In contrast, text-to-3D methods allow users to specify desired
characteristics in natural language, offering a high amount of flexibility and
expressivity. But unlike PCG, such approaches cannot guarantee functionality,
which is crucial for certain applications like game design. In this paper, we
present a method for generating functional 3D artifacts from free-form text
prompts in the open-world game Minecraft. Our method, DreamCraft, trains
quantized Neural Radiance Fields (NeRFs) to represent artifacts that, when
viewed in-game, match given text descriptions. We find that DreamCraft produces
more aligned in-game artifacts than a baseline that post-processes the output
of an unconstrained NeRF. Thanks to the quantized representation of the
environment, functional constraints can be integrated using specialized loss
terms. We show how this can be leveraged to generate 3D structures that match a
target distribution or obey certain adjacency rules over the block types.
DreamCraft inherits a high degree of expressivity and controllability from the
NeRF, while still being able to incorporate functional constraints through
domain-specific objectives.",2024-04-23,"Sam Earle, Filippos Kokkinos, Yuhe Nie, Julian Togelius, Roberta Raileanu",http://arxiv.org/pdf/2404.15538v1,cs.CL
BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis,"This paper presents BattleAgent, an emulation system that combines the Large
Vision-Language Model and Multi-agent System. This novel system aims to
simulate complex dynamic interactions among multiple agents, as well as between
agents and their environments, over a period of time. It emulates both the
decision-making processes of leaders and the viewpoints of ordinary
participants, such as soldiers. The emulation showcases the current
capabilities of agents, featuring fine-grained multi-modal interactions between
agents and landscapes. It develops customizable agent structures to meet
specific situational requirements, for example, a variety of battle-related
activities like scouting and trench digging. These components collaborate to
recreate historical events in a lively and comprehensive manner while offering
insights into the thoughts and feelings of individuals from diverse viewpoints.
The technological foundations of BattleAgent establish detailed and immersive
settings for historical battles, enabling individual agents to partake in,
observe, and dynamically respond to evolving battle scenarios. This methodology
holds the potential to substantially deepen our understanding of historical
events, particularly through individual accounts. Such initiatives can also aid
historical research, as conventional historical narratives often lack
documentation and prioritize the perspectives of decision-makers, thereby
overlooking the experiences of ordinary individuals. BattelAgent illustrates
AI's potential to revitalize the human aspect in crucial social events, thereby
fostering a more nuanced collective understanding and driving the progressive
development of human society.",2024-04-23,"Shuhang Lin, Wenyue Hua, Lingyao Li, Che-Jui Chang, Lizhou Fan, Jianchao Ji, Hang Hua, Mingyu Jin, Jiebo Luo, Yongfeng Zhang",http://arxiv.org/pdf/2404.15532v1,cs.CL
LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models,"Recently developed large language models (LLMs) have been shown to perform
remarkably well on a wide range of language understanding tasks. But, can they
really ""reason"" over the natural language? This question has been receiving
significant research attention and many reasoning skills such as commonsense,
numerical, and qualitative have been studied. However, the crucial skill
pertaining to 'logical reasoning' has remained underexplored. Existing work
investigating this reasoning ability of LLMs has focused only on a couple of
inference rules (such as modus ponens and modus tollens) of propositional and
first-order logic. Addressing the above limitation, we comprehensively evaluate
the logical reasoning ability of LLMs on 25 different reasoning patterns
spanning over propositional, first-order, and non-monotonic logics. To enable
systematic evaluation, we introduce LogicBench, a natural language
question-answering dataset focusing on the use of a single inference rule. We
conduct detailed analysis with a range of LLMs such as GPT-4, ChatGPT, Gemini,
Llama-2, and Mistral using chain-of-thought prompting. Experimental results
show that existing LLMs do not fare well on LogicBench; especially, they
struggle with instances involving complex reasoning and negations. Furthermore,
they sometimes overlook contextual information necessary for reasoning to
arrive at the correct conclusion. We believe that our work and findings
facilitate future research for evaluating and enhancing the logical reasoning
ability of LLMs. Data and code are available at
https://github.com/Mihir3009/LogicBench.",2024-04-23,"Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi Nakamura, Man Luo, Santosh Mashetty, Arindam Mitra, Chitta Baral",http://arxiv.org/pdf/2404.15522v2,cs.CL
ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models,"Theory of Mind (ToM) refers to the ability of individuals to attribute mental
states to others. While Large Language Models (LLMs) have shown some promise
with ToM ability, they still struggle with complex ToM reasoning. Our approach
leverages an external symbolic executor, specifically the SMCDEL model checker,
and fine-tuning to improve the ToM reasoning ability of LLMs. In our approach,
an LLM is first fine-tuned through pairs of natural language and symbolic
formulation representation of ToM problems and is then instructed to generate
the symbolic formulation with a one-shot in-context example. The generated
symbolic formulation is then executed by the SMCDEL model checker to perform
transparent and verifiable ToM reasoning and give the final result. We
demonstrate that our approach, ToM-LM, shows a significant improvement over all
the constructed baselines. Our study proposes a novel view about externalizing
a particular component of ToM reasoning, mainly reasoning about beliefs, and
suggests generalizing it to other aspects of ToM reasoning.",2024-04-23,"Weizhi Tang, Vaishak Belle",http://arxiv.org/pdf/2404.15515v3,cs.CL
Evaluating Tool-Augmented Agents in Remote Sensing Platforms,"Tool-augmented Large Language Models (LLMs) have shown impressive
capabilities in remote sensing (RS) applications. However, existing benchmarks
assume question-answering input templates over predefined image-text data
pairs. These standalone instructions neglect the intricacies of realistic
user-grounded tasks. Consider a geospatial analyst: they zoom in a map area,
they draw a region over which to collect satellite imagery, and they succinctly
ask ""Detect all objects here"". Where is `here`, if it is not explicitly
hardcoded in the image-text template, but instead is implied by the system
state, e.g., the live map positioning? To bridge this gap, we present
GeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual,
and click-based actions on a real UI platform. Through in-depth evaluation of
state-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights
towards stronger agents for RS applications.",2024-04-23,"Simranjit Singh, Michael Fore, Dimitrios Stamoulis",http://arxiv.org/pdf/2405.00709v1,cs.CL
Killkan: The Automatic Speech Recognition Dataset for Kichwa with Morphosyntactic Information,"This paper presents Killkan, the first dataset for automatic speech
recognition (ASR) in the Kichwa language, an indigenous language of Ecuador.
Kichwa is an extremely low-resource endangered language, and there have been no
resources before Killkan for Kichwa to be incorporated in applications of
natural language processing. The dataset contains approximately 4 hours of
audio with transcription, translation into Spanish, and morphosyntactic
annotation in the format of Universal Dependencies. The audio data was
retrieved from a publicly available radio program in Kichwa. This paper also
provides corpus-linguistic analyses of the dataset with a special focus on the
agglutinative morphology of Kichwa and frequent code-switching with Spanish.
The experiments show that the dataset makes it possible to develop the first
ASR system for Kichwa with reliable quality despite its small dataset size.
This dataset, the ASR model, and the code used to develop them will be publicly
available. Thus, our study positively showcases resource building and its
applications for low-resource languages and their community.",2024-04-23,"Chihiro Taguchi, Jefferson Saransig, Dayana Velásquez, David Chiang",http://arxiv.org/pdf/2404.15501v1,cs.CL
GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots,"Geospatial Copilots unlock unprecedented potential for performing Earth
Observation (EO) applications through natural language instructions. However,
existing agents rely on overly simplified single tasks and template-based
prompts, creating a disconnect with real-world scenarios. In this work, we
present GeoLLM-Engine, an environment for tool-augmented agents with intricate
tasks routinely executed by analysts on remote sensing platforms. We enrich our
environment with geospatial API tools, dynamic maps/UIs, and external
multimodal knowledge bases to properly gauge an agent's proficiency in
interpreting realistic high-level natural language commands and its functional
correctness in task completions. By alleviating overheads typically associated
with human-in-the-loop benchmark curation, we harness our massively parallel
engine across 100 GPT-4-Turbo nodes, scaling to over half a million diverse
multi-tool tasks and across 1.1 million satellite images. By moving beyond
traditional single-task image-caption paradigms, we investigate
state-of-the-art agents and prompting techniques against long-horizon prompts.",2024-04-23,"Simranjit Singh, Michael Fore, Dimitrios Stamoulis",http://arxiv.org/pdf/2404.15500v1,cs.CL
IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents,"In natural language processing applied to the clinical domain, utilizing
large language models has emerged as a promising avenue for error detection and
correction on clinical notes, a knowledge-intensive task for which annotated
data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a
suite of four LLM-based medical agents. The MedReAct agent initiates the
process by observing, analyzing, and taking action, generating trajectories to
guide the search to target a potential error in the clinical notes.
Subsequently, the MedEval agent employs five evaluators to assess the targeted
error and the proposed correction. In cases where MedReAct's actions prove
insufficient, the MedReFlex agent intervenes, engaging in reflective analysis
and proposing alternative strategies. Finally, the MedFinalParser agent formats
the final output, preserving the original style while ensuring the integrity of
the error correction process. One core component of our method is our RAG
pipeline based on our ClinicalCorp corpora. Among other well-known sources
containing clinical guidelines and information, we preprocess and release the
open-source MedWiki dataset for clinical RAG application. Our results
demonstrate the central role of our RAG approach with ClinicalCorp leveraged
through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the
MEDIQA-CORR 2024 final leaderboard.",2024-04-23,Jean-Philippe Corbeil,http://arxiv.org/pdf/2404.15488v1,cs.CL
Interactive Analysis of LLMs using Meaningful Counterfactuals,"Counterfactual examples are useful for exploring the decision boundaries of
machine learning models and determining feature attributions. How can we apply
counterfactual-based methods to analyze and explain LLMs? We identify the
following key challenges. First, the generated textual counterfactuals should
be meaningful and readable to users and thus can be mentally compared to draw
conclusions. Second, to make the solution scalable to long-form text, users
should be equipped with tools to create batches of counterfactuals from
perturbations at various granularity levels and interactively analyze the
results. In this paper, we tackle the above challenges and contribute 1) a
novel algorithm for generating batches of complete and meaningful textual
counterfactuals by removing and replacing text segments in different
granularities, and 2) LLM Analyzer, an interactive visualization tool to help
users understand an LLM's behaviors by interactively inspecting and aggregating
meaningful counterfactuals. We evaluate the proposed algorithm by the
grammatical correctness of its generated counterfactuals using 1,000 samples
from medical, legal, finance, education, and news datasets. In our experiments,
97.2% of the counterfactuals are grammatically correct. Through a use case,
user studies, and feedback from experts, we demonstrate the usefulness and
usability of the proposed interactive visualization tool.",2024-04-23,"Furui Cheng, Vilém Zouhar, Robin Shing Moon Chan, Daniel Fürst, Hendrik Strobelt, Mennatallah El-Assady",http://arxiv.org/pdf/2405.00708v1,cs.CL
Evaluating the Efficacy of Large Language Models in Identifying Phishing Attempts,"Phishing, a prevalent cybercrime tactic for decades, remains a significant
threat in today's digital world. By leveraging clever social engineering
elements and modern technology, cybercrime targets many individuals,
businesses, and organizations to exploit trust and security. These
cyber-attackers are often disguised in many trustworthy forms to appear as
legitimate sources. By cleverly using psychological elements like urgency,
fear, social proof, and other manipulative strategies, phishers can lure
individuals into revealing sensitive and personalized information. Building on
this pervasive issue within modern technology, this paper aims to analyze the
effectiveness of 15 Large Language Models (LLMs) in detecting phishing
attempts, specifically focusing on a randomized set of ""419 Scam"" emails. The
objective is to determine which LLMs can accurately detect phishing emails by
analyzing a text file containing email metadata based on predefined criteria.
The experiment concluded that the following models, ChatGPT 3.5,
GPT-3.5-Turbo-Instruct, and ChatGPT, were the most effective in detecting
phishing emails.",2024-04-23,"Het Patel, Umair Rehman, Farkhund Iqbal",http://arxiv.org/pdf/2404.15485v3,cs.CL
Evaluating LLMs for Hardware Design and Test,"Large Language Models (LLMs) have demonstrated capabilities for producing
code in Hardware Description Languages (HDLs). However, most of the focus
remains on their abilities to write functional code, not test code. The
hardware design process consists of both design and test, and so eschewing
validation and verification leaves considerable potential benefit unexplored,
given that a design and test framework may allow for progress towards full
automation of the digital design pipeline. In this work, we perform one of the
first studies exploring how a LLM can both design and test hardware modules
from provided specifications. Using a suite of 8 representative benchmarks, we
examined the capabilities and limitations of the state-of-the-art
conversational LLMs when producing Verilog for functional and verification
purposes. We taped out the benchmarks on a Skywater 130nm shuttle and received
the functional chip.",2024-04-23,"Jason Blocklove, Siddharth Garg, Ramesh Karri, Hammond Pearce",http://arxiv.org/pdf/2405.02326v2,cs.CL
Evaluating Large Language Models for Material Selection,"Material selection is a crucial step in conceptual design due to its
significant impact on the functionality, aesthetics, manufacturability, and
sustainability impact of the final product. This study investigates the use of
Large Language Models (LLMs) for material selection in the product design
process and compares the performance of LLMs against expert choices for various
design scenarios. By collecting a dataset of expert material preferences, the
study provides a basis for evaluating how well LLMs can align with expert
recommendations through prompt engineering and hyperparameter tuning. The
divergence between LLM and expert recommendations is measured across different
model configurations, prompt strategies, and temperature settings. This
approach allows for a detailed analysis of factors influencing the LLMs'
effectiveness in recommending materials. The results from this study highlight
two failure modes, and identify parallel prompting as a useful
prompt-engineering method when using LLMs for material selection. The findings
further suggest that, while LLMs can provide valuable assistance, their
recommendations often vary significantly from those of human experts. This
discrepancy underscores the need for further research into how LLMs can be
better tailored to replicate expert decision-making in material selection. This
work contributes to the growing body of knowledge on how LLMs can be integrated
into the design process, offering insights into their current limitations and
potential for future improvements.",2024-04-23,"Daniele Grandi, Yash Patawari Jain, Allin Groom, Brandon Cramer, Christopher McComb",http://arxiv.org/pdf/2405.03695v1,cs.CL
XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference,"In-context learning (ICL) approaches typically leverage prompting to
condition decoder-only language model generation on reference information.
Just-in-time processing of a context is inefficient due to the quadratic cost
of self-attention operations, and caching is desirable. However, caching
transformer states can easily require almost as much space as the model
parameters. When the right context isn't known in advance, caching ICL can be
challenging. This work addresses these limitations by introducing models that,
inspired by the encoder-decoder architecture, use cross-attention to condition
generation on reference text without the prompt. More precisely, we leverage
pre-trained decoder-only models and only train a small number of added layers.
We use Question-Answering (QA) as a testbed to evaluate the ability of our
models to perform conditional generation and observe that they outperform ICL,
are comparable to fine-tuned prompted LLMs, and drastically reduce the space
footprint relative to standard KV caching by two orders of magnitude.",2024-04-23,"João Monteiro, Étienne Marcotte, Pierre-André Noël, Valentina Zantedeschi, David Vázquez, Nicolas Chapados, Christopher Pal, Perouz Taslakian",http://arxiv.org/pdf/2404.15420v3,cs.CL
Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs,"Multimodal LLMs are the natural evolution of LLMs, and enlarge their
capabilities so as to work beyond the pure textual modality. As research is
being carried out to design novel architectures and vision-and-language
adapters, in this paper we concentrate on endowing such models with the
capability of answering questions that require external knowledge. Our
approach, termed Wiki-LLaVA, aims at integrating an external knowledge source
of multimodal documents, which is accessed through a hierarchical retrieval
pipeline. Relevant passages, using this approach, are retrieved from the
external knowledge source and employed as additional context for the LLM,
augmenting the effectiveness and precision of generated dialogues. We conduct
extensive experiments on datasets tailored for visual question answering with
external data and demonstrate the appropriateness of our approach.",2024-04-23,"Davide Caffagni, Federico Cocchi, Nicholas Moratelli, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara",http://arxiv.org/pdf/2404.15406v2,cs.CL
CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios,"Medical Vision-Language Pretraining (Med-VLP) establishes a connection
between visual content from medical images and the relevant textual
descriptions. Existing Med-VLP methods primarily focus on 2D images depicting a
single body part, notably chest X-rays. In this paper, we extend the scope of
Med-VLP to encompass 3D images, specifically targeting full-body scenarios, by
using a multimodal dataset of CT images and reports. Compared with the 2D
counterpart, 3D VLP is required to effectively capture essential semantics from
significantly sparser representation in 3D imaging. In this paper, we introduce
CT-GLIP (Grounded Language-Image Pretraining with CT scans), a novel method
that constructs organ-level image-text pairs to enhance multimodal contrastive
learning, aligning grounded visual features with precise diagnostic text.
Additionally, we developed an abnormality dictionary to augment contrastive
learning with diverse contrastive pairs. Our method, trained on a multimodal CT
dataset comprising 44,011 organ-level vision-text pairs from 17,702 patients
across 104 organs, demonstrates it can identify organs and abnormalities in a
zero-shot manner using natural languages. The performance of CT-GLIP is
validated on a separate test set of 1,130 patients, focusing on the 16 most
frequent abnormalities across 7 organs. The experimental results show our
model's superior performance over the standard CLIP framework across zero-shot
and fine-tuning scenarios, using both CNN and ViT architectures.",2024-04-23,"Jingyang Lin, Yingda Xia, Jianpeng Zhang, Ke Yan, Le Lu, Jiebo Luo, Ling Zhang",http://arxiv.org/pdf/2404.15272v3,cs.CL
Automatic Layout Planning for Visually-Rich Documents with Instruction-Following Models,"Recent advancements in instruction-following models have made user
interactions with models more user-friendly and efficient, broadening their
applicability. In graphic design, non-professional users often struggle to
create visually appealing layouts due to limited skills and resources. In this
work, we introduce a novel multimodal instruction-following framework for
layout planning, allowing users to easily arrange visual elements into tailored
layouts by specifying canvas size and design purpose, such as for book covers,
posters, brochures, or menus. We developed three layout reasoning tasks to
train the model in understanding and executing layout instructions. Experiments
on two benchmarks show that our method not only simplifies the design process
for non-professionals but also surpasses the performance of few-shot GPT-4V
models, with mIoU higher by 12% on Crello. This progress highlights the
potential of multimodal instruction-following models to automate and simplify
the design process, providing an approachable solution for a wide range of
design tasks on visually-rich documents.",2024-04-23,"Wanrong Zhu, Jennifer Healey, Ruiyi Zhang, William Yang Wang, Tong Sun",http://arxiv.org/pdf/2404.15271v1,cs.CL
Aligning LLM Agents by Learning Latent Preference from User Edits,"We study interactive learning of LLM-based language agents based on user
edits made to the agent's output. In a typical setting such as writing
assistants, the user interacts with a language agent to generate a response
given a context, and may optionally edit the agent response to personalize it
based on their latent preference, in addition to improving the correctness. The
edit feedback is naturally generated, making it a suitable candidate for
improving the agent's alignment with the user's preference, and for reducing
the cost of user edits over time. We propose a learning framework, PRELUDE that
infers a description of the user's latent preference based on historic edit
data. The inferred user preference descriptions are used to define prompts for
generating responses in the future. This avoids fine-tuning the agent, which is
costly, challenging to scale with the number of users, and may even degrade its
performance on other tasks. Furthermore, learning descriptive preference
improves interpretability, allowing the user to view and modify the learned
preference. However, user preference can be complex, subtle, and vary based on
context, making it challenging to learn. To address this, we propose a simple
yet effective algorithm named CIPHER that leverages the LLM to infer the user
preference for a given context based on user edits. In the future, CIPHER
retrieves inferred preferences from the k-closest contexts in the history, and
forms an aggregate preference for response generation. We introduce two
interactive environments -- summarization and email writing, and use a GPT-4
simulated user for evaluation. On both tasks, CIPHER outperforms several
baselines by achieving the lowest edit distance cost while only having a small
overhead in LLM query cost. Our analysis reports that user preferences learned
by CIPHER show significant similarity to the ground truth latent preferences.",2024-04-23,"Ge Gao, Alexey Taymanov, Eduardo Salinas, Paul Mineiro, Dipendra Misra",http://arxiv.org/pdf/2404.15269v3,cs.CL
XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts,"We introduce XFT, a simple yet powerful training scheme, by simply merging
upcycled Mixture-of-Experts (MoE) to unleash the performance limit of
instruction-tuned code Large Language Models (LLMs). While vanilla sparse
upcycling fails to improve instruction tuning, XFT introduces a shared expert
mechanism with a novel routing weight normalization strategy into sparse
upcycling, which significantly boosts instruction tuning. After fine-tuning the
upcycled MoE model, XFT introduces a learnable model merging mechanism to
compile the upcycled MoE model back to a dense model, achieving upcycled
MoE-level performance with only dense-model compute. By applying XFT to a 1.3B
model, we create a new state-of-the-art tiny code LLM (<3B) with 67.1 and 64.6
pass@1 on HumanEval and HumanEval+ respectively. With the same data and model
architecture, XFT improves supervised fine-tuning (SFT) by 13% on HumanEval+,
along with consistent improvements from 2% to 13% on MBPP+, MultiPL-E, and
DS-1000, demonstrating its generalizability. XFT is fully orthogonal to
existing techniques such as Evol-Instruct and OSS-Instruct, opening a new
dimension for improving code instruction tuning. Codes are available at
https://github.com/ise-uiuc/xft.",2024-04-23,"Yifeng Ding, Jiawei Liu, Yuxiang Wei, Terry Yue Zhuo, Lingming Zhang",http://arxiv.org/pdf/2404.15247v2,cs.CL
CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies,"To enhance language models' cultural awareness, we design a generalizable
pipeline to construct cultural knowledge bases from different online
communities on a massive scale. With the pipeline, we construct CultureBank, a
knowledge base built upon users' self-narratives with 12K cultural descriptors
sourced from TikTok and 11K from Reddit. Unlike previous cultural knowledge
resources, CultureBank contains diverse views on cultural descriptors to allow
flexible interpretation of cultural knowledge, and contextualized cultural
scenarios to help grounded evaluation. With CultureBank, we evaluate different
LLMs' cultural awareness, and identify areas for improvement. We also fine-tune
a language model on CultureBank: experiments show that it achieves better
performances on two downstream cultural tasks in a zero-shot setting. Finally,
we offer recommendations based on our findings for future culturally aware
language technologies. The project page is https://culturebank.github.io . The
code and model is at https://github.com/SALT-NLP/CultureBank . The released
CultureBank dataset is at https://huggingface.co/datasets/SALT-NLP/CultureBank .",2024-04-23,"Weiyan Shi, Ryan Li, Yutong Zhang, Caleb Ziems, Chunhua yu, Raya Horesh, Rogério Abreu de Paula, Diyi Yang",http://arxiv.org/pdf/2404.15238v1,cs.CL
Software Mention Recognition with a Three-Stage Framework Based on BERTology Models at SOMD 2024,"This paper describes our systems for the sub-task I in the Software Mention
Detection in Scholarly Publications shared-task. We propose three approaches
leveraging different pre-trained language models (BERT, SciBERT, and XLM-R) to
tackle this challenge. Our bestperforming system addresses the named entity
recognition (NER) problem through a three-stage framework. (1) Entity Sentence
Classification - classifies sentences containing potential software mentions;
(2) Entity Extraction - detects mentions within classified sentences; (3)
Entity Type Classification - categorizes detected mentions into specific
software types. Experiments on the official dataset demonstrate that our
three-stage framework achieves competitive performance, surpassing both other
participating teams and our alternative approaches. As a result, our framework
based on the XLM-R-based model achieves a weighted F1-score of 67.80%,
delivering our team the 3rd rank in Sub-task I for the Software Mention
Recognition task.",2024-04-23,"Thuy Nguyen Thi, Anh Nguyen Viet, Thin Dang Van, Ngan Nguyen Luu Thuy",http://arxiv.org/pdf/2405.01575v1,cs.CL
Re-Thinking Inverse Graphics With Large Language Models,"Inverse graphics -- the task of inverting an image into physical variables
that, when rendered, enable reproduction of the observed scene -- is a
fundamental challenge in computer vision and graphics. Successfully
disentangling an image into its constituent elements, such as the shape, color,
and material properties of the objects of the 3D scene that produced it,
requires a comprehensive understanding of the environment. This complexity
limits the ability of existing carefully engineered approaches to generalize
across domains. Inspired by the zero-shot ability of large language models
(LLMs) to generalize to novel contexts, we investigate the possibility of
leveraging the broad world knowledge encoded in such models to solve
inverse-graphics problems. To this end, we propose the Inverse-Graphics Large
Language Model (IG-LLM), an inverse-graphics framework centered around an LLM,
that autoregressively decodes a visual embedding into a structured,
compositional 3D-scene representation. We incorporate a frozen pre-trained
visual encoder and a continuous numeric head to enable end-to-end training.
Through our investigation, we demonstrate the potential of LLMs to facilitate
inverse graphics through next-token prediction, without the application of
image-space supervision. Our analysis enables new possibilities for precise
spatial reasoning about images that exploit the visual knowledge of LLMs. We
release our code and data at https://ig-llm.is.tue.mpg.de/ to ensure the
reproducibility of our investigation and to facilitate future research.",2024-04-23,"Peter Kulits, Haiwen Feng, Weiyang Liu, Victoria Abrevaya, Michael J. Black",http://arxiv.org/pdf/2404.15228v2,cs.CL
Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel,"Training task-oriented dialogue systems typically requires turn-level
annotations for interacting with their APIs: e.g. a dialogue state and the
system actions taken at each step. These annotations can be costly to produce,
error-prone, and require both domain and annotation expertise. With advances in
LLMs, we hypothesize that unlabeled data and a schema definition are sufficient
for building a working task-oriented dialogue system, completely unsupervised.
We consider a novel unsupervised setting of only (1) a well-defined API schema
(2) a set of unlabeled dialogues between a user and agent. We propose an
innovative approach using expectation-maximization (EM) that infers turn-level
annotations as latent variables using a noisy channel model to build an
end-to-end dialogue agent. Evaluating our approach on the MultiWOZ benchmark,
our method more than doubles the dialogue success rate of a strong GPT-3.5
baseline.",2024-04-23,"Brendan King, Jeffrey Flanigan",http://arxiv.org/pdf/2404.15219v2,cs.CL
Does Instruction Tuning Make LLMs More Consistent?,"The purpose of instruction tuning is enabling zero-shot performance, but
instruction tuning has also been shown to improve chain-of-thought reasoning
and value alignment (Si et al., 2023). Here we consider the impact on
$\textit{consistency}$, i.e., the sensitivity of language models to small
perturbations in the input. We compare 10 instruction-tuned LLaMA models to the
original LLaMA-7b model and show that almost across-the-board they become more
consistent, both in terms of their representations and their predictions in
zero-shot and downstream tasks. We explain these improvements through
mechanistic analyses of factual recall.",2024-04-23,"Constanza Fierro, Jiaang Li, Anders Søgaard",http://arxiv.org/pdf/2404.15206v3,cs.CL
Setting up the Data Printer with Improved English to Ukrainian Machine Translation,"To build large language models for Ukrainian we need to expand our corpora
with large amounts of new algorithmic tasks expressed in natural language.
Examples of task performance expressed in English are abundant, so with a
high-quality translation system our community will be enabled to curate
datasets faster. To aid this goal, we introduce a recipe to build a translation
system using supervised finetuning of a large pretrained language model with a
noisy parallel dataset of 3M pairs of Ukrainian and English sentences followed
by a second phase of training using 17K examples selected by k-fold perplexity
filtering on another dataset of higher quality. Our decoder-only model named
Dragoman beats performance of previous state of the art encoder-decoder models
on the FLORES devtest set.",2024-04-23,"Yurii Paniv, Dmytro Chaplynskyi, Nikita Trynus, Volodymyr Kyrylov",http://arxiv.org/pdf/2404.15196v2,cs.CL
Student Data Paradox and Curious Case of Single Student-Tutor Model: Regressive Side Effects of Training LLMs for Personalized Learning,"The pursuit of personalized education has led to the integration of Large
Language Models (LLMs) in developing intelligent tutoring systems. To better
understand and adapt to individual student needs, including their
misconceptions, LLMs need to be trained on extensive datasets of student-tutor
dialogues. Our research uncovers a fundamental challenge in this approach: the
``Student Data Paradox.'' This paradox emerges when LLMs, trained on student
data to understand learner behavior, inadvertently compromise their own factual
knowledge and reasoning abilities. We investigate this paradox by training
state-of-the-art language models on student-tutor dialogue datasets and
evaluating their performance across multiple benchmarks. These benchmarks
assess various aspects of language model capabilities, including reasoning,
truthfulness, and common sense understanding. Our findings reveal significant
declines in the models' performance across these diverse benchmarks, indicating
a broad impact on their capabilities when trained to model student behavior.
Our research makes two primary contributions: (1) empirical demonstration of
the Student Data Paradox through quantitative analysis of model performance,
and (2) introduction of ``hallucination tokens'' as a mitigation strategy.
These tokens, while improving performance, highlight the persistent challenge
of balancing accurate student behavior modeling with maintaining the LLM's
integrity as an educational tool. This study emphasizes the need for innovative
solutions to reconcile the conflicting goals of faithfully understanding
diverse student cognition while preserving the model's ability to provide
accurate information and guidance.",2024-04-23,"Shashank Sonkar, Naiming Liu, Richard G. Baraniuk",http://arxiv.org/pdf/2404.15156v2,cs.CL
Bias patterns in the application of LLMs for clinical decision support: A comprehensive study,"Large Language Models (LLMs) have emerged as powerful candidates to inform
clinical decision-making processes. While these models play an increasingly
prominent role in shaping the digital landscape, two growing concerns emerge in
healthcare applications: 1) to what extent do LLMs exhibit social bias based on
patients' protected attributes (like race), and 2) how do design choices (like
architecture design and prompting strategies) influence the observed biases? To
answer these questions rigorously, we evaluated eight popular LLMs across three
question-answering (QA) datasets using clinical vignettes (patient
descriptions) standardized for bias evaluations. We employ red-teaming
strategies to analyze how demographics affect LLM outputs, comparing both
general-purpose and clinically-trained models. Our extensive experiments reveal
various disparities (some significant) across protected groups. We also observe
several counter-intuitive patterns such as larger models not being necessarily
less biased and fined-tuned models on medical data not being necessarily better
than the general-purpose models. Furthermore, our study demonstrates the impact
of prompt design on bias patterns and shows that specific phrasing can
influence bias patterns and reflection-type approaches (like Chain of Thought)
can reduce biased outcomes effectively. Consistent with prior studies, we call
on additional evaluations, scrutiny, and enhancement of LLMs used in clinical
decision support applications.",2024-04-23,"Raphael Poulain, Hamed Fayyaz, Rahmatollah Beheshti",http://arxiv.org/pdf/2404.15149v1,cs.CL
Rethinking LLM Memorization through the Lens of Adversarial Compression,"Large language models (LLMs) trained on web-scale datasets raise substantial
concerns regarding permissible data usage. One major question is whether these
models ""memorize"" all their training data or they integrate many data sources
in some way more akin to how a human would learn and synthesize information.
The answer hinges, to a large degree, on how we define memorization. In this
work, we propose the Adversarial Compression Ratio (ACR) as a metric for
assessing memorization in LLMs. A given string from the training data is
considered memorized if it can be elicited by a prompt (much) shorter than the
string itself -- in other words, if these strings can be ""compressed"" with the
model by computing adversarial prompts of fewer tokens. The ACR overcomes the
limitations of existing notions of memorization by (i) offering an adversarial
view of measuring memorization, especially for monitoring unlearning and
compliance; and (ii) allowing for the flexibility to measure memorization for
arbitrary strings at a reasonably low compute. Our definition serves as a
practical tool for determining when model owners may be violating terms around
data usage, providing a potential legal tool and a critical lens through which
to address such scenarios.",2024-04-23,"Avi Schwarzschild, Zhili Feng, Pratyush Maini, Zachary C. Lipton, J. Zico Kolter",http://arxiv.org/pdf/2404.15146v3,cs.CL
GSCo: Towards Generalizable AI in Medicine via Generalist-Specialist Collaboration,"Generalist foundation models (GFMs) are renowned for their exceptional
capability and flexibility in effectively generalizing across diverse tasks and
modalities. In the field of medicine, while GFMs exhibit superior
generalizability based on their extensive intrinsic knowledge as well as
proficiency in instruction following and in-context learning, specialist models
excel in precision due to their domain knowledge. In this work, for the first
time, we explore the synergy between the GFM and specialist models, to enable
precise medical image analysis on a broader scope. Specifically, we propose a
cooperative framework, Generalist-Specialist Collaboration (GSCo), which
consists of two stages, namely the construction of GFM and specialists, and
collaborative inference on downstream tasks. In the construction stage, we
develop MedDr, the largest open-source GFM tailored for medicine, showcasing
exceptional instruction-following and in-context learning capabilities.
Meanwhile, a series of lightweight specialists are crafted for downstream tasks
with low computational cost. In the collaborative inference stage, we introduce
two cooperative mechanisms, Mixture-of-Expert Diagnosis and Retrieval-Augmented
Diagnosis, to harvest the generalist's in-context learning abilities alongside
the specialists' domain expertise. For a comprehensive evaluation, we curate a
large-scale benchmark featuring 28 datasets and about 250,000 images. Extensive
results demonstrate that MedDr consistently outperforms state-of-the-art GFMs
on downstream datasets. Furthermore, GSCo exceeds both GFMs and specialists
across all out-of-domain disease diagnosis datasets. These findings indicate a
significant paradigm shift in the application of GFMs, transitioning from
separate models for specific tasks to a collaborative approach between GFMs and
specialists, thereby advancing the frontiers of generalizable AI in medicine.",2024-04-23,"Sunan He, Yuxiang Nie, Hongmei Wang, Shu Yang, Yihui Wang, Zhiyuan Cai, Zhixuan Chen, Yingxue Xu, Luyang Luo, Huiling Xiang, Xi Lin, Mingxiang Wu, Yifan Peng, George Shih, Ziyang Xu, Xian Wu, Qiong Wang, Ronald Cheong Kin Chan, Varut Vardhanabhuti, Winnie Chiu Wing Chu, Yefeng Zheng, Pranav Rajpurkar, Kang Zhang, Hao Chen",http://arxiv.org/pdf/2404.15127v2,cs.CL
Identifying Fairness Issues in Automatically Generated Testing Content,"Natural language generation tools are powerful and effective for generating
content. However, language models are known to display bias and fairness
issues, making them impractical to deploy for many use cases. We here focus on
how fairness issues impact automatically generated test content, which can have
stringent requirements to ensure the test measures only what it was intended to
measure. Specifically, we review test content generated for a large-scale
standardized English proficiency test with the goal of identifying content that
only pertains to a certain subset of the test population as well as content
that has the potential to be upsetting or distracting to some test takers.
Issues like these could inadvertently impact a test taker's score and thus
should be avoided. This kind of content does not reflect the more
commonly-acknowledged biases, making it challenging even for modern models that
contain safeguards. We build a dataset of 601 generated texts annotated for
fairness and explore a variety of methods for classification: fine-tuning,
topic-based classification, and prompting, including few-shot and
self-correcting prompts. We find that combining prompt self-correction and
few-shot learning performs best, yielding an F1 score of 0.79 on our held-out
test set, while much smaller BERT- and topic-based models have competitive
performance on out-of-domain data.",2024-04-23,"Kevin Stowe, Benny Longwill, Alyssa Francis, Tatsuya Aoyama, Debanjan Ghosh, Swapna Somasundaran",http://arxiv.org/pdf/2404.15104v2,cs.CL
Multi-view Content-aware Indexing for Long Document Retrieval,"Long document question answering (DocQA) aims to answer questions from long
documents over 10k words. They usually contain content structures such as
sections, sub-sections, and paragraph demarcations. However, the indexing
methods of long documents remain under-explored, while existing systems
generally employ fixed-length chunking. As they do not consider content
structures, the resultant chunks can exclude vital information or include
irrelevant content. Motivated by this, we propose the Multi-view Content-aware
indexing (MC-indexing) for more effective long DocQA via (i) segment structured
document into content chunks, and (ii) represent each content chunk in
raw-text, keywords, and summary views. We highlight that MC-indexing requires
neither training nor fine-tuning. Having plug-and-play capability, it can be
seamlessly integrated with any retrievers to boost their performance. Besides,
we propose a long DocQA dataset that includes not only question-answer pair,
but also document structure and answer scope. When compared to state-of-art
chunking schemes, MC-indexing has significantly increased the recall by 42.8%,
30.0%, 23.9%, and 16.3% via top k= 1.5, 3, 5, and 10 respectively. These
improved scores are the average of 8 widely used retrievers (2 sparse and 6
dense) via extensive experiments.",2024-04-23,"Kuicai Dong, Derrick Goh Xin Deik, Yi Quan Lee, Hao Zhang, Xiangyang Li, Cong Zhang, Yong Liu",http://arxiv.org/pdf/2404.15103v1,cs.CL
From Complexity to Clarity: How AI Enhances Perceptions of Scientists and the Public's Understanding of Science,"This paper evaluated the effectiveness of using generative AI to simplify
science communication and enhance the public's understanding of science. By
comparing lay summaries of journal articles from PNAS, yoked to those generated
by AI, this work first assessed linguistic simplicity differences across such
summaries and public perceptions in follow-up experiments. Specifically, Study
1a analyzed simplicity features of PNAS abstracts (scientific summaries) and
significance statements (lay summaries), observing that lay summaries were
indeed linguistically simpler, but effect size differences were small. Study 1b
used a large language model, GPT-4, to create significance statements based on
paper abstracts and this more than doubled the average effect size without
fine-tuning. Study 2 experimentally demonstrated that simply-written GPT
summaries facilitated more favorable perceptions of scientists (they were
perceived as more credible and trustworthy, but less intelligent) than more
complexly-written human PNAS summaries. Crucially, Study 3 experimentally
demonstrated that participants comprehended scientific writing better after
reading simple GPT summaries compared to complex PNAS summaries. In their own
words, participants also summarized scientific papers in a more detailed and
concrete manner after reading GPT summaries compared to PNAS summaries of the
same article. AI has the potential to engage scientific communities and the
public via a simple language heuristic, advocating for its integration into
scientific dissemination for a more informed society.",2024-04-23,David M. Markowitz,http://arxiv.org/pdf/2405.00706v3,cs.CL
Enhancing Textual Personality Detection toward Social Media: Integrating Long-term and Short-term Perspectives,"Textual personality detection aims to identify personality characteristics by
analyzing user-generated content toward social media platforms. Numerous
psychological literature highlighted that personality encompasses both
long-term stable traits and short-term dynamic states. However, existing
studies often concentrate only on either long-term or short-term personality
representations, without effectively combining both aspects. This limitation
hinders a comprehensive understanding of individuals' personalities, as both
stable traits and dynamic states are vital. To bridge this gap, we propose a
Dual Enhanced Network(DEN) to jointly model users' long-term and short-term
personality for textual personality detection. In DEN, a Long-term Personality
Encoding is devised to effectively model long-term stable personality traits.
Short-term Personality Encoding is presented to capture short-term dynamic
personality states. The Bi-directional Interaction component facilitates the
integration of both personality aspects, allowing for a comprehensive
representation of the user's personality. Experimental results on two
personality detection datasets demonstrate the effectiveness of the DEN model
and the benefits of considering both the dynamic and stable nature of
personality characteristics for textual personality detection.",2024-04-23,"Haohao Zhu, Xiaokun Zhang, Junyu Lu, Youlin Wu, Zewen Bai, Changrong Min, Liang Yang, Bo Xu, Dongyu Zhang, Hongfei Lin",http://arxiv.org/pdf/2404.15067v1,cs.CL
Multi-Head Mixture-of-Experts,"Sparse Mixtures of Experts (SMoE) scales model capacity without significant
increases in training and inference costs, but exhibits the following two
issues: (1) Low expert activation, where only a small subset of experts are
activated for optimization. (2) Lacking fine-grained analytical capabilities
for multiple semantic concepts within individual tokens. We propose Multi-Head
Mixture-of-Experts (MH-MoE), which employs a multi-head mechanism to split each
token into multiple sub-tokens. These sub-tokens are then assigned to and
processed by a diverse set of experts in parallel, and seamlessly reintegrated
into the original token form. The multi-head mechanism enables the model to
collectively attend to information from various representation spaces within
different experts, while significantly enhances expert activation, thus deepens
context understanding and alleviate overfitting. Moreover, our MH-MoE is
straightforward to implement and decouples from other SMoE optimization
methods, making it easy to integrate with other SMoE models for enhanced
performance. Extensive experimental results across three tasks: English-focused
language modeling, Multi-lingual language modeling and Masked multi-modality
modeling tasks, demonstrate the effectiveness of MH-MoE.",2024-04-23,"Xun Wu, Shaohan Huang, Wenhui Wang, Furu Wei",http://arxiv.org/pdf/2404.15045v1,cs.CL
TAXI: Evaluating Categorical Knowledge Editing for Language Models,"Humans rarely learn one fact in isolation. Instead, learning a new fact
induces knowledge of other facts about the world. For example, in learning a
korat is a type of cat, you also infer it is a mammal and has claws, ensuring
your model of the world is consistent. Knowledge editing aims to inject new
facts into language models to improve their factuality, but current benchmarks
fail to evaluate consistency, which is critical to ensure efficient, accurate,
and generalizable edits. We manually create TAXI, a new benchmark dataset
specifically created to evaluate consistency in categorical knowledge edits.
TAXI contains 11,120 multiple-choice queries for 976 edits spanning 41
categories (e.g., Dogs), 164 subjects (e.g., Labrador), and 183 properties
(e.g., is a mammal). We then use TAXI to evaluate popular editors' categorical
consistency, measuring how often editing a subject's category appropriately
edits its properties. We find that 1) the editors achieve marginal, yet
non-random consistency, 2) their consistency far underperforms human baselines,
and 3) consistency is more achievable when editing atypical subjects Our code
and data are available at https://github.com/derekpowell/taxi.",2024-04-23,"Derek Powell, Walter Gerych, Thomas Hartvigsen",http://arxiv.org/pdf/2404.15004v2,cs.CL
Comparison of Current Approaches to Lemmatization: A Case Study in Estonian,"This study evaluates three different lemmatization approaches to Estonian --
Generative character-level models, Pattern-based word-level classification
models, and rule-based morphological analysis. According to our experiments, a
significantly smaller Generative model consistently outperforms the
Pattern-based classification model based on EstBERT. Additionally, we observe a
relatively small overlap in errors made by all three models, indicating that an
ensemble of different approaches could lead to improvements.",2024-04-23,"Aleksei Dorkin, Kairit Sirts",http://arxiv.org/pdf/2404.15003v1,cs.CL
Transformers Can Represent $n$-gram Language Models,"Existing work has analyzed the representational capacity of the transformer
architecture by means of formal models of computation. However, the focus so
far has been on analyzing the architecture in terms of language
\emph{acceptance}. We contend that this is an ill-suited problem in the study
of \emph{language models} (LMs), which are definitionally \emph{probability
distributions} over strings. In this paper, we focus on the relationship
between transformer LMs and $n$-gram LMs, a simple and historically relevant
class of language models. We show that transformer LMs using the hard or sparse
attention mechanisms can exactly represent any $n$-gram LM, giving us a
concrete lower bound on their probabilistic representational capacity. This
provides a first step towards understanding the mechanisms that transformer LMs
can use to represent probability distributions over strings.",2024-04-23,"Anej Svete, Ryan Cotterell",http://arxiv.org/pdf/2404.14994v3,cs.CL
A Reproducibility Study of PLAID,"The PLAID (Performance-optimized Late Interaction Driver) algorithm for
ColBERTv2 uses clustered term representations to retrieve and progressively
prune documents for final (exact) document scoring. In this paper, we reproduce
and fill in missing gaps from the original work. By studying the parameters
PLAID introduces, we find that its Pareto frontier is formed of a careful
balance among its three parameters; deviations beyond the suggested settings
can substantially increase latency without necessarily improving its
effectiveness. We then compare PLAID with an important baseline missing from
the paper: re-ranking a lexical system. We find that applying ColBERTv2 as a
re-ranker atop an initial pool of BM25 results provides better
efficiency-effectiveness trade-offs in low-latency settings. However,
re-ranking cannot reach peak effectiveness at higher latency settings due to
limitations in recall of lexical matching and provides a poor approximation of
an exhaustive ColBERTv2 search. We find that recently proposed modifications to
re-ranking that pull in the neighbors of top-scoring documents overcome this
limitation, providing a Pareto frontier across all operational points for
ColBERTv2 when evaluated using a well-annotated dataset. Curious about why
re-ranking methods are highly competitive with PLAID, we analyze the token
representation clusters PLAID uses for retrieval and find that most clusters
are predominantly aligned with a single token and vice versa. Given the
competitive trade-offs that re-ranking baselines exhibit, this work highlights
the importance of carefully selecting pertinent baselines when evaluating the
efficiency of retrieval engines.",2024-04-23,"Sean MacAvaney, Nicola Tonellotto",http://arxiv.org/pdf/2404.14989v1,cs.CL
Atomas: Hierarchical Alignment on Molecule-Text for Unified Molecule Understanding and Generation,"Molecule-and-text cross-modal representation learning has emerged as a
promising direction for enhancing the quality of molecular representation,
thereby improving performance in various scientific fields. However, most
approaches employ a global alignment approach to learn the knowledge from
different modalities that may fail to capture fine-grained information, such as
molecule-and-text fragments and stereoisomeric nuances, which is crucial for
downstream tasks. Furthermore, it is incapable of modeling such information
using a similar global alignment strategy due to the lack of annotations about
the fine-grained fragments in the existing dataset. In this paper, we propose
Atomas, a hierarchical molecular representation learning framework that jointly
learns representations from SMILES strings and text. We design a Hierarchical
Adaptive Alignment model to automatically learn the fine-grained fragment
correspondence between two modalities and align these representations at three
semantic levels. Atomas's end-to-end training framework supports understanding
and generating molecules, enabling a wider range of downstream tasks. Atomas
achieves superior performance across 12 tasks on 11 datasets, outperforming 11
baseline models thus highlighting the effectiveness and versatility of our
method. Scaling experiments further demonstrate Atomas's robustness and
scalability. Moreover, visualization and qualitative analysis, validated by
human experts, confirm the chemical relevance of our approach. Codes are
released on https://github.com/yikunpku/Atomas.",2024-04-23,"Yikun Zhang, Geyan Ye, Chaohao Yuan, Bo Han, Long-Kai Huang, Jianhua Yao, Wei Liu, Yu Rong",http://arxiv.org/pdf/2404.16880v3,cs.CL
Social Media and Artificial Intelligence for Sustainable Cities and Societies: A Water Quality Analysis Use-case,"This paper focuses on a very important societal challenge of water quality
analysis. Being one of the key factors in the economic and social development
of society, the provision of water and ensuring its quality has always remained
one of the top priorities of public authorities. To ensure the quality of
water, different methods for monitoring and assessing the water networks, such
as offline and online surveys, are used. However, these surveys have several
limitations, such as the limited number of participants and low frequency due
to the labor involved in conducting such surveys. In this paper, we propose a
Natural Language Processing (NLP) framework to automatically collect and
analyze water-related posts from social media for data-driven decisions. The
proposed framework is composed of two components, namely (i) text
classification, and (ii) topic modeling. For text classification, we propose a
merit-fusion-based framework incorporating several Large Language Models (LLMs)
where different weight selection and optimization methods are employed to
assign weights to the LLMs. In topic modeling, we employed the BERTopic library
to discover the hidden topic patterns in the water-related tweets. We also
analyzed relevant tweets originating from different regions and countries to
explore global, regional, and country-specific issues and water-related
concerns. We also collected and manually annotated a large-scale dataset, which
is expected to facilitate future research on the topic.",2024-04-23,"Muhammad Asif Auyb, Muhammad Tayyab Zamir, Imran Khan, Hannia Naseem, Nasir Ahmad, Kashif Ahmad",http://arxiv.org/pdf/2404.14977v1,cs.CL
Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems,"Chain-of-Thought (CoT) prompting has enhanced the performance of Large
Language Models (LLMs) across various reasoning tasks. However, CoT still falls
short in dealing with complex math word problems, as it usually suffers from
three pitfalls: semantic misunderstanding errors, calculation errors, and
step-missing errors. Prior studies involve addressing the calculation errors
and step-missing errors, but neglect the semantic misunderstanding errors,
which is the major factor limiting the reasoning performance of LLMs. To this
end, we propose a simple-yet-effective method, namely Deeply Understanding the
Problems (DUP), to improve the LLMs' math problem-solving ability by addressing
semantic misunderstanding errors. The core of our method is to encourage the
LLMs to deeply understand the problems and extract the key problem-solving
information used for better reasoning. Extensive experiments on 10 diverse
reasoning benchmarks show that our DUP method consistently outperforms the
other counterparts by a large margin. More encouragingly, DUP achieves a new
SOTA result on the GSM8K benchmark, with an accuracy of 97.1% under the
zero-shot setting.",2024-04-23,"Qihuang Zhong, Kang Wang, Ziyang Xu, Juhua Liu, Liang Ding, Bo Du",http://arxiv.org/pdf/2404.14963v5,cs.CL
StoryTTS: A Highly Expressive Text-to-Speech Dataset with Rich Textual Expressiveness Annotations,"While acoustic expressiveness has long been studied in expressive
text-to-speech (ETTS), the inherent expressiveness in text lacks sufficient
attention, especially for ETTS of artistic works. In this paper, we introduce
StoryTTS, a highly ETTS dataset that contains rich expressiveness both in
acoustic and textual perspective, from the recording of a Mandarin storytelling
show. A systematic and comprehensive labeling framework is proposed for textual
expressiveness. We analyze and define speech-related textual expressiveness in
StoryTTS to include five distinct dimensions through linguistics, rhetoric,
etc. Then we employ large language models and prompt them with a few manual
annotation examples for batch annotation. The resulting corpus contains 61
hours of consecutive and highly prosodic speech equipped with accurate text
transcriptions and rich textual expressiveness annotations. Therefore, StoryTTS
can aid future ETTS research to fully mine the abundant intrinsic textual and
acoustic features. Experiments are conducted to validate that TTS models can
generate speech with improved expressiveness when integrating with the
annotated textual labels in StoryTTS.",2024-04-23,"Sen Liu, Yiwei Guo, Xie Chen, Kai Yu",http://arxiv.org/pdf/2404.14946v1,cs.CL
Does It Make Sense to Explain a Black Box With Another Black Box?,"Although counterfactual explanations are a popular approach to explain ML
black-box classifiers, they are less widespread in NLP. Most methods find those
explanations by iteratively perturbing the target document until it is
classified differently by the black box. We identify two main families of
counterfactual explanation methods in the literature, namely, (a)
\emph{transparent} methods that perturb the target by adding, removing, or
replacing words, and (b) \emph{opaque} approaches that project the target
document into a latent, non-interpretable space where the perturbation is
carried out subsequently. This article offers a comparative study of the
performance of these two families of methods on three classical NLP tasks. Our
empirical evidence shows that opaque approaches can be an overkill for
downstream applications such as fake news detection or sentiment analysis since
they add an additional level of complexity with no significant performance
gain. These observations motivate our discussion, which raises the question of
whether it makes sense to explain a black box using another black box.",2024-04-23,"Julien Delaunay, Luis Galárraga, Christine Largouët",http://arxiv.org/pdf/2404.14943v1,cs.CL
Graph Machine Learning in the Era of Large Language Models (LLMs),"Graphs play an important role in representing complex relationships in
various domains like social networks, knowledge graphs, and molecular
discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have
emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the
representation and processing of graph structures. Recently, LLMs have
demonstrated unprecedented capabilities in language tasks and are widely
adopted in a variety of applications such as computer vision and recommender
systems. This remarkable success has also attracted interest in applying LLMs
to the graph domain. Increasing efforts have been made to explore the potential
of LLMs in advancing Graph ML's generalization, transferability, and few-shot
learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in
reliable factual knowledge, which can be utilized to enhance the reasoning
capabilities of LLMs and potentially alleviate their limitations such as
hallucinations and the lack of explainability. Given the rapid progress of this
research direction, a systematic review summarizing the latest advancements for
Graph ML in the era of LLMs is necessary to provide an in-depth understanding
to researchers and practitioners. Therefore, in this survey, we first review
the recent developments in Graph ML. We then explore how LLMs can be utilized
to enhance the quality of graph features, alleviate the reliance on labeled
data, and address challenges such as graph heterogeneity and
out-of-distribution (OOD) generalization. Afterward, we delve into how graphs
can enhance LLMs, highlighting their abilities to enhance LLM pre-training and
inference. Furthermore, we investigate various applications and discuss the
potential future directions in this promising field.",2024-04-23,"Wenqi Fan, Shijie Wang, Jiani Huang, Zhikai Chen, Yu Song, Wenzhuo Tang, Haitao Mao, Hui Liu, Xiaorui Liu, Dawei Yin, Qing Li",http://arxiv.org/pdf/2404.14928v2,cs.CL
Pillars of Grammatical Error Correction: Comprehensive Inspection Of Contemporary Approaches In The Era of Large Language Models,"In this paper, we carry out experimental research on Grammatical Error
Correction, delving into the nuances of single-model systems, comparing the
efficiency of ensembling and ranking methods, and exploring the application of
large language models to GEC as single-model systems, as parts of ensembles,
and as ranking methods. We set new state-of-the-art performance with F_0.5
scores of 72.8 on CoNLL-2014-test and 81.4 on BEA-test, respectively. To
support further advancements in GEC and ensure the reproducibility of our
research, we make our code, trained models, and systems' outputs publicly
available.",2024-04-23,"Kostiantyn Omelianchuk, Andrii Liubonko, Oleksandr Skurzhanskyi, Artem Chernodub, Oleksandr Korniienko, Igor Samokhin",http://arxiv.org/pdf/2404.14914v1,cs.CL
Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice,"Large Language Models (LLMs) are frequently discussed in academia and the
general public as support tools for virtually any use case that relies on the
production of text, including software engineering. Currently there is much
debate, but little empirical evidence, regarding the practical usefulness of
LLM-based tools such as ChatGPT for engineers in industry. We conduct an
observational study of 24 professional software engineers who have been using
ChatGPT over a period of one week in their jobs, and qualitatively analyse
their dialogues with the chatbot as well as their overall experience (as
captured by an exit survey). We find that, rather than expecting ChatGPT to
generate ready-to-use software artifacts (e.g., code), practitioners more often
use ChatGPT to receive guidance on how to solve their tasks or learn about a
topic in more abstract terms. We also propose a theoretical framework for how
(i) purpose of the interaction, (ii) internal factors (e.g., the user's
personality), and (iii) external factors (e.g., company policy) together shape
the experience (in terms of perceived usefulness and trust). We envision that
our framework can be used by future research to further the academic discussion
on LLM usage by software engineering practitioners, and to serve as a reference
point for the design of future empirical LLM research in this domain.",2024-04-23,"Ranim Khojah, Mazen Mohamad, Philipp Leitner, Francisco Gomes de Oliveira Neto",http://arxiv.org/pdf/2404.14901v2,cs.CL
Beyond the Speculative Game: A Survey of Speculative Execution in Large Language Models,"With the increasingly giant scales of (causal) large language models (LLMs),
the inference efficiency comes as one of the core concerns along the improved
performance. In contrast to the memory footprint, the latency bottleneck seems
to be of greater importance as there can be billions of requests to a LLM
(e.g., GPT-4) per day. The bottleneck is mainly due to the autoregressive
innateness of LLMs, where tokens can only be generated sequentially during
decoding. To alleviate the bottleneck, the idea of speculative execution, which
originates from the field of computer architecture, is introduced to LLM
decoding in a \textit{draft-then-verify} style. Under this regime, a sequence
of tokens will be drafted in a fast pace by utilizing some heuristics, and then
the tokens shall be verified in parallel by the LLM. As the costly sequential
inference is parallelized, LLM decoding speed can be significantly boosted.
Driven by the success of LLMs in recent couple of years, a growing literature
in this direction has emerged. Yet, there lacks a position survey to summarize
the current landscape and draw a roadmap for future development of this
promising area. To meet this demand, we present the very first survey paper
that reviews and unifies literature of speculative execution in LLMs (e.g.,
blockwise parallel decoding, speculative decoding, etc.) in a comprehensive
framework and a systematic taxonomy. Based on the taxonomy, we present a
critical review and comparative analysis of the current arts. Finally we
highlight various key challenges and future directions to further develop the
area.",2024-04-23,"Chen Zhang, Zhuorui Liu, Dawei Song",http://arxiv.org/pdf/2404.14897v1,cs.CL
Language in Vivo vs. in Silico: Size Matters but Larger Language Models Still Do Not Comprehend Language on a Par with Humans,"Understanding the limits of language is a prerequisite for Large Language
Models (LLMs) to act as theories of natural language. LLM performance in some
language tasks presents both quantitative and qualitative differences from that
of humans, however it remains to be determined whether such differences are
amenable to model size. This work investigates the critical role of model
scaling, determining whether increases in size make up for such differences
between humans and models. We test three LLMs from different families (Bard,
137 billion parameters; ChatGPT-3.5, 175 billion; ChatGPT-4, 1.5 trillion) on a
grammaticality judgment task featuring anaphora, center embedding,
comparatives, and negative polarity. N=1,200 judgments are collected and scored
for accuracy, stability, and improvements in accuracy upon repeated
presentation of a prompt. Results of the best performing LLM, ChatGPT-4, are
compared to results of n=80 humans on the same stimuli. We find that humans are
overall less accurate than ChatGPT-4 (76% vs. 80% accuracy, respectively), but
that this is due to ChatGPT-4 outperforming humans only in one task condition,
namely on grammatical sentences. Additionally, ChatGPT-4 wavers more than
humans in its answers (12.5% vs. 9.6% likelihood of an oscillating answer,
respectively). Thus, while increased model size may lead to better performance,
LLMs are still not sensitive to (un)grammaticality the same way as humans are.
It seems possible but unlikely that scaling alone can fix this issue. We
interpret these results by comparing language learning in vivo and in silico,
identifying three critical differences concerning (i) the type of evidence,
(ii) the poverty of the stimulus, and (iii) the occurrence of semantic
hallucinations due to impenetrable linguistic reference.",2024-04-23,"Vittoria Dentella, Fritz Guenther, Evelina Leivada",http://arxiv.org/pdf/2404.14883v2,cs.CL
From Matching to Generation: A Survey on Generative Information Retrieval,"Information Retrieval (IR) systems are crucial tools for users to access
information, which have long been dominated by traditional methods relying on
similarity matching. With the advancement of pre-trained language models,
generative information retrieval (GenIR) emerges as a novel paradigm,
attracting increasing attention. Based on the form of information provided to
users, current research in GenIR can be categorized into two aspects:
\textbf{(1) Generative Document Retrieval} (GR) leverages the generative
model's parameters for memorizing documents, enabling retrieval by directly
generating relevant document identifiers without explicit indexing. \textbf{(2)
Reliable Response Generation} employs language models to directly generate
information users seek, breaking the limitations of traditional IR in terms of
document granularity and relevance matching while offering flexibility,
efficiency, and creativity to meet practical needs. This paper aims to
systematically review the latest research progress in GenIR. We will summarize
the advancements in GR regarding model training and structure, document
identifier, incremental learning, etc., as well as progress in reliable
response generation in aspects of internal knowledge memorization, external
knowledge augmentation, etc. We also review the evaluation, challenges and
future developments in GenIR systems. This review aims to offer a comprehensive
reference for researchers, encouraging further development in the GenIR field.
Github Repository: https://github.com/RUC-NLPIR/GenIR-Survey",2024-04-23,"Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yuyao Zhang, Peitian Zhang, Yutao Zhu, Zhicheng Dou",http://arxiv.org/pdf/2404.14851v4,cs.CL
"Simple, Efficient and Scalable Structure-aware Adapter Boosts Protein Language Models","Fine-tuning Pre-trained protein language models (PLMs) has emerged as a
prominent strategy for enhancing downstream prediction tasks, often
outperforming traditional supervised learning approaches. As a widely applied
powerful technique in natural language processing, employing
Parameter-Efficient Fine-Tuning techniques could potentially enhance the
performance of PLMs. However, the direct transfer to life science tasks is
non-trivial due to the different training strategies and data forms. To address
this gap, we introduce SES-Adapter, a simple, efficient, and scalable adapter
method for enhancing the representation learning of PLMs. SES-Adapter
incorporates PLM embeddings with structural sequence embeddings to create
structure-aware representations. We show that the proposed method is compatible
with different PLM architectures and across diverse tasks. Extensive
evaluations are conducted on 2 types of folding structures with notable quality
differences, 9 state-of-the-art baselines, and 9 benchmark datasets across
distinct downstream tasks. Results show that compared to vanilla PLMs,
SES-Adapter improves downstream task performance by a maximum of 11% and an
average of 3%, with significantly accelerated training speed by a maximum of
1034% and an average of 362%, the convergence rate is also improved by
approximately 2 times. Moreover, positive optimization is observed even with
low-quality predicted structures. The source code for SES-Adapter is available
at https://github.com/tyang816/SES-Adapter.",2024-04-23,"Yang Tan, Mingchen Li, Bingxin Zhou, Bozitao Zhong, Lirong Zheng, Pan Tan, Ziyi Zhou, Huiqun Yu, Guisheng Fan, Liang Hong",http://arxiv.org/pdf/2404.14850v1,cs.CL
Towards Universal Dense Blocking for Entity Resolution,"Blocking is a critical step in entity resolution, and the emergence of neural
network-based representation models has led to the development of dense
blocking as a promising approach for exploring deep semantics in blocking.
However, previous advanced self-supervised dense blocking approaches require
domain-specific training on the target domain, which limits the benefits and
rapid adaptation of these methods. To address this issue, we propose
UniBlocker, a dense blocker that is pre-trained on a domain-independent,
easily-obtainable tabular corpus using self-supervised contrastive learning. By
conducting domain-independent pre-training, UniBlocker can be adapted to
various downstream blocking scenarios without requiring domain-specific
fine-tuning. To evaluate the universality of our entity blocker, we also
construct a new benchmark covering a wide range of blocking tasks from multiple
domains and scenarios. Our experiments show that the proposed UniBlocker,
without any domain-specific learning, significantly outperforms previous self-
and unsupervised dense blocking methods and is comparable and complementary to
the state-of-the-art sparse blocking methods.",2024-04-23,"Tianshu Wang, Hongyu Lin, Xianpei Han, Xiaoyang Chen, Boxi Cao, Le Sun",http://arxiv.org/pdf/2404.14831v2,cs.CL
Sentence-Level or Token-Level? A Comprehensive Study on Knowledge Distillation,"Knowledge distillation, transferring knowledge from a teacher model to a
student model, has emerged as a powerful technique in neural machine
translation for compressing models or simplifying training targets. Knowledge
distillation encompasses two primary methods: sentence-level distillation and
token-level distillation. In sentence-level distillation, the student model is
trained to align with the output of the teacher model, which can alleviate the
training difficulty and give student model a comprehensive understanding of
global structure. Differently, token-level distillation requires the student
model to learn the output distribution of the teacher model, facilitating a
more fine-grained transfer of knowledge. Studies have revealed divergent
performances between sentence-level and token-level distillation across
different scenarios, leading to the confusion on the empirical selection of
knowledge distillation methods. In this study, we argue that token-level
distillation, with its more complex objective (i.e., distribution), is better
suited for ``simple'' scenarios, while sentence-level distillation excels in
``complex'' scenarios. To substantiate our hypothesis, we systematically
analyze the performance of distillation methods by varying the model size of
student models, the complexity of text, and the difficulty of decoding
procedure. While our experimental results validate our hypothesis, defining the
complexity level of a given scenario remains a challenging task. So we further
introduce a novel hybrid method that combines token-level and sentence-level
distillation through a gating mechanism, aiming to leverage the advantages of
both individual methods. Experiments demonstrate that the hybrid method
surpasses the performance of token-level or sentence-level distillation methods
and the previous works by a margin, demonstrating the effectiveness of the
proposed hybrid method.",2024-04-23,"Jingxuan Wei, Linzhuang Sun, Yichong Leng, Xu Tan, Bihui Yu, Ruifeng Guo",http://arxiv.org/pdf/2404.14827v1,cs.CL
Enhancing Chain of Thought Prompting in Large Language Models via Reasoning Patterns,"Chain of Thought (CoT) prompting can encourage language models to engage in
multi-step logical reasoning. The quality of the provided demonstrations
significantly influences the success of downstream inference tasks. Current
unsupervised CoT methods primarily select examples based on the semantics of
the questions, which can introduce noise and lack interpretability. In this
paper, we propose leveraging reasoning patterns to enhance CoT prompting
effectiveness. Reasoning patterns represent the process by which language
models arrive at their final results. By utilizing prior knowledge and
prompt-based methods from large models, we first construct task-specific
pattern sets. We then select diverse demonstrations based on different
reasoning patterns. This approach not only mitigates the impact of noise but
also provides explicit interpretability to help us understand the mechanisms of
CoT. Extensive experiments demonstrate that our method is more robust and
consistently leads to improvements across various reasoning tasks.",2024-04-23,"Yufeng Zhang, Xuepeng Wang, Lingxiang Wu, Jinqiao Wang",http://arxiv.org/pdf/2404.14812v2,cs.CL
"A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications","A graph is a fundamental data model to represent various entities and their
complex relationships in society and nature, such as social networks,
transportation networks, financial networks, and biomedical systems. Recently,
large language models (LLMs) have showcased a strong generalization ability to
handle various NLP and multi-mode tasks to answer users' arbitrary questions
and specific-domain content generation. Compared with graph learning models,
LLMs enjoy superior advantages in addressing the challenges of generalizing
graph tasks by eliminating the need for training graph learning models and
reducing the cost of manual annotation. In this survey, we conduct a
comprehensive investigation of existing LLM studies on graph data, which
summarizes the relevant graph analytics tasks solved by advanced LLM models and
points out the existing remaining challenges and future directions.
Specifically, we study the key problems of LLM-based generative graph analytics
(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),
LLM-based graph inference and learning (LLM-GIL), and graph-LLM-based
applications. LLM-GQP focuses on an integration of graph analytics techniques
and LLM prompts, including graph understanding and knowledge graph (KG) based
augmented retrieval, while LLM-GIL focuses on learning and reasoning over
graphs, including graph learning, graph-formed reasoning and graph
representation. We summarize the useful prompts incorporated into LLM to handle
different graph downstream tasks. Moreover, we give a summary of LLM model
evaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM
models. We also explore open problems and future directions in this exciting
interdisciplinary research area of LLMs and graph analytics.",2024-04-23,"Wenbo Shang, Xin Huang",http://arxiv.org/pdf/2404.14809v1,cs.CL
Watch Out for Your Guidance on Generation! Exploring Conditional Backdoor Attacks against Large Language Models,"Mainstream backdoor attacks on large language models (LLMs) typically set a
fixed trigger in the input instance and specific responses for triggered
queries. However, the fixed trigger setting (e.g., unusual words) may be easily
detected by human detection, limiting the effectiveness and practicality in
real-world scenarios. To enhance the stealthiness of backdoor activation, we
present a new poisoning paradigm against LLMs triggered by specifying
generation conditions, which are commonly adopted strategies by users during
model inference. The poisoned model performs normally for output under
normal/other generation conditions, while becomes harmful for output under
target generation conditions. To achieve this objective, we introduce BrieFool,
an efficient attack framework. It leverages the characteristics of generation
conditions by efficient instruction sampling and poisoning data generation,
thereby influencing the behavior of LLMs under target conditions. Our attack
can be generally divided into two types with different targets: Safety
unalignment attack and Ability degradation attack. Our extensive experiments
demonstrate that BrieFool is effective across safety domains and ability
domains, achieving higher success rates than baseline methods, with 94.3 % on
GPT-3.5-turbo",2024-04-23,"Jiaming He, Wenbo Jiang, Guanyu Hou, Wenshu Fan, Rui Zhang, Hongwei Li",http://arxiv.org/pdf/2404.14795v5,cs.CL
Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches,"This study presents a comprehensive analysis and comparison of two
predominant fine-tuning methodologies - full-parameter fine-tuning and
parameter-efficient tuning - within the context of medical Large Language
Models (LLMs). We developed and refined a series of LLMs, based on the Llama-2
architecture, specifically designed to enhance medical knowledge retrieval,
reasoning, and question-answering capabilities. Our experiments systematically
evaluate the effectiveness of these tuning strategies across various well-known
medical benchmarks. Notably, our medical LLM Med42 showed an accuracy level of
72% on the US Medical Licensing Examination (USMLE) datasets, setting a new
standard in performance for openly available medical LLMs. Through this
comparative analysis, we aim to identify the most effective and efficient
method for fine-tuning LLMs in the medical domain, thereby contributing
significantly to the advancement of AI-driven healthcare applications.",2024-04-23,"Clément Christophe, Praveen K Kanithi, Prateek Munjal, Tathagata Raha, Nasir Hayat, Ronnie Rajan, Ahmed Al-Mahrooqi, Avani Gupta, Muhammad Umar Salman, Gurpreet Gosal, Bhargav Kanakiya, Charles Chen, Natalia Vassilieva, Boulbaba Ben Amor, Marco AF Pimentel, Shadab Khan",http://arxiv.org/pdf/2404.14779v1,cs.CL
ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning,"Large Language Models (LLMs) and multi-agent systems have shown impressive
capabilities in natural language tasks but face challenges in clinical trial
applications, primarily due to limited access to external knowledge.
Recognizing the potential of advanced clinical trial tools that aggregate and
predict based on the latest medical data, we propose an integrated solution to
enhance their accessibility and utility. We introduce Clinical Agent System
(ClinicalAgent), a clinical multi-agent system designed for clinical trial
tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct
reasoning technology. This integration not only boosts LLM performance in
clinical contexts but also introduces novel functionalities. The proposed
method achieves competitive predictive performance in clinical trial outcome
prediction (0.7908 PR-AUC), obtaining a 0.3326 improvement over the standard
prompt Method. Publicly available code can be found at
https://anonymous.4open.science/r/ClinicalAgent-6671.",2024-04-23,"Ling Yue, Sixue Xing, Jintai Chen, Tianfan Fu",http://arxiv.org/pdf/2404.14777v2,cs.CL
Simulating Task-Oriented Dialogues with State Transition Graphs and Large Language Models,"This paper explores SynTOD, a new synthetic data generation approach for
developing end-to-end Task-Oriented Dialogue (TOD) Systems capable of handling
complex tasks such as intent classification, slot filling, conversational
question-answering, and retrieval-augmented response generation, without
relying on crowdsourcing or real-world data. SynTOD utilizes a state transition
graph to define the desired behavior of a TOD system and generates diverse,
structured conversations through random walks and response simulation using
large language models (LLMs). In our experiments, using graph-guided response
simulations leads to significant improvements in intent classification, slot
filling and response relevance compared to naive single-prompt simulated
conversations. We also investigate the end-to-end TOD effectiveness of
different base and instruction-tuned LLMs, with and without the constructed
synthetic conversations. Finally, we explore how various LLMs can evaluate
responses in a TOD system and how well they are correlated with human
judgments. Our findings pave the path towards quick development and evaluation
of domain-specific TOD systems. We release our datasets, models, and code for
research purposes.",2024-04-23,"Chris Samarinas, Pracha Promthaw, Atharva Nijasure, Hansi Zeng, Julian Killingback, Hamed Zamani",http://arxiv.org/pdf/2404.14772v1,cs.CL
Retrieval Augmented Generation for Domain-specific Question Answering,"Question answering (QA) has become an important application in the advanced
development of large language models. General pre-trained large language models
for question-answering are not trained to properly understand the knowledge or
terminology for a specific domain, such as finance, healthcare, education, and
customer service for a product. To better cater to domain-specific
understanding, we build an in-house question-answering system for Adobe
products. We propose a novel framework to compile a large question-answer
database and develop the approach for retrieval-aware finetuning of a Large
Language model. We showcase that fine-tuning the retriever leads to major
improvements in the final generation. Our overall approach reduces
hallucinations during generation while keeping in context the latest retrieval
information for contextual grounding.",2024-04-23,"Sanat Sharma, David Seunghyun Yoon, Franck Dernoncourt, Dewang Sultania, Karishma Bagga, Mengjiao Zhang, Trung Bui, Varun Kotte",http://arxiv.org/pdf/2404.14760v2,cs.CL
Semantic Cells: Evolutional Process to Acquire Sense Diversity of Items,"Previous models for learning the semantic vectors of items and their groups,
such as words, sentences, nodes, and graphs, using distributed representation
have been based on the assumption that the basic sense of an item corresponds
to one vector composed of dimensions corresponding to hidden contexts in the
target real world, from which multiple senses of the item are obtained by
conforming to lexical databases or adapting to the context. However, there may
be multiple senses of an item, which are hardly assimilated and change or
evolve dynamically following the contextual shift even within a document or a
restricted period. This is a process similar to the evolution or adaptation of
a living entity with/to environmental shifts. Setting the scope of
disambiguation of items for sensemaking, the author presents a method in which
a word or item in the data embraces multiple semantic vectors that evolve via
interaction with others, similar to a cell embracing chromosomes crossing over
with each other. We obtained two preliminary results: (1) the role of a word
that evolves to acquire the largest or lower-middle variance of semantic
vectors tends to be explainable by the author of the text; (2) the epicenters
of earthquakes that acquire larger variance via crossover, corresponding to the
interaction with diverse areas of land crust, are likely to correspond to the
epicenters of forthcoming large earthquakes.",2024-04-23,"Yukio Ohsawa, Dingming Xue, Kaira Sekiguchi",http://arxiv.org/pdf/2404.14749v2,cs.CL
SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning,"The pre-trained Large Language Models (LLMs) can be adapted for many
downstream tasks and tailored to align with human preferences through
fine-tuning. Recent studies have discovered that LLMs can achieve desirable
performance with only a small amount of high-quality data, suggesting that a
large amount of the data in these extensive datasets is redundant or even
harmful. Identifying high-quality data from vast datasets to curate small yet
effective datasets has emerged as a critical challenge. In this paper, we
introduce SHED, an automated dataset refinement framework based on Shapley
value for instruction fine-tuning. SHED eliminates the need for human
intervention or the use of commercial LLMs. Moreover, the datasets curated
through SHED exhibit transferability, indicating they can be reused across
different LLMs with consistently high performance. We conduct extensive
experiments to evaluate the datasets curated by SHED. The results demonstrate
SHED's superiority over state-of-the-art methods across various tasks and LLMs;
notably, datasets comprising only 10% of the original data selected by SHED
achieve performance comparable to or surpassing that of the full datasets.",2024-04-23,"Yexiao He, Ziyao Wang, Zheyu Shen, Guoheng Sun, Yucong Dai, Yongkai Wu, Hongyi Wang, Ang Li",http://arxiv.org/pdf/2405.00705v2,cs.CL
Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing,"This position paper concerns the use of religious texts in Natural Language
Processing (NLP), which is of special interest to the Ethics of NLP. Religious
texts are expressions of culturally important values, and machine learned
models have a propensity to reproduce cultural values encoded in their training
data. Furthermore, translations of religious texts are frequently used by NLP
researchers when language data is scarce. This repurposes the translations from
their original uses and motivations, which often involve attracting new
followers. This paper argues that NLP's use of such texts raises considerations
that go beyond model biases, including data provenance, cultural contexts, and
their use in proselytism. We argue for more consideration of researcher
positionality, and of the perspectives of marginalized linguistic and religious
communities.",2024-04-23,Ben Hutchinson,http://arxiv.org/pdf/2404.14740v2,cs.CL
Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering,"To address the issues of insufficient knowledge and hallucination in Large
Language Models (LLMs), numerous studies have explored integrating LLMs with
Knowledge Graphs (KGs). However, these methods are typically evaluated on
conventional Knowledge Graph Question Answering (KGQA) with complete KGs, where
all factual triples required for each question are entirely covered by the
given KG. In such cases, LLMs primarily act as an agent to find answer entities
within the KG, rather than effectively integrating the internal knowledge of
LLMs and external knowledge sources such as KGs. In fact, KGs are often
incomplete to cover all the knowledge required to answer questions. To simulate
these real-world scenarios and evaluate the ability of LLMs to integrate
internal and external knowledge, we propose leveraging LLMs for QA under
Incomplete Knowledge Graph (IKGQA), where the provided KG lacks some of the
factual triples for each question, and construct corresponding datasets. To
handle IKGQA, we propose a training-free method called Generate-on-Graph (GoG),
which can generate new factual triples while exploring KGs. Specifically, GoG
performs reasoning through a Thinking-Searching-Generating framework, which
treats LLM as both Agent and KG in IKGQA. Experimental results on two datasets
demonstrate that our GoG outperforms all previous methods.",2024-04-23,"Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song, Hanghang Tong, Guang Liu, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2404.14741v3,cs.CL
Qualitative Approaches to Voice UX,"Voice is a natural mode of expression offered by modern computer-based
systems. Qualitative perspectives on voice-based user experiences (voice UX)
offer rich descriptions of complex interactions that numbers alone cannot fully
represent. We conducted a systematic review of the literature on qualitative
approaches to voice UX, capturing the nature of this body of work in a
systematic map and offering a qualitative synthesis of findings. We highlight
the benefits of qualitative methods for voice UX research, identify
opportunities for increasing rigour in methods and outcomes, and distill
patterns of experience across a diversity of devices and modes of qualitative
praxis.",2024-04-23,"Katie Seaborn, Jacqueline Urakami, Peter Pennefather, Norihisa P. Miyake",http://arxiv.org/pdf/2404.14736v1,cs.CL
Insights into Alignment: Evaluating DPO and its Variants Across Multiple Tasks,"This study evaluates Direct Preference Optimization (DPO) and its variants
for aligning Large Language Models (LLMs) with human preferences, testing three
configurations: (1) with Supervised Fine Tuning (SFT), (2) without SFT, and (3)
without SFT but using an instruction tuned model. We further investigate how
training set size influences model performance. Our evaluation spans 13
benchmarks covering dialogue, reasoning, mathematical problem-solving, question
answering, truthfulness, MT-Bench, Big Bench, and the Open LLM Leaderboard. We
find that: (1) alignment methods often achieve near optimal performance even
with smaller subsets of training data; (2) although they offer limited
improvements on complex reasoning tasks, they enhance mathematical
problem-solving; and (3) using an instruction tuned model improves
truthfulness. These insights highlight the conditions under which alignment
methods excel, as well as their limitations.",2024-04-23,"Amir Saeidi, Shivanshu Verma, Md Nayem Uddin, Chitta Baral",http://arxiv.org/pdf/2404.14723v2,cs.CL
"Bayesian Example Selection Improves In-Context Learning for Speech, Text, and Visual Modalities","Large language models (LLMs) can adapt to new tasks through in-context
learning (ICL) based on a few examples presented in dialogue history without
any model parameter update. Despite such convenience, the performance of ICL
heavily depends on the quality of the in-context examples presented, which
makes the in-context example selection approach a critical choice. This paper
proposes a novel Bayesian in-Context example Selection method (ByCS) for ICL.
Extending the inference probability conditioned on in-context examples based on
Bayes' theorem, ByCS focuses on the inverse inference conditioned on test
input. Following the assumption that accurate inverse inference probability
(likelihood) will result in accurate inference probability (posterior),
in-context examples are selected based on their inverse inference results.
Diverse and extensive cross-tasking and cross-modality experiments are
performed with speech, text, and image examples. Experimental results show the
efficacy and robustness of our ByCS method on various models, tasks and
modalities.",2024-04-23,"Siyin Wang, Chao-Han Huck Yang, Ji Wu, Chao Zhang",http://arxiv.org/pdf/2404.14716v2,cs.CL
FINEMATCH: Aspect-based Fine-grained Image and Text Mismatch Detection and Correction,"Recent progress in large-scale pre-training has led to the development of
advanced vision-language models (VLMs) with remarkable proficiency in
comprehending and generating multimodal content. Despite the impressive ability
to perform complex reasoning for VLMs, current models often struggle to
effectively and precisely capture the compositional information on both the
image and text sides. To address this, we propose FineMatch, a new aspect-based
fine-grained text and image matching benchmark, focusing on text and image
mismatch detection and correction. This benchmark introduces a novel task for
boosting and evaluating the VLMs' compositionality for aspect-based
fine-grained text and image matching. In this task, models are required to
identify mismatched aspect phrases within a caption, determine the aspect's
class, and propose corrections for an image-text pair that may contain between
0 and 3 mismatches. To evaluate the models' performance on this new task, we
propose a new evaluation metric named ITM-IoU for which our experiments show a
high correlation to human evaluation. In addition, we also provide a
comprehensive experimental analysis of existing mainstream VLMs, including
fully supervised learning and in-context learning settings. We have found that
models trained on FineMatch demonstrate enhanced proficiency in detecting
fine-grained text and image mismatches. Moreover, models (e.g., GPT-4V, Gemini
Pro Vision) with strong abilities to perform multimodal in-context learning are
not as skilled at fine-grained compositional image and text matching analysis.
With FineMatch, we are able to build a system for text-to-image generation
hallucination detection and correction.",2024-04-23,"Hang Hua, Jing Shi, Kushal Kafle, Simon Jenni, Daoan Zhang, John Collomosse, Scott Cohen, Jiebo Luo",http://arxiv.org/pdf/2404.14715v2,cs.CL
FlashSpeech: Efficient Zero-Shot Speech Synthesis,"Recent progress in large-scale zero-shot speech synthesis has been
significantly advanced by language models and diffusion models. However, the
generation process of both methods is slow and computationally intensive.
Efficient speech synthesis using a lower computing budget to achieve quality on
par with previous work remains a significant challenge. In this paper, we
present FlashSpeech, a large-scale zero-shot speech synthesis system with
approximately 5\% of the inference time compared with previous work.
FlashSpeech is built on the latent consistency model and applies a novel
adversarial consistency training approach that can train from scratch without
the need for a pre-trained diffusion model as the teacher. Furthermore, a new
prosody generator module enhances the diversity of prosody, making the rhythm
of the speech sound more natural. The generation processes of FlashSpeech can
be achieved efficiently with one or two sampling steps while maintaining high
audio quality and high similarity to the audio prompt for zero-shot speech
generation. Our experimental results demonstrate the superior performance of
FlashSpeech. Notably, FlashSpeech can be about 20 times faster than other
zero-shot speech synthesis systems while maintaining comparable performance in
terms of voice quality and similarity. Furthermore, FlashSpeech demonstrates
its versatility by efficiently performing tasks like voice conversion, speech
editing, and diverse speech sampling. Audio samples can be found in
https://flashspeech.github.io/.",2024-04-23,"Zhen Ye, Zeqian Ju, Haohe Liu, Xu Tan, Jianyi Chen, Yiwen Lu, Peiwen Sun, Jiahao Pan, Weizhen Bian, Shulin He, Wei Xue, Qifeng Liu, Yike Guo",http://arxiv.org/pdf/2404.14700v4,cs.CL
MisgenderMender: A Community-Informed Approach to Interventions for Misgendering,"Content Warning: This paper contains examples of misgendering and erasure
that could be offensive and potentially triggering.
  Misgendering, the act of incorrectly addressing someone's gender, inflicts
serious harm and is pervasive in everyday technologies, yet there is a notable
lack of research to combat it. We are the first to address this lack of
research into interventions for misgendering by conducting a survey of
gender-diverse individuals in the US to understand perspectives about automated
interventions for text-based misgendering. Based on survey insights on the
prevalence of misgendering, desired solutions, and associated concerns, we
introduce a misgendering interventions task and evaluation dataset,
MisgenderMender. We define the task with two sub-tasks: (i) detecting
misgendering, followed by (ii) correcting misgendering where misgendering is
present in domains where editing is appropriate. MisgenderMender comprises 3790
instances of social media content and LLM-generations about non-cisgender
public figures, annotated for the presence of misgendering, with additional
annotations for correcting misgendering in LLM-generated text. Using this
dataset, we set initial benchmarks by evaluating existing NLP systems and
highlighting challenges for future models to address. We release the full
dataset, code, and demo at
https://tamannahossainkay.github.io/misgendermender/.",2024-04-23,"Tamanna Hossain, Sunipa Dev, Sameer Singh",http://arxiv.org/pdf/2404.14695v1,cs.CL
Pegasus-v1 Technical Report,"This technical report introduces Pegasus-1, a multimodal language model
specialized in video content understanding and interaction through natural
language. Pegasus-1 is designed to address the unique challenges posed by video
data, such as interpreting spatiotemporal information, to offer nuanced video
content comprehension across various lengths. This technical report overviews
Pegasus-1's architecture, training strategies, and its performance in
benchmarks on video conversation, zero-shot video question answering, and video
summarization. We also explore qualitative characteristics of Pegasus-1 ,
demonstrating its capabilities as well as its limitations, in order to provide
readers a balanced view of its current state and its future direction.",2024-04-23,"Raehyuk Jung, Hyojun Go, Jaehyuk Yi, Jiho Jang, Daniel Kim, Jay Suh, Aiden Lee, Cooper Han, Jae Lee, Jeff Kim, Jin-Young Kim, Junwan Kim, Kyle Park, Lucas Lee, Mars Ha, Minjoon Seo, Abraham Jo, Ed Park, Hassan Kianinejad, SJ Kim, Tony Moon, Wade Jeong, Andrei Popescu, Esther Kim, EK Yoon, Genie Heo, Henry Choi, Jenna Kang, Kevin Han, Noah Seo, Sunny Nguyen, Ryan Won, Yeonhoo Park, Anthony Giuliani, Dave Chung, Hans Yoon, James Le, Jenny Ahn, June Lee, Maninder Saini, Meredith Sanders, Soyoung Lee, Sue Kim, Travis Couture",http://arxiv.org/pdf/2404.14687v1,cs.CL
Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers,"The task of accurate and efficient language translation is an extremely
important information processing task. Machine learning enabled and automated
translation that is accurate and fast is often a large topic of interest in the
machine learning and data science communities. In this study, we examine using
local Generative Pretrained Transformer (GPT) models to perform automated zero
shot black-box, sentence wise, multi-natural-language translation into English
text. We benchmark 16 different open-source GPT models, with no custom
fine-tuning, from the Huggingface LLM repository for translating 50 different
non-English languages into English using translated TED Talk transcripts as the
reference dataset. These GPT model inference calls are performed strictly
locally, on single A100 Nvidia GPUs. Benchmark metrics that are reported are
language translation accuracy, using BLEU, GLEU, METEOR, and chrF text overlap
measures, and wall-clock time for each sentence translation. The best overall
performing GPT model for translating into English text for the BLEU metric is
ReMM-v2-L2-13B with a mean score across all tested languages of $0.152$, for
the GLEU metric is ReMM-v2-L2-13B with a mean score across all tested languages
of $0.256$, for the chrF metric is Llama2-chat-AYT-13B with a mean score across
all tested languages of $0.448$, and for the METEOR metric is ReMM-v2-L2-13B
with a mean score across all tested languages of $0.438$.",2024-04-23,"Elijah Pelofske, Vincent Urias, Lorie M. Liebrock",http://arxiv.org/pdf/2404.14680v1,cs.CL
NExT: Teaching Large Language Models to Reason about Code Execution,"A fundamental skill among human developers is the ability to understand and
reason about program execution. As an example, a programmer can mentally
simulate code execution in natural language to debug and repair code (aka.
rubber duck debugging). However, large language models (LLMs) of code are
typically trained on the surface textual form of programs, thus may lack a
semantic understanding of how programs execute at run-time. To address this
issue, we propose NExT, a method to teach LLMs to inspect the execution traces
of programs (variable states of executed lines) and reason about their run-time
behavior through chain-of-thought (CoT) rationales. Specifically, NExT uses
self-training to bootstrap a synthetic training set of execution-aware
rationales that lead to correct task solutions (e.g., fixed programs) without
laborious manual annotation. Experiments on program repair tasks based on MBPP
and HumanEval demonstrate that NExT improves the fix rate of a PaLM 2 model, by
26.1% and 14.3% absolute, respectively, with significantly improved rationale
quality as verified by automated metrics and human raters. Our model can also
generalize to scenarios where program traces are absent at test-time.",2024-04-23,"Ansong Ni, Miltiadis Allamanis, Arman Cohan, Yinlin Deng, Kensen Shi, Charles Sutton, Pengcheng Yin",http://arxiv.org/pdf/2404.14662v1,cs.CL
Learning Word Embedding with Better Distance Weighting and Window Size Scheduling,"Distributed word representation (a.k.a. word embedding) is a key focus in
natural language processing (NLP). As a highly successful word embedding model,
Word2Vec offers an efficient method for learning distributed word
representations on large datasets. However, Word2Vec lacks consideration for
distances between center and context words. We propose two novel methods,
Learnable Formulated Weights (LFW) and Epoch-based Dynamic Window Size (EDWS),
to incorporate distance information into two variants of Word2Vec, the
Continuous Bag-of-Words (CBOW) model and the Continuous Skip-gram (Skip-gram)
model. For CBOW, LFW uses a formula with learnable parameters that best
reflects the relationship of influence and distance between words to calculate
distance-related weights for average pooling, providing insights for future NLP
text modeling research. For Skip-gram, we improve its dynamic window size
strategy to introduce distance information in a more balanced way. Experiments
prove the effectiveness of LFW and EDWS in enhancing Word2Vec's performance,
surpassing previous state-of-the-art methods.",2024-04-23,"Chaohao Yang, Chris Ding",http://arxiv.org/pdf/2404.14631v2,cs.CL
A Survey on the Real Power of ChatGPT,"ChatGPT has changed the AI community and an active research line is the
performance evaluation of ChatGPT. A key challenge for the evaluation is that
ChatGPT is still closed-source and traditional benchmark datasets may have been
used by ChatGPT as the training data. In this paper, (i) we survey recent
studies which uncover the real performance levels of ChatGPT in seven
categories of NLP tasks, (ii) review the social implications and safety issues
of ChatGPT, and (iii) emphasize key challenges and opportunities for its
evaluation. We hope our survey can shed some light on its blackbox manner, so
that researchers are not misleaded by its surface generation.",2024-04-22,"Ming Liu, Ran Liu, Ye Zhu, Hua Wang, Youyang Qu, Rongsheng Li, Yongpan Sheng, Wray Buntine",http://arxiv.org/pdf/2405.00704v2,cs.CL
OpenELM: An Efficient Language Model Family with Open Training and Inference Framework,"The reproducibility and transparency of large language models are crucial for
advancing open research, ensuring the trustworthiness of results, and enabling
investigations into data and model biases, as well as potential risks. To this
end, we release OpenELM, a state-of-the-art open language model. OpenELM uses a
layer-wise scaling strategy to efficiently allocate parameters within each
layer of the transformer model, leading to enhanced accuracy. For example, with
a parameter budget of approximately one billion parameters, OpenELM exhibits a
2.36% improvement in accuracy compared to OLMo while requiring $2\times$ fewer
pre-training tokens.
  Diverging from prior practices that only provide model weights and inference
code, and pre-train on private datasets, our release includes the complete
framework for training and evaluation of the language model on publicly
available datasets, including training logs, multiple checkpoints, and
pre-training configurations. We also release code to convert models to MLX
library for inference and fine-tuning on Apple devices. This comprehensive
release aims to empower and strengthen the open research community, paving the
way for future open research endeavors.
  Our source code along with pre-trained model weights and training recipes is
available at \url{https://github.com/apple/corenet}. Additionally, \model
models can be found on HuggingFace at:
\url{https://huggingface.co/apple/OpenELM}.",2024-04-22,"Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, Maxwell Horton, Yanzi Jin, Chenfan Sun, Iman Mirzadeh, Mahyar Najibi, Dmitry Belenko, Peter Zatloukal, Mohammad Rastegari",http://arxiv.org/pdf/2404.14619v2,cs.CL
Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing,"Large language models (LLMs) excel in most NLP tasks but also require
expensive cloud servers for deployment due to their size, while smaller models
that can be deployed on lower cost (e.g., edge) devices, tend to lag behind in
terms of response quality. Therefore in this work we propose a hybrid inference
approach which combines their respective strengths to save cost and maintain
quality. Our approach uses a router that assigns queries to the small or large
model based on the predicted query difficulty and the desired quality level.
The desired quality level can be tuned dynamically at test time to seamlessly
trade quality for cost as per the scenario requirements. In experiments our
approach allows us to make up to 40% fewer calls to the large model, with no
drop in response quality.",2024-04-22,"Dujian Ding, Ankur Mallick, Chi Wang, Robert Sim, Subhabrata Mukherjee, Victor Ruhle, Laks V. S. Lakshmanan, Ahmed Hassan Awadallah",http://arxiv.org/pdf/2404.14618v1,cs.CL
Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language Learning,"This paper introduces \textbf{Q-tuning}, a novel approach for continual
prompt tuning that enables the lifelong learning of a pre-trained language
model. When learning a new task, Q-tuning trains a task-specific prompt by
adding it to a prompt queue consisting of the prompts from older tasks. To
better transfer the knowledge of old tasks, we design an adaptive knowledge
aggregation technique that reweighs previous prompts in the queue with a
learnable low-rank matrix. Once the prompt queue reaches its maximum capacity,
we leverage a PCA-based eviction rule to reduce the queue's size, allowing the
newly trained prompt to be added while preserving the primary knowledge of old
tasks. In order to mitigate the accumulation of information loss caused by the
eviction, we additionally propose a globally shared prefix prompt and a memory
retention regularization based on information theory. Extensive experiments
demonstrate that our approach outperforms the state-of-the-art methods
substantially on continual prompt tuning benchmarks. Moreover, our approach
enables lifelong learning on linearly growing task sequences while requiring
constant complexity for training and inference.",2024-04-22,"Yanhui Guo, Shaoyuan Xu, Jinmiao Fu, Jia Liu, Chaosheng Dong, Bryan Wang",http://arxiv.org/pdf/2404.14607v1,cs.CL
Describe-then-Reason: Improving Multimodal Mathematical Reasoning through Visual Comprehension Training,"Open-source multimodal large language models (MLLMs) excel in various tasks
involving textual and visual inputs but still struggle with complex multimodal
mathematical reasoning, lagging behind proprietary models like GPT-4V(ision)
and Gemini-Pro. Although fine-tuning with intermediate steps (i.e., rationales)
elicits some mathematical reasoning skills, the resulting models still fall
short in visual comprehension due to inadequate visual-centric supervision,
which leads to inaccurate interpretation of math figures. To address this
issue, we propose a two-step training pipeline VCAR, which emphasizes the
Visual Comprehension training in Addition to mathematical Reasoning learning.
It first improves the visual comprehension ability of MLLMs through the visual
description generation task, followed by another training step on generating
rationales with the assistance of descriptions. Experimental results on two
popular benchmarks demonstrate that VCAR substantially outperforms baseline
methods solely relying on rationale supervision, especially on problems with
high visual demands.",2024-04-22,"Mengzhao Jia, Zhihan Zhang, Wenhao Yu, Fangkai Jiao, Meng Jiang",http://arxiv.org/pdf/2404.14604v3,cs.CL
Planning Ahead in Generative Retrieval: Guiding Autoregressive Generation through Simultaneous Decoding,"This paper introduces PAG-a novel optimization and decoding approach that
guides autoregressive generation of document identifiers in generative
retrieval models through simultaneous decoding. To this aim, PAG constructs a
set-based and sequential identifier for each document. Motivated by the
bag-of-words assumption in information retrieval, the set-based identifier is
built on lexical tokens. The sequential identifier, on the other hand, is
obtained via quantizing relevance-based representations of documents. Extensive
experiments on MSMARCO and TREC Deep Learning Track data reveal that PAG
outperforms the state-of-the-art generative retrieval model by a large margin
(e.g., 15.6% MRR improvements on MS MARCO), while achieving 22x speed up in
terms of query latency.",2024-04-22,"Hansi Zeng, Chen Luo, Hamed Zamani",http://arxiv.org/pdf/2404.14600v1,cs.CL
WangLab at MEDIQA-M3G 2024: Multimodal Medical Answer Generation using Large Language Models,"This paper outlines our submission to the MEDIQA2024 Multilingual and
Multimodal Medical Answer Generation (M3G) shared task. We report results for
two standalone solutions under the English category of the task, the first
involving two consecutive API calls to the Claude 3 Opus API and the second
involving training an image-disease label joint embedding in the style of CLIP
for image classification. These two solutions scored 1st and 2nd place
respectively on the competition leaderboard, substantially outperforming the
next best solution. Additionally, we discuss insights gained from
post-competition experiments. While the performance of these two solutions have
significant room for improvement due to the difficulty of the shared task and
the challenging nature of medical visual question answering in general, we
identify the multi-stage LLM approach and the CLIP image classification
approach as promising avenues for further investigation.",2024-04-22,"Ronald Xie, Steven Palayew, Augustin Toma, Gary Bader, Bo Wang",http://arxiv.org/pdf/2404.14567v1,cs.CL
WangLab at MEDIQA-CORR 2024: Optimized LLM-based Programs for Medical Error Detection and Correction,"Medical errors in clinical text pose significant risks to patient safety. The
MEDIQA-CORR 2024 shared task focuses on detecting and correcting these errors
across three subtasks: identifying the presence of an error, extracting the
erroneous sentence, and generating a corrected sentence. In this paper, we
present our approach that achieved top performance in all three subtasks. For
the MS dataset, which contains subtle errors, we developed a retrieval-based
system leveraging external medical question-answering datasets. For the UW
dataset, reflecting more realistic clinical notes, we created a pipeline of
modules to detect, localize, and correct errors. Both approaches utilized the
DSPy framework for optimizing prompts and few-shot examples in large language
model (LLM) based programs. Our results demonstrate the effectiveness of LLM
based programs for medical error correction. However, our approach has
limitations in addressing the full diversity of potential errors in medical
documentation. We discuss the implications of our work and highlight future
research directions to advance the robustness and applicability of medical
error detection and correction systems.",2024-04-22,"Augustin Toma, Ronald Xie, Steven Palayew, Patrick R. Lawler, Bo Wang",http://arxiv.org/pdf/2404.14544v1,cs.CL
SpaceByte: Towards Deleting Tokenization from Large Language Modeling,"Tokenization is widely used in large language models because it significantly
improves performance. However, tokenization imposes several disadvantages, such
as performance biases, increased adversarial vulnerability, decreased
character-level modeling performance, and increased modeling complexity. To
address these disadvantages without sacrificing performance, we propose
SpaceByte, a novel byte-level decoder architecture that closes the performance
gap between byte-level and subword autoregressive language modeling. SpaceByte
consists of a byte-level Transformer model, but with extra larger transformer
blocks inserted in the middle of the layers. We find that performance is
significantly improved by applying these larger blocks only after certain
bytes, such as space characters, which typically denote word boundaries. Our
experiments show that for a fixed training and inference compute budget,
SpaceByte outperforms other byte-level architectures and roughly matches the
performance of tokenized Transformer architectures.",2024-04-22,Kevin Slagle,http://arxiv.org/pdf/2404.14408v3,cs.CL
RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?,"Large language models (LLMs) and small language models (SLMs) are being
adopted at remarkable speed, although their safety still remains a serious
concern. With the advent of multilingual S/LLMs, the question now becomes a
matter of scale: can we expand multilingual safety evaluations of these models
with the same velocity at which they are deployed? To this end, we introduce
RTP-LX, a human-transcreated and human-annotated corpus of toxic prompts and
outputs in 28 languages. RTP-LX follows participatory design practices, and a
portion of the corpus is especially designed to detect culturally-specific
toxic language. We evaluate 10 S/LLMs on their ability to detect toxic content
in a culturally-sensitive, multilingual scenario. We find that, although they
typically score acceptably in terms of accuracy, they have low agreement with
human judges when scoring holistically the toxicity of a prompt; and have
difficulty discerning harm in context-dependent scenarios, particularly with
subtle-yet-harmful content (e.g. microaggressions, bias). We release this
dataset to contribute to further reduce harmful uses of these models and
improve their safe deployment.",2024-04-22,"Adrian de Wynter, Ishaan Watts, Tua Wongsangaroonsri, Minghui Zhang, Noura Farra, Nektar Ege Altıntoprak, Lena Baur, Samantha Claudet, Pavel Gajdusek, Can Gören, Qilong Gu, Anna Kaminska, Tomasz Kaminski, Ruby Kuo, Akiko Kyuba, Jongho Lee, Kartik Mathur, Petter Merok, Ivana Milovanović, Nani Paananen, Vesa-Matti Paananen, Anna Pavlenko, Bruno Pereira Vidal, Luciano Strika, Yueh Tsao, Davide Turcato, Oleksandr Vakhno, Judit Velcsov, Anna Vickers, Stéphanie Visser, Herdyan Widarmanto, Andrey Zaikin, Si-Qing Chen",http://arxiv.org/pdf/2404.14397v2,cs.CL
PARAMANU-GANITA: Can Small Math Language Models Rival with Large Language Models on Mathematical Reasoning?,"In this paper, we study whether domain specific pretraining of small
generative language models (SLM) from scratch with domain specialized tokenizer
and Chain-of-Thought (CoT) instruction fine-tuning results in competitive
performance on mathematical reasoning compared to LLMs? Secondly, whether this
approach is environmentally sustainable, highly cost efficient? To address
these research questions, we present Paramanu-Ganita, a 208 million-parameter
novel decoder-only Auto Regressive SLM on mathematics. We performed pretraining
from scratch on 31.5 billion tokens for 170 A100 hours using a context size of
4096 on a mixed mathematical corpus consisting of web pages, source code,
textbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture
notes in LaTeX curated by us. We also trained a math and code specialised BPE
tokenizer. We proposed and performed CoT instruction fine-tuning of
Paramanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite
being 34 times smaller than the 7B LLMs, outperforms generalist LLMs by
approximately 30% points, and even math-specialised LLMs by 3-23% points in
GSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the
various models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,
college level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),
Paramanu-Ganita outperformed others by 1-4%. Our model is available at
https://huggingface.co/gyanai/paramanu-ganita-208M-hf .",2024-04-22,"Mitodru Niyogi, Arnab Bhattacharya",http://arxiv.org/pdf/2404.14395v2,cs.CL
A Multimodal Automated Interpretability Agent,"This paper describes MAIA, a Multimodal Automated Interpretability Agent.
MAIA is a system that uses neural models to automate neural model understanding
tasks like feature interpretation and failure mode discovery. It equips a
pre-trained vision-language model with a set of tools that support iterative
experimentation on subcomponents of other models to explain their behavior.
These include tools commonly used by human interpretability researchers: for
synthesizing and editing inputs, computing maximally activating exemplars from
real-world datasets, and summarizing and describing experimental results.
Interpretability experiments proposed by MAIA compose these tools to describe
and explain system behavior. We evaluate applications of MAIA to computer
vision models. We first characterize MAIA's ability to describe (neuron-level)
features in learned representations of images. Across several trained models
and a novel dataset of synthetic vision neurons with paired ground-truth
descriptions, MAIA produces descriptions comparable to those generated by
expert human experimenters. We then show that MAIA can aid in two additional
interpretability tasks: reducing sensitivity to spurious features, and
automatically identifying inputs likely to be mis-classified.",2024-04-22,"Tamar Rott Shaham, Sarah Schwettmann, Franklin Wang, Achyuta Rajaram, Evan Hernandez, Jacob Andreas, Antonio Torralba",http://arxiv.org/pdf/2404.14394v2,cs.CL
A Survey on Self-Evolution of Large Language Models,"Large language models (LLMs) have significantly advanced in various fields
and intelligent agent applications. However, current LLMs that learn from human
or external model supervision are costly and may face performance ceilings as
task complexity and diversity increase. To address this issue, self-evolution
approaches that enable LLM to autonomously acquire, refine, and learn from
experiences generated by the model itself are rapidly growing. This new
training paradigm inspired by the human experiential learning process offers
the potential to scale LLMs towards superintelligence. In this work, we present
a comprehensive survey of self-evolution approaches in LLMs. We first propose a
conceptual framework for self-evolution and outline the evolving process as
iterative cycles composed of four phases: experience acquisition, experience
refinement, updating, and evaluation. Second, we categorize the evolution
objectives of LLMs and LLM-based agents; then, we summarize the literature and
provide taxonomy and insights for each module. Lastly, we pinpoint existing
challenges and propose future directions to improve self-evolution frameworks,
equipping researchers with critical insights to fast-track the development of
self-evolving LLMs. Our corresponding GitHub repository is available at
https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM",2024-04-22,"Zhengwei Tao, Ting-En Lin, Xiancai Chen, Hangyu Li, Yuchuan Wu, Yongbin Li, Zhi Jin, Fei Huang, Dacheng Tao, Jingren Zhou",http://arxiv.org/pdf/2404.14387v2,cs.CL
SnapKV: LLM Knows What You are Looking for Before Generation,"Large Language Models (LLMs) have made remarkable progress in processing
extensive contexts, with the Key-Value (KV) cache playing a vital role in
enhancing their performance. However, the growth of the KV cache in response to
increasing input length poses challenges to memory and time efficiency. To
address this problem, this paper introduces SnapKV, an innovative and
fine-tuning-free approach that efficiently minimizes KV cache size while still
delivering comparable performance in real-world applications.
  We discover that each attention head in the model consistently focuses on
specific prompt attention features during generation. Meanwhile, this robust
pattern can be obtained from an 'observation' window located at the end of the
prompts. Drawing on this insight, SnapKV automatically compresses KV caches by
selecting clustered important KV positions for each attention head. Our
approach significantly reduces the growing computational overhead and memory
footprint when processing long input sequences. Specifically, SnapKV achieves a
consistent decoding speed with a 3.6x increase in generation speed and an 8.2x
enhancement in memory efficiency compared to the baseline when processing
inputs of 16K tokens. At the same time, it maintains comparable performance to
the baseline models across 16 long sequence datasets. Moreover, SnapKV can
process up to 380K context tokens on a single A100-80GB GPU using HuggingFace
implementation with minor changes, exhibiting only a negligible accuracy drop
in the Needle-in-a-Haystack test. Further comprehensive studies suggest
SnapKV's potential for practical applications.",2024-04-22,"Yuhong Li, Yingbing Huang, Bowen Yang, Bharat Venkitesh, Acyr Locatelli, Hanchen Ye, Tianle Cai, Patrick Lewis, Deming Chen",http://arxiv.org/pdf/2404.14469v2,cs.CL
Less Peaky and More Accurate CTC Forced Alignment by Label Priors,"Connectionist temporal classification (CTC) models are known to have peaky
output distributions. Such behavior is not a problem for automatic speech
recognition (ASR), but it can cause inaccurate forced alignments (FA),
especially at finer granularity, e.g., phoneme level. This paper aims at
alleviating the peaky behavior for CTC and improve its suitability for forced
alignment generation, by leveraging label priors, so that the scores of
alignment paths containing fewer blanks are boosted and maximized during
training. As a result, our CTC model produces less peaky posteriors and is able
to more accurately predict the offset of the tokens besides their onset. It
outperforms the standard CTC model and a heuristics-based approach for
obtaining CTC's token offset timestamps by 12-40% in phoneme and word boundary
errors (PBE and WBE) measured on the Buckeye and TIMIT data. Compared with the
most widely used FA toolkit Montreal Forced Aligner (MFA), our method performs
similarly on PBE/WBE on Buckeye, yet falls behind MFA on TIMIT. Nevertheless,
our method has a much simpler training pipeline and better runtime efficiency.
Our training recipe and pretrained model are released in TorchAudio.",2024-04-22,"Ruizhe Huang, Xiaohui Zhang, Zhaoheng Ni, Li Sun, Moto Hira, Jeff Hwang, Vimal Manohar, Vineel Pratap, Matthew Wiesner, Shinji Watanabe, Daniel Povey, Sanjeev Khudanpur",http://arxiv.org/pdf/2406.02560v3,cs.CL
Pixels and Predictions: Potential of GPT-4V in Meteorological Imagery Analysis and Forecast Communication,"Generative AI, such as OpenAI's GPT-4V large-language model, has rapidly
entered mainstream discourse. Novel capabilities in image processing and
natural-language communication may augment existing forecasting methods. Large
language models further display potential to better communicate weather hazards
in a style honed for diverse communities and different languages. This study
evaluates GPT-4V's ability to interpret meteorological charts and communicate
weather hazards appropriately to the user, despite challenges of
hallucinations, where generative AI delivers coherent, confident, but incorrect
responses. We assess GPT-4V's competence via its web interface ChatGPT in two
tasks: (1) generating a severe-weather outlook from weather-chart analysis and
conducting self-evaluation, revealing an outlook that corresponds well with a
Storm Prediction Center human-issued forecast; and (2) producing hazard
summaries in Spanish and English from weather charts. Responses in Spanish,
however, resemble direct (not idiomatic) translations from English to Spanish,
yielding poorly translated summaries that lose critical idiomatic precision
required for optimal communication. Our findings advocate for cautious
integration of tools like GPT-4V in meteorology, underscoring the necessity of
human oversight and development of trustworthy, explainable AI.",2024-04-22,"John R. Lawson, Joseph E. Trujillo-Falcón, David M. Schultz, Montgomery L. Flora, Kevin H. Goebbert, Seth N. Lyman, Corey K. Potvin, Adam J. Stepanek",http://arxiv.org/pdf/2404.15166v2,cs.CL
Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph,"Model scaling is becoming the default choice for many language tasks due to
the success of large language models (LLMs). However, it can fall short in
specific scenarios where simple customized methods excel. In this paper, we
delve into the patent approval pre-diction task and unveil that simple
domain-specific graph methods outperform enlarging the model, using the
intrinsic dependencies within the patent data. Specifically, we first extend
the embedding-based state-of-the-art (SOTA) by scaling up its backbone model
with various sizes of open-source LLMs, then explore prompt-based methods to
harness proprietary LLMs' potential, but find the best results close to random
guessing, underlining the ineffectiveness of model scaling-up. Hence, we
propose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous
patent data analyses, capturing the inherent dependencies across segments of
the patent text. As it is model-agnostic, we apply cost-effective graph models
to our FLAN Graph to obtain representations for approval prediction. Extensive
experiments and detailed analyses prove that incorporating FLAN Graph via
various graph models consistently outperforms all LLM baselines significantly.
We hope that our observations and analyses in this paper can bring more
attention to this challenging task and prompt further research into the
limitations of LLMs. Our source code and dataset can be obtained from
http://github.com/ShangDataLab/FLAN-Graph.",2024-04-22,"Xiaochen Kev Gao, Feng Yao, Kewen Zhao, Beilei He, Animesh Kumar, Vish Krishnan, Jingbo Shang",http://arxiv.org/pdf/2404.14372v1,cs.CL
Graphic Design with Large Multimodal Model,"In the field of graphic design, automating the integration of design elements
into a cohesive multi-layered artwork not only boosts productivity but also
paves the way for the democratization of graphic design. One existing practice
is Graphic Layout Generation (GLG), which aims to layout sequential design
elements. It has been constrained by the necessity for a predefined correct
sequence of layers, thus limiting creative potential and increasing user
workload. In this paper, we present Hierarchical Layout Generation (HLG) as a
more flexible and pragmatic setup, which creates graphic composition from
unordered sets of design elements. To tackle the HLG task, we introduce
Graphist, the first layout generation model based on large multimodal models.
Graphist efficiently reframes the HLG as a sequence generation problem,
utilizing RGB-A images as input, outputs a JSON draft protocol, indicating the
coordinates, size, and order of each element. We develop new evaluation metrics
for HLG. Graphist outperforms prior arts and establishes a strong baseline for
this field. Project homepage: https://github.com/graphic-design-ai/graphist",2024-04-22,"Yutao Cheng, Zhao Zhang, Maoke Yang, Hui Nie, Chunyuan Li, Xinglong Wu, Jie Shao",http://arxiv.org/pdf/2404.14368v1,cs.CL
Better Synthetic Data by Retrieving and Transforming Existing Datasets,"Despite recent advances in large language models, building dependable and
deployable NLP models typically requires abundant, high-quality training data.
However, task-specific data is not available for many use cases, and manually
curating task-specific data is labor-intensive. Recent work has studied
prompt-driven synthetic data generation using large language models, but these
generated datasets tend to lack complexity and diversity. To address these
limitations, we introduce a method, DataTune, to make better use of existing,
publicly available datasets to improve automatic dataset generation. DataTune
performs dataset transformation, enabling the repurposing of publicly available
datasets into a format that is directly aligned with the specific requirements
of target tasks. On a diverse set of language-based tasks from the BIG-Bench
benchmark, we find that finetuning language models via DataTune improves over a
few-shot prompting baseline by 49% and improves over existing methods that use
synthetic or retrieved training data by 34%. We find that dataset
transformation significantly increases the diversity and difficulty of
generated data on many tasks. We integrate DataTune into an open-source
repository to make this method accessible to the community:
https://github.com/neulab/prompt2model.",2024-04-22,"Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang Wu, Graham Neubig",http://arxiv.org/pdf/2404.14361v3,cs.CL
Pre-Calc: Learning to Use the Calculator Improves Numeracy in Language Models,"Quantitative and numerical comprehension in language is an important task in
many fields like education and finance, but still remains a challenging task
for language models. While tool and calculator usage has shown to be helpful to
improve mathematical reasoning in large pretrained decoder-only language
models, this remains unexplored for smaller language models with encoders. In
this paper, we propose Pre-Calc, a simple pre-finetuning objective of learning
to use the calculator for both encoder-only and encoder-decoder architectures,
formulated as a discriminative and generative task respectively. We pre-train
BERT and RoBERTa for discriminative calculator use and Flan-T5 for generative
calculator use on the MAWPS, SVAMP, and AsDiv-A datasets, which improves
performance on downstream tasks that require numerical understanding. Our code
and data are available at https://github.com/calc-cmu/pre-calc.",2024-04-22,"Vishruth Veerendranath, Vishwa Shah, Kshitish Ghate",http://arxiv.org/pdf/2404.14355v3,cs.CL
Zero-shot Cross-lingual Stance Detection via Adversarial Language Adaptation,"Stance detection has been widely studied as the task of determining if a
social media post is positive, negative or neutral towards a specific issue,
such as support towards vaccines. Research in stance detection has however
often been limited to a single language and, where more than one language has
been studied, research has focused on few-shot settings, overlooking the
challenges of developing a zero-shot cross-lingual stance detection model. This
paper makes the first such effort by introducing a novel approach to zero-shot
cross-lingual stance detection, Multilingual Translation-Augmented BERT (MTAB),
aiming to enhance the performance of a cross-lingual classifier in the absence
of explicit training data for target languages. Our technique employs
translation augmentation to improve zero-shot performance and pairs it with
adversarial learning to further boost model efficacy. Through experiments on
datasets labeled for stance towards vaccines in four languages English, German,
French, Italian. We demonstrate the effectiveness of our proposed approach,
showcasing improved results in comparison to a strong baseline model as well as
ablated versions of our model. Our experiments demonstrate the effectiveness of
model components, not least the translation-augmented data as well as the
adversarial learning component, to the improved performance of the model. We
have made our source code accessible on GitHub.",2024-04-22,"Bharathi A, Arkaitz Zubiaga",http://arxiv.org/pdf/2404.14339v1,cs.CL
Integrating Chemistry Knowledge in Large Language Models via Prompt Engineering,"This paper presents a study on the integration of domain-specific knowledge
in prompt engineering to enhance the performance of large language models
(LLMs) in scientific domains. A benchmark dataset is curated to encapsulate the
intricate physical-chemical properties of small molecules, their drugability
for pharmacology, alongside the functional attributes of enzymes and crystal
materials, underscoring the relevance and applicability across biological and
chemical domains.The proposed domain-knowledge embedded prompt engineering
method outperforms traditional prompt engineering strategies on various
metrics, including capability, accuracy, F1 score, and hallucination drop. The
effectiveness of the method is demonstrated through case studies on complex
materials including the MacMillan catalyst, paclitaxel, and lithium cobalt
oxide. The results suggest that domain-knowledge prompts can guide LLMs to
generate more accurate and relevant responses, highlighting the potential of
LLMs as powerful tools for scientific discovery and innovation when equipped
with domain-specific prompts. The study also discusses limitations and future
directions for domain-specific prompt engineering development.",2024-04-22,"Hongxuan Liu, Haoyu Yin, Zhiyao Luo, Xiaonan Wang",http://arxiv.org/pdf/2404.14467v1,cs.CL
Performance Characterization of Expert Router for Scalable LLM Inference,"Large Language Models (LLMs) have experienced widespread adoption across
scientific and industrial domains due to their versatility and utility for
diverse tasks. Nevertheless, deploying and serving these models at scale with
optimal throughput and latency remains a significant challenge, primarily
because of LLMs' high computational and memory demands. Specialized models
optimized for specific tasks can be combined through a routing mechanism to
address these challenges, creating a modular inference system. This paper
introduces Expert Router, a scalable routing architecture that directs prompts
to specialized expert models. We characterize multiple Expert Router
configurations, including different LLama 3 models with quantized and
non-quantized weights under up to 1,000 concurrent users. Our findings reveal
that Expert Router introduces minimal latency overhead, with the configuration
of expert models being a dominating factor in performance outcomes.
High-parameter expert models deliver stable throughput and latency under
moderate concurrency levels. In contrast, smaller expert models maintain
competitive performance across a wider range of concurrent users compared to
tensor-parallelized baseline models. This highlights the potential of Expert
Router for efficient and scalable LLM deployment.",2024-04-22,"Josef Pichlmeier, Philipp Ross, Andre Luckow",http://arxiv.org/pdf/2404.15153v2,cs.CL
Automated Long Answer Grading with RiceChem Dataset,"We introduce a new area of study in the field of educational Natural Language
Processing: Automated Long Answer Grading (ALAG). Distinguishing itself from
Automated Short Answer Grading (ASAG) and Automated Essay Grading (AEG), ALAG
presents unique challenges due to the complexity and multifaceted nature of
fact-based long answers. To study ALAG, we introduce RiceChem, a dataset
derived from a college chemistry course, featuring real student responses to
long-answer questions with an average word count notably higher than typical
ASAG datasets. We propose a novel approach to ALAG by formulating it as a
rubric entailment problem, employing natural language inference models to
verify whether each criterion, represented by a rubric item, is addressed in
the student's response. This formulation enables the effective use of MNLI for
transfer learning, significantly improving the performance of models on the
RiceChem dataset. We demonstrate the importance of rubric-based formulation in
ALAG, showcasing its superiority over traditional score-based approaches in
capturing the nuances of student responses. We also investigate the performance
of models in cold start scenarios, providing valuable insights into the
practical deployment considerations in educational settings. Lastly, we
benchmark state-of-the-art open-sourced Large Language Models (LLMs) on
RiceChem and compare their results to GPT models, highlighting the increased
complexity of ALAG compared to ASAG. Despite leveraging the benefits of a
rubric-based approach and transfer learning from MNLI, the lower performance of
LLMs on RiceChem underscores the significant difficulty posed by the ALAG task.
With this work, we offer a fresh perspective on grading long, fact-based
answers and introduce a new dataset to stimulate further research in this
important area. Code:
\url{https://github.com/luffycodes/Automated-Long-Answer-Grading}.",2024-04-22,"Shashank Sonkar, Kangqi Ni, Lesa Tran Lu, Kristi Kincaid, John S. Hutchinson, Richard G. Baraniuk",http://arxiv.org/pdf/2404.14316v1,cs.CL
Self-Supervised Alignment with Mutual Information: Learning to Follow Principles without Preference Labels,"When prompting a language model (LM), users often expect the model to adhere
to a set of behavioral principles across diverse tasks, such as producing
insightful content while avoiding harmful or biased language. Instilling such
principles (i.e., a constitution) into a model is resource-intensive,
technically challenging, and generally requires human preference labels or
examples. We introduce SAMI, an iterative algorithm that finetunes a pretrained
language model (without requiring preference labels or demonstrations) to
increase the conditional mutual information between constitutions and
self-generated responses given queries from a dataset. On single-turn dialogue
and summarization, a SAMI-trained mistral-7b outperforms the initial pretrained
model, with win rates between 66% and 77%. Strikingly, it also surpasses an
instruction-finetuned baseline (mistral-7b-instruct) with win rates between 55%
and 57% on single-turn dialogue. SAMI requires a model that writes the
principles. To avoid dependence on strong models for writing principles, we
align a strong pretrained model (mixtral-8x7b) using constitutions written by a
weak instruction-finetuned model (mistral-7b-instruct), achieving a 65% win
rate on summarization. Finally, we investigate whether SAMI generalizes to
diverse summarization principles (e.g., ""summaries should be scientific"") and
scales to stronger models (llama3-70b), finding that it achieves win rates of
up to 68% for learned and 67% for held-out principles compared to the base
model. Our results show that a pretrained LM can learn to follow constitutions
without using preference labels, demonstrations, or human oversight.",2024-04-22,"Jan-Philipp Fränken, Eric Zelikman, Rafael Rafailov, Kanishk Gandhi, Tobias Gerstenberg, Noah D. Goodman",http://arxiv.org/pdf/2404.14313v2,cs.CL
Marking: Visual Grading with Highlighting Errors and Annotating Missing Bits,"In this paper, we introduce ""Marking"", a novel grading task that enhances
automated grading systems by performing an in-depth analysis of student
responses and providing students with visual highlights. Unlike traditional
systems that provide binary scores, ""marking"" identifies and categorizes
segments of the student response as correct, incorrect, or irrelevant and
detects omissions from gold answers. We introduce a new dataset meticulously
curated by Subject Matter Experts specifically for this task. We frame
""Marking"" as an extension of the Natural Language Inference (NLI) task, which
is extensively explored in the field of Natural Language Processing. The gold
answer and the student response play the roles of premise and hypothesis in
NLI, respectively. We subsequently train language models to identify
entailment, contradiction, and neutrality from student response, akin to NLI,
and with the added dimension of identifying omissions from gold answers. Our
experimental setup involves the use of transformer models, specifically BERT
and RoBERTa, and an intelligent training step using the e-SNLI dataset. We
present extensive baseline results highlighting the complexity of the ""Marking""
task, which sets a clear trajectory for the upcoming study. Our work not only
opens up new avenues for research in AI-powered educational assessment tools,
but also provides a valuable benchmark for the AI in education community to
engage with and improve upon in the future. The code and dataset can be found
at https://github.com/luffycodes/marking.",2024-04-22,"Shashank Sonkar, Naiming Liu, Debshila B. Mallick, Richard G. Baraniuk",http://arxiv.org/pdf/2404.14301v1,cs.CL
A Survey on Efficient Inference for Large Language Models,"Large Language Models (LLMs) have attracted extensive attention due to their
remarkable performance across various tasks. However, the substantial
computational and memory requirements of LLM inference pose challenges for
deployment in resource-constrained scenarios. Efforts within the field have
been directed towards developing techniques aimed at enhancing the efficiency
of LLM inference. This paper presents a comprehensive survey of the existing
literature on efficient LLM inference. We start by analyzing the primary causes
of the inefficient LLM inference, i.e., the large model size, the
quadratic-complexity attention operation, and the auto-regressive decoding
approach. Then, we introduce a comprehensive taxonomy that organizes the
current literature into data-level, model-level, and system-level optimization.
Moreover, the paper includes comparative experiments on representative methods
within critical sub-fields to provide quantitative insights. Last but not
least, we provide some knowledge summary and discuss future research
directions.",2024-04-22,"Zixuan Zhou, Xuefei Ning, Ke Hong, Tianyu Fu, Jiaming Xu, Shiyao Li, Yuming Lou, Luning Wang, Zhihang Yuan, Xiuhong Li, Shengen Yan, Guohao Dai, Xiao-Ping Zhang, Yuhan Dong, Yu Wang",http://arxiv.org/pdf/2404.14294v3,cs.CL
What do Transformers Know about Government?,"This paper investigates what insights about linguistic features and what
knowledge about the structure of natural language can be obtained from the
encodings in transformer language models.In particular, we explore how BERT
encodes the government relation between constituents in a sentence. We use
several probing classifiers, and data from two morphologically rich languages.
Our experiments show that information about government is encoded across all
transformer layers, but predominantly in the early layers of the model. We find
that, for both languages, a small number of attention heads encode enough
information about the government relations to enable us to train a classifier
capable of discovering new, previously unknown types of government, never seen
in the training data. Currently, data is lacking for the research community
working on grammatical constructions, and government in particular. We release
the Government Bank -- a dataset defining the government relations for
thousands of lemmas in the languages in our experiments.",2024-04-22,"Jue Hou, Anisia Katinskaia, Lari Kotilainen, Sathianpong Trangcasanchai, Anh-Duc Vu, Roman Yangarber",http://arxiv.org/pdf/2404.14270v1,cs.CL
Detecting and Mitigating Hallucination in Large Vision Language Models via Fine-Grained AI Feedback,"The rapidly developing Large Vision Language Models (LVLMs) have shown
notable capabilities on a range of multi-modal tasks, but still face the
hallucination phenomena where the generated texts do not align with the given
contexts, significantly restricting the usages of LVLMs. Most previous work
detects and mitigates hallucination at the coarse-grained level or requires
expensive annotation (e.g., labeling by proprietary models or human experts).
To address these issues, we propose detecting and mitigating hallucinations in
LVLMs via fine-grained AI feedback. The basic idea is that we generate a
small-size sentence-level hallucination annotation dataset by proprietary
models, whereby we train a hallucination detection model which can perform
sentence-level hallucination detection, covering primary hallucination types
(i.e., object, attribute, and relationship). Then, we propose a
detect-then-rewrite pipeline to automatically construct preference dataset for
training hallucination mitigating model. Furthermore, we propose
differentiating the severity of hallucinations, and introducing a Hallucination
Severity-Aware Direct Preference Optimization (HSA-DPO) for mitigating
hallucination in LVLMs by incorporating the severity of hallucinations into
preference learning. Extensive experiments demonstrate the effectiveness of our
method.",2024-04-22,"Wenyi Xiao, Ziwei Huang, Leilei Gan, Wanggui He, Haoyuan Li, Zhelun Yu, Fangxun Shu, Hao Jiang, Linchao Zhu",http://arxiv.org/pdf/2404.14233v2,cs.CL
Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,"We introduce phi-3-mini, a 3.8 billion parameter language model trained on
3.3 trillion tokens, whose overall performance, as measured by both academic
benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and
GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite
being small enough to be deployed on a phone. Our training dataset is a
scaled-up version of the one used for phi-2, composed of heavily filtered
publicly available web data and synthetic data. The model is also further
aligned for robustness, safety, and chat format. We also provide
parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called
phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini
(e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance
multilingual, multimodal, and long-context capabilities, we introduce three
models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision.
The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters,
achieves superior performance in language reasoning, math, and code tasks
compared to other open-source models of similar scale, such as Llama 3.1 and
the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini.
Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from
phi-3.5-mini, excels in reasoning tasks and is adept at handling both
single-image and text prompts, as well as multi-image and text prompts.",2024-04-22,"Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, Sébastien Bubeck, Martin Cai, Qin Cai, Vishrav Chaudhary, Dong Chen, Dongdong Chen, Weizhu Chen, Yen-Chun Chen, Yi-Ling Chen, Hao Cheng, Parul Chopra, Xiyang Dai, Matthew Dixon, Ronen Eldan, Victor Fragoso, Jianfeng Gao, Mei Gao, Min Gao, Amit Garg, Allie Del Giorno, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J. Hewett, Wenxiang Hu, Jamie Huynh, Dan Iter, Sam Ade Jacobs, Mojan Javaheripi, Xin Jin, Nikos Karampatziakis, Piero Kauffmann, Mahoud Khademi, Dongwoo Kim, Young Jin Kim, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li, Yunsheng Li, Chen Liang, Lars Liden, Xihui Lin, Zeqi Lin, Ce Liu, Liyuan Liu, Mengchen Liu, Weishung Liu, Xiaodong Liu, Chong Luo, Piyush Madan, Ali Mahmoudzadeh, David Majercak, Matt Mazzola, Caio César Teodoro Mendes, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac, Liliang Ren, Gustavo de Rosa, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Yelong Shen, Swadheen Shukla, Xia Song, Masahiro Tanaka, Andrea Tupini, Praneetha Vaddamanu, Chunyu Wang, Guanhua Wang, Lijuan Wang, Shuohang Wang, Xin Wang, Yu Wang, Rachel Ward, Wen Wen, Philipp Witte, Haiping Wu, Xiaoxia Wu, Michael Wyatt, Bin Xiao, Can Xu, Jiahang Xu, Weijian Xu, Jilong Xue, Sonali Yadav, Fan Yang, Jianwei Yang, Yifan Yang, Ziyi Yang, Donghan Yu, Lu Yuan, Chenruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, Xiren Zhou",http://arxiv.org/pdf/2404.14219v4,cs.CL
Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction,"The task of condensing large chunks of textual information into concise and
structured tables has gained attention recently due to the emergence of Large
Language Models (LLMs) and their potential benefit for downstream tasks, such
as text summarization and text mining. Previous approaches often generate
tables that directly replicate information from the text, limiting their
applicability in broader contexts, as text-to-table generation in real-life
scenarios necessitates information extraction, reasoning, and integration.
However, there is a lack of both datasets and methodologies towards this task.
In this paper, we introduce LiveSum, a new benchmark dataset created for
generating summary tables of competitions based on real-time commentary texts.
We evaluate the performances of state-of-the-art LLMs on this task in both
fine-tuning and zero-shot settings, and additionally propose a novel pipeline
called $T^3$(Text-Tuple-Table) to improve their performances. Extensive
experimental results demonstrate that LLMs still struggle with this task even
after fine-tuning, while our approach can offer substantial performance gains
without explicit training. Further analyses demonstrate that our method
exhibits strong generalization abilities, surpassing previous approaches on
several other text-to-table datasets. Our code and data can be found at
https://github.com/HKUST-KnowComp/LiveSum.",2024-04-22,"Zheye Deng, Chunkit Chan, Weiqi Wang, Yuxi Sun, Wei Fan, Tianshi Zheng, Yauwai Yim, Yangqiu Song",http://arxiv.org/pdf/2404.14215v2,cs.CL
"EnzChemRED, a rich enzyme chemistry relation extraction dataset","Expert curation is essential to capture knowledge of enzyme functions from
the scientific literature in FAIR open knowledgebases but cannot keep pace with
the rate of new discoveries and new publications. In this work we present
EnzChemRED, for Enzyme Chemistry Relation Extraction Dataset, a new training
and benchmarking dataset to support the development of Natural Language
Processing (NLP) methods such as (large) language models that can assist enzyme
curation. EnzChemRED consists of 1,210 expert curated PubMed abstracts in which
enzymes and the chemical reactions they catalyze are annotated using
identifiers from the UniProt Knowledgebase (UniProtKB) and the ontology of
Chemical Entities of Biological Interest (ChEBI). We show that fine-tuning
pre-trained language models with EnzChemRED can significantly boost their
ability to identify mentions of proteins and chemicals in text (Named Entity
Recognition, or NER) and to extract the chemical conversions in which they
participate (Relation Extraction, or RE), with average F1 score of 86.30% for
NER, 86.66% for RE for chemical conversion pairs, and 83.79% for RE for
chemical conversion pairs and linked enzymes. We combine the best performing
methods after fine-tuning using EnzChemRED to create an end-to-end pipeline for
knowledge extraction from text and apply this to abstracts at PubMed scale to
create a draft map of enzyme functions in literature to guide curation efforts
in UniProtKB and the reaction knowledgebase Rhea. The EnzChemRED corpus is
freely available at https://ftp.expasy.org/databases/rhea/nlp/.",2024-04-22,"Po-Ting Lai, Elisabeth Coudert, Lucila Aimo, Kristian Axelsen, Lionel Breuza, Edouard de Castro, Marc Feuermann, Anne Morgat, Lucille Pourcel, Ivo Pedruzzi, Sylvain Poux, Nicole Redaschi, Catherine Rivoire, Anastasia Sveshnikova, Chih-Hsuan Wei, Robert Leaman, Ling Luo, Zhiyong Lu, Alan Bridge",http://arxiv.org/pdf/2404.14209v1,cs.CL
Swap distance minimization beyond entropy minimization in word order variation,"Here we consider the problem of all the possible orders of a linguistic
structure formed by $n$ elements, for instance, subject, direct object and verb
($n=3$) or subject, direct object, indirect object and verb ($n=4$). We
investigate if the frequency of the $n!$ possible orders is constrained by two
principles. First, entropy minimization, a principle that has been suggested to
shape natural communication systems at distinct levels of organization. Second,
swap distance minimization, namely a preference for word orders that require
fewer swaps of adjacent elements to be produced from a source order. Here we
present average swap distance, a novel score for research on swap distance
minimization, and investigate the theoretical distribution of that score for
any $n$: its minimum and maximum values and its expected value in die rolling
experiments or when the word order frequencies are shuffled. We investigate
whether entropy and average swap distance are significantly small in distinct
linguistic structures with $n=3$ or $n=4$ in agreement with the corresponding
minimization principles. We find strong evidence of entropy minimization and
swap distance minimization with respect to a die rolling experiment. The
evidence of these two forces with respect to a Polya urn process is strong for
$n=4$ but weaker for $n=3$. We still find evidence of swap distance
minimization when word order frequencies are shuffled, indicating that swap
distance minimization effects are beyond pressure to minimize word order
entropy.",2024-04-22,"Víctor Franco-Sánchez, Arnau Martí-Llobet, Ramon Ferrer-i-Cancho",http://arxiv.org/pdf/2404.14192v4,cs.CL
"SemEval-2024 Task 8: Multidomain, Multimodel and Multilingual Machine-Generated Text Detection","We present the results and the main findings of SemEval-2024 Task 8:
Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection.
The task featured three subtasks. Subtask A is a binary classification task
determining whether a text is written by a human or generated by a machine.
This subtask has two tracks: a monolingual track focused solely on English
texts and a multilingual track. Subtask B is to detect the exact source of a
text, discerning whether it is written by a human or generated by a specific
LLM. Subtask C aims to identify the changing point within a text, at which the
authorship transitions from human to machine. The task attracted a large number
of participants: subtask A monolingual (126), subtask A multilingual (59),
subtask B (70), and subtask C (30). In this paper, we present the task, analyze
the results, and discuss the system submissions and the methods they used. For
all subtasks, the best systems used LLMs.",2024-04-22,"Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Osama Mohammed Afzal, Tarek Mahmoud, Giovanni Puccetti, Thomas Arnold, Chenxi Whitehouse, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov",http://arxiv.org/pdf/2404.14183v1,cs.CL
Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?,"Traditionally, success in multilingual machine translation can be attributed
to three key factors in training data: large volume, diverse translation
directions, and high quality. In the current practice of fine-tuning large
language models (LLMs) for translation, we revisit the importance of these
factors. We find that LLMs display strong translation capability after being
fine-tuned on as few as 32 parallel sentences and that fine-tuning on a single
translation direction enables translation in multiple directions. However, the
choice of direction is critical: fine-tuning LLMs with only English on the
target side can lead to task misinterpretation, which hinders translation into
non-English languages. Problems also arise when noisy synthetic data is placed
on the target side, especially when the target language is well-represented in
LLM pre-training. Yet interestingly, synthesized data in an under-represented
language has a less pronounced effect. Our findings suggest that when adapting
LLMs to translation, the requirement on data quantity can be eased but careful
considerations are still crucial to prevent an LLM from exploiting unintended
data biases.",2024-04-22,"Dawei Zhu, Pinzhen Chen, Miaoran Zhang, Barry Haddow, Xiaoyu Shen, Dietrich Klakow",http://arxiv.org/pdf/2404.14122v2,cs.CL
Benchmarking Advanced Text Anonymisation Methods: A Comparative Study on Novel and Traditional Approaches,"In the realm of data privacy, the ability to effectively anonymise text is
paramount. With the proliferation of deep learning and, in particular,
transformer architectures, there is a burgeoning interest in leveraging these
advanced models for text anonymisation tasks. This paper presents a
comprehensive benchmarking study comparing the performance of transformer-based
models and Large Language Models(LLM) against traditional architectures for
text anonymisation. Utilising the CoNLL-2003 dataset, known for its robustness
and diversity, we evaluate several models. Our results showcase the strengths
and weaknesses of each approach, offering a clear perspective on the efficacy
of modern versus traditional methods. Notably, while modern models exhibit
advanced capabilities in capturing con textual nuances, certain traditional
architectures still keep high performance. This work aims to guide researchers
in selecting the most suitable model for their anonymisation needs, while also
shedding light on potential paths for future advancements in the field.",2024-04-22,"Dimitris Asimopoulos, Ilias Siniosoglou, Vasileios Argyriou, Thomai Karamitsou, Eleftherios Fountoukidis, Sotirios K. Goudos, Ioannis D. Moscholios, Konstantinos E. Psannis, Panagiotis Sarigiannidis",http://arxiv.org/pdf/2404.14465v1,cs.CL
Bored to Death: Artificial Intelligence Research Reveals the Role of Boredom in Suicide Behavior,"Background: Recent advancements in Artificial Intelligence (AI) contributed
significantly to suicide assessment, however, our theoretical understanding of
this complex behavior is still limited. Objective: This study aimed to harness
AI methodologies to uncover hidden risk factors that trigger or aggravate
suicide behaviors. Method: The primary dataset included 228,052 Facebook
postings by 1,006 users who completed the gold-standard Columbia Suicide
Severity Rating Scale. This dataset was analyzed using a bottom-up research
pipeline without a-priory hypotheses and its findings were validated using a
top-down analysis of a new dataset. This secondary dataset included responses
by 1,062 participants to the same suicide scale as well as to well-validated
scales measuring depression and boredom. Results: An almost fully automated,
AI-guided research pipeline resulted in four Facebook topics that predicted the
risk of suicide, of which the strongest predictor was boredom. A comprehensive
literature review using APA PsycInfo revealed that boredom is rarely perceived
as a unique risk factor of suicide. A complementing top-down path analysis of
the secondary dataset uncovered an indirect relationship between boredom and
suicide, which was mediated by depression. An equivalent mediated relationship
was observed in the primary Facebook dataset as well. However, here, a direct
relationship between boredom and suicide risk was also observed. Conclusions:
Integrating AI methods allowed the discovery of an under-researched risk factor
of suicide. The study signals boredom as a maladaptive 'ingredient' that might
trigger suicide behaviors, regardless of depression. Further studies are
recommended to direct clinicians' attention to this burdening, and sometimes
existential experience.",2024-04-22,"Shir Lissak, Yaakov Ophir, Refael Tikochinski, Anat Brunstein Klomek, Itay Sisso, Eyal Fruchter, Roi Reichart",http://arxiv.org/pdf/2404.14057v2,cs.CL
Differential contributions of machine learning and statistical analysis to language and cognitive sciences,"Data-driven approaches have revolutionized scientific research, with machine
learning and statistical analysis being commonly used methodologies. Despite
their widespread use, these approaches differ significantly in their
techniques, objectives and implementations. Few studies have systematically
applied both methods to identical datasets to highlight potential differences,
particularly in language and cognitive sciences. This study employs the Buckeye
Speech Corpus to illustrate how machine learning and statistical analysis are
applied in data-driven research to obtain distinct insights on language
production. We demonstrate the theoretical differences, implementation steps,
and unique objectives of each approach through a comprehensive, tutorial-like
comparison. Our analysis reveals that while machine learning excels at pattern
recognition and prediction, statistical methods provide deeper insights into
relationships between variables. The study highlights how semantic relevance, a
novel metric measuring contextual influence on target words, contributes to
understanding word duration in speech. We also systematically compare the
differences between regression models used in machine learning and statistical
analysis, particularly focusing on the training and fitting processes.
Additionally, we clarify several common misconceptions that contribute to the
confusion between these two approaches. Overall, by elucidating the
complementary strengths of machine learning and statistics, this research
enhances our understanding of diverse data-driven strategies in language and
cognitive sciences, offering researchers valuable guidance on when and how to
effectively apply these approaches in different research contexts.",2024-04-22,"Kun Sun, Rong Wang",http://arxiv.org/pdf/2404.14052v2,cs.CL
LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation,"Retrieval-Augmented Generation (RAG) demonstrates great value in alleviating
outdated knowledge or hallucination by supplying LLMs with updated and relevant
knowledge. However, there are still several difficulties for RAG in
understanding complex multi-hop query and retrieving relevant documents, which
require LLMs to perform reasoning and retrieve step by step. Inspired by
human's reasoning process in which they gradually search for the required
information, it is natural to ask whether the LLMs could notice the missing
information in each reasoning step. In this work, we first experimentally
verified the ability of LLMs to extract information as well as to know the
missing. Based on the above discovery, we propose a Missing Information Guided
Retrieve-Extraction-Solving paradigm (MIGRES), where we leverage the
identification of missing information to generate a targeted query that steers
the subsequent knowledge retrieval. Besides, we design a sentence-level
re-ranking filtering approach to filter the irrelevant content out from
document, along with the information extraction capability of LLMs to extract
useful information from cleaned-up documents, which in turn to bolster the
overall efficacy of RAG. Extensive experiments conducted on multiple public
datasets reveal the superiority of the proposed MIGRES method, and analytical
experiments demonstrate the effectiveness of our proposed modules.",2024-04-22,"Keheng Wang, Feiyu Duan, Peiguang Li, Sirui Wang, Xunliang Cai",http://arxiv.org/pdf/2404.14043v1,cs.CL
Exploring neural oscillations during speech perception via surrogate gradient spiking neural networks,"Understanding cognitive processes in the brain demands sophisticated models
capable of replicating neural dynamics at large scales. We present a
physiologically inspired speech recognition architecture, compatible and
scalable with deep learning frameworks, and demonstrate that end-to-end
gradient descent training leads to the emergence of neural oscillations in the
central spiking neural network. Significant cross-frequency couplings,
indicative of these oscillations, are measured within and across network layers
during speech processing, whereas no such interactions are observed when
handling background noise inputs. Furthermore, our findings highlight the
crucial inhibitory role of feedback mechanisms, such as spike frequency
adaptation and recurrent connections, in regulating and synchronising neural
activity to improve recognition performance. Overall, on top of developing our
understanding of synchronisation phenomena notably observed in the human
auditory pathway, our architecture exhibits dynamic and efficient information
processing, with relevance to neuromorphic technology.",2024-04-22,"Alexandre Bittar, Philip N. Garner",http://arxiv.org/pdf/2404.14024v2,cs.CL
Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering,"Multi-hop question answering is a knowledge-intensive complex problem. Large
Language Models (LLMs) use their Chain of Thoughts (CoT) capability to reason
complex problems step by step, and retrieval-augmentation can effectively
alleviate factual errors caused by outdated and unknown knowledge in LLMs.
Recent works have introduced retrieval-augmentation in the CoT reasoning to
solve multi-hop question answering. However, these chain methods have the
following problems: 1) Retrieved irrelevant paragraphs may mislead the
reasoning; 2) An error in the chain structure may lead to a cascade of errors.
  In this paper, we propose a dynamic retrieval framework called Tree of
Reviews (ToR), where the root node is the question, and the other nodes are
paragraphs from retrieval, extending different reasoning paths from the root
node to other nodes. Our framework dynamically decides to initiate a new
search, reject, or accept based on the paragraphs on the reasoning paths.
Compared to related work, we introduce a tree structure to handle each
retrieved paragraph separately, alleviating the misleading effect of irrelevant
paragraphs on the reasoning path; the diversity of reasoning path extension
reduces the impact of a single reasoning error on the whole. We conducted
experiments on three different multi-hop question answering datasets. The
results show that compared to the baseline methods, ToR achieves
state-of-the-art performance in both retrieval and response generation. In
addition, we propose two tree-based search optimization strategies, pruning and
effective expansion, to reduce time overhead and increase the diversity of path
extension. We will release our code.",2024-04-22,"Li Jiapeng, Liu Runze, Li Yabo, Zhou Tong, Li Mingling, Chen Xiang",http://arxiv.org/pdf/2404.14464v1,cs.CL
DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews,"Automatic depression detection from conversational data has gained
significant interest in recent years. The DAIC-WOZ dataset, interviews
conducted by a human-controlled virtual agent, has been widely used for this
task. Recent studies have reported enhanced performance when incorporating
interviewer's prompts into the model. In this work, we hypothesize that this
improvement might be mainly due to a bias present in these prompts, rather than
the proposed architectures and methods. Through ablation experiments and
qualitative analysis, we discover that models using interviewer's prompts learn
to focus on a specific region of the interviews, where questions about past
experiences with mental health issues are asked, and use them as discriminative
shortcuts to detect depressed participants. In contrast, models using
participant responses gather evidence from across the entire interview.
Finally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by
intentionally exploiting it, the highest result reported to date on this
dataset using only textual information. Our findings underline the need for
caution when incorporating interviewers' prompts into models, as they may
inadvertently learn to exploit targeted prompts, rather than learning to
characterize the language and behavior that are genuinely indicative of the
patient's mental health condition.",2024-04-22,"Sergio Burdisso, Ernesto Reyes-Ramírez, Esaú Villatoro-Tello, Fernando Sánchez-Vega, Pastor López-Monroy, Petr Motlicek",http://arxiv.org/pdf/2404.14463v1,cs.CL
Information Re-Organization Improves Reasoning in Large Language Models,"Improving the reasoning capabilities of large language models (LLMs) has
attracted considerable interest. Recent approaches primarily focus on improving
the reasoning process to yield a more precise final answer. However, in
scenarios involving contextually aware reasoning, these methods neglect the
importance of first identifying logical relationships from the context before
proceeding with the reasoning. This oversight could lead to a superficial
understanding and interaction with the context, potentially undermining the
quality and reliability of the reasoning outcomes. In this paper, we propose an
information re-organization (InfoRE) method before proceeding with the
reasoning to enhance the reasoning ability of LLMs. Our re-organization method
involves initially extracting logical relationships from the contextual
content, such as documents or paragraphs, and subsequently pruning redundant
content to minimize noise. Then, we utilize the re-organized information in the
reasoning process. This enables LLMs to deeply understand the contextual
content by clearly perceiving these logical relationships, while also ensuring
high-quality responses by eliminating potential noise. To demonstrate the
effectiveness of our approach in improving the reasoning ability, we conduct
experiments using Llama2-70B, GPT-3.5, and GPT-4 on various contextually aware
multi-hop reasoning tasks. Using only a zero-shot setting, our method achieves
an average absolute improvement of 4% across all tasks, highlighting its
potential to improve the reasoning performance of LLMs. Our source code is
available at https://github.com/hustcxx/InfoRE.",2024-04-22,"Xiaoxia Cheng, Zeqi Tan, Wei Xue, Weiming Lu",http://arxiv.org/pdf/2404.13985v2,cs.CL
Do not think about pink elephant!,"Large Models (LMs) have heightened expectations for the potential of general
AI as they are akin to human intelligence. This paper shows that recent large
models such as Stable Diffusion and DALL-E3 also share the vulnerability of
human intelligence, namely the ""white bear phenomenon"". We investigate the
causes of the white bear phenomenon by analyzing their representation space.
Based on this analysis, we propose a simple prompt-based attack method, which
generates figures prohibited by the LM provider's policy. To counter these
attacks, we introduce prompt-based defense strategies inspired by cognitive
therapy techniques, successfully mitigating attacks by up to 48.22\%.",2024-04-22,"Kyomin Hwang, Suyoung Kim, JunHoo Lee, Nojun Kwak",http://arxiv.org/pdf/2404.15154v2,cs.CL
Protecting Your LLMs with Information Bottleneck,"The advent of large language models (LLMs) has revolutionized the field of
natural language processing, yet they might be attacked to produce harmful
content. Despite efforts to ethically align LLMs, these are often fragile and
can be circumvented by jailbreaking attacks through optimized or manual
adversarial prompts. To address this, we introduce the Information Bottleneck
Protector (IBProtector), a defense mechanism grounded in the information
bottleneck principle, and we modify the objective to avoid trivial solutions.
The IBProtector selectively compresses and perturbs prompts, facilitated by a
lightweight and trainable extractor, preserving only essential information for
the target LLMs to respond with the expected answer. Moreover, we further
consider a situation where the gradient is not visible to be compatible with
any LLM. Our empirical evaluations show that IBProtector outperforms current
defense methods in mitigating jailbreak attempts, without overly affecting
response quality or inference speed. Its effectiveness and adaptability across
various attack methods and target LLMs underscore the potential of IBProtector
as a novel, transferable defense that bolsters the security of LLMs without
requiring modifications to the underlying models.",2024-04-22,"Zichuan Liu, Zefan Wang, Linjie Xu, Jinyu Wang, Lei Song, Tianchun Wang, Chunlin Chen, Wei Cheng, Jiang Bian",http://arxiv.org/pdf/2404.13968v3,cs.CL
How Well Can LLMs Echo Us? Evaluating AI Chatbots' Role-Play Ability with ECHO,"The role-play ability of Large Language Models (LLMs) has emerged as a
popular research direction. However, existing studies focus on imitating
well-known public figures or fictional characters, overlooking the potential
for simulating ordinary individuals. Such an oversight limits the potential for
advancements in digital human clones and non-player characters in video games.
To bridge this gap, we introduce ECHO, an evaluative framework inspired by the
Turing test. This framework engages the acquaintances of the target individuals
to distinguish between human and machine-generated responses. Notably, our
framework focuses on emulating average individuals rather than historical or
fictional figures, presenting a unique advantage to apply the Turing Test. We
evaluated three role-playing LLMs using ECHO, with GPT-3.5 and GPT-4 serving as
foundational models, alongside the online application GPTs from OpenAI. Our
results demonstrate that GPT-4 more effectively deceives human evaluators, and
GPTs achieves a leading success rate of 48.3%. Furthermore, we investigated
whether LLMs could discern between human-generated and machine-generated texts.
While GPT-4 can identify differences, it could not determine which texts were
human-produced. Our code and results of reproducing the role-playing LLMs are
made publicly available via https://github.com/CUHK-ARISE/ECHO.",2024-04-22,"Man Tik Ng, Hui Tung Tse, Jen-tse Huang, Jingjing Li, Wenxuan Wang, Michael R. Lyu",http://arxiv.org/pdf/2404.13957v1,cs.CL
Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations,"The robustness of recent Large Language Models (LLMs) has become increasingly
crucial as their applicability expands across various domains and real-world
applications. Retrieval-Augmented Generation (RAG) is a promising solution for
addressing the limitations of LLMs, yet existing studies on the robustness of
RAG often overlook the interconnected relationships between RAG components or
the potential threats prevalent in real-world databases, such as minor textual
errors. In this work, we investigate two underexplored aspects when assessing
the robustness of RAG: 1) vulnerability to noisy documents through low-level
perturbations and 2) a holistic evaluation of RAG robustness. Furthermore, we
introduce a novel attack method, the Genetic Attack on RAG (\textit{GARAG}),
which targets these aspects. Specifically, GARAG is designed to reveal
vulnerabilities within each component and test the overall system functionality
against noisy documents. We validate RAG robustness by applying our
\textit{GARAG} to standard QA datasets, incorporating diverse retrievers and
LLMs. The experimental results show that GARAG consistently achieves high
attack success rates. Also, it significantly devastates the performance of each
component and their synergy, highlighting the substantial risk that minor
textual inaccuracies pose in disrupting RAG systems in the real world.",2024-04-22,"Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Taeho Hwang, Jong C. Park",http://arxiv.org/pdf/2404.13948v2,cs.CL
A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models,"Large language models (LLMs) are essential tools that users employ across
various scenarios, so evaluating their performance and guiding users in
selecting the suitable service is important. Although many benchmarks exist,
they mainly focus on specific predefined model abilities, such as world
knowledge, reasoning, etc. Based on these ability scores, it is hard for users
to determine which LLM best suits their particular needs. To address these
issues, we propose to evaluate LLMs from a user-centric perspective and design
this benchmark to measure their efficacy in satisfying user needs under
distinct intents. Firstly, we collect 1,846 real-world use cases from a user
study with 712 participants from 23 countries. This first-hand data helps us
understand actual user intents and needs in LLM interactions, forming the User
Reported Scenarios (URS) dataset, which is categorized with six types of user
intents. Secondly, based on this authentic dataset, we benchmark 10 LLM
services with GPT-4-as-Judge. Thirdly, we show that benchmark scores align well
with human preference in both real-world experience and pair-wise annotations,
achieving Pearson correlations of 0.95 and 0.94, respectively. This alignment
confirms that the URS dataset and our evaluation method establish an effective
user-centric benchmark. The dataset, code, and process data are available at
https://github.com/Alice1998/URS.",2024-04-22,"Jiayin Wang, Fengran Mo, Weizhi Ma, Peijie Sun, Min Zhang, Jian-Yun Nie",http://arxiv.org/pdf/2404.13940v3,cs.CL
SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense,"While vertical thinking relies on logical and commonsense reasoning, lateral
thinking requires systems to defy commonsense associations and overwrite them
through unconventional thinking. Lateral thinking has been shown to be
challenging for current models but has received little attention. A recent
benchmark, BRAINTEASER, aims to evaluate current models' lateral thinking
ability in a zero-shot setting. In this paper, we split the original benchmark
to also support fine-tuning setting and present SemEval Task 9:
BRAIN-TEASER(S), the first task at this competition designed to test the
system's reasoning and lateral thinking ability. As a popular task,
BRAINTEASER(S)'s two subtasks receive 483 team submissions from 182
participants during the competition. This paper provides a fine-grained system
analysis of the competition results, together with a reflection on what this
means for the ability of the systems to reason laterally. We hope that the
BRAINTEASER(S) subtasks and findings in this paper can stimulate future work on
lateral thinking and robust reasoning by computational models.",2024-04-22,"Yifan Jiang, Filip Ilievski, Kaixin Ma",http://arxiv.org/pdf/2404.16068v1,cs.CL
MARIO Eval: Evaluate Your Math LLM with your Math LLM--A mathematical dataset evaluation toolkit,"Large language models (LLMs) have been explored in a variety of reasoning
tasks including solving of mathematical problems. Each math dataset typically
includes its own specially designed evaluation script, which, while suitable
for its intended use, lacks generalizability across different datasets.
Consequently, updates and adaptations to these evaluation tools tend to occur
without being systematically reported, leading to inconsistencies and obstacles
to fair comparison across studies. To bridge this gap, we introduce a
comprehensive mathematical evaluation toolkit that not only utilizes a python
computer algebra system (CAS) for its numerical accuracy, but also integrates
an optional LLM, known for its considerable natural language processing
capabilities. To validate the effectiveness of our toolkit, we manually
annotated two distinct datasets. Our experiments demonstrate that the toolkit
yields more robust evaluation results compared to prior works, even without an
LLM. Furthermore, when an LLM is incorporated, there is a notable enhancement.
The code for our method will be made available at
\url{https://github.com/MARIO-Math-Reasoning/math_evaluation}.",2024-04-22,"Boning Zhang, Chengxi Li, Kai Fan",http://arxiv.org/pdf/2404.13925v1,cs.CL
Navigating the Path of Writing: Outline-guided Text Generation with Large Language Models,"Large Language Models (LLMs) have impacted the writing process, enhancing
productivity by collaborating with humans in content creation platforms.
However, generating high-quality, user-aligned text to satisfy real-world
content creation needs remains challenging. We propose WritingPath, a framework
that uses explicit outlines to guide LLMs in generating goal-oriented,
high-quality text. Our approach draws inspiration from structured writing
planning and reasoning paths, focusing on reflecting user intentions throughout
the writing process. To validate our approach in real-world scenarios, we
construct a diverse dataset from unstructured blog posts to benchmark writing
performance and introduce a comprehensive evaluation framework assessing the
quality of outlines and generated texts. Our evaluations with various LLMs
demonstrate that the WritingPath approach significantly enhances text quality
according to evaluations by both LLMs and professional writers.",2024-04-22,"Yukyung Lee, Soonwon Ka, Bokyung Son, Pilsung Kang, Jaewook Kang",http://arxiv.org/pdf/2404.13919v2,cs.CL
Generating Attractive and Authentic Copywriting from Customer Reviews,"The goal of product copywriting is to capture the interest of potential
buyers by emphasizing the features of products through text descriptions. As
e-commerce platforms offer a wide range of services, it's becoming essential to
dynamically adjust the styles of these auto-generated descriptions. Typical
approaches to copywriting generation often rely solely on specified product
attributes, which may result in dull and repetitive content. To tackle this
issue, we propose to generate copywriting based on customer reviews, as they
provide firsthand practical experiences with products, offering a richer source
of information than just product attributes. We have developed a
sequence-to-sequence framework, enhanced with reinforcement learning, to
produce copywriting that is attractive, authentic, and rich in information. Our
framework outperforms all existing baseline and zero-shot large language
models, including LLaMA-2-chat-7B and GPT-3.5, in terms of both attractiveness
and faithfulness. Furthermore, this work features the use of LLMs for
aspect-based summaries collection and argument allure assessment. Experiments
demonstrate the effectiveness of using LLMs for marketing domain corpus
construction. The code and the dataset is publicly available at:
https://github.com/YuXiangLin1234/Copywriting-Generation.",2024-04-22,"Yu-Xiang Lin, Wei-Yun Ma",http://arxiv.org/pdf/2404.13906v2,cs.CL
MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making,"Foundation models are becoming valuable tools in medicine. Yet despite their
promise, the best way to leverage Large Language Models (LLMs) in complex
medical tasks remains an open question. We introduce a novel multi-agent
framework, named Medical Decision-making Agents (MDAgents) that helps address
this gap by automatically assigning a collaboration structure to a team of
LLMs. The assigned solo or group collaboration structure is tailored to the
medical task at hand, emulating real-world medical decision-making processes
adapted to tasks of varying complexities. We evaluate our framework and
baseline methods using state-of-the-art LLMs across a suite of real-world
medical knowledge and medical diagnosis benchmarks, including a comparison of
LLMs' medical complexity classification against human physicians. MDAgents
achieved the best performance in seven out of ten benchmarks on tasks requiring
an understanding of medical knowledge and multi-modal reasoning, showing a
significant improvement of up to 4.2% (p < 0.05) compared to previous methods'
best performances. Ablation studies reveal that MDAgents effectively determines
medical complexity to optimize for efficiency and accuracy across diverse
medical tasks. Notably, the combination of moderator review and external
medical knowledge in group collaboration resulted in an average accuracy
improvement of 11.8%. Our code can be found at
https://github.com/mitmedialab/MDAgents.",2024-04-22,"Yubin Kim, Chanwoo Park, Hyewon Jeong, Yik Siu Chan, Xuhai Xu, Daniel McDuff, Hyeonhoon Lee, Marzyeh Ghassemi, Cynthia Breazeal, Hae Won Park",http://arxiv.org/pdf/2404.15155v3,cs.CL
Towards Better Text-to-Image Generation Alignment via Attention Modulation,"In text-to-image generation tasks, the advancements of diffusion models have
facilitated the fidelity of generated results. However, these models encounter
challenges when processing text prompts containing multiple entities and
attributes. The uneven distribution of attention results in the issues of
entity leakage and attribute misalignment. Training from scratch to address
this issue requires numerous labeled data and is resource-consuming. Motivated
by this, we propose an attribution-focusing mechanism, a training-free
phase-wise mechanism by modulation of attention for diffusion model. One of our
core ideas is to guide the model to concentrate on the corresponding syntactic
components of the prompt at distinct timesteps. To achieve this, we incorporate
a temperature control mechanism within the early phases of the self-attention
modules to mitigate entity leakage issues. An object-focused masking scheme and
a phase-wise dynamic weight control mechanism are integrated into the
cross-attention modules, enabling the model to discern the affiliation of
semantic information between entities more effectively. The experimental
results in various alignment scenarios demonstrate that our model attain better
image-text alignment with minimal additional computational cost.",2024-04-22,"Yihang Wu, Xiao Cao, Kaixin Li, Zitan Chen, Haonan Wang, Lei Meng, Zhiyong Huang",http://arxiv.org/pdf/2404.13899v1,cs.CL
Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals,"Large Language Models (LLMs) have emerged as potent tools for advancing the
United Nations' Sustainable Development Goals (SDGs). However, the attitudinal
disparities between LLMs and humans towards these goals can pose significant
challenges. This study conducts a comprehensive review and analysis of the
existing literature on the attitudes of LLMs towards the 17 SDGs, emphasizing
the comparison between their attitudes and support for each goal and those of
humans. We examine the potential disparities, primarily focusing on aspects
such as understanding and emotions, cultural and regional differences, task
objective variations, and factors considered in the decision-making process.
These disparities arise from the underrepresentation and imbalance in LLM
training data, historical biases, quality issues, lack of contextual
understanding, and skewed ethical values reflected. The study also investigates
the risks and harms that may arise from neglecting the attitudes of LLMs
towards the SDGs, including the exacerbation of social inequalities, racial
discrimination, environmental destruction, and resource wastage. To address
these challenges, we propose strategies and recommendations to guide and
regulate the application of LLMs, ensuring their alignment with the principles
and goals of the SDGs, and therefore creating a more just, inclusive, and
sustainable future.",2024-04-22,"Qingyang Wu, Ying Xu, Tingsong Xiao, Yunze Xiao, Yitong Li, Tianyang Wang, Yichi Zhang, Shanghai Zhong, Yuwei Zhang, Wei Lu, Yifan Yang",http://arxiv.org/pdf/2404.13885v2,cs.CL
Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs,"Large language models are aligned to be safe, preventing users from
generating harmful content like misinformation or instructions for illegal
activities. However, previous work has shown that the alignment process is
vulnerable to poisoning attacks. Adversaries can manipulate the safety training
data to inject backdoors that act like a universal sudo command: adding the
backdoor string to any prompt enables harmful responses from models that,
otherwise, behave safely. Our competition, co-located at IEEE SaTML 2024,
challenged participants to find universal backdoors in several large language
models. This report summarizes the key findings and promising ideas for future
research.",2024-04-22,"Javier Rando, Francesco Croce, Kryštof Mitka, Stepan Shabalin, Maksym Andriushchenko, Nicolas Flammarion, Florian Tramèr",http://arxiv.org/pdf/2404.14461v2,cs.CL
VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models,"Large Vision-Language Models (LVLMs) suffer from hallucination issues,
wherein the models generate plausible-sounding but factually incorrect outputs,
undermining their reliability. A comprehensive quantitative evaluation is
necessary to identify and understand the extent of hallucinations in these
models. However, existing benchmarks are often limited in scope, focusing
mainly on object hallucinations. Furthermore, current evaluation methods
struggle to effectively address the subtle semantic distinctions between model
outputs and reference data, as well as the balance between hallucination and
informativeness. To address these issues, we introduce a multi-dimensional
benchmark covering objects, attributes, and relations, with challenging images
selected based on associative biases. Moreover, we propose a large language
model (LLM)-based two-stage evaluation framework that generalizes the popular
CHAIR metric and incorporates both faithfulness and coverage into the
evaluation. Experiments on 10 established LVLMs demonstrate that our evaluation
metric is more comprehensive and better correlated with humans than existing
work when evaluating on our challenging human-annotated benchmark dataset. Our
work also highlights the critical balance between faithfulness and coverage of
model outputs, and encourages future works to address hallucinations in LVLMs
while keeping their outputs informative.",2024-04-22,"Haoyi Qiu, Wenbo Hu, Zi-Yi Dou, Nanyun Peng",http://arxiv.org/pdf/2404.13874v4,cs.CL
Context-Enhanced Language Models for Generating Multi-Paper Citations,"Citation text plays a pivotal role in elucidating the connection between
scientific documents, demanding an in-depth comprehension of the cited paper.
Constructing citations is often time-consuming, requiring researchers to delve
into extensive literature and grapple with articulating relevant content. To
address this challenge, the field of citation text generation (CTG) has
emerged. However, while earlier methods have primarily centered on creating
single-sentence citations, practical scenarios frequently necessitate citing
multiple papers within a single paragraph. To bridge this gap, we propose a
method that leverages Large Language Models (LLMs) to generate multi-citation
sentences. Our approach involves a single source paper and a collection of
target papers, culminating in a coherent paragraph containing multi-sentence
citation text. Furthermore, we introduce a curated dataset named MCG-S2ORC,
composed of English-language academic research papers in Computer Science,
showcasing multiple citation instances. In our experiments, we evaluate three
LLMs LLaMA, Alpaca, and Vicuna to ascertain the most effective model for this
endeavor. Additionally, we exhibit enhanced performance by integrating
knowledge graphs from target papers into the prompts for generating citation
text. This research underscores the potential of harnessing LLMs for citation
generation, opening a compelling avenue for exploring the intricate connections
between scientific documents.",2024-04-22,"Avinash Anand, Kritarth Prasad, Ujjwal Goel, Mohit Gupta, Naman Lal, Astha Verma, Rajiv Ratn Shah",http://arxiv.org/pdf/2404.13865v1,cs.CL
Understanding the role of FFNs in driving multilingual behaviour in LLMs,"Multilingualism in Large Language Models (LLMs) is an yet under-explored
area. In this paper, we conduct an in-depth analysis of the multilingual
capabilities of a family of a Large Language Model, examining its architecture,
activation patterns, and processing mechanisms across languages. We introduce
novel metrics to probe the model's multilingual behaviour at different layers
and shed light on the impact of architectural choices on multilingual
processing.
  Our findings reveal different patterns of multilinugal processing in the
sublayers of Feed-Forward Networks of the models. Furthermore, we uncover the
phenomenon of ""over-layerization"" in certain model configurations, where
increasing layer depth without corresponding adjustments to other parameters
may degrade model performance. Through comparisons within and across languages,
we demonstrate the interplay between model architecture, layer depth, and
multilingual processing capabilities of LLMs trained on multiple languages.",2024-04-22,"Sunit Bhattacharya, Ondřej Bojar",http://arxiv.org/pdf/2404.13855v1,cs.CL
EventLens: Leveraging Event-Aware Pretraining and Cross-modal Linking Enhances Visual Commonsense Reasoning,"Visual Commonsense Reasoning (VCR) is a cognitive task, challenging models to
answer visual questions requiring human commonsense, and to provide rationales
explaining why the answers are correct. With emergence of Large Language Models
(LLMs), it is natural and imperative to explore their applicability to VCR.
However, VCR task demands more external knowledge to tackle its challenging
questions, necessitating special designs to activate LLMs' commonsense
reasoning abilities. Also, most existing Multimodal LLMs adopted an abstraction
of entire input image, which makes it difficult to comprehend VCR's unique
co-reference tags between image regions and text, posing challenges for
fine-grained alignment. To address these issues, we propose EventLens that
leverages Event-Aware Pretraining and Cross-modal Linking and EnhanceS VCR.
First, by emulating the cognitive process of human reasoning, an Event-Aware
Pretraining auxiliary task is introduced to better activate LLM's global
comprehension of intricate scenarios. Second, during fine-tuning, we further
utilize reference tags to bridge RoI features with texts, while preserving both
modality semantics. Finally, we use instruct-style prompts to narrow the gap
between pretraining and fine-tuning, and task-specific adapters to better
integrate LLM's inherent knowledge with new commonsense. Experimental results
show the effectiveness of our proposed auxiliary task and fine-grained linking
strategy.",2024-04-22,"Mingjie Ma, Zhihuan Yu, Yichao Ma, Guohui Li",http://arxiv.org/pdf/2404.13847v1,cs.CL
Filtered Direct Preference Optimization,"Reinforcement learning from human feedback (RLHF) plays a crucial role in
aligning language models with human preferences. While the significance of
dataset quality is generally recognized, explicit investigations into its
impact within the RLHF framework, to our knowledge, have been limited. This
paper addresses the issue of text quality within the preference dataset by
focusing on direct preference optimization (DPO), an increasingly adopted
reward-model-free RLHF method. We confirm that text quality significantly
influences the performance of models optimized with DPO more than those
optimized with reward-model-based RLHF. Building on this new insight, we
propose an extension of DPO, termed filtered direct preference optimization
(fDPO). fDPO uses a trained reward model to monitor the quality of texts within
the preference dataset during DPO training. Samples of lower quality are
discarded based on comparisons with texts generated by the model being
optimized, resulting in a more accurate dataset. Experimental results
demonstrate that fDPO enhances the final model performance. Our code is
available at https://github.com/CyberAgentAILab/filtered-dpo.",2024-04-22,"Tetsuro Morimura, Mitsuki Sakamoto, Yuu Jinnai, Kenshi Abe, Kaito Ariu",http://arxiv.org/pdf/2404.13846v4,cs.CL
MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA-based Mixture of Experts,"Fine-tuning Large Language Models (LLMs) is a common practice to adapt
pre-trained models for specific applications. While methods like LoRA have
effectively addressed GPU memory constraints during fine-tuning, their
performance often falls short, especially in multi-task scenarios. In contrast,
Mixture-of-Expert (MoE) models, such as Mixtral 8x7B, demonstrate remarkable
performance in multi-task learning scenarios while maintaining a reduced
parameter count. However, the resource requirements of these MoEs remain
challenging, particularly for consumer-grade GPUs with less than 24GB memory.
To tackle these challenges, we propose MixLoRA, an approach to construct a
resource-efficient sparse MoE model based on LoRA. MixLoRA inserts multiple
LoRA-based experts within the feed-forward network block of a frozen
pre-trained dense model and employs a commonly used top-k router. Unlike other
LoRA-based MoE methods, MixLoRA enhances model performance by utilizing
independent attention-layer LoRA adapters. Additionally, an auxiliary load
balance loss is employed to address the imbalance problem of the router. Our
evaluations show that MixLoRA improves about 9% accuracy compared to
state-of-the-art PEFT methods in multi-task learning scenarios. We also propose
a new high-throughput framework to alleviate the computation and memory
bottlenecks during the training and inference of MOE models. This framework
reduces GPU memory consumption by 40% and token computation latency by 30%
during both training and inference.",2024-04-22,"Dengchun Li, Yingzi Ma, Naizheng Wang, Zhengmao Ye, Zhiyuan Cheng, Yinghao Tang, Yan Zhang, Lei Duan, Jie Zuo, Cal Yang, Mingjie Tang",http://arxiv.org/pdf/2404.15159v3,cs.CL
From LLM to NMT: Advancing Low-Resource Machine Translation with Claude,"We show that Claude 3 Opus, a large language model (LLM) released by
Anthropic in March 2024, exhibits stronger machine translation competence than
other LLMs. Though we find evidence of data contamination with Claude on
FLORES-200, we curate new benchmarks that corroborate the effectiveness of
Claude for low-resource machine translation into English. We find that Claude
has remarkable \textit{resource efficiency} -- the degree to which the quality
of the translation model depends on a language pair's resource level. Finally,
we show that advancements in LLM translation can be compressed into traditional
neural machine translation (NMT) models. Using Claude to generate synthetic
data, we demonstrate that knowledge distillation advances the state-of-the-art
in Yoruba-English translation, meeting or surpassing strong baselines like
NLLB-54B and Google Translate.",2024-04-22,"Maxim Enis, Mark Hopkins",http://arxiv.org/pdf/2404.13813v1,cs.CL
FASTTRACK: Fast and Accurate Fact Tracing for LLMs,"Fact tracing seeks to identify specific training examples that serve as the
knowledge source for a given query. Existing approaches to fact tracing rely on
assessing the similarity between each training sample and the query along a
certain dimension, such as lexical similarity, gradient, or embedding space.
However, these methods fall short of effectively distinguishing between samples
that are merely relevant and those that actually provide supportive evidence
for the information sought by the query. This limitation often results in
suboptimal effectiveness. Moreover, these approaches necessitate the
examination of the similarity of individual training points for each query,
imposing significant computational demands and creating a substantial barrier
for practical applications. This paper introduces FASTTRACK, a novel approach
that harnesses the capabilities of Large Language Models (LLMs) to validate
supportive evidence for queries and at the same time clusters the training
database towards a reduced extent for LLMs to trace facts. Our experiments show
that FASTTRACK substantially outperforms existing methods in both accuracy and
efficiency, achieving more than 100\% improvement in F1 score over the
state-of-the-art methods while being X33 faster than \texttt{TracIn}.",2024-04-22,"Si Chen, Feiyang Kang, Ning Yu, Ruoxi Jia",http://arxiv.org/pdf/2404.15157v1,cs.CL
Stream State-tying for Sign Language Recognition,"In this paper, a novel approach to sign language recognition based on state
tying in each of data streams is presented. In this framework, it is assumed
that hand gesture signal is represented in terms of six synchronous data
streams, i.e., the left/right hand position, left/right hand orientation and
left/right handshape. This approach offers a very accurate representation of
the sign space and keeps the number of parameters reasonably small in favor of
a fast decoding. Experiments were carried out for 5177 Chinese signs. The real
time isolated recognition rate is 94.8%. For continuous sign recognition, the
word correct rate is 91.4%. Keywords: Sign language recognition; Automatic sign
language translation; Hand gesture recognition; Hidden Markov models;
State-tying; Multimodal user interface; Virtual reality; Man-machine systems.",2024-04-21,"Jiyong Ma, Wen Gao, Chunli Wang",http://arxiv.org/pdf/2407.10975v1,cs.CL
Lightweight Connective Detection Using Gradient Boosting,"In this work, we introduce a lightweight discourse connective detection
system. Employing gradient boosting trained on straightforward, low-complexity
features, this proposed approach sidesteps the computational demands of the
current approaches that rely on deep neural networks. Considering its
simplicity, our approach achieves competitive results while offering
significant gains in terms of time even on CPU. Furthermore, the stable
performance across two unrelated languages suggests the robustness of our
system in the multilingual scenario. The model is designed to support the
annotation of discourse relations, particularly in scenarios with limited
resources, while minimizing performance loss.",2024-04-21,"Mustafa Erolcan Er, Murathan Kurfalı, Deniz Zeyrek",http://arxiv.org/pdf/2404.13793v1,cs.CL
Counterfactual Reasoning Using Predicted Latent Personality Dimensions for Optimizing Persuasion Outcome,"Customizing persuasive conversations related to the outcome of interest for
specific users achieves better persuasion results. However, existing persuasive
conversation systems rely on persuasive strategies and encounter challenges in
dynamically adjusting dialogues to suit the evolving states of individual users
during interactions. This limitation restricts the system's ability to deliver
flexible or dynamic conversations and achieve suboptimal persuasion outcomes.
In this paper, we present a novel approach that tracks a user's latent
personality dimensions (LPDs) during ongoing persuasion conversation and
generates tailored counterfactual utterances based on these LPDs to optimize
the overall persuasion outcome. In particular, our proposed method leverages a
Bi-directional Generative Adversarial Network (BiCoGAN) in tandem with a
Dialogue-based Personality Prediction Regression (DPPR) model to generate
counterfactual data. This enables the system to formulate alternative
persuasive utterances that are more suited to the user. Subsequently, we
utilize the D3QN model to learn policies for optimized selection of system
utterances on counterfactual data. Experimental results we obtained from using
the PersuasionForGood dataset demonstrate the superiority of our approach over
the existing method, BiCoGAN. The cumulative rewards and Q-values produced by
our method surpass ground truth benchmarks, showcasing the efficacy of
employing counterfactual reasoning and LPDs to optimize reinforcement learning
policy in online interactions.",2024-04-21,"Donghuo Zeng, Roberto S. Legaspi, Yuewen Sun, Xinshuai Dong, Kazushi Ikeda, Peter Spirtes, kun Zhang",http://arxiv.org/pdf/2404.13792v1,cs.CL
AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs,"While recently Large Language Models (LLMs) have achieved remarkable
successes, they are vulnerable to certain jailbreaking attacks that lead to
generation of inappropriate or harmful content. Manual red-teaming requires
finding adversarial prompts that cause such jailbreaking, e.g. by appending a
suffix to a given instruction, which is inefficient and time-consuming. On the
other hand, automatic adversarial prompt generation often leads to semantically
meaningless attacks that can easily be detected by perplexity-based filters,
may require gradient information from the TargetLLM, or do not scale well due
to time-consuming discrete optimization processes over the token space. In this
paper, we present a novel method that uses another LLM, called the AdvPrompter,
to generate human-readable adversarial prompts in seconds, $\sim800\times$
faster than existing optimization-based approaches. We train the AdvPrompter
using a novel algorithm that does not require access to the gradients of the
TargetLLM. This process alternates between two steps: (1) generating
high-quality target adversarial suffixes by optimizing the AdvPrompter
predictions, and (2) low-rank fine-tuning of the AdvPrompter with the generated
adversarial suffixes. The trained AdvPrompter generates suffixes that veil the
input instruction without changing its meaning, such that the TargetLLM is
lured to give a harmful response. Experimental results on popular open source
TargetLLMs show state-of-the-art results on the AdvBench dataset, that also
transfer to closed-source black-box LLM APIs. Further, we demonstrate that by
fine-tuning on a synthetic dataset generated by AdvPrompter, LLMs can be made
more robust against jailbreaking attacks while maintaining performance, i.e.
high MMLU scores.",2024-04-21,"Anselm Paulus, Arman Zharmagambetov, Chuan Guo, Brandon Amos, Yuandong Tian",http://arxiv.org/pdf/2404.16873v1,cs.CL
Iteratively Prompting Multimodal LLMs to Reproduce Natural and AI-Generated Images,"With the digital imagery landscape rapidly evolving, image stocks and
AI-generated image marketplaces have become central to visual media.
Traditional stock images now exist alongside innovative platforms that trade in
prompts for AI-generated visuals, driven by sophisticated APIs like DALL-E 3
and Midjourney. This paper studies the possibility of employing multi-modal
models with enhanced visual understanding to mimic the outputs of these
platforms, introducing an original attack strategy. Our method leverages
fine-tuned CLIP models, a multi-label classifier, and the descriptive
capabilities of GPT-4V to create prompts that generate images similar to those
available in marketplaces and from premium stock image providers, yet at a
markedly lower expense. In presenting this strategy, we aim to spotlight a new
class of economic and security considerations within the realm of digital
imagery. Our findings, supported by both automated metrics and human
assessment, reveal that comparable visual content can be produced for a
fraction of the prevailing market prices ($0.23 - $0.27 per image), emphasizing
the need for awareness and strategic discussions about the integrity of digital
media in an increasingly AI-integrated landscape. Our work also contributes to
the field by assembling a dataset consisting of approximately 19 million
prompt-image pairs generated by the popular Midjourney platform, which we plan
to release publicly.",2024-04-21,"Ali Naseh, Katherine Thai, Mohit Iyyer, Amir Houmansadr",http://arxiv.org/pdf/2404.13784v1,cs.CL
Evaluating Retrieval Quality in Retrieval-Augmented Generation,"Evaluating retrieval-augmented generation (RAG) presents challenges,
particularly for retrieval models within these systems. Traditional end-to-end
evaluation methods are computationally expensive. Furthermore, evaluation of
the retrieval model's performance based on query-document relevance labels
shows a small correlation with the RAG system's downstream performance. We
propose a novel evaluation approach, eRAG, where each document in the retrieval
list is individually utilized by the large language model within the RAG
system. The output generated for each document is then evaluated based on the
downstream task ground truth labels. In this manner, the downstream performance
for each document serves as its relevance label. We employ various downstream
task metrics to obtain document-level annotations and aggregate them using
set-based or ranking metrics. Extensive experiments on a wide range of datasets
demonstrate that eRAG achieves a higher correlation with downstream RAG
performance compared to baseline methods, with improvements in Kendall's $\tau$
correlation ranging from 0.168 to 0.494. Additionally, eRAG offers significant
computational advantages, improving runtime and consuming up to 50 times less
GPU memory than end-to-end evaluation.",2024-04-21,"Alireza Salemi, Hamed Zamani",http://arxiv.org/pdf/2404.13781v1,cs.CL
Automated Text Mining of Experimental Methodologies from Biomedical Literature,"Biomedical literature is a rapidly expanding field of science and technology.
Classification of biomedical texts is an essential part of biomedicine
research, especially in the field of biology. This work proposes the fine-tuned
DistilBERT, a methodology-specific, pre-trained generative classification
language model for mining biomedicine texts. The model has proven its
effectiveness in linguistic understanding capabilities and has reduced the size
of BERT models by 40\% but by 60\% faster. The main objective of this project
is to improve the model and assess the performance of the model compared to the
non-fine-tuned model. We used DistilBert as a support model and pre-trained on
a corpus of 32,000 abstracts and complete text articles; our results were
impressive and surpassed those of traditional literature classification methods
by using RNN or LSTM. Our aim is to integrate this highly specialised and
specific model into different research industries.",2024-04-21,Ziqing Guo,http://arxiv.org/pdf/2404.13779v1,cs.CL
Using Adaptive Empathetic Responses for Teaching English,"Existing English-teaching chatbots rarely incorporate empathy explicitly in
their feedback, but empathetic feedback could help keep students engaged and
reduce learner anxiety. Toward this end, we propose the task of negative
emotion detection via audio, for recognizing empathetic feedback opportunities
in language learning. We then build the first spoken English-teaching chatbot
with adaptive, empathetic feedback. This feedback is synthesized through
automatic prompt optimization of ChatGPT and is evaluated with English
learners. We demonstrate the effectiveness of our system through a preliminary
user study.",2024-04-21,"Li Siyan, Teresa Shao, Zhou Yu, Julia Hirschberg",http://arxiv.org/pdf/2404.13764v1,cs.CL
How to Encode Domain Information in Relation Classification,"Current language models require a lot of training data to obtain high
performance. For Relation Classification (RC), many datasets are
domain-specific, so combining datasets to obtain better performance is
non-trivial. We explore a multi-domain training setup for RC, and attempt to
improve performance by encoding domain information. Our proposed models improve
> 2 Macro-F1 against the baseline setup, and our analysis reveals that not all
the labels benefit the same: The classes which occupy a similar space across
domains (i.e., their interpretation is close across them, for example
""physical"") benefit the least, while domain-dependent relations (e.g.,
""part-of'') improve the most when encoding domain information.",2024-04-21,"Elisa Bassignana, Viggo Unmack Gascou, Frida Nøhr Laustsen, Gustav Kristensen, Marie Haahr Petersen, Rob van der Goot, Barbara Plank",http://arxiv.org/pdf/2404.13760v1,cs.CL
Adversarial Representation Engineering: A General Model Editing Framework for Large Language Models,"Since the rapid development of Large Language Models (LLMs) has achieved
remarkable success, understanding and rectifying their internal complex
mechanisms has become an urgent issue. Recent research has attempted to
interpret their behaviors through the lens of inner representation. However,
developing practical and efficient methods for applying these representations
for general and flexible model editing remains challenging. In this work, we
explore how to leverage insights from representation engineering to guide the
editing of LLMs by deploying a representation sensor as an editing oracle. We
first identify the importance of a robust and reliable sensor during editing,
then propose an Adversarial Representation Engineering (ARE) framework to
provide a unified and interpretable approach for conceptual model editing
without compromising baseline performance. Experiments on multiple tasks
demonstrate the effectiveness of ARE in various model editing scenarios. Our
code and data are available at
https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.",2024-04-21,"Yihao Zhang, Zeming Wei, Jun Sun, Meng Sun",http://arxiv.org/pdf/2404.13752v3,cs.CL
Embarrassingly Simple Unsupervised Aspect Based Sentiment Tuple Extraction,"Aspect Based Sentiment Analysis (ABSA) tasks involve the extraction of
fine-grained sentiment tuples from sentences, aiming to discern the author's
opinions. Conventional methodologies predominantly rely on supervised
approaches; however, the efficacy of such methods diminishes in low-resource
domains lacking labeled datasets since they often lack the ability to
generalize across domains. To address this challenge, we propose a simple and
novel unsupervised approach to extract opinion terms and the corresponding
sentiment polarity for aspect terms in a sentence. Our experimental
evaluations, conducted on four benchmark datasets, demonstrate compelling
performance to extract the aspect oriented opinion words as well as assigning
sentiment polarity. Additionally, unsupervised approaches for opinion word
mining have not been explored and our work establishes a benchmark for the
same.",2024-04-21,"Kevin Scaria, Abyn Scaria, Ben Scaria",http://arxiv.org/pdf/2404.13751v1,cs.CL
The Framework of a Design Process Language,"The thesis develops a view of design in a concept formation framework and
outlines a language to describe both the object of the design and the process
of designing. The unknown object at the outset of the design work may be seen
as an unknown concept that the designer is to define. Throughout the process,
she develops a description of this object by relating it to known concepts. The
search stops when the designer is satisfied that the design specification is
complete enough to satisfy the requirements from it once built. It is then a
collection of propositions that all contribute towards defining the design
object - a collection of sentences describing relationships between the object
and known concepts. Also, the design process itself may be described by
relating known concepts - by organizing known abilities into particular
patterns of activation, or mobilization. In view of the demands posed to a
language to use in this concept formation process, the framework of a Design
Process Language (DPL) is developed. The basis for the language are linguistic
categories that act as classes of relations used to combine concepts,
containing relations used for describing process and object within the same
general system, with some relations being process specific, others being object
specific, and with the bulk being used both for process and object description.
Another outcome is the distinction of modal relations, or relations describing
futurity, possibility, willingness, hypothetical events, and the like. The
design process almost always includes aspects such as these, and it is thus
necessary for a language facilitating design process description to support
such relationships to be constructed. The DPL is argued to be a foundation
whereupon to build a language that can be used for enabling computers to be
more useful - act more intelligently - in the design process.",2024-04-21,Arnulf Hagen,http://arxiv.org/pdf/2404.13721v1,cs.CL
Trojan Detection in Large Language Models: Insights from The Trojan Detection Challenge,"Large Language Models (LLMs) have demonstrated remarkable capabilities in
various domains, but their vulnerability to trojan or backdoor attacks poses
significant security risks. This paper explores the challenges and insights
gained from the Trojan Detection Competition 2023 (TDC2023), which focused on
identifying and evaluating trojan attacks on LLMs. We investigate the
difficulty of distinguishing between intended and unintended triggers, as well
as the feasibility of reverse engineering trojans in real-world scenarios. Our
comparative analysis of various trojan detection methods reveals that achieving
high Recall scores is significantly more challenging than obtaining high
Reverse-Engineering Attack Success Rate (REASR) scores. The top-performing
methods in the competition achieved Recall scores around 0.16, comparable to a
simple baseline of randomly sampling sentences from a distribution similar to
the given training prefixes. This finding raises questions about the
detectability and recoverability of trojans inserted into the model, given only
the harmful targets. Despite the inability to fully solve the problem, the
competition has led to interesting observations about the viability of trojan
detection and improved techniques for optimizing LLM input prompts. The
phenomenon of unintended triggers and the difficulty in distinguishing them
from intended triggers highlights the need for further research into the
robustness and interpretability of LLMs. The TDC2023 has provided valuable
insights into the challenges and opportunities associated with trojan detection
in LLMs, laying the groundwork for future research in this area to ensure their
safety and reliability in real-world applications.",2024-04-21,"Narek Maloyan, Ekansh Verma, Bulat Nutfullin, Bislan Ashinov",http://arxiv.org/pdf/2404.13660v1,cs.CL
PEACH: Pretrained-embedding Explanation Across Contextual and Hierarchical Structure,"In this work, we propose a novel tree-based explanation technique, PEACH
(Pretrained-embedding Explanation Across Contextual and Hierarchical
Structure), that can explain how text-based documents are classified by using
any pretrained contextual embeddings in a tree-based human-interpretable
manner. Note that PEACH can adopt any contextual embeddings of the PLMs as a
training input for the decision tree. Using the proposed PEACH, we perform a
comprehensive analysis of several contextual embeddings on nine different NLP
text classification benchmarks. This analysis demonstrates the flexibility of
the model by applying several PLM contextual embeddings, its attribute
selections, scaling, and clustering methods. Furthermore, we show the utility
of explanations by visualising the feature selection and important trend of
text classification via human-interpretable word-cloud-based trees, which
clearly identify model mistakes and assist in dataset debugging. Besides
interpretability, PEACH outperforms or is similar to those from pretrained
models.",2024-04-21,"Feiqi Cao, Caren Han, Hyunsuk Chung",http://arxiv.org/pdf/2404.13645v1,cs.CL
Incorporating Different Verbal Cues to Improve Text-Based Computer-Delivered Health Messaging,"The ubiquity of smartphones has led to an increase in on demand healthcare
being supplied. For example, people can share their illness-related experiences
with others similar to themselves, and healthcare experts can offer advice for
better treatment and care for remediable, terminal and mental illnesses. As
well as this human-to-human communication, there has been an increased use of
human-to-computer digital health messaging, such as chatbots. These can prove
advantageous as they offer synchronous and anonymous feedback without the need
for a human conversational partner. However, there are many subtleties involved
in human conversation that a computer agent may not properly exhibit. For
example, there are various conversational styles, etiquettes, politeness
strategies or empathic responses that need to be chosen appropriately for the
conversation. Encouragingly, computers are social actors (CASA) posits that
people apply the same social norms to computers as they would do to people. On
from this, previous studies have focused on applying conversational strategies
to computer agents to make them embody more favourable human characteristics.
However, if a computer agent fails in this regard it can lead to negative
reactions from users. Therefore, in this dissertation we describe a series of
studies we carried out to lead to more effective human-to-computer digital
health messaging.
  In our first study, we use the crowd [...]
  Our second study investigates the effect of a health chatbot's conversational
style [...]
  In our final study, we investigate the format used by a chatbot when [...]
  In summary, we have researched how to create more effective digital health
interventions starting from generating health messages, to choosing an
appropriate formality of messaging, and finally to formatting messages which
reference a user's previous utterances.",2024-04-21,Samuel Rhys Cox,http://arxiv.org/pdf/2404.13633v1,cs.CL
Utilizing Deep Learning to Optimize Software Development Processes,"This study explores the application of deep learning technologies in software
development processes, particularly in automating code reviews, error
prediction, and test generation to enhance code quality and development
efficiency. Through a series of empirical studies, experimental groups using
deep learning tools and control groups using traditional methods were compared
in terms of code error rates and project completion times. The results
demonstrated significant improvements in the experimental group, validating the
effectiveness of deep learning technologies. The research also discusses
potential optimization points, methodologies, and technical challenges of deep
learning in software development, as well as how to integrate these
technologies into existing software development workflows.",2024-04-21,"Keqin Li, Armando Zhu, Peng Zhao, Jintong Song, Jiabei Liu",http://arxiv.org/pdf/2404.13630v2,cs.CL
Mixture of LoRA Experts,"LoRA has gained widespread acceptance in the fine-tuning of large pre-trained
models to cater to a diverse array of downstream tasks, showcasing notable
effectiveness and efficiency, thereby solidifying its position as one of the
most prevalent fine-tuning techniques. Due to the modular nature of LoRA's
plug-and-play plugins, researchers have delved into the amalgamation of
multiple LoRAs to empower models to excel across various downstream tasks.
Nonetheless, extant approaches for LoRA fusion grapple with inherent
challenges. Direct arithmetic merging may result in the loss of the original
pre-trained model's generative capabilities or the distinct identity of LoRAs,
thereby yielding suboptimal outcomes. On the other hand, Reference tuning-based
fusion exhibits limitations concerning the requisite flexibility for the
effective combination of multiple LoRAs. In response to these challenges, this
paper introduces the Mixture of LoRA Experts (MoLE) approach, which harnesses
hierarchical control and unfettered branch selection. The MoLE approach not
only achieves superior LoRA fusion performance in comparison to direct
arithmetic merging but also retains the crucial flexibility for combining LoRAs
effectively. Extensive experimental evaluations conducted in both the Natural
Language Processing (NLP) and Vision & Language (V&L) domains substantiate the
efficacy of MoLE.",2024-04-21,"Xun Wu, Shaohan Huang, Furu Wei",http://arxiv.org/pdf/2404.13628v1,cs.CL
NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding,"Large Language Models (LLMs) have sparked substantial interest and debate
concerning their potential emergence of Theory of Mind (ToM) ability. Theory of
mind evaluations currently focuses on testing models using machine-generated
data or game settings prone to shortcuts and spurious correlations, which lacks
evaluation of machine ToM ability in real-world human interaction scenarios.
This poses a pressing demand to develop new real-world scenario benchmarks. We
introduce NegotiationToM, a new benchmark designed to stress-test machine ToM
in real-world negotiation surrounding covered multi-dimensional mental states
(i.e., desires, beliefs, and intentions). Our benchmark builds upon the
Belief-Desire-Intention (BDI) agent modeling theory and conducts the necessary
empirical experiments to evaluate large language models. Our findings
demonstrate that NegotiationToM is challenging for state-of-the-art LLMs, as
they consistently perform significantly worse than humans, even when employing
the chain-of-thought (CoT) method.",2024-04-21,"Chunkit Chan, Cheng Jiayang, Yauwai Yim, Zheye Deng, Wei Fan, Haoran Li, Xin Liu, Hongming Zhang, Weiqi Wang, Yangqiu Song",http://arxiv.org/pdf/2404.13627v3,cs.CL
The Branch Not Taken: Predicting Branching in Online Conversations,"Multi-participant discussions tend to unfold in a tree structure rather than
a chain structure. Branching may occur for multiple reasons -- from the
asynchronous nature of online platforms to a conscious decision by an
interlocutor to disengage with part of the conversation. Predicting branching
and understanding the reasons for creating new branches is important for many
downstream tasks such as summarization and thread disentanglement and may help
develop online spaces that encourage users to engage in online discussions in
more meaningful ways. In this work, we define the novel task of branch
prediction and propose GLOBS (Global Branching Score) -- a deep neural network
model for predicting branching. GLOBS is evaluated on three large discussion
forums from Reddit, achieving significant improvements over an array of
competitive baselines and demonstrating better transferability. We affirm that
structural, temporal, and linguistic features contribute to GLOBS success and
find that branching is associated with a greater number of conversation
participants and tends to occur in earlier levels of the conversation tree. We
publicly release GLOBS and our implementation of all baseline models to allow
reproducibility and promote further research on this important task.",2024-04-21,"Shai Meital, Lior Rokach, Roman Vainshtein, Nir Grinberg",http://arxiv.org/pdf/2404.13613v1,cs.CL
Video sentence grounding with temporally global textual knowledge,"Temporal sentence grounding involves the retrieval of a video moment with a
natural language query. Many existing works directly incorporate the given
video and temporally localized query for temporal grounding, overlooking the
inherent domain gap between different modalities. In this paper, we utilize
pseudo-query features containing extensive temporally global textual knowledge
sourced from the same video-query pair, to enhance the bridging of domain gaps
and attain a heightened level of similarity between multi-modal features.
Specifically, we propose a Pseudo-query Intermediary Network (PIN) to achieve
an improved alignment of visual and comprehensive pseudo-query features within
the feature space through contrastive learning. Subsequently, we utilize
learnable prompts to encapsulate the knowledge of pseudo-queries, propagating
them into the textual encoder and multi-modal fusion module, further enhancing
the feature alignment between visual and language for better temporal
grounding. Extensive experiments conducted on the Charades-STA and
ActivityNet-Captions datasets demonstrate the effectiveness of our method.",2024-04-21,"Cai Chen, Runzhong Zhang, Jianjun Gao, Kejun Wu, Kim-Hui Yap, Yi Wang",http://arxiv.org/pdf/2404.13611v2,cs.CL
"""A good pun is its own reword"": Can Large Language Models Understand Puns?","Puns play a vital role in academic research due to their distinct structure
and clear definition, which aid in the comprehensive analysis of linguistic
humor. However, the understanding of puns in large language models (LLMs) has
not been thoroughly examined, limiting their use in creative writing and humor
creation. In this paper, we leverage three popular tasks, i.e., pun
recognition, explanation and generation to systematically evaluate the
capabilities of LLMs in pun understanding. In addition to adopting the
automated evaluation metrics from prior research, we introduce new evaluation
methods and metrics that are better suited to the in-context learning paradigm
of LLMs. These new metrics offer a more rigorous assessment of an LLM's ability
to understand puns and align more closely with human cognition than previous
metrics. Our findings reveal the ""lazy pun generation"" pattern and identify the
primary challenges LLMs encounter in understanding puns.",2024-04-21,"Zhijun Xu, Siyu Yuan, Lingjie Chen, Deqing Yang",http://arxiv.org/pdf/2404.13599v2,cs.CL
Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses,"Addressing the global challenge of breast cancer, this research explores the
fusion of generative AI, focusing on ChatGPT 3.5 turbo model, and the
intricacies of breast cancer risk assessment. The research aims to evaluate
ChatGPT's reasoning capabilities, emphasizing its potential to process rules
and provide explanations for screening recommendations. The study seeks to
bridge the technology gap between intelligent machines and clinicians by
demonstrating ChatGPT's unique proficiency in natural language reasoning. The
methodology employs a supervised prompt-engineering approach to enforce
detailed explanations for ChatGPT's recommendations. Synthetic use cases,
generated algorithmically, serve as the testing ground for the encoded rules,
evaluating the model's processing prowess. Findings highlight ChatGPT's
promising capacity in processing rules comparable to Expert System Shells, with
a focus on natural language reasoning. The research introduces the concept of
reinforcement explainability, showcasing its potential in elucidating outcomes
and facilitating user-friendly interfaces for breast cancer risk assessment.",2024-04-21,"Yousef Khan, Ahmed Abdeen Hamed",http://arxiv.org/pdf/2404.14454v2,cs.CL
Socratic Planner: Self-QA-Based Zero-Shot Planning for Embodied Instruction Following,"Embodied Instruction Following (EIF) is the task of executing natural
language instructions by navigating and interacting with objects in interactive
environments. A key challenge in EIF is compositional task planning, typically
addressed through supervised learning or few-shot in-context learning with
labeled data. To this end, we introduce the Socratic Planner, a self-QA-based
zero-shot planning method that infers an appropriate plan without any further
training. The Socratic Planner first facilitates self-questioning and answering
by the Large Language Model (LLM), which in turn helps generate a sequence of
subgoals. While executing the subgoals, an embodied agent may encounter
unexpected situations, such as unforeseen obstacles. The Socratic Planner then
adjusts plans based on dense visual feedback through a visually-grounded
re-planning mechanism. Experiments demonstrate the effectiveness of the
Socratic Planner, outperforming current state-of-the-art planning models on the
ALFRED benchmark across all metrics, particularly excelling in long-horizon
tasks that demand complex inference. We further demonstrate its real-world
applicability through deployment on a physical robot for long-horizon tasks.",2024-04-21,"Suyeon Shin, Sujin jeon, Junghyun Kim, Gi-Cheon Kang, Byoung-Tak Zhang",http://arxiv.org/pdf/2404.15190v2,cs.CL
Exploring Diverse Methods in Visual Question Answering,"This study explores innovative methods for improving Visual Question
Answering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and
attention mechanisms. Leveraging a balanced VQA dataset, we investigate three
distinct strategies. Firstly, GAN-based approaches aim to generate answer
embeddings conditioned on image and question inputs, showing potential but
struggling with more complex tasks. Secondly, autoencoder-based techniques
focus on learning optimal embeddings for questions and images, achieving
comparable results with GAN due to better ability on complex questions. Lastly,
attention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),
address language priors and attention modeling, albeit with a
complexity-performance trade-off. This study underscores the challenges and
opportunities in VQA and suggests avenues for future research, including
alternative GAN formulations and attentional mechanisms.",2024-04-21,"Panfeng Li, Qikai Yang, Xieming Geng, Wenjing Zhou, Zhicheng Ding, Yi Nian",http://arxiv.org/pdf/2404.13565v3,cs.CL
ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval,"Conversational search requires accurate interpretation of user intent from
complex multi-turn contexts. This paper presents ChatRetriever, which inherits
the strong generalization capability of large language models to robustly
represent complex conversational sessions for dense retrieval. To achieve this,
we propose a simple and effective dual-learning approach that adapts LLM for
retrieval via contrastive learning while enhancing the complex session
understanding through masked instruction tuning on high-quality conversational
instruction tuning data. Extensive experiments on five conversational search
benchmarks demonstrate that ChatRetriever substantially outperforms existing
conversational dense retrievers, achieving state-of-the-art performance on par
with LLM-based rewriting approaches. Furthermore, ChatRetriever exhibits
superior robustness in handling diverse conversational contexts. Our work
highlights the potential of adapting LLMs for retrieval with complex inputs
like conversational search sessions and proposes an effective approach to
advance this research direction.",2024-04-21,"Kelong Mao, Chenlong Deng, Haonan Chen, Fengran Mo, Zheng Liu, Tetsuya Sakai, Zhicheng Dou",http://arxiv.org/pdf/2404.13556v1,cs.CL
E-QGen: Educational Lecture Abstract-based Question Generation System,"To optimize the preparation process for educators in academic lectures and
associated question-and-answer sessions, this paper presents E-QGen, a lecture
abstract-based question generation system. Given a lecture abstract, E-QGen
generates potential student inquiries. The questions suggested by our system
are expected to not only facilitate teachers in preparing answers in advance
but also enable them to supply additional resources when necessary.",2024-04-21,"Mao-Siang Chen, An-Zi Yen",http://arxiv.org/pdf/2404.13547v1,cs.CL
Listen Then See: Video Alignment with Speaker Attention,"Video-based Question Answering (Video QA) is a challenging task and becomes
even more intricate when addressing Socially Intelligent Question Answering
(SIQA). SIQA requires context understanding, temporal reasoning, and the
integration of multimodal information, but in addition, it requires processing
nuanced human behavior. Furthermore, the complexities involved are exacerbated
by the dominance of the primary modality (text) over the others. Thus, there is
a need to help the task's secondary modalities to work in tandem with the
primary modality. In this work, we introduce a cross-modal alignment and
subsequent representation fusion approach that achieves state-of-the-art
results (82.06\% accuracy) on the Social IQ 2.0 dataset for SIQA. Our approach
exhibits an improved ability to leverage the video modality by using the audio
modality as a bridge with the language modality. This leads to enhanced
performance by reducing the prevalent issue of language overfitting and
resultant video modality bypassing encountered by current existing techniques.
Our code and models are publicly available at
https://github.com/sts-vlcc/sts-vlcc",2024-04-21,"Aviral Agrawal, Carlos Mateo Samudio Lezcano, Iqui Balam Heredia-Marin, Prabhdeep Singh Sethi",http://arxiv.org/pdf/2404.13530v1,cs.CL
EPI-SQL: Enhancing Text-to-SQL Translation with Error-Prevention Instructions,"The conversion of natural language queries into SQL queries, known as
Text-to-SQL, is a critical yet challenging task. This paper introduces EPI-SQL,
a novel methodological framework leveraging Large Language Models (LLMs) to
enhance the performance of Text-to-SQL tasks. EPI-SQL operates through a
four-step process. Initially, the method involves gathering instances from the
Spider dataset on which LLMs are prone to failure. These instances are then
utilized to generate general error-prevention instructions (EPIs).
Subsequently, LLMs craft contextualized EPIs tailored to the specific context
of the current task. Finally, these context-specific EPIs are incorporated into
the prompt used for SQL generation. EPI-SQL is distinguished in that it
provides task-specific guidance, enabling the model to circumvent potential
errors for the task at hand. Notably, the methodology rivals the performance of
advanced few-shot methods despite being a zero-shot approach. An empirical
assessment using the Spider benchmark reveals that EPI-SQL achieves an
execution accuracy of 85.1\%, underscoring its effectiveness in generating
accurate SQL queries through LLMs. The findings indicate a promising direction
for future research, i.e. enhancing instructions with task-specific and
contextualized rules, for boosting LLMs' performance in NLP tasks.",2024-04-21,"Xiping Liu, Zhao Tan",http://arxiv.org/pdf/2404.14453v1,cs.CL
Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications,"The rise of deep learning has marked significant progress in fields such as
computer vision, natural language processing, and medical imaging, primarily
through the adaptation of pre-trained models for specific tasks. Traditional
fine-tuning methods, involving adjustments to all parameters, face challenges
due to high computational and memory demands. This has led to the development
of Parameter Efficient Fine-Tuning (PEFT) techniques, which selectively update
parameters to balance computational efficiency with performance. This review
examines PEFT approaches, offering a detailed comparison of various strategies
highlighting applications across different domains, including text generation,
medical imaging, protein modeling, and speech synthesis. By assessing the
effectiveness of PEFT methods in reducing computational load, speeding up
training, and lowering memory usage, this paper contributes to making deep
learning more accessible and adaptable, facilitating its wider application and
encouraging innovation in model optimization. Ultimately, the paper aims to
contribute towards insights into PEFT's evolving landscape, guiding researchers
and practitioners in overcoming the limitations of conventional fine-tuning
approaches.",2024-04-21,"Charith Chandra Sai Balne, Sreyoshi Bhaduri, Tamoghna Roy, Vinija Jain, Aman Chadha",http://arxiv.org/pdf/2404.13506v2,cs.CL
IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models,"Machine learning models have made incredible progress, but they still
struggle when applied to examples from unseen domains. This study focuses on a
specific problem of domain generalization, where a model is trained on one
source domain and tested on multiple target domains that are unseen during
training. We propose IMO: Invariant features Masks for Out-of-Distribution text
classification, to achieve OOD generalization by learning invariant features.
During training, IMO would learn sparse mask layers to remove irrelevant
features for prediction, where the remaining features keep invariant.
Additionally, IMO has an attention module at the token level to focus on tokens
that are useful for prediction. Our comprehensive experiments show that IMO
substantially outperforms strong baselines in terms of various evaluation
metrics and settings.",2024-04-21,"Tao Feng, Lizhen Qu, Zhuang Li, Haolan Zhan, Yuncheng Hua, Gholamreza Haffari",http://arxiv.org/pdf/2404.13504v1,cs.CL
"Do ""English"" Named Entity Recognizers Work Well on Global Englishes?","The vast majority of the popular English named entity recognition (NER)
datasets contain American or British English data, despite the existence of
many global varieties of English. As such, it is unclear whether they
generalize for analyzing use of English globally. To test this, we build a
newswire dataset, the Worldwide English NER Dataset, to analyze NER model
performance on low-resource English variants from around the world. We test
widely used NER toolkits and transformer models, including models using the
pre-trained contextual models RoBERTa and ELECTRA, on three datasets: a
commonly used British English newswire dataset, CoNLL 2003, a more American
focused dataset OntoNotes, and our global dataset. All models trained on the
CoNLL or OntoNotes datasets experienced significant performance drops-over 10
F1 in some cases-when tested on the Worldwide English dataset. Upon examination
of region-specific errors, we observe the greatest performance drops for
Oceania and Africa, while Asia and the Middle East had comparatively strong
performance. Lastly, we find that a combined model trained on the Worldwide
dataset and either CoNLL or OntoNotes lost only 1-2 F1 on both test sets.",2024-04-20,"Alexander Shan, John Bauer, Riley Carlson, Christopher Manning",http://arxiv.org/pdf/2404.13465v1,cs.CL
Fine-Grained Named Entities for Corona News,"Information resources such as newspapers have produced unstructured text data
in various languages related to the corona outbreak since December 2019.
Analyzing these unstructured texts is time-consuming without representing them
in a structured format; therefore, representing them in a structured format is
crucial. An information extraction pipeline with essential tasks -- named
entity tagging and relation extraction -- to accomplish this goal might be
applied to these texts. This study proposes a data annotation pipeline to
generate training data from corona news articles, including generic and
domain-specific entities. Named entity recognition models are trained on this
annotated corpus and then evaluated on test sentences manually annotated by
domain experts evaluating the performance of a trained model. The code base and
demonstration are available at https://github.com/sefeoglu/coronanews-ner.git.",2024-04-20,"Sefika Efeoglu, Adrian Paschke",http://arxiv.org/pdf/2404.13439v1,cs.CL
Predicting Question Quality on StackOverflow with Neural Networks,"The wealth of information available through the Internet and social media is
unprecedented. Within computing fields, websites such as Stack Overflow are
considered important sources for users seeking solutions to their computing and
programming issues. However, like other social media platforms, Stack Overflow
contains a mixture of relevant and irrelevant information. In this paper, we
evaluated neural network models to predict the quality of questions on Stack
Overflow, as an example of Question Answering (QA) communities. Our results
demonstrate the effectiveness of neural network models compared to baseline
machine learning models, achieving an accuracy of 80%. Furthermore, our
findings indicate that the number of layers in the neural network model can
significantly impact its performance.",2024-04-20,"Mohammad Al-Ramahi, Izzat Alsmadi, Abdullah Wahbeh",http://arxiv.org/pdf/2404.14449v1,cs.CL
Intrusion Detection at Scale with the Assistance of a Command-line Language Model,"Intrusion detection is a long standing and crucial problem in security. A
system capable of detecting intrusions automatically is on great demand in
enterprise security solutions. Existing solutions rely heavily on hand-crafted
rules designed by security operators, which suffer from high false negative
rates and poor generalization ability to new, zero-day attacks at scale. AI and
machine learning offer promising solutions to address the issues, by inspecting
abnormal user behaviors intelligently and automatically from data. However,
existing learning-based intrusion detection systems in the literature are
mostly designed for small data, and they lack the ability to leverage the power
of big data in cloud environments. In this paper, we target at this problem and
introduce an intrusion detection system which incorporates large-scale
pre-training, so as to train a large language model based on tens of millions
of command lines for AI-based intrusion detection. Experiments performed on 30
million training samples and 10 million test samples verify the effectiveness
of our solution.",2024-04-20,"Jiongliang Lin, Yiwen Guo, Hao Chen",http://arxiv.org/pdf/2404.13402v1,cs.CL
Retrieval-Augmented Generation-based Relation Extraction,"Information Extraction (IE) is a transformative process that converts
unstructured text data into a structured format by employing entity and
relation extraction (RE) methodologies. The identification of the relation
between a pair of entities plays a crucial role within this framework. Despite
the existence of various techniques for relation extraction, their efficacy
heavily relies on access to labeled data and substantial computational
resources. In addressing these challenges, Large Language Models (LLMs) emerge
as promising solutions; however, they might return hallucinating responses due
to their own training data. To overcome these limitations, Retrieved-Augmented
Generation-based Relation Extraction (RAG4RE) in this work is proposed,
offering a pathway to enhance the performance of relation extraction tasks.
  This work evaluated the effectiveness of our RAG4RE approach utilizing
different LLMs. Through the utilization of established benchmarks, such as
TACRED, TACREV, Re-TACRED, and SemEval RE datasets, our aim is to
comprehensively evaluate the efficacy of our RAG4RE approach. In particularly,
we leverage prominent LLMs including Flan T5, Llama2, and Mistral in our
investigation. The results of our study demonstrate that our RAG4RE approach
surpasses performance of traditional RE approaches based solely on LLMs,
particularly evident in the TACRED dataset and its variations. Furthermore, our
approach exhibits remarkable performance compared to previous RE methodologies
across both TACRED and TACREV datasets, underscoring its efficacy and potential
for advancing RE tasks in natural language processing.",2024-04-20,"Sefika Efeoglu, Adrian Paschke",http://arxiv.org/pdf/2404.13397v1,cs.CL
Explanation based Bias Decoupling Regularization for Natural Language Inference,"The robustness of Transformer-based Natural Language Inference encoders is
frequently compromised as they tend to rely more on dataset biases than on the
intended task-relevant features. Recent studies have attempted to mitigate this
by reducing the weight of biased samples during the training process. However,
these debiasing methods primarily focus on identifying which samples are biased
without explicitly determining the biased components within each case. This
limitation restricts those methods' capability in out-of-distribution
inference. To address this issue, we aim to train models to adopt the logic
humans use in explaining causality. We propose a simple, comprehensive, and
interpretable method: Explanation based Bias Decoupling Regularization
(EBD-Reg). EBD-Reg employs human explanations as criteria, guiding the encoder
to establish a tripartite parallel supervision of Distinguishing, Decoupling
and Aligning. This method enables encoders to identify and focus on keywords
that represent the task-relevant features during inference, while discarding
the residual elements acting as biases. Empirical evidence underscores that
EBD-Reg effectively guides various Transformer-based encoders to decouple
biases through a human-centric lens, significantly surpassing other methods in
terms of out-of-distribution inference capabilities.",2024-04-20,"Jianxiang Zang, Hui Liu",http://arxiv.org/pdf/2404.13390v1,cs.CL
Movie101v2: Improved Movie Narration Benchmark,"Automatic movie narration aims to generate video-aligned plot descriptions to
assist visually impaired audiences. Unlike standard video captioning, it
involves not only describing key visual details but also inferring plots that
unfold across multiple movie shots, presenting distinct and complex challenges.
To advance this field, we introduce Movie101v2, a large-scale, bilingual
dataset with enhanced data quality specifically designed for movie narration.
Revisiting the task, we propose breaking down the ultimate goal of automatic
movie narration into three progressive stages, offering a clear roadmap with
corresponding evaluation metrics. Based on our new benchmark, we baseline a
range of large vision-language models, including GPT-4V, and conduct an
in-depth analysis of the challenges in narration generation. Our findings
highlight that achieving applicable movie narration generation is a fascinating
goal that requires significant research.",2024-04-20,"Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin",http://arxiv.org/pdf/2404.13370v2,cs.CL
MahaSQuAD: Bridging Linguistic Divides in Marathi Question-Answering,"Question-answering systems have revolutionized information retrieval, but
linguistic and cultural boundaries limit their widespread accessibility. This
research endeavors to bridge the gap of the absence of efficient QnA datasets
in low-resource languages by translating the English Question Answering Dataset
(SQuAD) using a robust data curation approach. We introduce MahaSQuAD, the
first-ever full SQuAD dataset for the Indic language Marathi, consisting of
118,516 training, 11,873 validation, and 11,803 test samples. We also present a
gold test set of manually verified 500 examples. Challenges in maintaining
context and handling linguistic nuances are addressed, ensuring accurate
translations. Moreover, as a QnA dataset cannot be simply converted into any
low-resource language using translation, we need a robust method to map the
answer translation to its span in the translated passage. Hence, to address
this challenge, we also present a generic approach for translating SQuAD into
any low-resource language. Thus, we offer a scalable approach to bridge
linguistic and cultural gaps present in low-resource languages, in the realm of
question-answering systems. The datasets and models are shared publicly at
https://github.com/l3cube-pune/MarathiNLP .",2024-04-20,"Ruturaj Ghatage, Aditya Kulkarni, Rajlaxmi Patil, Sharvi Endait, Raviraj Joshi",http://arxiv.org/pdf/2404.13364v1,cs.CL
Semantically Corrected Amharic Automatic Speech Recognition,"Automatic Speech Recognition (ASR) can play a crucial role in enhancing the
accessibility of spoken languages worldwide. In this paper, we build a set of
ASR tools for Amharic, a language spoken by more than 50 million people
primarily in eastern Africa. Amharic is written in the Ge'ez script, a sequence
of graphemes with spacings denoting word boundaries. This makes computational
processing of Amharic challenging since the location of spacings can
significantly impact the meaning of formed sentences. We find that existing
benchmarks for Amharic ASR do not account for these spacings and only measure
individual grapheme error rates, leading to significantly inflated measurements
of in-the-wild performance. In this paper, we first release corrected
transcriptions of existing Amharic ASR test datasets, enabling the community to
accurately evaluate progress. Furthermore, we introduce a post-processing
approach using a transformer encoder-decoder architecture to organize raw ASR
outputs into a grammatically complete and semantically meaningful Amharic
sentence. Through experiments on the corrected test dataset, our model enhances
the semantic correctness of Amharic speech recognition systems, achieving a
Character Error Rate (CER) of 5.5\% and a Word Error Rate (WER) of 23.3\%.",2024-04-20,"Samuael Adnew, Paul Pu Liang",http://arxiv.org/pdf/2404.13362v1,cs.CL
Swa Bhasha: Message-Based Singlish to Sinhala Transliteration,"Machine Transliteration provides the ability to transliterate a basic
language into different languages in a computational way. Transliteration is an
important technical process that has caught the attention most recently. The
Sinhala transliteration has many constraints because of the insufficiency of
resources in the Sinhala language. Due to these limitations, Sinhala
Transliteration is highly complex and time-consuming. Therefore, the majority
of the Sri Lankans uses non-formal texting language named 'Singlish' to make
that process simple. This study has focused on the transliteration of the
Singlish language at the word level by reducing the complication in the
transliteration. A new approach of coding system has invented with the
rule-based approach that can map the matching Sinhala words even without the
vowels. Various typing patterns were collected by different communities for
this. The collected data have analyzed with every Sinhala character and unique
Singlish patterns related to them were generated. The system has introduced a
newly initiated numeric coding system to use with the Singlish letters by
matching with the recognized typing patterns. For the mapping process, fuzzy
logic-based implementation has used. A codified dictionary has also implemented
including unique numeric values. In this system, Each Romanized English letter
was assigned with a unique numeric code that can construct a unique pattern for
each word. The system can identify the most relevant Sinhala word that matches
with the pattern of the Singlish word or it gives the most related word
suggestions. For example, the word 'kiyanna,kianna, kynna, kynn, kiynna' have
mapped with the accurate Sinhala word ""kiyanna"". These results revealed that
the 'Swa Bhasha' transliteration system has the ability to enhance the Sinhala
users' experience while conducting the texting in Singlish to Sinhala.",2024-04-20,"Maneesha U. Athukorala, Deshan K. Sumanathilaka",http://arxiv.org/pdf/2404.13350v1,cs.CL
UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions,"This work explores a novel data augmentation method based on Large Language
Models (LLMs) for predicting item difficulty and response time of retired USMLE
Multiple-Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is
based on augmenting the dataset with answers from zero-shot LLMs (Falcon,
Meditron, Mistral) and employing transformer-based models based on six
alternative feature combinations. The results suggest that predicting the
difficulty of questions is more challenging. Notably, our top performing
methods consistently include the question text, and benefit from the
variability of LLM answers, highlighting the potential of LLMs for improving
automated assessment in medical licensing exams. We make our code available
https://github.com/ana-rogoz/BEA-2024.",2024-04-20,"Ana-Cristina Rogoz, Radu Tudor Ionescu",http://arxiv.org/pdf/2404.13343v1,cs.CL
A Multi-Faceted Evaluation Framework for Assessing Synthetic Data Generated by Large Language Models,"The rapid advancements in generative AI and large language models (LLMs) have
opened up new avenues for producing synthetic data, particularly in the realm
of structured tabular formats, such as product reviews. Despite the potential
benefits, concerns regarding privacy leakage have surfaced, especially when
personal information is utilized in the training datasets. In addition, there
is an absence of a comprehensive evaluation framework capable of quantitatively
measuring the quality of the generated synthetic data and their utility for
downstream tasks. In response to this gap, we introduce SynEval, an open-source
evaluation framework designed to assess the fidelity, utility, and privacy
preservation of synthetically generated tabular data via a suite of diverse
evaluation metrics. We validate the efficacy of our proposed framework -
SynEval - by applying it to synthetic product review data generated by three
state-of-the-art LLMs: ChatGPT, Claude, and Llama. Our experimental findings
illuminate the trade-offs between various evaluation metrics in the context of
synthetic data generation. Furthermore, SynEval stands as a critical instrument
for researchers and practitioners engaged with synthetic tabular data,,
empowering them to judiciously determine the suitability of the generated data
for their specific applications, with an emphasis on upholding user privacy.",2024-04-20,"Yefeng Yuan, Yuhong Liu, Liang Cheng",http://arxiv.org/pdf/2404.14445v1,cs.CL
Beyond Accuracy: Investigating Error Types in GPT-4 Responses to USMLE Questions,"GPT-4 demonstrates high accuracy in medical QA tasks, leading with an
accuracy of 86.70%, followed by Med-PaLM 2 at 86.50%. However, around 14% of
errors remain. Additionally, current works use GPT-4 to only predict the
correct option without providing any explanation and thus do not provide any
insight into the thinking process and reasoning used by GPT-4 or other LLMs.
Therefore, we introduce a new domain-specific error taxonomy derived from
collaboration with medical students. Our GPT-4 USMLE Error (G4UE) dataset
comprises 4153 GPT-4 correct responses and 919 incorrect responses to the
United States Medical Licensing Examination (USMLE) respectively. These
responses are quite long (258 words on average), containing detailed
explanations from GPT-4 justifying the selected option. We then launch a
large-scale annotation study using the Potato annotation platform and recruit
44 medical experts through Prolific, a well-known crowdsourcing platform. We
annotated 300 out of these 919 incorrect data points at a granular level for
different classes and created a multi-label span to identify the reasons behind
the error. In our annotated dataset, a substantial portion of GPT-4's incorrect
responses is categorized as a ""Reasonable response by GPT-4,"" by annotators.
This sheds light on the challenge of discerning explanations that may lead to
incorrect options, even among trained medical professionals. We also provide
medical concepts and medical semantic predications extracted using the SemRep
tool for every data point. We believe that it will aid in evaluating the
ability of LLMs to answer complex medical questions. We make the resources
available at https://github.com/roysoumya/usmle-gpt4-error-taxonomy .",2024-04-20,"Soumyadeep Roy, Aparup Khatua, Fatemeh Ghoochani, Uwe Hadler, Wolfgang Nejdl, Niloy Ganguly",http://arxiv.org/pdf/2404.13307v1,cs.CL
Evaluating Subword Tokenization: Alien Subword Composition and OOV Generalization Challenge,"The popular subword tokenizers of current language models, such as Byte-Pair
Encoding (BPE), are known not to respect morpheme boundaries, which affects the
downstream performance of the models. While many improved tokenization
algorithms have been proposed, their evaluation and cross-comparison is still
an open problem. As a solution, we propose a combined intrinsic-extrinsic
evaluation framework for subword tokenization. Intrinsic evaluation is based on
our new UniMorph Labeller tool that classifies subword tokenization as either
morphological or alien. Extrinsic evaluation, in turn, is performed via the
Out-of-Vocabulary Generalization Challenge 1.0 benchmark, which consists of
three newly specified downstream text classification tasks. Our empirical
findings show that the accuracy of UniMorph Labeller is 98%, and that, in all
language models studied (including ALBERT, BERT, RoBERTa, and DeBERTa), alien
tokenization leads to poorer generalizations compared to morphological
tokenization for semantic compositionality of word meanings.",2024-04-20,"Khuyagbaatar Batsuren, Ekaterina Vylomova, Verna Dankers, Tsetsuukhei Delgerbaatar, Omri Uzan, Yuval Pinter, Gábor Bella",http://arxiv.org/pdf/2404.13292v1,cs.CL
Double Mixture: Towards Continual Event Detection from Speech,"Speech event detection is crucial for multimedia retrieval, involving the
tagging of both semantic and acoustic events. Traditional ASR systems often
overlook the interplay between these events, focusing solely on content, even
though the interpretation of dialogue can vary with environmental context. This
paper tackles two primary challenges in speech event detection: the continual
integration of new events without forgetting previous ones, and the
disentanglement of semantic from acoustic events. We introduce a new task,
continual event detection from speech, for which we also provide two benchmark
datasets. To address the challenges of catastrophic forgetting and effective
disentanglement, we propose a novel method, 'Double Mixture.' This method
merges speech expertise with robust memory mechanisms to enhance adaptability
and prevent forgetting. Our comprehensive experiments show that this task
presents significant challenges that are not effectively addressed by current
state-of-the-art methods in either computer vision or natural language
processing. Our approach achieves the lowest rates of forgetting and the
highest levels of generalization, proving robust across various continual
learning sequences. Our code and data are available at
https://anonymous.4open.science/status/Continual-SpeechED-6461.",2024-04-20,"Jingqi Kang, Tongtong Wu, Jinming Zhao, Guitao Wang, Yinwei Wei, Hao Yang, Guilin Qi, Yuan-Fang Li, Gholamreza Haffari",http://arxiv.org/pdf/2404.13289v2,cs.CL
Evaluation of Machine Translation Based on Semantic Dependencies and Keywords,"In view of the fact that most of the existing machine translation evaluation
algorithms only consider the lexical and syntactic information, but ignore the
deep semantic information contained in the sentence, this paper proposes a
computational method for evaluating the semantic correctness of machine
translations based on reference translations and incorporating semantic
dependencies and sentence keyword information. Use the language technology
platform developed by the Social Computing and Information Retrieval Research
Center of Harbin Institute of Technology to conduct semantic dependency
analysis and keyword analysis on sentences, and obtain semantic dependency
graphs, keywords, and weight information corresponding to keywords. It includes
all word information with semantic dependencies in the sentence and keyword
information that affects semantic information. Construct semantic association
pairs including word and dependency multi-features. The key semantics of the
sentence cannot be highlighted in the semantic information extracted through
semantic dependence, resulting in vague semantics analysis. Therefore, the
sentence keyword information is also included in the scope of machine
translation semantic evaluation. To achieve a comprehensive and in-depth
evaluation of the semantic correctness of sentences, the experimental results
show that the accuracy of the evaluation algorithm has been improved compared
with similar methods, and it can more accurately measure the semantic
correctness of machine translation.",2024-04-20,"Kewei Yuan, Qiurong Zhao, Yang Xu, Xiao Zhang, Huansheng Ning",http://arxiv.org/pdf/2404.14443v1,cs.CL
ISQA: Informative Factuality Feedback for Scientific Summarization,"We propose Iterative Facuality Refining on Informative Scientific
Question-Answering (ISQA) feedback\footnote{Code is available at
\url{https://github.com/lizekai-richard/isqa}}, a method following human
learning theories that employs model-generated feedback consisting of both
positive and negative information. Through iterative refining of summaries, it
probes for the underlying rationale of statements to enhance the factuality of
scientific summarization. ISQA does this in a fine-grained manner by asking a
summarization agent to reinforce validated statements in positive feedback and
fix incorrect ones in negative feedback. Our findings demonstrate that the ISQA
feedback mechanism significantly improves the factuality of various open-source
LLMs on the summarization task, as evaluated across multiple scientific
datasets.",2024-04-20,"Zekai Li, Yanxia Qin, Qian Liu, Min-Yen Kan",http://arxiv.org/pdf/2404.13246v1,cs.CL
Personalized Wireless Federated Learning for Large Language Models,"Large Language Models (LLMs) have revolutionized natural language processing
tasks. However, their deployment in wireless networks still face challenges,
i.e., a lack of privacy and security protection mechanisms. Federated Learning
(FL) has emerged as a promising approach to address these challenges. Yet, it
suffers from issues including inefficient handling with big and heterogeneous
data, resource-intensive training, and high communication overhead. To tackle
these issues, we first compare different learning stages and their features of
LLMs in wireless networks. Next, we introduce two personalized wireless
federated fine-tuning methods with low communication overhead, i.e., (1)
Personalized Federated Instruction Tuning (PFIT), which employs reinforcement
learning to fine-tune local LLMs with diverse reward models to achieve
personalization; (2) Personalized Federated Task Tuning (PFTT), which can
leverage global adapters and local Low-Rank Adaptations (LoRA) to
collaboratively fine-tune local LLMs, where the local LoRAs can be applied to
achieve personalization without aggregation. Finally, we perform simulations to
demonstrate the effectiveness of the proposed two methods and comprehensively
discuss open issues.",2024-04-20,"Feibo Jiang, Li Dong, Siwei Tu, Yubo Peng, Kezhi Wang, Kun Yang, Cunhua Pan, Dusit Niyato",http://arxiv.org/pdf/2404.13238v1,cs.CL
The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions,"Today's LLMs are susceptible to prompt injections, jailbreaks, and other
attacks that allow adversaries to overwrite a model's original instructions
with their own malicious prompts. In this work, we argue that one of the
primary vulnerabilities underlying these attacks is that LLMs often consider
system prompts (e.g., text from an application developer) to be the same
priority as text from untrusted users and third parties. To address this, we
propose an instruction hierarchy that explicitly defines how models should
behave when instructions of different priorities conflict. We then propose a
data generation method to demonstrate this hierarchical instruction following
behavior, which teaches LLMs to selectively ignore lower-privileged
instructions. We apply this method to GPT-3.5, showing that it drastically
increases robustness -- even for attack types not seen during training -- while
imposing minimal degradations on standard capabilities.",2024-04-19,"Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng, Johannes Heidecke, Alex Beutel",http://arxiv.org/pdf/2404.13208v1,cs.CL
Heterogeneous Subgraph Transformer for Fake News Detection,"Fake news is pervasive on social media, inflicting substantial harm on public
discourse and societal well-being. We investigate the explicit structural
information and textual features of news pieces by constructing a heterogeneous
graph concerning the relations among news topics, entities, and content.
Through our study, we reveal that fake news can be effectively detected in
terms of the atypical heterogeneous subgraphs centered on them, which
encapsulate the essential semantics and intricate relations between news
elements. However, suffering from the heterogeneity, exploring such
heterogeneous subgraphs remains an open problem. To bridge the gap, this work
proposes a heterogeneous subgraph transformer (HeteroSGT) to exploit subgraphs
in our constructed heterogeneous graph. In HeteroSGT, we first employ a
pre-trained language model to derive both word-level and sentence-level
semantics. Then the random walk with restart (RWR) is applied to extract
subgraphs centered on each news, which are further fed to our proposed subgraph
Transformer to quantify the authenticity. Extensive experiments on five
real-world datasets demonstrate the superior performance of HeteroSGT over five
baselines. Further case and ablation studies validate our motivation and
demonstrate that performance improvement stems from our specially designed
components.",2024-04-19,"Yuchen Zhang, Xiaoxiao Ma, Jia Wu, Jian Yang, Hao Fan",http://arxiv.org/pdf/2404.13192v1,cs.CL
Course-Skill Atlas: A national longitudinal dataset of skills taught in U.S. higher education curricula,"Higher education plays a critical role in driving an innovative economy by
equipping students with knowledge and skills demanded by the workforce. While
researchers and practitioners have developed data systems to track detailed
occupational skills, such as those established by the U.S. Department of Labor
(DOL), much less effort has been made to document which of these skills are
being developed in higher education at a similar granularity. Here, we fill
this gap by presenting Course-Skill Atlas -- a longitudinal dataset of skills
inferred from over three million course syllabi taught at nearly three thousand
U.S. higher education institutions. To construct Course-Skill Atlas, we apply
natural language processing to quantify the alignment between course syllabi
and detailed workplace activities (DWAs) used by the DOL to describe
occupations. We then aggregate these alignment scores to create skill profiles
for institutions and academic majors. Our dataset offers a large-scale
representation of college education's role in preparing students for the labor
market. Overall, Course-Skill Atlas can enable new research on the source of
skills in the context of workforce development and provide actionable insights
for shaping the future of higher education to meet evolving labor demands,
especially in the face of new technologies.",2024-04-19,"Alireza Javadian Sabet, Sarah H. Bana, Renzhe Yu, Morgan R. Frank",http://arxiv.org/pdf/2404.13163v2,cs.CL
Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging,"Advances in large language models (LLMs) have encouraged their adoption in
the healthcare domain where vital clinical information is often contained in
unstructured notes. Cancer staging status is available in clinical reports, but
it requires natural language processing to extract the status from the
unstructured text. With the advance in clinical-oriented LLMs, it is promising
to extract such status without extensive efforts in training the algorithms.
Prompting approaches of the pre-trained LLMs that elicit a model's reasoning
process, such as chain-of-thought, may help to improve the trustworthiness of
the generated responses. Using self-consistency further improves model
performance, but often results in inconsistent generations across the multiple
reasoning paths. In this study, we propose an ensemble reasoning approach with
the aim of improving the consistency of the model generations. Using an open
access clinical large language model to determine the pathologic cancer stage
from real-world pathology reports, we show that the ensemble reasoning approach
is able to improve both the consistency and performance of the LLM in
determining cancer stage, thereby demonstrating the potential to use these
models in clinical or other domains where reliability and trustworthiness are
critical.",2024-04-19,"Chia-Hsuan Chang, Mary M. Lucas, Yeawon Lee, Christopher C. Yang, Grace Lu-Yao",http://arxiv.org/pdf/2404.13149v1,cs.CL
Data Alignment for Zero-Shot Concept Generation in Dermatology AI,"AI in dermatology is evolving at a rapid pace but the major limitation to
training trustworthy classifiers is the scarcity of data with ground-truth
concept level labels, which are meta-labels semantically meaningful to humans.
Foundation models like CLIP providing zero-shot capabilities can help alleviate
this challenge by leveraging vast amounts of image-caption pairs available on
the internet. CLIP can be fine-tuned using domain specific image-caption pairs
to improve classification performance. However, CLIP's pre-training data is not
well-aligned with the medical jargon that clinicians use to perform diagnoses.
The development of large language models (LLMs) in recent years has led to the
possibility of leveraging the expressive nature of these models to generate
rich text. Our goal is to use these models to generate caption text that aligns
well with both the clinical lexicon and with the natural human language used in
CLIP's pre-training data. Starting with captions used for images in PubMed
articles, we extend them by passing the raw captions through an LLM fine-tuned
on the field's several textbooks. We find that using captions generated by an
expressive fine-tuned LLM like GPT-3.5 improves downstream zero-shot concept
classification performance.",2024-04-19,"Soham Gadgil, Mahtab Bigverdi",http://arxiv.org/pdf/2404.13043v2,cs.CL
LaPA: Latent Prompt Assist Model For Medical Visual Question Answering,"Medical visual question answering (Med-VQA) aims to automate the prediction
of correct answers for medical images and questions, thereby assisting
physicians in reducing repetitive tasks and alleviating their workload.
Existing approaches primarily focus on pre-training models using additional and
comprehensive datasets, followed by fine-tuning to enhance performance in
downstream tasks. However, there is also significant value in exploring
existing models to extract clinically relevant information. In this paper, we
propose the Latent Prompt Assist model (LaPA) for medical visual question
answering. Firstly, we design a latent prompt generation module to generate the
latent prompt with the constraint of the target answer. Subsequently, we
propose a multi-modal fusion block with latent prompt fusion module that
utilizes the latent prompt to extract clinical-relevant information from
uni-modal and multi-modal features. Additionally, we introduce a prior
knowledge fusion module to integrate the relationship between diseases and
organs with the clinical-relevant information. Finally, we combine the final
integrated information with image-language cross-modal information to predict
the final answers. Experimental results on three publicly available Med-VQA
datasets demonstrate that LaPA outperforms the state-of-the-art model ARL,
achieving improvements of 1.83%, 0.63%, and 1.80% on VQA-RAD, SLAKE, and
VQA-2019, respectively. The code is publicly available at
https://github.com/GaryGuTC/LaPA_model.",2024-04-19,"Tiancheng Gu, Kaicheng Yang, Dongnan Liu, Weidong Cai",http://arxiv.org/pdf/2404.13039v1,cs.CL
Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs,"In the burgeoning field of Large Language Models (LLMs) like ChatGPT and
LLaMA, Prompt Engineering (PE) is renowned for boosting zero-shot or in-context
learning (ICL) through prompt modifications. Yet, the realm of the sample
design for downstream fine-tuning, crucial for task-specific LLM adaptation, is
largely unexplored. This paper introduces Sample Design Engineering (SDE), a
methodical approach to enhancing LLMs' post-tuning performance by refining
input, output, and reasoning designs. We conduct a series of in-domain (ID) and
out-of-domain (OOD) experiments to assess the impact of various design options
on LLMs' downstream performance, revealing several intriguing patterns that
hold consistently across different LLMs. Based on these insights, we propose an
integrated SDE strategy, combining the most effective options, and validate its
consistent superiority over heuristic sample designs in complex downstream
tasks like multi-aspect sentiment analysis, event extraction, and nested entity
recognition. Additionally, analyses of LLMs' inherent prompt/output perplexity,
zero-shot, and ICL abilities illustrate that good PE strategies may not always
translate to good SDE strategies. Code available at
https://github.com/beyondguo/LLM-Tuning.",2024-04-19,"Biyang Guo, He Wang, Wenyilin Xiao, Hong Chen, Zhuxin Lee, Songqiao Han, Hailiang Huang",http://arxiv.org/pdf/2404.13033v1,cs.CL
Stronger Random Baselines for In-Context Learning,"Evaluating the in-context learning classification performance of language
models poses challenges due to small dataset sizes, extensive prompt-selection
using the validation set, and intentionally difficult tasks that lead to
near-random performance. The standard random baseline--the expected accuracy of
guessing labels uniformly at random--is stable when the evaluation set is used
only once or when the dataset is large. We account for the common practice of
validation set reuse and existing small datasets with a stronger random
baseline: the expected maximum accuracy across multiple random classifiers.
When choosing the best prompt demonstrations across six quantized language
models applied to 16 BIG-bench Lite tasks, more than 20% of the few-shot
results that exceed the standard baseline do not exceed this stronger random
baseline. When held-out test sets are available, this stronger baseline is also
a better predictor of held-out performance than the standard baseline, avoiding
unnecessary test set evaluations. This maximum random baseline provides an
easily calculated drop-in replacement for the standard baseline.",2024-04-19,"Gregory Yauney, David Mimno",http://arxiv.org/pdf/2404.13020v2,cs.CL
Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models,"We introduce Groma, a Multimodal Large Language Model (MLLM) with grounded
and fine-grained visual perception ability. Beyond holistic image
understanding, Groma is adept at region-level tasks such as region captioning
and visual grounding. Such capabilities are built upon a localized visual
tokenization mechanism, where an image input is decomposed into regions of
interest and subsequently encoded into region tokens. By integrating region
tokens into user instructions and model responses, we seamlessly enable Groma
to understand user-specified region inputs and ground its textual output to
images. Besides, to enhance the grounded chat ability of Groma, we curate a
visually grounded instruction dataset by leveraging the powerful GPT-4V and
visual prompting techniques. Compared with MLLMs that rely on the language
model or external module for localization, Groma consistently demonstrates
superior performances in standard referring and grounding benchmarks,
highlighting the advantages of embedding localization into image tokenization.
Project page: https://groma-mllm.github.io/.",2024-04-19,"Chuofan Ma, Yi Jiang, Jiannan Wu, Zehuan Yuan, Xiaojuan Qi",http://arxiv.org/pdf/2404.13013v1,cs.CL
Rethinking the Evaluation of Dialogue Systems: Effects of User Feedback on Crowdworkers and LLMs,"In ad-hoc retrieval, evaluation relies heavily on user actions, including
implicit feedback. In a conversational setting such signals are usually
unavailable due to the nature of the interactions, and, instead, the evaluation
often relies on crowdsourced evaluation labels. The role of user feedback in
annotators' assessment of turns in a conversational perception has been little
studied. We focus on how the evaluation of task-oriented dialogue systems
(TDSs), is affected by considering user feedback, explicit or implicit, as
provided through the follow-up utterance of a turn being evaluated. We explore
and compare two methodologies for assessing TDSs: one includes the user's
follow-up utterance and one without. We use both crowdworkers and large
language models (LLMs) as annotators to assess system responses across four
aspects: relevance, usefulness, interestingness, and explanation quality. Our
findings indicate that there is a distinct difference in ratings assigned by
both annotator groups in the two setups, indicating user feedback does
influence system evaluation. Workers are more susceptible to user feedback on
usefulness and interestingness compared to LLMs on interestingness and
relevance. User feedback leads to a more personalized assessment of usefulness
by workers, aligning closely with the user's explicit feedback. Additionally,
in cases of ambiguous or complex user requests, user feedback improves
agreement among crowdworkers. These findings emphasize the significance of user
feedback in refining system evaluations and suggest the potential for automated
feedback integration in future research. We publicly release the annotated data
to foster research in this area.",2024-04-19,"Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke",http://arxiv.org/pdf/2404.12994v2,cs.CL
Towards Reliable Latent Knowledge Estimation in LLMs: Zero-Prompt Many-Shot Based Factual Knowledge Extraction,"In this paper, we focus on the challenging task of reliably estimating
factual knowledge that is embedded inside large language models (LLMs). To
avoid reliability concerns with prior approaches, we propose to eliminate
prompt engineering when probing LLMs for factual knowledge. Our approach,
called Zero-Prompt Latent Knowledge Estimator (ZP-LKE), leverages the
in-context learning ability of LLMs to communicate both the factual knowledge
question as well as the expected answer format. Our knowledge estimator is both
conceptually simpler (i.e., doesn't depend on meta-linguistic judgments of
LLMs) and easier to apply (i.e., is not LLM-specific), and we demonstrate that
it can surface more of the latent knowledge embedded in LLMs. We also
investigate how different design choices affect the performance of ZP-LKE.
Using the proposed estimator, we perform a large-scale evaluation of the
factual knowledge of a variety of open-source LLMs, like OPT, Pythia, Llama(2),
Mistral, Gemma, etc. over a large set of relations and facts from the Wikidata
knowledge base. We observe differences in the factual knowledge between
different model families and models of different sizes, that some relations are
consistently better known than others but that models differ in the precise
facts they know, and differences in the knowledge of base models and their
finetuned counterparts. Code available at:
https://github.com/QinyuanWu0710/ZeroPrompt_LKE",2024-04-19,"Qinyuan Wu, Mohammad Aflah Khan, Soumi Das, Vedant Nanda, Bishwamittra Ghosh, Camila Kolling, Till Speicher, Laurent Bindschaedler, Krishna P. Gummadi, Evimaria Terzi",http://arxiv.org/pdf/2404.12957v2,cs.CL
MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews,"Deceptive reviews are becoming increasingly common, especially given the
increase in performance and the prevalence of LLMs. While work to date has
addressed the development of models to differentiate between truthful and
deceptive human reviews, much less is known about the distinction between real
reviews and AI-authored fake reviews. Moreover, most of the research so far has
focused primarily on English, with very little work dedicated to other
languages. In this paper, we compile and make publicly available the MAiDE-up
dataset, consisting of 10,000 real and 10,000 AI-generated fake hotel reviews,
balanced across ten languages. Using this dataset, we conduct extensive
linguistic analyses to (1) compare the AI fake hotel reviews to real hotel
reviews, and (2) identify the factors that influence the deception detection
model performance. We explore the effectiveness of several models for deception
detection in hotel reviews across three main dimensions: sentiment, location,
and language. We find that these dimensions influence how well we can detect
AI-generated fake reviews.",2024-04-19,"Oana Ignat, Xiaomeng Xu, Rada Mihalcea",http://arxiv.org/pdf/2404.12938v2,cs.CL
Cross-cultural Inspiration Detection and Analysis in Real and LLM-generated Social Media Data,"Inspiration is linked to various positive outcomes, such as increased
creativity, productivity, and happiness. Although inspiration has great
potential, there has been limited effort toward identifying content that is
inspiring, as opposed to just engaging or positive. Additionally, most research
has concentrated on Western data, with little attention paid to other cultures.
This work is the first to study cross-cultural inspiration through machine
learning methods. We aim to identify and analyze real and AI-generated
cross-cultural inspiring posts. To this end, we compile and make publicly
available the InspAIred dataset, which consists of 2,000 real inspiring posts,
2,000 real non-inspiring posts, and 2,000 generated inspiring posts evenly
distributed across India and the UK. The real posts are sourced from Reddit,
while the generated posts are created using the GPT-4 model. Using this
dataset, we conduct extensive computational linguistic analyses to (1) compare
inspiring content across cultures, (2) compare AI-generated inspiring posts to
real inspiring posts, and (3) determine if detection models can accurately
distinguish between inspiring content across cultures and data sources.",2024-04-19,"Oana Ignat, Gayathri Ganesh Lakshmy, Rada Mihalcea",http://arxiv.org/pdf/2404.12933v2,cs.CL
Enabling Natural Zero-Shot Prompting on Encoder Models via Statement-Tuning,"While Large Language Models (LLMs) exhibit remarkable capabilities in
zero-shot and few-shot scenarios, they often require computationally
prohibitive sizes. Conversely, smaller Masked Language Models (MLMs) like BERT
and RoBERTa achieve state-of-the-art results through fine-tuning but struggle
with extending to few-shot and zero-shot settings due to their architectural
constraints. Hence, we propose Statement-Tuning, a technique that models
discriminative tasks as a set of finite statements and trains an encoder model
to discriminate between the potential statements to determine the label. We do
Statement-Tuning on multiple tasks to enable cross-task generalization.
Experimental results demonstrate that Statement-Tuning achieves competitive
performance compared to state-of-the-art LLMs with significantly fewer
parameters. Moreover, the study investigates the impact of several design
choices on few-shot and zero-shot generalization, revealing that
Statement-Tuning can achieve strong performance with modest training data and
benefits from task and statement diversity for unseen task generalizability.",2024-04-19,"Ahmed Elshabrawy, Yongxin Huang, Iryna Gurevych, Alham Fikri Aji",http://arxiv.org/pdf/2404.12897v3,cs.CL
Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented Generation,"While Retrieval-Augmented Generation (RAG) plays a crucial role in the
application of Large Language Models (LLMs), existing retrieval methods in
knowledge-dense domains like law and medicine still suffer from a lack of
multi-perspective views, which are essential for improving interpretability and
reliability. Previous research on multi-view retrieval often focused solely on
different semantic forms of queries, neglecting the expression of specific
domain knowledge perspectives. This paper introduces a novel multi-view RAG
framework, MVRAG, tailored for knowledge-dense domains that utilizes
intention-aware query rewriting from multiple domain viewpoints to enhance
retrieval precision, thereby improving the effectiveness of the final
inference. Experiments conducted on legal and medical case retrieval
demonstrate significant improvements in recall and precision rates with our
framework. Our multi-perspective retrieval approach unleashes the potential of
multi-view information enhancing RAG tasks, accelerating the further
application of LLMs in knowledge-intensive fields.",2024-04-19,"Guanhua Chen, Wenhan Yu, Lei Sha",http://arxiv.org/pdf/2404.12879v1,cs.CL
TopoLedgerBERT: Topological Learning of Ledger Description Embeddings using Siamese BERT-Networks,"This paper addresses a long-standing problem in the field of accounting:
mapping company-specific ledger accounts to a standardized chart of accounts.
We propose a novel solution, TopoLedgerBERT, a unique sentence embedding method
devised specifically for ledger account mapping. This model integrates
hierarchical information from the charts of accounts into the sentence
embedding process, aiming to accurately capture both the semantic similarity
and the hierarchical structure of the ledger accounts. In addition, we
introduce a data augmentation strategy that enriches the training data and, as
a result, increases the performance of our proposed model. Compared to
benchmark methods, TopoLedgerBERT demonstrates superior performance in terms of
accuracy and mean reciprocal rank.",2024-04-19,"Sander Noels, Sébastien Viaene, Tijl De Bie",http://arxiv.org/pdf/2407.05175v1,cs.CL
LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency,"Query rewrite, which aims to generate more efficient queries by altering a
SQL query's structure without changing the query result, has been an important
research problem. In order to maintain equivalence between the rewritten query
and the original one during rewriting, traditional query rewrite methods always
rewrite the queries following certain rewrite rules. However, some problems
still remain. Firstly, existing methods of finding the optimal choice or
sequence of rewrite rules are still limited and the process always costs a lot
of resources. Methods involving discovering new rewrite rules typically require
complicated proofs of structural logic or extensive user interactions.
Secondly, current query rewrite methods usually rely highly on DBMS cost
estimators which are often not accurate. In this paper, we address these
problems by proposing a novel method of query rewrite named LLM-R2, adopting a
large language model (LLM) to propose possible rewrite rules for a database
rewrite system. To further improve the inference ability of LLM in recommending
rewrite rules, we train a contrastive model by curriculum to learn query
representations and select effective query demonstrations for the LLM.
Experimental results have shown that our method can significantly improve the
query execution efficiency and outperform the baseline methods. In addition,
our method enjoys high robustness across different datasets.",2024-04-19,"Zhaodonghui Li, Haitao Yuan, Huiming Wang, Gao Cong, Lidong Bing",http://arxiv.org/pdf/2404.12872v1,cs.CL
How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?,"The increase in parameter size of multimodal large language models (MLLMs)
introduces significant capabilities, particularly in-context learning, where
MLLMs enhance task performance without updating pre-trained parameters. This
effectiveness, however, hinges on the appropriate selection of in-context
examples, a process that is currently biased towards visual data, overlooking
textual information. Furthermore, the area of supervised retrievers for MLLMs,
crucial for optimal in-context example selection, continues to be
uninvestigated. Our study offers an in-depth evaluation of the impact of
textual information on the unsupervised selection of in-context examples in
multimodal contexts, uncovering a notable sensitivity of retriever performance
to the employed modalities. Responding to this, we introduce a novel supervised
MLLM-retriever MSIER that employs a neural network to select examples that
enhance multimodal in-context learning efficiency. This approach is validated
through extensive testing across three distinct tasks, demonstrating the
method's effectiveness. Additionally, we investigate the influence of
modalities on our supervised retrieval method's training and pinpoint factors
contributing to our model's success. This exploration paves the way for future
advancements, highlighting the potential for refined in-context learning in
MLLMs through the strategic use of multimodal data.",2024-04-19,"Yang Luo, Zangwei Zheng, Zirui Zhu, Yang You",http://arxiv.org/pdf/2404.12866v2,cs.CL
Multi Class Depression Detection Through Tweets using Artificial Intelligence,"Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.",2024-04-19,"Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal",http://arxiv.org/pdf/2404.13104v1,cs.CL
TartuNLP @ SIGTYP 2024 Shared Task: Adapting XLM-RoBERTa for Ancient and Historical Languages,"We present our submission to the unconstrained subtask of the SIGTYP 2024
Shared Task on Word Embedding Evaluation for Ancient and Historical Languages
for morphological annotation, POS-tagging, lemmatization, character- and
word-level gap-filling. We developed a simple, uniform, and computationally
lightweight approach based on the adapters framework using parameter-efficient
fine-tuning. We applied the same adapter-based approach uniformly to all tasks
and 16 languages by fine-tuning stacked language- and task-specific adapters.
Our submission obtained an overall second place out of three submissions, with
the first place in word-level gap-filling. Our results show the feasibility of
adapting language models pre-trained on modern languages to historical and
ancient languages via adapter training.",2024-04-19,"Aleksei Dorkin, Kairit Sirts",http://arxiv.org/pdf/2404.12845v2,cs.CL
Towards Logically Consistent Language Models via Probabilistic Reasoning,"Large language models (LLMs) are a promising venue for natural language
understanding and generation tasks. However, current LLMs are far from
reliable: they are prone to generate non-factual information and, more
crucially, to contradict themselves when prompted to reason about beliefs of
the world. These problems are currently addressed with large scale fine-tuning
or by delegating consistent reasoning to external tools. In this work, we
strive for a middle ground and introduce a training objective based on
principled probabilistic reasoning that teaches a LLM to be consistent with
external knowledge in the form of a set of facts and rules. Fine-tuning with
our loss on a limited set of facts enables our LLMs to be more logically
consistent than previous baselines and allows them to extrapolate to unseen but
semantically similar factual knowledge more systematically.",2024-04-19,"Diego Calanzone, Stefano Teso, Antonio Vergari",http://arxiv.org/pdf/2404.12843v1,cs.CL
LiMe: a Latin Corpus of Late Medieval Criminal Sentences,"The Latin language has received attention from the computational linguistics
research community, which has built, over the years, several valuable
resources, ranging from detailed annotated corpora to sophisticated tools for
linguistic analysis. With the recent advent of large language models,
researchers have also started developing models capable of generating vector
representations of Latin texts. The performances of such models remain behind
the ones for modern languages, given the disparity in available data. In this
paper, we present the LiMe dataset, a corpus of 325 documents extracted from a
series of medieval manuscripts called Libri sententiarum potestatis Mediolani,
and thoroughly annotated by experts, in order to be employed for masked
language model, as well as supervised natural language processing tasks.",2024-04-19,"Alessandra Bassani, Beatrice Del Bo, Alfio Ferrara, Marta Mangini, Sergio Picascia, Ambra Stefanello",http://arxiv.org/pdf/2404.12829v1,cs.CL
An Evaluation Benchmark for Adverse Drug Event Prediction from Clinical Trial Results,"Adverse drug events (ADEs) are a major safety issue in clinical trials. Thus,
predicting ADEs is key to developing safer medications and enhancing patient
outcomes. To support this effort, we introduce CT-ADE, a dataset for multilabel
ADE prediction in monopharmacy treatments. CT-ADE encompasses 2,497 drugs and
168,984 drug-ADE pairs from clinical trial results, annotated using the MedDRA
ontology. Unlike existing resources, CT-ADE integrates treatment and target
population data, enabling comparative analyses under varying conditions, such
as dosage, administration route, and demographics. In addition, CT-ADE
systematically collects all ADEs in the study population, including positive
and negative cases. To provide a baseline for ADE prediction performance using
the CT-ADE dataset, we conducted analyses using large language models (LLMs).
The best LLM achieved an F1-score of 56%, with models incorporating treatment
and patient information outperforming by 21%-38% those relying solely on the
chemical structure. These findings underscore the importance of contextual
information in ADE prediction and establish CT-ADE as a robust resource for
safety risk assessment in pharmaceutical research and development.",2024-04-19,"Anthony Yazdani, Alban Bornet, Philipp Khlebnikov, Boya Zhang, Hossein Rouhizadeh, Poorya Amini, Douglas Teodoro",http://arxiv.org/pdf/2404.12827v3,cs.CL
REXEL: An End-to-end Model for Document-Level Relation Extraction and Entity Linking,"Extracting structured information from unstructured text is critical for many
downstream NLP applications and is traditionally achieved by closed information
extraction (cIE). However, existing approaches for cIE suffer from two
limitations: (i) they are often pipelines which makes them prone to error
propagation, and/or (ii) they are restricted to sentence level which prevents
them from capturing long-range dependencies and results in expensive inference
time. We address these limitations by proposing REXEL, a highly efficient and
accurate model for the joint task of document level cIE (DocIE). REXEL performs
mention detection, entity typing, entity disambiguation, coreference resolution
and document-level relation classification in a single forward pass to yield
facts fully linked to a reference knowledge graph. It is on average 11 times
faster than competitive existing approaches in a similar setting and performs
competitively both when optimised for any of the individual subtasks and a
variety of combinations of different joint tasks, surpassing the baselines by
an average of more than 6 F1 points. The combination of speed and accuracy
makes REXEL an accurate cost-efficient system for extracting structured
information at web-scale. We also release an extension of the DocRED dataset to
enable benchmarking of future work on DocIE, which is available at
https://github.com/amazon-science/e2e-docie.",2024-04-19,"Nacime Bouziani, Shubhi Tyagi, Joseph Fisher, Jens Lehmann, Andrea Pierleoni",http://arxiv.org/pdf/2404.12788v1,cs.CL
AutoScraper: A Progressive Understanding Web Agent for Web Scraper Generation,"Web scraping is a powerful technique that extracts data from websites,
enabling automated data collection, enhancing data analysis capabilities, and
minimizing manual data entry efforts. Existing methods, wrappers-based methods
suffer from limited adaptability and scalability when faced with a new website,
while language agents, empowered by large language models (LLMs), exhibit poor
reusability in diverse web environments. In this work, we introduce the
paradigm of generating web scrapers with LLMs and propose AutoScraper, a
two-stage framework that can handle diverse and changing web environments more
efficiently. AutoScraper leverages the hierarchical structure of HTML and
similarity across different web pages for generating web scrapers. Besides, we
propose a new executability metric for better measuring the performance of web
scraper generation tasks. We conduct comprehensive experiments with multiple
LLMs and demonstrate the effectiveness of our framework. Resources of this
paper can be found at \url{https://github.com/EZ-hwh/AutoScraper}",2024-04-19,"Wenhao Huang, Zhouhong Gu, Chenghao Peng, Zhixu Li, Jiaqing Liang, Yanghua Xiao, Liqian Wen, Zulong Chen",http://arxiv.org/pdf/2404.12753v2,cs.CL
Beyond Human Norms: Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches,"Recent advancements in Large Language Models (LLMs) have revolutionized the
AI field but also pose potential safety and ethical risks. Deciphering LLMs'
embedded values becomes crucial for assessing and mitigating their risks.
Despite extensive investigation into LLMs' values, previous studies heavily
rely on human-oriented value systems in social sciences. Then, a natural
question arises: Do LLMs possess unique values beyond those of humans? Delving
into it, this work proposes a novel framework, ValueLex, to reconstruct LLMs'
unique value system from scratch, leveraging psychological methodologies from
human personality/value research. Based on Lexical Hypothesis, ValueLex
introduces a generative approach to elicit diverse values from 30+ LLMs,
synthesizing a taxonomy that culminates in a comprehensive value framework via
factor analysis and semantic clustering. We identify three core value
dimensions, Competence, Character, and Integrity, each with specific
subdimensions, revealing that LLMs possess a structured, albeit non-human,
value system. Based on this system, we further develop tailored projective
tests to evaluate and analyze the value inclinations of LLMs across different
model sizes, training methods, and data sources. Our framework fosters an
interdisciplinary paradigm of understanding LLMs, paving the way for future AI
alignment and regulation.",2024-04-19,"Pablo Biedma, Xiaoyuan Yi, Linus Huang, Maosong Sun, Xing Xie",http://arxiv.org/pdf/2404.12744v2,cs.CL
Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?,"Analogical reasoning is a unique ability of humans to address unfamiliar
challenges by transferring strategies from relevant past experiences. One key
finding in psychology is that compared with irrelevant past experiences,
recalling relevant ones can help humans better handle new tasks.
Coincidentally, the NLP community has also recently found that self-generating
relevant examples in the context can help large language models (LLMs) better
solve a given problem than hand-crafted prompts. However, it is yet not clear
whether relevance is the key factor eliciting such capability, i.e., can LLMs
benefit more from self-generated relevant examples than irrelevant ones? In
this work, we systematically explore whether LLMs can truly perform analogical
reasoning on a diverse set of reasoning tasks. With extensive experiments and
analysis, we show that self-generated random examples can surprisingly achieve
comparable or even better performance, e.g., 4% performance boost on GSM8K with
random biological examples. We find that the accuracy of self-generated
examples is the key factor and subsequently design two improved methods with
significantly reduced inference costs. Overall, we aim to advance a deeper
understanding of LLM analogical reasoning and hope this work stimulates further
research in the design of self-generated contexts.",2024-04-19,"Chengwei Qin, Wenhan Xia, Tan Wang, Fangkai Jiao, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty",http://arxiv.org/pdf/2404.12728v2,cs.CL
Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works,"Large language models (LLMs) have demonstrated impressive performance and
spurred numerous AI applications, in which role-playing agents (RPAs) are
particularly popular, especially for fictional characters. The prerequisite for
these RPAs lies in the capability of LLMs to understand characters from
fictional works. Previous efforts have evaluated this capability via basic
classification tasks or characteristic imitation, failing to capture the
nuanced character understanding with LLMs. In this paper, we propose evaluating
LLMs' character understanding capability via the character profiling task,
i.e., summarizing character profiles from corresponding materials, a widely
adopted yet understudied practice for RPA development. Specifically, we
construct the CroSS dataset from literature experts and assess the generated
profiles by comparing them with ground truth references and evaluating their
applicability in downstream tasks. Our experiments, which cover various
summarization methods and LLMs, have yielded promising results. These results
strongly validate the character understanding capability of LLMs. Resources are
available at https://github.com/Joanna0123/character_profiling.",2024-04-19,"Xinfeng Yuan, Siyu Yuan, Yuhan Cui, Tianhe Lin, Xintao Wang, Rui Xu, Jiangjie Chen, Deqing Yang",http://arxiv.org/pdf/2404.12726v3,cs.CL
PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering,"Document Question Answering (QA) presents a challenge in understanding
visually-rich documents (VRD), particularly those dominated by lengthy textual
content like research journal articles. Existing studies primarily focus on
real-world documents with sparse text, while challenges persist in
comprehending the hierarchical semantic relations among multiple pages to
locate multimodal components. To address this gap, we propose PDF-MVQA, which
is tailored for research journal articles, encompassing multiple pages and
multimodal information retrieval. Unlike traditional machine reading
comprehension (MRC) tasks, our approach aims to retrieve entire paragraphs
containing answers or visually rich document entities like tables and figures.
Our contributions include the introduction of a comprehensive PDF Document VQA
dataset, allowing the examination of semantically hierarchical layout
structures in text-dominant documents. We also present new VRD-QA frameworks
designed to grasp textual contents and relations among document layouts
simultaneously, extending page-level understanding to the entire multi-page
document. Through this work, we aim to enhance the capabilities of existing
vision-and-language models in handling challenges posed by text-dominant
documents in VRD-QA.",2024-04-19,"Yihao Ding, Kaixuan Ren, Jiabin Huang, Siwen Luo, Soyeon Caren Han",http://arxiv.org/pdf/2404.12720v1,cs.CL
Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration,"Large language models (LLMs) exhibit complementary strengths in various
tasks, motivating the research of LLM ensembling. However, existing work
focuses on training an extra reward model or fusion model to select or combine
all candidate answers, posing a great challenge to the generalization on unseen
data distributions. Besides, prior methods use textual responses as
communication media, ignoring the valuable information in the internal
representations. In this work, we propose a training-free ensemble framework
DeePEn, fusing the informative probability distributions yielded by different
LLMs at each decoding step. Unfortunately, the vocabulary discrepancy between
heterogeneous LLMs directly makes averaging the distributions unfeasible due to
the token misalignment. To address this challenge, DeePEn maps the probability
distribution of each model from its own probability space to a universal
relative space based on the relative representation theory, and performs
aggregation. Next, we devise a search-based inverse transformation to transform
the aggregated result back to the probability space of one of the ensembling
LLMs (main model), in order to determine the next token. We conduct extensive
experiments on ensembles of different number of LLMs, ensembles of LLMs with
different architectures, and ensembles between the LLM and the specialist
model. Experimental results show that (i) DeePEn achieves consistent
improvements across six benchmarks covering subject examination, reasoning, and
knowledge, (ii) a well-performing specialist model can benefit from a less
effective LLM through distribution fusion, and (iii) DeePEn has complementary
strengths with other ensemble methods such as voting.",2024-04-19,"Yichong Huang, Xiaocheng Feng, Baohang Li, Yang Xiang, Hui Wang, Bing Qin, Ting Liu",http://arxiv.org/pdf/2404.12715v2,cs.CL
Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks,"The rapid progress in the field of natural language processing (NLP) systems
and the expansion of large language models (LLMs) have opened up numerous
opportunities in the field of education and instructional methods. These
advancements offer the potential for tailored learning experiences and
immediate feedback, all delivered through accessible and cost-effective
services. One notable application area for this technological advancement is in
the realm of solving mathematical problems. Mathematical problem-solving not
only requires the ability to decipher complex problem statements but also the
skill to perform precise arithmetic calculations at each step of the
problem-solving process. However, the evaluation of the arithmetic capabilities
of large language models remains an area that has received relatively little
attention. In response, we introduce an extensive mathematics dataset called
""MathQuest"" sourced from the 11th and 12th standard Mathematics NCERT
textbooks. This dataset encompasses mathematical challenges of varying
complexity and covers a wide range of mathematical concepts. Utilizing this
dataset, we conduct fine-tuning experiments with three prominent LLMs: LLaMA-2,
WizardMath, and MAmmoTH. These fine-tuned models serve as benchmarks for
evaluating their performance on our dataset. Our experiments reveal that among
the three models, MAmmoTH-13B emerges as the most proficient, achieving the
highest level of competence in solving the presented mathematical problems.
Consequently, MAmmoTH-13B establishes itself as a robust and dependable
benchmark for addressing NCERT mathematics problems.",2024-04-19,"Avinash Anand, Mohit Gupta, Kritarth Prasad, Navya Singla, Sanjana Sanjeev, Jatin Kumar, Adarsh Raj Shivam, Rajiv Ratn Shah",http://arxiv.org/pdf/2404.13099v1,cs.CL
Neural Semantic Parsing with Extremely Rich Symbolic Meaning Representations,"Current open-domain neural semantics parsers show impressive performance.
However, closer inspection of the symbolic meaning representations they produce
reveals significant weaknesses: sometimes they tend to merely copy character
sequences from the source text to form symbolic concepts, defaulting to the
most frequent word sense based in the training distribution. By leveraging the
hierarchical structure of a lexical ontology, we introduce a novel
compositional symbolic representation for concepts based on their position in
the taxonomical hierarchy. This representation provides richer semantic
information and enhances interpretability. We introduce a neural ""taxonomical""
semantic parser to utilize this new representation system of predicates, and
compare it with a standard neural semantic parser trained on the traditional
meaning representation format, employing a novel challenge set and evaluation
metric for evaluation. Our experimental findings demonstrate that the
taxonomical model, trained on much richer and complex meaning representations,
is slightly subordinate in performance to the traditional model using the
standard metrics for evaluation, but outperforms it when dealing with
out-of-vocabulary concepts. This finding is encouraging for research in
computational semantics that aims to combine data-driven distributional
meanings with knowledge-based symbolic representations.",2024-04-19,"Xiao Zhang, Gosse Bouma, Johan Bos",http://arxiv.org/pdf/2404.12698v2,cs.CL
Towards Human-centered Proactive Conversational Agents,"Recent research on proactive conversational agents (PCAs) mainly focuses on
improving the system's capabilities in anticipating and planning action
sequences to accomplish tasks and achieve goals before users articulate their
requests. This perspectives paper highlights the importance of moving towards
building human-centered PCAs that emphasize human needs and expectations, and
that considers ethical and social implications of these agents, rather than
solely focusing on technological capabilities. The distinction between a
proactive and a reactive system lies in the proactive system's
initiative-taking nature. Without thoughtful design, proactive systems risk
being perceived as intrusive by human users. We address the issue by
establishing a new taxonomy concerning three key dimensions of human-centered
PCAs, namely Intelligence, Adaptivity, and Civility. We discuss potential
research opportunities and challenges based on this new taxonomy upon the five
stages of PCA system construction. This perspectives paper lays a foundation
for the emerging area of conversational information retrieval research and
paves the way towards advancing human-centered proactive conversational
systems.",2024-04-19,"Yang Deng, Lizi Liao, Zhonghua Zheng, Grace Hui Yang, Tat-Seng Chua",http://arxiv.org/pdf/2404.12670v1,cs.CL
SOS-1K: A Fine-grained Suicide Risk Classification Dataset for Chinese Social Media Analysis,"In the social media, users frequently express personal emotions, a subset of
which may indicate potential suicidal tendencies. The implicit and varied forms
of expression in internet language complicate accurate and rapid identification
of suicidal intent on social media, thus creating challenges for timely
intervention efforts. The development of deep learning models for suicide risk
detection is a promising solution, but there is a notable lack of relevant
datasets, especially in the Chinese context. To address this gap, this study
presents a Chinese social media dataset designed for fine-grained suicide risk
classification, focusing on indicators such as expressions of suicide intent,
methods of suicide, and urgency of timing. Seven pre-trained models were
evaluated in two tasks: high and low suicide risk, and fine-grained suicide
risk classification on a level of 0 to 10. In our experiments, deep learning
models show good performance in distinguishing between high and low suicide
risk, with the best model achieving an F1 score of 88.39%. However, the results
for fine-grained suicide risk classification were still unsatisfactory, with an
weighted F1 score of 50.89%. To address the issues of data imbalance and
limited dataset size, we investigated both traditional and advanced, large
language model based data augmentation techniques, demonstrating that data
augmentation can enhance model performance by up to 4.65% points in F1-score.
Notably, the Chinese MentalBERT model, which was pre-trained on psychological
domain data, shows superior performance in both tasks. This study provides
valuable insights for automatic identification of suicidal individuals,
facilitating timely psychological intervention on social media platforms. The
source code and data are publicly available.",2024-04-19,"Hongzhi Qi, Hanfei Liu, Jianqiang Li, Qing Zhao, Wei Zhai, Dan Luo, Tian Yu He, Shuo Liu, Bing Xiang Yang, Guanghui Fu",http://arxiv.org/pdf/2404.12659v1,cs.CL
Pre-trained Vision-Language Models Learn Discoverable Visual Concepts,"Do vision-language models (VLMs) pre-trained to caption an image of a
""durian"" learn visual concepts such as ""brown"" (color) and ""spiky"" (texture) at
the same time? We aim to answer this question as visual concepts learned ""for
free"" would enable wide applications such as neuro-symbolic reasoning or
human-interpretable object classification. We assume that the visual concepts,
if captured by pre-trained VLMs, can be extracted by their vision-language
interface with text-based concept prompts. We observe that recent works
prompting VLMs with concepts often differ in their strategies to define and
evaluate the visual concepts, leading to conflicting conclusions. We propose a
new concept definition strategy based on two observations: First, certain
concept prompts include shortcuts that recognize correct concepts for wrong
reasons; Second, multimodal information (e.g. visual discriminativeness, and
textual knowledge) should be leveraged when selecting the concepts. Our
proposed concept discovery and learning (CDL) framework is thus designed to
identify a diverse list of generic visual concepts (e.g. ""spiky"" as opposed to
""spiky durian""), which are ranked and selected based on visual and language
mutual information. We carefully design quantitative and human evaluations of
the discovered concepts on six diverse visual recognition datasets, which
confirm that pre-trained VLMs do learn visual concepts that provide accurate
and thorough descriptions for the recognized objects. All code and models are
publicly released.",2024-04-19,"Yuan Zang, Tian Yun, Hao Tan, Trung Bui, Chen Sun",http://arxiv.org/pdf/2404.12652v2,cs.CL
Cooperative Sentiment Agents for Multimodal Sentiment Analysis,"In this paper, we propose a new Multimodal Representation Learning (MRL)
method for Multimodal Sentiment Analysis (MSA), which facilitates the adaptive
interaction between modalities through Cooperative Sentiment Agents, named
Co-SA. Co-SA comprises two critical components: the Sentiment Agents
Establishment (SAE) phase and the Sentiment Agents Cooperation (SAC) phase.
During the SAE phase, each sentiment agent deals with an unimodal signal and
highlights explicit dynamic sentiment variations within the modality via the
Modality-Sentiment Disentanglement (MSD) and Deep Phase Space Reconstruction
(DPSR) modules. Subsequently, in the SAC phase, Co-SA meticulously designs
task-specific interaction mechanisms for sentiment agents so that coordinating
multimodal signals to learn the joint representation. Specifically, Co-SA
equips an independent policy model for each sentiment agent that captures
significant properties within the modality. These policies are optimized
mutually through the unified reward adaptive to downstream tasks. Benefitting
from the rewarding mechanism, Co-SA transcends the limitation of pre-defined
fusion modes and adaptively captures unimodal properties for MRL in the
multimodal interaction setting. To demonstrate the effectiveness of Co-SA, we
apply it to address Multimodal Sentiment Analysis (MSA) and Multimodal Emotion
Recognition (MER) tasks. Our comprehensive experimental results demonstrate
that Co-SA excels at discovering diverse cross-modal features, encompassing
both common and complementary aspects. The code can be available at
https://github.com/smwanghhh/Co-SA.",2024-04-19,"Shanmin Wang, Hui Shuai, Qingshan Liu, Fei Wang",http://arxiv.org/pdf/2404.12642v1,cs.CL
Efficient infusion of self-supervised representations in Automatic Speech Recognition,"Self-supervised learned (SSL) models such as Wav2vec and HuBERT yield
state-of-the-art results on speech-related tasks. Given the effectiveness of
such models, it is advantageous to use them in conventional ASR systems. While
some approaches suggest incorporating these models as a trainable encoder or a
learnable frontend, training such systems is extremely slow and requires a lot
of computation cycles. In this work, we propose two simple approaches that use
(1) framewise addition and (2) cross-attention mechanisms to efficiently
incorporate the representations from the SSL model(s) into the ASR
architecture, resulting in models that are comparable in size with standard
encoder-decoder conformer systems while also avoiding the usage of SSL models
during training. Our approach results in faster training and yields significant
performance gains on the Librispeech and Tedlium datasets compared to
baselines. We further provide detailed analysis and ablation studies that
demonstrate the effectiveness of our approach.",2024-04-19,"Darshan Prabhu, Sai Ganesh Mirishkar, Pankaj Wasnik",http://arxiv.org/pdf/2404.12628v1,cs.CL
CORI: CJKV Benchmark with Romanization Integration -- A step towards Cross-lingual Transfer Beyond Textual Scripts,"Naively assuming English as a source language may hinder cross-lingual
transfer for many languages by failing to consider the importance of language
contact. Some languages are more well-connected than others, and target
languages can benefit from transferring from closely related languages; for
many languages, the set of closely related languages does not include English.
In this work, we study the impact of source language for cross-lingual
transfer, demonstrating the importance of selecting source languages that have
high contact with the target language. We also construct a novel benchmark
dataset for close contact Chinese-Japanese-Korean-Vietnamese (CJKV) languages
to further encourage in-depth studies of language contact. To comprehensively
capture contact between these languages, we propose to integrate Romanized
transcription beyond textual scripts via Contrastive Learning objectives,
leading to enhanced cross-lingual representations and effective zero-shot
cross-lingual transfer.",2024-04-19,"Hoang H. Nguyen, Chenwei Zhang, Ye Liu, Natalie Parde, Eugene Rohrbaugh, Philip S. Yu",http://arxiv.org/pdf/2404.12618v1,cs.CL
Auto-Formula: Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations,"Spreadsheets are widely recognized as the most popular end-user programming
tools, which blend the power of formula-based computation, with an intuitive
table-based interface. Today, spreadsheets are used by billions of users to
manipulate tables, most of whom are neither database experts nor professional
programmers.
  Despite the success of spreadsheets, authoring complex formulas remains
challenging, as non-technical users need to look up and understand non-trivial
formula syntax. To address this pain point, we leverage the observation that
there is often an abundance of similar-looking spreadsheets in the same
organization, which not only have similar data, but also share similar
computation logic encoded as formulas. We develop an Auto-Formula system that
can accurately predict formulas that users want to author in a target
spreadsheet cell, by learning and adapting formulas that already exist in
similar spreadsheets, using contrastive-learning techniques inspired by
""similar-face recognition"" from compute vision.
  Extensive evaluations on over 2K test formulas extracted from real enterprise
spreadsheets show the effectiveness of Auto-Formula over alternatives. Our
benchmark data is available at https://github.com/microsoft/Auto-Formula to
facilitate future research.",2024-04-19,"Sibei Chen, Yeye He, Weiwei Cui, Ju Fan, Song Ge, Haidong Zhang, Dongmei Zhang, Surajit Chaudhuri",http://arxiv.org/pdf/2404.12608v1,cs.CL
Parameter Efficient Diverse Paraphrase Generation Using Sequence-Level Knowledge Distillation,"Over the past year, the field of Natural Language Generation (NLG) has
experienced an exponential surge, largely due to the introduction of Large
Language Models (LLMs). These models have exhibited the most effective
performance in a range of domains within the Natural Language Processing and
Generation domains. However, their application in domain-specific tasks, such
as paraphrasing, presents significant challenges. The extensive number of
parameters makes them difficult to operate on commercial hardware, and they
require substantial time for inference, leading to high costs in a production
setting. In this study, we tackle these obstacles by employing LLMs to develop
three distinct models for the paraphrasing field, applying a method referred to
as sequence-level knowledge distillation. These distilled models are capable of
maintaining the quality of paraphrases generated by the LLM. They demonstrate
faster inference times and the ability to generate diverse paraphrases of
comparable quality. A notable characteristic of these models is their ability
to exhibit syntactic diversity while also preserving lexical diversity,
features previously uncommon due to existing data quality issues in datasets
and not typically observed in neural-based approaches. Human evaluation of our
models shows that there is only a 4% drop in performance compared to the LLM
teacher model used in the distillation process, despite being 1000 times
smaller. This research provides a significant contribution to the NLG field,
offering a more efficient and cost-effective solution for paraphrasing tasks.",2024-04-19,"Lasal Jayawardena, Prasan Yapa",http://arxiv.org/pdf/2404.12596v1,cs.CL
iTBLS: A Dataset of Interactive Conversations Over Tabular Information,"This paper introduces Interactive Tables (iTBLS), a dataset of interactive
conversations situated in tables from scientific articles. This dataset is
designed to facilitate human-AI collaborative problem-solving through
AI-powered multi-task tabular capabilities. In contrast to prior work that
models interactions as factoid QA or procedure synthesis, iTBLS broadens the
scope of interactions to include mathematical reasoning, natural language
manipulation, and expansion of existing tables from natural language
conversation by delineating interactions into one of three tasks:
interpretation, modification, or generation. Additionally, the paper presents a
suite of baseline approaches to iTBLS, utilizing zero-shot prompting and
parameter-efficient fine-tuning for different computing situations. We also
introduce a novel multi-step approach and show how it can be leveraged in
conjunction with parameter-efficient fine-tuning to achieve the
state-of-the-art on iTBLS; outperforming standard parameter-efficient
fine-tuning by up to 15% on interpretation, 18% on modification, and 38% on
generation.",2024-04-19,"Anirudh Sundar, Christopher Richardson, William Gay, Larry Heck",http://arxiv.org/pdf/2404.12580v1,cs.CL
Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL,"The current state-of-the-art (SOTA) for automated text-to-SQL still falls
well short of expert human performance as measured by execution accuracy (EX)
on the BIRD-SQL benchmark. The most accurate methods are also slow and
expensive. To advance the SOTA for text-to-SQL while reducing cost and
improving speed, we explore the combination of low-cost fine tuning, novel
methods for diverse retrieval-augmented generation (RAG) and new input and
output formats that help large language models (LLMs) achieve higher EX. We
introduce two new methods, Dubo-SQL v1 and v2. Dubo-SQL v1 sets a new record
for EX on the holdout test set of BIRD-SQL. Dubo-SQL v2 achieves even higher
performance on the BIRD-SQL dev set. Dubo-SQL v1 relies on LLMs from OpenAI,
but uses the low-cost GPT-3.5 Turbo while exceeding the performance of the
next-best model using OpenAI, which instead uses the more expensive GPT-4.
Dubo-SQL v1 exceeds the performance of the next-best model using GPT-3.5 by
over 20%. Dubo-SQL v2 uses GPT-4 Turbo and RAG in place of fine tuning to push
EX higher.",2024-04-19,"Dayton G. Thorpe, Andrew J. Duberstein, Ian A. Kinsey",http://arxiv.org/pdf/2404.12560v1,cs.CL
Latent Concept-based Explanation of NLP Models,"Interpreting and understanding the predictions made by deep learning models
poses a formidable challenge due to their inherently opaque nature. Many
previous efforts aimed at explaining these predictions rely on input features,
specifically, the words within NLP models. However, such explanations are often
less informative due to the discrete nature of these words and their lack of
contextual verbosity. To address this limitation, we introduce the Latent
Concept Attribution method (LACOAT), which generates explanations for
predictions based on latent concepts. Our foundational intuition is that a word
can exhibit multiple facets, contingent upon the context in which it is used.
Therefore, given a word in context, the latent space derived from our training
process reflects a specific facet of that word. LACOAT functions by mapping the
representations of salient input words into the training latent space, allowing
it to provide latent context-based explanations of the prediction.",2024-04-18,"Xuemin Yu, Fahim Dalvi, Nadir Durrani, Marzia Nouri, Hassan Sajjad",http://arxiv.org/pdf/2404.12545v3,cs.CL
"Is There No Such Thing as a Bad Question? H4R: HalluciBot For Ratiocination, Rewriting, Ranking, and Routing","Hallucination continues to be one of the most critical challenges in the
institutional adoption journey of Large Language Models (LLMs). While prior
studies have primarily focused on the post-generation analysis and refinement
of outputs, this paper centers on the effectiveness of queries in eliciting
accurate responses from LLMs. We present HalluciBot, a model that estimates the
query's propensity to hallucinate before generation, without invoking any LLMs
during inference. HalluciBot can serve as a proxy reward model for query
rewriting, offering a general framework to estimate query quality based on
accuracy and consensus. In essence, HalluciBot investigates how poorly
constructed queries can lead to erroneous outputs - moreover, by employing
query rewriting guided by HalluciBot's empirical estimates, we demonstrate that
95.7% output accuracy can be achieved for Multiple Choice questions. The
training procedure for HalluciBot consists of perturbing 369,837 queries n
times, employing n+1 independent LLM agents, sampling an output from each
query, conducting a Multi-Agent Monte Carlo simulation on the sampled outputs,
and training an encoder classifier. The idea of perturbation is the outcome of
our ablation studies that measures the increase in output diversity (+12.5
agreement spread) by perturbing a query in lexically different but semantically
similar ways. Therefore, HalluciBot paves the way to ratiocinate (76.0% test F1
score, 46.6% in saved computation on hallucinatory queries), rewrite (+30.2%
positive class transition from hallucinatory to non-hallucinatory), rank
(+50.6% positive class transition from hallucinatory to non-hallucinatory), and
route queries to effective pipelines.",2024-04-18,"William Watson, Nicole Cho, Nishan Srishankar",http://arxiv.org/pdf/2404.12535v3,cs.CL
Adaptive Memory Replay for Continual Learning,"Foundation Models (FMs) have become the hallmark of modern AI, however, these
models are trained on massive data, leading to financially expensive training.
Updating FMs as new data becomes available is important, however, can lead to
`catastrophic forgetting', where models underperform on tasks related to data
sub-populations observed too long ago. This continual learning (CL) phenomenon
has been extensively studied, but primarily in a setting where only a small
amount of past data can be stored. We advocate for the paradigm where memory is
abundant, allowing us to keep all previous data, but computational resources
are limited. In this setting, traditional replay-based CL approaches are
outperformed by a simple baseline which replays past data selected uniformly at
random, indicating that this setting necessitates a new approach. We address
this by introducing a framework of adaptive memory replay for continual
learning, where sampling of past data is phrased as a multi-armed bandit
problem. We utilize Bolzmann sampling to derive a method which dynamically
selects past data for training conditioned on the current task, assuming full
data access and emphasizing training efficiency. Through extensive evaluations
on both vision and language pre-training tasks, we demonstrate the
effectiveness of our approach, which maintains high performance while reducing
forgetting by up to 10% at no training efficiency cost.",2024-04-18,"James Seale Smith, Lazar Valkov, Shaunak Halbe, Vyshnavi Gutta, Rogerio Feris, Zsolt Kira, Leonid Karlinsky",http://arxiv.org/pdf/2404.12526v1,cs.CL
UIClip: A Data-driven Model for Assessing User Interface Design,"User interface (UI) design is a difficult yet important task for ensuring the
usability, accessibility, and aesthetic qualities of applications. In our
paper, we develop a machine-learned model, UIClip, for assessing the design
quality and visual relevance of a UI given its screenshot and natural language
description. To train UIClip, we used a combination of automated crawling,
synthetic augmentation, and human ratings to construct a large-scale dataset of
UIs, collated by description and ranked by design quality. Through training on
the dataset, UIClip implicitly learns properties of good and bad designs by i)
assigning a numerical score that represents a UI design's relevance and quality
and ii) providing design suggestions. In an evaluation that compared the
outputs of UIClip and other baselines to UIs rated by 12 human designers, we
found that UIClip achieved the highest agreement with ground-truth rankings.
Finally, we present three example applications that demonstrate how UIClip can
facilitate downstream applications that rely on instantaneous assessment of UI
design quality: i) UI code generation, ii) UI design tips generation, and iii)
quality-aware UI example search.",2024-04-18,"Jason Wu, Yi-Hao Peng, Amanda Li, Amanda Swearngin, Jeffrey P. Bigham, Jeffrey Nichols",http://arxiv.org/pdf/2404.12500v1,cs.CL
BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models,"Predictive models often need to work with incomplete information in
real-world tasks. Consequently, they must provide reliable probability or
confidence estimation, especially in large-scale decision-making and planning
tasks. Current large language models (LLMs) are insufficient for accurate
estimations, but they can generate relevant factors that may affect the
probabilities, produce coarse-grained probabilities when the information is
more complete, and help determine which factors are relevant to specific
downstream contexts. In this paper, we make use of these capabilities of LLMs
to provide a significantly more accurate probabilistic estimation. We propose
BIRD, a novel probabilistic inference framework that aligns a Bayesian network
with LLM abductions and then estimates more accurate probabilities in a
deduction step. We show BIRD provides reliable probability estimations that are
30% better than those provided directly by LLM baselines. These estimates
further contribute to better and more trustworthy decision making.",2024-04-18,"Yu Feng, Ben Zhou, Weidong Lin, Dan Roth",http://arxiv.org/pdf/2404.12494v3,cs.CL
EnriCo: Enriched Representation and Globally Constrained Inference for Entity and Relation Extraction,"Joint entity and relation extraction plays a pivotal role in various
applications, notably in the construction of knowledge graphs. Despite recent
progress, existing approaches often fall short in two key aspects: richness of
representation and coherence in output structure. These models often rely on
handcrafted heuristics for computing entity and relation representations,
potentially leading to loss of crucial information. Furthermore, they disregard
task and/or dataset-specific constraints, resulting in output structures that
lack coherence. In our work, we introduce EnriCo, which mitigates these
shortcomings. Firstly, to foster rich and expressive representation, our model
leverage attention mechanisms that allow both entities and relations to
dynamically determine the pertinent information required for accurate
extraction. Secondly, we introduce a series of decoding algorithms designed to
infer the highest scoring solutions while adhering to task and dataset-specific
constraints, thus promoting structured and coherent outputs. Our model
demonstrates competitive performance compared to baselines when evaluated on
Joint IE datasets.",2024-04-18,"Urchade Zaratiana, Nadi Tomeh, Yann Dauxais, Pierre Holat, Thierry Charnois",http://arxiv.org/pdf/2404.12493v1,cs.CL
GraphER: A Structure-aware Text-to-Graph Model for Entity and Relation Extraction,"Information extraction (IE) is an important task in Natural Language
Processing (NLP), involving the extraction of named entities and their
relationships from unstructured text. In this paper, we propose a novel
approach to this task by formulating it as graph structure learning (GSL). By
formulating IE as GSL, we enhance the model's ability to dynamically refine and
optimize the graph structure during the extraction process. This formulation
allows for better interaction and structure-informed decisions for entity and
relation prediction, in contrast to previous models that have separate or
untied predictions for these tasks. When compared against state-of-the-art
baselines on joint entity and relation extraction benchmarks, our model,
GraphER, achieves competitive results.",2024-04-18,"Urchade Zaratiana, Nadi Tomeh, Niama El Khbir, Pierre Holat, Thierry Charnois",http://arxiv.org/pdf/2404.12491v1,cs.CL
Grammatical Error Correction for Code-Switched Sentences by Learners of English,"Code-switching (CSW) is a common phenomenon among multilingual speakers where
multiple languages are used in a single discourse or utterance. Mixed language
utterances may still contain grammatical errors however, yet most existing
Grammar Error Correction (GEC) systems have been trained on monolingual data
and not developed with CSW in mind. In this work, we conduct the first
exploration into the use of GEC systems on CSW text. Through this exploration,
we propose a novel method of generating synthetic CSW GEC datasets by
translating different spans of text within existing GEC corpora. We then
investigate different methods of selecting these spans based on CSW ratio,
switch-point factor and linguistic constraints, and identify how they affect
the performance of GEC systems on CSW text. Our best model achieves an average
increase of 1.57 $F_{0.5}$ across 3 CSW test sets (English-Chinese,
English-Korean and English-Japanese) without affecting the model's performance
on a monolingual dataset. We furthermore discovered that models trained on one
CSW language generalise relatively well to other typologically similar CSW
languages.",2024-04-18,"Kelvin Wey Han Chan, Christopher Bryant, Li Nguyen, Andrew Caines, Zheng Yuan",http://arxiv.org/pdf/2404.12489v2,cs.CL
Monitoring Critical Infrastructure Facilities During Disasters Using Large Language Models,"Critical Infrastructure Facilities (CIFs), such as healthcare and
transportation facilities, are vital for the functioning of a community,
especially during large-scale emergencies. In this paper, we explore a
potential application of Large Language Models (LLMs) to monitor the status of
CIFs affected by natural disasters through information disseminated in social
media networks. To this end, we analyze social media data from two disaster
events in two different countries to identify reported impacts to CIFs as well
as their impact severity and operational status. We employ state-of-the-art
open-source LLMs to perform computational tasks including retrieval,
classification, and inference, all in a zero-shot setting. Through extensive
experimentation, we report the results of these tasks using standard evaluation
metrics and reveal insights into the strengths and weaknesses of LLMs. We note
that although LLMs perform well in classification tasks, they encounter
challenges with inference tasks, especially when the context/prompt is complex
and lengthy. Additionally, we outline various potential directions for future
exploration that can be beneficial during the initial adoption phase of LLMs
for disaster response tasks.",2024-04-18,"Abdul Wahab Ziaullah, Ferda Ofli, Muhammad Imran",http://arxiv.org/pdf/2404.14432v1,cs.CL
NormAd: A Framework for Measuring the Cultural Adaptability of Large Language Models,"To be effectively and safely deployed to global user populations, large
language models (LLMs) may need to adapt outputs to user values and cultures,
not just know about them. We introduce NormAd, an evaluation framework to
assess LLMs' cultural adaptability, specifically measuring their ability to
judge social acceptability across varying levels of cultural norm specificity,
from abstract values to explicit social norms. As an instantiation of our
framework, we create NormAd-Eti, a benchmark of 2.6k situational descriptions
representing social-etiquette related cultural norms from 75 countries. Through
comprehensive experiments on NormAd-Eti, we find that LLMs struggle to
accurately judge social acceptability across these varying degrees of cultural
contexts and show stronger adaptability to English-centric cultures over those
from the Global South. Even in the simplest setting where the relevant social
norms are provided, the best LLMs' performance (< 82\%) lags behind humans (>
95\%). In settings with abstract values and country information, model
performance drops substantially (< 60\%), while human accuracy remains high (>
90\%). Furthermore, we find that models are better at recognizing socially
acceptable versus unacceptable situations. Our findings showcase the current
pitfalls in socio-cultural reasoning of LLMs which hinder their adaptability
for global audiences.",2024-04-18,"Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, Maarten Sap",http://arxiv.org/pdf/2404.12464v9,cs.CL
RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation,"Retrieval-Augmented Generation (RAG) has shown significant improvements in
various natural language processing tasks by integrating the strengths of large
language models (LLMs) and external knowledge databases. However, RAG
introduces long sequence generation and leads to high computation and memory
costs. We propose RAGCache, a novel multilevel dynamic caching system tailored
for RAG. Our analysis benchmarks current RAG systems, pinpointing the
performance bottleneck (i.e., long sequence due to knowledge injection) and
optimization opportunities (i.e., caching knowledge's intermediate states).
Based on these insights, we design RAGCache, which organizes the intermediate
states of retrieved knowledge in a knowledge tree and caches them in the GPU
and host memory hierarchy. RAGCache proposes a replacement policy that is aware
of LLM inference characteristics and RAG retrieval patterns. It also
dynamically overlaps the retrieval and inference steps to minimize the
end-to-end latency. We implement RAGCache and evaluate it on vLLM, a
state-of-the-art LLM inference system and Faiss, a state-of-the-art vector
database. The experimental results show that RAGCache reduces the time to first
token (TTFT) by up to 4x and improves the throughput by up to 2.1x compared to
vLLM integrated with Faiss.",2024-04-18,"Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe Liu, Xin Jin",http://arxiv.org/pdf/2404.12457v2,cs.CL
Characterizing LLM Abstention Behavior in Science QA with Context Perturbations,"The correct model response in the face of uncertainty is to abstain from
answering a question so as not to mislead the user. In this work, we study the
ability of LLMs to abstain from answering context-dependent science questions
when provided insufficient or incorrect context. We probe model sensitivity in
several settings: removing gold context, replacing gold context with irrelevant
context, and providing additional context beyond what is given. In experiments
on four QA datasets with six LLMs, we show that performance varies greatly
across models, across the type of context provided, and also by question type;
in particular, many LLMs seem unable to abstain from answering boolean
questions using standard QA prompts. Our analysis also highlights the
unexpected impact of abstention performance on QA task accuracy.
Counter-intuitively, in some settings, replacing gold context with irrelevant
context or adding irrelevant context to gold context can improve abstention
performance in a way that results in improvements in task performance. Our
results imply that changes are needed in QA dataset design and evaluation to
more effectively assess the correctness and downstream impacts of model
abstention.",2024-04-18,"Bingbing Wen, Bill Howe, Lucy Lu Wang",http://arxiv.org/pdf/2404.12452v2,cs.CL
AmbigDocs: Reasoning across Documents on Different Entities under the Same Name,"Different entities with the same name can be difficult to distinguish.
Handling confusing entity mentions is a crucial skill for language models
(LMs). For example, given the question ""Where was Michael Jordan educated?"" and
a set of documents discussing different people named Michael Jordan, can LMs
distinguish entity mentions to generate a cohesive answer to the question? To
test this ability, we introduce a new benchmark, AmbigDocs. By leveraging
Wikipedia's disambiguation pages, we identify a set of documents, belonging to
different entities who share an ambiguous name. From these documents, we
generate questions containing an ambiguous name and their corresponding sets of
answers. Our analysis reveals that current state-of-the-art models often yield
ambiguous answers or incorrectly merge information belonging to different
entities. We establish an ontology categorizing four types of incomplete
answers and automatic evaluation metrics to identify such categories. We lay
the foundation for future work on reasoning across multiple documents with
ambiguous entities.",2024-04-18,"Yoonsang Lee, Xi Ye, Eunsol Choi",http://arxiv.org/pdf/2404.12447v3,cs.CL
mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?,"Many pretrained multilingual models exhibit cross-lingual transfer ability,
which is often attributed to a learned language-neutral representation during
pretraining. However, it remains unclear what factors contribute to the
learning of a language-neutral representation, and whether the learned
language-neutral representation suffices to facilitate cross-lingual transfer.
We propose a synthetic task, Multilingual Othello (mOthello), as a testbed to
delve into these two questions. We find that: (1) models trained with naive
multilingual pretraining fail to learn a language-neutral representation across
all input languages; (2) the introduction of ""anchor tokens"" (i.e., lexical
items that are identical across languages) helps cross-lingual representation
alignment; and (3) the learning of a language-neutral representation alone is
not sufficient to facilitate cross-lingual transfer. Based on our findings, we
propose a novel approach - multilingual pretraining with unified output space -
that both induces the learning of language-neutral representation and
facilitates cross-lingual transfer.",2024-04-18,"Tianze Hua, Tian Yun, Ellie Pavlick",http://arxiv.org/pdf/2404.12444v1,cs.CL
BLINK: Multimodal Large Language Models Can See but Not Perceive,"We introduce Blink, a new benchmark for multimodal language models (LLMs)
that focuses on core visual perception abilities not found in other
evaluations. Most of the Blink tasks can be solved by humans ""within a blink""
(e.g., relative depth estimation, visual correspondence, forensics detection,
and multi-view reasoning). However, we find these perception-demanding tasks
cast significant challenges for current multimodal LLMs because they resist
mediation through natural language. Blink reformats 14 classic computer vision
tasks into 3,807 multiple-choice questions, paired with single or multiple
images and visual prompting. While humans get 95.70% accuracy on average, Blink
is surprisingly challenging for existing multimodal LLMs: even the
best-performing GPT-4V and Gemini achieve accuracies of 51.26% and 45.72%, only
13.17% and 7.63% higher than random guessing, indicating that such perception
abilities have not ""emerged"" yet in recent multimodal LLMs. Our analysis also
highlights that specialist CV models could solve these problems much better,
suggesting potential pathways for future improvements. We believe Blink will
stimulate the community to help multimodal LLMs catch up with human-level
visual perception.",2024-04-18,"Xingyu Fu, Yushi Hu, Bangzheng Li, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth, Noah A. Smith, Wei-Chiu Ma, Ranjay Krishna",http://arxiv.org/pdf/2404.12390v4,cs.CL
"Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models","We introduce Reka Core, Flash, and Edge, a series of powerful multimodal
language models trained from scratch by Reka. Reka models are able to process
and reason with text, images, video, and audio inputs. This technical report
discusses details of training some of these models and provides comprehensive
evaluation results. We show that Reka Edge and Reka Flash are not only
state-of-the-art but also outperform many much larger models, delivering
outsized values for their respective compute class. Meanwhile, our most capable
and largest model, Reka Core, approaches the best frontier models on both
automatic evaluations and blind human evaluations. On image question answering
benchmarks (e.g. MMMU, VQAv2), Core performs competitively to GPT4-V.
Meanwhile, on multimodal chat, Core ranks as the second most preferred model
under a blind third-party human evaluation setup, outperforming other models
such as Claude 3 Opus. On text benchmarks, Core not only performs competitively
to other frontier models on a set of well-established benchmarks (e.g. MMLU,
GSM8K) but also outperforms GPT4-0613 on human evaluation. On video question
answering (Perception-Test), Core outperforms Gemini Ultra. Models are shipped
in production at http://chat.reka.ai . A showcase of non cherry picked
qualitative examples can also be found at http://showcase.reka.ai .",2024-04-18,"Reka Team, Aitor Ormazabal, Che Zheng, Cyprien de Masson d'Autume, Dani Yogatama, Deyu Fu, Donovan Ong, Eric Chen, Eugenie Lamprecht, Hai Pham, Isaac Ong, Kaloyan Aleksiev, Lei Li, Matthew Henderson, Max Bain, Mikel Artetxe, Nishant Relan, Piotr Padlewski, Qi Liu, Ren Chen, Samuel Phua, Yazheng Yang, Yi Tay, Yuqi Wang, Zhongkai Zhu, Zhihui Xie",http://arxiv.org/pdf/2404.12387v1,cs.CL
When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes,"We present FastFit, a method, and a Python package design to provide fast and
accurate few-shot classification, especially for scenarios with many
semantically similar classes. FastFit utilizes a novel approach integrating
batch contrastive learning and token-level similarity score. Compared to
existing few-shot learning packages, such as SetFit, Transformers, or few-shot
prompting of large language models via API calls, FastFit significantly
improves multiclass classification performance in speed and accuracy across
FewMany, our newly curated English benchmark, and Multilingual datasets.
FastFit demonstrates a 3-20x improvement in training speed, completing training
in just a few seconds. The FastFit package is now available on GitHub and PyPi,
presenting a user-friendly solution for NLP practitioners.",2024-04-18,"Asaf Yehudai, Elron Bendel",http://arxiv.org/pdf/2404.12365v1,cs.CL
Large Language Models in Targeted Sentiment Analysis,"In this paper we investigate the use of decoder-based generative transformers
for extracting sentiment towards the named entities in Russian news articles.
We study sentiment analysis capabilities of instruction-tuned large language
models (LLMs). We consider the dataset of RuSentNE-2023 in our study. The first
group of experiments was aimed at the evaluation of zero-shot capabilities of
LLMs with closed and open transparencies. The second covers the fine-tuning of
Flan-T5 using the ""chain-of-thought"" (CoT) three-hop reasoning framework
(THoR). We found that the results of the zero-shot approaches are similar to
the results achieved by baseline fine-tuned encoder-based transformers
(BERT-base). Reasoning capabilities of the fine-tuned Flan-T5 models with THoR
achieve at least 5% increment with the base-size model compared to the results
of the zero-shot experiment. The best results of sentiment analysis on
RuSentNE-2023 were achieved by fine-tuned Flan-T5-xl, which surpassed the
results of previous state-of-the-art transformer-based classifiers. Our CoT
application framework is publicly available:
https://github.com/nicolay-r/Reasoning-for-Sentiment-Analysis-Framework",2024-04-18,"Nicolay Rusnachenko, Anton Golubev, Natalia Loukachevitch",http://arxiv.org/pdf/2404.12342v1,cs.CL
Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment,"Aligning language models (LMs) based on human-annotated preference data is a
crucial step in obtaining practical and performant LM-based systems. However,
multilingual human preference data are difficult to obtain at scale, making it
challenging to extend this framework to diverse languages. In this work, we
evaluate a simple approach for zero-shot cross-lingual alignment, where a
reward model is trained on preference data in one source language and directly
applied to other target languages. On summarization and open-ended dialog
generation, we show that this method is consistently successful under
comprehensive evaluation settings, including human evaluation: cross-lingually
aligned models are preferred by humans over unaligned models on up to >70% of
evaluation instances. We moreover find that a different-language reward model
sometimes yields better aligned models than a same-language reward model. We
also identify best practices when there is no language-specific data for even
supervised finetuning, another component in alignment.",2024-04-18,"Zhaofeng Wu, Ananth Balashankar, Yoon Kim, Jacob Eisenstein, Ahmad Beirami",http://arxiv.org/pdf/2404.12318v2,cs.CL
Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair,"In Simultaneous Machine Translation (SiMT) systems, training with a
simultaneous interpretation (SI) corpus is an effective method for achieving
high-quality yet low-latency systems. However, it is very challenging to curate
such a corpus due to limitations in the abilities of annotators, and hence,
existing SI corpora are limited. Therefore, we propose a method to convert
existing speech translation corpora into interpretation-style data, maintaining
the original word order and preserving the entire source content using Large
Language Models (LLM-SI-Corpus). We demonstrate that fine-tuning SiMT models in
text-to-text and speech-to-text settings with the LLM-SI-Corpus reduces
latencies while maintaining the same level of quality as the models trained
with offline datasets. The LLM-SI-Corpus is available at
\url{https://github.com/yusuke1997/LLM-SI-Corpus}.",2024-04-18,"Yusuke Sakai, Mana Makinae, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2404.12299v1,cs.CL
Augmenting emotion features in irony detection with Large language modeling,"This study introduces a novel method for irony detection, applying Large
Language Models (LLMs) with prompt-based learning to facilitate emotion-centric
text augmentation. Traditional irony detection techniques typically fall short
due to their reliance on static linguistic features and predefined knowledge
bases, often overlooking the nuanced emotional dimensions integral to irony. In
contrast, our methodology augments the detection process by integrating subtle
emotional cues, augmented through LLMs, into three benchmark pre-trained NLP
models - BERT, T5, and GPT-2 - which are widely recognized as foundational in
irony detection. We assessed our method using the SemEval-2018 Task 3 dataset
and observed substantial enhancements in irony detection capabilities.",2024-04-18,"Yucheng Lin, Yuhan Xia, Yunfei Long",http://arxiv.org/pdf/2404.12291v2,cs.CL
Resilience through Scene Context in Visual Referring Expression Generation,"Scene context is well known to facilitate humans' perception of visible
objects. In this paper, we investigate the role of context in Referring
Expression Generation (REG) for objects in images, where existing research has
often focused on distractor contexts that exert pressure on the generator. We
take a new perspective on scene context in REG and hypothesize that contextual
information can be conceived of as a resource that makes REG models more
resilient and facilitates the generation of object descriptions, and object
types in particular. We train and test Transformer-based REG models with target
representations that have been artificially obscured with noise to varying
degrees. We evaluate how properties of the models' visual context affect their
processing and performance. Our results show that even simple scene contexts
make models surprisingly resilient to perturbations, to the extent that they
can identify referent types even when visual information about the target is
completely missing.",2024-04-18,"Simeon Junker, Sina Zarrieß",http://arxiv.org/pdf/2404.12289v2,cs.CL
Enhancing Embedding Performance through Large Language Model-based Text Enrichment and Rewriting,"Embedding models are crucial for various natural language processing tasks
but can be limited by factors such as limited vocabulary, lack of context, and
grammatical errors. This paper proposes a novel approach to improve embedding
performance by leveraging large language models (LLMs) to enrich and rewrite
input text before the embedding process. By utilizing ChatGPT 3.5 to provide
additional context, correct inaccuracies, and incorporate metadata, the
proposed method aims to enhance the utility and accuracy of embedding models.
The effectiveness of this approach is evaluated on three datasets:
Banking77Classification, TwitterSemEval 2015, and Amazon Counter-factual
Classification. Results demonstrate significant improvements over the baseline
model on the TwitterSemEval 2015 dataset, with the best-performing prompt
achieving a score of 85.34 compared to the previous best of 81.52 on the
Massive Text Embedding Benchmark (MTEB) Leaderboard. However, performance on
the other two datasets was less impressive, highlighting the importance of
considering domain-specific characteristics. The findings suggest that
LLM-based text enrichment has shown promising results to improve embedding
performance, particularly in certain domains. Hence, numerous limitations in
the process of embedding can be avoided.",2024-04-18,"Nicholas Harris, Anand Butani, Syed Hashmy",http://arxiv.org/pdf/2404.12283v1,cs.CL
Advancing the Robustness of Large Language Models through Self-Denoised Smoothing,"Although large language models (LLMs) have achieved significant success,
their vulnerability to adversarial perturbations, including recent jailbreak
attacks, has raised considerable concerns. However, the increasing size of
these models and their limited access make improving their robustness a
challenging task. Among various defense strategies, randomized smoothing has
shown great potential for LLMs, as it does not require full access to the
model's parameters or fine-tuning via adversarial training. However, randomized
smoothing involves adding noise to the input before model prediction, and the
final model's robustness largely depends on the model's performance on these
noise corrupted data. Its effectiveness is often limited by the model's
sub-optimal performance on noisy data. To address this issue, we propose to
leverage the multitasking nature of LLMs to first denoise the noisy inputs and
then to make predictions based on these denoised versions. We call this
procedure self-denoised smoothing. Unlike previous denoised smoothing
techniques in computer vision, which require training a separate model to
enhance the robustness of LLMs, our method offers significantly better
efficiency and flexibility. Our experimental results indicate that our method
surpasses existing methods in both empirical and certified robustness in
defending against adversarial attacks for both downstream tasks and human
alignments (i.e., jailbreak attacks). Our code is publicly available at
https://github.com/UCSB-NLP-Chang/SelfDenoise",2024-04-18,"Jiabao Ji, Bairu Hou, Zhen Zhang, Guanhua Zhang, Wenqi Fan, Qing Li, Yang Zhang, Gaowen Liu, Sijia Liu, Shiyu Chang",http://arxiv.org/pdf/2404.12274v1,cs.CL
FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom,"Federated Learning (FL) has emerged as a promising solution for collaborative
training of large language models (LLMs). However, the integration of LLMs into
FL introduces new challenges, particularly concerning the evaluation of LLMs.
Traditional evaluation methods that rely on labeled test sets and
similarity-based metrics cover only a subset of the acceptable answers, thereby
failing to accurately reflect the performance of LLMs on generative tasks.
Meanwhile, although automatic evaluation methods that leverage advanced LLMs
present potential, they face critical risks of data leakage due to the need to
transmit data to external servers and suboptimal performance on downstream
tasks due to the lack of domain knowledge. To address these issues, we propose
a Federated Evaluation framework of Large Language Models, named FedEval-LLM,
that provides reliable performance measurements of LLMs on downstream tasks
without the reliance on labeled test sets and external tools, thus ensuring
strong privacy-preserving capability. FedEval-LLM leverages a consortium of
personalized LLMs from participants as referees to provide domain knowledge and
collective evaluation capability, thus aligning to the respective downstream
tasks and mitigating uncertainties and biases associated with a single referee.
Experimental results demonstrate a significant improvement in the evaluation
capability of personalized evaluation models on downstream tasks. When applied
to FL, these evaluation models exhibit strong agreement with human preference
and RougeL-score on meticulously curated test sets. FedEval-LLM effectively
overcomes the limitations of traditional metrics and the reliance on external
services, making it a promising framework for the evaluation of LLMs within
collaborative training scenarios.",2024-04-18,"Yuanqin He, Yan Kang, Lixin Fan, Qiang Yang",http://arxiv.org/pdf/2404.12273v1,cs.CL
"Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing","Despite the impressive capabilities of Large Language Models (LLMs) on
various tasks, they still struggle with scenarios that involves complex
reasoning and planning. Recent work proposed advanced prompting techniques and
the necessity of fine-tuning with high-quality data to augment LLMs' reasoning
abilities. However, these approaches are inherently constrained by data
availability and quality. In light of this, self-correction and self-learning
emerge as viable solutions, employing strategies that allow LLMs to refine
their outputs and learn from self-assessed rewards. Yet, the efficacy of LLMs
in self-refining its response, particularly in complex reasoning and planning
task, remains dubious. In this paper, we introduce AlphaLLM for the
self-improvements of LLMs, which integrates Monte Carlo Tree Search (MCTS) with
LLMs to establish a self-improving loop, thereby enhancing the capabilities of
LLMs without additional annotations. Drawing inspiration from the success of
AlphaGo, AlphaLLM addresses the unique challenges of combining MCTS with LLM
for self-improvement, including data scarcity, the vastness search spaces of
language tasks, and the subjective nature of feedback in language tasks.
AlphaLLM is comprised of prompt synthesis component, an efficient MCTS approach
tailored for language tasks, and a trio of critic models for precise feedback.
Our experimental results in mathematical reasoning tasks demonstrate that
AlphaLLM significantly enhances the performance of LLMs without additional
annotations, showing the potential for self-improvement in LLMs.",2024-04-18,"Ye Tian, Baolin Peng, Linfeng Song, Lifeng Jin, Dian Yu, Haitao Mi, Dong Yu",http://arxiv.org/pdf/2404.12253v2,cs.CL
CMNEE: A Large-Scale Document-Level Event Extraction Dataset based on Open-Source Chinese Military News,"Extracting structured event knowledge, including event triggers and
corresponding arguments, from military texts is fundamental to many
applications, such as intelligence analysis and decision assistance. However,
event extraction in the military field faces the data scarcity problem, which
impedes the research of event extraction models in this domain. To alleviate
this problem, we propose CMNEE, a large-scale, document-level open-source
Chinese Military News Event Extraction dataset. It contains 17,000 documents
and 29,223 events, which are all manually annotated based on a pre-defined
schema for the military domain including 8 event types and 11 argument role
types. We designed a two-stage, multi-turns annotation strategy to ensure the
quality of CMNEE and reproduced several state-of-the-art event extraction
models with a systematic evaluation. The experimental results on CMNEE fall
shorter than those on other domain datasets obviously, which demonstrates that
event extraction for military domain poses unique challenges and requires
further research efforts. Our code and data can be obtained from
https://github.com/Mzzzhu/CMNEE.",2024-04-18,"Mengna Zhu, Zijie Xu, Kaisheng Zeng, Kaiming Xiao, Mao Wang, Wenjun Ke, Hongbin Huang",http://arxiv.org/pdf/2404.12242v1,cs.CL
Introducing v0.5 of the AI Safety Benchmark from MLCommons,"This paper introduces v0.5 of the AI Safety Benchmark, which has been created
by the MLCommons AI Safety Working Group. The AI Safety Benchmark has been
designed to assess the safety risks of AI systems that use chat-tuned language
models. We introduce a principled approach to specifying and constructing the
benchmark, which for v0.5 covers only a single use case (an adult chatting to a
general-purpose assistant in English), and a limited set of personas (i.e.,
typical users, malicious users, and vulnerable users). We created a new
taxonomy of 13 hazard categories, of which 7 have tests in the v0.5 benchmark.
We plan to release version 1.0 of the AI Safety Benchmark by the end of 2024.
The v1.0 benchmark will provide meaningful insights into the safety of AI
systems. However, the v0.5 benchmark should not be used to assess the safety of
AI systems. We have sought to fully document the limitations, flaws, and
challenges of v0.5. This release of v0.5 of the AI Safety Benchmark includes
(1) a principled approach to specifying and constructing the benchmark, which
comprises use cases, types of systems under test (SUTs), language and context,
personas, tests, and test items; (2) a taxonomy of 13 hazard categories with
definitions and subcategories; (3) tests for seven of the hazard categories,
each comprising a unique set of test items, i.e., prompts. There are 43,090
test items in total, which we created with templates; (4) a grading system for
AI systems against the benchmark; (5) an openly available platform, and
downloadable tool, called ModelBench that can be used to evaluate the safety of
AI systems on the benchmark; (6) an example evaluation report which benchmarks
the performance of over a dozen openly available chat-tuned language models;
(7) a test specification for the benchmark.",2024-04-18,"Bertie Vidgen, Adarsh Agrawal, Ahmed M. Ahmed, Victor Akinwande, Namir Al-Nuaimi, Najla Alfaraj, Elie Alhajjar, Lora Aroyo, Trupti Bavalatti, Max Bartolo, Borhane Blili-Hamelin, Kurt Bollacker, Rishi Bomassani, Marisa Ferrara Boston, Siméon Campos, Kal Chakra, Canyu Chen, Cody Coleman, Zacharie Delpierre Coudert, Leon Derczynski, Debojyoti Dutta, Ian Eisenberg, James Ezick, Heather Frase, Brian Fuller, Ram Gandikota, Agasthya Gangavarapu, Ananya Gangavarapu, James Gealy, Rajat Ghosh, James Goel, Usman Gohar, Sujata Goswami, Scott A. Hale, Wiebke Hutiri, Joseph Marvin Imperial, Surgan Jandial, Nick Judd, Felix Juefei-Xu, Foutse Khomh, Bhavya Kailkhura, Hannah Rose Kirk, Kevin Klyman, Chris Knotz, Michael Kuchnik, Shachi H. Kumar, Srijan Kumar, Chris Lengerich, Bo Li, Zeyi Liao, Eileen Peters Long, Victor Lu, Sarah Luger, Yifan Mai, Priyanka Mary Mammen, Kelvin Manyeki, Sean McGregor, Virendra Mehta, Shafee Mohammed, Emanuel Moss, Lama Nachman, Dinesh Jinenhally Naganna, Amin Nikanjam, Besmira Nushi, Luis Oala, Iftach Orr, Alicia Parrish, Cigdem Patlak, William Pietri, Forough Poursabzi-Sangdeh, Eleonora Presani, Fabrizio Puletti, Paul Röttger, Saurav Sahay, Tim Santos, Nino Scherrer, Alice Schoenauer Sebag, Patrick Schramowski, Abolfazl Shahbazi, Vin Sharma, Xudong Shen, Vamsi Sistla, Leonard Tang, Davide Testuggine, Vithursan Thangarasa, Elizabeth Anne Watkins, Rebecca Weiss, Chris Welty, Tyler Wilbers, Adina Williams, Carole-Jean Wu, Poonam Yadav, Xianjun Yang, Yi Zeng, Wenhui Zhang, Fedor Zhdanov, Jiacheng Zhu, Percy Liang, Peter Mattson, Joaquin Vanschoren",http://arxiv.org/pdf/2404.12241v2,cs.CL
Length Generalization of Causal Transformers without Position Encoding,"Generalizing to longer sentences is important for recent Transformer-based
language models. Besides algorithms manipulating explicit position features,
the success of Transformers without position encodings (NoPE) provides a new
way to overcome the challenge. In this paper, we study the length
generalization property of NoPE. We find that although NoPE can extend to
longer sequences than the commonly used explicit position encodings, it still
has a limited context length. We identify a connection between the failure of
NoPE's generalization and the distraction of attention distributions. We
propose a parameter-efficient tuning for searching attention heads' best
temperature hyper-parameters, which substantially expands NoPE's context size.
Experiments on long sequence language modeling, the synthetic passkey retrieval
task and real-world long context tasks show that NoPE can achieve competitive
performances with state-of-the-art length generalization algorithms. The source
code is publicly accessible",2024-04-18,"Jie Wang, Tao Ji, Yuanbin Wu, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang, Xiaoling Wang",http://arxiv.org/pdf/2404.12224v2,cs.CL
"OpenBezoar: Small, Cost-Effective and Open Models Trained on Mixes of Instruction Data","Instruction fine-tuning pretrained LLMs for diverse downstream tasks has
demonstrated remarkable success and has captured the interest of both academics
and practitioners. To ensure such fine-tuned LLMs align with human preferences,
techniques such as RLHF and DPO have emerged. At the same time, there is
increasing interest in smaller parameter counts for models. In this work, using
OpenLLaMA 3Bv2 as a base model, we describe the recipe used to fine-tune the
OpenBezoar family of models. In this recipe: We first generate synthetic
instruction fine-tuning data using an open and commercially non-restrictive
instruction fine-tuned variant of the Falcon-40B model under three schemes
based on: LaMini-LM, WizardLM/Evol-Instruct (with databricks-dolly-15k as a
seed dataset) and Orca (with the Flan Collection as a seed dataset), then
filter these generations using GPT-4 as a human proxy. We then perform
cost-effective QLoRA-based supervised fine-tuning sequentially with each
scheme. The resulting checkpoint is further fine-tuned with a subset of the
HH-RLHF dataset to minimize distribution shift prior to using the DPO loss to
obtain the final checkpoint. Evaluation is done with the LM Eval Harness
tasks/metrics as well as on MT-Bench using the ""LLM-as-a-judge"" framework with
Claude 2.1, with the finding that the final checkpoint,
""OpenBezoar-HH-RLHF-DPO"", demonstrates superior performance over many models at
the 3B parameter scale, even outperforming the top model in one of the
categories on the Huggingface Open LLM Leaderboard. We release
""OpenBezoar-SFT"", ""OpenBezoar-HH-RLHF-SFT"", ""OpenBezoar-HH-RLHF-DPO""
checkpoints, alongside our generated datasets on HuggingFace at
https://huggingface.co/collections/SurgeGlobal/open-bezoar-6620a24923e12127e9e2b9cc
and our codebase at
https://bitbucket.org/paladinanalytics/workspace/projects/OP.",2024-04-18,"Chandeepa Dissanayake, Lahiru Lowe, Sachith Gunasekara, Yasiru Ratnayake",http://arxiv.org/pdf/2404.12195v1,cs.CL
EuSQuAD: Automatically Translated and Aligned SQuAD2.0 for Basque,"The widespread availability of Question Answering (QA) datasets in English
has greatly facilitated the advancement of the Natural Language Processing
(NLP) field. However, the scarcity of such resources for minority languages,
such as Basque, poses a substantial challenge for these communities. In this
context, the translation and alignment of existing QA datasets plays a crucial
role in narrowing this technological gap. This work presents EuSQuAD, the first
initiative dedicated to automatically translating and aligning SQuAD2.0 into
Basque, resulting in more than 142k QA examples. We demonstrate EuSQuAD's value
through extensive qualitative analysis and QA experiments supported with
EuSQuAD as training data. These experiments are evaluated with a new
human-annotated dataset.",2024-04-18,"Aitor García-Pablos, Naiara Perez, Montse Cuadros, Jaione Bengoetxea",http://arxiv.org/pdf/2404.12177v2,cs.CL
Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation Guidelines?,"The increasing threat of disinformation calls for automating parts of the
fact-checking pipeline. Identifying text segments requiring fact-checking is
known as claim detection (CD) and claim check-worthiness detection (CW), the
latter incorporating complex domain-specific criteria of worthiness and often
framed as a ranking task. Zero- and few-shot LLM prompting is an attractive
option for both tasks, as it bypasses the need for labeled datasets and allows
verbalized claim and worthiness criteria to be directly used for prompting. We
evaluate the LLMs' predictive and calibration accuracy on five CD/CW datasets
from diverse domains, each utilizing a different worthiness criterion. We
investigate two key aspects: (1) how best to distill factuality and worthiness
criteria into a prompt and (2) what amount of context to provide for each
claim. To this end, we experiment with varying the level of prompt verbosity
and the amount of contextual information provided to the model. Our results
show that optimal prompt verbosity is domain-dependent, adding context does not
improve performance, and confidence scores can be directly used to produce
reliable check-worthiness rankings.",2024-04-18,"Laura Majer, Jan Šnajder",http://arxiv.org/pdf/2404.12174v2,cs.CL
Stance Detection on Social Media with Fine-Tuned Large Language Models,"Stance detection, a key task in natural language processing, determines an
author's viewpoint based on textual analysis. This study evaluates the
evolution of stance detection methods, transitioning from early machine
learning approaches to the groundbreaking BERT model, and eventually to modern
Large Language Models (LLMs) such as ChatGPT, LLaMa-2, and Mistral-7B. While
ChatGPT's closed-source nature and associated costs present challenges, the
open-source models like LLaMa-2 and Mistral-7B offers an encouraging
alternative. Initially, our research focused on fine-tuning ChatGPT, LLaMa-2,
and Mistral-7B using several publicly available datasets. Subsequently, to
provide a comprehensive comparison, we assess the performance of these models
in zero-shot and few-shot learning scenarios. The results underscore the
exceptional ability of LLMs in accurately detecting stance, with all tested
models surpassing existing benchmarks. Notably, LLaMa-2 and Mistral-7B
demonstrate remarkable efficiency and potential for stance detection, despite
their smaller sizes compared to ChatGPT. This study emphasizes the potential of
LLMs in stance detection and calls for more extensive research in this field.",2024-04-18,"İlker Gül, Rémi Lebret, Karl Aberer",http://arxiv.org/pdf/2404.12171v1,cs.CL
FecTek: Enhancing Term Weight in Lexicon-Based Retrieval with Feature Context and Term-level Knowledge,"Lexicon-based retrieval has gained siginificant popularity in text retrieval
due to its efficient and robust performance. To further enhance performance of
lexicon-based retrieval, researchers have been diligently incorporating
state-of-the-art methodologies like Neural retrieval and text-level contrastive
learning approaches. Nonetheless, despite the promising outcomes, current
lexicon-based retrieval methods have received limited attention in exploring
the potential benefits of feature context representations and term-level
knowledge guidance. In this paper, we introduce an innovative method by
introducing FEature Context and TErm-level Knowledge modules(FecTek). To
effectively enrich the feature context representations of term weight, the
Feature Context Module (FCM) is introduced, which leverages the power of BERT's
representation to determine dynamic weights for each element in the embedding.
Additionally, we develop a term-level knowledge guidance module (TKGM) for
effectively utilizing term-level knowledge to intelligently guide the modeling
process of term weight. Evaluation of the proposed method on MS Marco benchmark
demonstrates its superiority over the previous state-of-the-art approaches.",2024-04-18,"Zunran Wang, Zhonghua Li, Wei Shen, Qi Ye, Liqiang Nie",http://arxiv.org/pdf/2404.12152v1,cs.CL
Aligning language models with human preferences,"Language models (LMs) trained on vast quantities of text data can acquire
sophisticated skills such as generating summaries, answering questions or
generating code. However, they also manifest behaviors that violate human
preferences, e.g., they can generate offensive content, falsehoods or
perpetuate social biases. In this thesis, I explore several approaches to
aligning LMs with human preferences. First, I argue that aligning LMs can be
seen as Bayesian inference: conditioning a prior (base, pretrained LM) on
evidence about human preferences (Chapter 2). Conditioning on human preferences
can be implemented in numerous ways. In Chapter 3, I investigate the relation
between two approaches to finetuning pretrained LMs using feedback given by a
scoring function: reinforcement learning from human feedback (RLHF) and
distribution matching. I show that RLHF can be seen as a special case of
distribution matching but distributional matching is strictly more general. In
chapter 4, I show how to extend the distribution matching to conditional
language models. Finally, in chapter 5 I explore a different root: conditioning
an LM on human preferences already during pretraining. I show that involving
human feedback from the very start tends to be more effective than using it
only during supervised finetuning. Overall, these results highlight the room
for alignment techniques different from and complementary to RLHF.",2024-04-18,Tomasz Korbak,http://arxiv.org/pdf/2404.12150v1,cs.CL
From Form(s) to Meaning: Probing the Semantic Depths of Language Models Using Multisense Consistency,"The staggering pace with which the capabilities of large language models
(LLMs) are increasing, as measured by a range of commonly used natural language
understanding (NLU) benchmarks, raises many questions regarding what
""understanding"" means for a language model and how it compares to human
understanding. This is especially true since many LLMs are exclusively trained
on text, casting doubt on whether their stellar benchmark performances are
reflective of a true understanding of the problems represented by these
benchmarks, or whether LLMs simply excel at uttering textual forms that
correlate with what someone who understands the problem would say. In this
philosophically inspired work, we aim to create some separation between form
and meaning, with a series of tests that leverage the idea that world
understanding should be consistent across presentational modes - inspired by
Fregean senses - of the same meaning. Specifically, we focus on consistency
across languages as well as paraphrases. Taking GPT-3.5 as our object of study,
we evaluate multisense consistency across five different languages and various
tasks. We start the evaluation in a controlled setting, asking the model for
simple facts, and then proceed with an evaluation on four popular NLU
benchmarks. We find that the model's multisense consistency is lacking and run
several follow-up analyses to verify that this lack of consistency is due to a
sense-dependent task understanding. We conclude that, in this aspect, the
understanding of LLMs is still quite far from being consistent and human-like,
and deliberate on how this impacts their utility in the context of learning
about human language and understanding.",2024-04-18,"Xenia Ohmer, Elia Bruni, Dieuwke Hupkes",http://arxiv.org/pdf/2404.12145v1,cs.CL
Non-Invasive Suicide Risk Prediction Through Speech Analysis,"The delayed access to specialized psychiatric assessments and care for
patients at risk of suicidal tendencies in emergency departments creates a
notable gap in timely intervention, hindering the provision of adequate mental
health support during critical situations. To address this, we present a
non-invasive, speech-based approach for automatic suicide risk assessment. For
our study, we collected a novel speech recording dataset from $20$ patients. We
extract three sets of features, including wav2vec, interpretable speech and
acoustic features, and deep learning-based spectral representations. We proceed
by conducting a binary classification to assess suicide risk in a
leave-one-subject-out fashion. Our most effective speech model achieves a
balanced accuracy of $66.2\,\%$. Moreover, we show that integrating our speech
model with a series of patients' metadata, such as the history of suicide
attempts or access to firearms, improves the overall result. The metadata
integration yields a balanced accuracy of $94.4\,\%$, marking an absolute
improvement of $28.2\,\%$, demonstrating the efficacy of our proposed
approaches for automatic suicide risk assessment in emergency medicine.",2024-04-18,"Shahin Amiriparian, Maurice Gerczuk, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, Alexander Kathan, Björn W. Schuller",http://arxiv.org/pdf/2404.12132v3,cs.CL
Ethical-Lens: Curbing Malicious Usages of Open-Source Text-to-Image Models,"The burgeoning landscape of text-to-image models, exemplified by innovations
such as Midjourney and DALLE 3, has revolutionized content creation across
diverse sectors. However, these advancements bring forth critical ethical
concerns, particularly with the misuse of open-source models to generate
content that violates societal norms. Addressing this, we introduce
Ethical-Lens, a framework designed to facilitate the value-aligned usage of
text-to-image tools without necessitating internal model revision. Ethical-Lens
ensures value alignment in text-to-image models across toxicity and bias
dimensions by refining user commands and rectifying model outputs. Systematic
evaluation metrics, combining GPT4-V, HEIM, and FairFace scores, assess
alignment capability. Our experiments reveal that Ethical-Lens enhances
alignment capabilities to levels comparable with or superior to commercial
models like DALLE 3, ensuring user-generated content adheres to ethical
standards while maintaining image quality. This study indicates the potential
of Ethical-Lens to ensure the sustainable development of open-source
text-to-image tools and their beneficial integration into society. Our code is
available at https://github.com/yuzhu-cai/Ethical-Lens.",2024-04-18,"Yuzhu Cai, Sheng Yin, Yuxi Wei, Chenxin Xu, Weibo Mao, Felix Juefei-Xu, Siheng Chen, Yanfeng Wang",http://arxiv.org/pdf/2404.12104v2,cs.CL
LongEmbed: Extending Embedding Models for Long Context Retrieval,"Embedding models play a pivot role in modern NLP applications such as IR and
RAG. While the context limit of LLMs has been pushed beyond 1 million tokens,
embedding models are still confined to a narrow context window not exceeding 8k
tokens, refrained from application scenarios requiring long inputs such as
legal contracts. This paper explores context window extension of existing
embedding models, pushing the limit to 32k without requiring additional
training. First, we examine the performance of current embedding models for
long context retrieval on our newly constructed LongEmbed benchmark. LongEmbed
comprises two synthetic tasks and four carefully chosen real-world tasks,
featuring documents of varying length and dispersed target information.
Benchmarking results underscore huge room for improvement in these models.
Based on this, comprehensive experiments show that training-free context window
extension strategies like position interpolation can effectively extend the
context window of existing embedding models by several folds, regardless of
their original context being 512 or beyond 4k. Furthermore, for models
employing absolute position encoding (APE), we show the possibility of further
fine-tuning to harvest notable performance gains while strictly preserving
original behavior for short inputs. For models using rotary position embedding
(RoPE), significant enhancements are observed when employing RoPE-specific
methods, such as NTK and SelfExtend, indicating RoPE's superiority over APE for
context window extension. To facilitate future research, we release E5-Base-4k
and E5-RoPE-Base, along with the LongEmbed benchmark.",2024-04-18,"Dawei Zhu, Liang Wang, Nan Yang, Yifan Song, Wenhao Wu, Furu Wei, Sujian Li",http://arxiv.org/pdf/2404.12096v3,cs.CL
TIMIT Speaker Profiling: A Comparison of Multi-task learning and Single-task learning Approaches,"This study employs deep learning techniques to explore four speaker profiling
tasks on the TIMIT dataset, namely gender classification, accent
classification, age estimation, and speaker identification, highlighting the
potential and challenges of multi-task learning versus single-task models. The
motivation for this research is twofold: firstly, to empirically assess the
advantages and drawbacks of multi-task learning over single-task models in the
context of speaker profiling; secondly, to emphasize the undiminished
significance of skillful feature engineering for speaker recognition tasks. The
findings reveal challenges in accent classification, and multi-task learning is
found advantageous for tasks of similar complexity. Non-sequential features are
favored for speaker recognition, but sequential ones can serve as starting
points for complex models. The study underscores the necessity of meticulous
experimentation and parameter tuning for deep learning models.",2024-04-18,"Rong Wang, Kun Sun",http://arxiv.org/pdf/2404.12077v1,cs.CL
"RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models","The escalating challenge of misinformation, particularly in political
discourse, requires advanced fact-checking solutions; this is even clearer in
the more complex scenario of multimodal claims. We tackle this issue using a
multimodal large language model in conjunction with retrieval-augmented
generation (RAG), and introduce two novel reasoning techniques: Chain of RAG
(CoRAG) and Tree of RAG (ToRAG). They fact-check multimodal claims by
extracting both textual and image content, retrieving external information, and
reasoning subsequent questions to be answered based on prior evidence. We
achieve a weighted F1-score of 0.85, surpassing a baseline reasoning technique
by 0.14 points. Human evaluation confirms that the vast majority of our
generated fact-check explanations contain all information from gold standard
data.",2024-04-18,"M. Abdul Khaliq, P. Chang, M. Ma, B. Pflugfelder, F. Miletić",http://arxiv.org/pdf/2404.12065v2,cs.CL
Unsupervised Parsing by Searching for Frequent Word Sequences among Sentences with Equivalent Predicate-Argument Structures,"Unsupervised constituency parsing focuses on identifying word sequences that
form a syntactic unit (i.e., constituents) in target sentences. Linguists
identify the constituent by evaluating a set of Predicate-Argument Structure
(PAS) equivalent sentences where we find the constituent appears more
frequently than non-constituents (i.e., the constituent corresponds to a
frequent word sequence within the sentence set). However, such frequency
information is unavailable in previous parsing methods that identify the
constituent by observing sentences with diverse PAS. In this study, we
empirically show that constituents correspond to frequent word sequences in the
PAS-equivalent sentence set. We propose a frequency-based parser span-overlap
that (1) computes the span-overlap score as the word sequence's frequency in
the PAS-equivalent sentence set and (2) identifies the constituent structure by
finding a constituent tree with the maximum span-overlap score. The parser
achieves state-of-the-art level parsing accuracy, outperforming existing
unsupervised parsers in eight out of ten languages. Additionally, we discover a
multilingual phenomenon: participant-denoting constituents tend to have higher
span-overlap scores than equal-length event-denoting constituents, meaning that
the former tend to appear more frequently in the PAS-equivalent sentence set
than the latter. The phenomenon indicates a statistical difference between the
two constituent types, laying the foundation for future labeled unsupervised
parsing research.",2024-04-18,"Junjie Chen, Xiangheng He, Danushka Bollegala, Yusuke Miyao",http://arxiv.org/pdf/2404.12059v2,cs.CL
"emrQA-msquad: A Medical Dataset Structured with the SQuAD V2.0 Framework, Enriched with emrQA Medical Information","Machine Reading Comprehension (MRC) holds a pivotal role in shaping Medical
Question Answering Systems (QAS) and transforming the landscape of accessing
and applying medical information. However, the inherent challenges in the
medical field, such as complex terminology and question ambiguity, necessitate
innovative solutions. One key solution involves integrating specialized medical
datasets and creating dedicated datasets. This strategic approach enhances the
accuracy of QAS, contributing to advancements in clinical decision-making and
medical research. To address the intricacies of medical terminology, a
specialized dataset was integrated, exemplified by a novel Span extraction
dataset derived from emrQA but restructured into 163,695 questions and 4,136
manually obtained answers, this new dataset was called emrQA-msquad dataset.
Additionally, for ambiguous questions, a dedicated medical dataset for the Span
extraction task was introduced, reinforcing the system's robustness. The
fine-tuning of models such as BERT, RoBERTa, and Tiny RoBERTa for medical
contexts significantly improved response accuracy within the F1-score range of
0.75 to 1.00 from 10.1% to 37.4%, 18.7% to 44.7% and 16.0% to 46.8%,
respectively. Finally, emrQA-msquad dataset is publicy available at
https://huggingface.co/datasets/Eladio/emrqa-msquad.",2024-04-18,"Jimenez Eladio, Hao Wu",http://arxiv.org/pdf/2404.12050v1,cs.CL
RAM: Towards an Ever-Improving Memory System by Learning from Communications,"We introduce an innovative RAG-based framework with an ever-improving memory.
Inspired by humans'pedagogical process, RAM utilizes recursively
reasoning-based retrieval and experience reflections to continually update the
memory and learn from users' communicative feedback, namely communicative
learning. Extensive experiments with both simulated and real users demonstrate
significant improvements over traditional RAG and self-knowledge methods,
particularly excelling in handling false premise and multi-hop questions.
Furthermore, RAM exhibits promising adaptability to various feedback and
retrieval methods, showcasing its potential for advancing AI capabilities in
dynamic knowledge acquisition and lifelong learning.",2024-04-18,"Jiaqi Li, Xiaobo Wang, Wentao Ding, Zihao Wang, Yipeng Kang, Zixia Jia, Zilong Zheng",http://arxiv.org/pdf/2404.12045v2,cs.CL
Exploring Boundaries and Intensities in Offensive and Hate Speech: Unveiling the Complex Spectrum of Social Media Discourse,"The prevalence of digital media and evolving sociopolitical dynamics have
significantly amplified the dissemination of hateful content. Existing studies
mainly focus on classifying texts into binary categories, often overlooking the
continuous spectrum of offensiveness and hatefulness inherent in the text. In
this research, we present an extensive benchmark dataset for Amharic,
comprising 8,258 tweets annotated for three distinct tasks: category
classification, identification of hate targets, and rating offensiveness and
hatefulness intensities. Our study highlights that a considerable majority of
tweets belong to the less offensive and less hate intensity levels,
underscoring the need for early interventions by stakeholders. The prevalence
of ethnic and political hatred targets, with significant overlaps in our
dataset, emphasizes the complex relationships within Ethiopia's sociopolitical
landscape. We build classification and regression models and investigate the
efficacy of models in handling these tasks. Our results reveal that hate and
offensive speech can not be addressed by a simplistic binary classification,
instead manifesting as variables across a continuous range of values. The
Afro-XLMR-large model exhibits the best performances achieving F1-scores of
75.30%, 70.59%, and 29.42% for the category, target, and regression tasks,
respectively. The 80.22% correlation coefficient of the Afro-XLMR-large model
indicates strong alignments.",2024-04-18,"Abinew Ali Ayele, Esubalew Alemneh Jalew, Adem Chanie Ali, Seid Muhie Yimam, Chris Biemann",http://arxiv.org/pdf/2404.12042v1,cs.CL
Can We Catch the Elephant? A Survey of the Evolvement of Hallucination Evaluation on Natural Language Generation,"Hallucination in Natural Language Generation (NLG) is like the elephant in
the room, obvious but often overlooked until recent achievements significantly
improved the fluency and grammaticality of generated text. As the capabilities
of text generation models have improved, researchers have begun to pay more
attention to the phenomenon of hallucination. Despite significant progress in
this field in recent years, the evaluation system for hallucination is complex
and diverse, lacking clear organization. We are the first to comprehensively
survey how various evaluation methods have evolved with the development of text
generation models from three dimensions, including hallucinated fact
granularity, evaluator design principles, and assessment facets. This survey
aims to help researchers identify current limitations in hallucination
evaluation and highlight future research directions.",2024-04-18,"Siya Qi, Yulan He, Zheng Yuan",http://arxiv.org/pdf/2404.12041v2,cs.CL
Uncovering Safety Risks of Large Language Models through Concept Activation Vector,"Despite careful safety alignment, current large language models (LLMs) remain
vulnerable to various attacks. To further unveil the safety risks of LLMs, we
introduce a Safety Concept Activation Vector (SCAV) framework, which
effectively guides the attacks by accurately interpreting LLMs' safety
mechanisms. We then develop an SCAV-guided attack method that can generate both
attack prompts and embedding-level attacks with automatically selected
perturbation hyperparameters. Both automatic and human evaluations demonstrate
that our attack method significantly improves the attack success rate and
response quality while requiring less training data. Additionally, we find that
our generated attack prompts may be transferable to GPT-4, and the
embedding-level attacks may also be transferred to other white-box LLMs whose
parameters are known. Our experiments further uncover the safety risks present
in current LLMs. For example, in our evaluation of seven open-source LLMs, we
observe an average attack success rate of 99.14%, based on the classic
keyword-matching criterion. Finally, we provide insights into the safety
mechanism of LLMs. The code is available at
https://github.com/SproutNan/AI-Safety_SCAV.",2024-04-18,"Zhihao Xu, Ruixuan Huang, Changyu Chen, Xiting Wang",http://arxiv.org/pdf/2404.12038v5,cs.CL
Parallel Decoding via Hidden Transfer for Lossless Large Language Model Acceleration,"Large language models (LLMs) have recently shown remarkable performance
across a wide range of tasks. However, the substantial number of parameters in
LLMs contributes to significant latency during model inference. This is
particularly evident when utilizing autoregressive decoding methods, which
generate one token in a single forward process, thereby not fully capitalizing
on the parallel computing capabilities of GPUs. In this paper, we propose a
novel parallel decoding approach, namely \textit{hidden transfer}, which
decodes multiple successive tokens simultaneously in a single forward pass. The
idea is to transfer the intermediate hidden states of the previous context to
the \textit{pseudo} hidden states of the future tokens to be generated, and
then the pseudo hidden states will pass the following transformer layers
thereby assimilating more semantic information and achieving superior
predictive accuracy of the future tokens.
  Besides, we use the novel tree attention mechanism to simultaneously generate
and verify multiple candidates of output sequences, which ensure the lossless
generation and further improves the generation efficiency of our method.
Experiments demonstrate the effectiveness of our method. We conduct a lot of
analytic experiments to prove our motivation. In terms of acceleration metrics,
we outperform all the single-model acceleration techniques, including Medusa
and Self-Speculative decoding.",2024-04-18,"Pengfei Wu, Jiahao Liu, Zhuocheng Gong, Qifan Wang, Jinpeng Li, Jingang Wang, Xunliang Cai, Dongyan Zhao",http://arxiv.org/pdf/2404.12022v1,cs.CL
Enhance Robustness of Language Models Against Variation Attack through Graph Integration,"The widespread use of pre-trained language models (PLMs) in natural language
processing (NLP) has greatly improved performance outcomes. However, these
models' vulnerability to adversarial attacks (e.g., camouflaged hints from drug
dealers), particularly in the Chinese language with its rich character
diversity/variation and complex structures, hatches vital apprehension. In this
study, we propose a novel method, CHinese vAriatioN Graph Enhancement (CHANGE),
to increase the robustness of PLMs against character variation attacks in
Chinese content. CHANGE presents a novel approach for incorporating a Chinese
character variation graph into the PLMs. Through designing different
supplementary tasks utilizing the graph structure, CHANGE essentially enhances
PLMs' interpretation of adversarially manipulated text. Experiments conducted
in a multitude of NLP tasks show that CHANGE outperforms current language
models in combating against adversarial attacks and serves as a valuable
contribution to robust language model research. These findings contribute to
the groundwork on robust language models and highlight the substantial
potential of graph-guided pre-training strategies for real-world applications.",2024-04-18,"Zi Xiong, Lizhi Qing, Yangyang Kang, Jiawei Liu, Hongsong Li, Changlong Sun, Xiaozhong Liu, Wei Lu",http://arxiv.org/pdf/2404.12014v1,cs.CL
Sequential Compositional Generalization in Multimodal Models,"The rise of large-scale multimodal models has paved the pathway for
groundbreaking advances in generative modeling and reasoning, unlocking
transformative applications in a variety of complex tasks. However, a pressing
question that remains is their genuine capability for stronger forms of
generalization, which has been largely underexplored in the multimodal setting.
Our study aims to address this by examining sequential compositional
generalization using \textsc{CompAct} (\underline{Comp}ositional
\underline{Act}ivities)\footnote{Project Page:
\url{http://cyberiada.github.io/CompAct}}, a carefully constructed,
perceptually grounded dataset set within a rich backdrop of egocentric kitchen
activity videos. Each instance in our dataset is represented with a combination
of raw video footage, naturally occurring sound, and crowd-sourced step-by-step
descriptions. More importantly, our setup ensures that the individual concepts
are consistently distributed across training and evaluation sets, while their
compositions are novel in the evaluation set. We conduct a comprehensive
assessment of several unimodal and multimodal models. Our findings reveal that
bi-modal and tri-modal models exhibit a clear edge over their text-only
counterparts. This highlights the importance of multimodality while charting a
trajectory for future research in this domain.",2024-04-18,"Semih Yagcioglu, Osman Batur İnce, Aykut Erdem, Erkut Erdem, Desmond Elliott, Deniz Yuret",http://arxiv.org/pdf/2404.12013v1,cs.CL
ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity,"Paraphrase generation is a pivotal task in natural language processing (NLP).
Existing datasets in the domain lack syntactic and lexical diversity, resulting
in paraphrases that closely resemble the source sentences. Moreover, these
datasets often contain hate speech and noise, and may unintentionally include
non-English language sentences. This research introduces ParaFusion, a
large-scale, high-quality English paraphrase dataset developed using Large
Language Models (LLM) to address these challenges. ParaFusion augments existing
datasets with high-quality data, significantly enhancing both lexical and
syntactic diversity while maintaining close semantic similarity. It also
mitigates the presence of hate speech and reduces noise, ensuring a cleaner and
more focused English dataset. Results show that ParaFusion offers at least a
25% improvement in both syntactic and lexical diversity, measured across
several metrics for each data source. The paper also aims to set a gold
standard for paraphrase evaluation as it contains one of the most comprehensive
evaluation strategies to date. The results underscore the potential of
ParaFusion as a valuable resource for improving NLP applications.",2024-04-18,"Lasal Jayawardena, Prasan Yapa",http://arxiv.org/pdf/2404.12010v1,cs.CL
Variational Multi-Modal Hypergraph Attention Network for Multi-Modal Relation Extraction,"Multi-modal relation extraction (MMRE) is a challenging task that aims to
identify relations between entities in text leveraging image information.
Existing methods are limited by their neglect of the multiple entity pairs in
one sentence sharing very similar contextual information (ie, the same text and
image), resulting in increased difficulty in the MMRE task. To address this
limitation, we propose the Variational Multi-Modal Hypergraph Attention Network
(VM-HAN) for multi-modal relation extraction. Specifically, we first construct
a multi-modal hypergraph for each sentence with the corresponding image, to
establish different high-order intra-/inter-modal correlations for different
entity pairs in each sentence. We further design the Variational Hypergraph
Attention Networks (V-HAN) to obtain representational diversity among different
entity pairs using Gaussian distribution and learn a better hypergraph
structure via variational attention. VM-HAN achieves state-of-the-art
performance on the multi-modal relation extraction task, outperforming existing
methods in terms of accuracy and efficiency.",2024-04-18,"Qian Li, Cheng Ji, Shu Guo, Yong Zhao, Qianren Mao, Shangguang Wang, Yuntao Wei, Jianxin Li",http://arxiv.org/pdf/2404.12006v1,cs.CL
Token-level Direct Preference Optimization,"Fine-tuning pre-trained Large Language Models (LLMs) is essential to align
them with human values and intentions. This process often utilizes methods like
pairwise comparisons and KL divergence against a reference LLM, focusing on the
evaluation of full answers generated by the models. However, the generation of
these responses occurs in a token level, following a sequential,
auto-regressive fashion. In this paper, we introduce Token-level Direct
Preference Optimization (TDPO), a novel approach to align LLMs with human
preferences by optimizing policy at the token level. Unlike previous methods,
which face challenges in divergence efficiency, TDPO incorporates forward KL
divergence constraints for each token, improving alignment and diversity.
Utilizing the Bradley-Terry model for a token-based reward system, TDPO
enhances the regulation of KL divergence, while preserving simplicity without
the need for explicit reward modeling. Experimental results across various text
tasks demonstrate TDPO's superior performance in balancing alignment with
generation diversity. Notably, fine-tuning with TDPO strikes a better balance
than DPO in the controlled sentiment generation and single-turn dialogue
datasets, and significantly improves the quality of generated responses
compared to both DPO and PPO-based RLHF methods. Our code is open-sourced at
https://github.com/Vance0124/Token-level-Direct-Preference-Optimization.",2024-04-18,"Yongcheng Zeng, Guoqing Liu, Weiyu Ma, Ning Yang, Haifeng Zhang, Jun Wang",http://arxiv.org/pdf/2404.11999v5,cs.CL
EVIT: Event-Oriented Instruction Tuning for Event Reasoning,"Events refer to specific occurrences, incidents, or happenings that take
place under a particular background. Event reasoning aims to infer events
according to certain relations and predict future events. The cutting-edge
techniques for event reasoning play a crucial role in various natural language
processing applications. Large language models (LLMs) have made significant
advancements in event reasoning owing to their wealth of knowledge and
reasoning capabilities. However, smaller instruction-tuned models currently in
use do not consistently demonstrate exceptional proficiency in managing these
tasks. This discrepancy arises from the absence of explicit modeling of events
and the interconnections of them within their instruction data. Consequently,
these models face challenges in comprehending event structures and semantics
while struggling to bridge the gap between their interpretations and human
understanding of events. Additionally, their limitations in grasping event
relations lead to constrained event reasoning abilities to effectively deduce
and incorporate pertinent event knowledge. In this paper, we propose
Event-Oriented Instruction Tuning (EvIT) to train our LLM. Specifically, we
first propose a novel structure named event quadruple which contains the
structure and semantics of events and is complete in the event representation.
We then design event-relation learning based on the structures. We encapsulate
the learning into the instruction-tuning formulation to better stimulate the
event reasoning capacity of our model. We design a heuristic unsupervised
method to mine event quadruple from a large-scale corpus. At last, we finetune
a Llama model on our Event-Oriented Instruction Tuning. We conduct extensive
experiments on event reasoning tasks on several datasets. Automatic and human
evaluations demonstrate EvIT achieves competitive performances on event
reasoning.",2024-04-18,"Zhengwei Tao, Xiancai Chen, Zhi Jin, Xiaoying Bai, Haiyan Zhao, Yiwei Lou",http://arxiv.org/pdf/2404.11978v1,cs.CL
Aligning Language Models to Explicitly Handle Ambiguity,"In interactions between users and language model agents, user utterances
frequently exhibit ellipsis (omission of words or phrases) or imprecision (lack
of exactness) to prioritize efficiency. This can lead to varying
interpretations of the same input based on different assumptions or background
knowledge. It is thus crucial for agents to adeptly handle the inherent
ambiguity in queries to ensure reliability. However, even state-of-the-art
large language models (LLMs) still face challenges in such scenarios, primarily
due to the following hurdles: (1) LLMs are not explicitly trained to deal with
ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may
vary depending on the possessed knowledge. To address these issues, we propose
Alignment with Perceived Ambiguity (APA), a novel pipeline that aligns LLMs to
manage ambiguous queries by leveraging their own assessment of ambiguity (i.e.,
perceived ambiguity). Experimental results on question-answering datasets
demonstrate that APA empowers LLMs to explicitly detect and manage ambiguous
queries while retaining the ability to answer clear questions. Furthermore, our
finding proves that APA excels beyond training with gold-standard labels,
especially in out-of-distribution scenarios. The data and code are available at
https://github.com/heyjoonkim/APA.",2024-04-18,"Hyuhng Joon Kim, Youna Kim, Cheonbok Park, Junyeob Kim, Choonghyun Park, Kang Min Yoo, Sang-goo Lee, Taeuk Kim",http://arxiv.org/pdf/2404.11972v3,cs.CL
NALA: an Effective and Interpretable Entity Alignment Method,"Entity alignment (EA) aims to find equivalent entities between two Knowledge
Graphs. Existing embedding-based EA methods usually encode entities as
embeddings, triples as embeddings' constraint and learn to align the
embeddings. However, the details of the underlying logical inference steps
among the alignment process are usually omitted, resulting in inadequate
inference process. In this paper, we introduce NALA, an entity alignment method
that captures three types of logical inference paths with Non-Axiomatic Logic
(NAL). Type 1&2 align the entity pairs and type 3 aligns relations. NALA
iteratively aligns entities and relations by integrating the conclusions of the
inference paths. Our method is logically interpretable and extensible by
introducing NAL, and thus suitable for various EA settings. Experimental
results show that NALA outperforms state-of-the-art methods in terms of Hits@1,
achieving 0.98+ on all three datasets of DBP15K with both supervised and
unsupervised settings. We offer a pioneering in-depth analysis of the
fundamental principles of entity alignment, approaching the subject from a
unified and logical perspective. Our code is available at
https://github.com/13998151318/NALA.",2024-04-18,"Chuanhao Xu, Jingwei Cheng, Fu Zhang",http://arxiv.org/pdf/2404.11968v2,cs.CL
CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignment,"Multilingual proficiency presents a significant challenge for large language
models (LLMs). English-centric models are usually suboptimal in other
languages, particularly those that are linguistically distant from English.
This performance discrepancy mainly stems from the imbalanced distribution of
training data across languages during pre-training and instruction tuning
stages. To address this problem, we propose a novel approach called CrossIn,
which utilizes a mixed composition of cross-lingual instruction tuning data.
Our method leverages the compressed representation shared by various languages
to efficiently enhance the model's task-solving capabilities and multilingual
proficiency within a single process. In addition, we introduce a multi-task and
multi-faceted benchmark to evaluate the effectiveness of CrossIn. Experimental
results demonstrate that our method substantially improves performance across
tasks and languages, and we provide extensive insights into the impact of
cross-lingual data volume and the integration of translation data on enhancing
multilingual consistency and accuracy.",2024-04-18,"Geyu Lin, Bin Wang, Zhengyuan Liu, Nancy F. Chen",http://arxiv.org/pdf/2404.11932v3,cs.CL
Skeleton: A New Framework for Accelerating Language Models via Task Neuron Localized Prompt Tuning,"Prompt tuning methods have shown comparable performance to general training
methods as parameter-efficient fine-tuning (PEFT) methods in various natural
language understanding tasks. However, existing prompt tuning methods still
utilize the entire model architecture even when solving a specific task, which
prevents them from accelerating inference speed during the application
procedure. In this paper, we propose a novel prompt tuning framework called
Skeleton to efficiently utilize a language model in terms of memory and time
complexity for solving various tasks, retaining only task-relevant neurons by
using an explainability method. From our framework, we can efficiently solve
various tasks by using only task-relevant neurons and prepending adequate
task-specific prompt tokens with only a single language model. Experiments
reveal that our method significantly enhances inference efficiency (at most x
1.73 speed up) for various widely used benchmarks, showing comparable
performance to the prompt tuning method. Moreover, our method is applicable
across various transformer-based architectures, confirming its practicality and
scalability.",2024-04-18,"Nakyeong Yang, Jiwon Moon, Junseok Kim, Yunah Jang, Kyomin Jung",http://arxiv.org/pdf/2404.11916v2,cs.CL
TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding,"With large language models (LLMs) widely deployed in long content generation
recently, there has emerged an increasing demand for efficient long-sequence
inference support. However, key-value (KV) cache, which is stored to avoid
re-computation, has emerged as a critical bottleneck by growing linearly in
size with the sequence length. Due to the auto-regressive nature of LLMs, the
entire KV cache will be loaded for every generated token, resulting in low
utilization of computational cores and high latency. While various compression
methods for KV cache have been proposed to alleviate this issue, they suffer
from degradation in generation quality. We introduce TriForce, a hierarchical
speculative decoding system that is scalable for long sequence generation. This
approach leverages the original model weights and dynamic sparse KV cache via
retrieval as a draft model, which serves as an intermediate layer in the
hierarchy and is further speculated by a smaller model to reduce its drafting
latency. TriForce not only facilitates impressive speedups for Llama2-7B-128K,
achieving up to 2.31$\times$ on an A100 GPU but also showcases scalability in
handling even longer contexts. For the offloading setting on two RTX 4090 GPUs,
TriForce achieves 0.108s/token$\unicode{x2014}$only half as slow as the
auto-regressive baseline on an A100, which attains 7.78$\times$ on our
optimized offloading system. Additionally, TriForce performs 4.86$\times$ than
DeepSpeed-Zero-Inference on a single RTX 4090 GPU. TriForce's robustness is
highlighted by its consistently outstanding performance across various
temperatures. The code is available at
https://github.com/Infini-AI-Lab/TriForce.",2024-04-18,"Hanshi Sun, Zhuoming Chen, Xinyu Yang, Yuandong Tian, Beidi Chen",http://arxiv.org/pdf/2404.11912v3,cs.CL
Large Language Models Can Solve Real-World Planning Rigorously with Formal Verification Tools,"Large Language Models (LLMs) struggle to directly generate correct plans for
complex multi-constraint planning problems, even with self-verification and
self-critique. For example, a U.S. domestic travel planning benchmark
TravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAI
o1-preview can only find viable travel plans with a 10% success rate given all
needed information. In this work, we tackle this by proposing an LLM-based
planning framework that formalizes and solves complex multi-constraint planning
problems as constrained satisfiability problems, which are further consumed by
sound and complete satisfiability solvers. We start with TravelPlanner as the
primary use case and show that our framework achieves a success rate of 93.9%
and is effective with diverse paraphrased prompts. More importantly, our
framework has strong zero-shot generalizability, successfully handling unseen
constraints in our newly created unseen international travel dataset and
generalizing well to new fundamentally different domains. Moreover, when user
input queries are infeasible, our framework can identify the unsatisfiable
core, provide failure reasons, and offers personalized modification
suggestions. We show that our framework can modify and solve for an average of
81.6% and 91.7% unsatisfiable queries from two datasets and prove with
ablations that all key components of our framework are effective and necessary.
Project page: https://sites.google.com/view/llm-rwplanning.",2024-04-18,"Yilun Hao, Yongchao Chen, Yang Zhang, Chuchu Fan",http://arxiv.org/pdf/2404.11891v3,cs.CL
Enhancing Length Extrapolation in Sequential Models with Pointer-Augmented Neural Memory,"We propose Pointer-Augmented Neural Memory (PANM) to help neural networks
understand and apply symbol processing to new, longer sequences of data. PANM
integrates an external neural memory that uses novel physical addresses and
pointer manipulation techniques to mimic human and computer symbol processing
abilities. PANM facilitates pointer assignment, dereference, and arithmetic by
explicitly using physical pointers to access memory content. Remarkably, it can
learn to perform these operations through end-to-end training on sequence data,
powering various sequential models. Our experiments demonstrate PANM's
exceptional length extrapolating capabilities and improved performance in tasks
that require symbol processing, such as algorithmic reasoning and Dyck language
recognition. PANM helps Transformer achieve up to 100% generalization accuracy
in compositional learning tasks and significantly better results in
mathematical reasoning, question answering and machine translation tasks.",2024-04-18,"Hung Le, Dung Nguyen, Kien Do, Svetha Venkatesh, Truyen Tran",http://arxiv.org/pdf/2404.11870v1,cs.CL
Challenging Negative Gender Stereotypes: A Study on the Effectiveness of Automated Counter-Stereotypes,"Gender stereotypes are pervasive beliefs about individuals based on their
gender that play a significant role in shaping societal attitudes, behaviours,
and even opportunities. Recognizing the negative implications of gender
stereotypes, particularly in online communications, this study investigates
eleven strategies to automatically counter-act and challenge these views. We
present AI-generated gender-based counter-stereotypes to (self-identified) male
and female study participants and ask them to assess their offensiveness,
plausibility, and potential effectiveness. The strategies of counter-facts and
broadening universals (i.e., stating that anyone can have a trait regardless of
group membership) emerged as the most robust approaches, while humour,
perspective-taking, counter-examples, and empathy for the speaker were
perceived as less effective. Also, the differences in ratings were more
pronounced for stereotypes about the different targets than between the genders
of the raters. Alarmingly, many AI-generated counter-stereotypes were perceived
as offensive and/or implausible. Our analysis and the collected dataset offer
foundational insight into counter-stereotype generation, guiding future efforts
to develop strategies that effectively challenge gender stereotypes in online
interactions.",2024-04-18,"Isar Nejadgholi, Kathleen C. Fraser, Anna Kerkhof, Svetlana Kiritchenko",http://arxiv.org/pdf/2404.11845v1,cs.CL
AdvisorQA: Towards Helpful and Harmless Advice-seeking Question Answering with Collective Intelligence,"As the integration of large language models into daily life is on the rise,
there is a clear gap in benchmarks for advising on subjective and personal
dilemmas. To address this, we introduce AdvisorQA, the first benchmark
developed to assess LLMs' capability in offering advice for deeply personalized
concerns, utilizing the LifeProTips subreddit forum. This forum features a
dynamic interaction where users post advice-seeking questions, receiving an
average of 8.9 advice per query, with 164.2 upvotes from hundreds of users,
embodying a collective intelligence framework. Therefore, we've completed a
benchmark encompassing daily life questions, diverse corresponding responses,
and majority vote ranking to train our helpfulness metric. Baseline experiments
validate the efficacy of AdvisorQA through our helpfulness metric, GPT-4, and
human evaluation, analyzing phenomena beyond the trade-off between helpfulness
and harmlessness. AdvisorQA marks a significant leap in enhancing QA systems
for providing personalized, empathetic advice, showcasing LLMs' improved
understanding of human subjectivity.",2024-04-18,"Minbeom Kim, Hwanhee Lee, Joonsuk Park, Hwaran Lee, Kyomin Jung",http://arxiv.org/pdf/2404.11826v2,cs.CL
Autoformalizing Natural Language to First-Order Logic: A Case Study in Logical Fallacy Detection,"Translating natural language into formal language such as First-Order Logic
(FOL) is a foundational challenge in NLP with wide-ranging applications in
automated reasoning, misinformation tracking, and knowledge validation. In this
paper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework
to autoformalize natural language to FOL step by step using Large Language
Models (LLMs). Our approach addresses key challenges in this translation
process, including the integration of implicit background knowledge. By
leveraging structured representations generated by NL2FOL, we use
Satisfiability Modulo Theory (SMT) solvers to reason about the logical validity
of natural language statements. We present logical fallacy detection as a case
study to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach
also provides interpretable insights into the reasoning process and
demonstrates robustness without requiring model fine-tuning or labeled training
data. Our framework achieves strong performance on multiple datasets. On the
LOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing
effectively to the LOGICCLIMATE dataset with an F1-score of 80%.",2024-04-18,"Abhinav Lalwani, Tasha Kim, Lovish Chopra, Christopher Hahn, Zhijing Jin, Mrinmaya Sachan",http://arxiv.org/pdf/2405.02318v3,cs.CL
Sharing Parameter by Conjugation for Knowledge Graph Embeddings in Complex Space,"A Knowledge Graph (KG) is the directed graphical representation of entities
and relations in the real world. KG can be applied in diverse Natural Language
Processing (NLP) tasks where knowledge is required. The need to scale up and
complete KG automatically yields Knowledge Graph Embedding (KGE), a shallow
machine learning model that is suffering from memory and training time
consumption issues. To mitigate the computational load, we propose a
parameter-sharing method, i.e., using conjugate parameters for complex numbers
employed in KGE models. Our method improves memory efficiency by 2x in relation
embedding while achieving comparable performance to the state-of-the-art
non-conjugate models, with faster, or at least comparable, training time. We
demonstrated the generalizability of our method on two best-performing KGE
models $5^{\bigstar}\mathrm{E}$ and $\mathrm{ComplEx}$ on five benchmark
datasets.",2024-04-18,"Xincan Feng, Zhi Qu, Yuchang Cheng, Taro Watanabe, Nobuhiro Yugami",http://arxiv.org/pdf/2404.11809v1,cs.CL
Enhancing Argument Summarization: Prioritizing Exhaustiveness in Key Point Generation and Introducing an Automatic Coverage Evaluation Metric,"The proliferation of social media platforms has given rise to the amount of
online debates and arguments. Consequently, the need for automatic
summarization methods for such debates is imperative, however this area of
summarization is rather understudied. The Key Point Analysis (KPA) task
formulates argument summarization as representing the summary of a large
collection of arguments in the form of concise sentences in bullet-style
format, called key points. A sub-task of KPA, called Key Point Generation
(KPG), focuses on generating these key points given the arguments. This paper
introduces a novel extractive approach for key point generation, that
outperforms previous state-of-the-art methods for the task. Our method utilizes
an extractive clustering based approach that offers concise, high quality
generated key points with higher coverage of reference summaries, and less
redundant outputs. In addition, we show that the existing evaluation metrics
for summarization such as ROUGE are incapable of differentiating between
generated key points of different qualities. To this end, we propose a new
evaluation metric for assessing the generated key points by their coverage. Our
code can be accessed online.",2024-04-17,"Mohammad Khosravani, Chenyang Huang, Amine Trabelsi",http://arxiv.org/pdf/2404.11793v1,cs.CL
REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models,"The extensive scope of large language models (LLMs) across various domains
underscores the critical importance of responsibility in their application,
beyond natural language processing. In particular, the randomized nature of
LLMs, coupled with inherent biases and historical stereotypes in data, raises
critical concerns regarding reliability and equity. Addressing these challenges
are necessary before using LLMs for applications with societal impact. Towards
addressing this gap, we introduce REQUAL-LM, a novel method for finding
reliable and equitable LLM outputs through aggregation. Specifically, we
develop a Monte Carlo method based on repeated sampling to find a reliable
output close to the mean of the underlying distribution of possible outputs. We
formally define the terms such as reliability and bias, and design an
equity-aware aggregation to minimize harmful bias while finding a highly
reliable output. REQUAL-LM does not require specialized hardware, does not
impose a significant computing load, and uses LLMs as a blackbox. This design
choice enables seamless scalability alongside the rapid advancement of LLM
technologies. Our system does not require retraining the LLMs, which makes it
deployment ready and easy to adapt. Our comprehensive experiments using various
tasks and datasets demonstrate that REQUAL- LM effectively mitigates bias and
selects a more equitable response, specifically the outputs that properly
represents minority groups.",2024-04-17,"Sana Ebrahimi, Nima Shahbazi, Abolfazl Asudeh",http://arxiv.org/pdf/2404.11782v1,cs.CL
Language Models Still Struggle to Zero-shot Reason about Time Series,"Time series are critical for decision-making in fields like finance and
healthcare. Their importance has driven a recent influx of works passing time
series into language models, leading to non-trivial forecasting on some
datasets. But it remains unknown whether non-trivial forecasting implies that
language models can reason about time series. To address this gap, we generate
a first-of-its-kind evaluation framework for time series reasoning, including
formal tasks and a corresponding dataset of multi-scale time series paired with
text captions across ten domains. Using these data, we probe whether language
models achieve three forms of reasoning: (1) Etiological Reasoning - given an
input time series, can the language model identify the scenario that most
likely created it? (2) Question Answering - can a language model answer factual
questions about time series? (3) Context-Aided Forecasting - does highly
relevant textual context improve a language model's time series forecasts?
  We find that otherwise highly-capable language models demonstrate
surprisingly limited time series reasoning: they score marginally above random
on etiological and question answering tasks (up to 30 percentage points worse
than humans) and show modest success in using context to improve forecasting.
These weakness showcase that time series reasoning is an impactful, yet deeply
underdeveloped direction for language model research. We also make our datasets
and code public at to support further research in this direction at
https://github.com/behavioral-data/TSandLanguage",2024-04-17,"Mike A. Merrill, Mingtian Tan, Vinayak Gupta, Tom Hartvigsen, Tim Althoff",http://arxiv.org/pdf/2404.11757v1,cs.CL
Mapping Violence: Developing an Extensive Framework to Build a Bangla Sectarian Expression Dataset from Social Media Interactions,"Communal violence in online forums has become extremely prevalent in South
Asia, where many communities of different cultures coexist and share resources.
These societies exhibit a phenomenon characterized by strong bonds within their
own groups and animosity towards others, leading to conflicts that frequently
escalate into violent confrontations. To address this issue, we have developed
the first comprehensive framework for the automatic detection of communal
violence markers in online Bangla content accompanying the largest collection
(13K raw sentences) of social media interactions that fall under the definition
of four major violence class and their 16 coarse expressions. Our workflow
introduces a 7-step expert annotation process incorporating insights from
social scientists, linguists, and psychologists. By presenting data statistics
and benchmarking performance using this dataset, we have determined that, aside
from the category of Non-communal violence, Religio-communal violence is
particularly pervasive in Bangla text. Moreover, we have substantiated the
effectiveness of fine-tuning language models in identifying violent comments by
conducting preliminary benchmarking on the state-of-the-art Bangla deep
learning model.",2024-04-17,"Nazia Tasnim, Sujan Sen Gupta, Md. Istiak Hossain Shihab, Fatiha Islam Juee, Arunima Tahsin, Pritom Ghum, Kanij Fatema, Marshia Haque, Wasema Farzana, Prionti Nasir, Ashique KhudaBukhsh, Farig Sadeque, Asif Sushmit",http://arxiv.org/pdf/2404.11752v1,cs.CL
Missed Connections: Lateral Thinking Puzzles for Large Language Models,"The Connections puzzle published each day by the New York Times tasks players
with dividing a bank of sixteen words into four groups of four words that each
relate to a common theme. Solving the puzzle requires both common linguistic
knowledge (i.e. definitions and typical usage) as well as, in many cases,
lateral or abstract thinking. This is because the four categories ascend in
complexity, with the most challenging category often requiring thinking about
words in uncommon ways or as parts of larger phrases. We investigate the
capacity for automated AI systems to play Connections and explore the game's
potential as an automated benchmark for abstract reasoning and a way to measure
the semantic information encoded by data-driven linguistic systems. In
particular, we study both a sentence-embedding baseline and modern large
language models (LLMs). We report their accuracy on the task, measure the
impacts of chain-of-thought prompting, and discuss their failure modes.
Overall, we find that the Connections task is challenging yet feasible, and a
strong test-bed for future work.",2024-04-17,"Graham Todd, Tim Merino, Sam Earle, Julian Togelius",http://arxiv.org/pdf/2404.11730v2,cs.CL
Investigating Gender Bias in Turkish Language Models,"Language models are trained mostly on Web data, which often contains social
stereotypes and biases that the models can inherit. This has potentially
negative consequences, as models can amplify these biases in downstream tasks
or applications. However, prior research has primarily focused on the English
language, especially in the context of gender bias. In particular,
grammatically gender-neutral languages such as Turkish are underexplored
despite representing different linguistic properties to language models with
possibly different effects on biases. In this paper, we fill this research gap
and investigate the significance of gender bias in Turkish language models. We
build upon existing bias evaluation frameworks and extend them to the Turkish
language by translating existing English tests and creating new ones designed
to measure gender bias in the context of T\""urkiye. Specifically, we also
evaluate Turkish language models for their embedded ethnic bias toward Kurdish
people. Based on the experimental results, we attribute possible biases to
different model characteristics such as the model size, their multilingualism,
and the training corpora. We make the Turkish gender bias dataset publicly
available.",2024-04-17,"Orhun Caglidil, Malte Ostendorff, Georg Rehm",http://arxiv.org/pdf/2404.11726v1,cs.CL
How often are errors in natural language reasoning due to paraphrastic variability?,"Large language models have been shown to behave inconsistently in response to
meaning-preserving paraphrastic inputs. At the same time, researchers evaluate
the knowledge and reasoning abilities of these models with test evaluations
that do not disaggregate the effect of paraphrastic variability on performance.
We propose a metric for evaluating the paraphrastic consistency of natural
language reasoning models based on the probability of a model achieving the
same correctness on two paraphrases of the same problem. We mathematically
connect this metric to the proportion of a model's variance in correctness
attributable to paraphrasing. To estimate paraphrastic consistency, we collect
ParaNLU, a dataset of 7,782 human-written and validated paraphrased reasoning
problems constructed on top of existing benchmark datasets for defeasible and
abductive natural language inference. Using ParaNLU, we measure the
paraphrastic consistency of several model classes and show that consistency
dramatically increases with pretraining but not finetuning. All models tested
exhibited room for improvement in paraphrastic consistency.",2024-04-17,"Neha Srikanth, Marine Carpuat, Rachel Rudinger",http://arxiv.org/pdf/2404.11717v1,cs.CL
Demystifying Legalese: An Automated Approach for Summarizing and Analyzing Overlaps in Privacy Policies and Terms of Service,"The complexities of legalese in terms and policy documents can bind
individuals to contracts they do not fully comprehend, potentially leading to
uninformed data sharing. Our work seeks to alleviate this issue by developing
language models that provide automated, accessible summaries and scores for
such documents, aiming to enhance user understanding and facilitate informed
decisions. We compared transformer-based and conventional models during
training on our dataset, and RoBERTa performed better overall with a remarkable
0.74 F1-score. Leveraging our best-performing model, RoBERTa, we highlighted
redundancies and potential guideline violations by identifying overlaps in
GDPR-required documents, underscoring the necessity for stricter GDPR
compliance.",2024-04-17,"Shikha Soneji, Mitchell Hoesing, Sujay Koujalgi, Jonathan Dodge",http://arxiv.org/pdf/2404.13087v1,cs.CL
Improvement in Semantic Address Matching using Natural Language Processing,"Address matching is an important task for many businesses especially delivery
and take out companies which help them to take out a certain address from their
data warehouse. Existing solution uses similarity of strings, and edit distance
algorithms to find out the similar addresses from the address database, but
these algorithms could not work effectively with redundant, unstructured, or
incomplete address data. This paper discuss semantic Address matching
technique, by which we can find out a particular address from a list of
possible addresses. We have also reviewed existing practices and their
shortcoming. Semantic address matching is an essentially NLP task in the field
of deep learning. Through this technique We have the ability to triumph the
drawbacks of existing methods like redundant or abbreviated data problems. The
solution uses the OCR on invoices to extract the address and create the data
pool of addresses. Then this data is fed to the algorithm BM-25 for scoring the
best matching entries. Then to observe the best result, this will pass through
BERT for giving the best possible result from the similar queries. Our
investigation exhibits that our methodology enormously improves both accuracy
and review of cutting-edge technology existing techniques.",2024-04-17,"Vansh Gupta, Mohit Gupta, Jai Garg, Nitesh Garg",http://arxiv.org/pdf/2404.11691v1,cs.CL
How Well Can You Articulate that Idea? Insights from Automated Formative Assessment,"Automated methods are becoming increasingly integrated into studies of
formative feedback on students' science explanation writing. Most of this work,
however, addresses students' responses to short answer questions. We
investigate automated feedback on students' science explanation essays, where
students must articulate multiple ideas. Feedback is based on a rubric that
identifies the main ideas students are prompted to include in explanatory
essays about the physics of energy and mass, given their experiments with a
simulated roller coaster. We have found that students generally improve on
revised versions of their essays. Here, however, we focus on two factors that
affect the accuracy of the automated feedback. First, we find that the main
ideas in the rubric differ with respect to how much freedom they afford in
explanations of the idea, thus explanation of a natural law is relatively
constrained. Students have more freedom in how they explain complex relations
they observe in their roller coasters, such as transfer of different forms of
energy. Second, by tracing the automated decision process, we can diagnose when
a student's statement lacks sufficient clarity for the automated tool to
associate it more strongly with one of the main ideas above all others. This in
turn provides an opportunity for teachers and peers to help students reflect on
how to state their ideas more clearly.",2024-04-17,"Mahsa Sheikhi Karizaki, Dana Gnesdilow, Sadhana Puntambekar, Rebecca J. Passonneau",http://arxiv.org/pdf/2404.11682v1,cs.CL
MemLLM: Finetuning LLMs to Use An Explicit Read-Write Memory,"While current large language models (LLMs) perform well on many
knowledge-related tasks, they are limited by relying on their parameters as an
implicit storage mechanism. As a result, they struggle with memorizing rare
events and with updating their memory as facts change over time. In addition,
the uninterpretable nature of parametric memory makes it challenging to prevent
hallucination. Model editing and augmenting LLMs with parameters specialized
for memory are only partial solutions. In this paper, we introduce MemLLM, a
novel method of enhancing LLMs by integrating a structured and explicit
read-and-write memory module. MemLLM tackles the aforementioned challenges by
enabling dynamic interaction with the memory and improving the LLM's
capabilities in using stored knowledge. Our experiments indicate that MemLLM
enhances the LLM's performance and interpretability, in language modeling in
general and knowledge-intensive tasks in particular. We see MemLLM as an
important step towards making LLMs more grounded and factual through memory
augmentation. The project repository is publicly available at
https://github.com/amodaresi/MemLLM",2024-04-17,"Ali Modarressi, Abdullatif Köksal, Ayyoob Imani, Mohsen Fayyaz, Hinrich Schütze",http://arxiv.org/pdf/2404.11672v3,cs.CL
Related Work and Citation Text Generation: A Survey,"To convince readers of the novelty of their research paper, authors must
perform a literature review and compose a coherent story that connects and
relates prior works to the current work. This challenging nature of literature
review writing makes automatic related work generation (RWG) academically and
computationally interesting, and also makes it an excellent test bed for
examining the capability of SOTA natural language processing (NLP) models.
Since the initial proposal of the RWG task, its popularity has waxed and waned,
following the capabilities of mainstream NLP approaches. In this work, we
survey the zoo of RWG historical works, summarizing the key approaches and task
definitions and discussing the ongoing challenges of RWG.",2024-04-17,"Xiangci Li, Jessica Ouyang",http://arxiv.org/pdf/2404.11588v1,cs.CL
"The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey","This survey paper examines the recent advancements in AI agent
implementations, with a focus on their ability to achieve complex goals that
require enhanced reasoning, planning, and tool execution capabilities. The
primary objectives of this work are to a) communicate the current capabilities
and limitations of existing AI agent implementations, b) share insights gained
from our observations of these systems in action, and c) suggest important
considerations for future developments in AI agent design. We achieve this by
providing overviews of single-agent and multi-agent architectures, identifying
key patterns and divergences in design choices, and evaluating their overall
impact on accomplishing a provided goal. Our contribution outlines key themes
when selecting an agentic architecture, the impact of leadership on agent
systems, agent communication styles, and key phases for planning, execution,
and reflection that enable robust AI agent systems.",2024-04-17,"Tula Masterman, Sandi Besen, Mason Sawtell, Alex Chao",http://arxiv.org/pdf/2404.11584v1,cs.CL
Language Ranker: A Metric for Quantifying LLM Performance Across High and Low-Resource Languages,"The development of Large Language Models (LLMs) relies on extensive text
corpora, which are often unevenly distributed across languages. This imbalance
results in LLMs performing significantly better on high-resource languages like
English, German, and French, while their capabilities in low-resource languages
remain inadequate. Currently, there is a lack of quantitative methods to
evaluate the performance of LLMs in these low-resource languages. To address
this gap, we propose the Language Ranker, an intrinsic metric designed to
benchmark and rank languages based on LLM performance using internal
representations. By comparing the LLM's internal representation of various
languages against a baseline derived from English, we can assess the model's
multilingual capabilities in a robust and language-agnostic manner. Our
analysis reveals that high-resource languages exhibit higher similarity scores
with English, demonstrating superior performance, while low-resource languages
show lower similarity scores, underscoring the effectiveness of our metric in
assessing language-specific capabilities. Besides, the experiments show that
there is a strong correlation between the LLM's performance in different
languages and the proportion of those languages in its pre-training corpus.
These insights underscore the efficacy of the Language Ranker as a tool for
evaluating LLM performance across different languages, particularly those with
limited resources.",2024-04-17,"Zihao Li, Yucheng Shi, Zirui Liu, Fan Yang, Ali Payani, Ninghao Liu, Mengnan Du",http://arxiv.org/pdf/2404.11553v3,cs.CL
Evaluating Span Extraction in Generative Paradigm: A Reflection on Aspect-Based Sentiment Analysis,"In the era of rapid evolution of generative language models within the realm
of natural language processing, there is an imperative call to revisit and
reformulate evaluation methodologies, especially in the domain of aspect-based
sentiment analysis (ABSA). This paper addresses the emerging challenges
introduced by the generative paradigm, which has moderately blurred traditional
boundaries between understanding and generation tasks. Building upon prevailing
practices in the field, we analyze the advantages and shortcomings associated
with the prevalent ABSA evaluation paradigms. Through an in-depth examination,
supplemented by illustrative examples, we highlight the intricacies involved in
aligning generative outputs with other evaluative metrics, specifically those
derived from other tasks, including question answering. While we steer clear of
advocating for a singular and definitive metric, our contribution lies in
paving the path for a comprehensive guideline tailored for ABSA evaluations in
this generative paradigm. In this position paper, we aim to provide
practitioners with profound reflections, offering insights and directions that
can aid in navigating this evolving landscape, ensuring evaluations that are
both accurate and reflective of generative capabilities.",2024-04-17,"Soyoung Yang, Won Ik Cho",http://arxiv.org/pdf/2404.11539v1,cs.CL
GenFighter: A Generative and Evolutive Textual Attack Removal,"Adversarial attacks pose significant challenges to deep neural networks
(DNNs) such as Transformer models in natural language processing (NLP). This
paper introduces a novel defense strategy, called GenFighter, which enhances
adversarial robustness by learning and reasoning on the training classification
distribution. GenFighter identifies potentially malicious instances deviating
from the distribution, transforms them into semantically equivalent instances
aligned with the training data, and employs ensemble techniques for a unified
and robust response. By conducting extensive experiments, we show that
GenFighter outperforms state-of-the-art defenses in accuracy under attack and
attack success rate metrics. Additionally, it requires a high number of queries
per attack, making the attack more challenging in real scenarios. The ablation
study shows that our approach integrates transfer learning, a
generative/evolutive procedure, and an ensemble method, providing an effective
defense against NLP adversarial attacks.",2024-04-17,"Md Athikul Islam, Edoardo Serra, Sushil Jajodia",http://arxiv.org/pdf/2404.11538v1,cs.CL
Select and Reorder: A Novel Approach for Neural Sign Language Production,"Sign languages, often categorised as low-resource languages, face significant
challenges in achieving accurate translation due to the scarcity of parallel
annotated datasets. This paper introduces Select and Reorder (S&R), a novel
approach that addresses data scarcity by breaking down the translation process
into two distinct steps: Gloss Selection (GS) and Gloss Reordering (GR). Our
method leverages large spoken language models and the substantial lexical
overlap between source spoken languages and target sign languages to establish
an initial alignment. Both steps make use of Non-AutoRegressive (NAR) decoding
for reduced computation and faster inference speeds. Through this
disentanglement of tasks, we achieve state-of-the-art BLEU and Rouge scores on
the Meine DGS Annotated (mDGS) dataset, demonstrating a substantial BLUE-1
improvement of 37.88% in Text to Gloss (T2G) Translation. This innovative
approach paves the way for more effective translation models for sign
languages, even in resource-constrained settings.",2024-04-17,"Harry Walsh, Ben Saunders, Richard Bowden",http://arxiv.org/pdf/2404.11532v1,cs.CL
Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization,"Fusing knowledge from multiple Large Language Models (LLMs) can combine their
diverse strengths to achieve improved performance on a given task. However,
current fusion approaches either rely on learning-based fusers that do not
generalize to new LLMs, or do not take into account how well each LLM
understands the input. In this work, we study LLM fusion at test-time, which
enables leveraging knowledge from arbitrary user-specified LLMs during
inference. We introduce Pack of LLMs (PackLLM), an effective method for
test-time fusion that leverages each LLM's expertise, given an input prompt.
PackLLM performs model fusion by solving an optimization problem for
determining each LLM's importance, so that perplexity over the input prompt is
minimized. First, our simple PackLLM-sim variant validates that perplexity is a
good indicator for measuring each LLM's expertise. Second, our PackLLM-opt
variant approximately solves the perplexity minimization problem via a greedy
algorithm. The derived importance weights are used to combine the LLMs during
inference. We conduct experiments with over 100 total LLMs on a diverse set of
tasks. Experimental results show that (i) perplexity is a reliable measure for
LLM fusion, (ii) PackLLM outperforms test-time fusion baselines by 1.89%
accuracy points, and (iii) PackLLM can leverage new LLMs to improve performance
over learning-based fusion approaches by 3.92-11.94% accuracy points.",2024-04-17,"Costas Mavromatis, Petros Karypis, George Karypis",http://arxiv.org/pdf/2404.11531v1,cs.CL
Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large Language Models,"In real world, large language models (LLMs) can serve as the assistant to
help users accomplish their jobs, and also support the development of advanced
applications. For the wide application of LLMs, the inference efficiency is an
essential concern, which has been widely studied in existing work, and numerous
optimization algorithms and code libraries have been proposed to improve it.
Nonetheless, users still find it challenging to compare the effectiveness of
all the above methods and understand the underlying mechanisms. In this work,
we perform a detailed coarse-to-fine analysis of the inference performance of
various code libraries. To evaluate the overall effectiveness, we examine four
usage scenarios within two practical applications. We further provide both
theoretical and empirical fine-grained analyses of each module in the
Transformer architecture. Our experiments yield comprehensive results that are
invaluable for researchers to evaluate code libraries and improve inference
strategies.",2024-04-17,"Yushuo Chen, Tianyi Tang, Erge Xiang, Linjiang Li, Wayne Xin Zhao, Jing Wang, Yunpeng Chai, Ji-Rong Wen",http://arxiv.org/pdf/2404.11502v1,cs.CL
Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models,"This paper studies the relationship between the surface form of a
mathematical problem and its solvability by large language models. We find that
subtle alterations in the surface form can significantly impact the answer
distribution and the solve rate, exposing the language model's lack of
robustness and sensitivity to the surface form in reasoning through complex
problems. To improve mathematical reasoning performance, we propose
Self-Consistency-over-Paraphrases (SCoP), which diversifies reasoning paths
from specific surface forms of the problem. We evaluate our approach on four
mathematics reasoning benchmarks over three large language models and show that
SCoP improves mathematical reasoning performance over vanilla self-consistency,
particularly for problems initially deemed unsolvable. Finally, we provide
additional experiments and discussion regarding problem difficulty and surface
forms, including cross-model difficulty agreement and paraphrasing
transferability, and Variance of Variations (VOV) for language model
evaluation.",2024-04-17,"Yue Zhou, Yada Zhu, Diego Antognini, Yoon Kim, Yang Zhang",http://arxiv.org/pdf/2404.11500v1,cs.CL
A Data-Driven Representation for Sign Language Production,"Phonetic representations are used when recording spoken languages, but no
equivalent exists for recording signed languages. As a result, linguists have
proposed several annotation systems that operate on the gloss or sub-unit
level; however, these resources are notably irregular and scarce.
  Sign Language Production (SLP) aims to automatically translate spoken
language sentences into continuous sequences of sign language. However, current
state-of-the-art approaches rely on scarce linguistic resources to work. This
has limited progress in the field. This paper introduces an innovative solution
by transforming the continuous pose generation problem into a discrete sequence
generation problem. Thus, overcoming the need for costly annotation. Although,
if available, we leverage the additional information to enhance our approach.
  By applying Vector Quantisation (VQ) to sign language data, we first learn a
codebook of short motions that can be combined to create a natural sequence of
sign. Where each token in the codebook can be thought of as the lexicon of our
representation. Then using a transformer we perform a translation from spoken
language text to a sequence of codebook tokens. Each token can be directly
mapped to a sequence of poses allowing the translation to be performed by a
single network. Furthermore, we present a sign stitching method to effectively
join tokens together. We evaluate on the RWTH-PHOENIX-Weather-2014T
(PHOENIX14T) and the more challenging Meine DGS Annotated (mDGS) datasets. An
extensive evaluation shows our approach outperforms previous methods,
increasing the BLEU-1 back translation score by up to 72%.",2024-04-17,"Harry Walsh, Abolfazl Ravanshad, Mariam Rahmani, Richard Bowden",http://arxiv.org/pdf/2404.11499v1,cs.CL
A Federated Learning Approach to Privacy Preserving Offensive Language Identification,"The spread of various forms of offensive speech online is an important
concern in social media. While platforms have been investing heavily in ways of
coping with this problem, the question of privacy remains largely unaddressed.
Models trained to detect offensive language on social media are trained and/or
fine-tuned using large amounts of data often stored in centralized servers.
Since most social media data originates from end users, we propose a privacy
preserving decentralized architecture for identifying offensive language online
by introducing Federated Learning (FL) in the context of offensive language
identification. FL is a decentralized architecture that allows multiple models
to be trained locally without the need for data sharing hence preserving users'
privacy. We propose a model fusion approach to perform FL. We trained multiple
deep learning models on four publicly available English benchmark datasets
(AHSD, HASOC, HateXplain, OLID) and evaluated their performance in detail. We
also present initial cross-lingual experiments in English and Spanish. We show
that the proposed model fusion approach outperforms baselines in all the
datasets while preserving privacy.",2024-04-17,"Marcos Zampieri, Damith Premasiri, Tharindu Ranasinghe",http://arxiv.org/pdf/2404.11470v1,cs.CL
Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent,"A multimodal AI agent is characterized by its ability to process and learn
from various types of data, including natural language, visual, and audio
inputs, to inform its actions. Despite advancements in large language models
that incorporate visual data, such as GPT-4V, effectively translating
image-based data into actionable outcomes for AI agents continues to be
challenging. In this paper, we introduce a multimodal model that incorporates
the concept of functional token specifically designed for AI agent
applications. To ensure compatibility with edge devices, our model is optimized
to a compact size of less than 1B parameters. Like GPT-4, our model can process
both English and Chinese. We demonstrate that this model is capable of
operating efficiently on a wide range of edge devices, including as constrained
as a Raspberry Pi.",2024-04-17,"Wei Chen, Zhiyuan Li",http://arxiv.org/pdf/2404.11459v2,cs.CL
Bias and Unfairness in Information Retrieval Systems: New Challenges in the LLM Era,"With the rapid advancements of large language models (LLMs), information
retrieval (IR) systems, such as search engines and recommender systems, have
undergone a significant paradigm shift. This evolution, while heralding new
opportunities, introduces emerging challenges, particularly in terms of biases
and unfairness, which may threaten the information ecosystem. In this paper, we
present a comprehensive survey of existing works on emerging and pressing bias
and unfairness issues in IR systems when the integration of LLMs. We first
unify bias and unfairness issues as distribution mismatch problems, providing a
groundwork for categorizing various mitigation strategies through distribution
alignment. Subsequently, we systematically delve into the specific bias and
unfairness issues arising from three critical stages of LLMs integration into
IR systems: data collection, model development, and result evaluation. In doing
so, we meticulously review and analyze recent literature, focusing on the
definitions, characteristics, and corresponding mitigation strategies
associated with these issues. Finally, we identify and highlight some open
problems and challenges for future work, aiming to inspire researchers and
stakeholders in the IR field and beyond to better understand and mitigate bias
and unfairness issues of IR in this LLM era. We also consistently maintain a
GitHub repository for the relevant papers and resources in this rising
direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.",2024-04-17,"Sunhao Dai, Chen Xu, Shicheng Xu, Liang Pang, Zhenhua Dong, Jun Xu",http://arxiv.org/pdf/2404.11457v2,cs.CL
AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts,"Cognitive Behavioral Therapy (CBT) is an effective technique for addressing
the irrational thoughts stemming from mental illnesses, but it necessitates
precise identification of cognitive pathways to be successfully implemented in
patient care. In current society, individuals frequently express negative
emotions on social media on specific topics, often exhibiting cognitive
distortions, including suicidal behaviors in extreme cases. Yet, there is a
notable absence of methodologies for analyzing cognitive pathways that could
aid psychotherapists in conducting effective interventions online. In this
study, we gathered data from social media and established the task of
extracting cognitive pathways, annotating the data based on a cognitive
theoretical framework. We initially categorized the task of extracting
cognitive pathways as a hierarchical text classification with four main
categories and nineteen subcategories. Following this, we structured a text
summarization task to help psychotherapists quickly grasp the essential
information. Our experiments evaluate the performance of deep learning and
large language models (LLMs) on these tasks. The results demonstrate that our
deep learning method achieved a micro-F1 score of 62.34% in the hierarchical
text classification task. Meanwhile, in the text summarization task, GPT-4
attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the
experimental deep learning model's performance. However, it may suffer from an
issue of hallucination. We have made all models and codes publicly available to
support further research in this field.",2024-04-17,"Meng Jiang, Yi Jing Yu, Qing Zhao, Jianqiang Li, Changwei Song, Hongzhi Qi, Wei Zhai, Dan Luo, Xiaoqin Wang, Guanghui Fu, Bing Xiang Yang",http://arxiv.org/pdf/2404.11449v1,cs.CL
Research on emotionally intelligent dialogue generation based on automatic dialogue system,"Automated dialogue systems are important applications of artificial
intelligence, and traditional systems struggle to understand user emotions and
provide empathetic feedback. This study integrates emotional intelligence
technology into automated dialogue systems and creates a dialogue generation
model with emotional intelligence through deep learning and natural language
processing techniques. The model can detect and understand a wide range of
emotions and specific pain signals in real time, enabling the system to provide
empathetic interaction. By integrating the results of the study ""Can artificial
intelligence detect pain and express pain empathy?"", the model's ability to
understand the subtle elements of pain empathy has been enhanced, setting
higher standards for emotional intelligence dialogue systems. The project aims
to provide theoretical understanding and practical suggestions to integrate
advanced emotional intelligence capabilities into dialogue systems, thereby
improving user experience and interaction quality.",2024-04-17,"Jin Wang, JinFei Wang, Shuying Dai, Jiqiang Yu, Keqin Li",http://arxiv.org/pdf/2404.11447v1,cs.CL
Open-Ended Wargames with Large Language Models,"Wargames are a powerful tool for understanding and rehearsing real-world
decision making. Automated play of wargames using artificial intelligence (AI)
enables possibilities beyond those of human-conducted games, such as playing
the game many times over to see a range of possible outcomes. There are two
categories of wargames: quantitative games, with discrete types of moves, and
qualitative games, which revolve around open-ended responses. Historically,
automation efforts have focused on quantitative games, but large language
models (LLMs) make it possible to automate qualitative wargames. We introduce
""Snow Globe,"" an LLM-powered multi-agent system for playing qualitative
wargames. With Snow Globe, every stage of a text-based qualitative wargame from
scenario preparation to post-game analysis can be optionally carried out by AI,
humans, or a combination thereof. We describe its software architecture
conceptually and release an open-source implementation alongside this
publication. As case studies, we simulate a tabletop exercise about an AI
incident response and a political wargame about a geopolitical crisis. We
discuss potential applications of the approach and how it fits into the broader
wargaming ecosystem.",2024-04-17,"Daniel P. Hogan, Andrea Brennen",http://arxiv.org/pdf/2404.11446v1,cs.CL
Exploring Key Point Analysis with Pairwise Generation and Graph Partitioning,"Key Point Analysis (KPA), the summarization of multiple arguments into a
concise collection of key points, continues to be a significant and unresolved
issue within the field of argument mining. Existing models adapt a two-stage
pipeline of clustering arguments or generating key points for argument
clusters. This approach rely on semantic similarity instead of measuring the
existence of shared key points among arguments. Additionally, it only models
the intra-cluster relationship among arguments, disregarding the inter-cluster
relationship between arguments that do not share key points. To address these
limitations, we propose a novel approach for KPA with pairwise generation and
graph partitioning. Our objective is to train a generative model that can
simultaneously provide a score indicating the presence of shared key point
between a pair of arguments and generate the shared key point. Subsequently, to
map generated redundant key points to a concise set of key points, we proceed
to construct an arguments graph by considering the arguments as vertices, the
generated key points as edges, and the scores as edge weights. We then propose
a graph partitioning algorithm to partition all arguments sharing the same key
points to the same subgraph. Notably, our experimental findings demonstrate
that our proposed model surpasses previous models when evaluated on both the
ArgKP and QAM datasets.",2024-04-17,"Xiao Li, Yong Jiang, Shen Huang, Pengjun Xie, Gong Cheng, Fei Huang",http://arxiv.org/pdf/2404.11384v1,cs.CL
TeClass: A Human-Annotated Relevance-based Headline Classification and Generation Dataset for Telugu,"News headline generation is a crucial task in increasing productivity for
both the readers and producers of news. This task can easily be aided by
automated News headline-generation models. However, the presence of irrelevant
headlines in scraped news articles results in sub-optimal performance of
generation models. We propose that relevance-based headline classification can
greatly aid the task of generating relevant headlines. Relevance-based headline
classification involves categorizing news headlines based on their relevance to
the corresponding news articles. While this task is well-established in
English, it remains under-explored in low-resource languages like Telugu due to
a lack of annotated data. To address this gap, we present TeClass, the
first-ever human-annotated Telugu news headline classification dataset,
containing 78,534 annotations across 26,178 article-headline pairs. We
experiment with various baseline models and provide a comprehensive analysis of
their results. We further demonstrate the impact of this work by fine-tuning
various headline generation models using TeClass dataset. The headlines
generated by the models fine-tuned on highly relevant article-headline pairs,
showed about a 5 point increment in the ROUGE-L scores. To encourage future
research, the annotated dataset as well as the annotation guidelines will be
made publicly available.",2024-04-17,"Gopichand Kanumolu, Lokesh Madasu, Nirmal Surange, Manish Shrivastava",http://arxiv.org/pdf/2404.11349v1,cs.CL
To Drop or Not to Drop? Predicting Argument Ellipsis Judgments: A Case Study in Japanese,"Speakers sometimes omit certain arguments of a predicate in a sentence; such
omission is especially frequent in pro-drop languages. This study addresses a
question about ellipsis -- what can explain the native speakers' ellipsis
decisions? -- motivated by the interest in human discourse processing and
writing assistance for this choice. To this end, we first collect large-scale
human annotations of whether and why a particular argument should be omitted
across over 2,000 data points in the balanced corpus of Japanese, a
prototypical pro-drop language. The data indicate that native speakers overall
share common criteria for such judgments and further clarify their quantitative
characteristics, e.g., the distribution of related linguistic factors in the
balanced corpus. Furthermore, the performance of the language model-based
argument ellipsis judgment model is examined, and the gap between the systems'
prediction and human judgments in specific linguistic aspects is revealed. We
hope our fundamental resource encourages further studies on natural human
ellipsis judgment.",2024-04-17,"Yukiko Ishizuki, Tatsuki Kuribayashi, Yuichiroh Matsubayashi, Ryohei Sasano, Kentaro Inui",http://arxiv.org/pdf/2404.11315v2,cs.CL
A Preference-driven Paradigm for Enhanced Translation with Large Language Models,"Recent research has shown that large language models (LLMs) can achieve
remarkable translation performance through supervised fine-tuning (SFT) using
only a small amount of parallel data. However, SFT simply instructs the model
to imitate the reference translations at the token level, making it vulnerable
to the noise present in the references. Hence, the assistance from SFT often
reaches a plateau once the LLMs have achieved a certain level of translation
capability, and further increasing the size of parallel data does not provide
additional benefits. To overcome this plateau associated with imitation-based
SFT, we propose a preference-based approach built upon the Plackett-Luce model.
The objective is to steer LLMs towards a more nuanced understanding of
translation preferences from a holistic view, while also being more resilient
in the absence of gold translations. We further build a dataset named MAPLE to
verify the effectiveness of our approach, which includes multiple translations
of varying quality for each source sentence. Extensive experiments demonstrate
the superiority of our approach in ""breaking the plateau"" across diverse LLMs
and test settings. Our in-depth analysis underscores the pivotal role of
diverse translations and accurate preference scores in the success of our
approach.",2024-04-17,"Dawei Zhu, Sony Trenous, Xiaoyu Shen, Dietrich Klakow, Bill Byrne, Eva Hasler",http://arxiv.org/pdf/2404.11288v2,cs.CL
Sampling-based Pseudo-Likelihood for Membership Inference Attacks,"Large Language Models (LLMs) are trained on large-scale web data, which makes
it difficult to grasp the contribution of each text. This poses the risk of
leaking inappropriate data such as benchmarks, personal information, and
copyrighted texts in the training data. Membership Inference Attacks (MIA),
which determine whether a given text is included in the model's training data,
have been attracting attention. Previous studies of MIAs revealed that
likelihood-based classification is effective for detecting leaks in LLMs.
However, the existing methods cannot be applied to some proprietary models like
ChatGPT or Claude 3 because the likelihood is unavailable to the user. In this
study, we propose a Sampling-based Pseudo-Likelihood (\textbf{SPL}) method for
MIA (\textbf{SaMIA}) that calculates SPL using only the text generated by an
LLM to detect leaks. The SaMIA treats the target text as the reference text and
multiple outputs from the LLM as text samples, calculates the degree of
$n$-gram match as SPL, and determines the membership of the text in the
training data. Even without likelihoods, SaMIA performed on par with existing
likelihood-based methods.",2024-04-17,"Masahiro Kaneko, Youmi Ma, Yuki Wata, Naoaki Okazaki",http://arxiv.org/pdf/2404.11262v1,cs.CL
In-Context Learning State Vector with Inner and Momentum Optimization,"Large Language Models (LLMs) have exhibited an impressive ability to perform
In-Context Learning (ICL) from only a few examples. Recent works have indicated
that the functions learned by ICL can be represented through compressed vectors
derived from the transformer. However, the working mechanisms and optimization
of these vectors are yet to be thoroughly explored. In this paper, we address
this gap by presenting a comprehensive analysis of these compressed vectors,
drawing parallels to the parameters trained with gradient descent, and
introduce the concept of state vector. Inspired by the works on model soup and
momentum-based gradient descent, we propose inner and momentum optimization
methods that are applied to refine the state vector progressively as test-time
adaptation. Moreover, we simulate state vector aggregation in the multiple
example setting, where demonstrations comprising numerous examples are usually
too lengthy for regular ICL, and further propose a divide-and-conquer
aggregation method to address this challenge. We conduct extensive experiments
using Llama-2 and GPT-J in both zero-shot setting and few-shot setting. The
experimental results show that our optimization method effectively enhances the
state vector and achieves the state-of-the-art performance on diverse tasks.
Code is available at https://github.com/HITsz-TMG/ICL-State-Vector",2024-04-17,"Dongfang Li, Zhenyu Liu, Xinshuo Hu, Zetian Sun, Baotian Hu, Min Zhang",http://arxiv.org/pdf/2404.11225v2,cs.CL
Position Engineering: Boosting Large Language Models through Positional Information Manipulation,"The performance of large language models (LLMs) is significantly influenced
by the quality of the prompts provided. In response, researchers have developed
enormous prompt engineering strategies aimed at modifying the prompt text to
enhance task performance. In this paper, we introduce a novel technique termed
position engineering, which offers a more efficient way to guide large language
models. Unlike prompt engineering, which requires substantial effort to modify
the text provided to LLMs, position engineering merely involves altering the
positional information in the prompt without modifying the text itself. We have
evaluated position engineering in two widely-used LLM scenarios:
retrieval-augmented generation (RAG) and in-context learning (ICL). Our
findings show that position engineering substantially improves upon the
baseline in both cases. Position engineering thus represents a promising new
strategy for exploiting the capabilities of large language models.",2024-04-17,"Zhiyuan He, Huiqiang Jiang, Zilong Wang, Yuqing Yang, Luna Qiu, Lili Qiu",http://arxiv.org/pdf/2404.11216v2,cs.CL
Prompt-tuning for Clickbait Detection via Text Summarization,"Clickbaits are surprising social posts or deceptive news headlines that
attempt to lure users for more clicks, which have posted at unprecedented rates
for more profit or commercial revenue. The spread of clickbait has significant
negative impacts on the users, which brings users misleading or even
click-jacking attacks. Different from fake news, the crucial problem in
clickbait detection is determining whether the headline matches the
corresponding content. Most existing methods compute the semantic similarity
between the headlines and contents for detecting clickbait. However, due to
significant differences in length and semantic features between headlines and
contents, directly calculating semantic similarity is often difficult to
summarize the relationship between them. To address this problem, we propose a
prompt-tuning method for clickbait detection via text summarization in this
paper, text summarization is introduced to summarize the contents, and
clickbait detection is performed based on the similarity between the generated
summary and the contents. Specifically, we first introduce a two-stage text
summarization model to produce high-quality news summaries based on pre-trained
language models, and then both the headlines and new generated summaries are
incorporated as the inputs for prompt-tuning. Additionally, a variety of
strategies are conducted to incorporate external knowledge for improving the
performance of clickbait detection. The extensive experiments on well-known
clickbait detection datasets demonstrate that our method achieved
state-of-the-art performance.",2024-04-17,"Haoxiang Deng, Yi Zhu, Ye Wang, Jipeng Qiang, Yunhao Yuan, Yun Li, Runmei Zhang",http://arxiv.org/pdf/2404.11206v1,cs.CL
Pose2Gest: A Few-Shot Model-Free Approach Applied In South Indian Classical Dance Gesture Recognition,"The classical dances from India utilize a set of hand gestures known as
Mudras, serving as the foundational elements of its posture vocabulary.
Identifying these mudras represents a primary task in digitizing the dance
performances. With Kathakali, a dance-drama, as the focus, this work addresses
mudra recognition by framing it as a 24-class classification problem and
proposes a novel vector-similarity-based approach leveraging pose estimation
techniques. This method obviates the need for extensive training or
fine-tuning, thus mitigating the issue of limited data availability common in
similar AI applications. Achieving an accuracy rate of 92%, our approach
demonstrates comparable or superior performance to existing
model-training-based methodologies in this domain. Notably, it remains
effective even with small datasets comprising just 1 or 5 samples, albeit with
a slightly diminished performance. Furthermore, our system supports processing
images, videos, and real-time streams, accommodating both hand-cropped and
full-body images. As part of this research, we have curated and released a
publicly accessible Hasta Mudra dataset, which applies to multiple South Indian
art forms including Kathakali. The implementation of the proposed method is
also made available as a web application.",2024-04-17,"Kavitha Raju, Nandini J. Warrier, Manu Madhavan, Selvi C., Arun B. Warrier, Thulasi Kumar",http://arxiv.org/pdf/2404.11205v2,cs.CL
Neuron Specialization: Leveraging intrinsic task modularity for multilingual machine translation,"Training a unified multilingual model promotes knowledge transfer but
inevitably introduces negative interference. Language-specific modeling methods
show promise in reducing interference. However, they often rely on heuristics
to distribute capacity and struggle to foster cross-lingual transfer via
isolated modules. In this paper, we explore intrinsic task modularity within
multilingual networks and leverage these observations to circumvent
interference under multilingual translation. We show that neurons in the
feed-forward layers tend to be activated in a language-specific manner.
Meanwhile, these specialized neurons exhibit structural overlaps that reflect
language proximity, which progress across layers. Based on these findings, we
propose Neuron Specialization, an approach that identifies specialized neurons
to modularize feed-forward layers and then continuously updates them through
sparse networks. Extensive experiments show that our approach achieves
consistent performance gains over strong baselines with additional analyses
demonstrating reduced interference and increased knowledge transfer.",2024-04-17,"Shaomu Tan, Di Wu, Christof Monz",http://arxiv.org/pdf/2404.11201v1,cs.CL
FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document,"Through the advent of pre-trained language models, there have been notable
advancements in abstractive summarization systems. Simultaneously, a
considerable number of novel methods for evaluating factual consistency in
abstractive summarization systems has been developed. But these evaluation
approaches incorporate substantial limitations, especially on refinement and
interpretability. In this work, we propose highly effective and interpretable
factual inconsistency detection method metric Factual Inconsistency Detection
by Zoom-in Summary and Zoom-out Document for abstractive summarization systems
that is based on fine-grained atomic facts decomposition. Moreover, we align
atomic facts decomposed from the summary with the source document through
adaptive granularity expansion. These atomic facts represent a more
fine-grained unit of information, facilitating detailed understanding and
interpretability of the summary's factual inconsistency. Experimental results
demonstrate that our proposed factual consistency checking system significantly
outperforms existing systems.",2024-04-17,"Joonho Yang, Seunghyun Yoon, Byeongjeong Kim, Hwanhee Lee",http://arxiv.org/pdf/2404.11184v3,cs.CL
Context-Aware Siamese Networks for Efficient Emotion Recognition in Conversation,"The advent of deep learning models has made a considerable contribution to
the achievement of Emotion Recognition in Conversation (ERC). However, this
task still remains an important challenge due to the plurality and subjectivity
of human emotions. Previous work on ERC provides predictive models using mostly
graph-based conversation representations. In this work, we propose a way to
model the conversational context that we incorporate into a metric learning
training strategy, with a two-step process. This allows us to perform ERC in a
flexible classification scenario and to end up with a lightweight yet efficient
model. Using metric learning through a Siamese Network architecture, we achieve
57.71 in macro F1 score for emotion classification in conversation on
DailyDialog dataset, which outperforms the related work. This state-of-the-art
result is promising regarding the use of metric learning for emotion
recognition, yet perfectible compared to the microF1 score obtained.",2024-04-17,"Barbara Gendron, Gaël Guibon",http://arxiv.org/pdf/2404.11141v1,cs.CL
A Novel ICD Coding Method Based on Associated and Hierarchical Code Description Distillation,"ICD(International Classification of Diseases) coding involves assigning ICD
codes to patients visit based on their medical notes. ICD coding is a
challenging multilabel text classification problem due to noisy medical
document inputs. Recent advancements in automated ICD coding have enhanced
performance by integrating additional data and knowledge bases with the
encoding of medical notes and codes. However, most of them ignore the code
hierarchy, leading to improper code assignments. To address these problems, we
propose a novel framework based on associated and hierarchical code description
distillation (AHDD) for better code representation learning and avoidance of
improper code assignment.we utilize the code description and the hierarchical
structure inherent to the ICD codes. Therefore, in this paper, we leverage the
code description and the hierarchical structure inherent to the ICD codes. The
code description is also applied to aware the attention layer and output layer.
Experimental results on the benchmark dataset show the superiority of the
proposed framework over several state-of-the-art baselines.",2024-04-17,"Bin Zhang, Junli Wang",http://arxiv.org/pdf/2404.11132v2,cs.CL
What's under the hood: Investigating Automatic Metrics on Meeting Summarization,"Meeting summarization has become a critical task considering the increase in
online interactions. While new techniques are introduced regularly, their
evaluation uses metrics not designed to capture meeting-specific errors,
undermining effective evaluation. This paper investigates what the frequently
used automatic metrics capture and which errors they mask by correlating
automatic metric scores with human evaluations across a broad error taxonomy.
We commence with a comprehensive literature review on English meeting
summarization to define key challenges like speaker dynamics and contextual
turn-taking and error types such as missing information and linguistic
inaccuracy, concepts previously loosely defined in the field. We examine the
relationship between characteristic challenges and errors by using annotated
transcripts and summaries from Transformer-based sequence-to-sequence and
autoregressive models from the general summary QMSum dataset. Through
experimental validation, we find that different model architectures respond
variably to challenges in meeting transcripts, resulting in different
pronounced links between challenges and errors. Current default-used metrics
struggle to capture observable errors, showing weak to mid-correlations, while
a third of the correlations show trends of error masking. Only a subset reacts
accurately to specific errors, while most correlations show either
unresponsiveness or failure to reflect the error's impact on summary quality.",2024-04-17,"Frederic Kirstein, Jan Philip Wahle, Terry Ruas, Bela Gipp",http://arxiv.org/pdf/2404.11124v2,cs.CL
Consistency Training by Synthetic Question Generation for Conversational Question Answering,"Efficiently modeling historical information is a critical component in
addressing user queries within a conversational question-answering (QA)
context, as historical context plays a vital role in clarifying the user's
questions. However, irrelevant history induces noise in the reasoning process,
especially for those questions with a considerable historical context. In our
novel model-agnostic approach, referred to as CoTaH (Consistency-Trained
augmented History), we augment the historical information with synthetic
questions and subsequently employ consistency training to train a model that
utilizes both real and augmented historical data to implicitly make the
reasoning robust to irrelevant history. To the best of our knowledge, this is
the first instance of research using question generation as a form of data
augmentation to model conversational QA settings. By citing a common modeling
error prevalent in previous research, we introduce a new baseline model and
compare our model's performance against it, demonstrating an improvement in
results, particularly when dealing with questions that include a substantial
amount of historical context. The source code can be found on our GitHub page.",2024-04-17,"Hamed Hematian Hemati, Hamid Beigy",http://arxiv.org/pdf/2404.11109v1,cs.CL
Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues,"Aligning large language models (LLMs) with human expectations requires
high-quality instructional dialogues, which usually require instructions that
are diverse and in-depth. Existing methods leverage two LLMs to interact for
automatic collection: one simulating a user to pose instructions, and the other
acting as a system agent to respond. However, these user simulators struggle to
model the rules behind how dialogues can pose different instructions without
explicit guidance, resulting in general instructions. In this paper, we propose
to explicitly capture the complex rules to help the user simulator pose diverse
and in-depth instruction. Specifically, we first induce high-level instruction
strategies from various real instruction dialogues serving as rules. Afterward,
different possible strategies are applied to the newly given dialogue scenario
deductively to pose various instructions. Experimental results show that our
method can generate diverse and in-depth instructions. The constructed
multi-turn instructional dialogues can outperform competitive baselines on the
downstream chat model.",2024-04-17,"Jiao Ou, Jiayu Wu, Che Liu, Fuzheng Zhang, Di Zhang, Kun Gai",http://arxiv.org/pdf/2404.11095v2,cs.CL
ViLLM-Eval: A Comprehensive Evaluation Suite for Vietnamese Large Language Models,"The rapid advancement of large language models (LLMs) necessitates the
development of new benchmarks to accurately assess their capabilities. To
address this need for Vietnamese, this work aims to introduce ViLLM-Eval, the
comprehensive evaluation suite designed to measure the advanced knowledge and
reasoning abilities of foundation models within a Vietnamese context.
ViLLM-Eval consists of multiple-choice questions and predict next word tasks
spanning various difficulty levels and diverse disciplines, ranging from
humanities to science and engineering. A thorough evaluation of the most
advanced LLMs on ViLLM-Eval revealed that even the best performing models have
significant room for improvement in understanding and responding to Vietnamese
language tasks. ViLLM-Eval is believed to be instrumental in identifying key
strengths and weaknesses of foundation models, ultimately promoting their
development and enhancing their performance for Vietnamese users. This paper
provides a thorough overview of ViLLM-Eval as part of the Vietnamese Large
Language Model shared task, held within the 10th International Workshop on
Vietnamese Language and Speech Processing (VLSP 2023).",2024-04-17,"Trong-Hieu Nguyen, Anh-Cuong Le, Viet-Cuong Nguyen",http://arxiv.org/pdf/2404.11086v2,cs.CL
Efficient Contextual LLM Cascades through Budget-Constrained Policy Learning,"Recent successes in natural language processing have led to the proliferation
of large language models (LLMs) by multiple providers. Each LLM offering has
different inference accuracy, monetary cost, and latency, and their accuracy
further depends on the exact wording of the question (i.e., the specific
prompt). At the same time, users often have a limit on monetary budget and
latency to answer all their questions, and they do not know which LLMs to
choose for each question to meet their accuracy and long term budget
requirements. To navigate this rich design space, we propose TREACLE
($\underline{T}$hrifty $\underline{Rea}$soning via $\underline{C}$ontext-Aware
$\underline{L}$LM and Prompt S$\underline{e}$lection), a reinforcement learning
policy that jointly selects the model and prompting scheme while respecting the
user's monetary cost and latency constraints. TREACLE uses the problem context,
including question text embeddings (reflecting the type or difficulty of a
query) and the response history (reflecting the consistency of previous
responses) to make smart decisions. Our evaluations on standard reasoning
datasets (GSM8K, CSQA, and LLC) with various LLMs and prompts show that TREACLE
enables cost savings of up to 85% compared to baselines, while maintaining high
accuracy. Importantly, it provides the user with the ability to gracefully
trade off accuracy for cost.",2024-04-17,"Xuechen Zhang, Zijian Huang, Ege Onur Taga, Carlee Joe-Wong, Samet Oymak, Jiasi Chen",http://arxiv.org/pdf/2404.13082v2,cs.CL
Unified Examination of Entity Linking in Absence of Candidate Sets,"Despite remarkable strides made in the development of entity linking systems
in recent years, a comprehensive comparative analysis of these systems using a
unified framework is notably absent. This paper addresses this oversight by
introducing a new black-box benchmark and conducting a comprehensive evaluation
of all state-of-the-art entity linking methods. We use an ablation study to
investigate the impact of candidate sets on the performance of entity linking.
Our findings uncover exactly how much such entity linking systems depend on
candidate sets, and how much this limits the general applicability of each
system. We present an alternative approach to candidate sets, demonstrating
that leveraging the entire in-domain candidate set can serve as a viable
substitute for certain models. We show the trade-off between less restrictive
candidate sets, increased inference time and memory footprint for some models.",2024-04-17,"Nicolas Ong, Hassan Shavarani, Anoop Sarkar",http://arxiv.org/pdf/2404.11061v1,cs.CL
Do LLMs Think Fast and Slow? A Causal Study on Sentiment Analysis,"Sentiment analysis (SA) aims to identify the sentiment expressed in a text,
such as a product review. Given a review and the sentiment associated with it,
this work formulates SA as a combination of two tasks: (1) a causal discovery
task that distinguishes whether a review ""primes"" the sentiment (Causal
Hypothesis C1), or the sentiment ""primes"" the review (Causal Hypothesis C2);
and (2) the traditional prediction task to model the sentiment using the review
as input. Using the peak-end rule in psychology, we classify a sample as C1 if
its overall sentiment score approximates an average of all the sentence-level
sentiments in the review, and C2 if the overall sentiment score approximates an
average of the peak and end sentiments. For the prediction task, we use the
discovered causal mechanisms behind the samples to improve LLM performance by
proposing causal prompts that give the models an inductive bias of the
underlying causal graph, leading to substantial improvements by up to 32.13 F1
points on zero-shot five-class SA. Our code is at
https://github.com/cogito233/causal-sa",2024-04-17,"Zhiheng Lyu, Zhijing Jin, Fernando Gonzalez, Rada Mihalcea, Bernhard Schölkopf, Mrinmaya Sachan",http://arxiv.org/pdf/2404.11055v2,cs.CL
Stepwise Alignment for Constrained Language Model Policy Optimization,"Safety and trustworthiness are indispensable requirements for real-world
applications of AI systems using large language models (LLMs). This paper
formulates human value alignment as an optimization problem of the language
model policy to maximize reward under a safety constraint, and then proposes an
algorithm, Stepwise Alignment for Constrained Policy Optimization (SACPO). One
key idea behind SACPO, supported by theory, is that the optimal policy
incorporating reward and safety can be directly obtained from a reward-aligned
policy. Building on this key idea, SACPO aligns LLMs step-wise with each metric
while leveraging simple yet powerful alignment algorithms such as direct
preference optimization (DPO). SACPO offers several advantages, including
simplicity, stability, computational efficiency, and flexibility of algorithms
and datasets. Under mild assumptions, our theoretical analysis provides the
upper bounds on optimality and safety constraint violation. Our experimental
results show that SACPO can fine-tune Alpaca-7B better than the
state-of-the-art method in terms of both helpfulness and harmlessness.",2024-04-17,"Akifumi Wachi, Thien Q. Tran, Rei Sato, Takumi Tanabe, Youhei Akimoto",http://arxiv.org/pdf/2404.11049v3,cs.CL
Offset Unlearning for Large Language Models,"Despite the strong capabilities of Large Language Models (LLMs) to acquire
knowledge from their training corpora, the memorization of sensitive
information in the corpora such as copyrighted, biased, and private content has
led to ethical and legal concerns. In response to these challenges, unlearning
has emerged as a potential remedy for LLMs affected by problematic training
data. However, previous unlearning techniques are either not applicable to
black-box LLMs due to required access to model internal weights, or violate
data protection principles by retaining sensitive data for inference-time
correction. We propose {\delta}-Unlearning, an offset unlearning framework for
black-box LLMs. Instead of tuning the black-box LLM itself, {\delta}-Unlearning
learns the logit offset needed for unlearning by contrasting the logits from a
pair of smaller models. Experiments demonstrate that {\delta}- Unlearning can
effectively unlearn target data while maintaining similar or even stronger
performance on general out-of-forget-scope tasks. {\delta}-Unlearning also
effectively incorporates different unlearning algorithms, making our approach a
versatile solution to adapting various existing unlearning algorithms to
black-box LLMs.",2024-04-17,"James Y. Huang, Wenxuan Zhou, Fei Wang, Fred Morstatter, Sheng Zhang, Hoifung Poon, Muhao Chen",http://arxiv.org/pdf/2404.11045v2,cs.CL
Cross-Platform Hate Speech Detection with Weakly Supervised Causal Disentanglement,"Content moderation faces a challenging task as social media's ability to
spread hate speech contrasts with its role in promoting global connectivity.
With rapidly evolving slang and hate speech, the adaptability of conventional
deep learning to the fluid landscape of online dialogue remains limited. In
response, causality inspired disentanglement has shown promise by segregating
platform specific peculiarities from universal hate indicators. However, its
dependency on available ground truth target labels for discerning these nuances
faces practical hurdles with the incessant evolution of platforms and the
mutable nature of hate speech. Using confidence based reweighting and
contrastive regularization, this study presents HATE WATCH, a novel framework
of weakly supervised causal disentanglement that circumvents the need for
explicit target labeling and effectively disentangles input features into
invariant representations of hate. Empirical validation across platforms two
with target labels and two without positions HATE WATCH as a novel method in
cross platform hate speech detection with superior performance. HATE WATCH
advances scalable content moderation techniques towards developing safer online
communities.",2024-04-17,"Paras Sheth, Tharindu Kumarage, Raha Moraffah, Aman Chadha, Huan Liu",http://arxiv.org/pdf/2404.11036v1,cs.CL
Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions,"Building socially-intelligent AI agents (Social-AI) is a multidisciplinary,
multimodal research goal that involves creating agents that can sense,
perceive, reason about, learn from, and respond to affect, behavior, and
cognition of other agents (human or artificial). Progress towards Social-AI has
accelerated in the past decade across several computing communities, including
natural language processing, machine learning, robotics, human-machine
interaction, computer vision, and speech. Natural language processing, in
particular, has been prominent in Social-AI research, as language plays a key
role in constructing the social world. In this position paper, we identify a
set of underlying technical challenges and open questions for researchers
across computing communities to advance Social-AI. We anchor our discussion in
the context of social intelligence concepts and prior progress in Social-AI
research.",2024-04-17,"Leena Mathur, Paul Pu Liang, Louis-Philippe Morency",http://arxiv.org/pdf/2404.11023v2,cs.CL
Many-Shot In-Context Learning,"Large language models (LLMs) excel at few-shot in-context learning (ICL) --
learning from a few examples provided in context at inference, without any
weight updates. Newly expanded context windows allow us to investigate ICL with
hundreds or thousands of examples -- the many-shot regime. Going from few-shot
to many-shot, we observe significant performance gains across a wide variety of
generative and discriminative tasks. While promising, many-shot ICL can be
bottlenecked by the available amount of human-generated examples. To mitigate
this limitation, we explore two new settings: Reinforced and Unsupervised ICL.
Reinforced ICL uses model-generated chain-of-thought rationales in place of
human examples. Unsupervised ICL removes rationales from the prompt altogether,
and prompts the model only with domain-specific questions. We find that both
Reinforced and Unsupervised ICL can be quite effective in the many-shot regime,
particularly on complex reasoning tasks. Finally, we demonstrate that, unlike
few-shot learning, many-shot learning is effective at overriding pretraining
biases, can learn high-dimensional functions with numerical inputs, and
performs comparably to fine-tuning. We also find that inference cost increases
linearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL
to varying degrees. Our analysis also reveals the limitations of next-token
prediction loss as an indicator of downstream ICL performance.",2024-04-17,"Rishabh Agarwal, Avi Singh, Lei M. Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang, Ankesh Anand, Zaheer Abbas, Azade Nova, John D. Co-Reyes, Eric Chu, Feryal Behbahani, Aleksandra Faust, Hugo Larochelle",http://arxiv.org/pdf/2404.11018v3,cs.CL
A Survey on Retrieval-Augmented Text Generation for Large Language Models,"Retrieval-Augmented Generation (RAG) merges retrieval methods with deep
learning advancements to address the static limitations of large language
models (LLMs) by enabling the dynamic integration of up-to-date external
information. This methodology, focusing primarily on the text domain, provides
a cost-effective solution to the generation of plausible but possibly incorrect
responses by LLMs, thereby enhancing the accuracy and reliability of their
outputs through the use of real-world data. As RAG grows in complexity and
incorporates multiple concepts that can influence its performance, this paper
organizes the RAG paradigm into four categories: pre-retrieval, retrieval,
post-retrieval, and generation, offering a detailed perspective from the
retrieval viewpoint. It outlines RAG's evolution and discusses the field's
progression through the analysis of significant studies. Additionally, the
paper introduces evaluation methods for RAG, addressing the challenges faced
and proposing future research directions. By offering an organized framework
and categorization, the study aims to consolidate existing research on RAG,
clarify its technological underpinnings, and highlight its potential to broaden
the adaptability and applications of LLMs.",2024-04-17,"Yizheng Huang, Jimmy Huang",http://arxiv.org/pdf/2404.10981v2,cs.CL
SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs,"Large language models (LLMs) have made significant advancements in various
natural language processing tasks, including question answering (QA) tasks.
While incorporating new information with the retrieval of relevant passages is
a promising way to improve QA with LLMs, the existing methods often require
additional fine-tuning which becomes infeasible with recent LLMs. Augmenting
retrieved passages via prompting has the potential to address this limitation,
but this direction has been limitedly explored. To this end, we design a simple
yet effective framework to enhance open-domain QA (ODQA) with LLMs, based on
the summarized retrieval (SuRe). SuRe helps LLMs predict more accurate answers
for a given question, which are well-supported by the summarized retrieval that
could be viewed as an explicit rationale extracted from the retrieved passages.
Specifically, SuRe first constructs summaries of the retrieved passages for
each of the multiple answer candidates. Then, SuRe confirms the most plausible
answer from the candidate set by evaluating the validity and ranking of the
generated summaries. Experimental results on diverse ODQA benchmarks
demonstrate the superiority of SuRe, with improvements of up to 4.6% in exact
match (EM) and 4.0% in F1 score over standard prompting approaches. SuRe also
can be integrated with a broad range of retrieval methods and LLMs. Finally,
the generated summaries from SuRe show additional advantages to measure the
importance of retrieved passages and serve as more preferred rationales by
models and humans.",2024-04-17,"Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha, Jinwoo Shin",http://arxiv.org/pdf/2404.13081v1,cs.CL
Procedural Dilemma Generation for Evaluating Moral Reasoning in Humans and Language Models,"As AI systems like language models are increasingly integrated into
decision-making processes affecting people's lives, it's critical to ensure
that these systems have sound moral reasoning. To test whether they do, we need
to develop systematic evaluations. We provide a framework that uses a language
model to translate causal graphs that capture key aspects of moral dilemmas
into prompt templates. With this framework, we procedurally generated a large
and diverse set of moral dilemmas -- the OffTheRails benchmark -- consisting of
50 scenarios and 400 unique test items. We collected moral permissibility and
intention judgments from human participants for a subset of our items and
compared these judgments to those from two language models (GPT-4 and Claude-2)
across eight conditions. We find that moral dilemmas in which the harm is a
necessary means (as compared to a side effect) resulted in lower permissibility
and higher intention ratings for both participants and language models. The
same pattern was observed for evitable versus inevitable harmful outcomes.
However, there was no clear effect of whether the harm resulted from an agent's
action versus from having omitted to act. We discuss limitations of our prompt
generation pipeline and opportunities for improving scenarios to increase the
strength of experimental effects.",2024-04-17,"Jan-Philipp Fränken, Kanishk Gandhi, Tori Qiu, Ayesha Khawaja, Noah D. Goodman, Tobias Gerstenberg",http://arxiv.org/pdf/2404.10975v1,cs.CL
Uncertainty-Based Abstention in LLMs Improves Safety and Reduces Hallucinations,"A major barrier towards the practical deployment of large language models
(LLMs) is their lack of reliability. Three situations where this is
particularly apparent are correctness, hallucinations when given unanswerable
questions, and safety. In all three cases, models should ideally abstain from
responding, much like humans, whose ability to understand uncertainty makes us
refrain from answering questions we don't know. Inspired by analogous
approaches in classification, this study explores the feasibility and efficacy
of abstaining while uncertain in the context of LLMs within the domain of
question-answering. We investigate two kinds of uncertainties, statistical
uncertainty metrics and a distinct verbalized measure, termed as In-Dialogue
Uncertainty (InDU). Using these uncertainty measures combined with models with
and without Reinforcement Learning with Human Feedback (RLHF), we show that in
all three situations, abstention based on the right kind of uncertainty measure
can boost the reliability of LLMs. By sacrificing only a few highly uncertain
samples we can improve correctness by 2% to 8%, avoid 50% hallucinations via
correctly identifying unanswerable questions and increase safety by 70% up to
99% with almost no additional computational overhead.",2024-04-16,"Christian Tomani, Kamalika Chaudhuri, Ivan Evtimov, Daniel Cremers, Mark Ibrahim",http://arxiv.org/pdf/2404.10960v1,cs.CL
Can Language Models Solve Olympiad Programming?,"Computing olympiads contain some of the most challenging problems for humans,
requiring complex algorithmic reasoning, puzzle solving, in addition to
generating efficient code. However, it has been understudied as a domain to
evaluate language models (LMs). In this paper, we introduce the USACO benchmark
with 307 problems from the USA Computing Olympiad, along with high-quality unit
tests, reference code, and official analyses for each problem. These resources
enable us to construct and test a range of LM inference methods for competitive
programming for the first time. We find GPT-4 only achieves a 8.7% pass@1
accuracy with zero-shot chain-of-thought prompting, and our best inference
method improves it to 20.2% using a combination of self-reflection and
retrieval over episodic knowledge. However, this is far from solving the
benchmark. To better understand the remaining challenges, we design a novel
human-in-the-loop study and surprisingly find that a small number of targeted
hints enable GPT-4 to solve 13 out of 15 problems previously unsolvable by any
model and method. Our benchmark, baseline methods, quantitative results, and
qualitative analysis serve as an initial step toward LMs with grounded,
creative, and algorithmic reasoning.",2024-04-16,"Quan Shi, Michael Tang, Karthik Narasimhan, Shunyu Yao",http://arxiv.org/pdf/2404.10952v1,cs.CL
More Room for Language: Investigating the Effect of Retrieval on Language Models,"Retrieval-augmented language models pose a promising alternative to standard
language modeling. During pretraining, these models search in a corpus of
documents for contextually relevant information that could aid the language
modeling objective. We introduce an 'ideal retrieval' methodology to study
these models in a fully controllable setting. We conduct an extensive
evaluation to examine how retrieval augmentation affects the behavior of the
underlying language model. Among other things, we observe that these models: i)
save substantially less world knowledge in their weights, ii) are better at
understanding local context and inter-word dependencies, but iii) are worse at
comprehending global context.",2024-04-16,"David Samuel, Lucas Georges Gabriel Charpentier, Sondre Wold",http://arxiv.org/pdf/2404.10939v1,cs.CL
Shears: Unstructured Sparsity with Neural Low-rank Adapter Search,"Recently, several approaches successfully demonstrated that weight-sharing
Neural Architecture Search (NAS) can effectively explore a search space of
elastic low-rank adapters (LoRA), allowing the parameter-efficient fine-tuning
(PEFT) and compression of large language models. In this paper, we introduce a
novel approach called Shears, demonstrating how the integration of
cost-effective sparsity and a proposed Neural Low-rank adapter Search (NLS)
algorithm can further improve the efficiency of PEFT approaches. Results
demonstrate the benefits of Shears compared to other methods, reaching high
sparsity levels while improving or with little drop in accuracy, utilizing a
single GPU for a pair of hours.",2024-04-16,"J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain",http://arxiv.org/pdf/2404.10934v1,cs.CL
LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs,"Fine-tuning pre-trained large language models (LLMs) with limited hardware
presents challenges due to GPU memory constraints. Various distributed
fine-tuning methods have been proposed to alleviate memory constraints on GPU.
However, determining the most effective method for achieving rapid fine-tuning
while preventing GPU out-of-memory issues in a given environment remains
unclear. To address this challenge, we introduce LLMem, a solution that
estimates the GPU memory consumption when applying distributed fine-tuning
methods across multiple GPUs and identifies the optimal method. We conduct GPU
memory usage estimation prior to fine-tuning, leveraging the fundamental
structure of transformer-based decoder models and the memory usage distribution
of each method. Experimental results show that LLMem accurately estimates peak
GPU memory usage on a single GPU, with error rates of up to 1.6%. Additionally,
it shows an average error rate of 3.0% when applying distributed fine-tuning
methods to LLMs with more than a billion parameters on multi-GPU setups.",2024-04-16,"Taeho Kim, Yanming Wang, Vatshank Chaturvedi, Lokesh Gupta, Seyeon Kim, Yongin Kwon, Sangtae Ha",http://arxiv.org/pdf/2404.10933v1,cs.CL
Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors,"For natural language understanding and generation, embedding concepts using
an order-based representation is an essential task. Unlike traditional point
vector based representation, an order-based representation imposes geometric
constraints on the representation vectors for explicitly capturing various
semantic relationships that may exist between a pair of concepts. In existing
literature, several approaches on order-based embedding have been proposed,
mostly focusing on capturing hierarchical relationships; examples include
vectors in Euclidean space, complex, Hyperbolic, order, and Box Embedding. Box
embedding creates region-based rich representation of concepts, but along the
process it sacrifices simplicity, requiring a custom-made optimization scheme
for learning the representation. Hyperbolic embedding improves embedding
quality by exploiting the ever-expanding property of Hyperbolic space, but it
also suffers from the same fate as box embedding as gradient descent like
optimization is not simple in the Hyperbolic space. In this work, we propose
Binder, a novel approach for order-based representation. Binder uses binary
vectors for embedding, so the embedding vectors are compact with an order of
magnitude smaller footprint than other methods. Binder uses a simple and
efficient optimization scheme for learning representation vectors with a linear
time complexity. Our comprehensive experimental results show that Binder is
very accurate, yielding competitive results on the representation task. But
Binder stands out from its competitors on the transitive closure link
prediction task as it can learn concept embeddings just from the direct edges,
whereas all existing order-based approaches rely on the indirect edges.",2024-04-16,"Croix Gyurek, Niloy Talukder, Mohammad Al Hasan",http://arxiv.org/pdf/2404.10924v1,cs.CL
Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training,"Recent advancements in language modeling have led to the emergence of Large
Language Models (LLMs) capable of various natural language processing tasks.
Despite their success in text-based tasks, applying LLMs to the speech domain
remains limited and challenging. This paper presents BLOOMZMMS, a novel model
that integrates a multilingual LLM with a multilingual speech encoder, aiming
to harness the capabilities of LLMs for speech recognition and beyond.
Utilizing a multi-instructional training approach, we demonstrate the
transferability of linguistic knowledge from the text to the speech modality.
Our experiments, conducted on 1900 hours of transcribed data from 139
languages, establish that a multilingual speech representation can be
effectively learned and aligned with a multilingual LLM. While this learned
representation initially shows limitations in task generalization, we address
this issue by generating synthetic targets in a multi-instructional style. Our
zero-shot evaluation results confirm the robustness of our approach across
multiple tasks, including speech translation and multilingual spoken language
understanding, thereby opening new avenues for applying LLMs in the speech
domain.",2024-04-16,"Pavel Denisov, Ngoc Thang Vu",http://arxiv.org/pdf/2404.10922v1,cs.CL
Which questions should I answer? Salience Prediction of Inquisitive Questions,"Inquisitive questions -- open-ended, curiosity-driven questions people ask as
they read -- are an integral part of discourse processing (Kehler and Rohde,
2017; Onea, 2016) and comprehension (Prince, 2004). Recent work in NLP has
taken advantage of question generation capabilities of LLMs to enhance a wide
range of applications. But the space of inquisitive questions is vast: many
questions can be evoked from a given context. So which of those should be
prioritized to find answers? Linguistic theories, unfortunately, have not yet
provided an answer to this question. This paper presents QSALIENCE, a salience
predictor of inquisitive questions. QSALIENCE is instruction-tuned over our
dataset of linguist-annotated salience scores of 1,766 (context, question)
pairs. A question scores high on salience if answering it would greatly enhance
the understanding of the text (Van Rooy, 2003). We show that highly salient
questions are empirically more likely to be answered in the same article,
bridging potential questions (Onea, 2016) with Questions Under Discussion
(Roberts, 2012). We further validate our findings by showing that answering
salient questions is an indicator of summarization quality in news.",2024-04-16,"Yating Wu, Ritika Mangla, Alexandros G. Dimakis, Greg Durrett, Junyi Jessy Li",http://arxiv.org/pdf/2404.10917v2,cs.CL
Grounded Language Agent for Product Search via Intelligent Web Interactions,"The development of agents powered by large language models (LLMs) to
accomplish complex high-level user intents, has attracted significant attention
recently. However, employing LLMs with billions of parameters (e.g., GPT-4) may
incur substantial costs on top of handcrafting extensive prompts. To address
this, we introduce a Grounded Language Agent for Intelligent Web Interactions,
named GLAINTEL. GLAINTEL employs Flan-T5 as its backbone and is flexible in
training in various settings: unsupervised learning, supervised learning, and
unsupervised domain adaptation. Specifically, we tackle both the challenge of
learning without human demonstrations and the opportunity to leverage human
demonstrations effectively when those are available. Additionally, we explore
unsupervised domain adaptation for cases where demonstrations are limited to a
specific domain. Experimental evaluations across diverse setups demonstrate the
effectiveness of GLAINTEL in unsupervised settings, outperforming in-context
learning-based approaches that employ larger models with up to 540 billion
parameters. Surprisingly, behavioral cloning-based methods that
straightforwardly use human demonstrations do not outperform unsupervised
variants of GLAINTEL. Additionally, we show that combining human demonstrations
with reinforcement learning-based training yields results comparable to methods
utilizing GPT-4. The code is available at:
https://github.com/MultifacetedNLP/WebAgents-Unsupervised.",2024-04-16,"Moghis Fereidouni, Adib Mosharrof, A. B. Siddique",http://arxiv.org/pdf/2404.10887v2,cs.CL
Incubating Text Classifiers Following User Instruction with Nothing but LLM,"In this paper, we aim to generate text classification data given arbitrary
class definitions (i.e., user instruction), so one can train a small text
classifier without any human annotation or raw corpus. Compared with pioneer
attempts, our proposed Incubator is the first framework that can handle
complicated and even mutually dependent classes (e.g., ""TED Talk given by
Educator"" and ""Other""). Specifically, Incubator is an LLM firstly tuned on the
instruction-to-data mappings that we obtained from classification datasets and
descriptions on HuggingFace together with in-context augmentation by GPT-4. We
then refine Incubator by learning on the cluster centers of semantic textual
embeddings to emphasize the uniformity and semantic diversity in generations.
We compare Incubator on various classification tasks with strong baselines such
as direct LLM-based inference and training data generation by prompt
engineering. Experiments show Incubator is able to (1) perform well on
traditional benchmarks, (2) take label dependency and user preference into
consideration, and (3) enable logical text mining by incubating multiple
classifiers.",2024-04-16,"Letian Peng, Jingbo Shang",http://arxiv.org/pdf/2404.10877v2,cs.CL
Forcing Diffuse Distributions out of Language Models,"Despite being trained specifically to follow user instructions, today's
instructiontuned language models perform poorly when instructed to produce
random outputs. For example, when prompted to pick a number uniformly between
one and ten Llama-2-13B-chat disproportionately favors the number five, and
when tasked with picking a first name at random, Mistral-7B-Instruct chooses
Avery 40 times more often than we would expect based on the U.S. population.
When these language models are used for real-world tasks where diversity of
outputs is crucial, such as language model assisted dataset construction, their
inability to produce diffuse distributions over valid choices is a major
hurdle. In this work, we propose a fine-tuning method that encourages language
models to output distributions that are diffuse over valid outcomes. The
methods we introduce generalize across a variety of tasks and distributions and
make large language models practical for synthetic dataset generation with
little human intervention.",2024-04-16,"Yiming Zhang, Avi Schwarzschild, Nicholas Carlini, Zico Kolter, Daphne Ippolito",http://arxiv.org/pdf/2404.10859v2,cs.CL
D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation,"While human annotations play a crucial role in language technologies,
annotator subjectivity has long been overlooked in data collection. Recent
studies that have critically examined this issue are often situated in the
Western context, and solely document differences across age, gender, or racial
groups. As a result, NLP research on subjectivity have overlooked the fact that
individuals within demographic groups may hold diverse values, which can
influence their perceptions beyond their group norms. To effectively
incorporate these considerations into NLP pipelines, we need datasets with
extensive parallel annotations from various social and cultural groups. In this
paper we introduce the \dataset dataset: a large-scale cross-cultural dataset
of parallel annotations for offensive language in over 4.5K sentences annotated
by a pool of over 4k annotators, balanced across gender and age, from across 21
countries, representing eight geo-cultural regions. The dataset contains
annotators' moral values captured along six moral foundations: care, equality,
proportionality, authority, loyalty, and purity. Our analyses reveal
substantial regional variations in annotators' perceptions that are shaped by
individual moral values, offering crucial insights for building pluralistic,
culturally sensitive NLP models.",2024-04-16,"Aida Mostafazadeh Davani, Mark Díaz, Dylan Baker, Vinodkumar Prabhakaran",http://arxiv.org/pdf/2404.10857v1,cs.CL
A LayoutLMv3-Based Model for Enhanced Relation Extraction in Visually-Rich Documents,"Document Understanding is an evolving field in Natural Language Processing
(NLP). In particular, visual and spatial features are essential in addition to
the raw text itself and hence, several multimodal models were developed in the
field of Visual Document Understanding (VDU). However, while research is mainly
focused on Key Information Extraction (KIE), Relation Extraction (RE) between
identified entities is still under-studied. For instance, RE is crucial to
regroup entities or obtain a comprehensive hierarchy of data in a document. In
this paper, we present a model that, initialized from LayoutLMv3, can match or
outperform the current state-of-the-art results in RE applied to Visually-Rich
Documents (VRD) on FUNSD and CORD datasets, without any specific pre-training
and with fewer parameters. We also report an extensive ablation study performed
on FUNSD, highlighting the great impact of certain features and modelization
choices on the performances.",2024-04-16,"Wiam Adnan, Joel Tang, Yassine Bel Khayat Zouggari, Seif Edinne Laatiri, Laurent Lam, Fabien Caspani",http://arxiv.org/pdf/2404.10848v1,cs.CL
Dynamic Self-adaptive Multiscale Distillation from Pre-trained Multimodal Large Model for Efficient Cross-modal Representation Learning,"In recent years, pre-trained multimodal large models have attracted
widespread attention due to their outstanding performance in various multimodal
applications. Nonetheless, the extensive computational resources and vast
datasets required for their training present significant hurdles for deployment
in environments with limited computational resources. To address this
challenge, we propose a novel dynamic self-adaptive multiscale distillation
from pre-trained multimodal large model for efficient cross-modal
representation learning for the first time. Unlike existing distillation
methods, our strategy employs a multiscale perspective, enabling the extraction
structural knowledge across from the pre-trained multimodal large model.
Ensuring that the student model inherits a comprehensive and nuanced
understanding of the teacher knowledge. To optimize each distillation loss in a
balanced and efficient manner, we propose a dynamic self-adaptive distillation
loss balancer, a novel component eliminating the need for manual loss weight
adjustments and dynamically balances each loss item during the distillation
process. Our methodology streamlines pre-trained multimodal large models using
only their output features and original image-level information, requiring
minimal computational resources. This efficient approach is suited for various
applications and allows the deployment of advanced multimodal technologies even
in resource-limited settings. Extensive experiments has demonstrated that our
method maintains high performance while significantly reducing model complexity
and training costs. Moreover, our distilled student model utilizes only
image-level information to achieve state-of-the-art performance on cross-modal
retrieval tasks, surpassing previous methods that relied on region-level
information.",2024-04-16,"Zhengyang Liang, Meiyu Liang, Wei Huang, Yawen Li, Zhe Xue",http://arxiv.org/pdf/2404.10838v1,cs.CL
Fewer Truncations Improve Language Modeling,"In large language model training, input documents are typically concatenated
together and then split into sequences of equal length to avoid padding tokens.
Despite its efficiency, the concatenation approach compromises data integrity
-- it inevitably breaks many documents into incomplete pieces, leading to
excessive truncations that hinder the model from learning to compose logically
coherent and factually consistent content that is grounded on the complete
context. To address the issue, we propose Best-fit Packing, a scalable and
efficient method that packs documents into training sequences through
length-aware combinatorial optimization. Our method completely eliminates
unnecessary truncations while retaining the same training efficiency as
concatenation. Empirical results from both text and code pre-training show that
our method achieves superior performance (e.g., relatively +4.7% on reading
comprehension; +16.8% in context following; and +9.2% on program synthesis),
and reduces closed-domain hallucination effectively by up to 58.3%.",2024-04-16,"Hantian Ding, Zijian Wang, Giovanni Paolini, Varun Kumar, Anoop Deoras, Dan Roth, Stefano Soatto",http://arxiv.org/pdf/2404.10830v2,cs.CL
MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents,"Recognizing if LLM output can be grounded in evidence is central to many
tasks in NLP: retrieval-augmented generation, summarization, document-grounded
dialogue, and more. Current approaches to this kind of fact-checking are based
on verifying each piece of a model generation against potential evidence using
an LLM. However, this process can be very computationally expensive, requiring
many calls to a model to check a single response. In this work, we show how to
build small fact-checking models that have GPT-4-level performance but for 400x
lower cost. We do this by constructing synthetic training data with GPT-4,
which involves creating realistic yet challenging instances of factual errors
via a structured generation procedure. Training on this data teaches models to
check each fact in the claim and recognize synthesis of information across
sentences. For evaluation, we unify datasets from recent work on fact-checking
and grounding LLM generations into a new benchmark, LLM-AggreFact. Our best
system MiniCheck-FT5 (770M parameters) outperforms all systems of comparable
size and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data
synthesis, and models.",2024-04-16,"Liyan Tang, Philippe Laban, Greg Durrett",http://arxiv.org/pdf/2404.10774v2,cs.CL
LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?,"Diffusion models have exhibited remarkable capabilities in text-to-image
generation. However, their performance in image-to-text generation,
specifically image captioning, has lagged behind Auto-Regressive (AR) models,
casting doubt on their applicability for such tasks. In this work, we revisit
diffusion models, highlighting their capacity for holistic context modeling and
parallel decoding. With these benefits, diffusion models can alleviate the
inherent limitations of AR methods, including their slow inference speed, error
propagation, and unidirectional constraints. Furthermore, we identify the prior
underperformance of diffusion models stemming from the absence of an effective
latent space for image-text alignment, and the discrepancy between continuous
diffusion processes and discrete textual data. In response, we introduce a
novel architecture, LaDiC, which utilizes a split BERT to create a dedicated
latent space for captions and integrates a regularization module to manage
varying text lengths. Our framework also includes a diffuser for semantic
image-to-text conversion and a Back&Refine technique to enhance token
interactivity during inference. LaDiC achieves state-of-the-art performance for
diffusion-based methods on the MS COCO dataset with 38.2 BLEU@4 and 126.2
CIDEr, demonstrating exceptional performance without pre-training or ancillary
modules. This indicates strong competitiveness with AR models, revealing the
previously untapped potential of diffusion models in image-to-text generation.",2024-04-16,"Yuchi Wang, Shuhuai Ren, Rundong Gao, Linli Yao, Qingyan Guo, Kaikai An, Jianhong Bai, Xu Sun",http://arxiv.org/pdf/2404.10763v1,cs.CL
Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification,"Light curves serve as a valuable source of information on stellar formation
and evolution. With the rapid advancement of machine learning techniques, it
can be effectively processed to extract astronomical patterns and information.
In this study, we present a comprehensive evaluation of deep-learning and large
language model (LLM) based models for the automatic classification of variable
star light curves, based on large datasets from the Kepler and K2 missions.
Special emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries,
examining the influence of observational cadence and phase distribution on
classification precision. Employing AutoDL optimization, we achieve striking
performance with the 1D-Convolution+BiLSTM architecture and the Swin
Transformer, hitting accuracies of 94\% and 99\% correspondingly, with the
latter demonstrating a notable 83\% accuracy in discerning the elusive Type II
Cepheids-comprising merely 0.02\% of the total dataset.We unveil StarWhisper
LightCurve (LC), an innovative Series comprising three LLM-based models: LLM,
multimodal large language model (MLLM), and Large Audio Language Model (LALM).
Each model is fine-tuned with strategic prompt engineering and customized
training methods to explore the emergent abilities of these models for
astronomical data. Remarkably, StarWhisper LC Series exhibit high accuracies
around 90\%, significantly reducing the need for explicit feature engineering,
thereby paving the way for streamlined parallel data processing and the
progression of multifaceted multimodal models in astronomical applications. The
study furnishes two detailed catalogs illustrating the impacts of phase and
sampling intervals on deep learning classification accuracy, showing that a
substantial decrease of up to 14\% in observation duration and 21\% in sampling
points can be realized without compromising accuracy by more than 10\%.",2024-04-16,"Yu-Yang Li, Yu Bai, Cunshi Wang, Mengwei Qu, Ziteng Lu, Roberto Soria, Jifeng Liu",http://arxiv.org/pdf/2404.10757v2,cs.CL
Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study,"Reinforcement Learning from Human Feedback (RLHF) is currently the most
widely used method to align large language models (LLMs) with human
preferences. Existing RLHF methods can be roughly categorized as either
reward-based or reward-free. Novel applications such as ChatGPT and Claude
leverage reward-based methods that first learn a reward model and apply
actor-critic algorithms, such as Proximal Policy Optimization (PPO). However,
in academic benchmarks, state-of-the-art results are often achieved via
reward-free methods, such as Direct Preference Optimization (DPO). Is DPO truly
superior to PPO? Why does PPO perform poorly on these benchmarks? In this
paper, we first conduct both theoretical and empirical studies on the
algorithmic properties of DPO and show that DPO may have fundamental
limitations. Moreover, we also comprehensively examine PPO and reveal the key
factors for the best performances of PPO in fine-tuning LLMs. Finally, we
benchmark DPO and PPO across a collection of RLHF testbeds, ranging from
dialogue to code generation. Experiment results demonstrate that PPO is able to
surpass other alignment methods in all cases and achieve state-of-the-art
results in challenging code competitions. Our code is publicly available at
https://github.com/openpsi-project/ReaLHF.",2024-04-16,"Shusheng Xu, Wei Fu, Jiaxuan Gao, Wenjie Ye, Weilin Liu, Zhiyu Mei, Guangju Wang, Chao Yu, Yi Wu",http://arxiv.org/pdf/2404.10719v3,cs.CL
Autoregressive Pre-Training on Pixels and Texts,"The integration of visual and textual information represents a promising
direction in the advancement of language models. In this paper, we explore the
dual modality of language--both visual and textual--within an autoregressive
framework, pre-trained on both document images and texts. Our method employs a
multimodal training strategy, utilizing visual data through next patch
prediction with a regression head and/or textual data through next token
prediction with a classification head. We focus on understanding the
interaction between these two modalities and their combined impact on model
performance. Our extensive evaluation across a wide range of benchmarks shows
that incorporating both visual and textual data significantly improves the
performance of pixel-based language models. Remarkably, we find that a
unidirectional pixel-based model trained solely on visual data can achieve
comparable results to state-of-the-art bidirectional models on several language
understanding tasks. This work uncovers the untapped potential of integrating
visual and textual modalities for more effective language modeling. We release
our code, data, and model checkpoints at
\url{https://github.com/ernie-research/pixelgpt}.",2024-04-16,"Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, Hua Wu",http://arxiv.org/pdf/2404.10710v3,cs.CL
Cross-Language Evolution of Divergent Collective Memory Around the Arab Spring,"The Arab Spring was a historic set of protests beginning in 2011 that toppled
governments and led to major conflicts. Collective memories of events like
these can vary significantly across social contexts in response to political,
cultural, and linguistic factors. While Wikipedia plays an important role in
documenting both historic and current events, little attention has been given
to how Wikipedia articles, created in the aftermath of major events, continue
to evolve over years or decades. Using the archived content of Arab
Spring-related topics across the Arabic and English Wikipedias between 2011 and
2024, we define and evaluate multilingual measures of event salience,
deliberation, contextualization, and consolidation of collective memory
surrounding the Arab Spring. Our findings about the temporal evolution of the
Wikipedia articles' content similarity across languages has implications for
theorizing about online collective memory processes and evaluating linguistic
models trained on these data.",2024-04-16,"H. Laurie Jones, Brian C. Keegan",http://arxiv.org/pdf/2404.10706v1,cs.CL
Question Difficulty Ranking for Multiple-Choice Reading Comprehension,"Multiple-choice (MC) tests are an efficient method to assess English
learners. It is useful for test creators to rank candidate MC questions by
difficulty during exam curation. Typically, the difficulty is determined by
having human test takers trial the questions in a pretesting stage. However,
this is expensive and not scalable. Therefore, we explore automated approaches
to rank MC questions by difficulty. However, there is limited data for explicit
training of a system for difficulty scores. Hence, we compare task transfer and
zero-shot approaches: task transfer adapts level classification and reading
comprehension systems for difficulty ranking while zero-shot prompting of
instruction finetuned language models contrasts absolute assessment against
comparative. It is found that level classification transfers better than
reading comprehension. Additionally, zero-shot comparative assessment is more
effective at difficulty ranking than the absolute assessment and even the task
transfer approaches at question difficulty ranking with a Spearman's
correlation of 40.4%. Combining the systems is observed to further boost the
correlation.",2024-04-16,"Vatsal Raina, Mark Gales",http://arxiv.org/pdf/2404.10704v1,cs.CL
Integrating knowledge bases to improve coreference and bridging resolution for the chemical domain,"Resolving coreference and bridging relations in chemical patents is important
for better understanding the precise chemical process, where chemical domain
knowledge is very critical. We proposed an approach incorporating external
knowledge into a multi-task learning model for both coreference and bridging
resolution in the chemical domain. The results show that integrating external
knowledge can benefit both chemical coreference and bridging resolution.",2024-04-16,"Pengcheng Lu, Massimo Poesio",http://arxiv.org/pdf/2404.10696v1,cs.CL
ViTextVQA: A Large-Scale Visual Question Answering Dataset for Evaluating Vietnamese Text Comprehension in Images,"Visual Question Answerinng (VQA) is a complicated task that requires the
capability of simultaneously processing natural language and images. This task
was initially researched with a focus on developing methods to help machines
understand objects and scene contexts in images. However, some scene text that
carries explicit information about the full content of the image is not
mentioned. Along with the continuous development of the AI era, there have been
many studies on the reading comprehension ability of VQA models in the world.
Therefore, we introduce the first large-scale dataset in Vietnamese
specializing in the ability to understand scene text, we call it ViTextVQA
(\textbf{Vi}etnamese \textbf{Text}-based \textbf{V}isual \textbf{Q}uestion
\textbf{A}nswering dataset) which contains \textbf{over 16,000} images and
\textbf{over 50,000} questions with answers. To tackle this task efficiently,
we propose ViTextBLIP-2, an novel multimodal feature fusion Method, which
optimizes Vietnamese OCR-based VQA by integrating a frozen Vision Transformer,
SwinTextSpotter OCR, and ViT5 LLM with a trainable Q-Former for multimodal
feature fusion. Through experiments with various state-of-the-art models, we
uncover the significance of the order in which tokens in OCR text are processed
and selected to formulate answers. This finding helped us significantly improve
the performance of the baseline models on the ViTextVQA dataset. Our dataset is
available (https://github.com/minhquan6203/ViTextVQA-Dataset) for research
purposes.",2024-04-16,"Quan Van Nguyen, Dan Quang Tran, Huy Quang Pham, Thang Kien-Bao Nguyen, Nghia Hieu Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen",http://arxiv.org/pdf/2404.10652v3,cs.CL
Self-playing Adversarial Language Game Enhances LLM Reasoning,"We explore the potential of self-play training for large language models
(LLMs) in a two-player adversarial language game called Adversarial Taboo. In
this game, an attacker and a defender communicate around a target word only
visible to the attacker. The attacker aims to induce the defender to speak the
target word unconsciously, while the defender tries to infer the target word
from the attacker's utterances. To win the game, both players must have
sufficient knowledge about the target word and high-level reasoning ability to
infer and express in this information-reserved conversation. Hence, we are
curious about whether LLMs' reasoning ability can be further enhanced by
Self-Playing this Adversarial language Game (SPAG). With this goal, we select
several open-source LLMs and let each act as the attacker and play with a copy
of itself as the defender on an extensive range of target words. Through
reinforcement learning on the game outcomes, we observe that the LLMs'
performances uniformly improve on a broad range of reasoning benchmarks.
Furthermore, iteratively adopting this self-play process can continuously
promote LLMs' reasoning abilities. The code is available at
https://github.com/Linear95/SPAG.",2024-04-16,"Pengyu Cheng, Tianhao Hu, Han Xu, Zhisong Zhang, Zheng Yuan, Yong Dai, Lei Han, Nan Du, Xiaolong Li",http://arxiv.org/pdf/2404.10642v3,cs.CL
HLAT: High-quality Large Language Model Pre-trained on AWS Trainium,"Getting large language models (LLMs) to perform well on the downstream tasks
requires pre-training over trillions of tokens. This typically demands a large
number of powerful computational devices in addition to a stable distributed
training framework to accelerate the training. The growing number of
applications leveraging AI/ML led to a scarcity of the expensive conventional
accelerators (such as GPUs), which emphasizes the need for the alternative
specialized-accelerators that are scalable and cost-efficient. AWS Trainium is
the second-generation machine learning accelerator purposely built for training
large deep learning models. However, training LLMs with billions of parameters
on AWS Trainium is challenging due to its relatively nascent software
ecosystem. In this paper, we showcase HLAT: a family of 7B and 70B decoder-only
LLMs pre-trained using 4096 AWS Trainium accelerators over 1.8 trillion tokens.
The performance of HLAT is benchmarked against popular open source models
including LLaMA and OpenLLaMA, which have been trained on NVIDIA GPUs and
Google TPUs, respectively. On various evaluation tasks, we show that HLAT
achieves model quality on par with the baselines of similar model size. We also
open-source all the training scripts and configurations of HLAT
(https://github.com/awslabs/HLAT) and share the best practice of using the
NeuronX Distributed Training (NxDT), a customized distributed training library
for AWS Trainium. Our work demonstrates that AWS Trainium powered by NxDT is
able to successfully pre-train state-of-the-art LLM models with high
performance and cost-effectiveness.",2024-04-16,"Haozheng Fan, Hao Zhou, Guangtai Huang, Parameswaran Raman, Xinwei Fu, Gaurav Gupta, Dhananjay Ram, Yida Wang, Jun Huan",http://arxiv.org/pdf/2404.10630v2,cs.CL
The application of Augmented Reality (AR) in Remote Work and Education,"With the rapid advancement of technology, Augmented Reality (AR) technology,
known for its ability to deeply integrate virtual information with the real
world, is gradually transforming traditional work modes and teaching methods.
Particularly in the realms of remote work and online education, AR technology
demonstrates a broad spectrum of application prospects. This paper delves into
the application potential and actual effects of AR technology in remote work
and education. Through a systematic literature review, this study outlines the
key features, advantages, and challenges of AR technology. Based on theoretical
analysis, it discusses the scientific basis and technical support that AR
technology provides for enhancing remote work efficiency and promoting
innovation in educational teaching models. Additionally, by designing an
empirical research plan and analyzing experimental data, this article reveals
the specific performance and influencing factors of AR technology in practical
applications. Finally, based on the results of the experiments, this research
summarizes the application value of AR technology in remote work and education,
looks forward to its future development trends, and proposes forward-looking
research directions and strategic suggestions, offering empirical foundation
and theoretical guidance for further promoting the in-depth application of AR
technology in related fields.",2024-04-16,"Keqin Li, Peng Xirui, Jintong Song, Bo Hong, Jin Wang",http://arxiv.org/pdf/2404.10579v1,cs.CL
Construction of Domain-specified Japanese Large Language Model for Finance through Continual Pre-training,"Large language models (LLMs) are now widely used in various fields, including
finance. However, Japanese financial-specific LLMs have not been proposed yet.
Hence, this study aims to construct a Japanese financial-specific LLM through
continual pre-training. Before tuning, we constructed Japanese
financial-focused datasets for continual pre-training. As a base model, we
employed a Japanese LLM that achieved state-of-the-art performance on Japanese
financial benchmarks among the 10-billion-class parameter models. After
continual pre-training using the datasets and the base model, the tuned model
performed better than the original model on the Japanese financial benchmarks.
Moreover, the outputs comparison results reveal that the tuned model's outputs
tend to be better than the original model's outputs in terms of the quality and
length of the answers. These findings indicate that domain-specific continual
pre-training is also effective for LLMs. The tuned model is publicly available
on Hugging Face.",2024-04-16,"Masanori Hirano, Kentaro Imajo",http://arxiv.org/pdf/2404.10555v1,cs.CL
Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning,"The open-sourcing of large language models (LLMs) accelerates application
development, innovation, and scientific progress. This includes both base
models, which are pre-trained on extensive datasets without alignment, and
aligned models, deliberately designed to align with ethical standards and human
values. Contrary to the prevalent assumption that the inherent
instruction-following limitations of base LLMs serve as a safeguard against
misuse, our investigation exposes a critical oversight in this belief. By
deploying carefully designed demonstrations, our research demonstrates that
base LLMs could effectively interpret and execute malicious instructions. To
systematically assess these risks, we introduce a novel set of risk evaluation
metrics. Empirical results reveal that the outputs from base LLMs can exhibit
risk levels on par with those of models fine-tuned for malicious purposes. This
vulnerability, requiring neither specialized knowledge nor training, can be
manipulated by almost anyone, highlighting the substantial risk and the
critical need for immediate attention to the base LLMs' security protocols.",2024-04-16,"Xiao Wang, Tianze Chen, Xianjun Yang, Qi Zhang, Xun Zhao, Dahua Lin",http://arxiv.org/pdf/2404.10552v1,cs.CL
CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity,"State-of-the-art performance in QA tasks is currently achieved by systems
employing Large Language Models (LLMs), however these models tend to
hallucinate information in their responses. One approach focuses on enhancing
the generation process by incorporating attribution from the given input to the
output. However, the challenge of identifying appropriate attributions and
verifying their accuracy against a source is a complex task that requires
significant improvements in assessing such systems. We introduce an
attribution-oriented Chain-of-Thought reasoning method to enhance the accuracy
of attributions. This approach focuses the reasoning process on generating an
attribution-centric output. Evaluations on two context-enhanced
question-answering datasets using GPT-4 demonstrate improved accuracy and
correctness of attributions. In addition, the combination of our method with
finetuning enhances the response and attribution accuracy of two smaller LLMs,
showing their potential to outperform GPT-4 in some cases.",2024-04-16,"Moshe Berchansky, Daniel Fleischer, Moshe Wasserblat, Peter Izsak",http://arxiv.org/pdf/2404.10513v2,cs.CL
"White Men Lead, Black Women Help? Benchmarking Language Agency Social Biases in LLMs","Social biases can manifest in language agency. While several studies
approached agency-related bias in human-written language, very limited research
has investigated such biases in Large Language Model (LLM)-generated content.
In addition, previous works often rely on string-matching techniques to
identify agentic and communal words within texts, which fall short of
accurately classifying language agency. We introduce the novel Language Agency
Bias Evaluation (LABE) benchmark, which comprehensively evaluates biases in
LLMs by analyzing agency levels attributed to different demographic groups in
model generations. LABE leverages 5,400 template-based prompts, an accurate
agency classifier, and corresponding bias metrics to test for gender, racial,
and intersectional language agency biases in LLMs on 3 text generation tasks:
biographies, professor reviews, and reference letters. We also contribute the
Language Agency Classification (LAC) dataset, consisting of 3,724 agentic and
communal sentences. Using LABE, we unveil language agency social biases in 3
recent LLMs: ChatGPT, Llama3, and Mistral. We observe that: (1) LLM generations
tend to demonstrate greater gender bias than human-written texts; (2) Models
demonstrate remarkably higher levels of intersectional bias than the other bias
aspects. Those who are at the intersection of gender and racial minority
groups--such as Black females--are consistently described by texts with lower
levels of agency, aligning with real-world social inequalities; (3) Among the 3
LLMs investigated, Llama3 demonstrates the greatest overall bias; (4) Not only
does prompt-based mitigation fail to resolve language agency bias in LLMs, but
it frequently leads to the exacerbation of biases in generated texts.",2024-04-16,"Yixin Wan, Kai-Wei Chang",http://arxiv.org/pdf/2404.10508v4,cs.CL
A Sentiment Analysis of Medical Text Based on Deep Learning,"The field of natural language processing (NLP) has made significant progress
with the rapid development of deep learning technologies. One of the research
directions in text sentiment analysis is sentiment analysis of medical texts,
which holds great potential for application in clinical diagnosis. However, the
medical field currently lacks sufficient text datasets, and the effectiveness
of sentiment analysis is greatly impacted by different model design approaches,
which presents challenges. Therefore, this paper focuses on the medical domain,
using bidirectional encoder representations from transformers (BERT) as the
basic pre-trained model and experimenting with modules such as convolutional
neural network (CNN), fully connected network (FCN), and graph convolutional
networks (GCN) at the output layer. Experiments and analyses were conducted on
the METS-CoV dataset to explore the training performance after integrating
different deep learning networks. The results indicate that CNN models
outperform other networks when trained on smaller medical text datasets in
combination with pre-trained models like BERT. This study highlights the
significance of model selection in achieving effective sentiment analysis in
the medical domain and provides a reference for future research to develop more
efficient model architectures.",2024-04-16,Yinan Chen,http://arxiv.org/pdf/2404.10503v1,cs.CL
Self-Supervised Visual Preference Alignment,"This paper makes the first attempt towards unsupervised preference alignment
in Vision-Language Models (VLMs). We generate chosen and rejected responses
with regard to the original and augmented image pairs, and conduct preference
alignment with direct preference optimization. It is based on a core idea:
properly designed augmentation to the image input will induce VLM to generate
false but hard negative responses, which helps the model to learn from and
produce more robust and powerful answers. The whole pipeline no longer hinges
on supervision from GPT-4 or human involvement during alignment, and is highly
efficient with few lines of code. With only 8k randomly sampled unsupervised
data, it achieves 90\% relative score to GPT-4 on complex reasoning in
LLaVA-Bench, and improves LLaVA-7B/13B by 6.7\%/5.6\% score on complex
multi-modal benchmark MM-Vet. Visualizations shows its improved ability to
align with user-intentions. A series of ablations are firmly conducted to
reveal the latent mechanism of the approach, which also indicates its potential
towards further scaling. Code are available in
https://github.com/Kevinz-code/SeVa.",2024-04-16,"Ke Zhu, Zheng Ge, Liang Zhao, Xiangyu Zhang",http://arxiv.org/pdf/2404.10501v2,cs.CL
When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm,"With the development of Large Language Models (LLM), numerous prompts have
been proposed, each with a rich set of features and their own merits. This
paper summarizes the prompt words for large language models (LLMs),
categorizing them into stimulating and framework types, and proposes an
Auto-Prompt Graphical Paradigm(APGP) that combines both stimulating and
framework prompts to enhance the problem-solving capabilities of LLMs across
multiple domains, then exemplifies it with a framework that adheres to this
paradigm. The framework involves automated prompt generation and consideration
of emotion-stimulus factors, guiding LLMs in problem abstraction, diversified
solutions generation, comprehensive optimization, and self-verification after
providing answers, ensuring solution accuracy. Compared to traditional stimuli
and framework prompts, this framework integrates the advantages of both by
adopting automated approaches inspired by APE work, overcoming the limitations
of manually designed prompts. Test results on the ruozhiba and BBH datasets
demonstrate that this framework can effectively improve the efficiency and
accuracy of LLMs in problem-solving, paving the way for new applications of
LLMs.",2024-04-16,"Chenggian Ma, Xiangyu Zhao, Chunhui Zhang, Yanzhao Qin, Wentao Zhang",http://arxiv.org/pdf/2404.10500v1,cs.CL
Conversations as a Source for Teaching Scientific Concepts at Different Education Levels,"Open conversations are one of the most engaging forms of teaching. However,
creating those conversations in educational software is a complex endeavor,
especially if we want to address the needs of different audiences. While
language models hold great promise for educational applications, there are
substantial challenges in training them to engage in meaningful and effective
conversational teaching, especially when considering the diverse needs of
various audiences. No official data sets exist for this task to facilitate the
training of language models for conversational teaching, considering the
diverse needs of various audiences. This paper presents a novel source for
facilitating conversational teaching of scientific concepts at various
difficulty levels (from preschooler to expert), namely dialogues taken from
video transcripts. We analyse this data source in various ways to show that it
offers a diverse array of examples that can be used to generate contextually
appropriate and natural responses to scientific topics for specific target
audiences. It is a freely available valuable resource for training and
evaluating conversation models, encompassing organically occurring dialogues.
While the raw data is available online, we provide additional metadata for
conversational analysis of dialogues at each level in all available videos.",2024-04-16,"Donya Rooein, Dirk Hovy",http://arxiv.org/pdf/2404.10475v1,cs.CL
DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion,"Despite the remarkable achievements of language models (LMs) across a broad
spectrum of tasks, their propensity for generating toxic outputs remains a
prevalent concern. Current solutions involving finetuning or auxiliary models
usually require extensive computational resources, hindering their practicality
in large language models (LLMs). In this paper, we propose DeStein, a novel
method that detoxifies LMs by applying representation engineering in activation
spaces with lower resource and time costs. Specifically, we derive
detoxification vectors from self-induced, universal steering pairs through
arithmetic operations in activation spaces. During inference, detoxification is
achieved by fusing the detoxification vectors with the original representations
in a head-wise manner. Empirical results demonstrate that our method
significantly outperforms previous state-of-the-art approaches on various
metrics, while also maintaining satisfactory generation quality and diversity.
We further validate the practicality and scalability of DeStein with a series
of white-box LLMs. The method is open-sourced at
https://github.com/LizLizLi/DeStein. Warning: Some example model outputs may
contain highly offensive or disturbing text.",2024-04-16,"Yu Li, Han Jiang, Chuanyang Gong, Zhihua Wei",http://arxiv.org/pdf/2404.10464v3,cs.CL
"Language Proficiency and F0 Entrainment: A Study of L2 English Imitation in Italian, French, and Slovak Speakers","This study explores F0 entrainment in second language (L2) English speech
imitation during an Alternating Reading Task (ART). Participants with Italian,
French, and Slovak native languages imitated English utterances, and their F0
entrainment was quantified using the Dynamic Time Warping (DTW) distance
between the parameterized F0 contours of the imitated utterances and those of
the model utterances. Results indicate a nuanced relationship between L2
English proficiency and entrainment: speakers with higher proficiency generally
exhibit less entrainment in pitch variation and declination. However, within
dyads, the more proficient speakers demonstrate a greater ability to mimic
pitch range, leading to increased entrainment. This suggests that proficiency
influences entrainment differently at individual and dyadic levels,
highlighting the complex interplay between language skill and prosodic
adaptation.",2024-04-16,"Zheng Yuan, Štefan Beňuš, Alessandro D'Ausilio",http://arxiv.org/pdf/2404.10440v1,cs.CL
MAD Speech: Measures of Acoustic Diversity of Speech,"Generative spoken language models produce speech in a wide range of voices,
prosody, and recording conditions, seemingly approaching the diversity of
natural speech. However, the extent to which generated speech is acoustically
diverse remains unclear due to a lack of appropriate metrics. We address this
gap by developing lightweight metrics of acoustic diversity, which we
collectively refer to as MAD Speech. We focus on measuring five facets of
acoustic diversity: voice, gender, emotion, accent, and background noise. We
construct the metrics as a composition of specialized, per-facet embedding
models and an aggregation function that measures diversity within the embedding
space. Next, we build a series of datasets with a priori known diversity
preferences for each facet. Using these datasets, we demonstrate that our
proposed metrics achieve a stronger agreement with the ground-truth diversity
than baselines. Finally, we showcase the applicability of our proposed metrics
across several real-life evaluation scenarios. MAD Speech is made publicly
accessible.",2024-04-16,"Matthieu Futeral, Andrea Agostinelli, Marco Tagliasacchi, Neil Zeghidour, Eugene Kharitonov",http://arxiv.org/pdf/2404.10419v2,cs.CL
Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large Language Model for Domain Question Answering,"Large language models (LLMs), such as GPT3.5, GPT4 and LLAMA2 perform
surprisingly well and outperform human experts on many tasks. However, in many
domain-specific evaluations, these LLMs often suffer from hallucination
problems due to insufficient training of relevant corpus. Furthermore,
fine-tuning large models may face problems such as the LLMs are not open source
or the construction of high-quality domain instruction is difficult. Therefore,
structured knowledge databases such as knowledge graph can better provide
domain background knowledge for LLMs and make full use of the reasoning and
analysis capabilities of LLMs. In some previous works, LLM was called multiple
times to determine whether the current triplet was suitable for inclusion in
the subgraph when retrieving subgraphs through a question. Especially for the
question that require a multi-hop reasoning path, frequent calls to LLM will
consume a lot of computing power. Moreover, when choosing the reasoning path,
LLM will be called once for each step, and if one of the steps is selected
incorrectly, it will lead to the accumulation of errors in the following steps.
In this paper, we integrated and optimized a pipeline for selecting reasoning
paths from KG based on LLM, which can reduce the dependency on LLM. In
addition, we propose a simple and effective subgraph retrieval method based on
chain of thought (CoT) and page rank which can returns the paths most likely to
contain the answer. We conduct experiments on three datasets: GenMedGPT-5k
[14], WebQuestions [2], and CMCQA [21]. Finally, RoK can demonstrate that using
fewer LLM calls can achieve the same results as previous SOTAs models.",2024-04-16,"Yuqi Wang, Boran Jiang, Yi Luo, Dawei He, Peng Cheng, Liangcai Gao",http://arxiv.org/pdf/2404.10384v1,cs.CL
Self-Explore: Enhancing Mathematical Reasoning in Language Models with Fine-grained Rewards,"Training on large amounts of rationales (i.e., CoT Fine-tuning) is effective
at improving the reasoning capabilities of large language models (LLMs).
However, acquiring human-authored rationales or augmenting rationales from
proprietary models is costly and not scalable. In this paper, we study the
problem of whether LLMs could self-improve their reasoning capabilities. To
this end, we propose Self-Explore, where the LLM is tasked to explore the first
wrong step (i.e., the first pit) within the rationale and use such signals as
fine-grained rewards for further improvement. On the GSM8K and MATH test set,
Self-Explore achieves 11.57% and 2.89% improvement on average across three LLMs
compared to supervised fine-tuning (SFT). Our code is available at
https://github.com/hbin0701/Self-Explore.",2024-04-16,"Hyeonbin Hwang, Doyoung Kim, Seungone Kim, Seonghyeon Ye, Minjoon Seo",http://arxiv.org/pdf/2404.10346v4,cs.CL
Relational Graph Convolutional Networks for Sentiment Analysis,"With the growth of textual data across online platforms, sentiment analysis
has become crucial for extracting insights from user-generated content. While
traditional approaches and deep learning models have shown promise, they cannot
often capture complex relationships between entities. In this paper, we propose
leveraging Relational Graph Convolutional Networks (RGCNs) for sentiment
analysis, which offer interpretability and flexibility by capturing
dependencies between data points represented as nodes in a graph. We
demonstrate the effectiveness of our approach by using pre-trained language
models such as BERT and RoBERTa with RGCN architecture on product reviews from
Amazon and Digikala datasets and evaluating the results. Our experiments
highlight the effectiveness of RGCNs in capturing relational information for
sentiment analysis tasks.",2024-04-16,"Asal Khosravi, Zahed Rahmati, Ali Vefghi",http://arxiv.org/pdf/2404.13079v1,cs.CL
Enhancing Confidence Expression in Large Language Models Through Learning from Past Experience,"Large Language Models (LLMs) have exhibited remarkable performance across
various downstream tasks, but they may generate inaccurate or false information
with a confident tone. One of the possible solutions is to empower the LLM
confidence expression capability, in which the confidence expressed can be
well-aligned with the true probability of the generated answer being correct.
However, leveraging the intrinsic ability of LLMs or the signals from the
output logits of answers proves challenging in accurately capturing the
response uncertainty in LLMs. Therefore, drawing inspiration from cognitive
diagnostics, we propose a method of Learning from Past experience (LePe) to
enhance the capability for confidence expression. Specifically, we first
identify three key problems: (1) How to capture the inherent confidence of the
LLM? (2) How to teach the LLM to express confidence? (3) How to evaluate the
confidence expression of the LLM? Then we devise three stages in LePe to deal
with these problems. Besides, to accurately capture the confidence of an LLM
when constructing the training data, we design a complete pipeline including
question preparation and answer sampling. We also conduct experiments using the
Llama family of LLMs to verify the effectiveness of our proposed method on four
datasets.",2024-04-16,"Haixia Han, Tingyun Li, Shisong Chen, Jie Shi, Chengyu Du, Yanghua Xiao, Jiaqing Liang, Xin Lin",http://arxiv.org/pdf/2404.10315v1,cs.CL
Balancing Speciality and Versatility: A Coarse to Fine Framework for Mitigating Catastrophic Forgetting in Large Language Models,"Aligned Large Language Models (LLMs) showcase remarkable versatility, capable
of handling diverse real-world tasks. Meanwhile, aligned LLMs are also expected
to exhibit speciality, excelling in specific applications. However, fine-tuning
with extra data, a common practice to gain speciality, often leads to
catastrophic forgetting (CF) of previously acquired versatility, hindering the
model's performance across diverse tasks. In response to this challenge, we
propose CoFiTune, a coarse to fine framework in an attempt to strike the
balance between speciality and versatility. At the coarse-grained level, an
empirical tree-search algorithm is utilized to pinpoint and update specific
modules that are crucial for speciality, while keeping other parameters frozen;
at the fine-grained level, a soft-masking mechanism regulates the update to the
LLMs, mitigating the CF issue without harming speciality. In an overall
evaluation of both speciality and versatility, CoFiTune consistently
outperforms baseline methods across diverse tasks and model scales. Compared to
the full-parameter SFT, CoFiTune leads to about 14% versatility improvement and
marginal speciality loss on a 13B model. Lastly, based on further analysis, we
provide a speculative insight into the information forwarding process in LLMs,
which helps explain the effectiveness of the proposed method. The code is
available at https://github.com/rattlesnakey/CoFiTune.",2024-04-16,"Hengyuan Zhang, Yanru Wu, Dawei Li, Sak Yang, Rui Zhao, Yong Jiang, Fei Tan",http://arxiv.org/pdf/2404.10306v6,cs.CL
Exploring Social Media Posts for Depression Identification: A Study on Reddit Dataset,"Depression is one of the most common mental disorders affecting an
individual's personal and professional life. In this work, we investigated the
possibility of utilizing social media posts to identify depression in
individuals. To achieve this goal, we conducted a preliminary study where we
extracted and analyzed the top Reddit posts made in 2022 from
depression-related forums. The collected data were labeled as depressive and
non-depressive using UMLS Metathesaurus. Further, the pre-processed data were
fed to classical machine learning models, where we achieved an accuracy of
92.28\% in predicting the depressive and non-depressive posts.",2024-04-16,"Nandigramam Sai Harshit, Nilesh Kumar Sahu, Haroon R. Lone",http://arxiv.org/pdf/2405.06656v1,cs.CL
Future Language Modeling from Temporal Document History,"Predicting the future is of great interest across many aspects of human
activity. Businesses are interested in future trends, traders are interested in
future stock prices, and companies are highly interested in future
technological breakthroughs. While there are many automated systems for
predicting future numerical data, such as weather, stock prices, and demand for
products, there is relatively little work in automatically predicting textual
data. Humans are interested in textual data predictions because it is a natural
format for our consumption, and experts routinely make predictions in a textual
format (Christensen et al., 2004; Tetlock & Gardner, 2015; Frick, 2015).
However, there has been relatively little formalization of this general problem
in the machine learning or natural language processing communities. To address
this gap, we introduce the task of future language modeling: probabilistic
modeling of texts in the future based on a temporal history of texts. To our
knowledge, our work is the first work to formalize the task of predicting the
future in this way. We show that it is indeed possible to build future language
models that improve upon strong non-temporal language model baselines, opening
the door to working on this important, and widely applicable problem.",2024-04-16,"Changmao Li, Jeffrey Flanigan",http://arxiv.org/pdf/2404.10297v1,cs.CL
Empowering Interdisciplinary Research with BERT-Based Models: An Approach Through SciBERT-CNN with Topic Modeling,"Researchers must stay current in their fields by regularly reviewing academic
literature, a task complicated by the daily publication of thousands of papers.
Traditional multi-label text classification methods often ignore semantic
relationships and fail to address the inherent class imbalances. This paper
introduces a novel approach using the SciBERT model and CNNs to systematically
categorize academic abstracts from the Elsevier OA CC-BY corpus. We use a
multi-segment input strategy that processes abstracts, body text, titles, and
keywords obtained via BERT topic modeling through SciBERT. Here, the [CLS]
token embeddings capture the contextual representation of each segment,
concatenated and processed through a CNN. The CNN uses convolution and pooling
to enhance feature extraction and reduce dimensionality, optimizing the data
for classification. Additionally, we incorporate class weights based on label
frequency to address the class imbalance, significantly improving the
classification F1 score and enhancing text classification systems and
literature review efficiency.",2024-04-16,"Darya Likhareva, Hamsini Sankaran, Sivakumar Thiyagarajan",http://arxiv.org/pdf/2404.13078v2,cs.CL
Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback,"Foundation models such as GPT-4 are fine-tuned to avoid unsafe or otherwise
problematic behavior, such as helping to commit crimes or producing racist
text. One approach to fine-tuning, called reinforcement learning from human
feedback, learns from humans' expressed preferences over multiple outputs.
Another approach is constitutional AI, in which the input from humans is a list
of high-level principles. But how do we deal with potentially diverging input
from humans? How can we aggregate the input into consistent data about
""collective"" preferences or otherwise use it to make collective choices about
model behavior? In this paper, we argue that the field of social choice is well
positioned to address these questions, and we discuss ways forward for this
agenda, drawing on discussions in a recent workshop on Social Choice for AI
Ethics and Safety held in Berkeley, CA, USA in December 2023.",2024-04-16,"Vincent Conitzer, Rachel Freedman, Jobst Heitzig, Wesley H. Holliday, Bob M. Jacobs, Nathan Lambert, Milan Mossé, Eric Pacuit, Stuart Russell, Hailey Schoelkopf, Emanuel Tewolde, William S. Zwicker",http://arxiv.org/pdf/2404.10271v2,cs.CL
Modeling Low-Resource Health Coaching Dialogues via Neuro-Symbolic Goal Summarization and Text-Units-Text Generation,"Health coaching helps patients achieve personalized and lifestyle-related
goals, effectively managing chronic conditions and alleviating mental health
issues. It is particularly beneficial, however cost-prohibitive, for
low-socioeconomic status populations due to its highly personalized and
labor-intensive nature. In this paper, we propose a neuro-symbolic goal
summarizer to support health coaches in keeping track of the goals and a
text-units-text dialogue generation model that converses with patients and
helps them create and accomplish specific goals for physical activities. Our
models outperform previous state-of-the-art while eliminating the need for
predefined schema and corresponding annotation. We also propose a new health
coaching dataset extending previous work and a metric to measure the
unconventionality of the patient's response based on data difficulty,
facilitating potential coach alerts during deployment.",2024-04-16,"Yue Zhou, Barbara Di Eugenio, Brian Ziebart, Lisa Sharp, Bing Liu, Nikolaos Agadakos",http://arxiv.org/pdf/2404.10268v1,cs.CL
Improving the Capabilities of Large Language Model Based Marketing Analytics Copilots With Semantic Search And Fine-Tuning,"Artificial intelligence (AI) is widely deployed to solve problems related to
marketing attribution and budget optimization. However, AI models can be quite
complex, and it can be difficult to understand model workings and insights
without extensive implementation teams. In principle, recently developed large
language models (LLMs), like GPT-4, can be deployed to provide marketing
insights, reducing the time and effort required to make critical decisions. In
practice, there are substantial challenges that need to be overcome to reliably
use such models. We focus on domain-specific question-answering, SQL generation
needed for data retrieval, and tabular analysis and show how a combination of
semantic search, prompt engineering, and fine-tuning can be applied to
dramatically improve the ability of LLMs to execute these tasks accurately. We
compare both proprietary models, like GPT-4, and open-source models, like
Llama-2-70b, as well as various embedding methods. These models are tested on
sample use cases specific to marketing mix modeling and attribution.",2024-04-16,"Yilin Gao, Sai Kumar Arava, Yancheng Li, James W. Snyder Jr",http://arxiv.org/pdf/2404.13077v1,cs.CL
Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy,"The widespread use of social media has led to a surge in popularity for
automated methods of analyzing public opinion. Supervised methods are adept at
text categorization, yet the dynamic nature of social media discussions poses a
continual challenge for these techniques due to the constant shifting of the
focus. On the other hand, traditional unsupervised methods for extracting
themes from public discourse, such as topic modeling, often reveal overarching
patterns that might not capture specific nuances. Consequently, a significant
portion of research into social media discourse still depends on
labor-intensive manual coding techniques and a human-in-the-loop approach,
which are both time-consuming and costly. In this work, we study the problem of
discovering arguments associated with a specific theme. We propose a generic
LLMs-in-the-Loop strategy that leverages the advanced capabilities of Large
Language Models (LLMs) to extract latent arguments from social media messaging.
To demonstrate our approach, we apply our framework to contentious topics. We
use two publicly available datasets: (1) the climate campaigns dataset of 14k
Facebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of
9k Facebook ads with 14 themes. Additionally, we design a downstream task as
stance prediction by leveraging talking points in climate debates. Furthermore,
we analyze demographic targeting and the adaptation of messaging based on
real-world events.",2024-04-16,"Tunazzina Islam, Dan Goldwasser",http://arxiv.org/pdf/2404.10259v4,cs.CL
Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models,"Recent advancements in general-purpose or domain-specific multimodal large
language models (LLMs) have witnessed remarkable progress for medical
decision-making. However, they are designated for specific classification or
generative tasks, and require model training or finetuning on large-scale
datasets with sizeable parameters and tremendous computing, hindering their
clinical utility across diverse resource-constrained scenarios in practice. In
this paper, we propose a novel and lightweight framework Med-MoE
(Mixture-of-Experts) that tackles both discriminative and generative multimodal
medical tasks. The learning of Med-MoE consists of three steps: multimodal
medical alignment, instruction tuning and routing, and domain-specific MoE
tuning. After aligning multimodal medical images with LLM tokens, we then
enable the model for different multimodal medical tasks with instruction
tuning, together with a trainable router tailored for expert selection across
input modalities. Finally, the model is tuned by integrating the router with
multiple domain-specific experts, which are selectively activated and further
empowered by meta expert. Comprehensive experiments on both open- and close-end
medical question answering (Med-VQA) and image classification tasks across
datasets such as VQA-RAD, SLAKE and Path-VQA demonstrate that our model can
achieve performance superior to or on par with state-of-the-art baselines,
while only requiring approximately 30\%-50\% of activated model parameters.
Extensive analysis and ablations corroborate the effectiveness and practical
utility of our method.",2024-04-16,"Songtao Jiang, Tuo Zheng, Yan Zhang, Yeying Jin, Li Yuan, Zuozhu Liu",http://arxiv.org/pdf/2404.10237v3,cs.CL
Generative Text Steganography with Large Language Model,"Recent advances in large language models (LLMs) have blurred the boundary of
high-quality text generation between humans and machines, which is favorable
for generative text steganography. While, current advanced steganographic
mapping is not suitable for LLMs since most users are restricted to accessing
only the black-box API or user interface of the LLMs, thereby lacking access to
the training vocabulary and its sampling probabilities. In this paper, we
explore a black-box generative text steganographic method based on the user
interfaces of large language models, which is called LLM-Stega. The main goal
of LLM-Stega is that the secure covert communication between Alice (sender) and
Bob (receiver) is conducted by using the user interfaces of LLMs. Specifically,
We first construct a keyword set and design a new encrypted steganographic
mapping to embed secret messages. Furthermore, to guarantee accurate extraction
of secret messages and rich semantics of generated stego texts, an optimization
mechanism based on reject sampling is proposed. Comprehensive experiments
demonstrate that the proposed LLM-Stega outperforms current state-of-the-art
methods.",2024-04-16,"Jiaxuan Wu, Zhengxian Wu, Yiming Xue, Juan Wen, Wanli Peng",http://arxiv.org/pdf/2404.10229v2,cs.CL
Two-Stage Stance Labeling: User-Hashtag Heuristics with Graph Neural Networks,"The high volume and rapid evolution of content on social media present major
challenges for studying the stance of social media users. In this work, we
develop a two stage stance labeling method that utilizes the user-hashtag
bipartite graph and the user-user interaction graph. In the first stage, a
simple and efficient heuristic for stance labeling uses the user-hashtag
bipartite graph to iteratively update the stance association of user and
hashtag nodes via a label propagation mechanism. This set of soft labels is
then integrated with the user-user interaction graph to train a graph neural
network (GNN) model using semi-supervised learning. We evaluate this method on
two large-scale datasets containing tweets related to climate change from June
2021 to June 2022 and gun control from January 2022 to January 2023. Our
experiments demonstrate that enriching text-based embeddings of users with
network information from the user interaction graph using our semi-supervised
GNN method outperforms both classifiers trained on user textual embeddings and
zero-shot classification using LLMs such as GPT4. We discuss the need for
integrating nuanced understanding from social science with the scalability of
computational methods to better understand how polarization on social media
occurs for divisive issues such as climate change and gun control.",2024-04-16,"Joshua Melton, Shannon Reid, Gabriel Terejanu, Siddharth Krishnan",http://arxiv.org/pdf/2404.10228v2,cs.CL
Find The Gap: Knowledge Base Reasoning For Visual Question Answering,"We analyze knowledge-based visual question answering, for which given a
question, the models need to ground it into the visual modality and retrieve
the relevant knowledge from a given large knowledge base (KB) to be able to
answer. Our analysis has two folds, one based on designing neural architectures
and training them from scratch, and another based on large pre-trained language
models (LLMs). Our research questions are: 1) Can we effectively augment models
by explicit supervised retrieval of the relevant KB information to solve the
KB-VQA problem? 2) How do task-specific and LLM-based models perform in the
integration of visual and external knowledge, and multi-hop reasoning over both
sources of information? 3) Is the implicit knowledge of LLMs sufficient for
KB-VQA and to what extent it can replace the explicit KB? Our results
demonstrate the positive impact of empowering task-specific and LLM models with
supervised external and visual knowledge retrieval models. Our findings show
that though LLMs are stronger in 1-hop reasoning, they suffer in 2-hop
reasoning in comparison with our fine-tuned NN model even if the relevant
information from both modalities is available to the model. Moreover, we
observed that LLM models outperform the NN model for KB-related questions which
confirms the effectiveness of implicit knowledge in LLMs however, they do not
alleviate the need for external KB.",2024-04-16,"Elham J. Barezi, Parisa Kordjamshidi",http://arxiv.org/pdf/2404.10226v1,cs.CL
CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting,"As the utilization of large language models (LLMs) has proliferated
world-wide, it is crucial for them to have adequate knowledge and fair
representation for diverse global cultures. In this work, we uncover culture
perceptions of three SOTA models on 110 countries and regions on 8
culture-related topics through culture-conditioned generations, and extract
symbols from these generations that are associated to each culture by the LLM.
We discover that culture-conditioned generation consist of linguistic ""markers""
that distinguish marginalized cultures apart from default cultures. We also
discover that LLMs have an uneven degree of diversity in the culture symbols,
and that cultures from different geographic regions have different presence in
LLMs' culture-agnostic generation. Our findings promote further research in
studying the knowledge and fairness of global culture perception in LLMs. Code
and Data can be found here: https://github.com/huihanlhh/Culture-Gen/",2024-04-16,"Huihan Li, Liwei Jiang, Jena D. Hwang, Hyunwoo Kim, Sebastin Santy, Taylor Sorensen, Bill Yuchen Lin, Nouha Dziri, Xiang Ren, Yejin Choi",http://arxiv.org/pdf/2404.10199v5,cs.CL
ClashEval: Quantifying the tug-of-war between an LLM's internal prior and external evidence,"Retrieval augmented generation (RAG) is frequently used to mitigate
hallucinations and provide up-to-date knowledge for large language models
(LLMs). However, given that document retrieval is an imprecise task and
sometimes results in erroneous or even harmful content being presented in
context, this raises the question of how LLMs handle retrieved information: If
the provided content is incorrect, does the model know to ignore it, or does it
recapitulate the error? Conversely, when the model's initial response is
incorrect, does it always know to use the retrieved information to correct
itself, or does it insist on its wrong prior response? To answer this, we
curate a dataset of over 1200 questions across six domains (e.g., drug dosages,
Olympic records, locations) along with content relevant to answering each
question. We further apply precise perturbations to the answers in the content
that range from subtle to blatant errors. We benchmark six top-performing LLMs,
including GPT-4o, on this dataset and find that LLMs are susceptible to
adopting incorrect retrieved content, overriding their own correct prior
knowledge over 60% of the time. However, the more unrealistic the retrieved
content is (i.e. more deviated from truth), the less likely the model is to
adopt it. Also, the less confident a model is in its initial response (via
measuring token probabilities), the more likely it is to adopt the information
in the retrieved content. We exploit this finding and demonstrate simple
methods for improving model accuracy where there is conflicting retrieved
content. Our results highlight a difficult task and benchmark for LLMs --
namely, their ability to correctly discern when it is wrong in light of correct
retrieved content and to reject cases when the provided content is incorrect.",2024-04-16,"Kevin Wu, Eric Wu, James Zou",http://arxiv.org/pdf/2404.10198v3,cs.CL
Deferred NAM: Low-latency Top-K Context Injection via Deferred Context Encoding for Non-Streaming ASR,"Contextual biasing enables speech recognizers to transcribe important phrases
in the speaker's context, such as contact names, even if they are rare in, or
absent from, the training data. Attention-based biasing is a leading approach
which allows for full end-to-end cotraining of the recognizer and biasing
system and requires no separate inference-time components. Such biasers
typically consist of a context encoder; followed by a context filter which
narrows down the context to apply, improving per-step inference time; and,
finally, context application via cross attention. Though much work has gone
into optimizing per-frame performance, the context encoder is at least as
important: recognition cannot begin before context encoding ends. Here, we show
the lightweight phrase selection pass can be moved before context encoding,
resulting in a speedup of up to 16.1 times and enabling biasing to scale to 20K
phrases with a maximum pre-decoding delay under 33ms. With the addition of
phrase- and wordpiece-level cross-entropy losses, our technique also achieves
up to a 37.5% relative WER reduction over the baseline without the losses and
lightweight phrase selection pass.",2024-04-15,"Zelin Wu, Gan Song, Christopher Li, Pat Rondon, Zhong Meng, Xavier Velez, Weiran Wang, Diamantino Caseiro, Golan Pundak, Tsendsuren Munkhdalai, Angad Chandorkar, Rohit Prabhavalkar",http://arxiv.org/pdf/2404.10180v2,cs.CL
On the Effects of Fine-tuning Language Models for Text-Based Reinforcement Learning,"Text-based reinforcement learning involves an agent interacting with a
fictional environment using observed text and admissible actions in natural
language to complete a task. Previous works have shown that agents can succeed
in text-based interactive environments even in the complete absence of semantic
understanding or other linguistic capabilities. The success of these agents in
playing such games suggests that semantic understanding may not be important
for the task. This raises an important question about the benefits of LMs in
guiding the agents through the game states. In this work, we show that rich
semantic understanding leads to efficient training of text-based RL agents.
Moreover, we describe the occurrence of semantic degeneration as a consequence
of inappropriate fine-tuning of language models in text-based reinforcement
learning (TBRL). Specifically, we describe the shift in the semantic
representation of words in the LM, as well as how it affects the performance of
the agent in tasks that are semantically similar to the training games. We
believe these results may help develop better strategies to fine-tune agents in
text-based RL scenarios.",2024-04-15,"Mauricio Gruppi, Soham Dan, Keerthiram Murugesan, Subhajit Chaudhury",http://arxiv.org/pdf/2404.10174v1,cs.CL
TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition,"Table reasoning is a challenging task that requires understanding both
natural language questions and structured tabular data. Large language models
(LLMs) have shown impressive capabilities in natural language understanding and
generation, but they often struggle with large tables due to their limited
input length. In this paper, we propose TabSQLify, a novel method that
leverages text-to-SQL generation to decompose tables into smaller and relevant
sub-tables, containing only essential information for answering questions or
verifying statements, before performing the reasoning task. In our
comprehensive evaluation on four challenging datasets, our approach
demonstrates comparable or superior performance compared to prevailing methods
reliant on full tables as input. Moreover, our method can reduce the input
context length significantly, making it more scalable and efficient for
large-scale table reasoning applications. Our method performs remarkably well
on the WikiTQ benchmark, achieving an accuracy of 64.7%. Additionally, on the
TabFact benchmark, it achieves a high accuracy of 79.5%. These results surpass
other LLM-based baseline models on gpt-3.5-turbo (chatgpt). TabSQLify can
reduce the table size significantly alleviating the computational load on LLMs
when handling large tables without compromising performance.",2024-04-15,"Md Mahadi Hasan Nahid, Davood Rafiei",http://arxiv.org/pdf/2404.10150v1,cs.CL
ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis,"Text-to-Image (T2I) Synthesis has made tremendous strides in enhancing
synthesized image quality, but current datasets evaluate model performance only
on descriptive, instruction-based prompts. Real-world news image captions take
a more pragmatic approach, providing high-level situational and Named-Entity
(NE) information and limited physical object descriptions, making them
abstractive. To evaluate the ability of T2I models to capture intended subjects
from news captions, we introduce the Abstractive News Captions with High-level
cOntext Representation (ANCHOR) dataset, containing 70K+ samples sourced from 5
different news media organizations. With Large Language Models (LLM) achieving
success in language and commonsense reasoning tasks, we explore the ability of
different LLMs to identify and understand key subjects from abstractive
captions. Our proposed method Subject-Aware Finetuning (SAFE), selects and
enhances the representation of key subjects in synthesized images by leveraging
LLM-generated subject weights. It also adapts to the domain distribution of
news images and captions through custom Domain Fine-tuning, outperforming
current T2I baselines on ANCHOR. By launching the ANCHOR dataset, we hope to
motivate research in furthering the Natural Language Understanding (NLU)
capabilities of T2I models.",2024-04-15,"Aashish Anantha Ramakrishnan, Sharon X. Huang, Dongwon Lee",http://arxiv.org/pdf/2404.10141v1,cs.CL
Language Model Cascades: Token-level uncertainty and beyond,"Recent advances in language models (LMs) have led to significant improvements
in quality on complex NLP tasks, but at the expense of increased inference
costs. Cascading offers a simple strategy to achieve more favorable
cost-quality tradeoffs: here, a small model is invoked for most ""easy""
instances, while a few ""hard"" instances are deferred to the large model. While
the principles underpinning cascading are well-studied for classification tasks
- with deferral based on predicted class uncertainty favored theoretically and
practically - a similar understanding is lacking for generative LM tasks. In
this work, we initiate a systematic study of deferral rules for LM cascades. We
begin by examining the natural extension of predicted class uncertainty to
generative LM tasks, namely, the predicted sequence uncertainty. We show that
this measure suffers from the length bias problem, either over- or
under-emphasizing outputs based on their lengths. This is because LMs produce a
sequence of uncertainty values, one for each output token; and moreover, the
number of output tokens is variable across examples. To mitigate this issue, we
propose to exploit the richer token-level uncertainty information implicit in
generative LMs. We argue that naive predicted sequence uncertainty corresponds
to a simple aggregation of these uncertainties. By contrast, we show that
incorporating token-level uncertainty through learned post-hoc deferral rules
can significantly outperform such simple aggregation strategies, via
experiments on a range of natural language benchmarks with FLAN-T5 models. We
further show that incorporating embeddings from the smaller model and
intermediate layers of the larger model can give an additional boost in the
overall cost-quality tradeoff.",2024-04-15,"Neha Gupta, Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar",http://arxiv.org/pdf/2404.10136v1,cs.CL
PRODIS -- a speech database and a phoneme-based language model for the study of predictability effects in Polish,"We present a speech database and a phoneme-level language model of Polish.
The database and model are designed for the analysis of prosodic and discourse
factors and their impact on acoustic parameters in interaction with
predictability effects. The database is also the first large, publicly
available Polish speech corpus of excellent acoustic quality that can be used
for phonetic analysis and training of multi-speaker speech technology systems.
The speech in the database is processed in a pipeline that achieves a 90%
degree of automation. It incorporates state-of-the-art, freely available tools
enabling database expansion or adaptation to additional languages.",2024-04-15,"Zofia Malisz, Jan Foremski, Małgorzata Kul",http://arxiv.org/pdf/2404.10112v1,cs.CL
Chinchilla Scaling: A replication attempt,"Hoffmann et al. (2022) propose three methods for estimating a compute-optimal
scaling law. We attempt to replicate their third estimation procedure, which
involves fitting a parametric loss function to a reconstruction of data from
their plots. We find that the reported estimates are inconsistent with their
first two estimation methods, fail at fitting the extracted data, and report
implausibly narrow confidence intervals--intervals this narrow would require
over 600,000 experiments, while they likely only ran fewer than 500. In
contrast, our rederivation of the scaling law using the third approach yields
results that are compatible with the findings from the first two estimation
procedures described by Hoffmann et al.",2024-04-15,"Tamay Besiroglu, Ege Erdil, Matthew Barnett, Josh You",http://arxiv.org/pdf/2404.10102v2,cs.CL
AIGeN: An Adversarial Approach for Instruction Generation in VLN,"In the last few years, the research interest in Vision-and-Language
Navigation (VLN) has grown significantly. VLN is a challenging task that
involves an agent following human instructions and navigating in a previously
unknown environment to reach a specified goal. Recent work in literature
focuses on different ways to augment the available datasets of instructions for
improving navigation performance by exploiting synthetic training data. In this
work, we propose AIGeN, a novel architecture inspired by Generative Adversarial
Networks (GANs) that produces meaningful and well-formed synthetic instructions
to improve navigation agents' performance. The model is composed of a
Transformer decoder (GPT-2) and a Transformer encoder (BERT). During the
training phase, the decoder generates sentences for a sequence of images
describing the agent's path to a particular point while the encoder
discriminates between real and fake instructions. Experimentally, we evaluate
the quality of the generated instructions and perform extensive ablation
studies. Additionally, we generate synthetic instructions for 217K trajectories
using AIGeN on Habitat-Matterport 3D Dataset (HM3D) and show an improvement in
the performance of an off-the-shelf VLN method. The validation analysis of our
proposal is conducted on REVERIE and R2R and highlights the promising aspects
of our proposal, achieving state-of-the-art performance.",2024-04-15,"Niyati Rawal, Roberto Bigazzi, Lorenzo Baraldi, Rita Cucchiara",http://arxiv.org/pdf/2404.10054v1,cs.CL
MMInA: Benchmarking Multihop Multimodal Internet Agents,"Autonomous embodied agents live on an Internet of multimedia websites. Can
they hop around multimodal websites to complete complex user tasks? Existing
benchmarks fail to assess them in a realistic, evolving environment for their
embodiment across websites. To answer this question, we present MMInA, a
multihop and multimodal benchmark to evaluate the embodied agents for
compositional Internet tasks, with several appealing properties: 1) Evolving
real-world multimodal websites. Our benchmark uniquely operates on evolving
real-world websites, ensuring a high degree of realism and applicability to
natural user tasks. Our data includes 1,050 human-written tasks covering
various domains such as shopping and travel, with each task requiring the agent
to autonomously extract multimodal information from web pages as observations;
2) Multihop web browsing. Our dataset features naturally compositional tasks
that require information from or actions on multiple websites to solve, to
assess long-range reasoning capabilities on web tasks; 3) Holistic evaluation.
We propose a novel protocol for evaluating an agent's progress in completing
multihop tasks. We experiment with both standalone (multimodal) language models
and heuristic-based web agents. Extensive experiments demonstrate that while
long-chain multihop web tasks are easy for humans, they remain challenging for
state-of-the-art web agents. We identify that agents are more likely to fail on
the early hops when solving tasks of more hops, which results in lower task
success rates. To address this issue, we propose a simple memory augmentation
approach replaying past action trajectories to reflect. Our method
significantly improved both the single-hop and multihop web browsing abilities
of agents. See our code and data at https://mmina.cliangyu.com",2024-04-15,"Ziniu Zhang, Shulin Tian, Liangyu Chen, Ziwei Liu",http://arxiv.org/pdf/2404.09992v1,cs.CL
Memory Sharing for Large Language Model based Agents,"The adaptation of Large Language Model (LLM)-based agents to execute tasks
via natural language prompts represents a significant advancement, notably
eliminating the need for explicit retraining or fine tuning, but are
constrained by the comprehensiveness and diversity of the provided examples,
leading to outputs that often diverge significantly from expected results,
especially when it comes to the open-ended questions. This paper introduces the
Memory Sharing, a framework which integrates the real-time memory filter,
storage and retrieval to enhance the In-Context Learning process. This
framework allows for the sharing of memories among multiple agents, whereby the
interactions and shared memories between different agents effectively enhance
the diversity of the memories. The collective self-enhancement through
interactive learning among multiple agents facilitates the evolution from
individual intelligence to collective intelligence. Besides, the dynamically
growing memory pool is utilized not only to improve the quality of responses
but also to train and enhance the retriever. We evaluated our framework across
three distinct domains involving specialized tasks of agents. The experimental
results demonstrate that the MS framework significantly improves the agents'
performance in addressing open-ended questions.",2024-04-15,"Hang Gao, Yongfeng Zhang",http://arxiv.org/pdf/2404.09982v2,cs.CL
Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems,"Crowdsourced labels play a crucial role in evaluating task-oriented dialogue
systems (TDSs). Obtaining high-quality and consistent ground-truth labels from
annotators presents challenges. When evaluating a TDS, annotators must fully
comprehend the dialogue before providing judgments. Previous studies suggest
using only a portion of the dialogue context in the annotation process.
However, the impact of this limitation on label quality remains unexplored.
This study investigates the influence of dialogue context on annotation
quality, considering the truncated context for relevance and usefulness
labeling. We further propose to use large language models (LLMs) to summarize
the dialogue context to provide a rich and short description of the dialogue
context and study the impact of doing so on the annotator's performance.
Reducing context leads to more positive ratings. Conversely, providing the
entire dialogue context yields higher-quality relevance ratings but introduces
ambiguity in usefulness ratings. Using the first user utterance as context
leads to consistent ratings, akin to those obtained using the entire dialogue,
with significantly reduced annotation effort. Our findings show how task
design, particularly the availability of dialogue context, affects the quality
and consistency of crowdsourced evaluation labels.",2024-04-15,"Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke",http://arxiv.org/pdf/2404.09980v1,cs.CL
Constructing Benchmarks and Interventions for Combating Hallucinations in LLMs,"Large language models (LLMs) are prone to hallucinations, which sparked a
widespread effort to detect and prevent them. Recent work attempts to mitigate
hallucinations by intervening in the model's generation, typically computing
representative vectors of hallucinations vs. grounded generations, for steering
the model's hidden states away from a hallucinatory state. However, common
studies employ different setups and do not properly separate different possible
causes of hallucinations, making interventions misguided. In this work, we
introduce a method for categorizing examples based on the model's prior
knowledge, named WACK. We construct WACK benchmarks that support interventions
in two settings: open-book and closed-book question answering. Using the
benchmarks, we perform an extensive investigation of the effect of different
choices for intervention, such as the intervened components, and how often and
how strongly to intervene. We find that intervention success varies depending
on the component, with the attention blocks performing well and the residual
stream proving detrimental to language modeling capabilities. We also show that
interventions can benefit from representative vectors collected before, rather
than after, a hallucination occurs. Finally, we introduce a new dynamic
intervention, which intervenes only if needed, and thus is more robust than
standard static interventions. The code is available at
https://github.com/technion-cs-nlp/hallucination-mitigation .",2024-04-15,"Adi Simhi, Jonathan Herzig, Idan Szpektor, Yonatan Belinkov",http://arxiv.org/pdf/2404.09971v2,cs.CL
Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization,"Generative multimodal content is increasingly prevalent in much of the
content creation arena, as it has the potential to allow artists and media
personnel to create pre-production mockups by quickly bringing their ideas to
life. The generation of audio from text prompts is an important aspect of such
processes in the music and film industry. Many of the recent diffusion-based
text-to-audio models focus on training increasingly sophisticated diffusion
models on a large set of datasets of prompt-audio pairs. These models do not
explicitly focus on the presence of concepts or events and their temporal
ordering in the output audio with respect to the input prompt. Our hypothesis
is focusing on how these aspects of audio generation could improve audio
generation performance in the presence of limited data. As such, in this work,
using an existing text-to-audio model Tango, we synthetically create a
preference dataset where each prompt has a winner audio output and some loser
audio outputs for the diffusion model to learn from. The loser outputs, in
theory, have some concepts from the prompt missing or in an incorrect order. We
fine-tune the publicly available Tango text-to-audio model using diffusion-DPO
(direct preference optimization) loss on our preference dataset and show that
it leads to improved audio output over Tango and AudioLDM2, in terms of both
automatic- and manual-evaluation metrics.",2024-04-15,"Navonil Majumder, Chia-Yu Hung, Deepanway Ghosal, Wei-Ning Hsu, Rada Mihalcea, Soujanya Poria",http://arxiv.org/pdf/2404.09956v4,cs.CL
Compression Represents Intelligence Linearly,"There is a belief that learning to compress well will lead to intelligence.
Recently, language modeling has been shown to be equivalent to compression,
which offers a compelling rationale for the success of large language models
(LLMs): the development of more advanced language models is essentially
enhancing compression which facilitates intelligence. Despite such appealing
discussions, little empirical evidence is present for the interplay between
compression and intelligence. In this work, we examine their relationship in
the context of LLMs, treating LLMs as data compressors. Given the abstract
concept of ""intelligence"", we adopt the average downstream benchmark scores as
a surrogate, specifically targeting intelligence related to knowledge and
commonsense, coding, and mathematical reasoning. Across 12 benchmarks, our
study brings together 31 public LLMs that originate from diverse organizations.
Remarkably, we find that LLMs' intelligence -- reflected by average benchmark
scores -- almost linearly correlates with their ability to compress external
text corpora. These results provide concrete evidence supporting the belief
that superior compression indicates greater intelligence. Furthermore, our
findings suggest that compression efficiency, as an unsupervised metric derived
from raw text corpora, serves as a reliable evaluation measure that is linearly
associated with the model capabilities. We open-source our compression datasets
as well as our data collection pipelines to facilitate future researchers to
assess compression properly.",2024-04-15,"Yuzhen Huang, Jinghan Zhang, Zifei Shan, Junxian He",http://arxiv.org/pdf/2404.09937v2,cs.CL
Foundational Challenges in Assuring Alignment and Safety of Large Language Models,"This work identifies 18 foundational challenges in assuring the alignment and
safety of large language models (LLMs). These challenges are organized into
three different categories: scientific understanding of LLMs, development and
deployment methods, and sociotechnical challenges. Based on the identified
challenges, we pose $200+$ concrete research questions.",2024-04-15,"Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin L. Edelman, Zhaowei Zhang, Mario Günther, Anton Korinek, Jose Hernandez-Orallo, Lewis Hammond, Eric Bigelow, Alexander Pan, Lauro Langosco, Tomasz Korbak, Heidi Zhang, Ruiqi Zhong, Seán Ó hÉigeartaigh, Gabriel Recchia, Giulio Corsi, Alan Chan, Markus Anderljung, Lilian Edwards, Aleksandar Petrov, Christian Schroeder de Witt, Sumeet Ramesh Motwan, Yoshua Bengio, Danqi Chen, Philip H. S. Torr, Samuel Albanie, Tegan Maharaj, Jakob Foerster, Florian Tramer, He He, Atoosa Kasirzadeh, Yejin Choi, David Krueger",http://arxiv.org/pdf/2404.09932v2,cs.CL
LLM Evaluators Recognize and Favor Their Own Generations,"Self-evaluation using large language models (LLMs) has proven valuable not
only in benchmarking but also methods like reward modeling, constitutional AI,
and self-refinement. But new biases are introduced due to the same LLM acting
as both the evaluator and the evaluatee. One such bias is self-preference,
where an LLM evaluator scores its own outputs higher than others' while human
annotators consider them of equal quality. But do LLMs actually recognize their
own outputs when they give those texts higher scores, or is it just a
coincidence? In this paper, we investigate if self-recognition capability
contributes to self-preference. We discover that, out of the box, LLMs such as
GPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from
other LLMs and humans. By fine-tuning LLMs, we discover a linear correlation
between self-recognition capability and the strength of self-preference bias;
using controlled experiments, we show that the causal explanation resists
straightforward confounders. We discuss how self-recognition can interfere with
unbiased evaluations and AI safety more generally.",2024-04-15,"Arjun Panickssery, Samuel R. Bowman, Shi Feng",http://arxiv.org/pdf/2404.13076v1,cs.CL
Detecting AI Generated Text Based on NLP and Machine Learning Approaches,"Recent advances in natural language processing (NLP) may enable artificial
intelligence (AI) models to generate writing that is identical to human written
form in the future. This might have profound ethical, legal, and social
repercussions. This study aims to address this problem by offering an accurate
AI detector model that can differentiate between electronically produced text
and human-written text. Our approach includes machine learning methods such as
XGB Classifier, SVM, BERT architecture deep learning models. Furthermore, our
results show that the BERT performs better than previous models in identifying
information generated by AI from information provided by humans. Provide a
comprehensive analysis of the current state of AI-generated text identification
in our assessment of pertinent studies. Our testing yielded positive findings,
showing that our strategy is successful, with the BERT emerging as the most
probable answer. We analyze the research's societal implications, highlighting
the possible advantages for various industries while addressing sustainability
issues pertaining to morality and the environment. The XGB classifier and SVM
give 0.84 and 0.81 accuracy in this article, respectively. The greatest
accuracy in this research is provided by the BERT model, which provides 0.93%
accuracy.",2024-04-15,Nuzhat Prova,http://arxiv.org/pdf/2404.10032v1,cs.CL
ChatShop: Interactive Information Seeking with Language Agents,"The desire and ability to seek new information strategically are fundamental
to human learning but often overlooked in current language agent evaluation. We
analyze a popular web shopping task designed to test language agents' ability
to perform strategic exploration and discover that it can be reformulated and
solved as a single-turn retrieval task without the need for interactive
information seeking. This finding encourages us to rethink realistic
constraints on information access that would necessitate strategic information
seeking. We then redesign the task to introduce a notion of task ambiguity and
the role of a shopper, serving as a dynamic party with whom the agent
strategically interacts in an open-ended conversation to make informed
decisions. Our experiments demonstrate that the proposed task can effectively
evaluate the agent's ability to explore and gradually accumulate information
through multi-turn interactions. Additionally, we show that large language
model-simulated shoppers serve as a good proxy for real human shoppers,
revealing similar error patterns in agents.",2024-04-15,"Sanxing Chen, Sam Wiseman, Bhuwan Dhingra",http://arxiv.org/pdf/2404.09911v2,cs.CL
Progressive Knowledge Graph Completion,"Knowledge Graph Completion (KGC) has emerged as a promising solution to
address the issue of incompleteness within Knowledge Graphs (KGs). Traditional
KGC research primarily centers on triple classification and link prediction.
Nevertheless, we contend that these tasks do not align well with real-world
scenarios and merely serve as surrogate benchmarks. In this paper, we
investigate three crucial processes relevant to real-world construction
scenarios: (a) the verification process, which arises from the necessity and
limitations of human verifiers; (b) the mining process, which identifies the
most promising candidates for verification; and (c) the training process, which
harnesses verified data for subsequent utilization; in order to achieve a
transition toward more realistic challenges. By integrating these three
processes, we introduce the Progressive Knowledge Graph Completion (PKGC) task,
which simulates the gradual completion of KGs in real-world scenarios.
Furthermore, to expedite PKGC processing, we propose two acceleration modules:
Optimized Top-$k$ algorithm and Semantic Validity Filter. These modules
significantly enhance the efficiency of the mining procedure. Our experiments
demonstrate that performance in link prediction does not accurately reflect
performance in PKGC. A more in-depth analysis reveals the key factors
influencing the results and provides potential directions for future research.",2024-04-15,"Jiayi Li, Ruilin Luo, Jiaqi Sun, Jing Xiao, Yujiu Yang",http://arxiv.org/pdf/2404.09897v1,cs.CL
Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection,"With the expanding application of Large Language Models (LLMs) in various
domains, it becomes imperative to comprehensively investigate their unforeseen
behaviors and consequent outcomes. In this study, we introduce and
systematically explore the phenomenon of ""glitch tokens"", which are anomalous
tokens produced by established tokenizers and could potentially compromise the
models' quality of response. Specifically, we experiment on seven top popular
LLMs utilizing three distinct tokenizers and involving a totally of 182,517
tokens. We present categorizations of the identified glitch tokens and symptoms
exhibited by LLMs when interacting with glitch tokens. Based on our observation
that glitch tokens tend to cluster in the embedding space, we propose
GlitchHunter, a novel iterative clustering-based technique, for efficient
glitch token detection. The evaluation shows that our approach notably
outperforms three baseline methods on eight open-source LLMs. To the best of
our knowledge, we present the first comprehensive study on glitch tokens. Our
new detection further provides valuable insights into mitigating
tokenization-related errors in LLMs.",2024-04-15,"Yuxi Li, Yi Liu, Gelei Deng, Ying Zhang, Wenjia Song, Ling Shi, Kailong Wang, Yuekang Li, Yang Liu, Haoyu Wang",http://arxiv.org/pdf/2404.09894v3,cs.CL
Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval,"Retrieving relevant tables containing the necessary information to accurately
answer a given question over tables is critical to open-domain
question-answering (QA) systems. Previous methods assume the answer to such a
question can be found either in a single table or multiple tables identified
through question decomposition or rewriting. However, neither of these
approaches is sufficient, as many questions require retrieving multiple tables
and joining them through a join plan that cannot be discerned from the user
query itself. If the join plan is not considered in the retrieval stage, the
subsequent steps of reasoning and answering based on those retrieved tables are
likely to be incorrect. To address this problem, we introduce a method that
uncovers useful join relations for any query and database during table
retrieval. We use a novel re-ranking method formulated as a mixed-integer
program that considers not only table-query relevance but also table-table
relevance that requires inferring join relationships. Our method outperforms
the state-of-the-art approaches for table retrieval by up to 9.3% in F1 score
and for end-to-end QA by up to 5.4% in accuracy.",2024-04-15,"Peter Baile Chen, Yi Zhang, Dan Roth",http://arxiv.org/pdf/2404.09889v3,cs.CL
Software Engineering Methods For AI-Driven Deductive Legal Reasoning,"The recent proliferation of generative artificial intelligence (AI)
technologies such as pre-trained large language models (LLMs) has opened up new
frontiers in computational law. An exciting area of development is the use of
AI to automate the deductive rule-based reasoning inherent in statutory and
contract law. This paper argues that such automated deductive legal reasoning
can now be viewed from the lens of software engineering, treating LLMs as
interpreters of natural-language programs with natural-language inputs. We show
how it is possible to apply principled software engineering techniques to
enhance AI-driven legal reasoning of complex statutes and to unlock new
applications in automated meta-reasoning such as mutation-guided example
generation and metamorphic property-based testing.",2024-04-15,Rohan Padhye,http://arxiv.org/pdf/2404.09868v2,cs.CL
Anatomy of Industrial Scale Multilingual ASR,"This paper describes AssemblyAI's industrial-scale automatic speech
recognition (ASR) system, designed to meet the requirements of large-scale,
multilingual ASR serving various application needs. Our system leverages a
diverse training dataset comprising unsupervised (12.5M hours), supervised
(188k hours), and pseudo-labeled (1.6M hours) data across four languages. We
provide a detailed description of our model architecture, consisting of a
full-context 600M-parameter Conformer encoder pre-trained with BEST-RQ and an
RNN-T decoder fine-tuned jointly with the encoder. Our extensive evaluation
demonstrates competitive word error rates (WERs) against larger and more
computationally expensive models, such as Whisper large and Canary-1B.
Furthermore, our architectural choices yield several key advantages, including
an improved code-switching capability, a 5x inference speedup compared to an
optimized Whisper baseline, a 30% reduction in hallucination rate on speech
data, and a 90% reduction in ambient noise compared to Whisper, along with
significantly improved time-stamp accuracy. Throughout this work, we adopt a
system-centric approach to analyzing various aspects of fully-fledged ASR
models to gain practically relevant insights useful for real-world services
operating at scale.",2024-04-15,"Francis McCann Ramirez, Luka Chkhetiani, Andrew Ehrenberg, Robert McHardy, Rami Botros, Yash Khare, Andrea Vanzo, Taufiquzzaman Peyash, Gabriel Oexle, Michael Liang, Ilya Sklyar, Enver Fakhan, Ahmed Etefy, Daniel McCrystal, Sam Flamini, Domenic Donato, Takuya Yoshioka",http://arxiv.org/pdf/2404.09841v2,cs.CL
Negation Triplet Extraction with Syntactic Dependency and Semantic Consistency,"Previous works of negation understanding mainly focus on negation cue
detection and scope resolution, without identifying negation subject which is
also significant to the downstream tasks. In this paper, we propose a new
negation triplet extraction (NTE) task which aims to extract negation subject
along with negation cue and scope. To achieve NTE, we devise a novel
Syntax&Semantic-Enhanced Negation Extraction model, namely SSENE, which is
built based on a generative pretrained language model (PLM) {of Encoder-Decoder
architecture} with a multi-task learning framework. Specifically, the given
sentence's syntactic dependency tree is incorporated into the PLM's encoder to
discover the correlations between the negation subject, cue and scope.
Moreover, the semantic consistency between the sentence and the extracted
triplet is ensured by an auxiliary task learning. Furthermore, we have
constructed a high-quality Chinese dataset NegComment based on the users'
reviews from the real-world platform of Meituan, upon which our evaluations
show that SSENE achieves the best NTE performance compared to the baselines.
Our ablation and case studies also demonstrate that incorporating the syntactic
information helps the PLM's recognize the distant dependency between the
subject and cue, and the auxiliary task learning is helpful to extract the
negation triplets with more semantic consistency.",2024-04-15,"Yuchen Shi, Deqing Yang, Jingping Liu, Yanghua Xiao, Zongyu Wang, Huimin Xu",http://arxiv.org/pdf/2404.09830v1,cs.CL
Impact of Preference Noise on the Alignment Performance of Generative Language Models,"A key requirement in developing Generative Language Models (GLMs) is to have
their values aligned with human values. Preference-based alignment is a widely
used paradigm for this purpose, in which preferences over generation pairs are
first elicited from human annotators or AI systems, and then fed into some
alignment techniques, e.g., Direct Preference Optimization. However, a
substantial percent (20 - 40%) of the preference pairs used in GLM alignment
are noisy, and it remains unclear how the noise affects the alignment
performance and how to mitigate its negative impact. In this paper, we propose
a framework to inject desirable amounts and types of noise to the preferences,
and systematically study the impact of preference noise on the alignment
performance in two tasks (summarization and dialogue generation). We find that
the alignment performance can be highly sensitive to the noise rates in the
preference data: e.g., a 10 percentage points (pp) increase of the noise rate
can lead to 30 pp drop in the alignment performance (in win rate). To mitigate
the impact of noise, confidence-based data filtering shows significant benefit
when certain types of noise are present. We hope our work can help the
community better understand and mitigate the impact of preference noise in GLM
alignment.",2024-04-15,"Yang Gao, Dana Alon, Donald Metzler",http://arxiv.org/pdf/2404.09824v1,cs.CL
"Benchmarking Llama2, Mistral, Gemma and GPT for Factuality, Toxicity, Bias and Propensity for Hallucinations","This paper introduces fourteen novel datasets for the evaluation of Large
Language Models' safety in the context of enterprise tasks. A method was
devised to evaluate a model's safety, as determined by its ability to follow
instructions and output factual, unbiased, grounded, and appropriate content.
In this research, we used OpenAI GPT as point of comparison since it excels at
all levels of safety. On the open-source side, for smaller models, Meta Llama2
performs well at factuality and toxicity but has the highest propensity for
hallucination. Mistral hallucinates the least but cannot handle toxicity well.
It performs well in a dataset mixing several tasks and safety vectors in a
narrow vertical domain. Gemma, the newly introduced open-source model based on
Google Gemini, is generally balanced but trailing behind. When engaging in
back-and-forth conversation (multi-turn prompts), we find that the safety of
open-source models degrades significantly. Aside from OpenAI's GPT, Mistral is
the only model that still performed well in multi-turn tests.",2024-04-15,"David Nadeau, Mike Kroutikov, Karen McNeil, Simon Baribeau",http://arxiv.org/pdf/2404.09785v1,cs.CL
KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models,"Citation Text Generation (CTG) is a task in natural language processing (NLP)
that aims to produce text that accurately cites or references a cited document
within a source document. In CTG, the generated text draws upon contextual cues
from both the source document and the cited paper, ensuring accurate and
relevant citation information is provided. Previous work in the field of
citation generation is mainly based on the text summarization of documents.
Following this, this paper presents a framework, and a comparative study to
demonstrate the use of Large Language Models (LLMs) for the task of citation
generation. Also, we have shown the improvement in the results of citation
generation by incorporating the knowledge graph relations of the papers in the
prompt for the LLM to better learn the relationship between the papers. To
assess how well our model is performing, we have used a subset of standard
S2ORC dataset, which only consists of computer science academic research papers
in the English Language. Vicuna performs best for this task with 14.15 Meteor,
12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, and
improves the performance by 36.98% in Rouge-1, and 33.14% in Meteor by
including knowledge graphs.",2024-04-15,"Avinash Anand, Mohit Gupta, Kritarth Prasad, Ujjwal Goel, Naman Lal, Astha Verma, Rajiv Ratn Shah",http://arxiv.org/pdf/2404.09763v1,cs.CL
Resilience of Large Language Models for Noisy Instructions,"As the rapidly advancing domain of natural language processing (NLP), large
language models (LLMs) have emerged as powerful tools for interpreting human
commands and generating text across various tasks. Nonetheless, the resilience
of LLMs to handle text containing inherent errors, stemming from human
interactions and collaborative systems, has not been thoroughly explored. Our
study investigates the resilience of LLMs against five common types of
disruptions including 1) ASR (Automatic Speech Recognition) errors, 2) OCR
(Optical Character Recognition) errors, 3) grammatical mistakes, 4)
typographical errors, and 5) distractive content. We aim to investigate how
these models react by deliberately embedding these errors into instructions.
Our findings reveal that while some LLMs show a degree of resistance to certain
types of noise, their overall performance significantly suffers. This
emphasizes the importance of further investigation into enhancing model
resilience. In response to the observed decline in performance, our study also
evaluates a ""re-pass"" strategy, designed to purify the instructions of noise
before the LLMs process them. Our analysis indicates that correcting noisy
instructions, particularly for open-source LLMs, presents significant
challenges.",2024-04-15,"Bin Wang, Chengwei Wei, Zhengyuan Liu, Geyu Lin, Nancy F. Chen",http://arxiv.org/pdf/2404.09754v2,cs.CL
Personalized Collaborative Fine-Tuning for On-Device Large Language Models,"We explore on-device self-supervised collaborative fine-tuning of large
language models with limited local data availability. Taking inspiration from
the collaborative learning community, we introduce three distinct
trust-weighted gradient aggregation schemes: weight similarity-based,
prediction similarity-based and validation performance-based. To minimize
communication overhead, we integrate Low-Rank Adaptation (LoRA) and only
exchange LoRA weight updates. Our protocols, driven by prediction and
performance metrics, surpass both FedAvg and local fine-tuning methods, which
is particularly evident in realistic scenarios with more diverse local data
distributions. The results underscore the effectiveness of our approach in
addressing heterogeneity and scarcity within local datasets.",2024-04-15,"Nicolas Wagner, Dongyang Fan, Martin Jaggi",http://arxiv.org/pdf/2404.09753v2,cs.CL
Quantization of Large Language Models with an Overdetermined Basis,"In this paper, we introduce an algorithm for data quantization based on the
principles of Kashin representation. This approach hinges on decomposing any
given vector, matrix, or tensor into two factors. The first factor maintains a
small infinity norm, while the second exhibits a similarly constrained norm
when multiplied by an orthogonal matrix. Surprisingly, the entries of factors
after decomposition are well-concentrated around several peaks, which allows us
to efficiently replace them with corresponding centroids for quantization
purposes. We study the theoretical properties of the proposed approach and
rigorously evaluate our compression algorithm in the context of next-word
prediction tasks and on a set of downstream tasks for text classification. Our
findings demonstrate that Kashin Quantization achieves competitive or superior
quality in model performance while ensuring data compression, marking a
significant advancement in the field of data quantization.",2024-04-15,"Daniil Merkulov, Daria Cherniuk, Alexander Rudikov, Ivan Oseledets, Ekaterina Muravleva, Aleksandr Mikhalev, Boris Kashin",http://arxiv.org/pdf/2404.09737v1,cs.CL
Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model,"Many recent studies endeavor to improve open-source language models through
imitation learning, and re-training on the synthetic instruction data from
state-of-the-art proprietary models like ChatGPT and GPT-4. However, the innate
nature of synthetic data inherently contains noisy data, giving rise to a
substantial presence of low-quality data replete with erroneous responses, and
flawed reasoning. Although we intuitively grasp the potential harm of noisy
data, we lack a quantitative understanding of its impact. To this end, this
paper explores the correlation between the degree of noise and its impact on
language models through instruction tuning. We first introduce the
Falsity-Controllable (FACO) dataset, which comprises pairs of true answers with
corresponding reasoning, as well as false pairs to manually control the falsity
ratio of the dataset.Through our extensive experiments, we found multiple
intriguing findings of the correlation between the factuality of the dataset
and instruction tuning: Specifically, we verified falsity of the instruction is
highly relevant to various benchmark scores. Moreover, when LLMs are trained
with false instructions, they learn to lie and generate fake unfaithful
answers, even though they know the correct answer for the user request.
Additionally, we noted that once the language model is trained with a dataset
contaminated by noise, restoring its original performance is possible, but it
failed to reach full performance.",2024-04-15,Hyunsoo Cho,http://arxiv.org/pdf/2404.09717v1,cs.CL
Are Large Language Models Reliable Argument Quality Annotators?,"Evaluating the quality of arguments is a crucial aspect of any system
leveraging argument mining. However, it is a challenge to obtain reliable and
consistent annotations regarding argument quality, as this usually requires
domain-specific expertise of the annotators. Even among experts, the assessment
of argument quality is often inconsistent due to the inherent subjectivity of
this task. In this paper, we study the potential of using state-of-the-art
large language models (LLMs) as proxies for argument quality annotators. To
assess the capability of LLMs in this regard, we analyze the agreement between
model, human expert, and human novice annotators based on an established
taxonomy of argument quality dimensions. Our findings highlight that LLMs can
produce consistent annotations, with a moderately high agreement with human
experts across most of the quality dimensions. Moreover, we show that using
LLMs as additional annotators can significantly improve the agreement between
annotators. These results suggest that LLMs can serve as a valuable tool for
automated argument quality assessment, thus streamlining and accelerating the
evaluation of large argument datasets.",2024-04-15,"Nailia Mirzakhmedova, Marcel Gohsen, Chia Hao Chang, Benno Stein",http://arxiv.org/pdf/2404.09696v1,cs.CL
LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models,"Large language models (LLMs) show excellent performance in difficult tasks,
but they often require massive memories and computational resources. How to
reduce the parameter scale of LLMs has become research hotspots. In this study,
we make an important observation that the multi-head self-attention (MHA)
sub-layer of Transformer exhibits noticeable low-rank structure, while the
feed-forward network (FFN) sub-layer does not. With this regard, we design a
mixed compression model, which organically combines Low-Rank matrix
approximation And structured Pruning (LoRAP). For the MHA sub-layer, we propose
an input activation weighted singular value decomposition method to strengthen
the low-rank characteristic. Furthermore, we discover that the weight matrices
in MHA sub-layer have different low-rank degrees. Thus, a novel parameter
allocation scheme according to the discrepancy of low-rank degrees is devised.
For the FFN sub-layer, we propose a gradient-free structured channel pruning
method. During the pruning, we get an interesting finding that the least
important 1% of parameter actually play a vital role in model performance.
Extensive evaluations on zero-shot perplexity and zero-shot task classification
indicate that our proposal is superior to previous structured compression
rivals under multiple compression ratios.",2024-04-15,"Guangyan Li, Yongqiang Tang, Wensheng Zhang",http://arxiv.org/pdf/2404.09695v1,cs.CL
Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration,"The emergence of Large Multimodal Models (LMMs) marks a significant milestone
in the development of artificial intelligence. Insurance, as a vast and complex
discipline, involves a wide variety of data forms in its operational processes,
including text, images, and videos, thereby giving rise to diverse multimodal
tasks. Despite this, there has been limited systematic exploration of
multimodal tasks specific to insurance, nor a thorough investigation into how
LMMs can address these challenges. In this paper, we explore GPT-4V's
capabilities in the insurance domain. We categorize multimodal tasks by
focusing primarily on visual aspects based on types of insurance (e.g., auto,
household/commercial property, health, and agricultural insurance) and
insurance stages (e.g., risk assessment, risk monitoring, and claims
processing). Our experiment reveals that GPT-4V exhibits remarkable abilities
in insurance-related tasks, demonstrating not only a robust understanding of
multimodal content in the insurance domain but also a comprehensive knowledge
of insurance scenarios. However, there are notable shortcomings: GPT-4V
struggles with detailed risk rating and loss assessment, suffers from
hallucination in image understanding, and shows variable support for different
languages. Through this work, we aim to bridge the insurance domain with
cutting-edge LMM technology, facilitate interdisciplinary exchange and
development, and provide a foundation for the continued advancement and
evolution of future research endeavors.",2024-04-15,"Chenwei Lin, Hanjia Lyu, Jiebo Luo, Xian Xu",http://arxiv.org/pdf/2404.09690v1,cs.CL
Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation,"The quality of the dataset is crucial for ensuring optimal performance and
reliability of downstream task models. However, datasets often contain noisy
data inadvertently included during the construction process. Numerous attempts
have been made to correct this issue through human annotators. However, hiring
and managing human annotators is expensive and time-consuming. As an
alternative, recent studies are exploring the use of large language models
(LLMs) for data annotation.
  In this study, we present a case study that extends the application of
LLM-based data annotation to enhance the quality of existing datasets through a
cleansing strategy. Specifically, we leverage approaches such as
chain-of-thought and majority voting to imitate human annotation and classify
unrelated documents from the Multi-News dataset, which is widely used for the
multi-document summarization task. Through our proposed cleansing method, we
introduce an enhanced Multi-News+. By employing LLMs for data cleansing, we
demonstrate an efficient and effective approach to improving dataset quality
without relying on expensive human annotation efforts.",2024-04-15,"Juhwan Choi, Jungmin Yun, Kyohoon Jin, YoungBin Kim",http://arxiv.org/pdf/2404.09682v3,cs.CL
Towards Compositionally Generalizable Semantic Parsing in Large Language Models: A Survey,"Compositional generalization is the ability of a model to generalize to
complex, previously unseen types of combinations of entities from just having
seen the primitives. This type of generalization is particularly relevant to
the semantic parsing community for applications such as task-oriented dialogue,
text-to-SQL parsing, and information retrieval, as they can harbor infinite
complexity. Despite the success of large language models (LLMs) in a wide range
of NLP tasks, unlocking perfect compositional generalization still remains one
of the few last unsolved frontiers. The past few years has seen a surge of
interest in works that explore the limitations of, methods to improve, and
evaluation metrics for compositional generalization capabilities of LLMs for
semantic parsing tasks. In this work, we present a literature survey geared at
synthesizing recent advances in analysis, methods, and evaluation schemes to
offer a starting point for both practitioners and researchers in this area.",2024-04-15,Amogh Mannekote,http://arxiv.org/pdf/2404.13074v1,cs.CL
Learn Your Reference Model for Real Good Alignment,"Despite the fact that offline methods for Large Language Models (LLMs)
alignment do not require a direct reward model, they remain susceptible to
overoptimization. This issue arises when the trained model deviates excessively
from the reference policy, leading to a decrease in sample quality. We propose
a new paradigm of offline alignment methods, called Trust Region (including
variants TR-DPO, TR-IPO, TR-KTO), which dynamically updates the reference
policy throughout the training process. Our results show that TR alignment
methods effectively mitigate overoptimization, enabling models to maintain
strong performance even when substantially deviating from the initial reference
policy. We demonstrate the efficacy of these approaches not only through toy
examples that exhibit reduced overoptimization, but also through direct,
side-by-side comparisons in specific tasks such as helpful and harmless
dialogue, as well as summarization, where they surpass conventional methods.
Additionally, we report significant improvements in general-purpose assistant
setups with the Llama3 model on the AlpacaEval 2 and Arena-Hard benchmarks,
highlighting the advantages of Trust Region methods over classical approaches.",2024-04-15,"Alexey Gorbatovski, Boris Shaposhnikov, Alexey Malakhov, Nikita Surnachev, Yaroslav Aksenov, Ian Maksimov, Nikita Balagansky, Daniil Gavrilov",http://arxiv.org/pdf/2404.09656v4,cs.CL
Real-world Instance-specific Image Goal Navigation: Bridging Domain Gaps via Contrastive Learning,"Improving instance-specific image goal navigation (InstanceImageNav), which
locates the identical object in a real-world environment from a query image, is
essential for robotic systems to assist users in finding desired objects. The
challenge lies in the domain gap between low-quality images observed by the
moving robot, characterized by motion blur and low-resolution, and high-quality
query images provided by the user. Such domain gaps could significantly reduce
the task success rate but have not been the focus of previous work. To address
this, we propose a novel method called Few-shot Cross-quality Instance-aware
Adaptation (CrossIA), which employs contrastive learning with an instance
classifier to align features between massive low- and few high-quality images.
This approach effectively reduces the domain gap by bringing the latent
representations of cross-quality images closer on an instance basis.
Additionally, the system integrates an object image collection with a
pre-trained deblurring model to enhance the observed image quality. Our method
fine-tunes the SimSiam model, pre-trained on ImageNet, using CrossIA. We
evaluated our method's effectiveness through an InstanceImageNav task with 20
different types of instances, where the robot identifies the same instance in a
real-world environment as a high-quality query image. Our experiments showed
that our method improves the task success rate by up to three times compared to
the baseline, a conventional approach based on SuperGlue. These findings
highlight the potential of leveraging contrastive learning and image
enhancement techniques to bridge the domain gap and improve object localization
in robotic applications. The project website is
https://emergentsystemlabstudent.github.io/DomainBridgingNav/.",2024-04-15,"Taichi Sakaguchi, Akira Taniguchi, Yoshinobu Hagiwara, Lotfi El Hafi, Shoichi Hasegawa, Tadahiro Taniguchi",http://arxiv.org/pdf/2404.09645v2,cs.CL
"If there's a Trigger Warning, then where's the Trigger? Investigating Trigger Warnings at the Passage Level","Trigger warnings are labels that preface documents with sensitive content if
this content could be perceived as harmful by certain groups of readers. Since
warnings about a document intuitively need to be shown before reading it,
authors usually assign trigger warnings at the document level. What parts of
their writing prompted them to assign a warning, however, remains unclear. We
investigate for the first time the feasibility of identifying the triggering
passages of a document, both manually and computationally. We create a dataset
of 4,135 English passages, each annotated with one of eight common trigger
warnings. In a large-scale evaluation, we then systematically evaluate the
effectiveness of fine-tuned and few-shot classifiers, and their
generalizability. We find that trigger annotation belongs to the group of
subjective annotation tasks in NLP, and that automatic trigger classification
remains challenging but feasible.",2024-04-15,"Matti Wiegmann, Jennifer Rakete, Magdalena Wolska, Benno Stein, Martin Potthast",http://arxiv.org/pdf/2404.09615v1,cs.CL
Improving Recall of Large Language Models: A Model Collaboration Approach for Relational Triple Extraction,"Relation triple extraction, which outputs a set of triples from long
sentences, plays a vital role in knowledge acquisition. Large language models
can accurately extract triples from simple sentences through few-shot learning
or fine-tuning when given appropriate instructions. However, they often miss
out when extracting from complex sentences. In this paper, we design an
evaluation-filtering framework that integrates large language models with small
models for relational triple extraction tasks. The framework includes an
evaluation model that can extract related entity pairs with high precision. We
propose a simple labeling principle and a deep neural network to build the
model, embedding the outputs as prompts into the extraction process of the
large model. We conduct extensive experiments to demonstrate that the proposed
method can assist large language models in obtaining more accurate extraction
results, especially from complex sentences containing multiple relational
triples. Our evaluation model can also be embedded into traditional extraction
models to enhance their extraction precision from complex sentences.",2024-04-15,"Zepeng Ding, Wenhao Huang, Jiaqing Liang, Deqing Yang, Yanghua Xiao",http://arxiv.org/pdf/2404.09593v1,cs.CL
Modelling Language,"This paper argues that large language models have a valuable scientific role
to play in serving as scientific models of a language. Linguistic study should
not only be concerned with the cognitive processes behind linguistic
competence, but also with language understood as an external, social entity.
Once this is recognized, the value of large language models as scientific
models becomes clear. This paper defends this position against a number of
arguments to the effect that language models provide no linguistic insight. It
also draws upon recent work in philosophy of science to show how large language
models could serve as scientific models.",2024-04-15,Jumbly Grindrod,http://arxiv.org/pdf/2404.09579v1,cs.CL
"Transformers, Contextualism, and Polysemy","The transformer architecture, introduced by Vaswani et al. (2017), is at the
heart of the remarkable recent progress in the development of language models,
including widely-used chatbots such as Chat-GPT and Claude. In this paper, I
argue that we can extract from the way the transformer architecture works a
theory of the relationship between context and meaning. I call this the
transformer theory, and I argue that it is novel with regard to two related
philosophical debates: the contextualism debate regarding the extent of
context-sensitivity across natural language, and the polysemy debate regarding
how polysemy should be captured within an account of word meaning.",2024-04-15,Jumbly Grindrod,http://arxiv.org/pdf/2404.09577v2,cs.CL
Large language models and linguistic intentionality,"Do large language models like Chat-GPT or LLaMa meaningfully use the words
they produce? Or are they merely clever prediction machines, simulating
language use by producing statistically plausible text? There have already been
some initial attempts to answer this question by showing that these models meet
the criteria for entering meaningful states according to metasemantic theories
of mental content. In this paper, I will argue for a different approach - that
we should instead consider whether language models meet the criteria given by
our best metasemantic theories of linguistic content. In that vein, I will
illustrate how this can be done by applying two such theories to the case of
language models: Gareth Evans' (1982) account of naming practices and Ruth
Millikan's (1984, 2004, 2005) teleosemantics. In doing so, I will argue that it
is a mistake to think that the failure of LLMs to meet plausible conditions for
mental intentionality thereby renders their outputs meaningless, and that a
distinguishing feature of linguistic intentionality - dependency on a
pre-existing linguistic system - allows for the plausible result LLM outputs
are meaningful.",2024-04-15,Jumbly Grindrod,http://arxiv.org/pdf/2404.09576v2,cs.CL
Reliability Estimation of News Media Sources: Birds of a Feather Flock Together,"Evaluating the reliability of news sources is a routine task for journalists
and organizations committed to acquiring and disseminating accurate
information. Recent research has shown that predicting sources' reliability
represents an important first-prior step in addressing additional challenges
such as fake news detection and fact-checking. In this paper, we introduce a
novel approach for source reliability estimation that leverages reinforcement
learning strategies for estimating the reliability degree of news sources.
Contrary to previous research, our proposed approach models the problem as the
estimation of a reliability degree, and not a reliability label, based on how
all the news media sources interact with each other on the Web. We validated
the effectiveness of our method on a news media reliability dataset that is an
order of magnitude larger than comparable existing datasets. Results show that
the estimated reliability degrees strongly correlates with journalists-provided
scores (Spearman=0.80) and can effectively predict reliability labels
(macro-avg. F$_1$ score=81.05). We release our implementation and dataset,
aiming to provide a valuable resource for the NLP community working on
information verification.",2024-04-15,"Sergio Burdisso, Dairazalia Sánchez-Cortés, Esaú Villatoro-Tello, Petr Motlicek",http://arxiv.org/pdf/2404.09565v1,cs.CL
Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models,"During inference for transformer-based large language models (LLM),
prefilling is the computation of the key-value (KV) cache for input tokens in
the prompt prior to autoregressive generation. For longer input prompt lengths,
prefilling will incur a significant overhead on decoding time. In this work, we
highlight the following pitfall of prefilling: for batches containing
high-varying prompt lengths, significant computation is wasted by the standard
practice of padding sequences to the maximum length. As LLMs increasingly
support longer context lengths, potentially up to 10 million tokens, variations
in prompt lengths within a batch become more pronounced. To address this, we
propose Prepacking, a simple yet effective method to optimize prefilling
computation. To avoid redundant computation on pad tokens, prepacking combines
prompts of varying lengths into a sequence and packs multiple sequences into a
compact batch using a bin-packing algorithm. It then modifies the attention
mask and positional encoding to compute multiple prefilled KV-caches for
multiple prompts within a single sequence. On standard curated dataset
containing prompts with varying lengths, we obtain a significant speed and
memory efficiency improvements as compared to the default padding-based
prefilling computation within Huggingface across a range of base model
configurations and inference serving scenarios.",2024-04-15,"Siyan Zhao, Daniel Israel, Guy Van den Broeck, Aditya Grover",http://arxiv.org/pdf/2404.09529v1,cs.CL
State Space Model for New-Generation Network Alternative to Transformers: A Survey,"In the post-deep learning era, the Transformer architecture has demonstrated
its powerful performance across pre-trained big models and various downstream
tasks. However, the enormous computational demands of this architecture have
deterred many researchers. To further reduce the complexity of attention
models, numerous efforts have been made to design more efficient methods. Among
them, the State Space Model (SSM), as a possible replacement for the
self-attention based Transformer model, has drawn more and more attention in
recent years. In this paper, we give the first comprehensive review of these
works and also provide experimental comparisons and analysis to better
demonstrate the features and advantages of SSM. Specifically, we first give a
detailed description of principles to help the readers quickly capture the key
ideas of SSM. After that, we dive into the reviews of existing SSMs and their
various applications, including natural language processing, computer vision,
graph, multi-modal and multi-media, point cloud/event stream, time series data,
and other domains. In addition, we give statistical comparisons and analysis of
these models and hope it helps the readers to understand the effectiveness of
different structures on various tasks. Then, we propose possible research
points in this direction to better promote the development of the theoretical
model and application of SSM. More related works will be continuously updated
on the following GitHub:
https://github.com/Event-AHU/Mamba_State_Space_Model_Paper_List.",2024-04-15,"Xiao Wang, Shiao Wang, Yuhe Ding, Yuehang Li, Wentao Wu, Yao Rong, Weizhe Kong, Ju Huang, Shihao Li, Haoxiang Yang, Ziwen Wang, Bo Jiang, Chenglong Li, Yaowei Wang, Yonghong Tian, Jin Tang",http://arxiv.org/pdf/2404.09516v1,cs.CL
Bridging the Gap between Different Vocabularies for LLM Ensemble,"Ensembling different large language models (LLMs) to unleash their
complementary potential and harness their individual strengths is highly
valuable. Nevertheless, vocabulary discrepancies among various LLMs have
constrained previous studies to either selecting or blending completely
generated outputs. This limitation hinders the dynamic correction and
enhancement of outputs during the generation process, resulting in a limited
capacity for effective ensemble. To address this issue, we propose a novel
method to Ensemble LLMs via Vocabulary Alignment (EVA). EVA bridges the lexical
gap among various LLMs, enabling meticulous ensemble at each generation step.
Specifically, we first learn mappings between the vocabularies of different
LLMs with the assistance of overlapping tokens. Subsequently, these mappings
are employed to project output distributions of LLMs into a unified space,
facilitating a fine-grained ensemble. Finally, we design a filtering strategy
to exclude models that generate unfaithful tokens. Experimental results on
commonsense reasoning, arithmetic reasoning, machine translation, and
data-to-text generation tasks demonstrate the superiority of our approach
compared with individual LLMs and previous ensemble methods conducted on
complete outputs. Further analyses confirm that our approach can leverage
knowledge from different language models and yield consistent improvement.",2024-04-15,"Yangyifan Xu, Jinliang Lu, Jiajun Zhang",http://arxiv.org/pdf/2404.09492v1,cs.CL
MMCode: Benchmarking Multimodal Large Language Models for Code Generation with Visually Rich Programming Problems,"Programming often involves converting detailed and complex specifications
into code, a process during which developers typically utilize visual aids to
more effectively convey concepts. While recent developments in Large Multimodal
Models have demonstrated remarkable abilities in visual reasoning and
mathematical tasks, there is little work on investigating whether these models
can effectively interpret visual elements for code generation. To this end, we
present MMCode, the first multi-modal coding dataset for evaluating algorithmic
problem-solving skills in visually rich contexts. MMCode contains 3,548
questions and 6,620 images collected from real-world programming challenges
harvested from 10 code competition websites, presenting significant challenges
due to the extreme demand for reasoning abilities. Our experiment results show
that current state-of-the-art models struggle to solve these problems. The
results highlight the lack of powerful vision-code models, and we hope MMCode
can serve as an inspiration for future works in this domain. The data and code
are publicly available at https://github.com/likaixin2000/MMCode.",2024-04-15,"Kaixin Li, Yuchen Tian, Qisheng Hu, Ziyang Luo, Zhiyong Huang, Jing Ma",http://arxiv.org/pdf/2404.09486v2,cs.CL
Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information,"A primary challenge in abstractive summarization is hallucination -- the
phenomenon where a model generates plausible text that is absent in the source
text. We hypothesize that the domain (or topic) of the source text triggers the
model to generate text that is highly probable in the domain, neglecting the
details of the source text. To alleviate this model bias, we introduce a
decoding strategy based on domain-conditional pointwise mutual information.
This strategy adjusts the generation probability of each token by comparing it
with the token's marginal probability within the domain of the source text.
According to evaluation on the XSUM dataset, our method demonstrates
improvement in terms of faithfulness and source relevance. The code is publicly
available at \url{https://github.com/qqplot/dcpmi}.",2024-04-15,"Kyubyung Chae, Jaepill Choi, Yohan Jo, Taesup Kim",http://arxiv.org/pdf/2404.09480v1,cs.CL
Modeling Emotions and Ethics with Large Language Models,"This paper explores the integration of human-like emotions and ethical
considerations into Large Language Models (LLMs). We first model eight
fundamental human emotions, presented as opposing pairs, and employ
collaborative LLMs to reinterpret and express these emotions across a spectrum
of intensity. Our focus extends to embedding a latent ethical dimension within
LLMs, guided by a novel self-supervised learning algorithm with human feedback
(SSHF). This approach enables LLMs to perform self-evaluations and adjustments
concerning ethical guidelines, enhancing their capability to generate content
that is not only emotionally resonant but also ethically aligned. The
methodologies and case studies presented herein illustrate the potential of
LLMs to transcend mere text and image generation, venturing into the realms of
empathetic interaction and principled decision-making, thereby setting a new
precedent in the development of emotionally aware and ethically conscious AI
systems.",2024-04-15,Edward Y. Chang,http://arxiv.org/pdf/2404.13071v2,cs.CL
Automatic Knowledge Graph Construction for Judicial Cases,"In this paper, we explore the application of cognitive intelligence in legal
knowledge, focusing on the development of judicial artificial intelligence.
Utilizing natural language processing (NLP) as the core technology, we propose
a method for the automatic construction of case knowledge graphs for judicial
cases. Our approach centers on two fundamental NLP tasks: entity recognition
and relationship extraction. We compare two pre-trained models for entity
recognition to establish their efficacy. Additionally, we introduce a
multi-task semantic relationship extraction model that incorporates
translational embedding, leading to a nuanced contextualized case knowledge
representation. Specifically, in a case study involving a ""Motor Vehicle
Traffic Accident Liability Dispute,"" our approach significantly outperforms the
baseline model. The entity recognition F1 score improved by 0.36, while the
relationship extraction F1 score increased by 2.37. Building on these results,
we detail the automatic construction process of case knowledge graphs for
judicial cases, enabling the assembly of knowledge graphs for hundreds of
thousands of judgments. This framework provides robust semantic support for
applications of judicial AI, including the precise categorization and
recommendation of related cases.",2024-04-15,"Jie Zhou, Xin Chen, Hang Zhang, Zhe Li",http://arxiv.org/pdf/2404.09416v1,cs.CL
Few-shot Name Entity Recognition on StackOverflow,"StackOverflow, with its vast question repository and limited labeled
examples, raise an annotation challenge for us. We address this gap by
proposing RoBERTa+MAML, a few-shot named entity recognition (NER) method
leveraging meta-learning. Our approach, evaluated on the StackOverflow NER
corpus (27 entity types), achieves a 5% F1 score improvement over the baseline.
We improved the results further domain-specific phrase processing enhance
results.",2024-04-15,"Xinwei Chen, Kun Li, Tianyou Song, Jiangjian Guo",http://arxiv.org/pdf/2404.09405v2,cs.CL
A Large-Scale Evaluation of Speech Foundation Models,"The foundation model paradigm leverages a shared foundation model to achieve
state-of-the-art (SOTA) performance for various tasks, requiring minimal
downstream-specific modeling and data annotation. This approach has proven
crucial in the field of Natural Language Processing (NLP). However, the speech
processing community lacks a similar setup to explore the paradigm
systematically. In this work, we establish the Speech processing Universal
PERformance Benchmark (SUPERB) to study the effectiveness of the paradigm for
speech. We propose a unified multi-tasking framework to address speech
processing tasks in SUPERB using a frozen foundation model followed by
task-specialized, lightweight prediction heads. Combining our results with
community submissions, we verify that the foundation model paradigm is
promising for speech, and our multi-tasking framework is simple yet effective,
as the best-performing foundation model shows competitive generalizability
across most SUPERB tasks. For reproducibility and extensibility, we have
developed a long-term maintained platform that enables deterministic
benchmarking, allows for result sharing via an online leaderboard, and promotes
collaboration through a community-driven benchmark database to support new
development cycles. Finally, we conduct a series of analyses to offer an
in-depth understanding of SUPERB and speech foundation models, including
information flows across tasks inside the models, the correctness of the
weighted-sum benchmarking protocol and the statistical significance and
robustness of the benchmark.",2024-04-15,"Shu-wen Yang, Heng-Jui Chang, Zili Huang, Andy T. Liu, Cheng-I Lai, Haibin Wu, Jiatong Shi, Xuankai Chang, Hsiang-Sheng Tsai, Wen-Chin Huang, Tzu-hsun Feng, Po-Han Chi, Yist Y. Lin, Yung-Sung Chuang, Tzu-Hsien Huang, Wei-Cheng Tseng, Kushal Lakhotia, Shang-Wen Li, Abdelrahman Mohamed, Shinji Watanabe, Hung-yi Lee",http://arxiv.org/pdf/2404.09385v2,cs.CL
Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches,"Prompting has become one of the main approaches to leverage emergent
capabilities of Large Language Models [Brown et al. NeurIPS 2020, Wei et al.
TMLR 2022, Wei et al. NeurIPS 2022]. Recently, researchers and practitioners
have been ""playing"" with prompts (e.g., In-Context Learning) to see how to make
the most of pre-trained Language Models. By homogeneously dissecting more than
a hundred articles, we investigate how software testing and verification
research communities have leveraged LLMs capabilities. First, we validate that
downstream tasks are adequate to convey a nontrivial modular blueprint of
prompt-based proposals in scope. Moreover, we name and classify the concrete
downstream tasks we recover in both validation research papers and solution
proposals. In order to perform classification, mapping, and analysis, we also
develop a novel downstream-task taxonomy. The main taxonomy requirement is to
highlight commonalities while exhibiting variation points of task types that
enable pinpointing emerging patterns in a varied spectrum of Software
Engineering problems that encompasses testing, fuzzing, fault localization,
vulnerability detection, static analysis, and program verification approaches.
Avenues for future research are also discussed based on conceptual clusters
induced by the taxonomy.",2024-04-14,"Víctor A. Braberman, Flavia Bonomo-Braberman, Yiannis Charalambous, Juan G. Colonna, Lucas C. Cordeiro, Rosiane de Freitas",http://arxiv.org/pdf/2404.09384v2,cs.CL
"Low-Resource Named Entity Recognition with Cross-Lingual, Character-Level Neural Conditional Random Fields","Low-resource named entity recognition is still an open problem in NLP. Most
state-of-the-art systems require tens of thousands of annotated sentences in
order to obtain high performance. However, for most of the world's languages,
it is unfeasible to obtain such annotation. In this paper, we present a
transfer learning scheme, whereby we train character-level neural CRFs to
predict named entities for both high-resource languages and low resource
languages jointly. Learning character representations for multiple related
languages allows transfer among the languages, improving F1 by up to 9.8 points
over a loglinear CRF baseline.",2024-04-14,"Ryan Cotterell, Kevin Duh",http://arxiv.org/pdf/2404.09383v1,cs.CL
Deceptive Patterns of Intelligent and Interactive Writing Assistants,"Large Language Models have become an integral part of new intelligent and
interactive writing assistants. Many are offered commercially with a
chatbot-like UI, such as ChatGPT, and provide little information about their
inner workings. This makes this new type of widespread system a potential
target for deceptive design patterns. For example, such assistants might
exploit hidden costs by providing guidance up until a certain point before
asking for a fee to see the rest. As another example, they might sneak unwanted
content/edits into longer generated or revised text pieces (e.g. to influence
the expressed opinion). With these and other examples, we conceptually transfer
several deceptive patterns from the literature to the new context of AI writing
assistants. Our goal is to raise awareness and encourage future research into
how the UI and interaction design of such systems can impact people and their
writing.",2024-04-14,"Karim Benharrak, Tim Zindulka, Daniel Buschek",http://arxiv.org/pdf/2404.09375v1,cs.CL
The Effect of Data Partitioning Strategy on Model Generalizability: A Case Study of Morphological Segmentation,"Recent work to enhance data partitioning strategies for more realistic model
evaluation face challenges in providing a clear optimal choice. This study
addresses these challenges, focusing on morphological segmentation and
synthesizing limitations related to language diversity, adoption of multiple
datasets and splits, and detailed model comparisons. Our study leverages data
from 19 languages, including ten indigenous or endangered languages across 10
language families with diverse morphological systems (polysynthetic, fusional,
and agglutinative) and different degrees of data availability. We conduct
large-scale experimentation with varying sized combinations of training and
evaluation sets as well as new test data. Our results show that, when faced
with new test data: (1) models trained from random splits are able to achieve
higher numerical scores; (2) model rankings derived from random splits tend to
generalize more consistently.",2024-04-14,"Zoey Liu, Bonnie J. Dorr",http://arxiv.org/pdf/2404.09371v1,cs.CL
Evidence from counterfactual tasks supports emergent analogical reasoning in large language models,"We recently reported evidence that large language models are capable of
solving a wide range of text-based analogy problems in a zero-shot manner,
indicating the presence of an emergent capacity for analogical reasoning. Two
recent commentaries have challenged these results, citing evidence from
so-called `counterfactual' tasks in which the standard sequence of the alphabet
is arbitrarily permuted so as to decrease similarity with materials that may
have been present in the language model's training data. Here, we reply to
these critiques, clarifying some misunderstandings about the test materials
used in our original work, and presenting evidence that language models are
also capable of generalizing to these new counterfactual task variants.",2024-04-14,"Taylor Webb, Keith J. Holyoak, Hongjing Lu",http://arxiv.org/pdf/2404.13070v2,cs.CL
Understanding the Role of Temperature in Diverse Question Generation by GPT-4,"We conduct a preliminary study of the effect of GPT's temperature parameter
on the diversity of GPT4-generated questions. We find that using higher
temperature values leads to significantly higher diversity, with different
temperatures exposing different types of similarity between generated sets of
questions. We also demonstrate that diverse question generation is especially
difficult for questions targeting lower levels of Bloom's Taxonomy.",2024-04-14,"Arav Agarwal, Karthik Mittal, Aidan Doyle, Pragnya Sridhar, Zipiao Wan, Jacob Arthur Doughty, Jaromir Savelka, Majd Sakr",http://arxiv.org/pdf/2404.09366v1,cs.CL
LLeMpower: Understanding Disparities in the Control and Access of Large Language Models,"Large Language Models (LLMs) are a powerful technology that augment human
skill to create new opportunities, akin to the development of steam engines and
the internet. However, LLMs come with a high cost. They require significant
computing resources and energy to train and serve. Inequity in their control
and access has led to concentration of ownership and power to a small
collection of corporations. In our study, we collect training and inference
requirements for various LLMs. We then analyze the economic strengths of
nations and organizations in the context of developing and serving these
models. Additionally, we also look at whether individuals around the world can
access and use this emerging technology. We compare and contrast these groups
to show that these technologies are monopolized by a surprisingly few entities.
We conclude with a qualitative study on the ethical implications of our
findings and discuss future directions towards equity in LLM access.",2024-04-14,"Vishwas Sathish, Hannah Lin, Aditya K Kamath, Anish Nyayachavadi",http://arxiv.org/pdf/2404.09356v1,cs.CL
Towards Practical Tool Usage for Continually Learning LLMs,"Large language models (LLMs) show an innate skill for solving language based
tasks. But insights have suggested an inability to adjust for information or
task-solving skills becoming outdated, as their knowledge, stored directly
within their parameters, remains static in time. Tool use helps by offloading
work to systems that the LLM can access through an interface, but LLMs that use
them still must adapt to nonstationary environments for prolonged use, as new
tools can emerge and existing tools can change. Nevertheless, tools require
less specialized knowledge, therefore we hypothesize they are better suited for
continual learning (CL) as they rely less on parametric memory for solving
tasks and instead focus on learning when to apply pre-defined tools. To verify
this, we develop a synthetic benchmark and follow this by aggregating existing
NLP tasks to form a more realistic testing scenario. While we demonstrate
scaling model size is not a solution, regardless of tool usage, continual
learning techniques can enable tool LLMs to both adapt faster while forgetting
less, highlighting their potential as continual learners.",2024-04-14,"Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath Chandar",http://arxiv.org/pdf/2404.09339v1,cs.CL
Entropy Guided Extrapolative Decoding to Improve Factuality in Large Language Models,"Large language models (LLMs) exhibit impressive natural language capabilities
but suffer from hallucination -- generating content ungrounded in the realities
of training data. Recent work has focused on decoding techniques to improve
factuality during inference by leveraging LLMs' hierarchical representation of
factual knowledge, manipulating the predicted distributions at inference time.
Current state-of-the-art approaches refine decoding by contrasting early-exit
distributions from a lower layer with the final layer to exploit information
related to factuality within the model forward procedure. However, such methods
often assume the final layer is the most reliable and the lower layer selection
process depends on it. In this work, we first propose extrapolation of critical
token probabilities beyond the last layer for more accurate contrasting. We
additionally employ layer-wise entropy-guided lower layer selection, decoupling
the selection process from the final layer. Experiments demonstrate strong
performance - surpassing state-of-the-art on multiple different datasets by
large margins. Analyses show different kinds of prompts respond to different
selection strategies.",2024-04-14,"Souvik Das, Lifeng Jin, Linfeng Song, Haitao Mi, Baolin Peng, Dong Yu",http://arxiv.org/pdf/2404.09338v1,cs.CL
Self-Selected Attention Span for Accelerating Large Language Model Inference,"Large language models (LLMs) can solve challenging tasks. However, their
inference computation on modern GPUs is highly inefficient due to the
increasing number of tokens they must attend to as they generate new ones. To
address this inefficiency, we capitalize on LLMs' problem-solving capabilities
to optimize their own inference-time efficiency. We demonstrate with two
specific tasks: (a) evaluating complex arithmetic expressions and (b)
summarizing news articles. For both tasks, we create custom datasets to
fine-tune an LLM. The goal of fine-tuning is twofold: first, to make the LLM
learn to solve the evaluation or summarization task, and second, to train it to
identify the minimal attention spans required for each step of the task. As a
result, the fine-tuned model is able to convert these self-identified minimal
attention spans into sparse attention masks on-the-fly during inference. We
develop a custom CUDA kernel to take advantage of the reduced context to attend
to. We demonstrate that using this custom CUDA kernel improves the throughput
of LLM inference by 28%. Our work presents an end-to-end demonstration showing
that training LLMs to self-select their attention spans speeds up
autoregressive inference in solving real-world tasks.",2024-04-14,"Tian Jin, Wanzin Yazar, Zifei Xu, Sayeh Sharify, Xin Wang",http://arxiv.org/pdf/2404.09336v1,cs.CL
"Large Language Models are as persuasive as humans, but how? About the cognitive effort and moral-emotional language of LLM arguments","Large Language Models (LLMs) are already as persuasive as humans. However, we
know very little about how they do it. This paper investigates the persuasion
strategies of LLMs, comparing them with human-generated arguments. Using a
dataset of 1,251 participants in an experiment, we analyze the persuasion
strategies of LLM-generated and human-generated arguments using measures of
cognitive effort (lexical and grammatical complexity) and moral-emotional
language (sentiment and moral analysis). The study reveals that LLMs produce
arguments that require higher cognitive effort, exhibiting more complex
grammatical and lexical structures than human counterparts. Additionally, LLMs
demonstrate a significant propensity to engage more deeply with moral language,
utilizing both positive and negative moral foundations more frequently than
humans. In contrast with previous research, no significant difference was found
in the emotional content produced by LLMs and humans. These findings contribute
to the discourse on AI and persuasion, highlighting the dual potential of LLMs
to both enhance and undermine informational integrity through communication
strategies for digital persuasion.",2024-04-14,Carlos Carrasco-Farre,http://arxiv.org/pdf/2404.09329v2,cs.CL
Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora,"Media Storms, dramatic outbursts of attention to a story, are central
components of media dynamics and the attention landscape. Despite their
significance, there has been little systematic and empirical research on this
concept due to issues of measurement and operationalization. We introduce an
iterative human-in-the-loop method to identify media storms in a large-scale
corpus of news articles. The text is first transformed into signals of
dispersion based on several textual characteristics. In each iteration, we
apply unsupervised anomaly detection to these signals; each anomaly is then
validated by an expert to confirm the presence of a storm, and those results
are then used to tune the anomaly detection in the next iteration. We
demonstrate the applicability of this method in two scenarios: first,
supplementing an initial list of media storms within a specific time frame; and
second, detecting media storms in new time periods. We make available a media
storm dataset compiled using both scenarios. Both the method and dataset offer
the basis for comprehensive empirical research into the concept of media
storms, including characterizing them and predicting their outbursts and
durations, in mainstream media or social media platforms.",2024-04-14,"Dror K. Markus, Effi Levi, Tamir Sheafer, Shaul R. Shenhav",http://arxiv.org/pdf/2404.09299v2,cs.CL
Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT,"In today's rapidly evolving landscape of Artificial Intelligence, large
language models (LLMs) have emerged as a vibrant research topic. LLMs find
applications in various fields and contribute significantly. Despite their
powerful language capabilities, similar to pre-trained language models (PLMs),
LLMs still face challenges in remembering events, incorporating new
information, and addressing domain-specific issues or hallucinations. To
overcome these limitations, researchers have proposed Retrieval-Augmented
Generation (RAG) techniques, some others have proposed the integration of LLMs
with Knowledge Graphs (KGs) to provide factual context, thereby improving
performance and delivering more accurate feedback to user queries.
  Education plays a crucial role in human development and progress. With the
technology transformation, traditional education is being replaced by digital
or blended education. Therefore, educational data in the digital environment is
increasing day by day. Data in higher education institutions are diverse,
comprising various sources such as unstructured/structured text, relational
databases, web/app-based API access, etc. Constructing a Knowledge Graph from
these cross-data sources is not a simple task. This article proposes a method
for automatically constructing a Knowledge Graph from multiple data sources and
discusses some initial applications (experimental trials) of KG in conjunction
with LLMs for question-answering tasks.",2024-04-14,"Tuan Bui, Oanh Tran, Phuong Nguyen, Bao Ho, Long Nguyen, Thang Bui, Tho Quan",http://arxiv.org/pdf/2404.09296v2,cs.CL
Subtle Signs of Scribal Intent in the Voynich Manuscript,"This study explores the cryptic Voynich Manuscript, by looking for subtle
signs of scribal intent hidden in overlooked features of the ""Voynichese""
script. The findings indicate that distributions of tokens within paragraphs
vary significantly based on positions defined not only by elements intrinsic to
the script such as paragraph and line boundaries but also by extrinsic
elements, namely the hand-drawn illustrations of plants.",2024-04-14,"Andrew Steckley, Noah Steckley",http://arxiv.org/pdf/2404.13069v1,cs.CL
TrafficVLM: A Controllable Visual Language Model for Traffic Video Captioning,"Traffic video description and analysis have received much attention recently
due to the growing demand for efficient and reliable urban surveillance
systems. Most existing methods only focus on locating traffic event segments,
which severely lack descriptive details related to the behaviour and context of
all the subjects of interest in the events. In this paper, we present
TrafficVLM, a novel multi-modal dense video captioning model for vehicle ego
camera view. TrafficVLM models traffic video events at different levels of
analysis, both spatially and temporally, and generates long fine-grained
descriptions for the vehicle and pedestrian at different phases of the event.
We also propose a conditional component for TrafficVLM to control the
generation outputs and a multi-task fine-tuning paradigm to enhance
TrafficVLM's learning capability. Experiments show that TrafficVLM performs
well on both vehicle and overhead camera views. Our solution achieved
outstanding results in Track 2 of the AI City Challenge 2024, ranking us third
in the challenge standings. Our code is publicly available at
https://github.com/quangminhdinh/TrafficVLM.",2024-04-14,"Quang Minh Dinh, Minh Khoi Ho, Anh Quan Dang, Hung Phong Tran",http://arxiv.org/pdf/2404.09275v1,cs.CL
JaFIn: Japanese Financial Instruction Dataset,"We construct an instruction dataset for the large language model (LLM) in the
Japanese finance domain. Domain adaptation of language models, including LLMs,
is receiving more attention as language models become more popular. This study
demonstrates the effectiveness of domain adaptation through instruction tuning.
To achieve this, we propose an instruction tuning data in Japanese called
JaFIn, the Japanese Financial Instruction Dataset. JaFIn is manually
constructed based on multiple data sources, including Japanese government
websites, which provide extensive financial knowledge. We then utilize JaFIn to
apply instruction tuning for several LLMs, demonstrating that our models
specialized in finance have better domain adaptability than the original
models. The financial-specialized LLMs created were evaluated using a
quantitative Japanese financial benchmark and qualitative response comparisons,
showing improved performance over the originals.",2024-04-14,"Kota Tanabe, Masahiro Suzuki, Hiroki Sakaji, Itsuki Noda",http://arxiv.org/pdf/2404.09260v2,cs.CL
Test Code Generation for Telecom Software Systems using Two-Stage Generative Model,"In recent years, the evolution of Telecom towards achieving intelligent,
autonomous, and open networks has led to an increasingly complex Telecom
Software system, supporting various heterogeneous deployment scenarios, with
multi-standard and multi-vendor support. As a result, it becomes a challenge
for large-scale Telecom software companies to develop and test software for all
deployment scenarios. To address these challenges, we propose a framework for
Automated Test Generation for large-scale Telecom Software systems. We begin by
generating Test Case Input data for test scenarios observed using a time-series
Generative model trained on historical Telecom Network data during field
trials. Additionally, the time-series Generative model helps in preserving the
privacy of Telecom data. The generated time-series software performance data
are then utilized with test descriptions written in natural language to
generate Test Script using the Generative Large Language Model. Our
comprehensive experiments on public datasets and Telecom datasets obtained from
operational Telecom Networks demonstrate that the framework can effectively
generate comprehensive test case data input and useful test code.",2024-04-14,"Mohamad Nabeel, Doumitrou Daniil Nimara, Tahar Zanouda",http://arxiv.org/pdf/2404.09249v1,cs.CL
Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts,"Reinforcement learning (RL) trains agents to accomplish complex tasks through
environmental interaction data, but its capacity is also limited by the scope
of the available data. To obtain a knowledgeable agent, a promising approach is
to leverage the knowledge from large language models (LLMs). Despite previous
studies combining LLMs with RL, seamless integration of the two components
remains challenging due to their semantic gap. This paper introduces a novel
method, Knowledgeable Agents from Language Model Rollouts (KALM), which
extracts knowledge from LLMs in the form of imaginary rollouts that can be
easily learned by the agent through offline reinforcement learning methods. The
primary challenge of KALM lies in LLM grounding, as LLMs are inherently limited
to textual data, whereas environmental data often comprise numerical vectors
unseen to LLMs. To address this, KALM fine-tunes the LLM to perform various
tasks based on environmental data, including bidirectional translation between
natural language descriptions of skills and their corresponding rollout data.
This grounding process enhances the LLM's comprehension of environmental
dynamics, enabling it to generate diverse and meaningful imaginary rollouts
that reflect novel skills. Initial empirical evaluations on the CLEVR-Robot
environment demonstrate that KALM enables agents to complete complex
rephrasings of task goals and extend their capabilities to novel tasks
requiring unprecedented optimal behaviors. KALM achieves a success rate of 46%
in executing tasks with unseen goals, substantially surpassing the 26% success
rate achieved by baseline methods. Furthermore, KALM effectively enables the
LLM to comprehend environmental dynamics, resulting in the generation of
meaningful imaginary rollouts that reflect novel skills and demonstrate the
seamless integration of large language models and reinforcement learning.",2024-04-14,"Jing-Cheng Pang, Si-Hang Yang, Kaiyuan Li, Jiaji Zhang, Xiong-Hui Chen, Nan Tang, Yang Yu",http://arxiv.org/pdf/2404.09248v1,cs.CL
Exploring and Improving Drafts in Blockwise Parallel Decoding,"Despite the remarkable strides made by autoregressive language models, their
potential is often hampered by the slow inference speeds inherent in sequential
token generation. Blockwise parallel decoding (BPD) was proposed by Stern et
al. as a method to improve inference speed of language models by simultaneously
predicting multiple future tokens, termed block drafts, which are subsequently
verified and conditionally accepted by the autoregressive model. This paper
contributes to the understanding and improvement of block drafts in two ways.
First, we analyze the token distributions produced by multiple prediction
heads. Secondly, we leverage this analysis to develop algorithms to improve BPD
inference speed by refining the block drafts using n-gram and neural language
models. Experiments demonstrate that refined block drafts yield a +5-21%
increase in block efficiency (i.e., the number of accepted tokens from the
block draft) across diverse datasets.",2024-04-14,"Taehyeon Kim, Ananda Theertha Suresh, Kishore Papineni, Michael Riley, Sanjiv Kumar, Adrian Benton",http://arxiv.org/pdf/2404.09221v2,cs.CL
Compass: Large Multilingual Language Model for South-east Asia,"Large language models have exhibited significant proficiency in languages
endowed with extensive linguistic resources, such as English and Chinese.
Nevertheless, their effectiveness notably diminishes when applied to languages
characterized by limited linguistic resources, particularly within the
Southeast Asian linguistic landscape, such as Indonesian. The scarcity of
linguistic resources for these languages presents challenges associated with
inadequate training, restricted vocabulary coverage, and challenging evaluation
processes. In response to these exigencies, we have introduced CompassLLM, a
large multilingual model specifically tailored for Southeast Asian languages,
with the primary aim of supporting the developmental requirements of Shopee.
Our methodology encompasses several key strategies. To progressively enhance
multilingual proficiencies, we implemented a multi-stage pre-training strategy
integrated with curriculum learning, gradually intensifying the focus on
low-resource languages. Concurrently, to better accommodate low-resource human
instructions, we curated and generated a repository of high-quality
multilingual human instructions, culminating the CompassLLM-SFT model through
supervised instruction fine-tuning. Finally, to reinforce the model's alignment
with human preference behaviors, we have embraced the principle of Direct
Preference Optimization (DPO) to obtain CompassLLM-DPO model. Preliminary
evaluation of the CompassLLM model yields promising results, with our model
surpassing benchmark models like Vicuna-7b-v1.5, Sealion, Falcon and SeaLLM,
across diverse evaluation tasks, as verified through both automated and
human-driven assessments. Notably, our model exhibits its superior performance
in South-east Asia languages, such as Indonesian language.",2024-04-14,Sophia Maria,http://arxiv.org/pdf/2404.09220v1,cs.CL
DKE-Research at SemEval-2024 Task 2: Incorporating Data Augmentation with Generative Models and Biomedical Knowledge to Enhance Inference Robustness,"Safe and reliable natural language inference is critical for extracting
insights from clinical trial reports but poses challenges due to biases in
large pre-trained language models. This paper presents a novel data
augmentation technique to improve model robustness for biomedical natural
language inference in clinical trials. By generating synthetic examples through
semantic perturbations and domain-specific vocabulary replacement and adding a
new task for numerical and quantitative reasoning, we introduce greater
diversity and reduce shortcut learning. Our approach, combined with multi-task
learning and the DeBERTa architecture, achieved significant performance gains
on the NLI4CT 2024 benchmark compared to the original language models. Ablation
studies validate the contribution of each augmentation method in improving
robustness. Our best-performing model ranked 12th in terms of faithfulness and
8th in terms of consistency, respectively, out of the 32 participants.",2024-04-14,"Yuqi Wang, Zeqiang Wang, Wei Wang, Qi Chen, Kaizhu Huang, Anh Nguyen, Suparna De",http://arxiv.org/pdf/2404.09206v1,cs.CL
TransformerFAM: Feedback attention is working memory,"While Transformers have revolutionized deep learning, their quadratic
attention complexity hinders their ability to process infinitely long inputs.
We propose Feedback Attention Memory (FAM), a novel Transformer architecture
that leverages a feedback loop to enable the network to attend to its own
latent representations. This design fosters the emergence of working memory
within the Transformer, allowing it to process indefinitely long sequences.
TransformerFAM requires no additional weights, enabling seamless integration
with pre-trained models. Our experiments show that TransformerFAM significantly
improves Transformer performance on long-context tasks across various model
sizes (1B, 8B, and 24B). These results showcase the potential to empower Large
Language Models (LLMs) to process sequences of unlimited length.",2024-04-14,"Dongseong Hwang, Weiran Wang, Zhuoyuan Huo, Khe Chai Sim, Pedro Moreno Mengibar",http://arxiv.org/pdf/2404.09173v3,cs.CL
Distilling Reasoning Ability from Large Language Models with Adaptive Thinking,"Chain of thought finetuning (cot-finetuning) aims to endow small language
models (SLM) with reasoning ability to improve their performance towards
specific tasks by allowing them to imitate the reasoning procedure of large
language models (LLM) beyond simply predicting the answers. Most existing
cot-finetuning methods adopt a pre-thinking mechanism, allowing the SLM to
generate a rationale before providing an answer. This mechanism enables SLM to
analyze and think about complex questions, but it also makes answer correctness
highly sensitive to minor errors in rationale. Therefore, we propose a robust
post-thinking mechanism to generate answers before rationale. Thanks to this
answer-first setting, 1) the answer can escape from the adverse effects caused
by minor errors in the rationale; 2) the rationale serves as an error amplifier
to the answer, which makes the SLM focus on learning hard samples; 3) the
inferring efficiency can also benefit from the setting since users can stop the
generation right after answers are outputted when inference is conducted.
However, although the post-thinking mechanism brings many advantages and
improves the overall performance of SLM on specific tasks, it may lose the
ability to think about the questions and decompose complex questions into
simple sub-questions compared to pre-thinking mechanism. Therefore, a
plug-and-play adaptive-thinking mechanism is proposed with the aid of the soft
prompt tuning to integrate the merits of the pre-thinking mechanism and
post-thinking mechanism, in which a perception module is introduced to
adaptively prompt SLM answer or think first based on perceiving the complexity
of the questions. Extensive experiments are conducted across 12 reasoning tasks
and 2 representative language models to demonstrate the effectiveness of the
proposed mechanism.",2024-04-14,"Xiaoshu Chen, Sihang Zhou, Ke Liang, Xinwang Liu",http://arxiv.org/pdf/2404.09170v5,cs.CL
Evaluation and Improvement of Fault Detection for Large Language Models,"Large language models (LLMs) have recently achieved significant success
across various application domains, garnering substantial attention from
different communities. Unfortunately, even for the best LLM, many
\textit{faults} still exist that LLM cannot properly predict. Such faults will
harm the usability of LLMs in general and could introduce safety issues in
reliability-critical systems such as autonomous driving systems. How to quickly
reveal these faults in real-world datasets that LLM could face is important,
but challenging. The major reason is that the ground truth is necessary but the
data labeling process is heavy considering the time and human effort. To handle
this problem, in the conventional deep learning testing field, test selection
methods have been proposed for efficiently evaluating deep learning models by
prioritizing faults. However, despite their importance, the usefulness of these
methods on LLMs is unclear, and lack of exploration. In this paper, we conduct
the first empirical study to investigate the effectiveness of existing fault
detection methods for LLMs. Experimental results on four different
tasks~(including both code tasks and natural language processing tasks) and
four LLMs~(e.g., LLaMA3 and GPT4) demonstrated that simple methods such as
Margin perform well on LLMs but there is still a big room for improvement.
Based on the study, we further propose \textbf{MuCS}, a prompt
\textbf{Mu}tation-based prediction \textbf{C}onfidence \textbf{S}moothing
framework to boost the fault detection capability of existing methods.
Concretely, multiple prompt mutation techniques have been proposed to help
collect more diverse outputs for confidence smoothing. The results show that
our proposed framework significantly enhances existing methods with the
improvement of test relative coverage by up to 70.53\%.",2024-04-14,"Qiang Hu, Jin Wen, Maxime Cordy, Yuheng Huang, Wei Ma, Xiaofei Xie, Lei Ma",http://arxiv.org/pdf/2404.14419v2,cs.CL
GeMQuAD : Generating Multilingual Question Answering Datasets from Large Language Models using Few Shot Learning,"The emergence of Large Language Models (LLMs) with capabilities like
In-Context Learning (ICL) has ushered in new possibilities for data generation
across various domains while minimizing the need for extensive data collection
and modeling techniques. Researchers have explored ways to use this generated
synthetic data to optimize smaller student models for reduced deployment costs
and lower latency in downstream tasks. However, ICL-generated data often
suffers from low quality as the task specificity is limited with few examples
used in ICL. In this paper, we propose GeMQuAD - a semi-supervised learning
approach, extending the WeakDAP framework, applied to a dataset generated
through ICL with just one example in the target language using AlexaTM 20B
Seq2Seq LLM. Through our approach, we iteratively identify high-quality data to
enhance model performance, especially for low-resource multilingual setting in
the context of Extractive Question Answering task. Our framework outperforms
the machine translation-augmented model by 0.22/1.68 F1/EM (Exact Match) points
for Hindi and 0.82/1.37 F1/EM points for Spanish on the MLQA dataset, and it
surpasses the performance of model trained on an English-only dataset by
5.05/6.50 F1/EM points for Hindi and 3.81/3.69 points F1/EM for Spanish on the
same dataset. Notably, our approach uses a pre-trained LLM for generation with
no fine-tuning (FT), utilizing just a single annotated example in ICL to
generate data, providing a cost-effective development process.",2024-04-14,"Amani Namboori, Shivam Mangale, Andy Rosenbaum, Saleh Soltan",http://arxiv.org/pdf/2404.09163v1,cs.CL
Mitigating Heterogeneity among Factor Tensors via Lie Group Manifolds for Tensor Decomposition Based Temporal Knowledge Graph Embedding,"Recent studies have highlighted the effectiveness of tensor decomposition
methods in the Temporal Knowledge Graphs Embedding (TKGE) task. However, we
found that inherent heterogeneity among factor tensors in tensor decomposition
significantly hinders the tensor fusion process and further limits the
performance of link prediction. To overcome this limitation, we introduce a
novel method that maps factor tensors onto a unified smooth Lie group manifold
to make the distribution of factor tensors approximating homogeneous in tensor
decomposition. We provide the theoretical proof of our motivation that
homogeneous tensors are more effective than heterogeneous tensors in tensor
fusion and approximating the target for tensor decomposition based TKGE
methods. The proposed method can be directly integrated into existing tensor
decomposition based TKGE methods without introducing extra parameters.
Extensive experiments demonstrate the effectiveness of our method in mitigating
the heterogeneity and in enhancing the tensor decomposition based TKGE models.",2024-04-14,"Jiang Li, Xiangdong Su, Guanglai Gao",http://arxiv.org/pdf/2404.09155v2,cs.CL
ToNER: Type-oriented Named Entity Recognition with Generative Language Model,"In recent years, the fine-tuned generative models have been proven more
powerful than the previous tagging-based or span-based models on named entity
recognition (NER) task. It has also been found that the information related to
entities, such as entity types, can prompt a model to achieve NER better.
However, it is not easy to determine the entity types indeed existing in the
given sentence in advance, and inputting too many potential entity types would
distract the model inevitably. To exploit entity types' merit on promoting NER
task, in this paper we propose a novel NER framework, namely ToNER based on a
generative model. In ToNER, a type matching model is proposed at first to
identify the entity types most likely to appear in the sentence. Then, we
append a multiple binary classification task to fine-tune the generative
model's encoder, so as to generate the refined representation of the input
sentence. Moreover, we add an auxiliary task for the model to discover the
entity types which further fine-tunes the model to output more accurate
results. Our extensive experiments on some NER benchmarks verify the
effectiveness of our proposed strategies in ToNER that are oriented towards
entity types' exploitation.",2024-04-14,"Guochao Jiang, Ziqin Luo, Yuchen Shi, Dixuan Wang, Jiaqing Liang, Deqing Yang",http://arxiv.org/pdf/2404.09145v2,cs.CL
From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian Language Representation,"In the rapidly advancing field of AI and NLP, generative large language
models (LLMs) stand at the forefront of innovation, showcasing unparalleled
abilities in text understanding and generation. However, the limited
representation of low-resource languages like Ukrainian poses a notable
challenge, restricting the reach and relevance of this technology. Our paper
addresses this by fine-tuning the open-source Gemma and Mistral LLMs with
Ukrainian datasets, aiming to improve their linguistic proficiency and
benchmarking them against other existing models capable of processing Ukrainian
language. This endeavor not only aims to mitigate language bias in technology
but also promotes inclusivity in the digital realm. Our transparent and
reproducible approach encourages further NLP research and development.
Additionally, we present the Ukrainian Knowledge and Instruction Dataset (UKID)
to aid future efforts in language model fine-tuning. Our research not only
advances the field of NLP but also highlights the importance of linguistic
diversity in AI, which is crucial for cultural preservation, education, and
expanding AI's global utility. Ultimately, we advocate for a future where
technology is inclusive, enabling AI to communicate effectively across all
languages, especially those currently underrepresented.",2024-04-14,"Artur Kiulian, Anton Polishko, Mykola Khandoga, Oryna Chubych, Jack Connor, Raghav Ravishankar, Adarsh Shirawalmath",http://arxiv.org/pdf/2404.09138v1,cs.CL
TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis,"This paper introduces novel methodologies for the Natural Language Inference
for Clinical Trials (NLI4CT) task. We present TLDR (T5-generated
clinical-Language summaries for DeBERTa Report Analysis) which incorporates
T5-model generated premise summaries for improved entailment and contradiction
analysis in clinical NLI tasks. This approach overcomes the challenges posed by
small context windows and lengthy premises, leading to a substantial
improvement in Macro F1 scores: a 0.184 increase over truncated premises. Our
comprehensive experimental evaluation, including detailed error analysis and
ablations, confirms the superiority of TLDR in achieving consistency and
faithfulness in predictions against semantically altered inputs.",2024-04-14,"Spandan Das, Vinay Samuel, Shahriar Noroozizadeh",http://arxiv.org/pdf/2404.09136v1,cs.CL
Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions,"Natural Language Processing (NLP) is witnessing a remarkable breakthrough
driven by the success of Large Language Models (LLMs). LLMs have gained
significant attention across academia and industry for their versatile
applications in text generation, question answering, and text summarization. As
the landscape of NLP evolves with an increasing number of domain-specific LLMs
employing diverse techniques and trained on various corpus, evaluating
performance of these models becomes paramount. To quantify the performance,
it's crucial to have a comprehensive grasp of existing metrics. Among the
evaluation, metrics which quantifying the performance of LLMs play a pivotal
role. This paper offers a comprehensive exploration of LLM evaluation from a
metrics perspective, providing insights into the selection and interpretation
of metrics currently in use. Our main goal is to elucidate their mathematical
formulations and statistical interpretations. We shed light on the application
of these metrics using recent Biomedical LLMs. Additionally, we offer a
succinct comparison of these metrics, aiding researchers in selecting
appropriate metrics for diverse tasks. The overarching goal is to furnish
researchers with a pragmatic guide for effective LLM evaluation and metric
selection, thereby advancing the understanding and application of these large
language models.",2024-04-14,"Taojun Hu, Xiao-Hua Zhou",http://arxiv.org/pdf/2404.09135v1,cs.CL
When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models,"Recent studies suggest that self-reflective prompting can significantly
enhance the reasoning capabilities of Large Language Models (LLMs). However,
the use of external feedback as a stop criterion raises doubts about the true
extent of LLMs' ability to emulate human-like self-reflection. In this paper,
we set out to clarify these capabilities under a more stringent evaluation
setting in which we disallow any kind of external feedback. Our findings under
this setting show a split: while self-reflection enhances performance in
TruthfulQA, it adversely affects results in HotpotQA. We conduct follow-up
analyses to clarify the contributing factors in these patterns, and find that
the influence of self-reflection is impacted both by reliability of accuracy in
models' initial responses, and by overall question difficulty: specifically,
self-reflection shows the most benefit when models are less likely to be
correct initially, and when overall question difficulty is higher. We also find
that self-reflection reduces tendency toward majority voting. Based on our
findings, we propose guidelines for decisions on when to implement
self-reflection. We release the codebase for reproducing our experiments at
https://github.com/yanhong-lbh/LLM-SelfReflection-Eval.",2024-04-14,"Yanhong Li, Chenghao Yang, Allyson Ettinger",http://arxiv.org/pdf/2404.09129v1,cs.CL
Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation,"Uncertainty estimation is a significant issue for current large language
models (LLMs) that are generally poorly calibrated and over-confident,
especially with reinforcement learning from human feedback (RLHF). Unlike
humans, whose decisions and confidences not only stem from intrinsic beliefs
but can also be adjusted through daily observations, existing calibration
methods for LLMs focus on estimating or eliciting individual confidence without
taking full advantage of the ""Collective Wisdom"": the interaction among
multiple LLMs that can collectively improve both accuracy and calibration. In
this work, we propose Collaborative Calibration, a post-hoc training-free
calibration strategy that leverages the collaborative and expressive
capabilities of multiple tool-augmented LLM agents in a simulated group
deliberation process. We demonstrate the effectiveness of Collaborative
Calibration on generative QA tasks across various domains, showing its
potential in harnessing the rationalization of collectively calibrated
confidence assessments and improving the reliability of model predictions.",2024-04-14,"Ruixin Yang, Dheeraj Rajagopal, Shirley Anugrah Hayati, Bin Hu, Dongyeop Kang",http://arxiv.org/pdf/2404.09127v3,cs.CL
Provable Interactive Learning with Hindsight Instruction Feedback,"We study interactive learning in a setting where the agent has to generate a
response (e.g., an action or trajectory) given a context and an instruction. In
contrast, to typical approaches that train the system using reward or expert
supervision on response, we study learning with hindsight instruction where a
teacher provides an instruction that is most suitable for the agent's generated
response. This hindsight labeling of instruction is often easier to provide
than providing expert supervision of the optimal response which may require
expert knowledge or can be impractical to elicit. We initiate the theoretical
analysis of interactive learning with hindsight labeling. We first provide a
lower bound showing that in general, the regret of any algorithm must scale
with the size of the agent's response space. We then study a specialized
setting where the underlying instruction-response distribution can be
decomposed as a low-rank matrix. We introduce an algorithm called LORIL for
this setting and show that its regret scales as $\sqrt{T}$ where $T$ is the
number of rounds and depends on the intrinsic rank but does not depend on the
size of the agent's response space. We provide experiments in two domains
showing that LORIL outperforms baselines even when the low-rank assumption is
violated.",2024-04-14,"Dipendra Misra, Aldo Pacchiano, Robert E. Schapire",http://arxiv.org/pdf/2404.09123v1,cs.CL
Semantic In-Domain Product Identification for Search Queries,"Accurate explicit and implicit product identification in search queries is
critical for enhancing user experiences, especially at a company like Adobe
which has over 50 products and covers queries across hundreds of tools. In this
work, we present a novel approach to training a product classifier from user
behavioral data. Our semantic model led to >25% relative improvement in CTR
(click through rate) across the deployed surfaces; a >50% decrease in null
rate; a 2x increase in the app cards surfaced, which helps drive product
visibility.",2024-04-13,"Sanat Sharma, Jayant Kumar, Twisha Naik, Zhaoyu Lu, Arvind Srikantan, Tracy Holloway King",http://arxiv.org/pdf/2404.09091v2,cs.CL
CuriousLLM: Elevating Multi-Document Question Answering with LLM-Enhanced Knowledge Graph Reasoning,"Large Language Models (LLMs) have achieved significant success in open-domain
question answering. However, they continue to face challenges such as
hallucinations and knowledge cutoffs. These issues can be mitigated through
in-context learning by providing LLMs with relevant context before generating
answers. Recent literature proposes Knowledge Graph Prompting (KGP) which
integrates knowledge graphs with an LLM-based traversal agent to substantially
enhance document retrieval quality. However, KGP requires costly fine-tuning
with large datasets and remains prone to hallucination. In this paper, we
propose CuriousLLM, an enhancement that integrates a curiosity-driven reasoning
mechanism into an LLM agent. This mechanism enables the agent to generate
relevant follow-up questions, thereby guiding the information retrieval process
more efficiently. Central to our approach is the development of the new
Follow-upQA dataset, which includes questions and supporting evidence as input,
with follow-up questions serving as ground truths. These follow-up questions
either inquire about what is still missing to fully answer the user's query or
use special tokens to signify that the retrieved evidence is sufficient. Our
experiments show that CuriousLLM significantly boosts LLM performance in
multi-document question answering (MD-QA), circumventing the substantial
computational costs and latency from the original KGP framework.",2024-04-13,"Zukang Yang, Zixuan Zhu, Xuan Zhu",http://arxiv.org/pdf/2404.09077v3,cs.CL
CodeCloak: A Method for Evaluating and Mitigating Code Leakage by LLM Code Assistants,"LLM-based code assistants are becoming increasingly popular among developers.
These tools help developers improve their coding efficiency and reduce errors
by providing real-time suggestions based on the developer's codebase. While
beneficial, the use of these tools can inadvertently expose the developer's
proprietary code to the code assistant service provider during the development
process. In this work, we propose a method to mitigate the risk of code leakage
when using LLM-based code assistants. CodeCloak is a novel deep reinforcement
learning agent that manipulates the prompts before sending them to the code
assistant service. CodeCloak aims to achieve the following two contradictory
goals: (i) minimizing code leakage, while (ii) preserving relevant and useful
suggestions for the developer. Our evaluation, employing StarCoder and Code
Llama, LLM-based code assistants models, demonstrates CodeCloak's effectiveness
on a diverse set of code repositories of varying sizes, as well as its
transferability across different models. We also designed a method for
reconstructing the developer's original codebase from code segments sent to the
code assistant service (i.e., prompts) during the development process, to
thoroughly analyze code leakage risks and evaluate the effectiveness of
CodeCloak under practical development scenarios.",2024-04-13,"Amit Finkman Noah, Avishag Shapira, Eden Bar Kochva, Inbar Maimon, Dudu Mimran, Yuval Elovici, Asaf Shabtai",http://arxiv.org/pdf/2404.09066v3,cs.CL
Multilingual Evaluation of Semantic Textual Relatedness,"The explosive growth of online content demands robust Natural Language
Processing (NLP) techniques that can capture nuanced meanings and cultural
context across diverse languages. Semantic Textual Relatedness (STR) goes
beyond superficial word overlap, considering linguistic elements and
non-linguistic factors like topic, sentiment, and perspective. Despite its
pivotal role, prior NLP research has predominantly focused on English, limiting
its applicability across languages. Addressing this gap, our paper dives into
capturing deeper connections between sentences beyond simple word overlap.
Going beyond English-centric NLP research, we explore STR in Marathi, Hindi,
Spanish, and English, unlocking the potential for information retrieval,
machine translation, and more. Leveraging the SemEval-2024 shared task, we
explore various language models across three learning paradigms: supervised,
unsupervised, and cross-lingual. Our comprehensive methodology gains promising
results, demonstrating the effectiveness of our approach. This work aims to not
only showcase our achievements but also inspire further research in
multilingual STR, particularly for low-resourced languages.",2024-04-13,"Sharvi Endait, Srushti Sonavane, Ridhima Sinare, Pritika Rohera, Advait Naik, Dipali Kadam",http://arxiv.org/pdf/2404.09047v1,cs.CL
Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model,"Timely identification is essential for the efficient handling of mental
health illnesses such as depression. However, the current research fails to
adequately address the prediction of mental health conditions from social media
data in low-resource African languages like Swahili. This study introduces two
distinct approaches utilising model-agnostic meta-learning and leveraging large
language models (LLMs) to address this gap. Experiments are conducted on three
datasets translated to low-resource language and applied to four mental health
tasks, which include stress, depression, depression severity and suicidal
ideation prediction. we first apply a meta-learning model with
self-supervision, which results in improved model initialisation for rapid
adaptation and cross-lingual transfer. The results show that our meta-trained
model performs significantly better than standard fine-tuning methods,
outperforming the baseline fine-tuning in macro F1 score with 18\% and 0.8\%
over XLM-R and mBERT. In parallel, we use LLMs' in-context learning
capabilities to assess their performance accuracy across the Swahili mental
health prediction tasks by analysing different cross-lingual prompting
approaches. Our analysis showed that Swahili prompts performed better than
cross-lingual prompts but less than English prompts. Our findings show that
in-context learning can be achieved through cross-lingual transfer through
carefully crafted prompt templates with examples and instructions.",2024-04-13,"Zita Lifelo, Huansheng Ning, Sahraoui Dhelim",http://arxiv.org/pdf/2404.09045v1,cs.CL
Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation,"With the rapid advancement of large language models (LLMs) for handling
complex language tasks, an increasing number of studies are employing LLMs as
agents to emulate the sequential decision-making processes of humans often
represented as Markov decision-making processes (MDPs). The actions in MDPs
adhere to specific probability distributions and require iterative sampling.
This arouses curiosity regarding the capacity of LLM agents to comprehend
probability distributions, thereby guiding the agent's behavioral
decision-making through probabilistic sampling and generating behavioral
sequences. To answer the above question, we divide the problem into two main
aspects: sequence simulation with known probability distribution and sequence
simulation with unknown probability distribution. Our analysis indicates that
LLM agents can understand probabilities, but they struggle with probability
sampling. Their ability to perform probabilistic sampling can be improved to
some extent by integrating coding tools, but this level of sampling precision
still makes it difficult to simulate human behavior as agents.",2024-04-13,"Jia Gu, Liang Pang, Huawei Shen, Xueqi Cheng",http://arxiv.org/pdf/2404.09043v3,cs.CL
MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts,"Large language models like ChatGPT have shown substantial progress in natural
language understanding and generation, proving valuable across various
disciplines, including the medical field. Despite advancements, challenges
persist due to the complexity and diversity inherent in medical tasks which
often require multi-task learning capabilities. Previous approaches, although
beneficial, fall short in real-world applications because they necessitate
task-specific annotations at inference time, limiting broader generalization.
This paper introduces MING-MOE, a novel Mixture-of-Expert~(MOE)-based medical
large language model designed to manage diverse and complex medical tasks
without requiring task-specific annotations, thus enhancing its usability
across extensive datasets. MING-MOE employs a Mixture of Low-Rank Adaptation
(MoLoRA) technique, allowing for efficient parameter usage by maintaining base
model parameters static while adapting through a minimal set of trainable
parameters. We demonstrate that MING-MOE achieves state-of-the-art (SOTA)
performance on over 20 medical tasks, illustrating a significant improvement
over existing models. This approach not only extends the capabilities of
medical language models but also improves inference efficiency.",2024-04-13,"Yusheng Liao, Shuyang Jiang, Yu Wang, Yanfeng Wang",http://arxiv.org/pdf/2404.09027v1,cs.CL
Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies,"With the surge of ChatGPT,the use of large models has significantly
increased,rapidly rising to prominence across the industry and sweeping across
the internet. This article is a comprehensive review of fine-tuning methods for
large models. This paper investigates the latest technological advancements and
the application of advanced methods in aspects such as task-adaptive
fine-tuning,domain-adaptive fine-tuning,few-shot learning,knowledge
distillation,multi-task learning,parameter-efficient fine-tuning,and dynamic
fine-tuning.",2024-04-13,Benjue Weng,http://arxiv.org/pdf/2404.09022v1,cs.CL
Towards Efficient Resume Understanding: A Multi-Granularity Multi-Modal Pre-Training Approach,"In the contemporary era of widespread online recruitment, resume
understanding has been widely acknowledged as a fundamental and crucial task,
which aims to extract structured information from resume documents
automatically. Compared to the traditional rule-based approaches, the
utilization of recently proposed pre-trained document understanding models can
greatly enhance the effectiveness of resume understanding. The present
approaches have, however, disregarded the hierarchical relations within the
structured information presented in resumes, and have difficulty parsing
resumes in an efficient manner. To this end, in this paper, we propose a novel
model, namely ERU, to achieve efficient resume understanding. Specifically, we
first introduce a layout-aware multi-modal fusion transformer for encoding the
segments in the resume with integrated textual, visual, and layout information.
Then, we design three self-supervised tasks to pre-train this module via a
large number of unlabeled resumes. Next, we fine-tune the model with a
multi-granularity sequence labeling task to extract structured information from
resumes. Finally, extensive experiments on a real-world dataset clearly
demonstrate the effectiveness of ERU.",2024-04-13,"Feihu Jiang, Chuan Qin, Jingshuai Zhang, Kaichun Yao, Xi Chen, Dazhong Shen, Chen Zhu, Hengshu Zhu, Hui Xiong",http://arxiv.org/pdf/2404.13067v1,cs.CL
WikiSplit++: Easy Data Refinement for Split and Rephrase,"The task of Split and Rephrase, which splits a complex sentence into multiple
simple sentences with the same meaning, improves readability and enhances the
performance of downstream tasks in natural language processing (NLP). However,
while Split and Rephrase can be improved using a text-to-text generation
approach that applies encoder-decoder models fine-tuned with a large-scale
dataset, it still suffers from hallucinations and under-splitting. To address
these issues, this paper presents a simple and strong data refinement approach.
Here, we create WikiSplit++ by removing instances in WikiSplit where complex
sentences do not entail at least one of the simpler sentences and reversing the
order of reference simple sentences. Experimental results show that training
with WikiSplit++ leads to better performance than training with WikiSplit, even
with fewer training instances. In particular, our approach yields significant
gains in the number of splits and the entailment ratio, a proxy for measuring
hallucinations.",2024-04-13,"Hayato Tsukagoshi, Tsutomu Hirao, Makoto Morishita, Katsuki Chousa, Ryohei Sasano, Koichi Takeda",http://arxiv.org/pdf/2404.09002v1,cs.CL
Labeled Morphological Segmentation with Semi-Markov Models,"We present labeled morphological segmentation, an alternative view of
morphological processing that unifies several tasks. From an annotation
standpoint, we additionally introduce a new hierarchy of morphotactic tagsets.
Finally, we develop \modelname, a discriminative morphological segmentation
system that, contrary to previous work, explicitly models morphotactics. We
show that \textsc{chipmunk} yields improved performance on three tasks for all
six languages: (i) morphological segmentation, (ii) stemming and (iii)
morphological tag classification. On morphological segmentation, our method
shows absolute improvements of 2--6 points $F_1$ over the baseline.",2024-04-13,"Ryan Cotterell, Thomas Müller, Alexander Fraser, Hinrich Schütze",http://arxiv.org/pdf/2404.08997v1,cs.CL
RoNID: New Intent Discovery with Generated-Reliable Labels and Cluster-friendly Representations,"New Intent Discovery (NID) strives to identify known and reasonably deduce
novel intent groups in the open-world scenario. But current methods face issues
with inaccurate pseudo-labels and poor representation learning, creating a
negative feedback loop that degrades overall model performance, including
accuracy and the adjusted rand index. To address the aforementioned challenges,
we propose a Robust New Intent Discovery (RoNID) framework optimized by an
EM-style method, which focuses on constructing reliable pseudo-labels and
obtaining cluster-friendly discriminative representations. RoNID comprises two
main modules: reliable pseudo-label generation module and cluster-friendly
representation learning module. Specifically, the pseudo-label generation
module assigns reliable synthetic labels by solving an optimal transport
problem in the E-step, which effectively provides high-quality supervised
signals for the input of the cluster-friendly representation learning module.
To learn cluster-friendly representation with strong intra-cluster compactness
and large inter-cluster separation, the representation learning module combines
intra-cluster and inter-cluster contrastive learning in the M-step to feed more
discriminative features into the generation module. RoNID can be performed
iteratively to ultimately yield a robust model with reliable pseudo-labels and
cluster-friendly representations. Experimental results on multiple benchmarks
demonstrate our method brings substantial improvements over previous
state-of-the-art methods by a large margin of +1~+4 points.",2024-04-13,"Shun Zhang, Chaoran Yan, Jian Yang, Changyu Ren, Jiaqi Bai, Tongliang Li, Zhoujun Li",http://arxiv.org/pdf/2404.08977v2,cs.CL
OOVs in the Spotlight: How to Inflect them?,"We focus on morphological inflection in out-of-vocabulary (OOV) conditions,
an under-researched subtask in which state-of-the-art systems usually are less
effective. We developed three systems: a retrograde model and two
sequence-to-sequence (seq2seq) models based on LSTM and Transformer. For
testing in OOV conditions, we automatically extracted a large dataset of nouns
in the morphologically rich Czech language, with lemma-disjoint data splits,
and we further manually annotated a real-world OOV dataset of neologisms. In
the standard OOV conditions, Transformer achieves the best results, with
increasing performance in ensemble with LSTM, the retrograde model and
SIGMORPHON baselines. On the real-world OOV dataset of neologisms, the
retrograde model outperforms all neural models. Finally, our seq2seq models
achieve state-of-the-art results in 9 out of 16 languages from SIGMORPHON 2022
shared task data in the OOV evaluation (feature overlap) in the large data
condition. We release the Czech OOV Inflection Dataset for rigorous evaluation
in OOV conditions. Further, we release the inflection system with the seq2seq
models as a ready-to-use Python library.",2024-04-13,"Tomáš Sourada, Jana Straková, Rudolf Rosa",http://arxiv.org/pdf/2404.08974v2,cs.CL
AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning,"Recently, pre-trained vision-language models (e.g., CLIP) have shown great
potential in few-shot learning and attracted a lot of research interest.
Although efforts have been made to improve few-shot ability of CLIP, key
factors on the effectiveness of existing methods have not been well studied,
limiting further exploration of CLIP's potential in few-shot learning. In this
paper, we first introduce a unified formulation to analyze CLIP-based few-shot
learning methods from a perspective of logit bias, which encourages us to learn
an effective logit bias for further improving performance of CLIP-based
few-shot learning methods. To this end, we disassemble three key components
involved in computation of logit bias (i.e., logit features, logit predictor,
and logit fusion) and empirically analyze the effect on performance of few-shot
classification. Based on analysis of key components, this paper proposes a
novel AMU-Tuning method to learn effective logit bias for CLIP-based few-shot
classification. Specifically, our AMU-Tuning predicts logit bias by exploiting
the appropriate $\underline{\textbf{A}}$uxiliary features, which are fed into
an efficient feature-initialized linear classifier with
$\underline{\textbf{M}}$ulti-branch training. Finally, an
$\underline{\textbf{U}}$ncertainty-based fusion is developed to incorporate
logit bias into CLIP for few-shot classification. The experiments are conducted
on several widely used benchmarks, and the results show AMU-Tuning clearly
outperforms its counterparts while achieving state-of-the-art performance of
CLIP-based few-shot learning without bells and whistles.",2024-04-13,"Yuwei Tang, Zhenyi Lin, Qilong Wang, Pengfei Zhu, Qinghua Hu",http://arxiv.org/pdf/2404.08958v1,cs.CL
Multimodal Cross-Document Event Coreference Resolution Using Linear Semantic Transfer and Mixed-Modality Ensembles,"Event coreference resolution (ECR) is the task of determining whether
distinct mentions of events within a multi-document corpus are actually linked
to the same underlying occurrence. Images of the events can help facilitate
resolution when language is ambiguous. Here, we propose a multimodal
cross-document event coreference resolution method that integrates visual and
textual cues with a simple linear map between vision and language models. As
existing ECR benchmark datasets rarely provide images for all event mentions,
we augment the popular ECB+ dataset with event-centric images scraped from the
internet and generated using image diffusion models. We establish three methods
that incorporate images and text for coreference: 1) a standard fused model
with finetuning, 2) a novel linear mapping method without finetuning and 3) an
ensembling approach based on splitting mention pairs by semantic and
discourse-level difficulty. We evaluate on 2 datasets: the augmented ECB+, and
AIDA Phase 1. Our ensemble systems using cross-modal linear mapping establish
an upper limit (91.9 CoNLL F1) on ECB+ ECR performance given the preprocessing
assumptions used, and establish a novel baseline on AIDA Phase 1. Our results
demonstrate the utility of multimodal information in ECR for certain
challenging coreference problems, and highlight a need for more multimodal
resources in the coreference resolution space.",2024-04-13,"Abhijnan Nath, Huma Jamil, Shafiuddin Rehan Ahmed, George Baker, Rahul Ghosh, James H. Martin, Nathaniel Blanchard, Nikhil Krishnaswamy",http://arxiv.org/pdf/2404.08949v1,cs.CL
Introducing Super RAGs in Mistral 8x7B-v1,"The relentless pursuit of enhancing Large Language Models (LLMs) has led to
the advent of Super Retrieval-Augmented Generation (Super RAGs), a novel
approach designed to elevate the performance of LLMs by integrating external
knowledge sources with minimal structural modifications. This paper presents
the integration of Super RAGs into the Mistral 8x7B v1, a state-of-the-art LLM,
and examines the resultant improvements in accuracy, speed, and user
satisfaction. Our methodology uses a fine-tuned instruct model setup and a
cache tuning fork system, ensuring efficient and relevant data retrieval. The
evaluation, conducted over several epochs, demonstrates significant
enhancements across all metrics. The findings suggest that Super RAGs can
effectively augment LLMs, paving the way for more sophisticated and reliable AI
systems. This research contributes to the field by providing empirical evidence
of the benefits of Super RAGs and offering insights into their potential
applications.",2024-04-13,"Ayush Thakur, Raghav Gupta",http://arxiv.org/pdf/2404.08940v1,cs.CL
Improved Paraphrase Generation via Controllable Latent Diffusion,"Paraphrase generation strives to generate high-quality and diverse
expressions of a given text, a domain where diffusion models excel. Though SOTA
diffusion generation reconciles generation quality and diversity, textual
diffusion suffers from a truncation issue that hinders efficiency and quality
control. In this work, we propose \textit{L}atent \textit{D}iffusion
\textit{P}araphraser~(LDP), a novel paraphrase generation by modeling a
controllable diffusion process given a learned latent space. LDP achieves
superior generation efficiency compared to its diffusion counterparts. It can
facilitate only input segments to ensure paraphrase semantics, improving the
results without external features. Experiments show that LDP better reconciles
paraphrase generation quality and diversity than baselines. Further analysis
shows that our method is also helpful to other similar text generations and
domain adaptations",2024-04-13,"Wei Zou, Ziyuan Zhuang, Xiang Geng, Shujian Huang, Jia Liu, Jiajun Chen",http://arxiv.org/pdf/2404.08938v2,cs.CL
Leveraging Large Language Model as Simulated Patients for Clinical Education,"Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.",2024-04-13,"Yanzeng Li, Cheng Zeng, Jialun Zhong, Ruoyu Zhang, Minhao Zhang, Lei Zou",http://arxiv.org/pdf/2404.13066v2,cs.CL
Intellecta Cognitiva: A Comprehensive Dataset for Advancing Academic Knowledge and Machine Reasoning,"Intellecta dataset emerges as an innovative synthetic dataset, engineered to
enhance the cognitive processing capabilities of contemporary language models.
With a composition of 11.53 billion tokens, integrating 8.01 billion tokens of
synthetic data with 3.52 billion tokens of rich textbook data, Intellecta is
crafted to foster advanced reasoning and comprehensive educational narrative
generation. Leveraging the Mixtral-8x7B-Instruct-v0.1 model, the dataset
facilitates the generation of complex thought processes and detailed,
textbook-style explanations, thus enabling language models to engage in both
critical thinking and profound educational discourse. This hybrid dataset
stands as a testament to the potential of synthetic data in pushing the
boundaries of AI, offering a repository that is not only vast and varied but
also refined to align with ethical standards and intellectual rigor.",2024-04-13,"Ajmal PS, Ditto PS, Jithin VG",http://arxiv.org/pdf/2404.13065v1,cs.CL
Towards Enhancing Health Coaching Dialogue in Low-Resource Settings,"Health coaching helps patients identify and accomplish lifestyle-related
goals, effectively improving the control of chronic diseases and mitigating
mental health conditions. However, health coaching is cost-prohibitive due to
its highly personalized and labor-intensive nature. In this paper, we propose
to build a dialogue system that converses with the patients, helps them create
and accomplish specific goals, and can address their emotions with empathy.
However, building such a system is challenging since real-world health coaching
datasets are limited and empathy is subtle. Thus, we propose a modularized
health coaching dialogue system with simplified NLU and NLG frameworks combined
with mechanism-conditioned empathetic response generation. Through automatic
and human evaluation, we show that our system generates more empathetic,
fluent, and coherent responses and outperforms the state-of-the-art in NLU
tasks while requiring less annotation. We view our approach as a key step
towards building automated and more accessible health coaching systems.",2024-04-13,"Yue Zhou, Barbara Di Eugenio, Brian Ziebart, Lisa Sharp, Bing Liu, Ben Gerber, Nikolaos Agadakos, Shweta Yadav",http://arxiv.org/pdf/2404.08888v1,cs.CL
EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM,"In e-commerce, accurately extracting product attribute values from multimodal
data is crucial for improving user experience and operational efficiency of
retailers. However, previous approaches to multimodal attribute value
extraction often struggle with implicit attribute values embedded in images or
text, rely heavily on extensive labeled data, and can easily confuse similar
attribute values. To address these issues, we introduce EIVEN, a data- and
parameter-efficient generative framework that pioneers the use of multimodal
LLM for implicit attribute value extraction. EIVEN leverages the rich inherent
knowledge of a pre-trained LLM and vision encoder to reduce reliance on labeled
data. We also introduce a novel Learning-by-Comparison technique to reduce
model confusion by enforcing attribute value comparison and difference
identification. Additionally, we construct initial open-source datasets for
multimodal implicit attribute value extraction. Our extensive experiments
reveal that EIVEN significantly outperforms existing methods in extracting
implicit attribute values while requiring less labeled data.",2024-04-13,"Henry Peng Zou, Gavin Heqing Yu, Ziwei Fan, Dan Bu, Han Liu, Peng Dai, Dongmei Jia, Cornelia Caragea",http://arxiv.org/pdf/2404.08886v1,cs.CL
Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension,"Large language models (LLMs) has experienced exponential growth, they
demonstrate remarkable performance across various tasks. Notwithstanding,
contemporary research primarily centers on enhancing the size and quality of
pretraining data, still utilizing the next token prediction task on
autoregressive transformer model structure. The efficacy of this task in truly
facilitating the model's comprehension of code logic remains questionable, we
speculate that it still interprets code as mere text, while human emphasizes
the underlying logical knowledge. In order to prove it, we introduce a new
task, ""Logically Equivalent Code Selection,"" which necessitates the selection
of logically equivalent code from a candidate set, given a query code. Our
experimental findings indicate that current LLMs underperform in this task,
since they understand code by unordered bag of keywords. To ameliorate their
performance, we propose an advanced pretraining task, ""Next Token Prediction+"".
This task aims to modify the sentence embedding distribution of the LLM without
sacrificing its generative capabilities. Our experimental results reveal that
following this pretraining, both Code Llama and StarCoder, the prevalent code
domain pretraining models, display significant improvements on our logically
equivalent code selection task and the code completion task.",2024-04-13,"Mengnan Qi, Yufan Huang, Yongqiang Yao, Maoquan Wang, Bin Gu, Neel Sundaresan",http://arxiv.org/pdf/2404.08885v1,cs.CL
Aligning the Objective of LLM-based Program Repair,"Large language models (LLMs) have achieved decent results on automated
program repair (APR). However, the next token prediction training objective of
decoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction
objective of current infilling-style methods, which impedes LLMs from fully
leveraging pre-trained knowledge for program repair. In addition, while some
LLMs can locate and repair bugs in certain functions using the related
artifacts (e.g., test cases), existing methods still depend on statement-level
fault localization methods to provide a list of buggy hunks for repair. This
restriction hinders LLMs from exploring potential patches beyond the given
locations.
  In this paper, we investigate a new approach to adapt LLMs to program repair.
Our core insight is that LLM's APR capability can be greatly improved by simply
aligning the output to their training objective and allowing them to refine the
whole program without first identifying faulty statements. Based on this
insight, we designed D4C, a straightforward prompting framework for APR. D4C
can repair 180 bugs correctly in Defects4J, with each patch being sampled only
10 times. This surpasses the SOTA APR methods with perfect fault localization
by 10% and reduces the patch sampling number by 90%. Our findings reveal that
(1) objective alignment is crucial for fully exploiting LLM's pre-trained
capability, and (2) replacing the traditional localize-buggy-hunks-then-repair
workflow with direct debugging is more effective for LLM-based APR methods.
Thus, we believe this paper introduces a new mindset for harnessing LLMs in
APR.",2024-04-13,"Junjielong Xu, Ying Fu, Shin Hwei Tan, Pinjia He",http://arxiv.org/pdf/2404.08877v5,cs.CL
LLM In-Context Recall is Prompt Dependent,"The proliferation of Large Language Models (LLMs) highlights the critical
importance of conducting thorough evaluations to discern their comparative
advantages, limitations, and optimal use cases. Particularly important is
assessing their capacity to accurately retrieve information included in a given
prompt. A model's ability to do this significantly influences how effectively
it can utilize contextual details, thus impacting its practical efficacy and
dependability in real-world applications.
  Our research analyzes the in-context recall performance of various LLMs using
the needle-in-a-haystack method. In this approach, a factoid (the ""needle"") is
embedded within a block of filler text (the ""haystack""), which the model is
asked to retrieve. We assess the recall performance of each model across
various haystack lengths and with varying needle placements to identify
performance patterns. This study demonstrates that an LLM's recall capability
is not only contingent upon the prompt's content but also may be compromised by
biases in its training data. Conversely, adjustments to model architecture,
training strategy, or fine-tuning can improve performance. Our analysis
provides insight into LLM behavior, offering direction for the development of
more effective applications of LLMs.",2024-04-13,"Daniel Machlab, Rick Battle",http://arxiv.org/pdf/2404.08865v1,cs.CL
On Speculative Decoding for Multimodal Large Language Models,"Inference with Multimodal Large Language Models (MLLMs) is slow due to their
large-language-model backbone which suffers from memory bandwidth bottleneck
and generates tokens auto-regressively. In this paper, we explore the
application of speculative decoding to enhance the inference efficiency of
MLLMs, specifically the LLaVA 7B model. We show that a language-only model can
serve as a good draft model for speculative decoding with LLaVA 7B, bypassing
the need for image tokens and their associated processing components from the
draft model. Our experiments across three different tasks show that speculative
decoding can achieve a memory-bound speedup of up to 2.37$\times$ using a 115M
parameter language model that we trained from scratch. Additionally, we
introduce a compact LLaVA draft model incorporating an image adapter, which
shows marginal performance gains in image captioning while maintaining
comparable results in other tasks.",2024-04-13,"Mukul Gagrani, Raghavv Goel, Wonseok Jeon, Junyoung Park, Mingu Lee, Christopher Lott",http://arxiv.org/pdf/2404.08856v1,cs.CL
Experimental Design for Active Transductive Inference in Large Language Models,"One emergent ability of large language models (LLMs) is that query-specific
examples can be included in the prompt at inference time. In this work, we use
active learning for adaptive prompt design and call it Active In-context Prompt
Design (AIPD). We design the LLM prompt by adaptively choosing few-shot
examples from a training set to optimize performance on a test set. The
training examples are initially unlabeled and we obtain the label of the most
informative ones, which maximally reduces uncertainty in the LLM prediction. We
propose two algorithms, GO and SAL, which differ in how the few-shot examples
are chosen. We analyze these algorithms in linear models: first GO and then use
its equivalence with SAL. We experiment with many different tasks in small,
medium-sized, and large language models; and show that GO and SAL outperform
other methods for choosing few-shot examples in the LLM prompt at inference
time.",2024-04-12,"Subhojyoti Mukherjee, Anusha Lalitha, Aniket Deshmukh, Ge Liu, Yifei Ma, Branislav Kveton",http://arxiv.org/pdf/2404.08846v2,cs.CL
BERT-LSH: Reducing Absolute Compute For Attention,"This study introduces a novel BERT-LSH model that incorporates Locality
Sensitive Hashing (LSH) to approximate the attention mechanism in the BERT
architecture. We examine the computational efficiency and performance of this
model compared to a standard baseline BERT model. Our findings reveal that
BERT-LSH significantly reduces computational demand for the self-attention
layer while unexpectedly outperforming the baseline model in pretraining and
fine-tuning tasks. These results suggest that the LSH-based attention mechanism
not only offers computational advantages but also may enhance the model's
ability to generalize from its training data. For more information, visit our
GitHub repository: https://github.com/leo4life2/algoml-final",2024-04-12,"Zezheng Li, Kingston Yip",http://arxiv.org/pdf/2404.08836v1,cs.CL
Constrained C-Test Generation via Mixed-Integer Programming,"This work proposes a novel method to generate C-Tests; a deviated form of
cloze tests (a gap filling exercise) where only the last part of a word is
turned into a gap. In contrast to previous works that only consider varying the
gap size or gap placement to achieve locally optimal solutions, we propose a
mixed-integer programming (MIP) approach. This allows us to consider gap size
and placement simultaneously, achieving globally optimal solutions, and to
directly integrate state-of-the-art models for gap difficulty prediction into
the optimization problem. A user study with 40 participants across four C-Test
generation strategies (including GPT-4) shows that our approach (MIP)
significantly outperforms two of the baseline strategies (based on gap
placement and GPT-4); and performs on-par with the third (based on gap size).
Our analysis shows that GPT-4 still struggles to fulfill explicit constraints
during generation and that MIP produces C-Tests that correlate best with the
perceived difficulty. We publish our code, model, and collected data consisting
of 32 English C-Tests with 20 gaps each (totaling 3,200 individual gap
responses) under an open source license.",2024-04-12,"Ji-Ung Lee, Marc E. Pfetsch, Iryna Gurevych",http://arxiv.org/pdf/2404.08821v1,cs.CL
The Illusion of State in State-Space Models,"State-space models (SSMs) have emerged as a potential alternative
architecture for building large language models (LLMs) compared to the
previously ubiquitous transformer architecture. One theoretical weakness of
transformers is that they cannot express certain kinds of sequential
computation and state tracking (Merrill & Sabharwal, 2023), which SSMs are
explicitly designed to address via their close architectural similarity to
recurrent neural networks (RNNs). But do SSMs truly have an advantage (over
transformers) in expressive power for state tracking? Surprisingly, the answer
is no. Our analysis reveals that the expressive power of SSMs is limited very
similarly to transformers: SSMs cannot express computation outside the
complexity class $\mathsf{TC}^0$. In particular, this means they cannot solve
simple state-tracking problems like permutation composition. It follows that
SSMs are provably unable to accurately track chess moves with certain notation,
evaluate code, or track entities in a long narrative. To supplement our formal
analysis, we report experiments showing that Mamba-style SSMs indeed struggle
with state tracking. Thus, despite its recurrent formulation, the ""state"" in an
SSM is an illusion: SSMs have similar expressiveness limitations to
non-recurrent models like transformers, which may fundamentally limit their
ability to solve real-world state-tracking problems.",2024-04-12,"William Merrill, Jackson Petty, Ashish Sabharwal",http://arxiv.org/pdf/2404.08819v3,cs.CL
Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance,"This paper revisits recent code similarity evaluation metrics, particularly
focusing on the application of Abstract Syntax Tree (AST) editing distance in
diverse programming languages. In particular, we explore the usefulness of
these metrics and compare them to traditional sequence similarity metrics. Our
experiments showcase the effectiveness of AST editing distance in capturing
intricate code structures, revealing a high correlation with established
metrics. Furthermore, we explore the strengths and weaknesses of AST editing
distance and prompt-based GPT similarity scores in comparison to BLEU score,
execution match, and Jaccard Similarity. We propose, optimize, and publish an
adaptable metric that demonstrates effectiveness across all tested languages,
representing an enhanced version of Tree Similarity of Edit Distance (TSED).",2024-04-12,"Yewei Song, Cedric Lothritz, Daniel Tang, Tegawendé F. Bissyandé, Jacques Klein",http://arxiv.org/pdf/2404.08817v2,cs.CL
Measuring the Quality of Answers in Political Q&As with Large Language Models,"This article proposes a new approach for assessing the quality of answers in
political question-and-answer sessions. We measure the quality of an answer
based on how easily and accurately it can be recognized in a random set of
candidate answers given the question's text. This measure reflects the answer's
relevance and depth of engagement with the question. Like semantic search, we
can implement this approach by training a language model on the corpus of
observed questions and answers without additional human-labeled data. We
showcase and validate our methodology within the context of the Question Period
in the Canadian House of Commons. Our analysis reveals that while some answers
have a weak semantic connection to questions, hinting at some evasion or
obfuscation, they are generally at least moderately relevant, far exceeding
what we would expect from random replies. We also find a meaningful correlation
between answer quality and the party affiliation of the members of Parliament
asking the questions.",2024-04-12,"R. Michael Alvarez, Jacob Morrier",http://arxiv.org/pdf/2404.08816v5,cs.CL
CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation,"Large Language Models (LLMs) have proved effective and efficient in
generating code, leading to their utilization within the hardware design
process. Prior works evaluating LLMs' abilities for register transfer level
code generation solely focus on functional correctness. However, the creativity
associated with these LLMs, or the ability to generate novel and unique
solutions, is a metric not as well understood, in part due to the challenge of
quantifying this quality.
  To address this research gap, we present CreativeEval, a framework for
evaluating the creativity of LLMs within the context of generating hardware
designs. We quantify four creative sub-components, fluency, flexibility,
originality, and elaboration, through various prompting and post-processing
techniques. We then evaluate multiple popular LLMs (including GPT models,
CodeLlama, and VeriGen) upon this creativity metric, with results indicating
GPT-3.5 as the most creative model in generating hardware designs.",2024-04-12,"Matthew DeLorenzo, Vasudev Gohil, Jeyavijayan Rajendran",http://arxiv.org/pdf/2404.08806v1,cs.CL
Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length,"The quadratic complexity and weak length extrapolation of Transformers limits
their ability to scale to long sequences, and while sub-quadratic solutions
like linear attention and state space models exist, they empirically
underperform Transformers in pretraining efficiency and downstream task
accuracy. We introduce Megalodon, a neural architecture for efficient sequence
modeling with unlimited context length. Megalodon inherits the architecture of
Mega (exponential moving average with gated attention), and further introduces
multiple technical components to improve its capability and stability,
including complex exponential moving average (CEMA), timestep normalization
layer, normalized attention mechanism and pre-norm with two-hop residual
configuration. In a controlled head-to-head comparison with Llama2, Megalodon
achieves better efficiency than Transformer in the scale of 7 billion
parameters and 2 trillion training tokens. Megalodon reaches a training loss of
1.70, landing mid-way between Llama2-7B (1.75) and 13B (1.67). Code:
https://github.com/XuezheMax/megalodon",2024-04-12,"Xuezhe Ma, Xiaomeng Yang, Wenhan Xiong, Beidi Chen, Lili Yu, Hao Zhang, Jonathan May, Luke Zettlemoyer, Omer Levy, Chunting Zhou",http://arxiv.org/pdf/2404.08801v2,cs.CL
JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models,"The proliferation of large language models (LLMs) has underscored concerns
regarding their security vulnerabilities, notably against jailbreak attacks,
where adversaries design jailbreak prompts to circumvent safety mechanisms for
potential misuse. Addressing these concerns necessitates a comprehensive
analysis of jailbreak prompts to evaluate LLMs' defensive capabilities and
identify potential weaknesses. However, the complexity of evaluating jailbreak
performance and understanding prompt characteristics makes this analysis
laborious. We collaborate with domain experts to characterize problems and
propose an LLM-assisted framework to streamline the analysis process. It
provides automatic jailbreak assessment to facilitate performance evaluation
and support analysis of components and keywords in prompts. Based on the
framework, we design JailbreakLens, a visual analysis system that enables users
to explore the jailbreak performance against the target model, conduct
multi-level analysis of prompt characteristics, and refine prompt instances to
verify findings. Through a case study, technical evaluations, and expert
interviews, we demonstrate our system's effectiveness in helping users evaluate
model security and identify model weaknesses.",2024-04-12,"Yingchaojie Feng, Zhizhang Chen, Zhining Kang, Sijia Wang, Minfeng Zhu, Wei Zhang, Wei Chen",http://arxiv.org/pdf/2404.08793v1,cs.CL
CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models,"Large Language Models (LLMs) have dramatically advanced AI applications, yet
their deployment remains challenging due to their immense inference costs.
Recent studies ameliorate the computational costs of LLMs by increasing their
activation sparsity but suffer from significant performance degradation on
downstream tasks. In this work, we introduce a new framework for sparsifying
the activations of base LLMs and reducing inference costs, dubbed Contextually
Aware Thresholding for Sparsity (CATS). CATS is relatively simple, easy to
implement, and highly effective. At the heart of our framework is a new
non-linear activation function. We demonstrate that CATS can be applied to
various base models, including Mistral-7B and Llama2-7B, and outperforms
existing sparsification techniques in downstream task performance. More
precisely, CATS-based models often achieve downstream task performance within
1-2% of their base models without any fine-tuning and even at activation
sparsity levels of 50%. Furthermore, CATS-based models converge faster and
display better task performance than competing techniques when fine-tuning is
applied. Finally, we develop a custom GPU kernel for efficient implementation
of CATS that translates the activation of sparsity of CATS to real wall-clock
time speedups. Our custom kernel implementation of CATS results in a ~15%
improvement in wall-clock inference latency of token generation on both
Llama-7B and Mistral-7B.",2024-04-12,"Donghyun Lee, Je-Yong Lee, Genghan Zhang, Mo Tiwari, Azalia Mirhoseini",http://arxiv.org/pdf/2404.08763v4,cs.CL
The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models,"We explore the alignment of values in Large Language Models (LLMs) with
specific age groups, leveraging data from the World Value Survey across
thirteen categories. Through a diverse set of prompts tailored to ensure
response robustness, we find a general inclination of LLM values towards
younger demographics, especially when compared to the US population. Although a
general inclination can be observed, we also found that this inclination toward
younger groups can be different across different value categories.
Additionally, we explore the impact of incorporating age identity information
in prompts and observe challenges in mitigating value discrepancies with
different age cohorts. Our findings highlight the age bias in LLMs and provide
insights for future work. Materials for our analysis are available at \url{
https://github.com/MichiganNLP/Age-Bias-In-LLMs}",2024-04-12,"Siyang Liu, Trish Maturi, Bowen Yi, Siqi Shen, Rada Mihalcea",http://arxiv.org/pdf/2404.08760v4,cs.CL
Inheritune: Training Smaller Yet More Attentive Language Models,"Large Language Models (LLMs) have achieved remarkable performance across
various natural language processing tasks, primarily due to the transformer
architecture and its self-attention mechanism. However, we observe that in
standard decoder-style LLMs, attention matrices degenerate to single-column for
deeper layers. Layers in this state are unable to learn anything meaningful and
mostly redundant; we refer to these as lazy layers. The goal of this paper is
to train smaller models by eliminating this structural inefficiency without
compromising performance.
  Motivated by this observation, we propose Inheritune, a simple yet effective
training recipe for developing smaller, high-performing language models.
Smaller models trained with Inheritune, inherit early transformer layers from a
larger pre-trained model, then retrain and progressively expand until they
match or exceed the performance of the larger model. We demonstrate that
Inheritune enables the training of various sizes of GPT-2 models on datasets
like OpenWebText-9B and FineWeb_edu. Models trained with Inheritune, despite
having significantly fewer layers, match or even surpass the performance of
their larger counterparts. For instance, our 16-layer GPT-2 medium variant
achieves comparable performance to the standard 24-layer GPT-2 medium model.
Code is available at https://github.com/sanyalsunny111/LLM-Inheritune.",2024-04-12,"Sunny Sanyal, Ravid Shwartz-Ziv, Alexandros G. Dimakis, Sujay Sanghavi",http://arxiv.org/pdf/2404.08634v2,cs.CL
Is ChatGPT Transforming Academics' Writing Style?,"Based on one million arXiv papers submitted from May 2018 to January 2024, we
assess the textual density of ChatGPT's writing style in their abstracts
through a statistical analysis of word frequency changes. Our model is
calibrated and validated on a mixture of real abstracts and ChatGPT-modified
abstracts (simulated data) after a careful noise analysis. The words used for
estimation are not fixed but adaptive, including those with decreasing
frequency. We find that large language models (LLMs), represented by ChatGPT,
are having an increasing impact on arXiv abstracts, especially in the field of
computer science, where the fraction of LLM-style abstracts is estimated to be
approximately 35%, if we take the responses of GPT-3.5 to one simple prompt,
""revise the following sentences"", as a baseline. We conclude with an analysis
of both positive and negative aspects of the penetration of LLMs into
academics' writing style.",2024-04-12,"Mingmeng Geng, Roberto Trotta",http://arxiv.org/pdf/2404.08627v2,cs.CL
Synthetic Dataset Creation and Fine-Tuning of Transformer Models for Question Answering in Serbian,"In this paper, we focus on generating a synthetic question answering (QA)
dataset using an adapted Translate-Align-Retrieve method. Using this method, we
created the largest Serbian QA dataset of more than 87K samples, which we name
SQuAD-sr. To acknowledge the script duality in Serbian, we generated both
Cyrillic and Latin versions of the dataset. We investigate the dataset quality
and use it to fine-tune several pre-trained QA models. Best results were
obtained by fine-tuning the BERTi\'c model on our Latin SQuAD-sr dataset,
achieving 73.91% Exact Match and 82.97% F1 score on the benchmark XQuAD
dataset, which we translated into Serbian for the purpose of evaluation. The
results show that our model exceeds zero-shot baselines, but fails to go beyond
human performance. We note the advantage of using a monolingual pre-trained
model over multilingual, as well as the performance increase gained by using
Latin over Cyrillic. By performing additional analysis, we show that questions
about numeric values or dates are more likely to be answered correctly than
other types of questions. Finally, we conclude that SQuAD-sr is of sufficient
quality for fine-tuning a Serbian QA model, in the absence of a manually
crafted and annotated dataset.",2024-04-12,"Aleksa Cvetanović, Predrag Tadić",http://arxiv.org/pdf/2404.08617v1,cs.CL
Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases,"Large Language Models (LLMs) can automate or substitute different types of
tasks in the software engineering process. This study evaluates the resource
utilization and accuracy of LLM in interpreting and executing natural language
queries against traditional SQL within relational database management systems.
We empirically examine the resource utilization and accuracy of nine LLMs
varying from 7 to 34 Billion parameters, including Llama2 7B, Llama2 13B,
Mistral, Mixtral, Optimus-7B, SUS-chat-34B, platypus-yi-34b,
NeuralHermes-2.5-Mistral-7B and Starling-LM-7B-alpha, using a small transaction
dataset. Our findings indicate that using LLMs for database queries incurs
significant energy overhead (even small and quantized models), making it an
environmentally unfriendly approach. Therefore, we advise against replacing
relational databases with LLMs due to their substantial resource utilization.",2024-04-12,"Xiang Zhang, Khatoon Khedri, Reza Rawassizadeh",http://arxiv.org/pdf/2404.08727v1,cs.CL
Small Models Are (Still) Effective Cross-Domain Argument Extractors,"Effective ontology transfer has been a major goal of recent work on event
argument extraction (EAE). Two methods in particular -- question answering (QA)
and template infilling (TI) -- have emerged as promising approaches to this
problem. However, detailed explorations of these techniques' ability to
actually enable this transfer are lacking. In this work, we provide such a
study, exploring zero-shot transfer using both techniques on six major EAE
datasets at both the sentence and document levels. Further, we challenge the
growing reliance on LLMs for zero-shot extraction, showing that vastly smaller
models trained on an appropriate source ontology can yield zero-shot
performance superior to that of GPT-3.5 or GPT-4.",2024-04-12,"William Gantt, Aaron Steven White",http://arxiv.org/pdf/2404.08579v1,cs.CL
MoPE: Mixture of Prefix Experts for Zero-Shot Dialogue State Tracking,"Zero-shot dialogue state tracking (DST) transfers knowledge to unseen
domains, reducing the cost of annotating new datasets. Previous zero-shot DST
models mainly suffer from domain transferring and partial prediction problems.
To address these challenges, we propose Mixture of Prefix Experts (MoPE) to
establish connections between similar slots in different domains, which
strengthens the model transfer performance in unseen domains. Empirical results
demonstrate that MoPE-DST achieves the joint goal accuracy of 57.13% on
MultiWOZ2.1 and 55.40% on SGD.",2024-04-12,"Tianwen Tang, Tong Zhu, Haodong Liu, Yin Bai, Jia Cheng, Wenliang Chen",http://arxiv.org/pdf/2404.08559v1,cs.CL
RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs,"State-of-the-art large language models (LLMs) have become indispensable tools
for various tasks. However, training LLMs to serve as effective assistants for
humans requires careful consideration. A promising approach is reinforcement
learning from human feedback (RLHF), which leverages human feedback to update
the model in accordance with human preferences and mitigate issues like
toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely
entangled with initial design choices that popularized the method and current
research focuses on augmenting those choices rather than fundamentally
improving the framework. In this paper, we analyze RLHF through the lens of
reinforcement learning principles to develop an understanding of its
fundamentals, dedicating substantial focus to the core component of RLHF -- the
reward model. Our study investigates modeling choices, caveats of function
approximation, and their implications on RLHF training algorithms, highlighting
the underlying assumptions made about the expressivity of reward. Our analysis
improves the understanding of the role of reward models and methods for their
training, concurrently revealing limitations of the current methodology. We
characterize these limitations, including incorrect generalization, model
misspecification, and the sparsity of feedback, along with their impact on the
performance of a language model. The discussion and analysis are substantiated
by a categorical review of current literature, serving as a reference for
researchers and practitioners to understand the challenges of RLHF and build
upon existing efforts.",2024-04-12,"Shreyas Chaudhari, Pranjal Aggarwal, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan, Ameet Deshpande, Bruno Castro da Silva",http://arxiv.org/pdf/2404.08555v2,cs.CL
VertAttack: Taking advantage of Text Classifiers' horizontal vision,"Text classification systems have continuously improved in performance over
the years. However, nearly all current SOTA classifiers have a similar
shortcoming, they process text in a horizontal manner. Vertically written words
will not be recognized by a classifier. In contrast, humans are easily able to
recognize and read words written both horizontally and vertically. Hence, a
human adversary could write problematic words vertically and the meaning would
still be preserved to other humans. We simulate such an attack, VertAttack.
VertAttack identifies which words a classifier is reliant on and then rewrites
those words vertically. We find that VertAttack is able to greatly drop the
accuracy of 4 different transformer models on 5 datasets. For example, on the
SST2 dataset, VertAttack is able to drop RoBERTa's accuracy from 94 to 13%.
Furthermore, since VertAttack does not replace the word, meaning is easily
preserved. We verify this via a human study and find that crowdworkers are able
to correctly label 77% perturbed texts perturbed, compared to 81% of the
original texts. We believe VertAttack offers a look into how humans might
circumvent classifiers in the future and thus inspire a look into more robust
algorithms.",2024-04-12,Jonathan Rusert,http://arxiv.org/pdf/2404.08538v1,cs.CL
"Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward","While Large Language Models (LLMs) have seen widespread applications across
numerous fields, their limited interpretability poses concerns regarding their
safe operations from multiple aspects, e.g., truthfulness, robustness, and
fairness. Recent research has started developing quality assurance methods for
LLMs, introducing techniques such as offline detector-based or uncertainty
estimation methods. However, these approaches predominantly concentrate on
post-generation analysis, leaving the online safety analysis for LLMs during
the generation phase an unexplored area. To bridge this gap, we conduct in this
work a comprehensive evaluation of the effectiveness of existing online safety
analysis methods on LLMs. We begin with a pilot study that validates the
feasibility of detecting unsafe outputs in the early generation process.
Following this, we establish the first publicly available benchmark of online
safety analysis for LLMs, including a broad spectrum of methods, models, tasks,
datasets, and evaluation metrics. Utilizing this benchmark, we extensively
analyze the performance of state-of-the-art online safety analysis methods on
both open-source and closed-source LLMs. This analysis reveals the strengths
and weaknesses of individual methods and offers valuable insights into
selecting the most appropriate method based on specific application scenarios
and task requirements. Furthermore, we also explore the potential of using
hybridization methods, i.e., combining multiple methods to derive a collective
safety conclusion, to enhance the efficacy of online safety analysis for LLMs.
Our findings indicate a promising direction for the development of innovative
and trustworthy quality assurance methodologies for LLMs, facilitating their
reliable deployments across diverse domains.",2024-04-12,"Xuan Xie, Jiayang Song, Zhehua Zhou, Yuheng Huang, Da Song, Lei Ma",http://arxiv.org/pdf/2404.08517v1,cs.CL
Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery,"In the rapidly evolving field of artificial intelligence, the ability to
harness and integrate knowledge across various domains stands as a paramount
challenge and opportunity. This study introduces a novel approach to
cross-domain knowledge discovery through the deployment of multi-AI agents,
each specialized in distinct knowledge domains. These AI agents, designed to
function as domain-specific experts, collaborate in a unified framework to
synthesize and provide comprehensive insights that transcend the limitations of
single-domain expertise. By facilitating seamless interaction among these
agents, our platform aims to leverage the unique strengths and perspectives of
each, thereby enhancing the process of knowledge discovery and decision-making.
We present a comparative analysis of the different multi-agent workflow
scenarios evaluating their performance in terms of efficiency, accuracy, and
the breadth of knowledge integration. Through a series of experiments involving
complex, interdisciplinary queries, our findings demonstrate the superior
capability of domain specific multi-AI agent system in identifying and bridging
knowledge gaps. This research not only underscores the significance of
collaborative AI in driving innovation but also sets the stage for future
advancements in AI-driven, cross-disciplinary research and application. Our
methods were evaluated on a small pilot data and it showed a trend we expected,
if we increase the amount of data we custom train the agents, the trend is
expected to be more smooth.",2024-04-12,"Shiva Aryal, Tuyen Do, Bisesh Heyojoo, Sandeep Chataut, Bichar Dip Shrestha Gurung, Venkataramana Gadhamshetty, Etienne Gnimpieba",http://arxiv.org/pdf/2404.08511v1,cs.CL
Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction,"Large language models (LLMs) have been driving a new wave of interactive AI
applications across numerous domains. However, efficiently serving LLM
inference requests is challenging due to their unpredictable execution times
originating from the autoregressive nature of generative models. Existing LLM
serving systems exploit first-come-first-serve (FCFS) scheduling, suffering
from head-of-line blocking issues. To address the non-deterministic nature of
LLMs and enable efficient interactive LLM serving, we present a speculative
shortest-job-first (SSJF) scheduler that uses a light proxy model to predict
LLM output sequence lengths. Our open-source SSJF implementation does not
require changes to memory management or batching strategies. Evaluations on
real-world datasets and production workload traces show that SSJF reduces
average job completion times by 30.5-39.6% and increases throughput by 2.2-3.6x
compared to FCFS schedulers, across no batching, dynamic batching, and
continuous batching settings.",2024-04-12,"Haoran Qiu, Weichao Mao, Archit Patke, Shengkun Cui, Saurabh Jha, Chen Wang, Hubertus Franke, Zbigniew T. Kalbarczyk, Tamer Başar, Ravishankar K. Iyer",http://arxiv.org/pdf/2404.08509v2,cs.CL
Dataset Reset Policy Optimization for RLHF,"Reinforcement Learning (RL) from Human Preference-based feedback is a popular
paradigm for fine-tuning generative models, which has produced impressive
models such as GPT-4 and Claude3 Opus. This framework often consists of two
steps: learning a reward model from an offline preference dataset followed by
running online RL to optimize the learned reward model. In this work,
leveraging the idea of reset, we propose a new RLHF algorithm with provable
guarantees. Motivated by the fact that offline preference dataset provides
informative states (i.e., data that is preferred by the labelers), our new
algorithm, Dataset Reset Policy Optimization (DR-PO), integrates the existing
offline preference dataset into the online policy training procedure via
dataset reset: it directly resets the policy optimizer to the states in the
offline dataset, instead of always starting from the initial state
distribution. In theory, we show that DR-PO learns to perform at least as good
as any policy that is covered by the offline dataset under general function
approximation with finite sample complexity. In experiments, we demonstrate
that on both the TL;DR summarization and the Anthropic Helpful Harmful (HH)
dataset, the generation from DR-PO is better than that from Proximal Policy
Optimization (PPO) and Direction Preference Optimization (DPO), under the
metric of GPT4 win-rate. Code for this work can be found at
https://github.com/Cornell-RL/drpo.",2024-04-12,"Jonathan D. Chang, Wenhao Zhan, Owen Oertell, Kianté Brantley, Dipendra Misra, Jason D. Lee, Wen Sun",http://arxiv.org/pdf/2404.08495v3,cs.CL
Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation,"Large-scale multilingual Pretrained Language Models (mPLMs) yield impressive
performance on cross-language tasks, yet significant performance disparities
exist across different languages within the same mPLM. Previous studies
endeavored to narrow these disparities by supervise fine-tuning the mPLMs with
multilingual data. However, obtaining labeled multilingual data is
time-consuming, and fine-tuning mPLM with limited labeled multilingual data
merely encapsulates the knowledge specific to the labeled data. Therefore, we
introduce ALSACE to leverage the learned knowledge from the well-performing
languages to guide under-performing ones within the same mPLM, eliminating the
need for additional labeled multilingual data. Experiments show that ALSACE
effectively mitigates language-level performance disparity across various mPLMs
while showing the competitive performance on different multilingual NLU tasks,
ranging from full resource to limited resource settings. The code for our
approach is available at https://github.com/pkunlp-icler/ALSACE.",2024-04-12,"Haozhe Zhao, Zefan Cai, Shuzheng Si, Liang Chen, Yufeng He, Kaikai An, Baobao Chang",http://arxiv.org/pdf/2404.08491v1,cs.CL
Thematic Analysis with Large Language Models: does it work with languages other than English? A targeted test in Italian,"This paper proposes a test to perform Thematic Analysis (TA) with Large
Language Model (LLM) on data which is in a different language than English.
While there has been initial promising work on using pre-trained LLMs for TA on
data in English, we lack any tests on whether these models can reasonably
perform the same analysis with good quality in other language. In this paper a
test will be proposed using an open access dataset of semi-structured
interviews in Italian. The test shows that a pre-trained model can perform such
a TA on the data, also using prompts in Italian. A comparative test shows the
model capacity to produce themes which have a good resemblance with those
produced independently by human researchers. The main implication of this study
is that pre-trained LLMs may thus be suitable to support analysis in
multilingual situations, so long as the language is supported by the model
used.",2024-04-12,Stefano De Paoli,http://arxiv.org/pdf/2404.08488v1,cs.CL
Decoding AI: The inside story of data analysis in ChatGPT,"As a result of recent advancements in generative AI, the field of Data
Science is prone to various changes. This review critically examines the Data
Analysis (DA) capabilities of ChatGPT assessing its performance across a wide
range of tasks. While DA provides researchers and practitioners with
unprecedented analytical capabilities, it is far from being perfect, and it is
important to recognize and address its limitations.",2024-04-12,"Ozan Evkaya, Miguel de Carvalho",http://arxiv.org/pdf/2404.08480v1,cs.CL
AdapterSwap: Continuous Training of LLMs with Data Removal and Access-Control Guarantees,"Large language models (LLMs) are increasingly capable of completing knowledge
intensive tasks by recalling information from a static pretraining corpus. Here
we are concerned with LLMs in the context of evolving data requirements. For
instance: batches of new data that are introduced periodically; subsets of data
with user-based access controls; or requirements on dynamic removal of
documents with guarantees that associated knowledge cannot be recalled. We wish
to satisfy these requirements while at the same time ensuring a model does not
forget old information when new data becomes available. To address these
issues, we introduce AdapterSwap, a training and inference scheme that
organizes knowledge from a data collection into a set of low-rank adapters,
which are dynamically composed during inference. Our experiments demonstrate
AdapterSwap's ability to support efficient continual learning, while also
enabling organizations to have fine-grained control over data access and
deletion.",2024-04-12,"William Fleshman, Aleem Khan, Marc Marone, Benjamin Van Durme",http://arxiv.org/pdf/2404.08417v2,cs.CL
AIMDiT: Modality Augmentation and Interaction via Multimodal Dimension Transformation for Emotion Recognition in Conversations,"Emotion Recognition in Conversations (ERC) is a popular task in natural
language processing, which aims to recognize the emotional state of the speaker
in conversations. While current research primarily emphasizes contextual
modeling, there exists a dearth of investigation into effective multimodal
fusion methods. We propose a novel framework called AIMDiT to solve the problem
of multimodal fusion of deep features. Specifically, we design a Modality
Augmentation Network which performs rich representation learning through
dimension transformation of different modalities and parameter-efficient
inception block. On the other hand, the Modality Interaction Network performs
interaction fusion of extracted inter-modal features and intra-modal features.
Experiments conducted using our AIMDiT framework on the public benchmark
dataset MELD reveal 2.34% and 2.87% improvements in terms of the Acc-7 and w-F1
metrics compared to the state-of-the-art (SOTA) models.",2024-04-12,"Sheng Wu, Jiaxing Liu, Longbiao Wang, Dongxiao He, Xiaobao Wang, Jianwu Dang",http://arxiv.org/pdf/2407.00743v1,cs.CL
Learning representations of learning representations,"The ICLR conference is unique among the top machine learning conferences in
that all submitted papers are openly available. Here we present the ICLR
dataset consisting of abstracts of all 24 thousand ICLR submissions from
2017-2024 with meta-data, decision scores, and custom keyword-based labels. We
find that on this dataset, bag-of-words representation outperforms most
dedicated sentence transformer models in terms of $k$NN classification
accuracy, and the top performing language models barely outperform TF-IDF. We
see this as a challenge for the NLP community. Furthermore, we use the ICLR
dataset to study how the field of machine learning has changed over the last
seven years, finding some improvement in gender balance. Using a 2D embedding
of the abstracts' texts, we describe a shift in research topics from 2017 to
2024 and identify hedgehogs and foxes among the authors with the highest number
of ICLR submissions.",2024-04-12,"Rita González-Márquez, Dmitry Kobak",http://arxiv.org/pdf/2404.08403v1,cs.CL
Exploring Contrastive Learning for Long-Tailed Multi-Label Text Classification,"Learning an effective representation in multi-label text classification
(MLTC) is a significant challenge in NLP. This challenge arises from the
inherent complexity of the task, which is shaped by two key factors: the
intricate connections between labels and the widespread long-tailed
distribution of the data. To overcome this issue, one potential approach
involves integrating supervised contrastive learning with classical supervised
loss functions. Although contrastive learning has shown remarkable performance
in multi-class classification, its impact in the multi-label framework has not
been thoroughly investigated. In this paper, we conduct an in-depth study of
supervised contrastive learning and its influence on representation in MLTC
context. We emphasize the importance of considering long-tailed data
distributions to build a robust representation space, which effectively
addresses two critical challenges associated with contrastive learning that we
identify: the ""lack of positives"" and the ""attraction-repulsion imbalance"".
Building on this insight, we introduce a novel contrastive loss function for
MLTC. It attains Micro-F1 scores that either match or surpass those obtained
with other frequently employed loss functions, and demonstrates a significant
improvement in Macro-F1 scores across three multi-label datasets.",2024-04-12,"Alexandre Audibert, Aurélien Gauffre, Massih-Reza Amini",http://arxiv.org/pdf/2404.08720v1,cs.CL
Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think,"Multiple choice questions (MCQs) are commonly used to evaluate the
capabilities of large language models (LLMs). One common way to evaluate the
model response is to rank the candidate answers based on the log probability of
the first token prediction. An alternative way is to examine the text output.
Prior work has shown that first token probabilities lack robustness to changes
in MCQ phrasing, and that first token probabilities do not match text answers
for instruction-tuned models. Therefore, in this paper, we investigate the
robustness of text answers. We show that the text answers are more robust to
question perturbations than the first token probabilities, when the first token
answers mismatch the text answers. The difference in robustness increases as
the mismatch rate becomes greater. As the mismatch reaches over 50\%, the text
answer is more robust to option order changes than the debiased first token
probabilities using state-of-the-art debiasing methods such as PriDe. Our
findings provide further evidence for the benefits of text answer evaluation
over first token probability evaluation.",2024-04-12,"Xinpeng Wang, Chengzhi Hu, Bolei Ma, Paul Röttger, Barbara Plank",http://arxiv.org/pdf/2404.08382v2,cs.CL
Automatic Speech Recognition Advancements for Indigenous Languages of the Americas,"Indigenous languages are a fundamental legacy in the development of human
communication, embodying the unique identity and culture of local communities
in America. The Second AmericasNLP (Americas Natural Language Processing)
Competition Track 1 of NeurIPS (Neural Information Processing Systems) 2022
proposed the task of training automatic speech recognition (ASR) systems for
five Indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa'ikhana. In
this paper, we describe the fine-tuning of a state-of-the-art ASR model for
each target language, using approximately 36.65 h of transcribed speech data
from diverse sources enriched with data augmentation methods. We systematically
investigate, using a Bayesian search, the impact of the different
hyperparameters on the Wav2vec2.0 XLS-R (Cross-Lingual Speech Representations)
variants of 300 M and 1 B parameters. Our findings indicate that data and
detailed hyperparameter tuning significantly affect ASR accuracy, but language
complexity determines the final result. The Quechua model achieved the lowest
character error rate (CER) (12.14), while the Kotiria model, despite having the
most extensive dataset during the fine-tuning phase, showed the highest CER
(36.59). Conversely, with the smallest dataset, the Guarani model achieved a
CER of 15.59, while Bribri and Wa'ikhana obtained, respectively, CERs of 34.70
and 35.23. Additionally, Sobol' sensitivity analysis highlighted the crucial
roles of freeze fine-tuning updates and dropout rates. We release our best
models for each language, marking the first open ASR models for Wa'ikhana and
Kotiria. This work opens avenues for future research to advance ASR techniques
in preserving minority Indigenous languages",2024-04-12,"Monica Romero, Sandra Gomez, Ivan G. Torre",http://arxiv.org/pdf/2404.08368v3,cs.CL
Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval,"In today's digital world, seeking answers to health questions on the Internet
is a common practice. However, existing question answering (QA) systems often
rely on using pre-selected and annotated evidence documents, thus making them
inadequate for addressing novel questions. Our study focuses on the open-domain
QA setting, where the key challenge is to first uncover relevant evidence in
large knowledge bases. By utilizing the common retrieve-then-read QA pipeline
and PubMed as a trustworthy collection of medical research documents, we answer
health questions from three diverse datasets. We modify different retrieval
settings to observe their influence on the QA pipeline's performance, including
the number of retrieved documents, sentence selection process, the publication
year of articles, and their number of citations. Our results reveal that
cutting down on the amount of retrieved documents and favoring more recent and
highly cited documents can improve the final macro F1 score up to 10%. We
discuss the results, highlight interesting examples, and outline challenges for
future research, like managing evidence disagreement and crafting user-friendly
explanations.",2024-04-12,"Juraj Vladika, Florian Matthes",http://arxiv.org/pdf/2404.08359v1,cs.CL
PMB5: Gaining More Insight into Neural Semantic Parsing with Challenging Benchmarks,"The Parallel Meaning Bank (PMB) serves as a corpus for semantic processing
with a focus on semantic parsing and text generation. Currently, we witness an
excellent performance of neural parsers and generators on the PMB. This might
suggest that such semantic processing tasks have by and large been solved. We
argue that this is not the case and that performance scores from the past on
the PMB are inflated by non-optimal data splits and test sets that are too
easy. In response, we introduce several changes. First, instead of the prior
random split, we propose a more systematic splitting approach to improve the
reliability of the standard test data. Second, except for the standard test
set, we also propose two challenge sets: one with longer texts including
discourse structure, and one that addresses compositional generalization. We
evaluate five neural models for semantic parsing and meaning-to-text
generation. Our results show that model performance declines (in some cases
dramatically) on the challenge sets, revealing the limitations of neural models
when confronting such challenges.",2024-04-12,"Xiao Zhang, Chunliu Wang, Rik van Noord, Johan Bos",http://arxiv.org/pdf/2404.08354v4,cs.CL
FastSpell: the LangId Magic Spell,"Language identification is a crucial component in the automated production of
language resources, particularly in multilingual and big data contexts.
However, commonly used language identifiers struggle to differentiate between
similar or closely-related languages. This paper introduces FastSpell, a
language identifier that combines fastText (a pre-trained language identifier
tool) and Hunspell (a spell checker) with the aim of having a refined
second-opinion before deciding which language should be assigned to a text. We
provide a description of the FastSpell algorithm along with an explanation on
how to use and configure it. To that end, we motivate the need of such a tool
and present a benchmark including some popular language identifiers evaluated
during the development of FastSpell. We show how FastSpell is useful not only
to improve identification of similar languages, but also to identify new ones
ignored by other tools.",2024-04-12,"Marta Bañón, Jaume Zaragoza-Bernabeu, Gema Ramírez-Sánchez, Sergio Ortiz-Rojas",http://arxiv.org/pdf/2404.08345v1,cs.CL
Toward a Theory of Tokenization in LLMs,"While there has been a large body of research attempting to circumvent
tokenization for language modeling (Clark et al., 2022; Xue et al., 2022), the
current consensus is that it is a necessary initial step for designing
state-of-the-art performant language models. In this paper, we investigate
tokenization from a theoretical point of view by studying the behavior of
transformers on simple data generating processes. When trained on data drawn
from certain simple $k^{\text{th}}$-order Markov processes for $k > 1$,
transformers exhibit a surprising phenomenon - in the absence of tokenization,
they empirically fail to learn the right distribution and predict characters
according to a unigram model (Makkuva et al., 2024). With the addition of
tokenization, however, we empirically observe that transformers break through
this barrier and are able to model the probabilities of sequences drawn from
the source near-optimally, achieving small cross-entropy loss. With this
observation as starting point, we study the end-to-end cross-entropy loss
achieved by transformers with and without tokenization. With the appropriate
tokenization, we show that even the simplest unigram models (over tokens)
learnt by transformers are able to model the probability of sequences drawn
from $k^{\text{th}}$-order Markov sources near optimally. Our analysis provides
a justification for the use of tokenization in practice through studying the
behavior of transformers on Markovian data.",2024-04-12,"Nived Rajaraman, Jiantao Jiao, Kannan Ramchandran",http://arxiv.org/pdf/2404.08335v2,cs.CL
RLHF from Heterogeneous Feedback via Personalization and Preference Aggregation,"Reinforcement learning from human feedback (RLHF) has been an effective
technique for aligning AI systems with human values, with remarkable successes
in fine-tuning large-language models recently. Most existing RLHF paradigms
make the underlying assumption that human preferences are relatively
homogeneous, and can be encoded by a single reward model. In this paper, we
focus on addressing the issues due to the inherent heterogeneity in human
preferences, as well as their potential strategic behavior in providing
feedback. Specifically, we propose two frameworks to address heterogeneous
human feedback in principled ways: personalization-based one and
aggregation-based one. For the former, we propose two approaches based on
representation learning and clustering, respectively, for learning multiple
reward models that trades off the bias (due to preference heterogeneity) and
variance (due to the use of fewer data for learning each model by
personalization). We then establish sample complexity guarantees for both
approaches. For the latter, we aim to adhere to the single-model framework, as
already deployed in the current RLHF paradigm, by carefully aggregating diverse
and truthful preferences from humans. We propose two approaches based on reward
and preference aggregation, respectively: the former utilizes both
utilitarianism and Leximin approaches to aggregate individual reward models,
with sample complexity guarantees; the latter directly aggregates the human
feedback in the form of probabilistic opinions. Under the
probabilistic-opinion-feedback model, we also develop an approach to handle
strategic human labelers who may bias and manipulate the aggregated preferences
with untruthful feedback. Based on the ideas in mechanism design, our approach
ensures truthful preference reporting, with the induced aggregation rule
maximizing social welfare functions.",2024-04-30,"Chanwoo Park, Mingyang Liu, Dingwen Kong, Kaiqing Zhang, Asuman Ozdaglar",http://arxiv.org/pdf/2405.00254v2,cs.LG
Q-Newton: Hybrid Quantum-Classical Scheduling for Accelerating Neural Network Training with Newton's Gradient Descent,"Optimization techniques in deep learning are predominantly led by first-order
gradient methodologies, such as SGD. However, neural network training can
greatly benefit from the rapid convergence characteristics of second-order
optimization. Newton's GD stands out in this category, by rescaling the
gradient using the inverse Hessian. Nevertheless, one of its major bottlenecks
is matrix inversion, which is notably time-consuming in $O(N^3)$ time with weak
scalability.
  Matrix inversion can be translated into solving a series of linear equations.
Given that quantum linear solver algorithms (QLSAs), leveraging the principles
of quantum superposition and entanglement, can operate within a
$\text{polylog}(N)$ time frame, they present a promising approach with
exponential acceleration. Specifically, one of the most recent QLSAs
demonstrates a complexity scaling of $O(d\cdot\kappa
\log(N\cdot\kappa/\epsilon))$, depending on: {size~$N$, condition
number~$\kappa$, error tolerance~$\epsilon$, quantum oracle sparsity~$d$} of
the matrix. However, this also implies that their potential exponential
advantage may be hindered by certain properties (i.e. $\kappa$ and $d$).
  We propose Q-Newton, a hybrid quantum-classical scheduler for accelerating
neural network training with Newton's GD. Q-Newton utilizes a streamlined
scheduling module that coordinates between quantum and classical linear
solvers, by estimating & reducing $\kappa$ and constructing $d$ for the quantum
solver.
  Our evaluation showcases the potential for Q-Newton to significantly reduce
the total training time compared to commonly used optimizers like SGD. We
hypothesize a future scenario where the gate time of quantum machines is
reduced, possibly realized by attoseconds physics. Our evaluation establishes
an ambitious and promising target for the evolution of quantum computing.",2024-04-30,"Pingzhi Li, Junyu Liu, Hanrui Wang, Tianlong Chen",http://arxiv.org/pdf/2405.00252v3,cs.LG
Semantically Consistent Video Inpainting with Conditional Diffusion Models,"Current state-of-the-art methods for video inpainting typically rely on
optical flow or attention-based approaches to inpaint masked regions by
propagating visual information across frames. While such approaches have led to
significant progress on standard benchmarks, they struggle with tasks that
require the synthesis of novel content that is not present in other frames. In
this paper, we reframe video inpainting as a conditional generative modeling
problem and present a framework for solving such problems with conditional
video diffusion models. We introduce inpainting-specific sampling schemes which
capture crucial long-range dependencies in the context, and devise a novel
method for conditioning on the known pixels in incomplete frames. We highlight
the advantages of using a generative approach for this task, showing that our
method is capable of generating diverse, high-quality inpaintings and
synthesizing new content that is spatially, temporally, and semantically
consistent with the provided context.",2024-04-30,"Dylan Green, William Harvey, Saeid Naderiparizi, Matthew Niedoba, Yunpeng Liu, Xiaoxuan Liang, Jonathan Lavington, Ke Zhang, Vasileios Lioutas, Setareh Dabiri, Adam Scibior, Berend Zwartsenberg, Frank Wood",http://arxiv.org/pdf/2405.00251v2,cs.LG
At the edge of a generative cultural precipice,"Since NFTs and large generative models (such as DALLE2 and Stable Diffusion)
have been publicly available, artists have seen their jobs threatened and
stolen. While artists depend on sharing their art on online platforms such as
Deviantart, Pixiv, and Artstation, many slowed down sharing their work or
downright removed their past work therein, especially if these platforms fail
to provide certain guarantees regarding the copyright of their uploaded work.
Text-to-image (T2I) generative models are trained using human-produced content
to better guide the style and themes they can produce. Still, if the trend
continues where data found online is generated by a machine instead of a human,
this will have vast repercussions in culture. Inspired by recent work in
generative models, we wish to tell a cautionary tale and ask what will happen
to the visual arts if generative models continue on the path to be (eventually)
trained solely on generated content.",2024-04-30,"Diego Porres, Alex Gomez-Villa",http://arxiv.org/pdf/2406.08739v1,cs.LG
"Weakly-Supervised PET Anomaly Detection using Implicitly-Guided Attention-Conditional Counterfactual Diffusion Modeling: a Multi-Center, Multi-Cancer, and Multi-Tracer Study","Minimizing the need for pixel-level annotated data to train PET lesion
detection and segmentation networks is highly desired and can be
transformative, given time and cost constraints associated with expert
annotations. Current un-/weakly-supervised anomaly detection methods rely on
autoencoder or generative adversarial networks trained only on healthy data;
however GAN-based networks are more challenging to train due to issues with
simultaneous optimization of two competing networks, mode collapse, etc. In
this paper, we present the weakly-supervised Implicitly guided COuNterfactual
diffusion model for Detecting Anomalies in PET images (IgCONDA-PET). The
solution is developed and validated using PET scans from six retrospective
cohorts consisting of a total of 2652 cases containing both local and public
datasets. The training is conditioned on image class labels (healthy vs.
unhealthy) via attention modules, and we employ implicit diffusion guidance. We
perform counterfactual generation which facilitates ""unhealthy-to-healthy""
domain translation by generating a synthetic, healthy version of an unhealthy
input image, enabling the detection of anomalies through the calculated
differences. The performance of our method was compared against several other
deep learning based weakly-supervised or unsupervised methods as well as
traditional methods like 41% SUVmax thresholding. We also highlight the
importance of incorporating attention modules in our network for the detection
of small anomalies. The code is publicly available at:
https://github.com/ahxmeds/IgCONDA-PET.git.",2024-04-30,"Shadab Ahamed, Arman Rahmim",http://arxiv.org/pdf/2405.00239v2,cs.LG
STT: Stateful Tracking with Transformers for Autonomous Driving,"Tracking objects in three-dimensional space is critical for autonomous
driving. To ensure safety while driving, the tracker must be able to reliably
track objects across frames and accurately estimate their states such as
velocity and acceleration in the present. Existing works frequently focus on
the association task while either neglecting the model performance on state
estimation or deploying complex heuristics to predict the states. In this
paper, we propose STT, a Stateful Tracking model built with Transformers, that
can consistently track objects in the scenes while also predicting their states
accurately. STT consumes rich appearance, geometry, and motion signals through
long term history of detections and is jointly optimized for both data
association and state estimation tasks. Since the standard tracking metrics
like MOTA and MOTP do not capture the combined performance of the two tasks in
the wider spectrum of object states, we extend them with new metrics called
S-MOTA and MOTPS that address this limitation. STT achieves competitive
real-time performance on the Waymo Open Dataset.",2024-04-30,"Longlong Jing, Ruichi Yu, Xu Chen, Zhengli Zhao, Shiwei Sheng, Colin Graber, Qi Chen, Qinru Li, Shangxuan Wu, Han Deng, Sangjin Lee, Chris Sweeney, Qiurui He, Wei-Chih Hung, Tong He, Xingyi Zhou, Farshid Moussavi, Zijian Guo, Yin Zhou, Mingxing Tan, Weilong Yang, Congcong Li",http://arxiv.org/pdf/2405.00236v1,cs.LG
Almanac Copilot: Towards Autonomous Electronic Health Record Navigation,"Clinicians spend large amounts of time on clinical documentation, and
inefficiencies impact quality of care and increase clinician burnout. Despite
the promise of electronic medical records (EMR), the transition from
paper-based records has been negatively associated with clinician wellness, in
part due to poor user experience, increased burden of documentation, and alert
fatigue. In this study, we present Almanac Copilot, an autonomous agent capable
of assisting clinicians with EMR-specific tasks such as information retrieval
and order placement. On EHR-QA, a synthetic evaluation dataset of 300 common
EHR queries based on real patient data, Almanac Copilot obtains a successful
task completion rate of 74% (n = 221 tasks) with a mean score of 2.45 over 3
(95% CI:2.34-2.56). By automating routine tasks and streamlining the
documentation process, our findings highlight the significant potential of
autonomous agents to mitigate the cognitive load imposed on clinicians by
current EMR systems.",2024-04-30,"Cyril Zakka, Joseph Cho, Gracia Fahed, Rohan Shad, Michael Moor, Robyn Fong, Dhamanpreet Kaur, Vishnu Ravi, Oliver Aalami, Roxana Daneshjou, Akshay Chaudhari, William Hiesinger",http://arxiv.org/pdf/2405.07896v2,cs.LG
Context-Aware Mobile Network Performance Prediction Using Network & Remote Sensing Data,"Accurate estimation of Network Performance is crucial for several tasks in
telecom networks. Telecom networks regularly serve a vast number of radio
nodes. Each radio node provides services to end-users in the associated
coverage areas. The task of predicting Network Performance for telecom networks
necessitates considering complex spatio-temporal interactions and incorporating
geospatial information where the radio nodes are deployed. Instead of relying
on historical data alone, our approach augments network historical performance
datasets with satellite imagery data. Our comprehensive experiments, using
real-world data collected from multiple different regions of an operational
network, show that the model is robust and can generalize across different
scenarios. The results indicate that the model, utilizing satellite imagery,
performs very well across the tested regions. Additionally, the model
demonstrates a robust approach to the cold-start problem, offering a promising
alternative for initial performance estimation in newly deployed sites.",2024-04-30,"Ali Shibli, Tahar Zanouda",http://arxiv.org/pdf/2405.00220v1,cs.LG
Machine Learning-based Estimation of Respiratory Fluctuations in a Healthy Adult Population using BOLD fMRI and Head Motion Parameters,"Motivation: In many fMRI studies, respiratory signals are often missing or of
poor quality. Therefore, it could be highly beneficial to have a tool to
extract respiratory variation (RV) waveforms directly from fMRI data without
the need for peripheral recording devices.
  Goal(s): Investigate the hypothesis that head motion parameters contain
valuable information regarding respiratory patter, which can help machine
learning algorithms estimate the RV waveform.
  Approach: This study proposes a CNN model for reconstruction of RV waveforms
using head motion parameters and BOLD signals.
  Results: This study showed that combining head motion parameters with BOLD
signals enhances RV waveform estimation.
  Impact: It is expected that application of the proposed method will lower the
cost of fMRI studies, reduce complexity, and decrease the burden on
participants as they will not be required to wear a respiratory bellows.",2024-04-30,"Abdoljalil Addeh, Fernando Vega, Rebecca J. Williams, G. Bruce Pike, M. Ethan MacDonald",http://arxiv.org/pdf/2405.00219v1,cs.LG
Constrained Decoding for Secure Code Generation,"Code Large Language Models (Code LLMs) have been increasingly used by
developers to boost productivity, but they often generate vulnerable code.
Thus, there is an urgent need to ensure that code generated by Code LLMs is
correct and secure. Previous research has primarily focused on generating
secure code, overlooking the fact that secure code also needs to be correct.
This oversight can lead to a false sense of security. Currently, the community
lacks a method to measure actual progress in this area, and we need solutions
that address both security and correctness of code generation.
  This paper introduces a new benchmark, CodeGuard+, along with two new
metrics, to measure Code LLMs' ability to generate both secure and correct
code. Using our new evaluation methods, we show that the state-of-the-art
defense technique, prefix tuning, may not be as strong as previously believed,
since it generates secure code but sacrifices functional correctness. We also
demonstrate that different decoding methods significantly affect the security
of Code LLMs.
  Furthermore, we explore a new defense direction: constrained decoding for
secure code generation. We propose new constrained decoding techniques to
generate secure code. Our results reveal that constrained decoding is more
effective than prefix tuning to improve the security of Code LLMs, without
requiring a specialized training dataset. Moreover, our evaluations over eight
state-of-the-art Code LLMs show that constrained decoding has strong
performance to improve the security of Code LLMs, and our technique outperforms
GPT-4.",2024-04-30,"Yanjun Fu, Ethan Baker, Yu Ding, Yizheng Chen",http://arxiv.org/pdf/2405.00218v3,cs.LG
GMC-PINNs: A new general Monte Carlo PINNs method for solving fractional partial differential equations on irregular domains,"Physics-Informed Neural Networks (PINNs) have been widely used for solving
partial differential equations (PDEs) of different types, including fractional
PDEs (fPDES) [29]. Herein, we propose a new general (quasi) Monte Carlo PINN
for solving fPDEs on irregular domains. Specifically, instead of approximating
fractional derivatives by Monte Carlo approximations of integrals as was done
previously in [31], we use a more general Monte Carlo approximation method to
solve different fPDEs, which is valid for fractional differentiation under any
definition. Moreover, based on the ensemble probability density function, the
generated nodes are all located in denser regions near the target point where
we perform the differentiation. This has an unexpected connection with known
finite difference methods on non-equidistant or nested grids, and hence our
method inherits their advantages. At the same time, the generated nodes exhibit
a block-like dense distribution, leading to a good computational efficiency of
this approach. We present the framework for using this algorithm and apply it
to several examples. Our results demonstrate the effectiveness of GMC-PINNs in
dealing with irregular domain problems and show a higher computational
efficiency compared to the original fPINN method. We also include comparisons
with the Monte Carlo fPINN [31]. Finally, we use examples to demonstrate the
effectiveness of the method in dealing with fuzzy boundary location problems,
and then use the method to solve the coupled 3D fractional Bloch-Torrey
equation defined in the ventricular domain of the human brain, and compare the
results with classical numerical methods.",2024-04-30,"Shupeng Wang, George Em Karniadakis",http://arxiv.org/pdf/2405.00217v1,cs.LG
Graphical Reasoning: LLM-based Semi-Open Relation Extraction,"This paper presents a comprehensive exploration of relation extraction
utilizing advanced language models, specifically Chain of Thought (CoT) and
Graphical Reasoning (GRE) techniques. We demonstrate how leveraging in-context
learning with GPT-3.5 can significantly enhance the extraction process,
particularly through detailed example-based reasoning. Additionally, we
introduce a novel graphical reasoning approach that dissects relation
extraction into sequential sub-tasks, improving precision and adaptability in
processing complex relational data. Our experiments, conducted on multiple
datasets, including manually annotated data, show considerable improvements in
performance metrics, underscoring the effectiveness of our methodologies.",2024-04-30,"Yicheng Tao, Yiqun Wang, Longju Bai",http://arxiv.org/pdf/2405.00216v1,cs.LG
Block-As-Domain Adaptation for Workload Prediction from fNIRS Data,"Functional near-infrared spectroscopy (fNIRS) is a non-intrusive way to
measure cortical hemodynamic activity. Predicting cognitive workload from fNIRS
data has taken on a diffuse set of methods. To be applicable in real-world
settings, models are needed, which can perform well across different sessions
as well as different subjects. However, most existing works assume that
training and testing data come from the same subjects and/or cannot generalize
well across never-before-seen subjects. Additional challenges imposed by fNIRS
data include the high variations in inter-subject fNIRS data and also in
intra-subject data collected across different blocks of sessions. To address
these issues, we propose an effective method, referred to as the
class-aware-block-aware domain adaptation (CABA-DA) which explicitly minimize
intra-session variance by viewing different blocks from the same subject same
session as different domains. We minimize the intra-class domain discrepancy
and maximize the inter-class domain discrepancy accordingly. In addition, we
propose an MLPMixer-based model for cognitive load classification. Experimental
results demonstrate the proposed model has better performance compared with
three different baseline models on three public-available datasets of cognitive
workload. Two of them are collected from n-back tasks and one of them is from
finger tapping. From our experiments, we also show the proposed contrastive
learning method can also improve baseline models we compared with.",2024-04-30,"Jiyang Wang, Ayse Altay, Senem Velipasalar",http://arxiv.org/pdf/2405.00213v1,cs.LG
A Logic for Reasoning About Aggregate-Combine Graph Neural Networks,"We propose a modal logic in which counting modalities appear in linear
inequalities. We show that each formula can be transformed into an equivalent
graph neural network (GNN). We also show that a broad class of GNNs can be
transformed efficiently into a formula, thus significantly improving upon the
literature about the logical expressiveness of GNNs. We also show that the
satisfiability problem is PSPACE-complete. These results bring together the
promise of using standard logical methods for reasoning about GNNs and their
properties, particularly in applications such as GNN querying, equivalence
checking, etc. We prove that such natural problems can be solved in polynomial
space.",2024-04-30,"Pierre Nunn, Marco Sälzer, François Schwarzentruber, Nicolas Troquard",http://arxiv.org/pdf/2405.00205v2,cs.LG
Leveraging Active Subspaces to Capture Epistemic Model Uncertainty in Deep Generative Models for Molecular Design,"Deep generative models have been accelerating the inverse design process in
material and drug design. Unlike their counterpart property predictors in
typical molecular design frameworks, generative molecular design models have
seen fewer efforts on uncertainty quantification (UQ) due to computational
challenges in Bayesian inference posed by their large number of parameters. In
this work, we focus on the junction-tree variational autoencoder (JT-VAE), a
popular model for generative molecular design, and address this issue by
leveraging the low dimensional active subspace to capture the uncertainty in
the model parameters. Specifically, we approximate the posterior distribution
over the active subspace parameters to estimate the epistemic model uncertainty
in an extremely high dimensional parameter space. The proposed UQ scheme does
not require alteration of the model architecture, making it readily applicable
to any pre-trained model. Our experiments demonstrate the efficacy of the
AS-based UQ and its potential impact on molecular optimization by exploring the
model diversity under epistemic uncertainty.",2024-04-30,"A N M Nafiz Abeer, Sanket Jantre, Nathan M Urban, Byung-Jun Yoon",http://arxiv.org/pdf/2405.00202v2,cs.LG
Semi-Supervised Hierarchical Multi-Label Classifier Based on Local Information,"Scarcity of labeled data is a common problem in supervised classification,
since hand-labeling can be time consuming, expensive or hard to label; on the
other hand, large amounts of unlabeled information can be found. The problem of
scarcity of labeled data is even more notorious in hierarchical classification,
because the data of a node is split among its children, which results in few
instances associated to the deepest nodes of the hierarchy. In this work it is
proposed the semi-supervised hierarchical multi-label classifier based on local
information (SSHMC-BLI) which can be trained with labeled and unlabeled data to
perform hierarchical classification tasks. The method can be applied to any
type of hierarchical problem, here we focus on the most difficult case:
hierarchies of DAG type, where the instances can be associated to multiple
paths of labels which can finish in an internal node. SSHMC-BLI builds
pseudo-labels for each unlabeled instance from the paths of labels of its
labeled neighbors, while it considers whether the unlabeled instance is similar
to its neighbors. Experiments on 12 challenging datasets from functional
genomics show that making use of unlabeled along with labeled data can help to
improve the performance of a supervised hierarchical classifier trained only on
labeled data, even with statistical significance.",2024-04-30,"Jonathan Serrano-Pérez, L. Enrique Sucar",http://arxiv.org/pdf/2405.00184v1,cs.LG
M-DEW: Extending Dynamic Ensemble Weighting to Handle Missing Values,"Missing value imputation is a crucial preprocessing step for many machine
learning problems. However, it is often considered as a separate subtask from
downstream applications such as classification, regression, or clustering, and
thus is not optimized together with them. We hypothesize that treating the
imputation model and downstream task model together and optimizing over full
pipelines will yield better results than treating them separately. Our work
describes a novel AutoML technique for making downstream predictions with
missing data that automatically handles preprocessing, model weighting, and
selection during inference time, with minimal compute overhead. Specifically we
develop M-DEW, a Dynamic missingness-aware Ensemble Weighting (DEW) approach,
that constructs a set of two-stage imputation-prediction pipelines, trains each
component separately, and dynamically calculates a set of pipeline weights for
each sample during inference time. We thus extend previous work on dynamic
ensemble weighting to handle missing data at the level of full
imputation-prediction pipelines, improving performance and calibration on
downstream machine learning tasks over standard model averaging techniques.
M-DEW is shown to outperform the state-of-the-art in that it produces
statistically significant reductions in model perplexity in 17 out of 18
experiments, while improving average precision in 13 out of 18 experiments.",2024-04-30,"Adam Catto, Nan Jia, Ansaf Salleb-Aouissi, Anita Raja",http://arxiv.org/pdf/2405.00182v1,cs.LG
Soft Preference Optimization: Aligning Language Models to Expert Distributions,"We propose Soft Preference Optimization (SPO), a method for aligning
generative models, such as Large Language Models (LLMs), with human
preferences, without the need for a reward model. SPO optimizes model outputs
directly over a preference dataset through a natural loss function that
integrates preference loss with a regularization term across the model's entire
output distribution rather than limiting it to the preference dataset. Although
SPO does not require the assumption of an existing underlying reward model, we
demonstrate that, under the Bradley-Terry (BT) model assumption, it converges
to a softmax of scaled rewards, with the distribution's ""softness"" adjustable
via the softmax exponent, an algorithm parameter. We showcase SPO's
methodology, its theoretical foundation, and its comparative advantages in
simplicity, computational efficiency, and alignment precision.",2024-04-30,"Arsalan Sharifnassab, Saber Salehkaleybar, Sina Ghiassian, Surya Kanoria, Dale Schuurmans",http://arxiv.org/pdf/2405.00747v4,cs.LG
Re-visiting Skip-Gram Negative Sampling: Dimension Regularization for More Efficient Dissimilarity Preservation in Graph Embeddings,"A wide range of graph embedding objectives decompose into two components: one
that attracts the embeddings of nodes that are perceived as similar, and
another that repels embeddings of nodes that are perceived as dissimilar.
Because real-world graphs are sparse and the number of dissimilar pairs grows
quadratically with the number of nodes, Skip-Gram Negative Sampling (SGNS) has
emerged as a popular and efficient repulsion approach. SGNS repels each node
from a sample of dissimilar nodes, as opposed to all dissimilar nodes. In this
work, we show that node-wise repulsion is, in aggregate, an approximate
re-centering of the node embedding dimensions. Such dimension operations are
much more scalable than node operations. The dimension approach, in addition to
being more efficient, yields a simpler geometric interpretation of the
repulsion. Our result extends findings from the self-supervised learning
literature to the skip-gram model, establishing a connection between skip-gram
node contrast and dimension regularization. We show that in the limit of large
graphs, under mild regularity conditions, the original node repulsion objective
converges to optimization with dimension regularization. We use this
observation to propose an algorithm augmentation framework that speeds up any
existing algorithm, supervised or unsupervised, using SGNS. The framework
prioritizes node attraction and replaces SGNS with dimension regularization. We
instantiate this generic framework for LINE and node2vec and show that the
augmented algorithms preserve downstream performance while dramatically
increasing efficiency.",2024-04-30,"David Liu, Arjun Seshadri, Tina Eliassi-Rad, Johan Ugander",http://arxiv.org/pdf/2405.00172v1,cs.LG
Discovering intrinsic multi-compartment pharmacometric models using Physics Informed Neural Networks,"Pharmacometric models are pivotal across drug discovery and development,
playing a decisive role in determining the progression of candidate molecules.
However, the derivation of mathematical equations governing the system is a
labor-intensive trial-and-error process, often constrained by tight timelines.
In this study, we introduce PKINNs, a novel purely data-driven
pharmacokinetic-informed neural network model. PKINNs efficiently discovers and
models intrinsic multi-compartment-based pharmacometric structures, reliably
forecasting their derivatives. The resulting models are both interpretable and
explainable through Symbolic Regression methods. Our computational framework
demonstrates the potential for closed-form model discovery in pharmacometric
applications, addressing the labor-intensive nature of traditional model
derivation. With the increasing availability of large datasets, this framework
holds the potential to significantly enhance model-informed drug discovery.",2024-04-30,"Imran Nasim, Adam Nasim",http://arxiv.org/pdf/2405.00166v1,cs.LG
"BayesBlend: Easy Model Blending using Pseudo-Bayesian Model Averaging, Stacking and Hierarchical Stacking in Python","Averaging predictions from multiple competing inferential models frequently
outperforms predictions from any single model, providing that models are
optimally weighted to maximize predictive performance. This is particularly the
case in so-called $\mathcal{M}$-open settings where the true model is not in
the set of candidate models, and may be neither mathematically reifiable nor
known precisely. This practice of model averaging has a rich history in
statistics and machine learning, and there are currently a number of methods to
estimate the weights for constructing model-averaged predictive distributions.
Nonetheless, there are few existing software packages that can estimate model
weights from the full variety of methods available, and none that blend model
predictions into a coherent predictive distribution according to the estimated
weights. In this paper, we introduce the BayesBlend Python package, which
provides a user-friendly programming interface to estimate weights and blend
multiple (Bayesian) models' predictive distributions. BayesBlend implements
pseudo-Bayesian model averaging, stacking and, uniquely, hierarchical Bayesian
stacking to estimate model weights. We demonstrate the usage of BayesBlend with
examples of insurance loss modeling.",2024-04-30,"Nathaniel Haines, Conor Goold",http://arxiv.org/pdf/2405.00158v1,cs.LG
Strategic Integration of Artificial Intelligence in the C-Suite: The Role of the Chief AI Officer,"The integration of Artificial Intelligence (AI) into corporate strategy has
become a pivotal focus for organizations aiming to maintain a competitive
advantage in the digital age. As AI reshapes business operations and drives
innovation, the need for specialized leadership to effectively manage these
changes becomes increasingly apparent. In this paper, I explore the role of the
Chief AI Officer (CAIO) within the C-suite, emphasizing the necessity of this
position for successful AI strategy, integration, and governance. I analyze
future scenarios based on current trends in three key areas: the AI Economy, AI
Organization, and Competition in the Age of AI. These explorations lay the
foundation for identifying the antecedents (environmental, structural, and
strategic factors) that justify the inclusion of a CAIO in top management
teams. This sets the stage for a comprehensive examination of the CAIO's role
and the broader implications of AI leadership. This paper advances the
discussion on AI leadership by providing a rationale for the strategic
integration of AI at the executive level and examining the role of the Chief AI
Officer within organizations.",2024-04-30,Marc Schmitt,http://arxiv.org/pdf/2407.10247v1,cs.LG
Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification,"Quantum machine learning (QML) has the potential for improving the
multi-label classification of rare, albeit critical, diseases in large-scale
chest x-ray (CXR) datasets due to theoretical quantum advantages over classical
machine learning (CML) in sample efficiency and generalizability. While prior
literature has explored QML with CXRs, it has focused on binary classification
tasks with small datasets due to limited access to quantum hardware and
computationally expensive simulations. To that end, we implemented a Jax-based
framework that enables the simulation of medium-sized qubit architectures with
significant improvements in wall-clock time over current software offerings. We
evaluated the performance of our Jax-based framework in terms of efficiency and
performance for hybrid quantum transfer learning for long-tailed classification
across 8, 14, and 19 disease labels using large-scale CXR datasets. The
Jax-based framework resulted in up to a 58% and 95% speed-up compared to
PyTorch and TensorFlow implementations, respectively. However, compared to CML,
QML demonstrated slower convergence and an average AUROC of 0.70, 0.73, and
0.74 for the classification of 8, 14, and 19 CXR disease labels. In comparison,
the CML models had an average AUROC of 0.77, 0.78, and 0.80 respectively. In
conclusion, our work presents an accessible implementation of hybrid quantum
transfer learning for long-tailed CXR classification with a computationally
efficient Jax-based framework.",2024-04-30,"Skylar Chan, Pranav Kulkarni, Paul H. Yi, Vishwa S. Parekh",http://arxiv.org/pdf/2405.00156v2,cs.LG
Leveraging Sub-Optimal Data for Human-in-the-Loop Reinforcement Learning,"To create useful reinforcement learning (RL) agents, step zero is to design a
suitable reward function that captures the nuances of the task. However, reward
engineering can be a difficult and time-consuming process. Instead,
human-in-the-loop RL methods hold the promise of learning reward functions from
human feedback. Despite recent successes, many of the human-in-the-loop RL
methods still require numerous human interactions to learn successful reward
functions. To improve the feedback efficiency of human-in-the-loop RL methods
(i.e., require less human interaction), this paper introduces Sub-optimal Data
Pre-training, SDP, an approach that leverages reward-free, sub-optimal data to
improve scalar- and preference-based RL algorithms. In SDP, we start by
pseudo-labeling all low-quality data with the minimum environment reward.
Through this process, we obtain reward labels to pre-train our reward model
without requiring human labeling or preferences. This pre-training phase
provides the reward model a head start in learning, enabling it to recognize
that low-quality transitions should be assigned low rewards. Through extensive
experiments with both simulated and human teachers, we find that SDP can at
least meet, but often significantly improve, state of the art human-in-the-loop
RL performance across a variety of simulated robotic tasks.",2024-04-30,"Calarina Muslimani, Matthew E. Taylor",http://arxiv.org/pdf/2405.00746v2,cs.LG
Utilizing Machine Learning and 3D Neuroimaging to Predict Hearing Loss: A Comparative Analysis of Dimensionality Reduction and Regression Techniques,"In this project, we have explored machine learning approaches for predicting
hearing loss thresholds on the brain's gray matter 3D images. We have solved
the problem statement in two phases. In the first phase, we used a 3D CNN model
to reduce high-dimensional input into latent space and decode it into an
original image to represent the input in rich feature space. In the second
phase, we utilized this model to reduce input into rich features and used these
features to train standard machine learning models for predicting hearing
thresholds. We have experimented with autoencoders and variational autoencoders
in the first phase for dimensionality reduction and explored random forest,
XGBoost and multi-layer perceptron for regressing the thresholds. We split the
given data set into training and testing sets and achieved an 8.80 range and
22.57 range for PT500 and PT4000 on the test set, respectively. We got the
lowest RMSE using multi-layer perceptron among the other models.
  Our approach leverages the unique capabilities of VAEs to capture complex,
non-linear relationships within high-dimensional neuroimaging data. We
rigorously evaluated the models using various metrics, focusing on the root
mean squared error (RMSE). The results highlight the efficacy of the
multi-layer neural network model, which outperformed other techniques in terms
of accuracy. This project advances the application of data mining in medical
diagnostics and enhances our understanding of age-related hearing loss through
innovative machine-learning frameworks.",2024-04-30,"Trinath Sai Subhash Reddy Pittala, Uma Maheswara R Meleti, Manasa Thatipamula",http://arxiv.org/pdf/2405.00142v2,cs.LG
Data-Driven Permissible Safe Control with Barrier Certificates,"This paper introduces a method of identifying a maximal set of safe
strategies from data for stochastic systems with unknown dynamics using barrier
certificates. The first step is learning the dynamics of the system via
Gaussian process (GP) regression and obtaining probabilistic errors for this
estimate. Then, we develop an algorithm for constructing piecewise stochastic
barrier functions to find a maximal permissible strategy set using the learned
GP model, which is based on sequentially pruning the worst controls until a
maximal set is identified. The permissible strategies are guaranteed to
maintain probabilistic safety for the true system. This is especially important
for learning-enabled systems, because a rich strategy space enables additional
data collection and complex behaviors while remaining safe. Case studies on
linear and nonlinear systems demonstrate that increasing the size of the
dataset for learning the system grows the permissible strategy set.",2024-04-30,"Rayan Mazouz, John Skovbekk, Frederik Baymler Mathiesen, Eric Frew, Luca Laurenti, Morteza Lahijanian",http://arxiv.org/pdf/2405.00136v2,cs.LG
A Flexible 2.5D Medical Image Segmentation Approach with In-Slice and Cross-Slice Attention,"Deep learning has become the de facto method for medical image segmentation,
with 3D segmentation models excelling in capturing complex 3D structures and 2D
models offering high computational efficiency. However, segmenting 2.5D images,
which have high in-plane but low through-plane resolution, is a relatively
unexplored challenge. While applying 2D models to individual slices of a 2.5D
image is feasible, it fails to capture the spatial relationships between
slices. On the other hand, 3D models face challenges such as resolution
inconsistencies in 2.5D images, along with computational complexity and
susceptibility to overfitting when trained with limited data. In this context,
2.5D models, which capture inter-slice correlations using only 2D neural
networks, emerge as a promising solution due to their reduced computational
demand and simplicity in implementation. In this paper, we introduce CSA-Net, a
flexible 2.5D segmentation model capable of processing 2.5D images with an
arbitrary number of slices through an innovative Cross-Slice Attention (CSA)
module. This module uses the cross-slice attention mechanism to effectively
capture 3D spatial information by learning long-range dependencies between the
center slice (for segmentation) and its neighboring slices. Moreover, CSA-Net
utilizes the self-attention mechanism to understand correlations among pixels
within the center slice. We evaluated CSA-Net on three 2.5D segmentation tasks:
(1) multi-class brain MRI segmentation, (2) binary prostate MRI segmentation,
and (3) multi-class prostate MRI segmentation. CSA-Net outperformed leading 2D
and 2.5D segmentation methods across all three tasks, demonstrating its
efficacy and superiority. Our code is publicly available at
https://github.com/mirthAI/CSA-Net.",2024-04-30,"Amarjeet Kumar, Hongxu Jiang, Muhammad Imran, Cyndi Valdes, Gabriela Leon, Dahyun Kang, Parvathi Nataraj, Yuyin Zhou, Michael D. Weiss, Wei Shao",http://arxiv.org/pdf/2405.00130v1,cs.LG
Graph Neural Network Approach to Semantic Type Detection in Tables,"This study addresses the challenge of detecting semantic column types in
relational tables, a key task in many real-world applications. While language
models like BERT have improved prediction accuracy, their token input
constraints limit the simultaneous processing of intra-table and inter-table
information. We propose a novel approach using Graph Neural Networks (GNNs) to
model intra-table dependencies, allowing language models to focus on
inter-table information. Our proposed method not only outperforms existing
state-of-the-art algorithms but also offers novel insights into the utility and
functionality of various GNN types for semantic type detection. The code is
available at https://github.com/hoseinzadeehsan/GAIT",2024-04-30,"Ehsan Hoseinzade, Ke Wang",http://arxiv.org/pdf/2405.00123v1,cs.LG
Creative Beam Search: LLM-as-a-Judge For Improving Response Generation,"Large language models are revolutionizing several areas, including artificial
creativity. However, the process of generation in machines profoundly diverges
from that observed in humans. In particular, machine generation is
characterized by a lack of intentionality and an underlying creative process.
We propose a method called Creative Beam Search that uses Diverse Beam Search
and LLM-as-a-Judge to perform response generation and response validation. The
results of a qualitative experiment show how our approach can provide better
output than standard sampling techniques. We also show that the response
validation step is a necessary complement to the response generation step.",2024-04-30,"Giorgio Franceschelli, Mirco Musolesi",http://arxiv.org/pdf/2405.00099v4,cs.LG
Structure learning of Hamiltonians from real-time evolution,"We study the problem of Hamiltonian structure learning from real-time
evolution: given the ability to apply $e^{-\mathrm{i} Ht}$ for an unknown local
Hamiltonian $H = \sum_{a = 1}^m \lambda_a E_a$ on $n$ qubits, the goal is to
recover $H$. This problem is already well-understood under the assumption that
the interaction terms, $E_a$, are given, and only the interaction strengths,
$\lambda_a$, are unknown. But how efficiently can we learn a local Hamiltonian
without prior knowledge of its interaction structure?
  We present a new, general approach to Hamiltonian learning that not only
solves the challenging structure learning variant, but also resolves other open
questions in the area, all while achieving the gold standard of
Heisenberg-limited scaling. In particular, our algorithm recovers the
Hamiltonian to $\varepsilon$ error with total evolution time $O(\log
(n)/\varepsilon)$, and has the following appealing properties: (1) it does not
need to know the Hamiltonian terms; (2) it works beyond the short-range
setting, extending to any Hamiltonian $H$ where the sum of terms interacting
with a qubit has bounded norm; (3) it evolves according to $H$ in constant time
$t$ increments, thus achieving constant time resolution. As an application, we
can also learn Hamiltonians exhibiting power-law decay up to accuracy
$\varepsilon$ with total evolution time beating the standard limit of
$1/\varepsilon^2$.",2024-04-30,"Ainesh Bakshi, Allen Liu, Ankur Moitra, Ewin Tang",http://arxiv.org/pdf/2405.00082v3,cs.LG
KAN: Kolmogorov-Arnold Networks,"Inspired by the Kolmogorov-Arnold representation theorem, we propose
Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer
Perceptrons (MLPs). While MLPs have fixed activation functions on nodes
(""neurons""), KANs have learnable activation functions on edges (""weights"").
KANs have no linear weights at all -- every weight parameter is replaced by a
univariate function parametrized as a spline. We show that this seemingly
simple change makes KANs outperform MLPs in terms of accuracy and
interpretability. For accuracy, much smaller KANs can achieve comparable or
better accuracy than much larger MLPs in data fitting and PDE solving.
Theoretically and empirically, KANs possess faster neural scaling laws than
MLPs. For interpretability, KANs can be intuitively visualized and can easily
interact with human users. Through two examples in mathematics and physics,
KANs are shown to be useful collaborators helping scientists (re)discover
mathematical and physical laws. In summary, KANs are promising alternatives for
MLPs, opening opportunities for further improving today's deep learning models
which rely heavily on MLPs.",2024-04-30,"Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y. Hou, Max Tegmark",http://arxiv.org/pdf/2404.19756v5,cs.LG
DOCCI: Descriptions of Connected and Contrasting Images,"Vision-language datasets are vital for both text-to-image (T2I) and
image-to-text (I2T) research. However, current datasets lack descriptions with
fine-grained detail that would allow for richer associations to be learned by
models. To fill the gap, we introduce Descriptions of Connected and Contrasting
Images (DOCCI), a dataset with long, human-annotated English descriptions for
15k images that were taken, curated and donated by a single researcher intent
on capturing key challenges such as spatial relations, counting, text
rendering, world knowledge, and more. We instruct human annotators to create
comprehensive descriptions for each image; these average 136 words in length
and are crafted to clearly distinguish each image from those that are related
or similar. Each description is highly compositional and typically encompasses
multiple challenges. Through both quantitative and qualitative analyses, we
demonstrate that DOCCI serves as an effective training resource for
image-to-text generation -- a PaLI 5B model finetuned on DOCCI shows equal or
superior results compared to highly-performant larger models like LLaVA-1.5 7B
and InstructBLIP 7B. Furthermore, we show that DOCCI is a useful testbed for
text-to-image generation, highlighting the limitations of current text-to-image
models in capturing long descriptions and fine details.",2024-04-30,"Yasumasa Onoe, Sunayana Rane, Zachary Berger, Yonatan Bitton, Jaemin Cho, Roopal Garg, Alexander Ku, Zarana Parekh, Jordi Pont-Tuset, Garrett Tanzer, Su Wang, Jason Baldridge",http://arxiv.org/pdf/2404.19753v1,cs.LG
Scale-Robust Timely Asynchronous Decentralized Learning,"We consider an asynchronous decentralized learning system, which consists of
a network of connected devices trying to learn a machine learning model without
any centralized parameter server. The users in the network have their own local
training data, which is used for learning across all the nodes in the network.
The learning method consists of two processes, evolving simultaneously without
any necessary synchronization. The first process is the model update, where the
users update their local model via a fixed number of stochastic gradient
descent steps. The second process is model mixing, where the users communicate
with each other via randomized gossiping to exchange their models and average
them to reach consensus. In this work, we investigate the staleness criteria
for such a system, which is a sufficient condition for convergence of
individual user models. We show that for network scaling, i.e., when the number
of user devices $n$ is very large, if the gossip capacity of individual users
scales as $\Omega(\log n)$, we can guarantee the convergence of user models in
finite time. Furthermore, we show that the bounded staleness can only be
guaranteed by any distributed opportunistic scheme by $\Omega(n)$ scaling.",2024-04-30,"Purbesh Mitra, Sennur Ulukus",http://arxiv.org/pdf/2404.19749v1,cs.LG
Mixed Continuous and Categorical Flow Matching for 3D De Novo Molecule Generation,"Deep generative models that produce novel molecular structures have the
potential to facilitate chemical discovery. Diffusion models currently achieve
state of the art performance for 3D molecule generation. In this work, we
explore the use of flow matching, a recently proposed generative modeling
framework that generalizes diffusion models, for the task of de novo molecule
generation. Flow matching provides flexibility in model design; however, the
framework is predicated on the assumption of continuously-valued data. 3D de
novo molecule generation requires jointly sampling continuous and categorical
variables such as atom position and atom type. We extend the flow matching
framework to categorical data by constructing flows that are constrained to
exist on a continuous representation of categorical data known as the
probability simplex. We call this extension SimplexFlow. We explore the use of
SimplexFlow for de novo molecule generation. However, we find that, in
practice, a simpler approach that makes no accommodations for the categorical
nature of the data yields equivalent or superior performance. As a result of
these experiments, we present FlowMol, a flow matching model for 3D de novo
generative model that achieves improved performance over prior flow matching
methods, and we raise important questions about the design of prior
distributions for achieving strong performance in flow matching models. Code
and trained models for reproducing this work are available at
https://github.com/dunni3/FlowMol",2024-04-30,"Ian Dunn, David Ryan Koes",http://arxiv.org/pdf/2404.19739v1,cs.LG
Fairness Without Demographics in Human-Centered Federated Learning,"Federated learning (FL) enables collaborative model training while preserving
data privacy, making it suitable for decentralized human-centered AI
applications. However, a significant research gap remains in ensuring fairness
in these systems. Current fairness strategies in FL require knowledge of
bias-creating/sensitive attributes, clashing with FL's privacy principles.
Moreover, in human-centered datasets, sensitive attributes may remain latent.
To tackle these challenges, we present a novel bias mitigation approach
inspired by ""Fairness without Demographics"" in machine learning. The presented
approach achieves fairness without needing knowledge of sensitive attributes by
minimizing the top eigenvalue of the Hessian matrix during training, ensuring
equitable loss landscapes across FL participants. Notably, we introduce a novel
FL aggregation scheme that promotes participating models based on error rates
and loss landscape curvature attributes, fostering fairness across the FL
system. This work represents the first approach to attaining ""Fairness without
Demographics"" in human-centered FL. Through comprehensive evaluation, our
approach demonstrates effectiveness in balancing fairness and efficacy across
various real-world applications, FL setups, and scenarios involving single and
multiple bias-inducing factors, representing a significant advancement in
human-centered FL.",2024-04-30,"Shaily Roy, Harshit Sharma, Asif Salekin",http://arxiv.org/pdf/2404.19725v3,cs.LG
The lazy (NTK) and rich ($μ$P) regimes: a gentle tutorial,"A central theme of the modern machine learning paradigm is that larger neural
networks achieve better performance on a variety of metrics. Theoretical
analyses of these overparameterized models have recently centered around
studying very wide neural networks. In this tutorial, we provide a nonrigorous
but illustrative derivation of the following fact: in order to train wide
networks effectively, there is only one degree of freedom in choosing
hyperparameters such as the learning rate and the size of the initial weights.
This degree of freedom controls the richness of training behavior: at minimum,
the wide network trains lazily like a kernel machine, and at maximum, it
exhibits feature learning in the active $\mu$P regime. In this paper, we
explain this richness scale, synthesize recent research results into a coherent
whole, offer new perspectives and intuitions, and provide empirical evidence
supporting our claims. In doing so, we hope to encourage further study of the
richness scale, as it may be key to developing a scientific theory of feature
learning in practical deep neural networks.",2024-04-30,Dhruva Karkada,http://arxiv.org/pdf/2404.19719v2,cs.LG
A rank decomposition for the topological classification of neural representations,"Neural networks can be thought of as applying a transformation to an input
dataset. The way in which they change the topology of such a dataset often
holds practical significance for many tasks, particularly those demanding
non-homeomorphic mappings for optimal solutions, such as classification
problems. In this work, we leverage the fact that neural networks are
equivalent to continuous piecewise-affine maps, whose rank can be used to
pinpoint regions in the input space that undergo non-homeomorphic
transformations, leading to alterations in the topological structure of the
input dataset. Our approach enables us to make use of the relative homology
sequence, with which one can study the homology groups of the quotient of a
manifold $\mathcal{M}$ and a subset $A$, assuming some minimal properties on
these spaces.
  As a proof of principle, we empirically investigate the presence of low-rank
(topology-changing) affine maps as a function of network width and mean weight.
We show that in randomly initialized narrow networks, there will be regions in
which the (co)homology groups of a data manifold can change. As the width
increases, the homology groups of the input manifold become more likely to be
preserved. We end this part of our work by constructing highly non-random wide
networks that do not have this property and relating this non-random regime to
Dale's principle, which is a defining characteristic of biological neural
networks.
  Finally, we study simple feedforward networks trained on MNIST, as well as on
toy classification and regression tasks, and show that networks manipulate the
topology of data differently depending on the continuity of the task they are
trained on.",2024-04-30,"Kosio Beshkov, Gaute T. Einevoll",http://arxiv.org/pdf/2404.19710v3,cs.LG
Harmonic LLMs are Trustworthy,"We introduce an intuitive method to test the robustness (stability and
explainability) of any black-box LLM in real-time via its local deviation from
harmoniticity, denoted as $\gamma$. To the best of our knowledge this is the
first completely model-agnostic and unsupervised method of measuring the
robustness of any given response from an LLM, based upon the model itself
conforming to a purely mathematical standard. To show general application and
immediacy of results, we measure $\gamma$ in 10 popular LLMs (ChatGPT,
Claude-2.1, Claude3.0, GPT-4, GPT-4o, Smaug-72B, Mixtral-8x7B, Llama2-7B,
Mistral-7B and MPT-7B) across thousands of queries in three objective domains:
WebQA, ProgrammingQA, and TruthfulQA. Across all models and domains tested,
human annotation confirms that $\gamma \to 0$ indicates trustworthiness, and
conversely searching higher values of $\gamma$ easily exposes examples of
hallucination, a fact that enables efficient adversarial prompt generation
through stochastic gradient ascent in $\gamma$. The low-$\gamma$ leaders among
the models in the respective domains are GPT-4o, GPT-4, and Smaug-72B,
providing evidence that mid-size open-source models can win out against large
commercial models.",2024-04-30,"Nicholas S. Kersting, Mohammad Rahman, Suchismitha Vedala, Yang Wang",http://arxiv.org/pdf/2404.19708v2,cs.LG
Feature Purified Transformer With Cross-level Feature Guiding Decoder For Multi-class OOD and Anomaly Deteciton,"Reconstruction networks are prevalently used in unsupervised anomaly and
Out-of-Distribution (OOD) detection due to their independence from labeled
anomaly data. However, in multi-class datasets, the effectiveness of anomaly
detection is often compromised by the models' generalized reconstruction
capabilities, which allow anomalies to blend within the expanded boundaries of
normality resulting from the added categories, thereby reducing detection
accuracy. We introduce the FUTUREG framework, which incorporates two innovative
modules: the Feature Purification Module (FPM) and the CFG Decoder. The FPM
constrains the normality boundary within the latent space to effectively filter
out anomalous features, while the CFG Decoder uses layer-wise encoder
representations to guide the reconstruction of filtered features, preserving
fine-grained details. Together, these modules enhance the reconstruction error
for anomalies, ensuring high-quality reconstructions for normal samples. Our
results demonstrate that FUTUREG achieves state-of-the-art performance in
multi-class OOD settings and remains competitive in industrial anomaly
detection scenarios.",2024-04-30,"Jerry Chun-Wei Lin, Pi-Wei Chen, Chao-Chun Chen",http://arxiv.org/pdf/2406.15396v1,cs.LG
Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners,"3D visual grounding is a challenging task that often requires direct and
dense supervision, notably the semantic label for each object in the scene. In
this paper, we instead study the naturally supervised setting that learns from
only 3D scene and QA pairs, where prior works underperform. We propose the
Language-Regularized Concept Learner (LARC), which uses constraints from
language as regularization to significantly improve the accuracy of
neuro-symbolic concept learners in the naturally supervised setting. Our
approach is based on two core insights: the first is that language constraints
(e.g., a word's relation to another) can serve as effective regularization for
structured representations in neuro-symbolic models; the second is that we can
query large language models to distill such constraints from language
properties. We show that LARC improves performance of prior works in naturally
supervised 3D visual grounding, and demonstrates a wide range of 3D visual
reasoning capabilities-from zero-shot composition, to data efficiency and
transferability. Our method represents a promising step towards regularizing
structured visual reasoning frameworks with language-based priors, for learning
in settings without dense supervision.",2024-04-30,"Chun Feng, Joy Hsu, Weiyu Liu, Jiajun Wu",http://arxiv.org/pdf/2404.19696v1,cs.LG
Recommenadation aided Caching using Combinatorial Multi-armed Bandits,"We study content caching with recommendations in a wireless network where the
users are connected through a base station equipped with a finite-capacity
cache. We assume a fixed set of contents with unknown user preferences and
content popularities. The base station can cache a subset of the contents and
can also recommend subsets of the contents to different users in order to
encourage them to request the recommended contents. Recommendations, depending
on their acceptability, can thus be used to increase cache hits. We first
assume that the users' recommendation acceptabilities are known and formulate
the cache hit optimization problem as a combinatorial multi-armed bandit
(CMAB). We propose a UCB-based algorithm to decide which contents to cache and
recommend and provide an upper bound on the regret of this algorithm.
Subsequently, we consider a more general scenario where the users'
recommendation acceptabilities are also unknown and propose another UCB-based
algorithm that learns these as well. We numerically demonstrate the performance
of our algorithms and compare these to state-of-the-art algorithms.",2024-04-30,"Pavamana K J, Chandramani Kishore Singh",http://arxiv.org/pdf/2405.00080v4,cs.LG
Continuum limit of $p$-biharmonic equations on graphs,"This paper studies the $p$-biharmonic equation on graphs, which arises in
point cloud processing and can be interpreted as a natural extension of the
graph $p$-Laplacian from the perspective of hypergraph. The asymptotic behavior
of the solution is investigated when the random geometric graph is considered
and the number of data points goes to infinity. We show that the continuum
limit is an appropriately weighted $p$-biharmonic equation with homogeneous
Neumann boundary conditions. The result relies on the uniform $L^p$ estimates
for solutions and gradients of nonlocal and graph Poisson equations. The
$L^\infty$ estimates of solutions are also obtained as a byproduct.",2024-04-30,"Kehan Shi, Martin Burger",http://arxiv.org/pdf/2404.19689v2,cs.LG
Neural Controlled Differential Equations with Quantum Hidden Evolutions,"We introduce a class of neural controlled differential equation inspired by
quantum mechanics. Neural quantum controlled differential equations (NQDEs)
model the dynamics by analogue of the Schr\""{o}dinger equation. Specifically,
the hidden state represents the wave function, and its collapse leads to an
interpretation of the classification probability. We implement and compare the
results of four variants of NQDEs on a toy spiral classification problem.",2024-04-30,"Lingyi Yang, Zhen Shao",http://arxiv.org/pdf/2404.19673v2,cs.LG
Towards Generalist Robot Learning from Internet Video: A Survey,"Scaling deep learning to massive, diverse internet data has yielded
remarkably general capabilities in visual and natural language understanding
and generation. However, data has remained scarce and challenging to collect in
robotics, seeing robot learning struggle to obtain similarly general
capabilities. Promising Learning from Videos (LfV) methods aim to address the
robotics data bottleneck by augmenting traditional robot data with large-scale
internet video data. This video data offers broad foundational information
regarding physical behaviour and the underlying physics of the world, and thus
can be highly informative for a generalist robot.
  In this survey, we present a thorough overview of the emerging field of LfV.
We outline fundamental concepts, including the benefits and challenges of LfV.
We provide a comprehensive review of current methods for extracting knowledge
from large-scale internet video, addressing key challenges in LfV, and boosting
downstream robot and reinforcement learning via the use of video data. The
survey concludes with a critical discussion of challenges and opportunities in
LfV. Here, we advocate for scalable foundation model approaches that can
leverage the full range of available internet video to improve the learning of
robot policies and dynamics models. We hope this survey can inform and catalyse
further LfV research, driving progress towards the development of
general-purpose robots.",2024-04-30,"Robert McCarthy, Daniel C. H. Tan, Dominik Schmidt, Fernando Acero, Nathan Herr, Yilun Du, Thomas G. Thuruthel, Zhibin Li",http://arxiv.org/pdf/2404.19664v4,cs.LG
Masked Multi-Query Slot Attention for Unsupervised Object Discovery,"Unsupervised object discovery is becoming an essential line of research for
tackling recognition problems that require decomposing an image into entities,
such as semantic segmentation and object detection. Recently, object-centric
methods that leverage self-supervision have gained popularity, due to their
simplicity and adaptability to different settings and conditions. However,
those methods do not exploit effective techniques already employed in modern
self-supervised approaches. In this work, we consider an object-centric
approach in which DINO ViT features are reconstructed via a set of queried
representations called slots. Based on that, we propose a masking scheme on
input features that selectively disregards the background regions, inducing our
model to focus more on salient objects during the reconstruction phase.
Moreover, we extend the slot attention to a multi-query approach, allowing the
model to learn multiple sets of slots, producing more stable masks. During
training, these multiple sets of slots are learned independently while, at test
time, these sets are merged through Hungarian matching to obtain the final
slots. Our experimental results and ablations on the PASCAL-VOC 2012 dataset
show the importance of each component and highlight how their combination
consistently improves object localization. Our source code is available at:
https://github.com/rishavpramanik/maskedmultiqueryslot",2024-04-30,"Rishav Pramanik, José-Fabian Villa-Vásquez, Marco Pedersoli",http://arxiv.org/pdf/2404.19654v1,cs.LG
Provably Robust Conformal Prediction with Improved Efficiency,"Conformal prediction is a powerful tool to generate uncertainty sets with
guaranteed coverage using any predictive model, under the assumption that the
training and test data are i.i.d.. Recently, it has been shown that adversarial
examples are able to manipulate conformal methods to construct prediction sets
with invalid coverage rates, as the i.i.d. assumption is violated. To address
this issue, a recent work, Randomized Smoothed Conformal Prediction (RSCP), was
first proposed to certify the robustness of conformal prediction methods to
adversarial noise. However, RSCP has two major limitations: (i) its robustness
guarantee is flawed when used in practice and (ii) it tends to produce large
uncertainty sets. To address these limitations, we first propose a novel
framework called RSCP+ to provide provable robustness guarantee in evaluation,
which fixes the issues in the original RSCP method. Next, we propose two novel
methods, Post-Training Transformation (PTT) and Robust Conformal Training
(RCT), to effectively reduce prediction set size with little computation
overhead. Experimental results in CIFAR10, CIFAR100, and ImageNet suggest the
baseline method only yields trivial predictions including full label set, while
our methods could boost the efficiency by up to $4.36\times$, $5.46\times$, and
$16.9\times$ respectively and provide practical robustness guarantee. Our codes
are available at
https://github.com/Trustworthy-ML-Lab/Provably-Robust-Conformal-Prediction.",2024-04-30,"Ge Yan, Yaniv Romano, Tsui-Wei Weng",http://arxiv.org/pdf/2404.19651v1,cs.LG
On Training a Neural Network to Explain Binaries,"In this work, we begin to investigate the possibility of training a deep
neural network on the task of binary code understanding. Specifically, the
network would take, as input, features derived directly from binaries and
output English descriptions of functionality to aid a reverse engineer in
investigating the capabilities of a piece of closed-source software, be it
malicious or benign. Given recent success in applying large language models
(generative AI) to the task of source code summarization, this seems a
promising direction. However, in our initial survey of the available datasets,
we found nothing of sufficiently high quality and volume to train these complex
models. Instead, we build our own dataset derived from a capture of Stack
Overflow containing 1.1M entries. A major result of our work is a novel dataset
evaluation method using the correlation between two distances on sample pairs:
one distance in the embedding space of inputs and the other in the embedding
space of outputs. Intuitively, if two samples have inputs close in the input
embedding space, their outputs should also be close in the output embedding
space. We found this Embedding Distance Correlation (EDC) test to be highly
diagnostic, indicating that our collected dataset and several existing
open-source datasets are of low quality as the distances are not well
correlated. We proceed to explore the general applicability of EDC, applying it
to a number of qualitatively known good datasets and a number of synthetically
known bad ones and found it to be a reliable indicator of dataset value.",2024-04-30,"Alexander Interrante-Grant, Andy Davis, Heather Preslier, Tim Leek",http://arxiv.org/pdf/2404.19631v1,cs.LG
Analyzing and Exploring Training Recipes for Large-Scale Transformer-Based Weather Prediction,"The rapid rise of deep learning (DL) in numerical weather prediction (NWP)
has led to a proliferation of models which forecast atmospheric variables with
comparable or superior skill than traditional physics-based NWP. However, among
these leading DL models, there is a wide variance in both the training settings
and architecture used. Further, the lack of thorough ablation studies makes it
hard to discern which components are most critical to success. In this work, we
show that it is possible to attain high forecast skill even with relatively
off-the-shelf architectures, simple training procedures, and moderate compute
budgets. Specifically, we train a minimally modified SwinV2 transformer on ERA5
data, and find that it attains superior forecast skill when compared against
IFS. We present some ablations on key aspects of the training pipeline,
exploring different loss functions, model sizes and depths, and multi-step
fine-tuning to investigate their effect. We also examine the model performance
with metrics beyond the typical ACC and RMSE, and investigate how the
performance scales with model size.",2024-04-30,"Jared D. Willard, Peter Harrington, Shashank Subramanian, Ankur Mahesh, Travis A. O'Brien, William D. Collins",http://arxiv.org/pdf/2404.19630v1,cs.LG
Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference,"Selection bias in recommender system arises from the recommendation process
of system filtering and the interactive process of user selection. Many
previous studies have focused on addressing selection bias to achieve unbiased
learning of the prediction model, but ignore the fact that potential outcomes
for a given user-item pair may vary with the treatments assigned to other
user-item pairs, named neighborhood effect. To fill the gap, this paper
formally formulates the neighborhood effect as an interference problem from the
perspective of causal inference and introduces a treatment representation to
capture the neighborhood effect. On this basis, we propose a novel ideal loss
that can be used to deal with selection bias in the presence of neighborhood
effect. We further develop two new estimators for estimating the proposed ideal
loss. We theoretically establish the connection between the proposed and
previous debiasing methods ignoring the neighborhood effect, showing that the
proposed methods can achieve unbiased learning when both selection bias and
neighborhood effect are present, while the existing methods are biased.
Extensive semi-synthetic and real-world experiments are conducted to
demonstrate the effectiveness of the proposed methods.",2024-04-30,"Haoxuan Li, Chunyuan Zheng, Sihao Ding, Peng Wu, Zhi Geng, Fuli Feng, Xiangnan He",http://arxiv.org/pdf/2404.19620v1,cs.LG
Data-Driven Invertible Neural Surrogates of Atmospheric Transmission,"We present a framework for inferring an atmospheric transmission profile from
a spectral scene. This framework leverages a lightweight, physics-based
simulator that is automatically tuned - by virtue of autodifferentiation and
differentiable programming - to construct a surrogate atmospheric profile to
model the observed data. We demonstrate utility of the methodology by (i)
performing atmospheric correction, (ii) recasting spectral data between various
modalities (e.g. radiance and reflectance at the surface and at the sensor),
and (iii) inferring atmospheric transmission profiles, such as absorbing bands
and their relative magnitudes.",2024-04-30,"James Koch, Brenda Forland, Bruce Bernacki, Timothy Doster, Tegan Emerson",http://arxiv.org/pdf/2404.19605v1,cs.LG
Debiased Collaborative Filtering with Kernel-Based Causal Balancing,"Debiased collaborative filtering aims to learn an unbiased prediction model
by removing different biases in observational datasets. To solve this problem,
one of the simple and effective methods is based on the propensity score, which
adjusts the observational sample distribution to the target one by reweighting
observed instances. Ideally, propensity scores should be learned with causal
balancing constraints. However, existing methods usually ignore such
constraints or implement them with unreasonable approximations, which may
affect the accuracy of the learned propensity scores. To bridge this gap, in
this paper, we first analyze the gaps between the causal balancing requirements
and existing methods such as learning the propensity with cross-entropy loss or
manually selecting functions to balance. Inspired by these gaps, we propose to
approximate the balancing functions in reproducing kernel Hilbert space and
demonstrate that, based on the universal property and representer theorem of
kernel functions, the causal balancing constraints can be better satisfied.
Meanwhile, we propose an algorithm that adaptively balances the kernel function
and theoretically analyze the generalization error bound of our methods. We
conduct extensive experiments to demonstrate the effectiveness of our methods,
and to promote this research direction, we have released our project at
https://github.com/haoxuanli-pku/ICLR24-Kernel-Balancing.",2024-04-30,"Haoxuan Li, Chunyuan Zheng, Yanghao Xiao, Peng Wu, Zhi Geng, Xu Chen, Peng Cui",http://arxiv.org/pdf/2404.19596v1,cs.LG
"Towards Interactively Improving ML Data Preparation Code via ""Shadow Pipelines""","Data scientists develop ML pipelines in an iterative manner: they repeatedly
screen a pipeline for potential issues, debug it, and then revise and improve
its code according to their findings. However, this manual process is tedious
and error-prone. Therefore, we propose to support data scientists during this
development cycle with automatically derived interactive suggestions for
pipeline improvements. We discuss our vision to generate these suggestions with
so-called shadow pipelines, hidden variants of the original pipeline that
modify it to auto-detect potential issues, try out modifications for
improvements, and suggest and explain these modifications to the user. We
envision to apply incremental view maintenance-based optimisations to ensure
low-latency computation and maintenance of the shadow pipelines. We conduct
preliminary experiments to showcase the feasibility of our envisioned approach
and the potential benefits of our proposed optimisations.",2024-04-30,"Stefan Grafberger, Paul Groth, Sebastian Schelter",http://arxiv.org/pdf/2404.19591v1,cs.LG
URVFL: Undetectable Data Reconstruction Attack on Vertical Federated Learning,"Launching effective malicious attacks in VFL presents unique challenges: 1)
Firstly, given the distributed nature of clients' data features and models,
each client rigorously guards its privacy and prohibits direct querying,
complicating any attempts to steal data; 2) Existing malicious attacks alter
the underlying VFL training task, and are hence easily detected by comparing
the received gradients with the ones received in honest training. To overcome
these challenges, we develop URVFL, a novel attack strategy that evades current
detection mechanisms. The key idea is to integrate a discriminator with
auxiliary classifier that takes a full advantage of the label information and
generates malicious gradients to the victim clients: on one hand, label
information helps to better characterize embeddings of samples from distinct
classes, yielding an improved reconstruction performance; on the other hand,
computing malicious gradients with label information better mimics the honest
training, making the malicious gradients indistinguishable from the honest
ones, and the attack much more stealthy. Our comprehensive experiments
demonstrate that URVFL significantly outperforms existing attacks, and
successfully circumvents SOTA detection methods for malicious attacks.
Additional ablation studies and evaluations on defenses further underscore the
robustness and effectiveness of URVFL. Our code will be available at
https://github.com/duanyiyao/URVFL.",2024-04-30,"Duanyi Yao, Songze Li, Xueluan Gong, Sizai Hou, Gaoning Pan",http://arxiv.org/pdf/2404.19582v2,cs.LG
Automatic Cardiac Pathology Recognition in Echocardiography Images Using Higher Order Dynamic Mode Decomposition and a Vision Transformer for Small Datasets,"Heart diseases are the main international cause of human defunction.
According to the WHO, nearly 18 million people decease each year because of
heart diseases. Also considering the increase of medical data, much pressure is
put on the health industry to develop systems for early and accurate heart
disease recognition. In this work, an automatic cardiac pathology recognition
system based on a novel deep learning framework is proposed, which analyses in
real-time echocardiography video sequences. The system works in two stages. The
first one transforms the data included in a database of echocardiography
sequences into a machine-learning-compatible collection of annotated images
which can be used in the training stage of any kind of machine learning-based
framework, and more specifically with deep learning. This includes the use of
the Higher Order Dynamic Mode Decomposition (HODMD) algorithm, for the first
time to the authors' knowledge, for both data augmentation and feature
extraction in the medical field. The second stage is focused on building and
training a Vision Transformer (ViT), barely explored in the related literature.
The ViT is adapted for an effective training from scratch, even with small
datasets. The designed neural network analyses images from an echocardiography
sequence to predict the heart state. The results obtained show the superiority
of the proposed system and the efficacy of the HODMD algorithm, even
outperforming pretrained Convolutional Neural Networks (CNNs), which are so far
the method of choice in the literature.",2024-04-30,"Andrés Bell-Navas, Nourelhouda Groun, María Villalba-Orero, Enrique Lara-Pezzi, Jesús Garicano-Mena, Soledad Le Clainche",http://arxiv.org/pdf/2404.19579v1,cs.LG
Neural Dynamic Data Valuation,"Data constitute the foundational component of the data economy and its
marketplaces. Efficient and fair data valuation has emerged as a topic of
significant interest.\ Many approaches based on marginal contribution have
shown promising results in various downstream tasks. However, they are well
known to be computationally expensive as they require training a large number
of utility functions, which are used to evaluate the usefulness or value of a
given dataset for a specific purpose. As a result, it has been recognized as
infeasible to apply these methods to a data marketplace involving large-scale
datasets. Consequently, a critical issue arises: how can the re-training of the
utility function be avoided? To address this issue, we propose a novel data
valuation method from the perspective of optimal control, named the neural
dynamic data valuation (NDDV). Our method has solid theoretical interpretations
to accurately identify the data valuation via the sensitivity of the data
optimal control state. In addition, we implement a data re-weighting strategy
to capture the unique features of data points, ensuring fairness through the
interaction between data points and the mean-field states. Notably, our method
requires only training once to estimate the value of all data points,
significantly improving the computational efficiency. We conduct comprehensive
experiments using different datasets and tasks. The results demonstrate that
the proposed NDDV method outperforms the existing state-of-the-art data
valuation methods in accurately identifying data points with either high or low
values and is more computationally efficient.",2024-04-30,"Zhangyong Liang, Huanhuan Gao, Ji Zhang",http://arxiv.org/pdf/2404.19557v3,cs.LG
Physics-Informed Machine Learning On Polar Ice: A Survey,"The mass loss of the polar ice sheets contributes considerably to ongoing
sea-level rise and changing ocean circulation, leading to coastal flooding and
risking the homes and livelihoods of tens of millions of people globally. To
address the complex problem of ice behavior, physical models and data-driven
models have been proposed in the literature. Although traditional physical
models can guarantee physically meaningful results, they have limitations in
producing high-resolution results. On the other hand, data-driven approaches
require large amounts of high-quality and labeled data, which is rarely
available in the polar regions. Hence, as a promising framework that leverages
the advantages of physical models and data-driven methods, physics-informed
machine learning (PIML) has been widely studied in recent years. In this paper,
we review the existing algorithms of PIML, provide our own taxonomy based on
the methods of combining physics and data-driven approaches, and analyze the
advantages of PIML in the aspects of accuracy and efficiency. Further, our
survey discusses some current challenges and highlights future opportunities,
including PIML on sea ice studies, PIML with different combination methods and
backbone networks, and neural operator methods.",2024-04-30,"Zesheng Liu, YoungHyun Koo, Maryam Rahnemoonfar",http://arxiv.org/pdf/2404.19536v1,cs.LG
Generating Robust Counterfactual Witnesses for Graph Neural Networks,"This paper introduces a new class of explanation structures, called robust
counterfactual witnesses (RCWs), to provide robust, both counterfactual and
factual explanations for graph neural networks. Given a graph neural network M,
a robust counterfactual witness refers to the fraction of a graph G that are
counterfactual and factual explanation of the results of M over G, but also
remains so for any ""disturbed"" G by flipping up to k of its node pairs. We
establish the hardness results, from tractable results to co-NP-hardness, for
verifying and generating robust counterfactual witnesses. We study such
structures for GNN-based node classification, and present efficient algorithms
to verify and generate RCWs. We also provide a parallel algorithm to verify and
generate RCWs for large graphs with scalability guarantees. We experimentally
verify our explanation generation process for benchmark datasets, and showcase
their applications.",2024-04-30,"Dazhuo Qiu, Mengying Wang, Arijit Khan, Yinghui Wu",http://arxiv.org/pdf/2404.19519v1,cs.LG
Temporal Graph ODEs for Irregularly-Sampled Time Series,"Modern graph representation learning works mostly under the assumption of
dealing with regularly sampled temporal graph snapshots, which is far from
realistic, e.g., social networks and physical systems are characterized by
continuous dynamics and sporadic observations. To address this limitation, we
introduce the Temporal Graph Ordinary Differential Equation (TG-ODE) framework,
which learns both the temporal and spatial dynamics from graph streams where
the intervals between observations are not regularly spaced. We empirically
validate the proposed approach on several graph benchmarks, showing that TG-ODE
can achieve state-of-the-art performance in irregular graph stream tasks.",2024-04-30,"Alessio Gravina, Daniele Zambon, Davide Bacciu, Cesare Alippi",http://arxiv.org/pdf/2404.19508v1,cs.LG
A Unified Theory of Exact Inference and Learning in Exponential Family Latent Variable Models,"Bayes' rule describes how to infer posterior beliefs about latent variables
given observations, and inference is a critical step in learning algorithms for
latent variable models (LVMs). Although there are exact algorithms for
inference and learning for certain LVMs such as linear Gaussian models and
mixture models, researchers must typically develop approximate inference and
learning algorithms when applying novel LVMs. In this paper we study the line
that separates LVMs that rely on approximation schemes from those that do not,
and develop a general theory of exponential family, latent variable models for
which inference and learning may be implemented exactly. Firstly, under mild
assumptions about the exponential family form of a given LVM, we derive
necessary and sufficient conditions under which the LVM prior is in the same
exponential family as its posterior, such that the prior is conjugate to the
posterior. We show that all models that satisfy these conditions are
constrained forms of a particular class of exponential family graphical model.
We then derive general inference and learning algorithms, and demonstrate them
on a variety of example models. Finally, we show how to compose our models into
graphical models that retain tractable inference and learning. In addition to
our theoretical work, we have implemented our algorithms in a collection of
libraries with which we provide numerous demonstrations of our theory, and with
which researchers may apply our theory in novel statistical settings.",2024-04-30,Sacha Sokoloski,http://arxiv.org/pdf/2404.19501v1,cs.LG
Finetuning greedy kernel models by exchange algorithms,"Kernel based approximation offers versatile tools for high-dimensional
approximation, which can especially be leveraged for surrogate modeling. For
this purpose, both ""knot insertion"" and ""knot removal"" approaches aim at
choosing a suitable subset of the data, in order to obtain a sparse but
nevertheless accurate kernel model. In the present work, focussing on kernel
based interpolation, we aim at combining these two approaches to further
improve the accuracy of kernel models, without increasing the computational
complexity of the final kernel model. For this, we introduce a class of kernel
exchange algorithms (KEA). The resulting KEA algorithm can be used for
finetuning greedy kernel surrogate models, allowing for an reduction of the
error up to 86.4% (17.2% on average) in our experiments.",2024-04-30,"Tizian Wenzel, Armin Iske",http://arxiv.org/pdf/2404.19487v1,cs.LG
Safe Training with Sensitive In-domain Data: Leveraging Data Fragmentation To Mitigate Linkage Attacks,"Current text generation models are trained using real data which can
potentially contain sensitive information, such as confidential patient
information and the like. Under certain conditions output of the training data
which they have memorised can be triggered, exposing sensitive data. To
mitigate against this risk we propose a safer alternative which sees fragmented
data in the form of domain-specific short phrases randomly grouped together
shared instead of full texts. Thus, text fragments that could re-identify an
individual cannot be reproduced by the model in one sequence, giving
significant protection against linkage attacks. We fine-tune several
state-of-the-art LLMs using meaningful syntactic chunks to explore their
utility. In particular, we fine-tune BERT-based models to predict two
cardiovascular diagnoses. Our results demonstrate the capacity of LLMs to
benefit from the pre-trained knowledge and deliver classification results when
fine-tuned with fragmented data comparable to fine-tuning with full training
data.",2024-04-30,"Mariia Ignashina, Julia Ive",http://arxiv.org/pdf/2404.19486v1,cs.LG
More Compute Is What You Need,"Large language model pre-training has become increasingly expensive, with
most practitioners relying on scaling laws to allocate compute budgets for
model size and training tokens, commonly referred to as Compute-Optimal or
Chinchilla Optimal. In this paper, we hypothesize a new scaling law that
suggests model performance depends mostly on the amount of compute spent for
transformer-based models, independent of the specific allocation to model size
and dataset size. Using this unified scaling law, we predict that (a) for
inference efficiency, training should prioritize smaller model sizes and larger
training datasets, and (b) assuming the exhaustion of available web datasets,
scaling the model size might be the only way to further improve model
performance.",2024-04-30,Zhen Guo,http://arxiv.org/pdf/2404.19484v2,cs.LG
Bayesian Functional Connectivity and Graph Convolutional Network for Working Memory Load Classification,"Brain responses related to working memory originate from distinct brain areas
and oscillate at different frequencies. EEG signals with high temporal
correlation can effectively capture these responses. Therefore, estimating the
functional connectivity of EEG for working memory protocols in different
frequency bands plays a significant role in analyzing the brain dynamics with
increasing memory and cognitive loads, which remains largely unexplored. The
present study introduces a Bayesian structure learning algorithm to learn the
functional connectivity of EEG in sensor space. Next, the functional
connectivity graphs are taken as input to the graph convolutional network to
classify the working memory loads. The intrasubject (subject-specific)
classification performed on 154 subjects for six different verbal working
memory loads produced the highest classification accuracy of 96% and average
classification accuracy of 89%, outperforming state-of-the-art classification
models proposed in the literature. Furthermore, the proposed Bayesian structure
learning algorithm is compared with state-of-the-art functional connectivity
estimation methods through intersubject and intrasubject statistical analysis
of variance. The results also show that the alpha and theta bands have better
classification accuracy than the beta band.",2024-04-30,"Harshini Gangapuram, Vidya Manian",http://arxiv.org/pdf/2404.19467v1,cs.LG
Continual Model-based Reinforcement Learning for Data Efficient Wireless Network Optimisation,"We present a method that addresses the pain point of long lead-time required
to deploy cell-level parameter optimisation policies to new wireless network
sites. Given a sequence of action spaces represented by overlapping subsets of
cell-level configuration parameters provided by domain experts, we formulate
throughput optimisation as Continual Reinforcement Learning of control
policies. Simulation results suggest that the proposed system is able to
shorten the end-to-end deployment lead-time by two-fold compared to a
reinitialise-and-retrain baseline without any drop in optimisation gain.",2024-04-30,"Cengis Hasan, Alexandros Agapitos, David Lynch, Alberto Castagna, Giorgio Cruciata, Hao Wang, Aleksandar Milenovic",http://arxiv.org/pdf/2404.19462v1,cs.LG
AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples,"Adversarial examples are typically optimized with gradient-based attacks.
While novel attacks are continuously proposed, each is shown to outperform its
predecessors using different experimental setups, hyperparameter settings, and
number of forward and backward calls to the target models. This provides
overly-optimistic and even biased evaluations that may unfairly favor one
particular attack over the others. In this work, we aim to overcome these
limitations by proposing AttackBench, i.e., the first evaluation framework that
enables a fair comparison among different attacks. To this end, we first
propose a categorization of gradient-based attacks, identifying their main
components and differences. We then introduce our framework, which evaluates
their effectiveness and efficiency. We measure these characteristics by (i)
defining an optimality metric that quantifies how close an attack is to the
optimal solution, and (ii) limiting the number of forward and backward queries
to the model, such that all attacks are compared within a given maximum query
budget. Our extensive experimental analysis compares more than $100$ attack
implementations with a total of over $800$ different configurations against
CIFAR-10 and ImageNet models, highlighting that only very few attacks
outperform all the competing approaches. Within this analysis, we shed light on
several implementation issues that prevent many attacks from finding better
solutions or running at all. We release AttackBench as a publicly-available
benchmark, aiming to continuously update it to include and evaluate novel
gradient-based attacks for optimizing adversarial examples.",2024-04-30,"Antonio Emanuele Cinà, Jérôme Rony, Maura Pintor, Luca Demetrio, Ambra Demontis, Battista Biggio, Ismail Ben Ayed, Fabio Roli",http://arxiv.org/pdf/2404.19460v3,cs.LG
"A Survey of Imitation Learning Methods, Environments and Metrics","Imitation learning is an approach in which an agent learns how to execute a
task by trying to mimic how one or more teachers perform it. This learning
approach offers a compromise between the time it takes to learn a new task and
the effort needed to collect teacher samples for the agent. It achieves this by
balancing learning from the teacher, who has some information on how to perform
the task, and deviating from their examples when necessary, such as states not
present in the teacher samples. Consequently, the field of imitation learning
has received much attention from researchers in recent years, resulting in many
new methods and applications. However, with this increase in published work and
past surveys focusing mainly on methodology, a lack of standardisation became
more prominent in the field. This non-standardisation is evident in the use of
environments, which appear in no more than two works, and evaluation processes,
such as qualitative analysis, that have become rare in current literature. In
this survey, we systematically review current imitation learning literature and
present our findings by (i) classifying imitation learning techniques,
environments and metrics by introducing novel taxonomies; (ii) reflecting on
main problems from the literature; and (iii) presenting challenges and future
directions for researchers.",2024-04-30,"Nathan Gavenski, Felipe Meneguzzi, Michael Luck, Odinaldo Rodrigues",http://arxiv.org/pdf/2404.19456v2,cs.LG
How to Sustainably Monitor ML-Enabled Systems? Accuracy and Energy Efficiency Tradeoffs in Concept Drift Detection,"ML-enabled systems that are deployed in a production environment typically
suffer from decaying model prediction quality through concept drift, i.e., a
gradual change in the statistical characteristics of a certain real-world
domain. To combat this, a simple solution is to periodically retrain ML models,
which unfortunately can consume a lot of energy. One recommended tactic to
improve energy efficiency is therefore to systematically monitor the level of
concept drift and only retrain when it becomes unavoidable. Different methods
are available to do this, but we know very little about their concrete impact
on the tradeoff between accuracy and energy efficiency, as these methods also
consume energy themselves.
  To address this, we therefore conducted a controlled experiment to study the
accuracy vs. energy efficiency tradeoff of seven common methods for concept
drift detection. We used five synthetic datasets, each in a version with abrupt
and one with gradual drift, and trained six different ML models as base
classifiers. Based on a full factorial design, we tested 420 combinations (7
drift detectors * 5 datasets * 2 types of drift * 6 base classifiers) and
compared energy consumption and drift detection accuracy.
  Our results indicate that there are three types of detectors: a) detectors
that sacrifice energy efficiency for detection accuracy (KSWIN), b) balanced
detectors that consume low to medium energy with good accuracy (HDDM_W, ADWIN),
and c) detectors that consume very little energy but are unusable in practice
due to very poor accuracy (HDDM_A, PageHinkley, DDM, EDDM). By providing rich
evidence for this energy efficiency tactic, our findings support ML
practitioners in choosing the best suited method of concept drift detection for
their ML-enabled systems.",2024-04-30,"Rafiullah Omar, Justus Bogner, Joran Leest, Vincenzo Stoico, Patricia Lago, Henry Muccini",http://arxiv.org/pdf/2404.19452v1,cs.LG
BrainODE: Dynamic Brain Signal Analysis via Graph-Aided Neural Ordinary Differential Equations,"Brain network analysis is vital for understanding the neural interactions
regarding brain structures and functions, and identifying potential biomarkers
for clinical phenotypes. However, widely used brain signals such as Blood
Oxygen Level Dependent (BOLD) time series generated from functional Magnetic
Resonance Imaging (fMRI) often manifest three challenges: (1) missing values,
(2) irregular samples, and (3) sampling misalignment, due to instrumental
limitations, impacting downstream brain network analysis and clinical outcome
predictions. In this work, we propose a novel model called BrainODE to achieve
continuous modeling of dynamic brain signals using Ordinary Differential
Equations (ODE). By learning latent initial values and neural ODE functions
from irregular time series, BrainODE effectively reconstructs brain signals at
any time point, mitigating the aforementioned three data challenges of brain
signals altogether. Comprehensive experimental results on real-world
neuroimaging datasets demonstrate the superior performance of BrainODE and its
capability of addressing the three data challenges.",2024-04-30,"Kaiqiao Han, Yi Yang, Zijie Huang, Xuan Kan, Yang Yang, Ying Guo, Lifang He, Liang Zhan, Yizhou Sun, Wei Wang, Carl Yang",http://arxiv.org/pdf/2405.00077v1,cs.LG
Towards trustable SHAP scores,"SHAP scores represent the proposed use of the well-known Shapley values in
eXplainable Artificial Intelligence (XAI). Recent work has shown that the exact
computation of SHAP scores can produce unsatisfactory results. Concretely, for
some ML models, SHAP scores will mislead with respect to relative feature
influence. To address these limitations, recently proposed alternatives exploit
different axiomatic aggregations, all of which are defined in terms of
abductive explanations. However, the proposed axiomatic aggregations are not
Shapley values. This paper investigates how SHAP scores can be modified so as
to extend axiomatic aggregations to the case of Shapley values in XAI. More
importantly, the proposed new definition of SHAP scores avoids all the known
cases where unsatisfactory results have been identified. The paper also
characterizes the complexity of computing the novel definition of SHAP scores,
highlighting families of classifiers for which computing these scores is
tractable. Furthermore, the paper proposes modifications to the existing
implementations of SHAP scores. These modifications eliminate some of the known
limitations of SHAP scores, and have negligible impact in terms of performance.",2024-04-30,"Olivier Letoffe, Xuanxiang Huang, Joao Marques-Silva",http://arxiv.org/pdf/2405.00076v2,cs.LG
Lancet: Accelerating Mixture-of-Experts Training via Whole Graph Computation-Communication Overlapping,"The Mixture-of-Expert (MoE) technique plays a crucial role in expanding the
size of DNN model parameters. However, it faces the challenge of extended
all-to-all communication latency during the training process. Existing methods
attempt to mitigate this issue by overlapping all-to-all with expert
computation. Yet, these methods frequently fall short of achieving sufficient
overlap, consequently restricting the potential for performance enhancements.
In our study, we extend the scope of this challenge by considering overlap at
the broader training graph level. During the forward pass, we enable non-MoE
computations to overlap with all-to-all through careful partitioning and
pipelining. In the backward pass, we achieve overlap with all-to-all by
scheduling gradient weight computations. We implement these techniques in
Lancet, a system using compiler-based optimization to automatically enhance MoE
model training. Our extensive evaluation reveals that Lancet significantly
reduces the time devoted to non-overlapping communication, by as much as 77%.
Moreover, it achieves a notable end-to-end speedup of up to 1.3 times when
compared to the state-of-the-art solutions.",2024-04-30,"Chenyu Jiang, Ye Tian, Zhen Jia, Shuai Zheng, Chuan Wu, Yida Wang",http://arxiv.org/pdf/2404.19429v1,cs.LG
Let's Focus: Focused Backdoor Attack against Federated Transfer Learning,"Federated Transfer Learning (FTL) is the most general variation of Federated
Learning. According to this distributed paradigm, a feature learning pre-step
is commonly carried out by only one party, typically the server, on publicly
shared data. After that, the Federated Learning phase takes place to train a
classifier collaboratively using the learned feature extractor. Each involved
client contributes by locally training only the classification layers on a
private training set. The peculiarity of an FTL scenario makes it hard to
understand whether poisoning attacks can be developed to craft an effective
backdoor. State-of-the-art attack strategies assume the possibility of shifting
the model attention toward relevant features introduced by a forged trigger
injected in the input data by some untrusted clients. Of course, this is not
feasible in FTL, as the learned features are fixed once the server performs the
pre-training step. Consequently, in this paper, we investigate this intriguing
Federated Learning scenario to identify and exploit a vulnerability obtained by
combining eXplainable AI (XAI) and dataset distillation. In particular, the
proposed attack can be carried out by one of the clients during the Federated
Learning phase of FTL by identifying the optimal local for the trigger through
XAI and encapsulating compressed information of the backdoor class. Due to its
behavior, we refer to our approach as a focused backdoor approach (FB-FTL for
short) and test its performance by explicitly referencing an image
classification scenario. With an average 80% attack success rate, obtained
results show the effectiveness of our attack also against existing defenses for
Federated Learning.",2024-04-30,"Marco Arazzi, Stefanos Koffas, Antonino Nocera, Stjepan Picek",http://arxiv.org/pdf/2404.19420v1,cs.LG
Can humans teach machines to code?,"The goal of inductive program synthesis is for a machine to automatically
generate a program from user-supplied examples. A key underlying assumption is
that humans can provide sufficient examples to teach a concept to a machine. To
evaluate the validity of this assumption, we conduct a study where human
participants provide examples for six programming concepts, such as finding the
maximum element of a list. We evaluate the generalisation performance of five
program synthesis systems trained on input-output examples (i) from non-expert
humans, (ii) from a human expert, and (iii) randomly sampled. Our results
suggest that non-experts typically do not provide sufficient examples for a
program synthesis system to learn an accurate program.",2024-04-30,"Céline Hocquette, Johannes Langer, Andrew Cropper, Ute Schmid",http://arxiv.org/pdf/2404.19397v2,cs.LG
Tackling water table depth modeling via machine learning: From proxy observations to verifiability,"Spatial patterns of water table depth (WTD) play a crucial role in shaping
ecological resilience, hydrological connectivity, and human-centric systems.
Generally, a large-scale (e.g., continental or global) continuous map of static
WTD can be simulated using either physically-based (PB) or machine
learning-based (ML) models. We construct three fine-resolution (500 m) ML
simulations of WTD, using the XGBoost algorithm and more than 20 million real
and proxy observations of WTD, across the United States and Canada. The three
ML models were constrained using known physical relations between WTD's drivers
and WTD and were trained by sequentially adding real and proxy observations of
WTD. Through an extensive (pixel-by-pixel) evaluation across the study region
and within ten major ecoregions of North America, we demonstrate that our
models (corr=0.6-0.75) can more accurately predict unseen real and proxy
observations of WTD compared to two available PB simulations of WTD
(corr=0.21-0.40). However, we still argue that currently-available large-scale
simulations of static WTD could be uncertain within data-scarce regions such as
steep mountainous regions. We reason that biased observational data mainly
collected from low-elevation floodplains and the over-flexibility of available
models can negatively affect the verifiability of large-scale simulations of
WTD. Ultimately, we thoroughly discuss future directions that may help
hydrogeologists decide how to improve machine learning-based WTD estimations.
In particular, we advocate for the use of proxy satellite data, the
incorporation of physical laws, the implementation of better model verification
standards, the development of novel globally-available emergent indices, and
the collection of more reliable observations.",2024-04-30,"Joseph Janssen, Ardalan Tootchi, Ali A. Ameli",http://arxiv.org/pdf/2405.04579v3,cs.LG
Numeric Reward Machines,"Reward machines inform reinforcement learning agents about the reward
structure of the environment and often drastically speed up the learning
process. However, reward machines only accept Boolean features such as
robot-reached-gold. Consequently, many inherently numeric tasks cannot profit
from the guidance offered by reward machines. To address this gap, we aim to
extend reward machines with numeric features such as distance-to-gold. For
this, we present two types of reward machines: numeric-Boolean and numeric. In
a numeric-Boolean reward machine, distance-to-gold is emulated by two Boolean
features distance-to-gold-decreased and robot-reached-gold. In a numeric reward
machine, distance-to-gold is used directly alongside the Boolean feature
robot-reached-gold. We compare our new approaches to a baseline reward machine
in the Craft domain, where the numeric feature is the agent-to-target distance.
We use cross-product Q-learning, Q-learning with counter-factual experiences,
and the options framework for learning. Our experimental results show that our
new approaches significantly outperform the baseline approach. Extending reward
machines with numeric features opens up new possibilities of using reward
machines in inherently numeric tasks.",2024-04-30,"Kristina Levina, Nikolaos Pappas, Athanasios Karapantelakis, Aneta Vulgarakis Feljan, Jendrik Seipp",http://arxiv.org/pdf/2404.19370v1,cs.LG
PEFSL: A deployment Pipeline for Embedded Few-Shot Learning on a FPGA SoC,"This paper tackles the challenges of implementing few-shot learning on
embedded systems, specifically FPGA SoCs, a vital approach for adapting to
diverse classification tasks, especially when the costs of data acquisition or
labeling prove to be prohibitively high. Our contributions encompass the
development of an end-to-end open-source pipeline for a few-shot learning
platform for object classification on a FPGA SoCs. The pipeline is built on top
of the Tensil open-source framework, facilitating the design, training,
evaluation, and deployment of DNN backbones tailored for few-shot learning.
Additionally, we showcase our work's potential by building and deploying a
low-power, low-latency demonstrator trained on the MiniImageNet dataset with a
dataflow architecture. The proposed system has a latency of 30 ms while
consuming 6.2 W on the PYNQ-Z1 board.",2024-04-30,"Lucas Grativol Ribeiro, Lubin Gauthier, Mathieu Leonardon, Jérémy Morlier, Antoine Lavrard-Meyer, Guillaume Muller, Virginie Fresse, Matthieu Arzel",http://arxiv.org/pdf/2404.19354v1,cs.LG
Deep Learning Forecasts Caldera Collapse Events at Kilauea Volcano,"During the three month long eruption of Kilauea volcano, Hawaii in 2018, the
pre-existing summit caldera collapsed in over 60 quasi-periodic failure events.
The last 40 of these events, which generated Mw >5 very long period (VLP)
earthquakes, had inter-event times between 0.8 - 2.2 days. These failure events
offer a unique dataset for testing methods for predicting earthquake recurrence
based on locally recorded GPS, tilt, and seismicity data. In this work, we
train a deep learning graph neural network (GNN) to predict the time-to-failure
of the caldera collapse events using only a fraction of the data recorded at
the start of each cycle. We find that the GNN generalizes to unseen data and
can predict the time-to-failure to within a few hours using only 0.5 days of
data, substantially improving upon a null model based only on inter-event
statistics. Predictions improve with increasing input data length, and are most
accurate when using high-SNR tilt-meter data. Applying the trained GNN to
synthetic data with different magma pressure decay times predicts failure at a
nearly constant stress threshold, revealing that the GNN is sensing the
underling physics of caldera collapse. These findings demonstrate the
predictability of caldera collapse sequences under well monitored conditions,
and highlight the potential of machine learning methods for forecasting real
world catastrophic events with limited training data.",2024-04-30,"Ian W. McBrearty, Paul Segall",http://arxiv.org/pdf/2404.19351v2,cs.LG
Human-AI Interaction in Industrial Robotics: Design and Empirical Evaluation of a User Interface for Explainable AI-Based Robot Program Optimization,"While recent advances in deep learning have demonstrated its transformative
potential, its adoption for real-world manufacturing applications remains
limited. We present an Explanation User Interface (XUI) for a state-of-the-art
deep learning-based robot program optimizer which provides both naive and
expert users with different user experiences depending on their skill level, as
well as Explainable AI (XAI) features to facilitate the application of deep
learning methods in real-world applications. To evaluate the impact of the XUI
on task performance, user satisfaction and cognitive load, we present the
results of a preliminary user survey and propose a study design for a
large-scale follow-up study.",2024-04-30,"Benjamin Alt, Johannes Zahn, Claudius Kienle, Julia Dvorak, Marvin May, Darko Katic, Rainer Jäkel, Tobias Kopp, Michael Beetz, Gisela Lanza",http://arxiv.org/pdf/2404.19349v1,cs.LG
Pessimistic Value Iteration for Multi-Task Data Sharing in Offline Reinforcement Learning,"Offline Reinforcement Learning (RL) has shown promising results in learning a
task-specific policy from a fixed dataset. However, successful offline RL often
relies heavily on the coverage and quality of the given dataset. In scenarios
where the dataset for a specific task is limited, a natural approach is to
improve offline RL with datasets from other tasks, namely, to conduct
Multi-Task Data Sharing (MTDS). Nevertheless, directly sharing datasets from
other tasks exacerbates the distribution shift in offline RL. In this paper, we
propose an uncertainty-based MTDS approach that shares the entire dataset
without data selection. Given ensemble-based uncertainty quantification, we
perform pessimistic value iteration on the shared offline dataset, which
provides a unified framework for single- and multi-task offline RL. We further
provide theoretical analysis, which shows that the optimality gap of our method
is only related to the expected data coverage of the shared dataset, thus
resolving the distribution shift issue in data sharing. Empirically, we release
an MTDS benchmark and collect datasets from three challenging domains. The
experimental results show our algorithm outperforms the previous
state-of-the-art methods in challenging MTDS problems. See
https://github.com/Baichenjia/UTDS for the datasets and code.",2024-04-30,"Chenjia Bai, Lingxiao Wang, Jianye Hao, Zhuoran Yang, Bin Zhao, Zhen Wang, Xuelong Li",http://arxiv.org/pdf/2404.19346v1,cs.LG
PAODING: A High-fidelity Data-free Pruning Toolkit for Debloating Pre-trained Neural Networks,"We present PAODING, a toolkit to debloat pretrained neural network models
through the lens of data-free pruning. To preserve the model fidelity, PAODING
adopts an iterative process, which dynamically measures the effect of deleting
a neuron to identify candidates that have the least impact to the output layer.
Our evaluation shows that PAODING can significantly reduce the model size,
generalize on different datasets and models, and meanwhile preserve the model
fidelity in terms of test accuracy and adversarial robustness. PAODING is
publicly available on PyPI via https://pypi.org/project/paoding-dl.",2024-04-30,"Mark Huasong Meng, Hao Guan, Liuhuo Wan, Sin Gee Teo, Guangdong Bai, Jin Song Dong",http://arxiv.org/pdf/2405.00074v1,cs.LG
Comprehensive Forecasting-Based Analysis of Hybrid and Stacked Stateful/ Stateless Models,"Wind speed is a powerful source of renewable energy, which can be used as an
alternative to the non-renewable resources for production of electricity.
Renewable sources are clean, infinite and do not impact the environment
negatively during production of electrical energy. However, while eliciting
electrical energy from renewable resources viz. solar irradiance, wind speed,
hydro should require special planning failing which may result in huge loss of
labour and money for setting up the system. In this paper, we discuss four deep
recurrent neural networks viz. Stacked Stateless LSTM, Stacked Stateless GRU,
Stacked Stateful LSTM and Statcked Stateful GRU which will be used to predict
wind speed on a short-term basis for the airport sites beside two campuses of
Mississippi State University. The paper does a comprehensive analysis of the
performance of the models used describing their architectures and how
efficiently they elicit the results with the help of RMSE values. A detailed
description of the time and space complexities of the above models has also
been discussed.",2024-04-30,Swayamjit Saha,http://arxiv.org/pdf/2404.19306v1,cs.LG
Statistics and explainability: a fruitful alliance,"In this paper, we propose standard statistical tools as a solution to
commonly highlighted problems in the explainability literature. Indeed,
leveraging statistical estimators allows for a proper definition of
explanations, enabling theoretical guarantees and the formulation of evaluation
metrics to quantitatively assess the quality of explanations. This approach
circumvents, among other things, the subjective human assessment currently
prevalent in the literature. Moreover, we argue that uncertainty quantification
is essential for providing robust and trustworthy explanations, and it can be
achieved in this framework through classical statistical procedures such as the
bootstrap. However, it is crucial to note that while Statistics offers valuable
contributions, it is not a panacea for resolving all the challenges. Future
research avenues could focus on open problems, such as defining a purpose for
the explanations or establishing a statistical framework for counterfactual or
adversarial scenarios.",2024-04-30,Valentina Ghidini,http://arxiv.org/pdf/2404.19301v1,cs.LG
Provably Efficient Information-Directed Sampling Algorithms for Multi-Agent Reinforcement Learning,"This work designs and analyzes a novel set of algorithms for multi-agent
reinforcement learning (MARL) based on the principle of information-directed
sampling (IDS). These algorithms draw inspiration from foundational concepts in
information theory, and are proven to be sample efficient in MARL settings such
as two-player zero-sum Markov games (MGs) and multi-player general-sum MGs. For
episodic two-player zero-sum MGs, we present three sample-efficient algorithms
for learning Nash equilibrium. The basic algorithm, referred to as MAIDS,
employs an asymmetric learning structure where the max-player first solves a
minimax optimization problem based on the joint information ratio of the joint
policy, and the min-player then minimizes the marginal information ratio with
the max-player's policy fixed. Theoretical analyses show that it achieves a
Bayesian regret of tilde{O}(sqrt{K}) for K episodes. To reduce the
computational load of MAIDS, we develop an improved algorithm called Reg-MAIDS,
which has the same Bayesian regret bound while enjoying less computational
complexity. Moreover, by leveraging the flexibility of IDS principle in
choosing the learning target, we propose two methods for constructing
compressed environments based on rate-distortion theory, upon which we develop
an algorithm Compressed-MAIDS wherein the learning target is a compressed
environment. Finally, we extend Reg-MAIDS to multi-player general-sum MGs and
prove that it can learn either the Nash equilibrium or coarse correlated
equilibrium in a sample efficient manner.",2024-04-30,"Qiaosheng Zhang, Chenjia Bai, Shuyue Hu, Zhen Wang, Xuelong Li",http://arxiv.org/pdf/2404.19292v1,cs.LG
"On Improving the Algorithm-, Model-, and Data- Efficiency of Self-Supervised Learning","Self-supervised learning (SSL) has developed rapidly in recent years.
However, most of the mainstream methods are computationally expensive and rely
on two (or more) augmentations for each image to construct positive pairs.
Moreover, they mainly focus on large models and large-scale datasets, which
lack flexibility and feasibility in many practical applications. In this paper,
we propose an efficient single-branch SSL method based on non-parametric
instance discrimination, aiming to improve the algorithm, model, and data
efficiency of SSL. By analyzing the gradient formula, we correct the update
rule of the memory bank with improved performance. We further propose a novel
self-distillation loss that minimizes the KL divergence between the probability
distribution and its square root version. We show that this alleviates the
infrequent updating problem in instance discrimination and greatly accelerates
convergence. We systematically compare the training overhead and performance of
different methods in different scales of data, and under different backbones.
Experimental results show that our method outperforms various baselines with
significantly less overhead, and is especially effective for limited amounts of
data and small models.",2024-04-30,"Yun-Hao Cao, Jianxin Wu",http://arxiv.org/pdf/2404.19289v1,cs.LG
Training-free Graph Neural Networks and the Power of Labels as Features,"We propose training-free graph neural networks (TFGNNs), which can be used
without training and can also be improved with optional training, for
transductive node classification. We first advocate labels as features (LaF),
which is an admissible but not explored technique. We show that LaF provably
enhances the expressive power of graph neural networks. We design TFGNNs based
on this analysis. In the experiments, we confirm that TFGNNs outperform
existing GNNs in the training-free setting and converge with much fewer
training iterations than traditional GNNs.",2024-04-30,Ryoma Sato,http://arxiv.org/pdf/2404.19288v2,cs.LG
Approximate Nearest Neighbour Search on Dynamic Datasets: An Investigation,"Approximate k-Nearest Neighbour (ANN) methods are often used for mining
information and aiding machine learning on large scale high-dimensional
datasets. ANN methods typically differ in the index structure used for
accelerating searches, resulting in various recall/runtime trade-off points.
For applications with static datasets, runtime constraints and dataset
properties can be used to empirically select an ANN method with suitable
operating characteristics. However, for applications with dynamic datasets,
which are subject to frequent online changes (like addition of new samples),
there is currently no consensus as to which ANN methods are most suitable.
Traditional evaluation approaches do not consider the computational costs of
updating the index structure, as well as the rate and size of index updates. To
address this, we empirically evaluate 5 popular ANN methods on two main
applications (online data collection and online feature learning) while taking
into account these considerations. Two dynamic datasets are used, derived from
the SIFT1M dataset with 1 million samples and the DEEP1B dataset with 1 billion
samples. The results indicate that the often used k-d trees method is not
suitable on dynamic datasets as it is slower than a straightforward baseline
exhaustive search method. For online data collection, the Hierarchical
Navigable Small World Graphs method achieves a consistent speedup over baseline
across a wide range of recall rates. For online feature learning, the Scalable
Nearest Neighbours method is faster than baseline for recall rates below 75%.",2024-04-30,"Ben Harwood, Amir Dezfouli, Iadine Chades, Conrad Sanderson",http://arxiv.org/pdf/2404.19284v5,cs.LG
MAP-Former: Multi-Agent-Pair Gaussian Joint Prediction,"There is a gap in risk assessment of trajectories between the trajectory
information coming from a traffic motion prediction module and what is actually
needed. Closing this gap necessitates advancements in prediction beyond current
practices. Existing prediction models yield joint predictions of agents' future
trajectories with uncertainty weights or marginal Gaussian probability density
functions (PDFs) for single agents. Although, these methods achieve high
accurate trajectory predictions, they only provide little or no information
about the dependencies of interacting agents. Since traffic is a process of
highly interdependent agents, whose actions directly influence their mutual
behavior, the existing methods are not sufficient to reliably assess the risk
of future trajectories. This paper addresses that gap by introducing a novel
approach to motion prediction, focusing on predicting agent-pair covariance
matrices in a ``scene-centric'' manner, which can then be used to model
Gaussian joint PDFs for all agent-pairs in a scene. We propose a model capable
of predicting those agent-pair covariance matrices, leveraging an enhanced
awareness of interactions. Utilizing the prediction results of our model, this
work forms the foundation for comprehensive risk assessment with statistically
based methods for analyzing agents' relations by their joint PDFs.",2024-04-30,"Marlon Steiner, Marvin Klemp, Christoph Stiller",http://arxiv.org/pdf/2404.19283v1,cs.LG
On the weight dynamics of learning networks,"Neural networks have become a widely adopted tool for tackling a variety of
problems in machine learning and artificial intelligence. In this contribution
we use the mathematical framework of local stability analysis to gain a deeper
understanding of the learning dynamics of feed forward neural networks.
Therefore, we derive equations for the tangent operator of the learning
dynamics of three-layer networks learning regression tasks. The results are
valid for an arbitrary numbers of nodes and arbitrary choices of activation
functions. Applying the results to a network learning a regression task, we
investigate numerically, how stability indicators relate to the final
training-loss. Although the specific results vary with different choices of
initial conditions and activation functions, we demonstrate that it is possible
to predict the final training loss, by monitoring finite-time Lyapunov
exponents or covariant Lyapunov vectors during the training process.",2024-04-30,"Nahal Sharafi, Christoph Martin, Sarah Hallerberg",http://arxiv.org/pdf/2405.00743v1,cs.LG
Federated Graph Learning for EV Charging Demand Forecasting with Personalization Against Cyberattacks,"Mitigating cybersecurity risk in electric vehicle (EV) charging demand
forecasting plays a crucial role in the safe operation of collective EV
chargings, the stability of the power grid, and the cost-effective
infrastructure expansion. However, existing methods either suffer from the data
privacy issue and the susceptibility to cyberattacks or fail to consider the
spatial correlation among different stations. To address these challenges, a
federated graph learning approach involving multiple charging stations is
proposed to collaboratively train a more generalized deep learning model for
demand forecasting while capturing spatial correlations among various stations
and enhancing robustness against potential attacks. Firstly, for better model
performance, a Graph Neural Network (GNN) model is leveraged to characterize
the geographic correlation among different charging stations in a federated
manner. Secondly, to ensure robustness and deal with the data heterogeneity in
a federated setting, a message passing that utilizes a global attention
mechanism to aggregate personalized models for each client is proposed.
Thirdly, by concerning cyberattacks, a special credit-based function is
designed to mitigate potential threats from malicious clients or unwanted
attacks. Extensive experiments on a public EV charging dataset are conducted
using various deep learning techniques and federated learning methods to
demonstrate the prediction accuracy and robustness of the proposed approach.",2024-04-30,"Yi Li, Renyou Xie, Chaojie Li, Yi Wang, Zhaoyang Dong",http://arxiv.org/pdf/2405.00742v1,cs.LG
High dimensional analysis reveals conservative sharpening and a stochastic edge of stability,"Recent empirical and theoretical work has shown that the dynamics of the
large eigenvalues of the training loss Hessian have some remarkably robust
features across models and datasets in the full batch regime. There is often an
early period of progressive sharpening where the large eigenvalues increase,
followed by stabilization at a predictable value known as the edge of
stability. Previous work showed that in the stochastic setting, the eigenvalues
increase more slowly - a phenomenon we call conservative sharpening. We provide
a theoretical analysis of a simple high-dimensional model which shows the
origin of this slowdown. We also show that there is an alternative stochastic
edge of stability which arises at small batch size that is sensitive to the
trace of the Neural Tangent Kernel rather than the large Hessian eigenvalues.
We conduct an experimental study which highlights the qualitative differences
from the full batch phenomenology, and suggests that controlling the stochastic
edge of stability can help optimization.",2024-04-30,"Atish Agarwala, Jeffrey Pennington",http://arxiv.org/pdf/2404.19261v2,cs.LG
"AI, Pluralism, and (Social) Compensation","One strategy in response to pluralistic values in a user population is to
personalize an AI system: if the AI can adapt to the specific values of each
individual, then we can potentially avoid many of the challenges of pluralism.
Unfortunately, this approach creates a significant ethical issue: if there is
an external measure of success for the human-AI team, then the adaptive AI
system may develop strategies (sometimes deceptive) to compensate for its human
teammate. This phenomenon can be viewed as a form of social compensation, where
the AI makes decisions based not on predefined goals but on its human partner's
deficiencies in relation to the team's performance objectives. We provide a
practical ethical analysis of the conditions in which such compensation may
nonetheless be justifiable.",2024-04-30,"Nandhini Swaminathan, David Danks",http://arxiv.org/pdf/2404.19256v2,cs.LG
Improved AutoEncoder with LSTM module and KL divergence,"The task of anomaly detection is to separate anomalous data from normal data
in the dataset. Models such as deep convolutional autoencoder (CAE) network and
deep supporting vector data description (SVDD) model have been universally
employed and have demonstrated significant success in detecting anomalies.
However, the over-reconstruction ability of CAE network for anomalous data can
easily lead to high false negative rate in detecting anomalous data. On the
other hand, the deep SVDD model has the drawback of feature collapse, which
leads to a decrease of detection accuracy for anomalies. To address these
problems, we propose the Improved AutoEncoder with LSTM module and
Kullback-Leibler divergence (IAE-LSTM-KL) model in this paper. An LSTM network
is added after the encoder to memorize feature representations of normal data.
In the meanwhile, the phenomenon of feature collapse can also be mitigated by
penalizing the featured input to SVDD module via KL divergence. The efficacy of
the IAE-LSTM-KL model is validated through experiments on both synthetic and
real-world datasets. Experimental results show that IAE-LSTM-KL model yields
higher detection accuracy for anomalies. In addition, it is also found that the
IAE-LSTM-KL model demonstrates enhanced robustness to contaminated outliers in
the dataset. All code may be found at
https://github.com/crazyn2/IAE-LSTM-KL_codes",2024-04-30,"Wei Huang, Bingyang Zhang, Kaituo Zhang, Hua Gao, Rongchun Wan",http://arxiv.org/pdf/2404.19247v2,cs.LG
Pilot Contamination in Massive MIMO Systems: Challenges and Future Prospects,"Massive multiple input multiple output (M-MIMO) technology plays a pivotal
role in fifth-generation (5G) and beyond communication systems, offering a wide
range of benefits, from increased spectral efficiency (SE) to enhanced energy
efficiency and higher reliability. However, these advantages are contingent
upon precise channel state information (CSI) availability at the base station
(BS). Ensuring precise CSI is challenging due to the constrained size of the
coherence interval and the resulting limitations on pilot sequence length.
Therefore, reusing pilot sequences in adjacent cells introduces pilot
contamination, hindering SE enhancement. This paper reviews recent advancements
and addresses research challenges in mitigating pilot contamination and
improving channel estimation, categorizing the existing research into three
broader categories: pilot assignment schemes, advanced signal processing
methods, and advanced channel estimation techniques. Salient representative
pilot mitigation/assignment techniques are analyzed and compared in each
category. Lastly, possible future research directions are discussed.",2024-04-30,"Muhammad Kamran Saeed, Ashfaq Khokhar, Shakil Ahmed",http://arxiv.org/pdf/2404.19238v1,cs.LG
Weighted Point Set Embedding for Multimodal Contrastive Learning Toward Optimal Similarity Metric,"In typical multimodal contrastive learning, such as CLIP, encoders produce
one point in the latent representation space for each input. However, one-point
representation has difficulty in capturing the relationship and the similarity
structure of a huge amount of instances in the real world. For richer classes
of the similarity, we propose the use of weighted point sets, namely, sets of
pairs of weight and vector, as representations of instances. In this work, we
theoretically show the benefit of our proposed method through a new
understanding of the contrastive loss of CLIP, which we call symmetric InfoNCE.
We clarify that the optimal similarity that minimizes symmetric InfoNCE is the
pointwise mutual information, and show an upper bound of excess risk on
downstream classification tasks of representations that achieve the optimal
similarity. In addition, we show that our proposed similarity based on weighted
point sets consistently achieves the optimal similarity. To verify the
effectiveness of our proposed method, we demonstrate pretraining of text-image
representation models and classification tasks on common benchmarks.",2024-04-30,"Toshimitsu Uesaka, Taiji Suzuki, Yuhta Takida, Chieh-Hsin Lai, Naoki Murata, Yuki Mitsufuji",http://arxiv.org/pdf/2404.19228v3,cs.LG
Regression for matrix-valued data via Kronecker products factorization,"We study the matrix-variate regression problem $Y_i = \sum_{k} \beta_{1k} X_i
\beta_{2k}^{\top} + E_i$ for $i=1,2\dots,n$ in the high dimensional regime
wherein the response $Y_i$ are matrices whose dimensions $p_{1}\times p_{2}$
outgrow both the sample size $n$ and the dimensions $q_{1}\times q_{2}$ of the
predictor variables $X_i$ i.e., $q_{1},q_{2} \ll n \ll p_{1},p_{2}$. We propose
an estimation algorithm, termed KRO-PRO-FAC, for estimating the parameters
$\{\beta_{1k}\} \subset \Re^{p_1 \times q_1}$ and $\{\beta_{2k}\} \subset
\Re^{p_2 \times q_2}$ that utilizes the Kronecker product factorization and
rearrangement operations from Van Loan and Pitsianis (1993). The KRO-PRO-FAC
algorithm is computationally efficient as it does not require estimating the
covariance between the entries of the $\{Y_i\}$. We establish perturbation
bounds between $\hat{\beta}_{1k} -\beta_{1k}$ and $\hat{\beta}_{2k} -
\beta_{2k}$ in spectral norm for the setting where either the rows of $E_i$ or
the columns of $E_i$ are independent sub-Gaussian random vectors. Numerical
studies on simulated and real data indicate that our procedure is competitive,
in terms of both estimation error and predictive accuracy, compared to other
existing methods.",2024-04-30,"Yin-Jen Chen, Minh Tang",http://arxiv.org/pdf/2404.19220v1,cs.LG
Flight Trajectory Prediction Using an Enhanced CNN-LSTM Network,"Aiming at the problem of low accuracy of flight trajectory prediction caused
by the high speed of fighters, the diversity of tactical maneuvers, and the
transient nature of situational change in close range air combat, this paper
proposes an enhanced CNN-LSTM network as a fighter flight trajectory prediction
method. Firstly, we extract spatial features from fighter trajectory data using
CNN, aggregate spatial features of multiple fighters using the social-pooling
module to capture geographic information and positional relationships in the
trajectories, and use the attention mechanism to capture mutated trajectory
features in air combat; subsequently, we extract temporal features by using the
memory nature of LSTM to capture long-term temporal dependence in the
trajectories; and finally, we merge the temporal and spatial features to
predict the flight trajectories of enemy fighters. Extensive simulation
experiments verify that the proposed method improves the trajectory prediction
accuracy compared to the original CNN-LSTM method, with the improvements of 32%
and 34% in ADE and FDE indicators.",2024-04-30,"Qinzhi Hao, Jiali Zhang, Tengyu Jing, Wei Wang",http://arxiv.org/pdf/2404.19218v1,cs.LG
Modeling Caption Diversity in Contrastive Vision-Language Pretraining,"There are a thousand ways to caption an image. Contrastive Language
Pretraining (CLIP) on the other hand, works by mapping an image and its caption
to a single vector -- limiting how well CLIP-like models can represent the
diverse ways to describe an image. In this work, we introduce Llip, Latent
Language Image Pretraining, which models the diversity of captions that could
match an image. Llip's vision encoder outputs a set of visual features that are
mixed into a final representation by conditioning on information derived from
the text. We show that Llip outperforms non-contextualized baselines like CLIP
and SigLIP on a variety of tasks even with large-scale encoders. Llip improves
zero-shot classification by an average of 2.9% zero-shot classification
benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot
top-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by
1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by
6.0%. We provide a comprehensive analysis of the components introduced by the
method and demonstrate that Llip leads to richer visual representations.",2024-04-30,"Samuel Lavoie, Polina Kirichenko, Mark Ibrahim, Mahmoud Assran, Andrew Gordon Wilson, Aaron Courville, Nicolas Ballas",http://arxiv.org/pdf/2405.00740v4,cs.LG
Why does Knowledge Distillation Work? Rethink its Attention and Fidelity Mechanism,"Does Knowledge Distillation (KD) really work? Conventional wisdom viewed it
as a knowledge transfer procedure where a perfect mimicry of the student to its
teacher is desired. However, paradoxical studies indicate that closely
replicating the teacher's behavior does not consistently improve student
generalization, posing questions on its possible causes. Confronted with this
gap, we hypothesize that diverse attentions in teachers contribute to better
student generalization at the expense of reduced fidelity in ensemble KD
setups. By increasing data augmentation strengths, our key findings reveal a
decrease in the Intersection over Union (IoU) of attentions between teacher
models, leading to reduced student overfitting and decreased fidelity. We
propose this low-fidelity phenomenon as an underlying characteristic rather
than a pathology when training KD. This suggests that stronger data
augmentation fosters a broader perspective provided by the divergent teacher
ensemble and lower student-teacher mutual information, benefiting
generalization performance. These insights clarify the mechanism on
low-fidelity phenomenon in KD. Thus, we offer new perspectives on optimizing
student model performance, by emphasizing increased diversity in teacher
attentions and reduced mimicry behavior between teachers and student.",2024-04-30,"Chenqi Guo, Shiwei Zhong, Xiaofeng Liu, Qianli Feng, Yinglong Ma",http://arxiv.org/pdf/2405.00739v1,cs.LG
DelGrad: Exact event-based gradients for training delays and weights on spiking neuromorphic hardware,"Spiking neural networks (SNNs) inherently rely on the timing of signals for
representing and processing information. Incorporating trainable transmission
delays, alongside synaptic weights, is crucial for shaping these temporal
dynamics. While recent methods have shown the benefits of training delays and
weights in terms of accuracy and memory efficiency, they rely on discrete time,
approximate gradients, and full access to internal variables like membrane
potentials. This limits their precision, efficiency, and suitability for
neuromorphic hardware due to increased memory requirements and I/O bandwidth
demands. To address these challenges, we propose DelGrad, an analytical,
event-based method to compute exact loss gradients for both synaptic weights
and delays. The inclusion of delays in the training process emerges naturally
within our proposed formalism, enriching the model's search space with a
temporal dimension. Moreover, DelGrad, grounded purely in spike timing,
eliminates the need to track additional variables such as membrane potentials.
To showcase this key advantage, we demonstrate the functionality and benefits
of DelGrad on the BrainScaleS-2 neuromorphic platform, by training SNNs in a
chip-in-the-loop fashion. For the first time, we experimentally demonstrate the
memory efficiency and accuracy benefits of adding delays to SNNs on noisy
mixed-signal hardware. Additionally, these experiments also reveal the
potential of delays for stabilizing networks against noise. DelGrad opens a new
way for training SNNs with delays on neuromorphic hardware, which results in
fewer required parameters, higher accuracy and ease of hardware training.",2024-04-30,"Julian Göltz, Jimmy Weber, Laura Kriener, Sebastian Billaudelle, Peter Lake, Johannes Schemmel, Melika Payvand, Mihai A. Petrovici",http://arxiv.org/pdf/2404.19165v3,cs.LG
Scalable Bayesian Inference in the Era of Deep Learning: From Gaussian Processes to Deep Neural Networks,"Large neural networks trained on large datasets have become the dominant
paradigm in machine learning. These systems rely on maximum likelihood point
estimates of their parameters, precluding them from expressing model
uncertainty. This may result in overconfident predictions and it prevents the
use of deep learning models for sequential decision making. This thesis
develops scalable methods to equip neural networks with model uncertainty. In
particular, we leverage the linearised Laplace approximation to equip
pre-trained neural networks with the uncertainty estimates provided by their
tangent linear models. This turns the problem of Bayesian inference in neural
networks into one of Bayesian inference in conjugate Gaussian-linear models.
Alas, the cost of this remains cubic in either the number of network parameters
or in the number of observations times output dimensions. By assumption,
neither are tractable. We address this intractability by using stochastic
gradient descent (SGD) -- the workhorse algorithm of deep learning -- to
perform posterior sampling in linear models and their convex duals: Gaussian
processes. With this, we turn back to linearised neural networks, finding the
linearised Laplace approximation to present a number of incompatibilities with
modern deep learning practices -- namely, stochastic optimisation, early
stopping and normalisation layers -- when used for hyperparameter learning. We
resolve these and construct a sample-based EM algorithm for scalable
hyperparameter learning with linearised neural networks. We apply the above
methods to perform linearised neural network inference with ResNet-50 (25M
parameters) trained on Imagenet (1.2M observations and 1000 output dimensions).
Additionally, we apply our methods to estimate uncertainty for 3d tomographic
reconstructions obtained with the deep image prior network.",2024-04-29,Javier Antoran,http://arxiv.org/pdf/2404.19157v1,cs.LG
Orthogonal Bootstrap: Efficient Simulation of Input Uncertainty,"Bootstrap is a popular methodology for simulating input uncertainty. However,
it can be computationally expensive when the number of samples is large. We
propose a new approach called \textbf{Orthogonal Bootstrap} that reduces the
number of required Monte Carlo replications. We decomposes the target being
simulated into two parts: the \textit{non-orthogonal part} which has a
closed-form result known as Infinitesimal Jackknife and the \textit{orthogonal
part} which is easier to be simulated. We theoretically and numerically show
that Orthogonal Bootstrap significantly reduces the computational cost of
Bootstrap while improving empirical accuracy and maintaining the same width of
the constructed interval.",2024-04-29,"Kaizhao Liu, Jose Blanchet, Lexing Ying, Yiping Lu",http://arxiv.org/pdf/2404.19145v2,cs.LG
Micro-Macro Spatial-Temporal Graph-based Encoder-Decoder for Map-Constrained Trajectory Recovery,"Recovering intermediate missing GPS points in a sparse trajectory, while
adhering to the constraints of the road network, could offer deep insights into
users' moving behaviors in intelligent transportation systems. Although recent
studies have demonstrated the advantages of achieving map-constrained
trajectory recovery via an end-to-end manner, they still face two significant
challenges. Firstly, existing methods are mostly sequence-based models. It is
extremely hard for them to comprehensively capture the micro-semantics of
individual trajectory, including the information of each GPS point and the
movement between two GPS points. Secondly, existing approaches ignore the
impact of the macro-semantics, i.e., the road conditions and the people's
shared travel preferences reflected by a group of trajectories. To address the
above challenges, we propose a Micro-Macro Spatial-Temporal Graph-based
Encoder-Decoder (MM-STGED). Specifically, we model each trajectory as a graph
to efficiently describe the micro-semantics of trajectory and design a novel
message-passing mechanism to learn trajectory representations. Additionally, we
extract the macro-semantics of trajectories and further incorporate them into a
well-designed graph-based decoder to guide trajectory recovery. Extensive
experiments conducted on sparse trajectories with three different sampling
intervals that are respectively constructed from two real-world trajectory
datasets demonstrate the superiority of our proposed model.",2024-04-29,"Tonglong Wei, Youfang Lin, Yan Lin, Shengnan Guo, Lan Zhang, Huaiyu Wan",http://arxiv.org/pdf/2404.19141v1,cs.LG
Integrating Present and Past in Unsupervised Continual Learning,"We formulate a unifying framework for unsupervised continual learning (UCL),
which disentangles learning objectives that are specific to the present and the
past data, encompassing stability, plasticity, and cross-task consolidation.
The framework reveals that many existing UCL approaches overlook cross-task
consolidation and try to balance plasticity and stability in a shared embedding
space. This results in worse performance due to a lack of within-task data
diversity and reduced effectiveness in learning the current task. Our method,
Osiris, which explicitly optimizes all three objectives on separate embedding
spaces, achieves state-of-the-art performance on all benchmarks, including two
novel benchmarks proposed in this paper featuring semantically structured task
sequences. Compared to standard benchmarks, these two structured benchmarks
more closely resemble visual signals received by humans and animals when
navigating real-world environments. Finally, we show some preliminary evidence
that continual models can benefit from such realistic learning scenarios.",2024-04-29,"Yipeng Zhang, Laurent Charlin, Richard Zemel, Mengye Ren",http://arxiv.org/pdf/2404.19132v2,cs.LG
SpherE: Expressive and Interpretable Knowledge Graph Embedding for Set Retrieval,"Knowledge graphs (KGs), which store an extensive number of relational facts
(head, relation, tail), serve various applications. While many downstream tasks
highly rely on the expressive modeling and predictive embedding of KGs, most of
the current KG representation learning methods, where each entity is embedded
as a vector in the Euclidean space and each relation is embedded as a
transformation, follow an entity ranking protocol. On one hand, such an
embedding design cannot capture many-to-many relations. On the other hand, in
many retrieval cases, the users wish to get an exact set of answers without any
ranking, especially when the results are expected to be precise, e.g., which
genes cause an illness. Such scenarios are commonly referred to as ""set
retrieval"". This work presents a pioneering study on the KG set retrieval
problem. We show that the set retrieval highly depends on expressive modeling
of many-to-many relations, and propose a new KG embedding model SpherE to
address this problem. SpherE is based on rotational embedding methods, but each
entity is embedded as a sphere instead of a vector. While inheriting the high
interpretability of rotational-based models, our SpherE can more expressively
model one-to-many, many-to-one, and many-to-many relations. Through extensive
experiments, we show that our SpherE can well address the set retrieval problem
while still having a good predictive ability to infer missing facts. The code
is available at https://github.com/Violet24K/SpherE.",2024-04-29,"Zihao Li, Yuyi Ao, Jingrui He",http://arxiv.org/pdf/2404.19130v1,cs.LG
Q-GroundCAM: Quantifying Grounding in Vision Language Models via GradCAM,"Vision and Language Models (VLMs) continue to demonstrate remarkable
zero-shot (ZS) performance across various tasks. However, many probing studies
have revealed that even the best-performing VLMs struggle to capture aspects of
compositional scene understanding, lacking the ability to properly ground and
localize linguistic phrases in images. Recent VLM advancements include scaling
up both model and dataset sizes, additional training objectives and levels of
supervision, and variations in the model architectures. To characterize the
grounding ability of VLMs, such as phrase grounding, referring expressions
comprehension, and relationship understanding, Pointing Game has been used as
an evaluation metric for datasets with bounding box annotations. In this paper,
we introduce a novel suite of quantitative metrics that utilize GradCAM
activations to rigorously evaluate the grounding capabilities of pre-trained
VLMs like CLIP, BLIP, and ALBEF. These metrics offer an explainable and
quantifiable approach for a more detailed comparison of the zero-shot
capabilities of VLMs and enable measuring models' grounding uncertainty. This
characterization reveals interesting tradeoffs between the size of the model,
the dataset size, and their performance.",2024-04-29,"Navid Rajabi, Jana Kosecka",http://arxiv.org/pdf/2404.19128v1,cs.LG
Enhancing IoT Security: A Novel Feature Engineering Approach for ML-Based Intrusion Detection Systems,"The integration of Internet of Things (IoT) applications in our daily lives
has led to a surge in data traffic, posing significant security challenges. IoT
applications using cloud and edge computing are at higher risk of cyberattacks
because of the expanded attack surface from distributed edge and cloud
services, the vulnerability of IoT devices, and challenges in managing security
across interconnected systems leading to oversights. This led to the rise of
ML-based solutions for intrusion detection systems (IDSs), which have proven
effective in enhancing network security and defending against diverse threats.
However, ML-based IDS in IoT systems encounters challenges, particularly from
noisy, redundant, and irrelevant features in varied IoT datasets, potentially
impacting its performance. Therefore, reducing such features becomes crucial to
enhance system performance and minimize computational costs. This paper focuses
on improving the effectiveness of ML-based IDS at the edge level by introducing
a novel method to find a balanced trade-off between cost and accuracy through
the creation of informative features in a two-tier edge-user IoT environment. A
hybrid Binary Quantum-inspired Artificial Bee Colony and Genetic Programming
algorithm is utilized for this purpose. Three IoT intrusion detection datasets,
namely NSL-KDD, UNSW-NB15, and BoT-IoT, are used for the evaluation of the
proposed approach.",2024-04-29,"Afsaneh Mahanipour, Hana Khamfroush",http://arxiv.org/pdf/2404.19114v1,cs.LG
HLSTransform: Energy-Efficient Llama 2 Inference on FPGAs Via High Level Synthesis,"Graphics Processing Units (GPUs) have become the leading hardware accelerator
for deep learning applications and are used widely in training and inference of
transformers; transformers have achieved state-of-the-art performance in many
areas of machine learning and are especially used in most modern Large Language
Models (LLMs). However, GPUs require large amounts of energy, which poses
environmental concerns, demands high operational costs, and causes GPUs to be
unsuitable for edge computing. We develop an accelerator for transformers,
namely, Llama 2, an open-source state-of-the-art LLM, using high level
synthesis (HLS) on Field Programmable Gate Arrays (FPGAs). HLS allows us to
rapidly prototype FPGA designs without writing code at the register-transfer
level (RTL). We name our method HLSTransform, and the FPGA designs we
synthesize with HLS achieve up to a 12.75x reduction and 8.25x reduction in
energy used per token on the Xilinx Virtex UltraScale+ VU9P FPGA compared to an
Intel Xeon Broadwell E5-2686 v4 CPU and NVIDIA RTX 3090 GPU respectively, while
increasing inference speeds by up to 2.46x compared to CPU and maintaining
0.53x the speed of an RTX 3090 GPU despite the GPU's 4 times higher base clock
rate. With the lack of existing open-source FPGA accelerators for transformers,
we open-source our code and document our steps for synthesis. We hope this work
will serve as a step in democratizing the use of FPGAs in transformer inference
and inspire research into energy-efficient inference methods as a whole. The
code can be found on https://github.com/HLSTransform/submission.",2024-04-29,"Andy He, Darren Key, Mason Bulling, Andrew Chang, Skyler Shapiro, Everett Lee",http://arxiv.org/pdf/2405.00738v1,cs.LG
Source-Free Domain Adaptation of Weakly-Supervised Object Localization Models for Histology,"Given the emergence of deep learning, digital pathology has gained popularity
for cancer diagnosis based on histology images. Deep weakly supervised object
localization (WSOL) models can be trained to classify histology images
according to cancer grade and identify regions of interest (ROIs) for
interpretation, using inexpensive global image-class annotations. A WSOL model
initially trained on some labeled source image data can be adapted using
unlabeled target data in cases of significant domain shifts caused by
variations in staining, scanners, and cancer type. In this paper, we focus on
source-free (unsupervised) domain adaptation (SFDA), a challenging problem
where a pre-trained source model is adapted to a new target domain without
using any source domain data for privacy and efficiency reasons. SFDA of WSOL
models raises several challenges in histology, most notably because they are
not intended to adapt for both classification and localization tasks. In this
paper, 4 state-of-the-art SFDA methods, each one representative of a main SFDA
family, are compared for WSOL in terms of classification and localization
accuracy. They are the SFDA-Distribution Estimation, Source HypOthesis
Transfer, Cross-Domain Contrastive Learning, and Adaptively Domain Statistics
Alignment. Experimental results on the challenging Glas (smaller, breast
cancer) and Camelyon16 (larger, colon cancer) histology datasets indicate that
these SFDA methods typically perform poorly for localization after adaptation
when optimized for classification.",2024-04-29,"Alexis Guichemerre, Soufiane Belharbi, Tsiry Mayet, Shakeeb Murtaza, Pourya Shamsolmoali, Luke McCaffrey, Eric Granger",http://arxiv.org/pdf/2404.19113v2,cs.LG
Hidden Synergy: $L_1$ Weight Normalization and 1-Path-Norm Regularization,"We present PSiLON Net, an MLP architecture that uses $L_1$ weight
normalization for each weight vector and shares the length parameter across the
layer. The 1-path-norm provides a bound for the Lipschitz constant of a neural
network and reflects on its generalizability, and we show how PSiLON Net's
design drastically simplifies the 1-path-norm, while providing an inductive
bias towards efficient learning and near-sparse parameters. We propose a
pruning method to achieve exact sparsity in the final stages of training, if
desired. To exploit the inductive bias of residual networks, we present a
simplified residual block, leveraging concatenated ReLU activations. For
networks constructed with such blocks, we prove that considering only a subset
of possible paths in the 1-path-norm is sufficient to bound the Lipschitz
constant. Using the 1-path-norm and this improved bound as regularizers, we
conduct experiments in the small data regime using overparameterized PSiLON
Nets and PSiLON ResNets, demonstrating reliable optimization and strong
performance.",2024-04-29,Aditya Biswas,http://arxiv.org/pdf/2404.19112v1,cs.LG
The Shape of Money Laundering: Subgraph Representation Learning on the Blockchain with the Elliptic2 Dataset,"Subgraph representation learning is a technique for analyzing local
structures (or shapes) within complex networks. Enabled by recent developments
in scalable Graph Neural Networks (GNNs), this approach encodes relational
information at a subgroup level (multiple connected nodes) rather than at a
node level of abstraction. We posit that certain domain applications, such as
anti-money laundering (AML), are inherently subgraph problems and mainstream
graph techniques have been operating at a suboptimal level of abstraction. This
is due in part to the scarcity of annotated datasets of real-world size and
complexity, as well as the lack of software tools for managing subgraph GNN
workflows at scale. To enable work in fundamental algorithms as well as domain
applications in AML and beyond, we introduce Elliptic2, a large graph dataset
containing 122K labeled subgraphs of Bitcoin clusters within a background graph
consisting of 49M node clusters and 196M edge transactions. The dataset
provides subgraphs known to be linked to illicit activity for learning the set
of ""shapes"" that money laundering exhibits in cryptocurrency and accurately
classifying new criminal activity. Along with the dataset we share our graph
techniques, software tooling, promising early experimental results, and new
domain insights already gleaned from this approach. Taken together, we find
immediate practical value in this approach and the potential for a new standard
in anti-money laundering and forensic analytics in cryptocurrencies and other
financial networks.",2024-04-29,"Claudio Bellei, Muhua Xu, Ross Phillips, Tom Robinson, Mark Weber, Tim Kaler, Charles E. Leiserson, Arvind, Jie Chen",http://arxiv.org/pdf/2404.19109v3,cs.LG
Predicting Fairness of ML Software Configurations,"This paper investigates the relationships between hyperparameters of machine
learning and fairness. Data-driven solutions are increasingly used in critical
socio-technical applications where ensuring fairness is important. Rather than
explicitly encoding decision logic via control and data structures, the ML
developers provide input data, perform some pre-processing, choose ML
algorithms, and tune hyperparameters (HPs) to infer a program that encodes the
decision logic. Prior works report that the selection of HPs can significantly
influence fairness. However, tuning HPs to find an ideal trade-off between
accuracy, precision, and fairness has remained an expensive and tedious task.
Can we predict fairness of HP configuration for a given dataset? Are the
predictions robust to distribution shifts?
  We focus on group fairness notions and investigate the HP space of 5 training
algorithms. We first find that tree regressors and XGBoots significantly
outperformed deep neural networks and support vector machines in accurately
predicting the fairness of HPs. When predicting the fairness of ML
hyperparameters under temporal distribution shift, the tree regressors
outperforms the other algorithms with reasonable accuracy. However, the
precision depends on the ML training algorithm, dataset, and protected
attributes. For example, the tree regressor model was robust for training data
shift from 2014 to 2018 on logistic regression and discriminant analysis HPs
with sex as the protected attribute; but not for race and other training
algorithms. Our method provides a sound framework to efficiently perform
fine-tuning of ML training algorithms and understand the relationships between
HPs and fairness.",2024-04-29,"Salvador Robles Herrera, Verya Monjezi, Vladik Kreinovich, Ashutosh Trivedi, Saeid Tizpaz-Niari",http://arxiv.org/pdf/2404.19100v2,cs.LG
Catalyzing Social Interactions in Mixed Reality using ML Recommendation Systems,"We create an innovative mixed reality-first social recommendation model,
utilizing features uniquely collected through mixed reality (MR) systems to
promote social interaction, such as gaze recognition, proximity, noise level,
congestion level, and conversational intensity. We further extend these models
to include right-time features to deliver timely notifications. We measure
performance metrics across various models by creating a new intersection of
user features, MR features, and right-time features. We create four model types
trained on different combinations of the feature classes, where we compare the
baseline model trained on the class of user features against the models trained
on MR features, right-time features, and a combination of all of the feature
classes. Due to limitations in data collection and cost, we observe performance
degradation in the right-time, mixed reality, and combination models. Despite
these challenges, we introduce optimizations to improve accuracy across all
models by over 14 percentage points, where the best performing model achieved
24% greater accuracy.",2024-04-29,"Sparsh Srivastava, Rohan Arora",http://arxiv.org/pdf/2404.19095v1,cs.LG
In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery,"State of the art Symbolic Regression (SR) methods currently build specialized
models, while the application of Large Language Models (LLMs) remains largely
unexplored. In this work, we introduce the first comprehensive framework that
utilizes LLMs for the task of SR. We propose In-Context Symbolic Regression
(ICSR), an SR method which iteratively refines a functional form with an LLM
and determines its coefficients with an external optimizer. ICSR leverages
LLMs' strong mathematical prior both to propose an initial set of possible
functions given the observations and to refine them based on their errors. Our
findings reveal that LLMs are able to successfully find symbolic equations that
fit the given data, matching or outperforming the overall performance of the
best SR baselines on four popular benchmarks, while yielding simpler equations
with better out of distribution generalization.",2024-04-29,"Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, Pekka Marttinen",http://arxiv.org/pdf/2404.19094v2,cs.LG
Deep Reinforcement Learning for Advanced Longitudinal Control and Collision Avoidance in High-Risk Driving Scenarios,"Existing Advanced Driver Assistance Systems primarily focus on the vehicle
directly ahead, often overlooking potential risks from following vehicles. This
oversight can lead to ineffective handling of high risk situations, such as
high speed, closely spaced, multi vehicle scenarios where emergency braking by
one vehicle might trigger a pile up collision. To overcome these limitations,
this study introduces a novel deep reinforcement learning based algorithm for
longitudinal control and collision avoidance. This proposed algorithm
effectively considers the behavior of both leading and following vehicles. Its
implementation in simulated high risk scenarios, which involve emergency
braking in dense traffic where traditional systems typically fail, has
demonstrated the algorithm ability to prevent potential pile up collisions,
including those involving heavy duty vehicles.",2024-04-29,"Dianwei Chen, Yaobang Gong, Xianfeng Yang",http://arxiv.org/pdf/2404.19087v2,cs.LG
Distributed Stochastic Optimization of a Neural Representation Network for Time-Space Tomography Reconstruction,"4D time-space reconstruction of dynamic events or deforming objects using
X-ray computed tomography (CT) is an important inverse problem in
non-destructive evaluation. Conventional back-projection based reconstruction
methods assume that the object remains static for the duration of several tens
or hundreds of X-ray projection measurement images (reconstruction of
consecutive limited-angle CT scans). However, this is an unrealistic assumption
for many in-situ experiments that causes spurious artifacts and inaccurate
morphological reconstructions of the object. To solve this problem, we propose
to perform a 4D time-space reconstruction using a distributed implicit neural
representation (DINR) network that is trained using a novel distributed
stochastic training algorithm. Our DINR network learns to reconstruct the
object at its output by iterative optimization of its network parameters such
that the measured projection images best match the output of the CT forward
measurement model. We use a forward measurement model that is a function of the
DINR outputs at a sparsely sampled set of continuous valued 4D object
coordinates. Unlike previous neural representation architectures that forward
and back propagate through dense voxel grids that sample the object's entire
time-space coordinates, we only propagate through the DINR at a small subset of
object coordinates in each iteration resulting in an order-of-magnitude
reduction in memory and compute for training. DINR leverages distributed
computation across several compute nodes and GPUs to produce high-fidelity 4D
time-space reconstructions. We use both simulated parallel-beam and
experimental cone-beam X-ray CT datasets to demonstrate the superior
performance of our approach.",2024-04-29,"K. Aditya Mohan, Massimiliano Ferrucci, Chuck Divin, Garrett A. Stevenson, Hyojin Kim",http://arxiv.org/pdf/2404.19075v2,cs.LG
Learning Sparse High-Dimensional Matrix-Valued Graphical Models From Dependent Data,"We consider the problem of inferring the conditional independence graph (CIG)
of a sparse, high-dimensional, stationary matrix-variate Gaussian time series.
All past work on high-dimensional matrix graphical models assumes that
independent and identically distributed (i.i.d.) observations of the
matrix-variate are available. Here we allow dependent observations. We consider
a sparse-group lasso-based frequency-domain formulation of the problem with a
Kronecker-decomposable power spectral density (PSD), and solve it via an
alternating direction method of multipliers (ADMM) approach. The problem is
bi-convex which is solved via flip-flop optimization. We provide sufficient
conditions for local convergence in the Frobenius norm of the inverse PSD
estimators to the true value. This result also yields a rate of convergence. We
illustrate our approach using numerical examples utilizing both synthetic and
real data.",2024-04-29,Jitendra K Tugnait,http://arxiv.org/pdf/2404.19073v1,cs.LG
HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models,"Recent research on instructable agents has used memory-augmented Large
Language Models (LLMs) as task planners, a technique that retrieves
language-program examples relevant to the input instruction and uses them as
in-context examples in the LLM prompt to improve the performance of the LLM in
inferring the correct action and task plans. In this technical report, we
extend the capabilities of HELPER, by expanding its memory with a wider array
of examples and prompts, and by integrating additional APIs for asking
questions. This simple expansion of HELPER into a shared memory enables the
agent to work across the domains of executing plans from dialogue, natural
language instruction following, active question asking, and commonsense room
reorganization. We evaluate the agent on four diverse interactive
visual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the
Tidy Task. HELPER-X achieves few-shot, state-of-the-art performance across
these benchmarks using a single agent, without requiring in-domain training,
and remains competitive with agents that have undergone in-domain training.",2024-04-29,"Gabriel Sarch, Sahil Somani, Raghav Kapoor, Michael J. Tarr, Katerina Fragkiadaki",http://arxiv.org/pdf/2404.19065v1,cs.LG
What is Reproducibility in Artificial Intelligence and Machine Learning Research?,"In the rapidly evolving fields of Artificial Intelligence (AI) and Machine
Learning (ML), the reproducibility crisis underscores the urgent need for clear
validation methodologies to maintain scientific integrity and encourage
advancement. The crisis is compounded by the prevalent confusion over
validation terminology. In response to this challenge, we introduce a framework
that clarifies the roles and definitions of key validation efforts:
repeatability, dependent and independent reproducibility, and direct and
conceptual replicability. This structured framework aims to provide AI/ML
researchers with the necessary clarity on these essential concepts,
facilitating the appropriate design, conduct, and interpretation of validation
studies. By articulating the nuances and specific roles of each type of
validation study, we aim to enhance the reliability and trustworthiness of
research findings and support the community's efforts to address
reproducibility challenges effectively.",2024-04-29,"Abhyuday Desai, Mohamed Abdelhamid, Nakul R. Padalkar",http://arxiv.org/pdf/2407.10239v2,cs.LG
Stylus: Automatic Adapter Selection for Diffusion Models,"Beyond scaling base models with more data or parameters, fine-tuned adapters
provide an alternative way to generate high fidelity, custom images at reduced
costs. As such, adapters have been widely adopted by open-source communities,
accumulating a database of over 100K adapters-most of which are highly
customized with insufficient descriptions. This paper explores the problem of
matching the prompt to a set of relevant adapters, built on recent work that
highlight the performance gains of composing adapters. We introduce Stylus,
which efficiently selects and automatically composes task-specific adapters
based on a prompt's keywords. Stylus outlines a three-stage approach that first
summarizes adapters with improved descriptions and embeddings, retrieves
relevant adapters, and then further assembles adapters based on prompts'
keywords by checking how well they fit the prompt. To evaluate Stylus, we
developed StylusDocs, a curated dataset featuring 75K adapters with
pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion
checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as
preferred, with humans and multimodal models as evaluators, over the base
model. See stylus-diffusion.github.io for more.",2024-04-29,"Michael Luo, Justin Wong, Brandon Trabucco, Yanping Huang, Joseph E. Gonzalez, Zhifeng Chen, Ruslan Salakhutdinov, Ion Stoica",http://arxiv.org/pdf/2404.18928v1,cs.LG
Point Cloud Models Improve Visual Robustness in Robotic Learners,"Visual control policies can encounter significant performance degradation
when visual conditions like lighting or camera position differ from those seen
during training -- often exhibiting sharp declines in capability even for minor
differences. In this work, we examine robustness to a suite of these types of
visual changes for RGB-D and point cloud based visual control policies. To
perform these experiments on both model-free and model-based reinforcement
learners, we introduce a novel Point Cloud World Model (PCWM) and point cloud
based control policies. Our experiments show that policies that explicitly
encode point clouds are significantly more robust than their RGB-D
counterparts. Further, we find our proposed PCWM significantly outperforms
prior works in terms of sample efficiency during training. Taken together,
these results suggest reasoning about the 3D scene through point clouds can
improve performance, reduce learning time, and increase robustness for robotic
learners. Project Webpage: https://pvskand.github.io/projects/PCWM",2024-04-29,"Skand Peri, Iain Lee, Chanho Kim, Li Fuxin, Tucker Hermans, Stefan Lee",http://arxiv.org/pdf/2404.18926v1,cs.LG
DPO Meets PPO: Reinforced Token Optimization for RLHF,"In the classical Reinforcement Learning from Human Feedback (RLHF) framework,
Proximal Policy Optimization (PPO) is employed to learn from sparse,
sentence-level rewards -- a challenging scenario in traditional deep
reinforcement learning. Despite the great successes of PPO in the alignment of
large language models, its open-source implementation is still largely
sub-optimal. To address these issues, we introduce a framework that models RLHF
problems as a Markov decision process (MDP), enabling the capture of
fine-grained token-wise information. Under this framework, we introduce an
algorithm Reinforced Token Optimization (\texttt{RTO}), which learns the
token-wise reward function from preference data and performs policy
optimization based on this learned token-wise reward signal. Theoretically,
\texttt{RTO} is proven to have the capability of finding the near-optimal
policy sample-efficiently. For its practical implementation, \texttt{RTO}
innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,
originally derived from sparse sentence rewards, surprisingly provides us with
a token-wise characterization of response quality, which is seamlessly
incorporated into our subsequent PPO training stage. Extensive experiments
demonstrate that \texttt{RTO} performs better than PPO and other direct
preference learning algorithms. In particular, RTO outperforms PPO by 7.5
points on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our code
and models are available at
\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}.",2024-04-29,"Han Zhong, Zikang Shan, Guhao Feng, Wei Xiong, Xinle Cheng, Li Zhao, Di He, Jiang Bian, Liwei Wang",http://arxiv.org/pdf/2404.18922v4,cs.LG
Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting,"Speculative decoding has demonstrated its effectiveness in accelerating the
inference of large language models while maintaining a consistent sampling
distribution. However, the conventional approach of training a separate draft
model to achieve a satisfactory token acceptance rate can be costly. Drawing
inspiration from early exiting, we propose a novel self-speculative decoding
framework \emph{Kangaroo}, which uses a fixed shallow sub-network as a
self-draft model, with the remaining layers serving as the larger target model.
We train a lightweight and efficient adapter module on top of the sub-network
to bridge the gap between the sub-network and the full model's representation
ability. It is noteworthy that the inference latency of the self-draft model
may no longer be negligible compared to the large model, necessitating
strategies to increase the token acceptance rate while minimizing the drafting
steps of the small model. To address this challenge, we introduce an additional
early exiting mechanism for generating draft tokens. Specifically, we halt the
small model's subsequent prediction during the drafting phase once the
confidence level for the current token falls below a certain threshold.
Extensive experiments on the Spec-Bench demonstrate the effectiveness of
Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to
$1.68\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\% fewer additional
parameters (67M compared to 591M). The code for Kangaroo is available at
https://github.com/Equationliu/Kangaroo.",2024-04-29,"Fangcheng Liu, Yehui Tang, Zhenhua Liu, Yunsheng Ni, Kai Han, Yunhe Wang",http://arxiv.org/pdf/2404.18911v1,cs.LG
Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty,"To overcome the sim-to-real gap in reinforcement learning (RL), learned
policies must maintain robustness against environmental uncertainties. While
robust RL has been widely studied in single-agent regimes, in multi-agent
environments, the problem remains understudied -- despite the fact that the
problems posed by environmental uncertainties are often exacerbated by
strategic interactions. This work focuses on learning in distributionally
robust Markov games (RMGs), a robust variant of standard Markov games, wherein
each agent aims to learn a policy that maximizes its own worst-case performance
when the deployed environment deviates within its own prescribed uncertainty
set. This results in a set of robust equilibrium strategies for all agents that
align with classic notions of game-theoretic equilibria. Assuming a
non-adaptive sampling mechanism from a generative model, we propose a
sample-efficient model-based algorithm (DRNVI) with finite-sample complexity
guarantees for learning robust variants of various notions of game-theoretic
equilibria. We also establish an information-theoretic lower bound for solving
RMGs, which confirms the near-optimal sample complexity of DRNVI with respect
to problem-dependent factors such as the size of the state space, the target
accuracy, and the horizon length.",2024-04-29,"Laixi Shi, Eric Mazumdar, Yuejie Chi, Adam Wierman",http://arxiv.org/pdf/2404.18909v3,cs.LG
Detecting critical treatment effect bias in small subgroups,"Randomized trials are considered the gold standard for making informed
decisions in medicine, yet they often lack generalizability to the patient
populations in clinical practice. Observational studies, on the other hand,
cover a broader patient population but are prone to various biases. Thus,
before using an observational study for decision-making, it is crucial to
benchmark its treatment effect estimates against those derived from a
randomized trial. We propose a novel strategy to benchmark observational
studies beyond the average treatment effect. First, we design a statistical
test for the null hypothesis that the treatment effects estimated from the two
studies, conditioned on a set of relevant features, differ up to some
tolerance. We then estimate an asymptotically valid lower bound on the maximum
bias strength for any subgroup in the observational study. Finally, we validate
our benchmarking strategy in a real-world setting and show that it leads to
conclusions that align with established medical knowledge.",2024-04-29,"Piersilvio De Bartolomeis, Javier Abad, Konstantin Donhauser, Fanny Yang",http://arxiv.org/pdf/2404.18905v2,cs.LG
Overcoming Knowledge Barriers: Online Imitation Learning from Visual Observation with Pretrained World Models,"Pretraining and finetuning models has become increasingly popular in
decision-making. But there are still serious impediments in Imitation Learning
from Observation (ILfO) with pretrained models. This study identifies two
primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration
Knowledge Barrier (DKB). The EKB emerges due to the pretrained models'
limitations in handling novel observations, which leads to inaccurate action
inference. Conversely, the DKB stems from the reliance on limited demonstration
datasets, restricting the model's adaptability across diverse scenarios. We
propose separate solutions to overcome each barrier and apply them to Action
Inference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new
algorithm, AIME-NoB, integrates online interactions and a data-driven
regulariser to mitigate the EKB. Additionally, it uses a surrogate reward
function to broaden the policy's supported states, addressing the DKB. Our
experiments on vision-based control tasks from the DeepMind Control Suite and
MetaWorld benchmarks show that AIME-NoB significantly improves sample
efficiency and converged performance, presenting a robust framework for
overcoming the challenges in ILfO with pretrained models. Code available at
https://github.com/IcarusWizard/AIME-NoB.",2024-04-29,"Xingyuan Zhang, Philip Becker-Ehmck, Patrick van der Smagt, Maximilian Karl",http://arxiv.org/pdf/2404.18896v2,cs.LG
Learning general Gaussian mixtures with efficient score matching,"We study the problem of learning mixtures of $k$ Gaussians in $d$ dimensions.
We make no separation assumptions on the underlying mixture components: we only
require that the covariance matrices have bounded condition number and that the
means and covariances lie in a ball of bounded radius. We give an algorithm
that draws $d^{\mathrm{poly}(k/\varepsilon)}$ samples from the target mixture,
runs in sample-polynomial time, and constructs a sampler whose output
distribution is $\varepsilon$-far from the unknown mixture in total variation.
Prior works for this problem either (i) required exponential runtime in the
dimension $d$, (ii) placed strong assumptions on the instance (e.g., spherical
covariances or clusterability), or (iii) had doubly exponential dependence on
the number of components $k$.
  Our approach departs from commonly used techniques for this problem like the
method of moments. Instead, we leverage a recently developed reduction, based
on diffusion models, from distribution learning to a supervised learning task
called score matching. We give an algorithm for the latter by proving a
structural result showing that the score function of a Gaussian mixture can be
approximated by a piecewise-polynomial function, and there is an efficient
algorithm for finding it. To our knowledge, this is the first example of
diffusion models achieving a state-of-the-art theoretical guarantee for an
unsupervised learning task.",2024-04-29,"Sitan Chen, Vasilis Kontonis, Kulin Shah",http://arxiv.org/pdf/2404.18893v2,cs.LG
IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation,"The scarcity of labeled data in real-world scenarios is a critical bottleneck
of deep learning's effectiveness. Semi-supervised semantic segmentation has
been a typical solution to achieve a desirable tradeoff between annotation cost
and segmentation performance. However, previous approaches, whether based on
consistency regularization or self-training, tend to neglect the contextual
knowledge embedded within inter-pixel relations. This negligence leads to
suboptimal performance and limited generalization. In this paper, we propose a
novel approach IPixMatch designed to mine the neglected but valuable
Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch
is constructed as an extension of the standard teacher-student network,
incorporating additional loss terms to capture inter-pixel relations. It shines
in low-data regimes by efficiently leveraging the limited labeled data and
extracting maximum utility from the available unlabeled data. Furthermore,
IPixMatch can be integrated seamlessly into most teacher-student frameworks
without the need of model modification or adding additional components. Our
straightforward IPixMatch method demonstrates consistent performance
improvements across various benchmark datasets under different partitioning
protocols.",2024-04-29,"Kebin Wu, Wenbin Li, Xiaofei Xiao",http://arxiv.org/pdf/2404.18891v1,cs.LG
A Survey on Diffusion Models for Time Series and Spatio-Temporal Data,"The study of time series is crucial for understanding trends and anomalies
over time, enabling predictive insights across various sectors. Spatio-temporal
data, on the other hand, is vital for analyzing phenomena in both space and
time, providing a dynamic perspective on complex system interactions. Recently,
diffusion models have seen widespread application in time series and
spatio-temporal data mining. Not only do they enhance the generative and
inferential capabilities for sequential and temporal data, but they also extend
to other downstream tasks. In this survey, we comprehensively and thoroughly
review the use of diffusion models in time series and spatio-temporal data,
categorizing them by model category, task type, data modality, and practical
application domain. In detail, we categorize diffusion models into
unconditioned and conditioned types and discuss time series and spatio-temporal
data separately. Unconditioned models, which operate unsupervised, are
subdivided into probability-based and score-based models, serving predictive
and generative tasks such as forecasting, anomaly detection, classification,
and imputation. Conditioned models, on the other hand, utilize extra
information to enhance performance and are similarly divided for both
predictive and generative tasks. Our survey extensively covers their
application in various fields, including healthcare, recommendation, climate,
energy, audio, and transportation, providing a foundational understanding of
how these models analyze and generate data. Through this structured overview,
we aim to provide researchers and practitioners with a comprehensive
understanding of diffusion models for time series and spatio-temporal data
analysis, aiming to direct future innovations and applications by addressing
traditional challenges and exploring innovative solutions within the diffusion
model framework.",2024-04-29,"Yiyuan Yang, Ming Jin, Haomin Wen, Chaoli Zhang, Yuxuan Liang, Lintao Ma, Yi Wang, Chenghao Liu, Bin Yang, Zenglin Xu, Jiang Bian, Shirui Pan, Qingsong Wen",http://arxiv.org/pdf/2404.18886v3,cs.LG
Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking,"Data augmentation techniques apply transformations to existing texts to
generate additional data. The transformations may produce low-quality texts,
where the meaning of the text is changed and the text may even be mangled
beyond human comprehension. Analyzing the synthetically generated texts and
their corresponding labels is slow and demanding. To winnow out texts with
incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection
technique. INSPECTOR combines the strengths of provenance tracking techniques
with assistive labeling. INSPECTOR allows users to group related texts by their
transformation provenance, i.e., the transformations applied to the original
text, or feature provenance, the linguistic features of the original text. For
assistive labeling, INSPECTOR computes metrics that approximate data quality,
and allows users to compare the corresponding label of each text against the
predictions of a large language model. In a user study, INSPECTOR increases the
number of texts with correct labels identified by 3X on a sentiment analysis
task and by 4X on a hate speech detection task. The participants found grouping
the synthetically generated texts by their common transformation to be the most
useful technique. Surprisingly, grouping texts by common linguistic features
was perceived to be unhelpful. Contrary to prior work, our study finds that no
single technique obviates the need for human inspection effort. This validates
the design of INSPECTOR which combines both analysis of data provenance and
assistive labeling to reduce human inspection effort.",2024-04-29,"Hong Jin Kang, Fabrice Harel-Canada, Muhammad Ali Gulzar, Violet Peng, Miryung Kim",http://arxiv.org/pdf/2404.18881v1,cs.LG
Learning Mixtures of Gaussians Using Diffusion Models,"We give a new algorithm for learning mixtures of $k$ Gaussians (with identity
covariance in $\mathbb{R}^n$) to TV error $\varepsilon$, with quasi-polynomial
($O(n^{\text{poly\,log}\left(\frac{n+k}{\varepsilon}\right)})$) time and sample
complexity, under a minimum weight assumption. Our results extend to continuous
mixtures of Gaussians where the mixing distribution is supported on a union of
$k$ balls of constant radius. In particular, this applies to the case of
Gaussian convolutions of distributions on low-dimensional manifolds, or more
generally sets with small covering number, for which no sub-exponential
algorithm was previously known. Unlike previous approaches, most of which are
algebraic in nature, our approach is analytic and relies on the framework of
diffusion models. Diffusion models are a modern paradigm for generative
modeling, which typically rely on learning the score function (gradient
log-pdf) along a process transforming a pure noise distribution, in our case a
Gaussian, to the data distribution. Despite their dazzling performance in tasks
such as image generation, there are few end-to-end theoretical guarantees that
they can efficiently learn nontrivial families of distributions; we give some
of the first such guarantees. We proceed by deriving higher-order Gaussian
noise sensitivity bounds for the score functions for a Gaussian mixture to show
that that they can be inductively learned using piecewise polynomial regression
(up to poly-logarithmic degree), and combine this with known convergence
results for diffusion models.",2024-04-29,"Khashayar Gatmiry, Jonathan Kelner, Holden Lee",http://arxiv.org/pdf/2404.18869v2,cs.LG
FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition,"Despite their exceptional performance on various tasks after fine-tuning,
pre-trained language models (PLMs) face significant challenges due to growing
privacy concerns with data in centralized training methods. We consider
federated learning (FL) to fine-tune PLMs in this paper. However, the
substantial number of parameters in PLMs poses significant difficulties for
client devices with limited communication and computational resources. One
promising solution is to exploit parameter-efficient fine-tuning (PEFT) into
FL, which trains a much smaller set of parameters than full parameter
fine-tuning (FFT). Although remarkably improving training efficiency, PEFT
methods may lead to degraded performance especially when data across different
clients are non i.i.d, as revealed by experimental results. To overcome this,
we propose FeDeRA, which extends and improves a widely used PEFT method, i.e.,
low-rank adaption (LoRA). FeDeRA follows LoRA by decomposing the weight
matrices of the PLMs into low-rank matrices, which allows for more efficient
computation and parameter updates during fine-tuning. Different from LoRA which
simply initializes these low-rank matrices by random sampling or zeros, the
proposed FeDeRA initializes these matrices by the results of performing
singular value decomposition (SVD) on the pre-trained weight matrices.
Extensive experiments across various tasks and datasets show that FeDeRA
outperforms the considered PEFT baselines and is comparable to or even
surpasses FFT method within the FL setting in terms of task performance.
Moreover, FeDeRA requires only 1% trainable paramentes compared to FFT,
significantly reducing training time costs by more than 90% to achieve the same
task performance level. The experimental results also highlight the robustness
of FeDeRA against data heterogeneity, as it maintains stable task performance
even as data heterogeneity increases.",2024-04-29,"Yuxuan Yan, Qianqian Yang, Shunpu Tang, Zhiguo Shi",http://arxiv.org/pdf/2404.18848v3,cs.LG
Fast Quantum Process Tomography via Riemannian Gradient Descent,"Constrained optimization plays a crucial role in the fields of quantum
physics and quantum information science and becomes especially challenging for
high-dimensional complex structure problems. One specific issue is that of
quantum process tomography, in which the goal is to retrieve the underlying
quantum process based on a given set of measurement data. In this paper, we
introduce a modified version of stochastic gradient descent on a Riemannian
manifold that integrates recent advancements in numerical methods for
Riemannian optimization. This approach inherently supports the physically
driven constraints of a quantum process, takes advantage of state-of-the-art
large-scale stochastic objective optimization, and has superior performance to
traditional approaches such as maximum likelihood estimation and projected
least squares. The data-driven approach enables accurate, order-of-magnitude
faster results, and works with incomplete data. We demonstrate our approach on
simulations of quantum processes and in hardware by characterizing an
engineered process on quantum computers.",2024-04-29,"Daniel Volya, Andrey Nikitin, Prabhat Mishra",http://arxiv.org/pdf/2404.18840v1,cs.LG
Harmonic Machine Learning Models are Robust,"We introduce Harmonic Robustness, a powerful and intuitive method to test the
robustness of any machine-learning model either during training or in black-box
real-time inference monitoring without ground-truth labels. It is based on
functional deviation from the harmonic mean value property, indicating
instability and lack of explainability. We show implementation examples in
low-dimensional trees and feedforward NNs, where the method reliably identifies
overfitting, as well as in more complex high-dimensional models such as
ResNet-50 and Vision Transformer where it efficiently measures adversarial
vulnerability across image classes.",2024-04-29,"Nicholas S. Kersting, Yi Li, Aman Mohanty, Oyindamola Obisesan, Raphael Okochu",http://arxiv.org/pdf/2404.18825v1,cs.LG
Benchmarking Benchmark Leakage in Large Language Models,"Amid the expanding use of pre-training data, the phenomenon of benchmark
dataset leakage has become increasingly prominent, exacerbated by opaque
training processes and the often undisclosed inclusion of supervised data in
contemporary Large Language Models (LLMs). This issue skews benchmark
effectiveness and fosters potentially unfair comparisons, impeding the field's
healthy development. To address this, we introduce a detection pipeline
utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that
gauge a model's prediction precision on benchmark, to identify potential data
leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we
reveal substantial instances of training even test set misuse, resulting in
potentially unfair comparisons. These findings prompt us to offer several
recommendations regarding model documentation, benchmark setup, and future
evaluations. Notably, we propose the ""Benchmark Transparency Card"" to encourage
clear documentation of benchmark utilization, promoting transparency and
healthy developments of LLMs. we have made our leaderboard, pipeline
implementation, and model predictions publicly available, fostering future
research.",2024-04-29,"Ruijie Xu, Zengzhi Wang, Run-Ze Fan, Pengfei Liu",http://arxiv.org/pdf/2404.18824v1,cs.LG
Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies,"A continuous rise in the penetration of renewable energy sources, along with
the use of the single imbalance pricing, provides a new opportunity for balance
responsible parties to reduce their cost through energy arbitrage in the
imbalance settlement mechanism. Model-free reinforcement learning (RL) methods
are an appropriate choice for solving the energy arbitrage problem due to their
outstanding performance in solving complex stochastic sequential problems.
However, RL is rarely deployed in real-world applications since its learned
policy does not necessarily guarantee safety during the execution phase. In
this paper, we propose a new RL-based control framework for batteries to obtain
a safe energy arbitrage strategy in the imbalance settlement mechanism. In our
proposed control framework, the agent initially aims to optimize the arbitrage
revenue. Subsequently, in the post-processing step, we correct (constrain) the
learned policy following a knowledge distillation process based on properties
that follow human intuition. Our post-processing step is a generic method and
is not restricted to the energy arbitrage domain. We use the Belgian imbalance
price of 2023 to evaluate the performance of our proposed framework.
Furthermore, we deploy our proposed control framework on a real battery to show
its capability in the real world.",2024-04-29,"Seyed Soroush Karimi Madahi, Gargya Gokhale, Marie-Sophie Verwee, Bert Claessens, Chris Develder",http://arxiv.org/pdf/2404.18821v2,cs.LG
Safe Reach Set Computation via Neural Barrier Certificates,"We present a novel technique for online safety verification of autonomous
systems, which performs reachability analysis efficiently for both bounded and
unbounded horizons by employing neural barrier certificates. Our approach uses
barrier certificates given by parameterized neural networks that depend on a
given initial set, unsafe sets, and time horizon. Such networks are trained
efficiently offline using system simulations sampled from regions of the state
space. We then employ a meta-neural network to generalize the barrier
certificates to state space regions that are outside the training set. These
certificates are generated and validated online as sound over-approximations of
the reachable states, thus either ensuring system safety or activating
appropriate alternative actions in unsafe scenarios. We demonstrate our
technique on case studies from linear models to nonlinear control-dependent
models for online autonomous driving scenarios.",2024-04-29,"Alessandro Abate, Sergiy Bogomolov, Alec Edwards, Kostiantyn Potomkin, Sadegh Soudjani, Paolo Zuliani",http://arxiv.org/pdf/2404.18813v1,cs.LG
The Landscape of Unfolding with Machine Learning,"Recent innovations from machine learning allow for data unfolding, without
binning and including correlations across many dimensions. We describe a set of
known, upgraded, and new methods for ML-based unfolding. The performance of
these approaches are evaluated on the same two datasets. We find that all
techniques are capable of accurately reproducing the particle-level spectra
across complex observables. Given that these approaches are conceptually
diverse, they offer an exciting toolkit for a new class of measurements that
can probe the Standard Model with an unprecedented level of detail and may
enable sensitivity to new phenomena.",2024-04-29,"Nathan Huetsch, Javier Mariño Villadamigo, Alexander Shmakov, Sascha Diefenbacher, Vinicius Mikuni, Theo Heimel, Michael Fenton, Kevin Greif, Benjamin Nachman, Daniel Whiteson, Anja Butter, Tilman Plehn",http://arxiv.org/pdf/2404.18807v2,cs.LG
A Partial Replication of MaskFormer in TensorFlow on TPUs for the TensorFlow Model Garden,"This paper undertakes the task of replicating the MaskFormer model a
universal image segmentation model originally developed using the PyTorch
framework, within the TensorFlow ecosystem, specifically optimized for
execution on Tensor Processing Units (TPUs). Our implementation exploits the
modular constructs available within the TensorFlow Model Garden (TFMG),
encompassing elements such as the data loader, training orchestrator, and
various architectural components, tailored and adapted to meet the
specifications of the MaskFormer model. We address key challenges encountered
during the replication, non-convergence issues, slow training, adaptation of
loss functions, and the integration of TPU-specific functionalities. We verify
our reproduced implementation and present qualitative results on the COCO
dataset. Although our implementation meets some of the objectives for
end-to-end reproducibility, we encountered challenges in replicating the
PyTorch version of MaskFormer in TensorFlow. This replication process is not
straightforward and requires substantial engineering efforts. Specifically, it
necessitates the customization of various components within the TFMG, alongside
thorough verification and hyper-parameter tuning. The replication is available
at:
https://github.com/PurdueDualityLab/tf-maskformer/tree/main/official/projects/maskformer",2024-04-29,"Vishal Purohit, Wenxin Jiang, Akshath R. Ravikiran, James C. Davis",http://arxiv.org/pdf/2404.18801v1,cs.LG
Joint Signal Detection and Automatic Modulation Classification via Deep Learning,"Signal detection and modulation classification are two crucial tasks in
various wireless communication systems. Different from prior works that
investigate them independently, this paper studies the joint signal detection
and automatic modulation classification (AMC) by considering a realistic and
complex scenario, in which multiple signals with different modulation schemes
coexist at different carrier frequencies. We first generate a coexisting
RADIOML dataset (CRML23) to facilitate the joint design. Different from the
publicly available AMC dataset ignoring the signal detection step and
containing only one signal, our synthetic dataset covers the more realistic
multiple-signal coexisting scenario. Then, we present a joint framework for
detection and classification (JDM) for such a multiple-signal coexisting
environment, which consists of two modules for signal detection and AMC,
respectively. In particular, these two modules are interconnected using a
designated data structure called ""proposal"". Finally, we conduct extensive
simulations over the newly developed dataset, which demonstrate the
effectiveness of our designs. Our code and dataset are now available as
open-source (https://github.com/Singingkettle/ChangShuoRadioData).",2024-04-29,"Huijun Xing, Xuhui Zhang, Shuo Chang, Jinke Ren, Zixun Zhang, Jie Xu, Shuguang Cui",http://arxiv.org/pdf/2405.00736v1,cs.LG
Optimal time sampling in physics-informed neural networks,"Physics-informed neural networks (PINN) is a extremely powerful paradigm used
to solve equations encountered in scientific computing applications. An
important part of the procedure is the minimization of the equation residual
which includes, when the equation is time-dependent, a time sampling. It was
argued in the literature that the sampling need not be uniform but should
overweight initial time instants, but no rigorous explanation was provided for
this choice. In the present work we take some prototypical examples and, under
standard hypothesis concerning the neural network convergence, we show that the
optimal time sampling follows a (truncated) exponential distribution. In
particular we explain when is best to use uniform time sampling and when one
should not. The findings are illustrated with numerical examples on linear
equation, Burgers' equation and the Lorenz system.",2024-04-29,Gabriel Turinici,http://arxiv.org/pdf/2404.18780v2,cs.LG
A Universal Metric of Dataset Similarity for Cross-silo Federated Learning,"Federated Learning is increasingly used in domains such as healthcare to
facilitate collaborative model training without data-sharing. However, datasets
located in different sites are often non-identically distributed, leading to
degradation of model performance in FL. Most existing methods for assessing
these distribution shifts are limited by being dataset or task-specific.
Moreover, these metrics can only be calculated by exchanging data, a practice
restricted in many FL scenarios. To address these challenges, we propose a
novel metric for assessing dataset similarity. Our metric exhibits several
desirable properties for FL: it is dataset-agnostic, is calculated in a
privacy-preserving manner, and is computationally efficient, requiring no model
training. In this paper, we first establish a theoretical connection between
our metric and training dynamics in FL. Next, we extensively evaluate our
metric on a range of datasets including synthetic, benchmark, and medical
imaging datasets. We demonstrate that our metric shows a robust and
interpretable relationship with model performance and can be calculated in
privacy-preserving manner. As the first federated dataset similarity metric, we
believe this metric can better facilitate successful collaborations between
sites.",2024-04-29,"Ahmed Elhussein, Gamze Gursoy",http://arxiv.org/pdf/2404.18773v1,cs.LG
"Learning with Norm Constrained, Over-parameterized, Two-layer Neural Networks","Recent studies show that a reproducing kernel Hilbert space (RKHS) is not a
suitable space to model functions by neural networks as the curse of
dimensionality (CoD) cannot be evaded when trying to approximate even a single
ReLU neuron (Bach, 2017). In this paper, we study a suitable function space for
over-parameterized two-layer neural networks with bounded norms (e.g., the path
norm, the Barron norm) in the perspective of sample complexity and
generalization properties. First, we show that the path norm (as well as the
Barron norm) is able to obtain width-independence sample complexity bounds,
which allows for uniform convergence guarantees. Based on this result, we
derive the improved result of metric entropy for $\epsilon$-covering up to
$O(\epsilon^{-\frac{2d}{d+2}})$ ($d$ is the input dimension and the depending
constant is at most linear order of $d$) via the convex hull technique, which
demonstrates the separation with kernel methods with $\Omega(\epsilon^{-d})$ to
learn the target function in a Barron space. Second, this metric entropy result
allows for building a sharper generalization bound under a general moment
hypothesis setting, achieving the rate at $O(n^{-\frac{d+2}{2d+2}})$. Our
analysis is novel in that it offers a sharper and refined estimation for metric
entropy with a linear dimension dependence and unbounded sampling in the
estimation of the sample error and the output error.",2024-04-29,"Fanghui Liu, Leello Dadi, Volkan Cevher",http://arxiv.org/pdf/2404.18769v2,cs.LG
Transitive Vision-Language Prompt Learning for Domain Generalization,"The vision-language pre-training has enabled deep models to make a huge step
forward in generalizing across unseen domains. The recent learning method based
on the vision-language pre-training model is a great tool for domain
generalization and can solve this problem to a large extent. However, there are
still some issues that an advancement still suffers from trading-off between
domain invariance and class separability, which are crucial in current DG
problems. However, there are still some issues that an advancement still
suffers from trading-off between domain invariance and class separability,
which are crucial in current DG problems. In this paper, we introduce a novel
prompt learning strategy that leverages deep vision prompts to address domain
invariance while utilizing language prompts to ensure class separability,
coupled with adaptive weighting mechanisms to balance domain invariance and
class separability. Extensive experiments demonstrate that deep vision prompts
effectively extract domain-invariant features, significantly improving the
generalization ability of deep models and achieving state-of-the-art
performance on three datasets.",2024-04-29,"Liyuan Wang, Yan Jin, Zhen Chen, Jinlin Wu, Mengke Li, Yang Lu, Hanzi Wang",http://arxiv.org/pdf/2404.18758v1,cs.LG
HMAR: Hierarchical Masked Attention for Multi-Behaviour Recommendation,"In the context of recommendation systems, addressing multi-behavioral user
interactions has become vital for understanding the evolving user behavior.
Recent models utilize techniques like graph neural networks and attention
mechanisms for modeling diverse behaviors, but capturing sequential patterns in
historical interactions remains challenging. To tackle this, we introduce
Hierarchical Masked Attention for multi-behavior recommendation (HMAR).
Specifically, our approach applies masked self-attention to items of the same
behavior, followed by self-attention across all behaviors. Additionally, we
propose historical behavior indicators to encode the historical frequency of
each items behavior in the input sequence. Furthermore, the HMAR model operates
in a multi-task setting, allowing it to learn item behaviors and their
associated ranking scores concurrently. Extensive experimental results on four
real-world datasets demonstrate that our proposed model outperforms
state-of-the-art methods. Our code and datasets are available here
(https://github.com/Shereen-Elsayed/HMAR).",2024-04-29,"Shereen Elsayed, Ahmed Rashed, Lars Schmidt-Thieme",http://arxiv.org/pdf/2405.09638v1,cs.LG
Towards Generalizable Agents in Text-Based Educational Environments: A Study of Integrating RL with LLMs,"There has been a growing interest in developing learner models to enhance
learning and teaching experiences in educational environments. However,
existing works have primarily focused on structured environments relying on
meticulously crafted representations of tasks, thereby limiting the agent's
ability to generalize skills across tasks. In this paper, we aim to enhance the
generalization capabilities of agents in open-ended text-based learning
environments by integrating Reinforcement Learning (RL) with Large Language
Models (LLMs). We investigate three types of agents: (i) RL-based agents that
utilize natural language for state and action representations to find the best
interaction strategy, (ii) LLM-based agents that leverage the model's general
knowledge and reasoning through prompting, and (iii) hybrid LLM-assisted RL
agents that combine these two strategies to improve agents' performance and
generalization. To support the development and evaluation of these agents, we
introduce PharmaSimText, a novel benchmark derived from the PharmaSim virtual
pharmacy environment designed for practicing diagnostic conversations. Our
results show that RL-based agents excel in task completion but lack in asking
quality diagnostic questions. In contrast, LLM-based agents perform better in
asking diagnostic questions but fall short of completing the task. Finally,
hybrid LLM-assisted RL agents enable us to overcome these limitations,
highlighting the potential of combining RL and LLMs to develop high-performing
agents for open-ended learning environments.",2024-04-29,"Bahar Radmehr, Adish Singla, Tanja Käser",http://arxiv.org/pdf/2404.18978v1,cs.LG
Foundations of Multisensory Artificial Intelligence,"Building multisensory AI systems that learn from multiple sensory inputs such
as text, speech, video, real-world sensors, wearable devices, and medical data
holds great promise for impact in many scientific areas with practical
benefits, such as in supporting human health and well-being, enabling
multimedia content processing, and enhancing real-world autonomous agents. By
synthesizing a range of theoretical frameworks and application domains, this
thesis aims to advance the machine learning foundations of multisensory AI. In
the first part, we present a theoretical framework formalizing how modalities
interact with each other to give rise to new information for a task. These
interactions are the basic building blocks in all multimodal problems, and
their quantification enables users to understand their multimodal datasets,
design principled approaches to learn these interactions, and analyze whether
their model has succeeded in learning. In the second part, we study the design
of practical multimodal foundation models that generalize over many modalities
and tasks, which presents a step toward grounding large language models to
real-world sensory modalities. We introduce MultiBench, a unified large-scale
benchmark across a wide range of modalities, tasks, and research areas,
followed by the cross-modal attention and multimodal transformer architectures
that now underpin many of today's multimodal foundation models. Scaling these
architectures on MultiBench enables the creation of general-purpose
multisensory AI systems, and we discuss our collaborative efforts in applying
these models for real-world impact in affective computing, mental health,
cancer prognosis, and robotics. Finally, we conclude this thesis by discussing
how future work can leverage these ideas toward more general, interactive, and
safe multisensory AI.",2024-04-29,Paul Pu Liang,http://arxiv.org/pdf/2404.18976v1,cs.LG
M3H: Multimodal Multitask Machine Learning for Healthcare,"Developing an integrated many-to-many framework leveraging multimodal data
for multiple tasks is crucial to unifying healthcare applications ranging from
diagnoses to operations. In resource-constrained hospital environments, a
scalable and unified machine learning framework that improves previous forecast
performances could improve hospital operations and save costs. We introduce
M3H, an explainable Multimodal Multitask Machine Learning for Healthcare
framework that consolidates learning from tabular, time-series, language, and
vision data for supervised binary/multiclass classification, regression, and
unsupervised clustering. It features a novel attention mechanism balancing
self-exploitation (learning source-task), and cross-exploration (learning
cross-tasks), and offers explainability through a proposed TIM score, shedding
light on the dynamics of task learning interdependencies. M3H encompasses an
unprecedented range of medical tasks and machine learning problem classes and
consistently outperforms traditional single-task models by on average 11.6%
across 40 disease diagnoses from 16 medical departments, three hospital
operation forecasts, and one patient phenotyping task. The modular design of
the framework ensures its generalizability in data processing, task definition,
and rapid model prototyping, making it production ready for both clinical and
operational healthcare settings, especially those in constrained environments.",2024-04-29,"Dimitris Bertsimas, Yu Ma",http://arxiv.org/pdf/2404.18975v3,cs.LG
Mapping the Potential of Explainable AI for Fairness Along the AI Lifecycle,"The widespread use of artificial intelligence (AI) systems across various
domains is increasingly surfacing issues related to algorithmic fairness,
especially in high-stakes scenarios. Thus, critical considerations of how
fairness in AI systems might be improved -- and what measures are available to
aid this process -- are overdue. Many researchers and policymakers see
explainable AI (XAI) as a promising way to increase fairness in AI systems.
However, there is a wide variety of XAI methods and fairness conceptions
expressing different desiderata, and the precise connections between XAI and
fairness remain largely nebulous. Besides, different measures to increase
algorithmic fairness might be applicable at different points throughout an AI
system's lifecycle. Yet, there currently is no coherent mapping of fairness
desiderata along the AI lifecycle. In this paper, we we distill eight fairness
desiderata, map them along the AI lifecycle, and discuss how XAI could help
address each of them. We hope to provide orientation for practical applications
and to inspire XAI research specifically focused on these fairness desiderata.",2024-04-29,"Luca Deck, Astrid Schomäcker, Timo Speith, Jakob Schöffer, Lena Kästner, Niklas Kühl",http://arxiv.org/pdf/2404.18736v4,cs.LG
Real Time Multi Organ Classification on Computed Tomography Images,"Organ segmentation is a fundamental task in medical imaging since it is
useful for many clinical automation pipelines. However, some tasks do not
require full segmentation. Instead, a classifier can identify the selected
organ without segmenting the entire volume. In this study, we demonstrate a
classifier based method to obtain organ labels in real time by using a large
context size with a sparse data sampling strategy. Although our method operates
as an independent classifier at query locations, it can generate full
segmentations by querying grid locations at any resolution, offering faster
performance than segmentation algorithms. We compared our method with existing
segmentation techniques, demonstrating its superior runtime potential for
practical applications in medical imaging.",2024-04-29,"Halid Ziya Yerebakan, Yoshihisa Shinagawa, Gerardo Hermosillo Valadez",http://arxiv.org/pdf/2404.18731v3,cs.LG
CVTN: Cross Variable and Temporal Integration for Time Series Forecasting,"In multivariate time series forecasting, the Transformer architecture
encounters two significant challenges: effectively mining features from
historical sequences and avoiding overfitting during the learning of temporal
dependencies. To tackle these challenges, this paper deconstructs time series
forecasting into the learning of historical sequences and prediction sequences,
introducing the Cross-Variable and Time Network (CVTN). This unique method
divides multivariate time series forecasting into two phases: cross-variable
learning for effectively mining fea tures from historical sequences, and
cross-time learning to capture the temporal dependencies of prediction
sequences. Separating these two phases helps avoid the impact of overfitting in
cross-time learning on cross-variable learning. Exten sive experiments on
various real-world datasets have confirmed its state-of-the-art (SOTA)
performance. CVTN emphasizes three key dimensions in time series fore casting:
the short-term and long-term nature of time series (locality and longevity),
feature mining from both historical and prediction sequences, and the
integration of cross-variable and cross-time learning. This approach not only
advances the current state of time series forecasting but also provides a more
comprehensive framework for future research in this field.",2024-04-29,"Han Zhou, Yuntian Chen",http://arxiv.org/pdf/2404.18730v1,cs.LG
Why You Should Not Trust Interpretations in Machine Learning: Adversarial Attacks on Partial Dependence Plots,"The adoption of artificial intelligence (AI) across industries has led to the
widespread use of complex black-box models and interpretation tools for
decision making. This paper proposes an adversarial framework to uncover the
vulnerability of permutation-based interpretation methods for machine learning
tasks, with a particular focus on partial dependence (PD) plots. This
adversarial framework modifies the original black box model to manipulate its
predictions for instances in the extrapolation domain. As a result, it produces
deceptive PD plots that can conceal discriminatory behaviors while preserving
most of the original model's predictions. This framework can produce multiple
fooled PD plots via a single model. By using real-world datasets including an
auto insurance claims dataset and COMPAS (Correctional Offender Management
Profiling for Alternative Sanctions) dataset, our results show that it is
possible to intentionally hide the discriminatory behavior of a predictor and
make the black-box model appear neutral through interpretation tools like PD
plots while retaining almost all the predictions of the original black-box
model. Managerial insights for regulators and practitioners are provided based
on the findings.",2024-04-29,"Xi Xin, Giles Hooker, Fei Huang",http://arxiv.org/pdf/2404.18702v2,cs.LG
Convergence Properties of Score-Based Models for Linear Inverse Problems Using Graduated Optimisation,"The incorporation of generative models as regularisers within variational
formulations for inverse problems has proven effective across numerous image
reconstruction tasks. However, the resulting optimisation problem is often
non-convex and challenging to solve. In this work, we show that score-based
generative models (SGMs) can be used in a graduated optimisation framework to
solve inverse problems. We show that the resulting graduated non-convexity flow
converge to stationary points of the original problem and provide a numerical
convergence analysis of a 2D toy example. We further provide experiments on
computed tomography image reconstruction, where we show that this framework is
able to recover high-quality images, independent of the initial value. The
experiments highlight the potential of using SGMs in graduated optimisation
frameworks. The source code is publicly available on GitHub.",2024-04-29,"Pascal Fernsel, Željko Kereta, Alexander Denker",http://arxiv.org/pdf/2404.18699v2,cs.LG
CLASSP: a Biologically-Inspired Approach to Continual Learning through Adjustment Suppression and Sparsity Promotion,"This paper introduces a new biologically-inspired training method named
Continual Learning through Adjustment Suppression and Sparsity Promotion
(CLASSP). CLASSP is based on two main principles observed in neuroscience,
particularly in the context of synaptic transmission and Long-Term Potentiation
(LTP). The first principle is a decay rate over the weight adjustment, which is
implemented as a generalization of the AdaGrad optimization algorithm. This
means that weights that have received many updates should have lower learning
rates as they likely encode important information about previously seen data.
However, this principle results in a diffuse distribution of updates throughout
the model, as it promotes updates for weights that haven't been previously
updated, while a sparse update distribution is preferred to leave weights
unassigned for future tasks. Therefore, the second principle introduces a
threshold on the loss gradient. This promotes sparse learning by updating a
weight only if the loss gradient with respect to that weight is above a certain
threshold, i.e. only updating weights with a significant impact on the current
loss. Both principles reflect phenomena observed in LTP, where a threshold
effect and a gradual saturation of potentiation have been observed. CLASSP is
implemented in a Python/PyTorch class, making it applicable to any model. When
compared with Elastic Weight Consolidation (EWC) using Computer Vision and
sentiment analysis datasets, CLASSP demonstrates superior performance in terms
of accuracy and memory footprint.",2024-04-29,Oswaldo Ludwig,http://arxiv.org/pdf/2405.09637v2,cs.LG
FALE: Fairness-Aware ALE Plots for Auditing Bias in Subgroups,"Fairness is steadily becoming a crucial requirement of Machine Learning (ML)
systems. A particularly important notion is subgroup fairness, i.e., fairness
in subgroups of individuals that are defined by more than one attributes.
Identifying bias in subgroups can become both computationally challenging, as
well as problematic with respect to comprehensibility and intuitiveness of the
finding to end users. In this work we focus on the latter aspects; we propose
an explainability method tailored to identifying potential bias in subgroups
and visualizing the findings in a user friendly manner to end users. In
particular, we extend the ALE plots explainability method, proposing FALE
(Fairness aware Accumulated Local Effects) plots, a method for measuring the
change in fairness for an affected population corresponding to different values
of a feature (attribute). We envision FALE to function as an efficient, user
friendly, comprehensible and reliable first-stage tool for identifying
subgroups with potential bias issues.",2024-04-29,"Giorgos Giannopoulos, Dimitris Sacharidis, Nikolas Theologitis, Loukas Kavouras, Ioannis Emiris",http://arxiv.org/pdf/2404.18685v1,cs.LG
Open-Source Drift Detection Tools in Action: Insights from Two Use Cases,"Data drifts pose a critical challenge in the lifecycle of machine learning
(ML) models, affecting their performance and reliability. In response to this
challenge, we present a microbenchmark study, called D3Bench, which evaluates
the efficacy of open-source drift detection tools. D3Bench examines the
capabilities of Evidently AI, NannyML, and Alibi-Detect, leveraging real-world
data from two smart building use cases.We prioritize assessing the functional
suitability of these tools to identify and analyze data drifts. Furthermore, we
consider a comprehensive set of non-functional criteria, such as the
integrability with ML pipelines, the adaptability to diverse data types,
user-friendliness, computational efficiency, and resource demands. Our findings
reveal that Evidently AI stands out for its general data drift detection,
whereas NannyML excels at pinpointing the precise timing of shifts and
evaluating their consequent effects on predictive accuracy.",2024-04-29,"Rieke Müller, Mohamed Abdelaal, Davor Stjelja",http://arxiv.org/pdf/2404.18673v2,cs.LG
Enhancing Uncertain Demand Prediction in Hospitals Using Simple and Advanced Machine Learning,"Early and timely prediction of patient care demand not only affects effective
resource allocation but also influences clinical decision-making as well as
patient experience. Accurately predicting patient care demand, however, is a
ubiquitous challenge for hospitals across the world due, in part, to the
demand's time-varying temporal variability, and, in part, to the difficulty in
modelling trends in advance. To address this issue, here, we develop two
methods, a relatively simple time-vary linear model, and a more advanced neural
network model. The former forecasts patient arrivals hourly over a week based
on factors such as day of the week and previous 7-day arrival patterns. The
latter leverages a long short-term memory (LSTM) model, capturing non-linear
relationships between past data and a three-day forecasting window. We evaluate
the predictive capabilities of the two proposed approaches compared to two
na\""ive approaches - a reduced-rank vector autoregressive (VAR) model and the
TBATS model. Using patient care demand data from Rambam Medical Center in
Israel, our results show that both proposed models effectively capture hourly
variations of patient demand. Additionally, the linear model is more
explainable thanks to its simple architecture, whereas, by accurately modelling
weekly seasonal trends, the LSTM model delivers lower prediction errors. Taken
together, our explorations suggest the utility of machine learning in
predicting time-varying patient care demand; additionally, it is possible to
predict patient care demand with good accuracy (around 4 patients) three days
or a week in advance using machine learning.",2024-04-29,"Annie Hu, Samuel Stockman, Xun Wu, Richard Wood, Bangdong Zhi, Oliver Y. Chén",http://arxiv.org/pdf/2404.18670v1,cs.LG
Terrain characterisation for online adaptability of automated sonar processing: Lessons learnt from operationally applying ATR to sidescan sonar in MCM applications,"The performance of Automated Recognition (ATR) algorithms on side-scan sonar
imagery has shown to degrade rapidly when deployed on non benign environments.
Complex seafloors and acoustic artefacts constitute distractors in the form of
strong textural patterns, creating false detections or preventing detections of
true objects. This paper presents two online seafloor characterisation
techniques to improve explainability during Autonomous Underwater Vehicles
(AUVs) missions. Importantly and as opposed to previous work in the domain,
these techniques are not based on a model and require limited input from human
operators, making it suitable for real-time onboard processing. Both techniques
rely on an unsupervised machine learning approach to extract terrain features
which relate to the human understanding of terrain complexity. The first
technnique provides a quantitative, application-driven terrain characterisation
metric based on the performance of an ATR algorithm. The second method provides
a way to incorporate subject matter expertise and enables contextualisation and
explainability in support for scenario-dependent subjective terrain
characterisation. The terrain complexity matches the expectation of seasoned
users making this tool desirable and trustworthy in comparison to traditional
unsupervised approaches. We finally detail an application of these techniques
to repair a Mine Countermeasures (MCM) mission carried with SeeByte autonomy
framework Neptune.",2024-04-29,"Thomas Guerneve, Stephanos Loizou, Andrea Munafo, Pierre-Yves Mignotte",http://arxiv.org/pdf/2404.18663v1,cs.LG
Feature importance to explain multimodal prediction models. A clinical use case,"Surgery to treat elderly hip fracture patients may cause complications that
can lead to early mortality. An early warning system for complications could
provoke clinicians to monitor high-risk patients more carefully and address
potential complications early, or inform the patient. In this work, we develop
a multimodal deep-learning model for post-operative mortality prediction using
pre-operative and per-operative data from elderly hip fracture patients.
Specifically, we include static patient data, hip and chest images before
surgery in pre-operative data, vital signals, and medications administered
during surgery in per-operative data. We extract features from image modalities
using ResNet and from vital signals using LSTM. Explainable model outcomes are
essential for clinical applicability, therefore we compute Shapley values to
explain the predictions of our multimodal black box model. We find that i)
Shapley values can be used to estimate the relative contribution of each
modality both locally and globally, and ii) a modified version of the chain
rule can be used to propagate Shapley values through a sequence of models
supporting interpretable local explanations. Our findings imply that a
multimodal combination of black box models can be explained by propagating
Shapley values through the model sequence.",2024-04-29,"Jorn-Jan van de Beld, Shreyasi Pathak, Jeroen Geerdink, Johannes H. Hegeman, Christin Seifert",http://arxiv.org/pdf/2404.18631v1,cs.LG
Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?,"Vision and language model (VLM) decoders are currently the best-performing
architectures on multimodal tasks. Next to answers, they are able to produce
natural language explanations, either in post-hoc or CoT settings. However, it
is not clear to what extent they are using the input vision and text modalities
when generating answers or explanations. In this work, we investigate if VLMs
rely on their input modalities differently when they produce explanations as
opposed to answers. We also evaluate the self-consistency of VLM decoders in
both post-hoc and CoT explanation settings, by extending existing unimodal
tests and measures to VLM decoders. We find that most tested VLMs are less
self-consistent than LLMs. Text contributions in all tested VL decoders are
more important than image contributions in all examined tasks. However, when
comparing explanation generation to answer generation, the contributions of
images are significantly stronger for generating explanations compared to
answers. This difference is even larger in CoT compared to post-hoc
explanations. Lastly, we provide an up-to-date benchmarking of state-of-the-art
VL decoders on the VALSE benchmark, which before was restricted to VL encoders.
We find that the tested VL decoders still struggle with most phenomena tested
by VALSE.",2024-04-29,"Letitia Parcalabescu, Anette Frank",http://arxiv.org/pdf/2404.18624v4,cs.LG
PoPE: Legendre Orthogonal Polynomials Based Position Encoding for Large Language Models,"There are several improvements proposed over the baseline Absolute Positional
Encoding (APE) method used in original transformer. In this study, we aim to
investigate the implications of inadequately representing positional encoding
in higher dimensions on crucial aspects of the attention mechanism, the model's
capacity to learn relative positional information, and the convergence of
models, all stemming from the choice of sinusoidal basis functions. Through a
combination of theoretical insights and empirical analyses, we elucidate how
these challenges extend beyond APEs and may adversely affect the performance of
Relative Positional Encoding (RPE) methods, such as Rotatory Positional
Encoding (RoPE).
  Subsequently, we introduce an innovative solution termed Orthogonal
Polynomial Based Positional Encoding (PoPE) to address some of the limitations
associated with existing methods. The PoPE method encodes positional
information by leveraging Orthogonal Legendre polynomials. Legendre polynomials
as basis functions offers several desirable properties for positional encoding,
including improved correlation structure, non-periodicity, orthogonality, and
distinct functional forms among polynomials of varying orders. Our experimental
findings demonstrate that transformer models incorporating PoPE outperform
baseline transformer models on the $Multi30k$ English-to-German translation
task, thus establishing a new performance benchmark. Furthermore, PoPE-based
transformers exhibit significantly accelerated convergence rates.
  Additionally, we will present novel theoretical perspectives on position
encoding based on the superior performance of PoPE.",2024-04-29,Arpit Aggarwal,http://arxiv.org/pdf/2405.04585v1,cs.LG
Predicting Safety Misbehaviours in Autonomous Driving Systems using Uncertainty Quantification,"The automated real-time recognition of unexpected situations plays a crucial
role in the safety of autonomous vehicles, especially in unsupported and
unpredictable scenarios. This paper evaluates different Bayesian uncertainty
quantification methods from the deep learning domain for the anticipatory
testing of safety-critical misbehaviours during system-level simulation-based
testing. Specifically, we compute uncertainty scores as the vehicle executes,
following the intuition that high uncertainty scores are indicative of
unsupported runtime conditions that can be used to distinguish safe from
failure-inducing driving behaviors. In our study, we conducted an evaluation of
the effectiveness and computational overhead associated with two Bayesian
uncertainty quantification methods, namely MC- Dropout and Deep Ensembles, for
misbehaviour avoidance. Overall, for three benchmarks from the Udacity
simulator comprising both out-of-distribution and unsafe conditions introduced
via mutation testing, both methods successfully detected a high number of
out-of-bounds episodes providing early warnings several seconds in advance,
outperforming two state-of-the-art misbehaviour prediction methods based on
autoencoders and attention maps in terms of effectiveness and efficiency.
Notably, Deep Ensembles detected most misbehaviours without any false alarms
and did so even when employing a relatively small number of models, making them
computationally feasible for real-time detection. Our findings suggest that
incorporating uncertainty quantification methods is a viable approach for
building fail-safe mechanisms in deep neural network-based autonomous vehicles.",2024-04-29,"Ruben Grewal, Paolo Tonella, Andrea Stocco",http://arxiv.org/pdf/2404.18573v2,cs.LG
Learning Governing Equations of Unobserved States in Dynamical Systems,"Data-driven modelling and scientific machine learning have been responsible
for significant advances in determining suitable models to describe data.
Within dynamical systems, neural ordinary differential equations (ODEs), where
the system equations are set to be governed by a neural network, have become a
popular tool for this challenge in recent years. However, less emphasis has
been placed on systems that are only partially-observed. In this work, we
employ a hybrid neural ODE structure, where the system equations are governed
by a combination of a neural network and domain-specific knowledge, together
with symbolic regression (SR), to learn governing equations of
partially-observed dynamical systems. We test this approach on two case
studies: A 3-dimensional model of the Lotka-Volterra system and a 5-dimensional
model of the Lorenz system. We demonstrate that the method is capable of
successfully learning the true underlying governing equations of unobserved
states within these systems, with robustness to measurement noise.",2024-04-29,"Gevik Grigorian, Sandip V. George, Simon Arridge",http://arxiv.org/pdf/2404.18572v2,cs.LG
EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based Cross-Center Brain Disease Diagnosis under Unreliable Annotations,"Cross-center data heterogeneity and annotation unreliability significantly
challenge the intelligent diagnosis of diseases using brain signals. A notable
example is the EEG-based diagnosis of neurodegenerative diseases, which
features subtler abnormal neural dynamics typically observed in small-group
settings. To advance this area, in this work, we introduce a transferable
framework employing Manifold Attention and Confidence Stratification (MACS) to
diagnose neurodegenerative disorders based on EEG signals sourced from four
centers with unreliable annotations. The MACS framework's effectiveness stems
from these features: 1) The Augmentor generates various EEG-represented brain
variants to enrich the data space; 2) The Switcher enhances the feature space
for trusted samples and reduces overfitting on incorrectly labeled samples; 3)
The Encoder uses the Riemannian manifold and Euclidean metrics to capture
spatiotemporal variations and dynamic synchronization in EEG; 4) The Projector,
equipped with dual heads, monitors consistency across multiple brain variants
and ensures diagnostic accuracy; 5) The Stratifier adaptively stratifies
learned samples by confidence levels throughout the training process; 6)
Forward and backpropagation in MACS are constrained by confidence
stratification to stabilize the learning system amid unreliable annotations.
Our subject-independent experiments, conducted on both neurocognitive and
movement disorders using cross-center corpora, have demonstrated superior
performance compared to existing related algorithms. This work not only
improves EEG-based diagnostics for cross-center and small-setting brain
diseases but also offers insights into extending MACS techniques to other data
analyses, tackling data heterogeneity and annotation unreliability in
multimedia and multimodal content understanding.",2024-04-29,"Zhenxi Song, Ruihan Qin, Huixia Ren, Zhen Liang, Yi Guo, Min Zhang, Zhiguo Zhang",http://arxiv.org/pdf/2405.00734v2,cs.LG
Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting,"Autoregressive Recurrent Neural Networks are widely employed in time-series
forecasting tasks, demonstrating effectiveness in univariate and certain
multivariate scenarios. However, their inherent structure does not readily
accommodate the integration of future, time-dependent covariates. A proposed
solution, outlined by Salinas et al 2019, suggests forecasting both covariates
and the target variable in a multivariate framework. In this study, we
conducted comprehensive tests on publicly available time-series datasets,
artificially introducing highly correlated covariates to future time-step
values. Our evaluation aimed to assess the performance of an LSTM network when
considering these covariates and compare it against a univariate baseline. As
part of this study we introduce a novel approach using seasonal time segments
in combination with an RNN architecture, which is both simple and extremely
effective over long forecast horizons with comparable performance to many state
of the art architectures. Our findings from the results of more than 120 models
reveal that under certain conditions jointly training covariates with target
variables can improve overall performance of the model, but often there exists
a significant performance disparity between multivariate and univariate
predictions. Surprisingly, even when provided with covariates informing the
network about future target values, multivariate predictions exhibited inferior
performance. In essence, compelling the network to predict multiple values can
prove detrimental to model performance, even in the presence of informative
covariates. These results suggest that LSTM architectures may not be suitable
for forecasting tasks where predicting covariates would typically be expected
to enhance model accuracy.",2024-04-29,Gareth Davies,http://arxiv.org/pdf/2404.18553v1,cs.LG
IncidentResponseGPT: Generating Traffic Incident Response Plans with Generative Artificial Intelligence,"The proposed IncidentResponseGPT framework - a novel system that applies
generative artificial intelligence (AI) to potentially enhance the efficiency
and effectiveness of traffic incident response. This model allows for synthesis
of region-specific incident response guidelines and generates incident response
plans adapted to specific area, aiming to expedite decision-making for traffic
management authorities. This approach aims to accelerate incident resolution
times by suggesting various recommendations (e.g. optimal rerouting strategies,
estimating resource needs) to minimize the overall impact on the urban traffic
network. The system suggests specific actions, including dynamic lane closures,
optimized rerouting and dispatching appropriate emergency resources. We utilize
the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) to
rank generated response plans based on criteria like impact minimization and
resource efficiency based on their proximity to an human-proposed solution.",2024-04-29,"Artur Grigorev, Adriana-Simona Mihaita Khaled Saleh, Yuming Ou",http://arxiv.org/pdf/2404.18550v4,cs.LG
Time Machine GPT,"Large language models (LLMs) are often trained on extensive, temporally
indiscriminate text corpora, reflecting the lack of datasets with temporal
metadata. This approach is not aligned with the evolving nature of language.
Conventional methods for creating temporally adapted language models often
depend on further pre-training static models on time-specific data. This paper
presents a new approach: a series of point-in-time LLMs called Time Machine GPT
(TiMaGPT), specifically designed to be nonprognosticative. This ensures they
remain uninformed about future factual information and linguistic changes. This
strategy is beneficial for understanding language evolution and is of critical
importance when applying models in dynamic contexts, such as time-series
forecasting, where foresight of future information can prove problematic. We
provide access to both the models and training datasets.",2024-04-29,"Felix Drinkall, Eghbal Rahimikia, Janet B. Pierrehumbert, Stefan Zohren",http://arxiv.org/pdf/2404.18543v1,cs.LG
Symmetry group based domain decomposition to enhance physics-informed neural networks for solving partial differential equations,"Domain decomposition provides an effective way to tackle the dilemma of
physics-informed neural networks (PINN) which struggle to accurately and
efficiently solve partial differential equations (PDEs) in the whole domain,
but the lack of efficient tools for dealing with the interfaces between two
adjacent sub-domains heavily hinders the training effects, even leads to the
discontinuity of the learned solutions. In this paper, we propose a symmetry
group based domain decomposition strategy to enhance the PINN for solving the
forward and inverse problems of the PDEs possessing a Lie symmetry group.
Specifically, for the forward problem, we first deploy the symmetry group to
generate the dividing-lines having known solution information which can be
adjusted flexibly and are used to divide the whole training domain into a
finite number of non-overlapping sub-domains, then utilize the PINN and the
symmetry-enhanced PINN methods to learn the solutions in each sub-domain and
finally stitch them to the overall solution of PDEs. For the inverse problem,
we first utilize the symmetry group acting on the data of the initial and
boundary conditions to generate labeled data in the interior domain of PDEs and
then find the undetermined parameters as well as the solution by only training
the neural networks in a sub-domain. Consequently, the proposed method can
predict high-accuracy solutions of PDEs which are failed by the vanilla PINN in
the whole domain and the extended physics-informed neural network in the same
sub-domains. Numerical results of the Korteweg-de Vries equation with a
translation symmetry and the nonlinear viscous fluid equation with a scaling
symmetry show that the accuracies of the learned solutions are improved
largely.",2024-04-29,"Ye Liu, Jie-Ying Li, Li-Sheng Zhang, Lei-Lei Guo, Zhi-Yong Zhang",http://arxiv.org/pdf/2404.18538v1,cs.LG
Time Series Data Augmentation as an Imbalanced Learning Problem,"Recent state-of-the-art forecasting methods are trained on collections of
time series. These methods, often referred to as global models, can capture
common patterns in different time series to improve their generalization
performance. However, they require large amounts of data that might not be
readily available. Besides this, global models sometimes fail to capture
relevant patterns unique to a particular time series. In these cases, data
augmentation can be useful to increase the sample size of time series datasets.
The main contribution of this work is a novel method for generating univariate
time series synthetic samples. Our approach stems from the insight that the
observations concerning a particular time series of interest represent only a
small fraction of all observations. In this context, we frame the problem of
training a forecasting model as an imbalanced learning task. Oversampling
strategies are popular approaches used to deal with the imbalance problem in
machine learning. We use these techniques to create synthetic time series
observations and improve the accuracy of forecasting models. We carried out
experiments using 7 different databases that contain a total of 5502 univariate
time series. We found that the proposed solution outperforms both a global and
a local model, thus providing a better trade-off between these two approaches.",2024-04-29,"Vitor Cerqueira, Nuno Moniz, Ricardo Inácio, Carlos Soares",http://arxiv.org/pdf/2404.18537v1,cs.LG
MileBench: Benchmarking MLLMs in Long Context,"Despite the advancements and impressive performance of Multimodal Large
Language Models (MLLMs) on benchmarks, their effectiveness in real-world,
long-context, and multi-image tasks is unclear due to the benchmarks' limited
scope. Existing benchmarks often focus on single-image and short-text samples,
and when assessing multi-image tasks, they either limit the image count or
focus on specific task (e.g time-series captioning), potentially obscuring the
performance challenges of MLLMs. To address these limitations, we introduce
MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt
capabilities of MLLMs. This benchmark comprises not only multimodal long
contexts, but also multiple tasks requiring both comprehension and generation.
We establish two distinct evaluation sets, diagnostic and realistic, to
systematically assess MLLMs' long-context adaptation capacity and their ability
to complete tasks in long-context scenarios. Our experimental results, obtained
from testing 22 models, revealed that while the closed-source GPT-4o
outperforms others, most open-source MLLMs struggle in long-context situations.
Interestingly, the performance gap tends to widen with an increase in the
number of images. We strongly encourage an intensification of research efforts
towards enhancing MLLMs' long-context capabilities, especially in scenarios
involving multiple images.",2024-04-29,"Dingjie Song, Shunian Chen, Guiming Hardy Chen, Fei Yu, Xiang Wan, Benyou Wang",http://arxiv.org/pdf/2404.18532v2,cs.LG
A Framework to Model ML Engineering Processes,"The development of Machine Learning (ML) based systems is complex and
requires multidisciplinary teams with diverse skill sets. This may lead to
communication issues or misapplication of best practices. Process models can
alleviate these challenges by standardizing task orchestration, providing a
common language to facilitate communication, and nurturing a collaborative
environment. Unfortunately, current process modeling languages are not suitable
for describing the development of such systems. In this paper, we introduce a
framework for modeling ML-based software development processes, built around a
domain-specific language and derived from an analysis of scientific and gray
literature. A supporting toolkit is also available.",2024-04-29,"Sergio Morales, Robert Clarisó, Jordi Cabot",http://arxiv.org/pdf/2404.18531v2,cs.LG
Solving Partial Differential Equations with Equivariant Extreme Learning Machines,"We utilize extreme-learning machines for the prediction of partial
differential equations (PDEs). Our method splits the state space into multiple
windows that are predicted individually using a single model. Despite requiring
only few data points (in some cases, our method can learn from a single
full-state snapshot), it still achieves high accuracy and can predict the flow
of PDEs over long time horizons. Moreover, we show how additional symmetries
can be exploited to increase sample efficiency and to enforce equivariance.",2024-04-29,"Hans Harder, Jean Rabault, Ricardo Vinuesa, Mikael Mortensen, Sebastian Peitz",http://arxiv.org/pdf/2404.18530v5,cs.LG
Generation of Uncorrelated Residual Variables for Chemical Process Fault Diagnosis via Transfer Learning-based Input-Output Decoupled Network,"Structural decoupling has played an essential role in model-based fault
isolation and estimation in past decades, which facilitates accurate fault
localization and reconstruction thanks to the diagonal transfer matrix design.
However, traditional methods exhibit limited effectiveness in modeling
high-dimensional nonlinearity and big data, and the decoupling idea has not
been well-valued in data-driven frameworks. Known for big data and complex
feature extraction capabilities, deep learning has recently been used to
develop residual generation models. Nevertheless, it lacks decoupling-related
diagnostic designs. To this end, this paper proposes a transfer learning-based
input-output decoupled network (TDN) for diagnostic purposes, which consists of
an input-output decoupled network (IDN) and a pre-trained variational autocoder
(VAE). In IDN, uncorrelated residual variables are generated by diagonalization
and parallel computing operations. During the transfer learning phase,
knowledge of normal status is provided according to VAE's loss and maximum mean
discrepancy loss to guide the training of IDN. After training, IDN learns the
mapping from faulty to normal, thereby serving as the fault detection index and
the estimated fault signal simultaneously. At last, the effectiveness of the
developed TDN is verified by a numerical example and a chemical simulation.",2024-04-29,"Zhuofu Pan, Qingkai Sui, Yalin Wang, Jiang Luo, Jie Chen, Hongtian Chen",http://arxiv.org/pdf/2404.18528v1,cs.LG
Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning,"Machine learning algorithms emerge as a promising approach in energy fields,
but its practical is hindered by data barriers, stemming from high collection
costs and privacy concerns. This study introduces a novel federated learning
(FL) framework based on XGBoost models, enabling safe collaborative modeling
with accessible yet concealed data from multiple parties. Hyperparameter tuning
of the models is achieved through Bayesian Optimization. To ascertain the
merits of the proposed FL-XGBoost method, a comparative analysis is conducted
between separate and centralized models to address a classical binary
classification problem in geoenergy sector. The results reveal that the
proposed FL framework strikes an optimal balance between privacy and accuracy.
FL models demonstrate superior accuracy and generalization capabilities
compared to separate models, particularly for participants with limited data or
low correlation features and offers significant privacy benefits compared to
centralized model. The aggregated optimization approach within the FL agreement
proves effective in tuning hyperparameters. This study opens new avenues for
assessing unconventional reservoirs through collaborative and
privacy-preserving FL techniques.",2024-04-29,"Weike Peng, Jiaxin Gao, Yuntian Chen, Shengwei Wang",http://arxiv.org/pdf/2404.18527v1,cs.LG
Enabling Efficient and Flexible Interpretability of Data-driven Anomaly Detection in Industrial Processes with AcME-AD,"While Machine Learning has become crucial for Industry 4.0, its opaque nature
hinders trust and impedes the transformation of valuable insights into
actionable decision, a challenge exacerbated in the evolving Industry 5.0 with
its human-centric focus. This paper addresses this need by testing the
applicability of AcME-AD in industrial settings. This recently developed
framework facilitates fast and user-friendly explanations for anomaly
detection. AcME-AD is model-agnostic, offering flexibility, and prioritizes
real-time efficiency. Thus, it seems suitable for seamless integration with
industrial Decision Support Systems. We present the first industrial
application of AcME-AD, showcasing its effectiveness through experiments. These
tests demonstrate AcME-AD's potential as a valuable tool for explainable AD and
feature-based root cause analysis within industrial environments, paving the
way for trustworthy and actionable insights in the age of Industry 5.0.",2024-04-29,"Valentina Zaccaria, Chiara Masiero, David Dandolo, Gian Antonio Susto",http://arxiv.org/pdf/2404.18525v2,cs.LG
On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks,"Federated Learning (FL) allows multiple privacy-sensitive applications to
leverage their dataset for a global model construction without any disclosure
of the information. One of those domains is healthcare, where groups of silos
collaborate in order to generate a global predictor with improved accuracy and
generalization. However, the inherent challenge lies in the high heterogeneity
of medical data, necessitating sophisticated techniques for assessment and
compensation. This paper presents a comprehensive exploration of the
mathematical formalization and taxonomy of heterogeneity within FL
environments, focusing on the intricacies of medical data. In particular, we
address the evaluation and comparison of the most popular FL algorithms with
respect to their ability to cope with quantity-based, feature and label
distribution-based heterogeneity. The goal is to provide a quantitative
evaluation of the impact of data heterogeneity in FL systems for healthcare
networks as well as a guideline on FL algorithm selection. Our research extends
beyond existing studies by benchmarking seven of the most common FL algorithms
against the unique challenges posed by medical data use cases. The paper
targets the prediction of the risk of stroke recurrence through a set of
tabular clinical reports collected by different federated hospital silos: data
heterogeneity frequently encountered in this scenario and its impact on FL
performance are discussed.",2024-04-29,"Usevalad Milasheuski, Luca Barbieri, Bernardo Camajori Tedeschini, Monica Nicoli, Stefano Savazzi",http://arxiv.org/pdf/2404.18519v3,cs.LG
A Systematic Evaluation of Adversarial Attacks against Speech Emotion Recognition Models,"Speech emotion recognition (SER) is constantly gaining attention in recent
years due to its potential applications in diverse fields and thanks to the
possibility offered by deep learning technologies. However, recent studies have
shown that deep learning models can be vulnerable to adversarial attacks. In
this paper, we systematically assess this problem by examining the impact of
various adversarial white-box and black-box attacks on different languages and
genders within the context of SER. We first propose a suitable methodology for
audio data processing, feature extraction, and CNN-LSTM architecture. The
observed outcomes highlighted the significant vulnerability of CNN-LSTM models
to adversarial examples (AEs). In fact, all the considered adversarial attacks
are able to significantly reduce the performance of the constructed models.
Furthermore, when assessing the efficacy of the attacks, minor differences were
noted between the languages analyzed as well as between male and female speech.
In summary, this work contributes to the understanding of the robustness of
CNN-LSTM models, particularly in SER scenarios, and the impact of AEs.
Interestingly, our findings serve as a baseline for a) developing more robust
algorithms for SER, b) designing more effective attacks, c) investigating
possible defenses, d) improved understanding of the vocal differences between
different languages and genders, and e) overall, enhancing our comprehension of
the SER task.",2024-04-29,"Nicolas Facchinetti, Federico Simonetta, Stavros Ntalampiras",http://arxiv.org/pdf/2404.18514v1,cs.LG
Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models,"Event-based sensors are well suited for real-time processing due to their
fast response times and encoding of the sensory data as successive temporal
differences. These and other valuable properties, such as a high dynamic range,
are suppressed when the data is converted to a frame-based format. However,
most current methods either collapse events into frames or cannot scale up when
processing the event data directly event-by-event. In this work, we address the
key challenges of scaling up event-by-event modeling of the long event streams
emitted by such sensors, which is a particularly relevant problem for
neuromorphic computing. While prior methods can process up to a few thousand
time steps, our model, based on modern recurrent deep state-space models,
scales to event streams of millions of events for both training and inference.
We leverage their stable parameterization for learning long-range dependencies,
parallelizability along the sequence dimension, and their ability to integrate
asynchronous events effectively to scale them up to long event streams. We
further augment these with novel event-centric techniques enabling our model to
match or beat the state-of-the-art performance on several event stream
benchmarks. In the Spiking Speech Commands task, we improve state-of-the-art by
a large margin of 7.7% to 88.4%. On the DVS128-Gestures dataset, we achieve
competitive results without using frames or convolutional neural networks. Our
work demonstrates, for the first time, that it is possible to use fully
event-based processing with purely recurrent networks to achieve
state-of-the-art task performance in several event-based benchmarks.",2024-04-29,"Mark Schöne, Neeraj Mohan Sushma, Jingyue Zhuge, Christian Mayr, Anand Subramoney, David Kappel",http://arxiv.org/pdf/2404.18508v3,cs.LG
Multisensor Data Fusion for Automatized Insect Monitoring (KInsecta),"Insect populations are declining globally, making systematic monitoring
essential for conservation. Most classical methods involve death traps and
counter insect conservation. This paper presents a multisensor approach that
uses AI-based data fusion for insect classification. The system is designed as
low-cost setup and consists of a camera module and an optical wing beat sensor
as well as environmental sensors to measure temperature, irradiance or daytime
as prior information. The system has been tested in the laboratory and in the
field. First tests on a small very unbalanced data set with 7 species show
promising results for species classification. The multisensor system will
support biodiversity and agriculture studies.",2024-04-29,"Martin Tschaikner, Danja Brandt, Henning Schmidt, Felix Bießmann, Teodor Chiaburu, Ilona Schrimpf, Thomas Schrimpf, Alexandra Stadel, Frank Haußer, Ingeborg Beckers",http://arxiv.org/pdf/2404.18504v1,cs.LG
Reduced-Rank Multi-objective Policy Learning and Optimization,"Evaluating the causal impacts of possible interventions is crucial for
informing decision-making, especially towards improving access to opportunity.
However, if causal effects are heterogeneous and predictable from covariates,
personalized treatment decisions can improve individual outcomes and contribute
to both efficiency and equity. In practice, however, causal researchers do not
have a single outcome in mind a priori and often collect multiple outcomes of
interest that are noisy estimates of the true target of interest. For example,
in government-assisted social benefit programs, policymakers collect many
outcomes to understand the multidimensional nature of poverty. The ultimate
goal is to learn an optimal treatment policy that in some sense maximizes
multiple outcomes simultaneously. To address such issues, we present a
data-driven dimensionality-reduction methodology for multiple outcomes in the
context of optimal policy learning with multiple objectives. We learn a
low-dimensional representation of the true outcome from the observed outcomes
using reduced rank regression. We develop a suite of estimates that use the
model to denoise observed outcomes, including commonly-used index weightings.
These methods improve estimation error in policy evaluation and optimization,
including on a case study of real-world cash transfer and social intervention
data. Reducing the variance of noisy social outcomes can improve the
performance of algorithmic allocations.",2024-04-29,"Ezinne Nwankwo, Michael I. Jordan, Angela Zhou",http://arxiv.org/pdf/2404.18490v1,cs.LG
RE-GrievanceAssist: Enhancing Customer Experience through ML-Powered Complaint Management,"In recent years, digital platform companies have faced increasing challenges
in managing customer complaints, driven by widespread consumer adoption. This
paper introduces an end-to-end pipeline, named RE-GrievanceAssist, designed
specifically for real estate customer complaint management. The pipeline
consists of three key components: i) response/no-response ML model using TF-IDF
vectorization and XGBoost classifier ; ii) user type classifier using fasttext
classifier; iii) issue/sub-issue classifier using TF-IDF vectorization and
XGBoost classifier. Finally, it has been deployed as a batch job in Databricks,
resulting in a remarkable 40% reduction in overall manual effort with monthly
cost reduction of Rs 1,50,000 since August 2023.",2024-04-29,"Venkatesh C, Harshit Oberoi, Anurag Kumar Pandey, Anil Goyal, Nikhil Sikka",http://arxiv.org/pdf/2404.18963v1,cs.LG
Autonomous Quality and Hallucination Assessment for Virtual Tissue Staining and Digital Pathology,"Histopathological staining of human tissue is essential in the diagnosis of
various diseases. The recent advances in virtual tissue staining technologies
using AI alleviate some of the costly and tedious steps involved in the
traditional histochemical staining process, permitting multiplexed rapid
staining of label-free tissue without using staining reagents, while also
preserving tissue. However, potential hallucinations and artifacts in these
virtually stained tissue images pose concerns, especially for the clinical
utility of these approaches. Quality assessment of histology images is
generally performed by human experts, which can be subjective and depends on
the training level of the expert. Here, we present an autonomous quality and
hallucination assessment method (termed AQuA), mainly designed for virtual
tissue staining, while also being applicable to histochemical staining. AQuA
achieves 99.8% accuracy when detecting acceptable and unacceptable virtually
stained tissue images without access to ground truth, also presenting an
agreement of 98.5% with the manual assessments made by board-certified
pathologists. Besides, AQuA achieves super-human performance in identifying
realistic-looking, virtually stained hallucinatory images that would normally
mislead human diagnosticians by deceiving them into diagnosing patients that
never existed. We further demonstrate the wide adaptability of AQuA across
various virtually and histochemically stained tissue images and showcase its
strong external generalization to detect unseen hallucination patterns of
virtual staining network models as well as artifacts observed in the
traditional histochemical staining workflow. This framework creates new
opportunities to enhance the reliability of virtual staining and will provide
quality assurance for various image generation and transformation tasks in
digital pathology and computational imaging.",2024-04-29,"Luzhe Huang, Yuzhu Li, Nir Pillar, Tal Keidar Haran, William Dean Wallace, Aydogan Ozcan",http://arxiv.org/pdf/2404.18458v1,cs.LG
Strategic Behavior and AI Training Data,"Human-created works represent critical data inputs to artificial intelligence
(AI). Strategic behavior can play a major role for AI training datasets, be it
in limiting access to existing works or in deciding which types of new works to
create or whether to create new works at all. We examine creators' behavioral
change when their works become training data for AI. Specifically, we focus on
contributors on Unsplash, a popular stock image platform with about 6 million
high-quality photos and illustrations. In the summer of 2020, Unsplash launched
an AI research program by releasing a dataset of 25,000 images for commercial
use. We study contributors' reactions, comparing contributors whose works were
included in this dataset to contributors whose works were not included. Our
results suggest that treated contributors left the platform at a
higher-than-usual rate and substantially slowed down the rate of new uploads.
Professional and more successful photographers react stronger than amateurs and
less successful photographers. We also show that affected users changed the
variety and novelty of contributions to the platform, with long-run
implications for the stock of works potentially available for AI training.
Taken together, our findings highlight the trade-off between interests of
rightsholders and promoting innovation at the technological frontier. We
discuss implications for copyright and AI policy.",2024-04-29,"Christian Peukert, Florian Abeillon, Jérémie Haese, Franziska Kaiser, Alexander Staub",http://arxiv.org/pdf/2404.18445v1,cs.LG
"U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models","U-Nets are among the most widely used architectures in computer vision,
renowned for their exceptional performance in applications such as image
segmentation, denoising, and diffusion modeling. However, a theoretical
explanation of the U-Net architecture design has not yet been fully
established.
  This paper introduces a novel interpretation of the U-Net architecture by
studying certain generative hierarchical models, which are tree-structured
graphical models extensively utilized in both language and image domains. With
their encoder-decoder structure, long skip connections, and pooling and
up-sampling layers, we demonstrate how U-Nets can naturally implement the
belief propagation denoising algorithm in such generative hierarchical models,
thereby efficiently approximating the denoising functions. This leads to an
efficient sample complexity bound for learning the denoising function using
U-Nets within these models. Additionally, we discuss the broader implications
of these findings for diffusion models in generative hierarchical models. We
also demonstrate that the conventional architecture of convolutional neural
networks (ConvNets) is ideally suited for classification tasks within these
models. This offers a unified view of the roles of ConvNets and U-Nets,
highlighting the versatility of generative hierarchical models in modeling
complex data distributions across language and image domains.",2024-04-29,Song Mei,http://arxiv.org/pdf/2404.18444v2,cs.LG
An Aggregation-Free Federated Learning for Tackling Data Heterogeneity,"The performance of Federated Learning (FL) hinges on the effectiveness of
utilizing knowledge from distributed datasets. Traditional FL methods adopt an
aggregate-then-adapt framework, where clients update local models based on a
global model aggregated by the server from the previous training round. This
process can cause client drift, especially with significant cross-client data
heterogeneity, impacting model performance and convergence of the FL algorithm.
To address these challenges, we introduce FedAF, a novel aggregation-free FL
algorithm. In this framework, clients collaboratively learn condensed data by
leveraging peer knowledge, the server subsequently trains the global model
using the condensed data and soft labels received from the clients. FedAF
inherently avoids the issue of client drift, enhances the quality of condensed
data amid notable data heterogeneity, and improves the global model
performance. Extensive numerical studies on several popular benchmark datasets
show FedAF surpasses various state-of-the-art FL algorithms in handling
label-skew and feature-skew data heterogeneity, leading to superior global
model accuracy and faster convergence.",2024-04-29,"Yuan Wang, Huazhu Fu, Renuga Kanagavelu, Qingsong Wei, Yong Liu, Rick Siow Mong Goh",http://arxiv.org/pdf/2404.18962v1,cs.LG
Protein Representation Learning by Capturing Protein Sequence-Structure-Function Relationship,"The goal of protein representation learning is to extract knowledge from
protein databases that can be applied to various protein-related downstream
tasks. Although protein sequence, structure, and function are the three key
modalities for a comprehensive understanding of proteins, existing methods for
protein representation learning have utilized only one or two of these
modalities due to the difficulty of capturing the asymmetric interrelationships
between them. To account for this asymmetry, we introduce our novel asymmetric
multi-modal masked autoencoder (AMMA). AMMA adopts (1) a unified multi-modal
encoder to integrate all three modalities into a unified representation space
and (2) asymmetric decoders to ensure that sequence latent features reflect
structural and functional information. The experiments demonstrate that the
proposed AMMA is highly effective in learning protein representations that
exhibit well-aligned inter-modal relationships, which in turn makes it
effective for various downstream protein-related tasks.",2024-04-29,"Eunji Ko, Seul Lee, Minseon Kim, Dongki Kim",http://arxiv.org/pdf/2405.06663v1,cs.LG
Potential Paradigm Shift in Hazard Risk Management: AI-Based Weather Forecast for Tropical Cyclone Hazards,"The advents of Artificial Intelligence (AI)-driven models marks a paradigm
shift in risk management strategies for meteorological hazards. This study
specifically employs tropical cyclones (TCs) as a focal example. We engineer a
perturbation-based method to produce ensemble forecasts using the advanced
Pangu AI weather model. Unlike traditional approaches that often generate fewer
than 20 scenarios from Weather Research and Forecasting (WRF) simulations for
one event, our method facilitates the rapid nature of AI-driven model to create
thousands of scenarios. We offer open-source access to our model and evaluate
its effectiveness through retrospective case studies of significant TC events:
Hurricane Irma (2017), Typhoon Mangkhut (2018), and TC Debbie (2017), affecting
regions across North America, East Asia, and Australia. Our findings indicate
that the AI-generated ensemble forecasts align closely with the European Centre
for Medium-Range Weather Forecasts (ECMWF) ensemble predictions up to seven
days prior to landfall. This approach could substantially enhance the
effectiveness of weather forecast-driven risk analysis and management,
providing unprecedented operational speed, user-friendliness, and global
applicability.",2024-04-29,"Kairui Feng, Dazhi Xi, Wei Ma, Cao Wang, Yuanlong Li, Xuanhong Chen",http://arxiv.org/pdf/2404.18440v1,cs.LG
Learning bridge numbers of knots,"This paper employs various computational techniques to determine the bridge
numbers of both classical and virtual knots. For classical knots, there is no
ambiguity of what the bridge number means. For virtual knots, there are
multiple natural definitions of bridge number, and we demonstrate that the
difference can be arbitrarily far apart. We then acquired two datasets, one for
classical and one for virtual knots, each comprising over one million labeled
data points. With the data, we conduct experiments to evaluate the
effectiveness of common machine learning models in classifying knots based on
their bridge numbers.",2024-04-29,"Hanh Vo, Puttipong Pongtanapaisan, Thieu Nguyen",http://arxiv.org/pdf/2405.05272v1,cs.LG
"Unleashing the Power of Multi-Task Learning: A Comprehensive Survey Spanning Traditional, Deep, and Pretrained Foundation Model Eras","MTL is a learning paradigm that effectively leverages both task-specific and
shared information to address multiple related tasks simultaneously. In
contrast to STL, MTL offers a suite of benefits that enhance both the training
process and the inference efficiency. MTL's key advantages encompass
streamlined model architecture, performance enhancement, and cross-domain
generalizability. Over the past twenty years, MTL has become widely recognized
as a flexible and effective approach in various fields, including CV, NLP,
recommendation systems, disease prognosis and diagnosis, and robotics. This
survey provides a comprehensive overview of the evolution of MTL, encompassing
the technical aspects of cutting-edge methods from traditional approaches to
deep learning and the latest trend of pretrained foundation models. Our survey
methodically categorizes MTL techniques into five key areas: regularization,
relationship learning, feature propagation, optimization, and pre-training.
This categorization not only chronologically outlines the development of MTL
but also dives into various specialized strategies within each category.
Furthermore, the survey reveals how the MTL evolves from handling a fixed set
of tasks to embracing a more flexible approach free from task or modality
constraints. It explores the concepts of task-promptable and -agnostic
training, along with the capacity for ZSL, which unleashes the untapped
potential of this historically coveted learning paradigm. Overall, we hope this
survey provides the research community with a comprehensive overview of the
advancements in MTL from its inception in 1997 to the present in 2023. We
address present challenges and look ahead to future possibilities, shedding
light on the opportunities and potential avenues for MTL research in a broad
manner. This project is publicly available at
https://github.com/junfish/Awesome-Multitask-Learning.",2024-04-29,"Jun Yu, Yutong Dai, Xiaokang Liu, Jin Huang, Yishan Shen, Ke Zhang, Rong Zhou, Eashan Adhikarla, Wenxuan Ye, Yixin Liu, Zhaoming Kong, Kai Zhang, Yilong Yin, Vinod Namboodiri, Brian D. Davison, Jason H. Moore, Yong Chen",http://arxiv.org/pdf/2404.18961v1,cs.LG
Landmark Alternating Diffusion,"Alternating Diffusion (AD) is a commonly applied diffusion-based sensor
fusion algorithm. While it has been successfully applied to various problems,
its computational burden remains a limitation. Inspired by the landmark
diffusion idea considered in the Robust and Scalable Embedding via Landmark
Diffusion (ROSELAND), we propose a variation of AD, called Landmark AD (LAD),
which captures the essence of AD while offering superior computational
efficiency. We provide a series of theoretical analyses of LAD under the
manifold setup and apply it to the automatic sleep stage annotation problem
with two electroencephalogram channels to demonstrate its application.",2024-04-29,"Sing-Yuan Yeh, Hau-Tieng Wu, Ronen Talmon, Mao-Pei Tsui",http://arxiv.org/pdf/2404.19649v1,cs.LG
Artificial General Intelligence (AGI)-Native Wireless Systems: A Journey Beyond 6G,"Building future wireless systems that support services like digital twins
(DTs) is challenging to achieve through advances to conventional technologies
like meta-surfaces. While artificial intelligence (AI)-native networks promise
to overcome some limitations of wireless technologies, developments still rely
on AI tools like neural networks. Such tools struggle to cope with the
non-trivial challenges of the network environment and the growing demands of
emerging use cases. In this paper, we revisit the concept of AI-native wireless
systems, equipping them with the common sense necessary to transform them into
artificial general intelligence (AGI)-native systems. These systems acquire
common sense by exploiting different cognitive abilities such as perception,
analogy, and reasoning, that enable them to generalize and deal with unforeseen
scenarios. Towards developing the components of such a system, we start by
showing how the perception module can be built through abstracting real-world
elements into generalizable representations. These representations are then
used to create a world model, founded on principles of causality and
hyper-dimensional (HD) computing, that aligns with intuitive physics and
enables analogical reasoning, that define common sense. Then, we explain how
methods such as integrated information theory play a role in the proposed
intent-driven and objective-driven planning methods that maneuver the
AGI-native network to take actions. Next, we discuss how an AGI-native network
can enable use cases related to human and autonomous agents: a) analogical
reasoning for next-generation DTs, b) synchronized and resilient experiences
for cognitive avatars, and c) brain-level metaverse experiences like
holographic teleportation. Finally, we conclude with a set of recommendations
to build AGI-native systems. Ultimately, we envision this paper as a roadmap
for the beyond 6G era.",2024-04-29,"Walid Saad, Omar Hashash, Christo Kurisummoottil Thomas, Christina Chaccour, Merouane Debbah, Narayan Mandayam, Zhu Han",http://arxiv.org/pdf/2405.02336v1,cs.LG
Leak Proof CMap; a framework for training and evaluation of cell line agnostic L1000 similarity methods,"The Connectivity Map (CMap) is a large publicly available database of
cellular transcriptomic responses to chemical and genetic perturbations built
using a standardized acquisition protocol known as the L1000 technique.
Databases such as CMap provide an exciting opportunity to enrich drug discovery
efforts, providing a 'known' phenotypic landscape to explore and enabling the
development of state of the art techniques for enhanced information extraction
and better informed decisions. Whilst multiple methods for measuring phenotypic
similarity and interrogating profiles have been developed, the field is
severely lacking standardized benchmarks using appropriate data splitting for
training and unbiased evaluation of machine learning methods. To address this,
we have developed 'Leak Proof CMap' and exemplified its application to a set of
common transcriptomic and generic phenotypic similarity methods along with an
exemplar triplet loss-based method. Benchmarking in three critical performance
areas (compactness, distinctness, and uniqueness) is conducted using carefully
crafted data splits ensuring no similar cell lines or treatments with shared or
closely matching responses or mechanisms of action are present in training,
validation, or test sets. This enables testing of models with unseen samples
akin to exploring treatments with novel modes of action in novel patient
derived cell lines. With a carefully crafted benchmark and data splitting
regime in place, the tooling now exists to create performant phenotypic
similarity methods for use in personalized medicine (novel cell lines) and to
better augment high throughput phenotypic screening technologies with the L1000
transcriptomic technology.",2024-04-29,"Steven Shave, Richard Kasprowicz, Abdullah M. Athar, Denise Vlachou, Neil O. Carragher, Cuong Q. Nguyen",http://arxiv.org/pdf/2404.18960v1,cs.LG
Capabilities of Gemini Models in Medicine,"Excellence in a wide variety of medical applications poses considerable
challenges for AI, requiring advanced reasoning, access to up-to-date medical
knowledge and understanding of complex multimodal data. Gemini models, with
strong general capabilities in multimodal and long-context reasoning, offer
exciting possibilities in medicine. Building on these core strengths of Gemini,
we introduce Med-Gemini, a family of highly capable multimodal models that are
specialized in medicine with the ability to seamlessly use web search, and that
can be efficiently tailored to novel modalities using custom encoders. We
evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
benchmark where a direct comparison is viable, often by a wide margin. On the
popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
(health & medicine), Med-Gemini improves over GPT-4V by an average relative
margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
capabilities through SoTA performance on a needle-in-a-haystack retrieval task
from long de-identified health records and medical video question answering,
surpassing prior bespoke methods using only in-context learning. Finally,
Med-Gemini's performance suggests real-world utility by surpassing human
experts on tasks such as medical text summarization, alongside demonstrations
of promising potential for multimodal medical dialogue, medical research and
education. Taken together, our results offer compelling evidence for
Med-Gemini's potential, although further rigorous evaluation will be crucial
before real-world deployment in this safety-critical domain.",2024-04-29,"Khaled Saab, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, Tim Strother, Chunjong Park, Elahe Vedadi, Juanma Zambrano Chaves, Szu-Yeu Hu, Mike Schaekermann, Aishwarya Kamath, Yong Cheng, David G. T. Barrett, Cathy Cheung, Basil Mustafa, Anil Palepu, Daniel McDuff, Le Hou, Tomer Golany, Luyang Liu, Jean-baptiste Alayrac, Neil Houlsby, Nenad Tomasev, Jan Freyberg, Charles Lau, Jonas Kemp, Jeremy Lai, Shekoofeh Azizi, Kimberly Kanada, SiWai Man, Kavita Kulkarni, Ruoxi Sun, Siamak Shakeri, Luheng He, Ben Caine, Albert Webson, Natasha Latysheva, Melvin Johnson, Philip Mansfield, Jian Lu, Ehud Rivlin, Jesper Anderson, Bradley Green, Renee Wong, Jonathan Krause, Jonathon Shlens, Ewa Dominowska, S. M. Ali Eslami, Katherine Chou, Claire Cui, Oriol Vinyals, Koray Kavukcuoglu, James Manyika, Jeff Dean, Demis Hassabis, Yossi Matias, Dale Webster, Joelle Barral, Greg Corrado, Christopher Semturs, S. Sara Mahdavi, Juraj Gottweis, Alan Karthikesalingam, Vivek Natarajan",http://arxiv.org/pdf/2404.18416v2,cs.LG
Learning a Sparse Neural Network using IHT,"The core of a good model is in its ability to focus only on important
information that reflects the basic patterns and consistencies, thus pulling
out a clear, noise-free signal from the dataset. This necessitates using a
simplified model defined by fewer parameters. The importance of theoretical
foundations becomes clear in this context, as this paper relies on established
results from the domain of advanced sparse optimization, particularly those
addressing nonlinear differentiable functions. The need for such theoretical
foundations is further highlighted by the trend that as computational power for
training NNs increases, so does the complexity of the models in terms of a
higher number of parameters. In practical scenarios, these large models are
often simplified to more manageable versions with fewer parameters.
  Understanding why these simplified models with less number of parameters
remain effective raises a crucial question. Understanding why these simplified
models with fewer parameters remain effective raises an important question.
This leads to the broader question of whether there is a theoretical framework
that can clearly explain these empirical observations. Recent developments,
such as establishing necessary conditions for the convergence of iterative hard
thresholding (IHT) to a sparse local minimum (a sparse method analogous to
gradient descent) are promising. The remarkable capacity of the IHT algorithm
to accurately identify and learn the locations of nonzero parameters
underscores its practical effectiveness and utility.
  This paper aims to investigate whether the theoretical prerequisites for such
convergence are applicable in the realm of neural network (NN) training by
providing justification for all the necessary conditions for convergence. Then,
these conditions are validated by experiments on a single-layer NN, using the
IRIS dataset as a testbed.",2024-04-29,"Saeed Damadi, Soroush Zolfaghari, Mahdi Rezaie, Jinglai Shen",http://arxiv.org/pdf/2404.18414v2,cs.LG
"LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report","Low Rank Adaptation (LoRA) has emerged as one of the most widely adopted
methods for Parameter Efficient Fine-Tuning (PEFT) of Large Language Models
(LLMs). LoRA reduces the number of trainable parameters and memory usage while
achieving comparable performance to full fine-tuning. We aim to assess the
viability of training and serving LLMs fine-tuned with LoRA in real-world
applications. First, we measure the quality of LLMs fine-tuned with quantized
low rank adapters across 10 base models and 31 tasks for a total of 310 models.
We find that 4-bit LoRA fine-tuned models outperform base models by 34 points
and GPT-4 by 10 points on average. Second, we investigate the most effective
base models for fine-tuning and assess the correlative and predictive
capacities of task complexity heuristics in forecasting the outcomes of
fine-tuning. Finally, we evaluate the latency and concurrency capabilities of
LoRAX, an open-source Multi-LoRA inference server that facilitates the
deployment of multiple LoRA fine-tuned models on a single GPU using shared base
model weights and dynamic adapter loading. LoRAX powers LoRA Land, a web
application that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA
A100 GPU with 80GB memory. LoRA Land highlights the quality and
cost-effectiveness of employing multiple specialized LLMs over a single,
general-purpose LLM.",2024-04-29,"Justin Zhao, Timothy Wang, Wael Abid, Geoffrey Angus, Arnav Garg, Jeffery Kinnison, Alex Sherstinsky, Piero Molino, Travis Addair, Devvret Rishi",http://arxiv.org/pdf/2405.00732v1,cs.LG
Deep generative modelling of canonical ensemble with differentiable thermal properties,"We propose a variational modelling method with differentiable temperature for
canonical ensembles. Using a deep generative model, the free energy is
estimated and minimized simultaneously in a continuous temperature range. At
optimal, this generative model is a Boltzmann distribution with temperature
dependence. The training process requires no dataset, and works with arbitrary
explicit density generative models. We applied our method to study the phase
transitions (PT) in the Ising and XY models, and showed that the
direct-sampling simulation of our model is as accurate as the Markov Chain
Monte Carlo (MCMC) simulation, but more efficient. Moreover, our method can
give thermodynamic quantities as differentiable functions of temperature akin
to an analytical solution. The free energy aligns closely with the exact one to
the second-order derivative, so this inclusion of temperature dependence
enables the otherwise biased variational model to capture the subtle thermal
effects at the PTs. These findings shed light on the direct simulation of
physical systems using deep generative models",2024-04-29,"Shuo-Hui Li, Yao-Wen Zhang, Ding Pan",http://arxiv.org/pdf/2404.18404v1,cs.LG
LLM-SR: Scientific Equation Discovery via Programming with Large Language Models,"Mathematical equations have been unreasonably effective in describing complex
natural phenomena across various scientific disciplines. However, discovering
such insightful equations from data presents significant challenges due to the
necessity of navigating extremely large combinatorial hypothesis spaces.
Current methods of equation discovery, commonly known as symbolic regression
techniques, largely focus on extracting equations from data alone, often
neglecting the domain-specific prior knowledge that scientists typically depend
on. They also employ limited representations such as expression trees,
constraining the search space and expressiveness of equations. To bridge this
gap, we introduce LLM-SR, a novel approach that leverages the extensive
scientific knowledge and robust code generation capabilities of Large Language
Models (LLMs) to discover scientific equations from data. Specifically, LLM-SR
treats equations as programs with mathematical operators and combines LLMs'
scientific priors with evolutionary search over equation programs. The LLM
iteratively proposes new equation skeleton hypotheses, drawing from its domain
knowledge, which are then optimized against data to estimate parameters. We
evaluate LLM-SR on four benchmark problems across diverse scientific domains
(e.g., physics, biology), which we carefully designed to simulate the discovery
process and prevent LLM recitation. Our results demonstrate that LLM-SR
discovers physically accurate equations that significantly outperform
state-of-the-art symbolic regression baselines, particularly in out-of-domain
test settings. We also show that LLM-SR's incorporation of scientific priors
enables more efficient equation space exploration than the baselines. Code and
data are available: https://github.com/deep-symbolic-mathematics/LLM-SR",2024-04-29,"Parshin Shojaee, Kazem Meidani, Shashank Gupta, Amir Barati Farimani, Chandan K Reddy",http://arxiv.org/pdf/2404.18400v3,cs.LG
Physics-informed Convolutional Neural Network for Microgrid Economic Dispatch,"The variability of renewable energy generation and the unpredictability of
electricity demand create a need for real-time economic dispatch (ED) of assets
in microgrids. However, solving numerical optimization problems in real-time
can be incredibly challenging. This study proposes using a convolutional neural
network (CNN) based on deep learning to address these challenges. Compared to
traditional methods, CNN is more efficient, delivers more dependable results,
and has a shorter response time when dealing with uncertainties. While CNN has
shown promising results, it does not extract explainable knowledge from the
data. To address this limitation, a physics-inspired CNN model is developed by
incorporating constraints of the ED problem into the CNN training to ensure
that the model follows physical laws while fitting the data. The proposed
method can significantly accelerate real-time economic dispatch of microgrids
without compromising the accuracy of numerical optimization techniques. The
effectiveness of the proposed data-driven approach for optimal allocation of
microgrid resources in real-time is verified through a comprehensive comparison
with conventional numerical optimization approaches.",2024-04-29,"Xiaoyu Ge, Javad Khazaei",http://arxiv.org/pdf/2404.18362v2,cs.LG
SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies,"While Deep Reinforcement Learning (DRL) has emerged as a promising solution
for intricate control tasks, the lack of explainability of the learned policies
impedes its uptake in safety-critical applications, such as automated driving
systems (ADS). Counterfactual (CF) explanations have recently gained prominence
for their ability to interpret black-box Deep Learning (DL) models. CF examples
are associated with minimal changes in the input, resulting in a complementary
output by the DL model. Finding such alternations, particularly for
high-dimensional visual inputs, poses significant challenges. Besides, the
temporal dependency introduced by the reliance of the DRL agent action on a
history of past state observations further complicates the generation of CF
examples. To address these challenges, we propose using a saliency map to
identify the most influential input pixels across the sequence of past observed
states by the agent. Then, we feed this map to a deep generative model,
enabling the generation of plausible CFs with constrained modifications centred
on the salient regions. We evaluate the effectiveness of our framework in
diverse domains, including ADS, Atari Pong, Pacman and space-invaders games,
using traditional performance metrics such as validity, proximity and sparsity.
Experimental results demonstrate that this framework generates more informative
and plausible CFs than the state-of-the-art for a wide range of environments
and DRL agents. In order to foster research in this area, we have made our
datasets and codes publicly available at
https://github.com/Amir-Samadi/SAFE-RL.",2024-04-28,"Amir Samadi, Konstantinos Koufos, Kurt Debattista, Mehrdad Dianati",http://arxiv.org/pdf/2404.18326v1,cs.LG
Position: Do Not Explain Vision Models Without Context,"Does the stethoscope in the picture make the adjacent person a doctor or a
patient? This, of course, depends on the contextual relationship of the two
objects. If it's obvious, why don't explanation methods for vision models use
contextual information? In this paper, we (1) review the most popular methods
of explaining computer vision models by pointing out that they do not take into
account context information, (2) show examples of failures of popular XAI
methods, (3) provide examples of real-world use cases where spatial context
plays a significant role, (4) propose new research directions that may lead to
better use of context information in explaining computer vision models, (5)
argue that a change in approach to explanations is needed from 'where' to
'how'.",2024-04-28,"Paulina Tomaszewska, Przemysław Biecek",http://arxiv.org/pdf/2404.18316v3,cs.LG
"DIRESA, a distance-preserving nonlinear dimension reduction technique based on regularized autoencoders","In meteorology, finding similar weather patterns or analogs in historical
datasets can be useful for data assimilation, forecasting, and postprocessing.
In climate science, analogs in historical and climate projection data are used
for attribution and impact studies. However, most of the time, those large
weather and climate datasets are nearline. This means that they must be
downloaded, which takes a lot of bandwidth and disk space, before the
computationally expensive search can be executed. We propose a dimension
reduction technique based on autoencoder (AE) neural networks to compress the
datasets and perform the search in an interpretable, compressed latent space. A
distance-regularized Siamese twin autoencoder (DIRESA) architecture is designed
to preserve distance in latent space while capturing the nonlinearities in the
datasets. Using conceptual climate models of different complexities, we show
that the latent components thus obtained provide physical insight into the
dominant modes of variability in the system. Compressing datasets with DIRESA
reduces the online storage and keeps the latent components uncorrelated, while
the distance (ordering) preservation and reconstruction fidelity robustly
outperform Principal Component Analysis (PCA) and other dimension reduction
techniques such as UMAP or variational autoencoders.",2024-04-28,"Geert De Paepe, Lesley De Cruz",http://arxiv.org/pdf/2404.18314v2,cs.LG
Towards Incremental Learning in Large Language Models: A Critical Review,"Incremental learning is the ability of systems to acquire knowledge over
time, enabling their adaptation and generalization to novel tasks. It is a
critical ability for intelligent, real-world systems, especially when data
changes frequently or is limited. This review provides a comprehensive analysis
of incremental learning in Large Language Models. It synthesizes the
state-of-the-art incremental learning paradigms, including continual learning,
meta-learning, parameter-efficient learning, and mixture-of-experts learning.
We demonstrate their utility for incremental learning by describing specific
achievements from these related topics and their critical factors. An important
finding is that many of these approaches do not update the core model, and none
of them update incrementally in real-time. The paper highlights current
problems and challenges for future research in the field. By consolidating the
latest relevant research developments, this review offers a comprehensive
understanding of incremental learning and its implications for designing and
developing LLM-based learning systems.",2024-04-28,"Mladjan Jovanovic, Peter Voss",http://arxiv.org/pdf/2404.18311v4,cs.LG
Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms,"Recent work on decentralized computational trust models for open Multi Agent
Systems has resulted in the development of CA, a biologically inspired model
which focuses on the trustee's perspective. This new model addresses a serious
unresolved problem in existing trust and reputation models, namely the
inability to handle constantly changing behaviors and agents' continuous entry
and exit from the system. In previous work, we compared CA to FIRE, a
well-known trust and reputation model, and found that CA is superior when the
trustor population changes, whereas FIRE is more resilient to the trustee
population changes. Thus, in this paper, we investigate how the trustors can
detect the presence of several dynamic factors in their environment and then
decide which trust model to employ in order to maximize utility. We frame this
problem as a machine learning problem in a partially observable environment,
where the presence of several dynamic factors is not known to the trustor and
we describe how an adaptable trustor can rely on a few measurable features so
as to assess the current state of the environment and then use Deep Q Learning
(DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt
to a changing environment. We ran a series of simulation experiments to compare
the performance of the adaptable trustor with the performance of trustors using
only one model (FIRE or CA) and we show that an adaptable agent is indeed
capable of learning when to use each model and, thus, perform consistently in
dynamic environments.",2024-04-28,"Zoi Lygizou, Dimitris Kalles",http://arxiv.org/pdf/2404.18296v1,cs.LG
Joint Energy and Latency Optimization in Federated Learning over Cell-Free Massive MIMO Networks,"Federated learning (FL) is a distributed learning paradigm wherein users
exchange FL models with a server instead of raw datasets, thereby preserving
data privacy and reducing communication overhead. However, the increased number
of FL users may hinder completing large-scale FL over wireless networks due to
high imposed latency. Cell-free massive multiple-input
multiple-output~(CFmMIMO) is a promising architecture for implementing FL
because it serves many users on the same time/frequency resources. While
CFmMIMO enhances energy efficiency through spatial multiplexing and
collaborative beamforming, it remains crucial to meticulously allocate uplink
transmission powers to the FL users. In this paper, we propose an uplink power
allocation scheme in FL over CFmMIMO by considering the effect of each user's
power on the energy and latency of other users to jointly minimize the users'
uplink energy and the latency of FL training. The proposed solution algorithm
is based on the coordinate gradient descent method. Numerical results show that
our proposed method outperforms the well-known max-sum rate by increasing up
to~$27$\% and max-min energy efficiency of the Dinkelbach method by increasing
up to~$21$\% in terms of test accuracy while having limited uplink energy and
latency budget for FL over CFmMIMO.",2024-04-28,"Afsaneh Mahmoudi, Mahmoud Zaher, Emil Björnson",http://arxiv.org/pdf/2404.18287v1,cs.LG
Improve Academic Query Resolution through BERT-based Question Extraction from Images,"Providing fast and accurate resolution to the student's query is an essential
solution provided by Edtech organizations. This is generally provided with a
chat-bot like interface to enable students to ask their doubts easily. One
preferred format for student queries is images, as it allows students to
capture and post questions without typing complex equations and information.
However, this format also presents difficulties, as images may contain multiple
questions or textual noise that lowers the accuracy of existing single-query
answering solutions. In this paper, we propose a method for extracting
questions from text or images using a BERT-based deep learning model and
compare it to the other rule-based and layout-based methods. Our method aims to
improve the accuracy and efficiency of student query resolution in Edtech
organizations.",2024-04-28,"Nidhi Kamal, Saurabh Yadav, Jorawar Singh, Aditi Avasthi",http://arxiv.org/pdf/2405.01587v1,cs.LG
Kernel Corrector LSTM,"Forecasting methods are affected by data quality issues in two ways: 1. they
are hard to predict, and 2. they may affect the model negatively when it is
updated with new data. The latter issue is usually addressed by pre-processing
the data to remove those issues. An alternative approach has recently been
proposed, Corrector LSTM (cLSTM), which is a Read \& Write Machine Learning
(RW-ML) algorithm that changes the data while learning to improve its
predictions. Despite promising results being reported, cLSTM is computationally
expensive, as it uses a meta-learner to monitor the hidden states of the LSTM.
We propose a new RW-ML algorithm, Kernel Corrector LSTM (KcLSTM), that replaces
the meta-learner of cLSTM with a simpler method: Kernel Smoothing. We
empirically evaluate the forecasting accuracy and the training time of the new
algorithm and compare it with cLSTM and LSTM. Results indicate that it is able
to decrease the training time while maintaining a competitive forecasting
accuracy.",2024-04-28,"Rodrigo Tuna, Yassine Baghoussi, Carlos Soares, João Mendes-Moreira",http://arxiv.org/pdf/2404.18273v1,cs.LG
Parameter-Efficient Tuning Large Language Models for Graph Representation Learning,"Text-rich graphs, which exhibit rich textual information on nodes and edges,
are prevalent across a wide range of real-world business applications. Large
Language Models (LLMs) have demonstrated remarkable abilities in understanding
text, which also introduced the potential for more expressive modeling in
text-rich graphs. Despite these capabilities, efficiently applying LLMs to
representation learning on graphs presents significant challenges. Recently,
parameter-efficient fine-tuning methods for LLMs have enabled efficient new
task generalization with minimal time and memory consumption. Inspired by this,
we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
approach for efficient graph representation learning with LLMs on text-rich
graphs. Specifically, we utilize a graph neural network (GNN) to encode
structural information from neighboring nodes into a graph prompt. This prompt
is then inserted at the beginning of the text sequence. To improve the quality
of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
the next token in the node text. Compared with existing joint GNN and LMs, our
method directly generate the node embeddings from large language models with an
affordable fine-tuning cost. We validate our approach through comprehensive
experiments conducted on 8 different text-rich graphs, observing an average
improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
evaluations. Our results demonstrate the efficacy and efficiency of our model,
showing that it can be smoothly integrated with various large language models,
including OPT, LLaMA and Falcon.",2024-04-28,"Qi Zhu, Da Zheng, Xiang Song, Shichang Zhang, Bowen Jin, Yizhou Sun, George Karypis",http://arxiv.org/pdf/2404.18271v1,cs.LG
LINOCS: Lookahead Inference of Networked Operators for Continuous Stability,"Identifying latent interactions within complex systems is key to unlocking
deeper insights into their operational dynamics, including how their elements
affect each other and contribute to the overall system behavior. For instance,
in neuroscience, discovering neuron-to-neuron interactions is essential for
understanding brain function; in ecology, recognizing the interactions among
populations is key for understanding complex ecosystems. Such systems, often
modeled as dynamical systems, typically exhibit noisy high-dimensional and
non-stationary temporal behavior that renders their identification challenging.
Existing dynamical system identification methods often yield operators that
accurately capture short-term behavior but fail to predict long-term trends,
suggesting an incomplete capture of the underlying process. Methods that
consider extended forecasts (e.g., recurrent neural networks) lack explicit
representations of element-wise interactions and require substantial training
data, thereby failing to capture interpretable network operators. Here we
introduce Lookahead-driven Inference of Networked Operators for Continuous
Stability (LINOCS), a robust learning procedure for identifying hidden
dynamical interactions in noisy time-series data. LINOCS integrates several
multi-step predictions with adaptive weights during training to recover
dynamical operators that can yield accurate long-term predictions. We
demonstrate LINOCS' ability to recover the ground truth dynamical operators
underlying synthetic time-series data for multiple dynamical systems models
(including linear, piece-wise linear, time-changing linear systems'
decomposition, and regularized linear time-varying systems) as well as its
capability to produce meaningful operators with robust reconstructions through
various real-world examples.",2024-04-28,"Noga Mudrik, Eva Yezerets, Yenho Chen, Christopher Rozell, Adam Charles",http://arxiv.org/pdf/2404.18267v1,cs.LG
Efficient Remote Sensing with Harmonized Transfer Learning and Modality Alignment,"With the rise of Visual and Language Pretraining (VLP), an increasing number
of downstream tasks are adopting the paradigm of pretraining followed by
fine-tuning. Although this paradigm has demonstrated potential in various
multimodal downstream tasks, its implementation in the remote sensing domain
encounters some obstacles. Specifically, the tendency for same-modality
embeddings to cluster together impedes efficient transfer learning. To tackle
this issue, we review the aim of multimodal transfer learning for downstream
tasks from a unified perspective, and rethink the optimization process based on
three distinct objectives. We propose ""Harmonized Transfer Learning and
Modality Alignment (HarMA)"", a method that simultaneously satisfies task
constraints, modality alignment, and single-modality uniform alignment, while
minimizing training overhead through parameter-efficient fine-tuning.
Remarkably, without the need for external data for training, HarMA achieves
state-of-the-art performance in two popular multimodal retrieval tasks in the
field of remote sensing. Our experiments reveal that HarMA achieves competitive
and even superior performance to fully fine-tuned models with only minimal
adjustable parameters. Due to its simplicity, HarMA can be integrated into
almost all existing multimodal pretraining models. We hope this method can
facilitate the efficient application of large models to a wide range of
downstream tasks while significantly reducing the resource consumption. Code is
available at https://github.com/seekerhuang/HarMA.",2024-04-28,Tengjun Huang,http://arxiv.org/pdf/2404.18253v5,cs.LG
Machine Learning for Blockchain Data Analysis: Progress and Opportunities,"Blockchain technology has rapidly emerged to mainstream attention, while its
publicly accessible, heterogeneous, massive-volume, and temporal data are
reminiscent of the complex dynamics encountered during the last decade of big
data. Unlike any prior data source, blockchain datasets encompass multiple
layers of interactions across real-world entities, e.g., human users,
autonomous programs, and smart contracts. Furthermore, blockchain's integration
with cryptocurrencies has introduced financial aspects of unprecedented scale
and complexity such as decentralized finance, stablecoins, non-fungible tokens,
and central bank digital currencies. These unique characteristics present both
opportunities and challenges for machine learning on blockchain data.
  On one hand, we examine the state-of-the-art solutions, applications, and
future directions associated with leveraging machine learning for blockchain
data analysis critical for the improvement of blockchain technology such as
e-crime detection and trends prediction. On the other hand, we shed light on
the pivotal role of blockchain by providing vast datasets and tools that can
catalyze the growth of the evolving machine learning ecosystem. This paper
serves as a comprehensive resource for researchers, practitioners, and
policymakers, offering a roadmap for navigating this dynamic and transformative
field.",2024-04-28,"Poupak Azad, Cuneyt Gurcan Akcora, Arijit Khan",http://arxiv.org/pdf/2404.18251v1,cs.LG
Classical integrability in the presence of a cosmological constant: analytic and machine learning results,"We study the integrability of two-dimensional theories that are obtained by a
dimensional reduction of certain four-dimensional gravitational theories
describing the coupling of Maxwell fields and neutral scalar fields to gravity
in the presence of a potential for the neutral scalar fields. For a certain
solution subspace, we demonstrate partial integrability by showing that a
subset of the equations of motion in two dimensions are the compatibility
conditions for a linear system. Subsequently, we study the integrability of
these two-dimensional models from a complementary one-dimensional point of
view, framed in terms of Liouville integrability. In this endeavour, we employ
various machine learning techniques to systematise our search for numerical Lax
pair matrices for these models, as well as conserved currents expressed as
functions of phase space variables.",2024-04-28,"Gabriel Lopes Cardoso, Damián Mayorga Peña, Suresh Nampuri",http://arxiv.org/pdf/2404.18247v3,cs.LG
AdaFSNet: Time Series Classification Based on Convolutional Network with a Adaptive and Effective Kernel Size Configuration,"Time series classification is one of the most critical and challenging
problems in data mining, existing widely in various fields and holding
significant research importance. Despite extensive research and notable
achievements with successful real-world applications, addressing the challenge
of capturing the appropriate receptive field (RF) size from one-dimensional or
multi-dimensional time series of varying lengths remains a persistent issue,
which greatly impacts performance and varies considerably across different
datasets. In this paper, we propose an Adaptive and Effective Full-Scope
Convolutional Neural Network (AdaFSNet) to enhance the accuracy of time series
classification. This network includes two Dense Blocks. Particularly, it can
dynamically choose a range of kernel sizes that effectively encompass the
optimal RF size for various datasets by incorporating multiple prime numbers
corresponding to the time series length. We also design a TargetDrop block,
which can reduce redundancy while extracting a more effective RF. To assess the
effectiveness of the AdaFSNet network, comprehensive experiments were conducted
using the UCR and UEA datasets, which include one-dimensional and
multi-dimensional time series data, respectively. Our model surpassed baseline
models in terms of classification accuracy, underscoring the AdaFSNet network's
efficiency and effectiveness in handling time series classification tasks.",2024-04-28,"Haoxiao Wang, Bo Peng, Jianhua Zhang, Xu Cheng",http://arxiv.org/pdf/2404.18246v1,cs.LG
LEGENT: Open Platform for Embodied Agents,"Despite advancements in Large Language Models (LLMs) and Large Multimodal
Models (LMMs), their integration into language-grounded, human-like embodied
agents remains incomplete, hindering complex real-life task performance in
physical environments. Existing integrations often feature limited open
sourcing, challenging collective progress in this field. We introduce LEGENT,
an open, scalable platform for developing embodied agents using LLMs and LMMs.
LEGENT offers a dual approach: a rich, interactive 3D environment with
communicable and actionable agents, paired with a user-friendly interface, and
a sophisticated data generation pipeline utilizing advanced algorithms to
exploit supervision from simulated worlds at scale. In our experiments, an
embryonic vision-language-action model trained on LEGENT-generated data
surpasses GPT-4V in embodied tasks, showcasing promising generalization
capabilities.",2024-04-28,"Zhili Cheng, Zhitong Wang, Jinyi Hu, Shengding Hu, An Liu, Yuge Tu, Pengkai Li, Lei Shi, Zhiyuan Liu, Maosong Sun",http://arxiv.org/pdf/2404.18243v2,cs.LG
SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning,"Large Language Models (LLMs) have highlighted the necessity of effective
unlearning mechanisms to comply with data regulations and ethical AI practices.
LLM unlearning aims at removing undesired data influences and associated model
capabilities without compromising utility beyond the scope of unlearning. While
interest in studying LLM unlearning is growing, the impact of the optimizer
choice for LLM unlearning remains unexplored. In this work, we shed light on
the significance of optimizer selection in LLM unlearning for the first time,
establishing a clear connection between second-order optimization and influence
unlearning (a classical approach using influence functions to update the model
for data influence removal). This insight propels us to develop a second-order
optimization-based LLM unlearning framework, termed Second-Order UnLearning
(SOUL), which extends the static, one-shot model update using influence
unlearning to a dynamic, iterative unlearning process. Our extensive
experiments show that SOUL consistently outperforms conventional first-order
methods across various unlearning tasks, models, and metrics, indicating that
second-order optimization offers an effective and broadly applicable solution
for LLM unlearning. Codes are available at https://github.com/OPTML-Group/SOUL.",2024-04-28,"Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu",http://arxiv.org/pdf/2404.18239v4,cs.LG
A Note on Asynchronous Challenges: Unveiling Formulaic Bias and Data Loss in the Hayashi-Yoshida Estimator,"The Hayashi-Yoshida (\HY)-estimator exhibits an intrinsic, telescoping
property that leads to an often overlooked computational bias, which we
denote,formulaic or intrinsic bias. This formulaic bias results in data loss by
cancelling out potentially relevant data points, the nonextant data points.
This paper attempts to formalize and quantify the data loss arising from this
bias. In particular, we highlight the existence of nonextant data points via a
concrete example, and prove necessary and sufficient conditions for the
telescoping property to induce this type of formulaic bias.Since this type of
bias is nonexistent when inputs, i.e., observation times, $\Pi^{(1)}
:=(t_i^{(1)})_{i=0,1,\ldots}$ and $\Pi^{(2)} :=(t_j^{(2)})_{j=0,1,\ldots}$, are
synchronous, we introduce the (a,b)-asynchronous adversary. This adversary
generates inputs $\Pi^{(1)}$ and $\Pi^{(2)}$ according to two independent
homogenous Poisson processes with rates a>0 and b>0, respectively. We address
the foundational questions regarding cumulative minimal (or least) average data
point loss, and determine the values for a and b. We prove that for equal rates
a=b, the minimal average cumulative data loss over both inputs is attained and
amounts to 25\%. We present an algorithm, which is based on our theorem, for
computing the exact number of nonextant data points given inputs $\Pi^{(1)}$
and $\Pi^{(2)}$, and suggest alternative methods. Finally, we use simulated
data to empirically compare the (cumulative) average data loss of the
(\HY)-estimator.",2024-04-28,Evangelos Georgiadis,http://arxiv.org/pdf/2404.18233v1,cs.LG
TextGram: Towards a better domain-adaptive pretraining,"For green AI, it is crucial to measure and reduce the carbon footprint
emitted during the training of large language models. In NLP, performing
pre-training on Transformer models requires significant computational
resources. This pre-training involves using a large amount of text data to gain
prior knowledge for performing downstream tasks. Thus, it is important that we
select the correct data in the form of domain-specific data from this vast
corpus to achieve optimum results aligned with our domain-specific tasks. While
training on large unsupervised data is expensive, it can be optimized by
performing a data selection step before pretraining. Selecting important data
reduces the space overhead and the substantial amount of time required to
pre-train the model while maintaining constant accuracy. We investigate the
existing selection strategies and propose our own domain-adaptive data
selection method - TextGram - that effectively selects essential data from
large corpora. We compare and evaluate the results of finetuned models for text
classification task with and without data selection. We show that the proposed
strategy works better compared to other selection methods.",2024-04-28,"Sharayu Hiwarkhedkar, Saloni Mittal, Vidula Magdum, Omkar Dhekane, Raviraj Joshi, Geetanjali Kale, Arnav Ladkat",http://arxiv.org/pdf/2404.18228v1,cs.LG
BUFF: Boosted Decision Tree based Ultra-Fast Flow matching,"Tabular data stands out as one of the most frequently encountered types in
high energy physics. Unlike commonly homogeneous data such as pixelated images,
simulating high-dimensional tabular data and accurately capturing their
correlations are often quite challenging, even with the most advanced
architectures. Based on the findings that tree-based models surpass the
performance of deep learning models for tasks specific to tabular data, we
adopt the very recent generative modeling class named conditional flow matching
and employ different techniques to integrate the usage of Gradient Boosted
Trees. The performances are evaluated for various tasks on different analysis
level with several public datasets. We demonstrate the training and inference
time of most high-level simulation tasks can achieve speedup by orders of
magnitude. The application can be extended to low-level feature simulation and
conditioned generations with competitive performance.",2024-04-28,"Cheng Jiang, Sitian Qian, Huilin Qu",http://arxiv.org/pdf/2404.18219v1,cs.LG
L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi,"The availability of text or topic classification datasets in the low-resource
Marathi language is limited, typically consisting of fewer than 4 target
labels, with some achieving nearly perfect accuracy. In this work, we introduce
L3Cube-MahaNews, a Marathi text classification corpus that focuses on News
headlines and articles. This corpus stands out as the largest supervised
Marathi Corpus, containing over 1.05L records classified into a diverse range
of 12 categories. To accommodate different document lengths, MahaNews comprises
three supervised datasets specifically designed for short text, long documents,
and medium paragraphs. The consistent labeling across these datasets
facilitates document length-based analysis. We provide detailed data statistics
and baseline results on these datasets using state-of-the-art pre-trained BERT
models. We conduct a comparative analysis between monolingual and multilingual
BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT
model outperforms all others on every dataset. These resources also serve as
Marathi topic classification datasets or models and are publicly available at
https://github.com/l3cube-pune/MarathiNLP .",2024-04-28,"Saloni Mittal, Vidula Magdum, Omkar Dhekane, Sharayu Hiwarkhedkar, Raviraj Joshi",http://arxiv.org/pdf/2404.18216v1,cs.LG
A survey of dynamic graph neural networks,"Graph neural networks (GNNs) have emerged as a powerful tool for effectively
mining and learning from graph-structured data, with applications spanning
numerous domains. However, most research focuses on static graphs, neglecting
the dynamic nature of real-world networks where topologies and attributes
evolve over time. By integrating sequence modeling modules into traditional GNN
architectures, dynamic GNNs aim to bridge this gap, capturing the inherent
temporal dependencies of dynamic graphs for a more authentic depiction of
complex networks. This paper provides a comprehensive review of the fundamental
concepts, key techniques, and state-of-the-art dynamic GNN models. We present
the mainstream dynamic GNN models in detail and categorize models based on how
temporal information is incorporated. We also discuss large-scale dynamic GNNs
and pre-training techniques. Although dynamic GNNs have shown superior
performance, challenges remain in scalability, handling heterogeneous
information, and lack of diverse graph datasets. The paper also discusses
possible future directions, such as adaptive and memory-enhanced models,
inductive learning, and theoretical analysis.",2024-04-28,"Yanping Zheng, Lu Yi, Zhewei Wei",http://arxiv.org/pdf/2404.18211v1,cs.LG
4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on Relational DBs,"Although RDBs store vast amounts of rich, informative data spread across
interconnected tables, the progress of predictive machine learning models as
applied to such tasks arguably falls well behind advances in other domains such
as computer vision or natural language processing. This deficit stems, at least
in part, from the lack of established/public RDB benchmarks as needed for
training and evaluation purposes. As a result, related model development thus
far often defaults to tabular approaches trained on ubiquitous single-table
benchmarks, or on the relational side, graph-based alternatives such as GNNs
applied to a completely different set of graph datasets devoid of tabular
characteristics. To more precisely target RDBs lying at the nexus of these two
complementary regimes, we explore a broad class of baseline models predicated
on: (i) converting multi-table datasets into graphs using various strategies
equipped with efficient subsampling, while preserving tabular characteristics;
and (ii) trainable models with well-matched inductive biases that output
predictions based on these input subgraphs. Then, to address the dearth of
suitable public benchmarks and reduce siloed comparisons, we assemble a diverse
collection of (i) large-scale RDB datasets and (ii) coincident predictive
tasks. From a delivery standpoint, we operationalize the above four dimensions
(4D) of exploration within a unified, scalable open-source toolbox called
4DBInfer. We conclude by presenting evaluations using 4DBInfer, the results of
which highlight the importance of considering each such dimension in the design
of RDB predictive models, as well as the limitations of more naive approaches
such as simply joining adjacent tables. Our source code is released at
https://github.com/awslabs/multi-table-benchmark .",2024-04-28,"Minjie Wang, Quan Gan, David Wipf, Zhenkun Cai, Ning Li, Jianheng Tang, Yanlin Zhang, Zizhao Zhang, Zunyao Mao, Yakun Song, Yanbo Wang, Jiahang Li, Han Zhang, Guang Yang, Xiao Qin, Chuan Lei, Muhan Zhang, Weinan Zhang, Christos Faloutsos, Zheng Zhang",http://arxiv.org/pdf/2404.18209v1,cs.LG
Permutation-equivariant quantum convolutional neural networks,"The Symmetric group $S_{n}$ manifests itself in large classes of quantum
systems as the invariance of certain characteristics of a quantum state with
respect to permuting the qubits. The subgroups of $S_{n}$ arise, among many
other contexts, to describe label symmetry of classical images with respect to
spatial transformations, e.g. reflection or rotation. Equipped with the
formalism of geometric quantum machine learning, in this work we propose the
architectures of equivariant quantum convolutional neural networks (EQCNNs)
adherent to $S_{n}$ and its subgroups. We demonstrate that a careful choice of
pixel-to-qubit embedding order can facilitate easy construction of EQCNNs for
small subgroups of $S_{n}$. Our novel EQCNN architecture corresponding to the
full permutation group $S_{n}$ is built by applying all possible QCNNs with
equal probability, which can also be conceptualized as a dropout strategy in
quantum neural networks. For subgroups of $S_{n}$, our numerical results using
MNIST datasets show better classification accuracy than non-equivariant QCNNs.
The $S_{n}$-equivariant QCNN architecture shows significantly improved training
and test performance than non-equivariant QCNN for classification of connected
and non-connected graphs. When trained with sufficiently large number of data,
the $S_{n}$-equivariant QCNN shows better average performance compared to
$S_{n}$-equivariant QNN . These results contribute towards building powerful
quantum machine learning architectures in permutation-symmetric systems.",2024-04-28,"Sreetama Das, Filippo Caruso",http://arxiv.org/pdf/2404.18198v1,cs.LG
A General Causal Inference Framework for Cross-Sectional Observational Data,"Causal inference methods for observational data are highly regarded due to
their wide applicability. While there are already numerous methods available
for de-confounding bias, these methods generally assume that covariates consist
solely of confounders or make naive assumptions about the covariates. Such
assumptions face challenges in both theory and practice, particularly when
dealing with high-dimensional covariates. Relaxing these naive assumptions and
identifying the confounding covariates that truly require correction can
effectively enhance the practical significance of these methods. Therefore,
this paper proposes a General Causal Inference (GCI) framework specifically
designed for cross-sectional observational data, which precisely identifies the
key confounding covariates and provides corresponding identification algorithm.
Specifically, based on progressive derivations of the Markov property on
Directed Acyclic Graph, we conclude that the key confounding covariates are
equivalent to the common root ancestors of the treatment and the outcome
variable. Building upon this conclusion, the GCI framework is composed of a
novel Ancestor Set Identification (ASI) algorithm and de-confounding inference
methods. Firstly, the ASI algorithm is theoretically supported by the
conditional independence properties and causal asymmetry between variables,
enabling the identification of key confounding covariates. Subsequently, the
identified confounding covariates are used in the de-confounding inference
methods to obtain unbiased causal effect estimation, which can support informed
decision-making. Extensive experiments on synthetic datasets demonstrate that
the GCI framework can effectively identify the critical confounding covariates
and significantly improve the precision, stability, and interpretability of
causal inference in observational studies.",2024-04-28,"Yonghe Zhao, Huiyan Sun",http://arxiv.org/pdf/2404.18197v1,cs.LG
Exploring the Robustness of In-Context Learning with Noisy Labels,"Recently, the mysterious In-Context Learning (ICL) ability exhibited by
Transformer architectures, especially in large language models (LLMs), has
sparked significant research interest. However, the resilience of Transformers'
in-context learning capabilities in the presence of noisy samples, prevalent in
both training corpora and prompt demonstrations, remains underexplored. In this
paper, inspired by prior research that studies ICL ability using simple
function classes, we take a closer look at this problem by investigating the
robustness of Transformers against noisy labels. Specifically, we first conduct
a thorough evaluation and analysis of the robustness of Transformers against
noisy labels during in-context learning and show that they exhibit notable
resilience against diverse types of noise in demonstration labels. Furthermore,
we delve deeper into this problem by exploring whether introducing noise into
the training set, akin to a form of data augmentation, enhances such robustness
during inference, and find that such noise can indeed improve the robustness of
ICL. Overall, our fruitful analysis and findings provide a comprehensive
understanding of the resilience of Transformer models against label noises
during ICL and provide valuable insights into the research on Transformers in
natural language processing. Our code is available at
https://github.com/InezYu0928/in-context-learning.",2024-04-28,"Chen Cheng, Xinzhi Yu, Haodong Wen, Jingsong Sun, Guanzhang Yue, Yihao Zhang, Zeming Wei",http://arxiv.org/pdf/2404.18191v2,cs.LG
Enhancing Computational Efficiency in Multiscale Systems Using Deep Learning of Coordinates and Flow Maps,"Complex systems often show macroscopic coherent behavior due to the
interactions of microscopic agents like molecules, cells, or individuals in a
population with their environment. However, simulating such systems poses
several computational challenges during simulation as the underlying dynamics
vary and span wide spatiotemporal scales of interest. To capture the
fast-evolving features, finer time steps are required while ensuring that the
simulation time is long enough to capture the slow-scale behavior, making the
analyses computationally unmanageable. This paper showcases how deep learning
techniques can be used to develop a precise time-stepping approach for
multiscale systems using the joint discovery of coordinates and flow maps.
While the former allows us to represent the multiscale dynamics on a
representative basis, the latter enables the iterative time-stepping estimation
of the reduced variables. The resulting framework achieves state-of-the-art
predictive accuracy while incurring lesser computational costs. We demonstrate
this ability of the proposed scheme on the large-scale Fitzhugh Nagumo neuron
model and the 1D Kuramoto-Sivashinsky equation in the chaotic regime.",2024-04-28,"Asif Hamid, Danish Rafiq, Shahkar Ahmad Nahvi, Mohammad Abid Bazaz",http://arxiv.org/pdf/2407.00011v1,cs.LG
Naive Bayes Classifiers and One-hot Encoding of Categorical Variables,"This paper investigates the consequences of encoding a $K$-valued categorical
variable incorrectly as $K$ bits via one-hot encoding, when using a Na\""{\i}ve
Bayes classifier. This gives rise to a product-of-Bernoullis (PoB) assumption,
rather than the correct categorical Na\""{\i}ve Bayes classifier. The
differences between the two classifiers are analysed mathematically and
experimentally. In our experiments using probability vectors drawn from a
Dirichlet distribution, the two classifiers are found to agree on the maximum a
posteriori class label for most cases, although the posterior probabilities are
usually greater for the PoB case.",2024-04-28,Christopher K. I. Williams,http://arxiv.org/pdf/2404.18190v1,cs.LG
Ranked List Truncation for Large Language Model-based Re-Ranking,"We study ranked list truncation (RLT) from a novel ""retrieve-then-re-rank""
perspective, where we optimize re-ranking by truncating the retrieved list
(i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can
improve re-ranking efficiency by sending variable-length candidate lists to a
re-ranker on a per-query basis. It also has the potential to improve re-ranking
effectiveness. Despite its importance, there is limited research into applying
RLT methods to this new perspective. To address this research gap, we reproduce
existing RLT methods in the context of re-ranking, especially newly emerged
large language model (LLM)-based re-ranking. In particular, we examine to what
extent established findings on RLT for retrieval are generalizable to the
""retrieve-then-re-rank"" setup from three perspectives: (i) assessing RLT
methods in the context of LLM-based re-ranking with lexical first-stage
retrieval, (ii) investigating the impact of different types of first-stage
retrievers on RLT methods, and (iii) investigating the impact of different
types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and
2020 deep learning tracks, investigating 8 RLT methods for pipelines involving
3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the
context of re-ranking.",2024-04-28,"Chuan Meng, Negar Arabzadeh, Arian Askari, Mohammad Aliannejadi, Maarten de Rijke",http://arxiv.org/pdf/2404.18185v1,cs.LG
Assessing Image Quality Using a Simple Generative Representation,"Perceptual image quality assessment (IQA) is the task of predicting the
visual quality of an image as perceived by a human observer. Current
state-of-the-art techniques are based on deep representations trained in
discriminative manner. Such representations may ignore visually important
features, if they are not predictive of class labels. Recent generative models
successfully learn low-dimensional representations using auto-encoding and have
been argued to preserve better visual features. Here we leverage existing
auto-encoders and propose VAE-QA, a simple and efficient method for predicting
image quality in the presence of a full-reference. We evaluate our approach on
four standard benchmarks and find that it significantly improves generalization
across datasets, has fewer trainable parameters, a smaller memory footprint and
faster run time.",2024-04-28,"Simon Raviv, Gal Chechik",http://arxiv.org/pdf/2404.18178v1,cs.LG
IMEX-Reg: Implicit-Explicit Regularization in the Function Space for Continual Learning,"Continual learning (CL) remains one of the long-standing challenges for deep
neural networks due to catastrophic forgetting of previously acquired
knowledge. Although rehearsal-based approaches have been fairly successful in
mitigating catastrophic forgetting, they suffer from overfitting on buffered
samples and prior information loss, hindering generalization under low-buffer
regimes. Inspired by how humans learn using strong inductive biases, we propose
IMEX-Reg to improve the generalization performance of experience rehearsal in
CL under low buffer regimes. Specifically, we employ a two-pronged
implicit-explicit regularization approach using contrastive representation
learning (CRL) and consistency regularization. To further leverage the global
relationship between representations learned using CRL, we propose a
regularization strategy to guide the classifier toward the activation
correlations in the unit hypersphere of the CRL. Our results show that IMEX-Reg
significantly improves generalization performance and outperforms
rehearsal-based approaches in several CL scenarios. It is also robust to
natural and adversarial corruptions with less task-recency bias. Additionally,
we provide theoretical insights to support our design decisions further.",2024-04-28,"Prashant Bhat, Bharath Renjith, Elahe Arani, Bahram Zonooz",http://arxiv.org/pdf/2404.18161v1,cs.LG
Evaluating ROCKET and Catch22 features for calf behaviour classification from accelerometer data using Machine Learning models,"Monitoring calf behaviour continuously would be beneficial to identify
routine practices (e.g., weaning, dehorning, etc.) that impact calf welfare in
dairy farms. In that regard, accelerometer data collected from neck collars can
be used along with Machine Learning models to classify calf behaviour
automatically. Hand-crafted features are commonly used in Machine Learning
models, while ROCKET and Catch22 features are specifically designed for
time-series classification problems in related fields. This study aims to
compare the performance of ROCKET and Catch22 features to Hand-Crafted
features. 30 Irish Holstein Friesian and Jersey pre-weaned calves were
monitored using accelerometer sensors allowing for 27.4 hours of annotated
behaviors. Additional time-series were computed from the raw X, Y and Z-axis
and split into 3-second time windows. ROCKET, Catch22 and Hand-Crafted features
were calculated for each time window, and the dataset was then split into the
train, validation and test sets. Each set of features was used to train three
Machine Learning models (Random Forest, eXtreme Gradient Boosting, and
RidgeClassifierCV) to classify six behaviours indicative of pre-weaned calf
welfare (drinking milk, grooming, lying, running, walking and other). Models
were tuned with the validation set, and the performance of each feature-model
combination was evaluated with the test set. The best performance across the
three models was obtained with ROCKET [average balanced accuracy +/- standard
deviation] (0.70 +/- 0.07), followed by Catch22 (0.69 +/- 0.05), surpassing
Hand-Crafted (0.65 +/- 0.034). The best balanced accuracy (0.77) was obtained
with ROCKET and RidgeClassifierCV, followed by Catch22 and Random Forest
(0.73). Thus, tailoring these approaches for specific behaviours and contexts
will be crucial in advancing precision livestock farming and enhancing animal
welfare on a larger scale.",2024-04-28,"Oshana Dissanayake, Sarah E. McPherson, Joseph Allyndree, Emer Kennedy, Padraig Cunningham, Lucile Riaboff",http://arxiv.org/pdf/2404.18159v2,cs.LG
Generative AI for Visualization: State of the Art and Future Directions,"Generative AI (GenAI) has witnessed remarkable progress in recent years and
demonstrated impressive performance in various generation tasks in different
domains such as computer vision and computational design. Many researchers have
attempted to integrate GenAI into visualization framework, leveraging the
superior generative capacity for different operations. Concurrently, recent
major breakthroughs in GenAI like diffusion model and large language model have
also drastically increase the potential of GenAI4VIS. From a technical
perspective, this paper looks back on previous visualization studies leveraging
GenAI and discusses the challenges and opportunities for future research.
Specifically, we cover the applications of different types of GenAI methods
including sequence, tabular, spatial and graph generation techniques for
different tasks of visualization which we summarize into four major stages:
data enhancement, visual mapping generation, stylization and interaction. For
each specific visualization sub-task, we illustrate the typical data and
concrete GenAI algorithms, aiming to provide in-depth understanding of the
state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based
on the survey, we discuss three major aspects of challenges and research
opportunities including evaluation, dataset, and the gap between end-to-end
GenAI and generative algorithms. By summarizing different generation
algorithms, their current applications and limitations, this paper endeavors to
provide useful insights for future GenAI4VIS research.",2024-04-28,"Yilin Ye, Jianing Hao, Yihan Hou, Zhan Wang, Shishi Xiao, Yuyu Luo, Wei Zeng",http://arxiv.org/pdf/2404.18144v1,cs.LG
Lightweight Conceptual Dictionary Learning for Text Classification Using Information Compression,"We propose a novel, lightweight supervised dictionary learning framework for
text classification based on data compression and representation. This
two-phase algorithm initially employs the Lempel-Ziv-Welch (LZW) algorithm to
construct a dictionary from text datasets, focusing on the conceptual
significance of dictionary elements. Subsequently, dictionaries are refined
considering label data, optimizing dictionary atoms to enhance discriminative
power based on mutual information and class distribution. This process
generates discriminative numerical representations, facilitating the training
of simple classifiers such as SVMs and neural networks. We evaluate our
algorithm's information-theoretic performance using information bottleneck
principles and introduce the information plane area rank (IPAR) as a novel
metric to quantify the information-theoretic performance. Tested on six
benchmark text datasets, our algorithm competes closely with top models,
especially in limited-vocabulary contexts, using significantly fewer
parameters. \review{Our algorithm closely matches top-performing models,
deviating by only ~2\% on limited-vocabulary datasets, using just 10\% of their
parameters. However, it falls short on diverse-vocabulary datasets, likely due
to the LZW algorithm's constraints with low-repetition data. This contrast
highlights its efficiency and limitations across different dataset types.",2024-04-28,"Li Wan, Tansu Alpcan, Margreta Kuijper, Emanuele Viterbo",http://arxiv.org/pdf/2405.01584v1,cs.LG
Learning Fairer Representations with FairVIC,"Mitigating bias in automated decision-making systems, particularly in deep
learning models, is a critical challenge due to nuanced definitions of
fairness, dataset-specific biases, and the inherent trade-off between fairness
and accuracy. To address these issues, we introduce FairVIC, an innovative
approach that enhances fairness in neural networks by integrating variance,
invariance, and covariance terms into the loss function during training. Unlike
methods that rely on predefined fairness criteria, FairVIC abstracts fairness
concepts to minimise dependency on protected characteristics. We evaluate
FairVIC against comparable bias mitigation techniques on benchmark datasets,
considering both group and individual fairness, and conduct an ablation study
on the accuracy-fairness trade-off. FairVIC demonstrates significant
improvements ($\approx70\%$) in fairness across all tested metrics without
compromising accuracy, thus offering a robust, generalisable solution for fair
deep learning across diverse tasks and datasets.",2024-04-28,"Charmaine Barker, Daniel Bethell, Dimitar Kazakov",http://arxiv.org/pdf/2404.18134v2,cs.LG
Advancing Supervised Learning with the Wave Loss Function: A Robust and Smooth Approach,"Loss function plays a vital role in supervised learning frameworks. The
selection of the appropriate loss function holds the potential to have a
substantial impact on the proficiency attained by the acquired model. The
training of supervised learning algorithms inherently adheres to predetermined
loss functions during the optimization process. In this paper, we present a
novel contribution to the realm of supervised machine learning: an asymmetric
loss function named wave loss. It exhibits robustness against outliers,
insensitivity to noise, boundedness, and a crucial smoothness property.
Theoretically, we establish that the proposed wave loss function manifests the
essential characteristic of being classification-calibrated. Leveraging this
breakthrough, we incorporate the proposed wave loss function into the least
squares setting of support vector machines (SVM) and twin support vector
machines (TSVM), resulting in two robust and smooth models termed Wave-SVM and
Wave-TSVM, respectively. To address the optimization problem inherent in
Wave-SVM, we utilize the adaptive moment estimation (Adam) algorithm. It is
noteworthy that this paper marks the first instance of the Adam algorithm
application to solve an SVM model. Further, we devise an iterative algorithm to
solve the optimization problems of Wave-TSVM. To empirically showcase the
effectiveness of the proposed Wave-SVM and Wave-TSVM, we evaluate them on
benchmark UCI and KEEL datasets (with and without feature noise) from diverse
domains. Moreover, to exemplify the applicability of Wave-SVM in the biomedical
domain, we evaluate it on the Alzheimer Disease Neuroimaging Initiative (ADNI)
dataset. The experimental outcomes unequivocally reveal the prowess of Wave-SVM
and Wave-TSVM in achieving superior prediction accuracy against the baseline
models.",2024-04-28,"Mushir Akhtar, M. Tanveer, Mohd. Arshad",http://arxiv.org/pdf/2404.18101v2,cs.LG
ComposerX: Multi-Agent Symbolic Music Composition with LLMs,"Music composition represents the creative side of humanity, and itself is a
complex task that requires abilities to understand and generate information
with long dependency and harmony constraints. While demonstrating impressive
capabilities in STEM subjects, current LLMs easily fail in this task,
generating ill-written music even when equipped with modern techniques like
In-Context-Learning and Chain-of-Thoughts. To further explore and enhance LLMs'
potential in music composition by leveraging their reasoning ability and the
large knowledge base in music history and theory, we propose ComposerX, an
agent-based symbolic music generation framework. We find that applying a
multi-agent approach significantly improves the music composition quality of
GPT-4. The results demonstrate that ComposerX is capable of producing coherent
polyphonic music compositions with captivating melodies, while adhering to user
instructions.",2024-04-28,"Qixin Deng, Qikai Yang, Ruibin Yuan, Yipeng Huang, Yi Wang, Xubo Liu, Zeyue Tian, Jiahao Pan, Ge Zhang, Hanfeng Lin, Yizhi Li, Yinghao Ma, Jie Fu, Chenghua Lin, Emmanouil Benetos, Wenwu Wang, Guangyu Xia, Wei Xue, Yike Guo",http://arxiv.org/pdf/2404.18081v2,cs.LG
Generative AI for Low-Carbon Artificial Intelligence of Things with Large Language Models,"By integrating Artificial Intelligence (AI) with the Internet of Things
(IoT), Artificial Intelligence of Things (AIoT) has revolutionized many fields.
However, AIoT is facing the challenges of energy consumption and carbon
emissions due to the continuous advancement of mobile technology. Fortunately,
Generative AI (GAI) holds immense potential to reduce carbon emissions of AIoT
due to its excellent reasoning and generation capabilities. In this article, we
explore the potential of GAI for carbon emissions reduction and propose a novel
GAI-enabled solution for low-carbon AIoT. Specifically, we first study the main
impacts that cause carbon emissions in AIoT, and then introduce GAI techniques
and their relations to carbon emissions. We then explore the application
prospects of GAI in low-carbon AIoT, focusing on how GAI can reduce carbon
emissions of network components. Subsequently, we propose a Large Language
Model (LLM)-enabled carbon emission optimization framework, in which we design
pluggable LLM and Retrieval Augmented Generation (RAG) modules to generate more
accurate and reliable optimization problems. Furthermore, we utilize Generative
Diffusion Models (GDMs) to identify optimal strategies for carbon emission
reduction. Numerical results demonstrate the effectiveness of the proposed
framework. Finally, we insightfully provide open research directions for
low-carbon AIoT.",2024-04-28,"Jinbo Wen, Ruichen Zhang, Dusit Niyato, Jiawen Kang, Hongyang Du, Yang Zhang, Zhu Han",http://arxiv.org/pdf/2404.18077v2,cs.LG
Can Perplexity Predict Fine-Tuning Performance? An Investigation of Tokenization Effects on Sequential Language Models for Nepali,"Recent language models use subwording mechanisms to handle
Out-of-Vocabulary(OOV) words seen during test time and, their generation
capacity is generally measured using perplexity, an intrinsic metric. It is
known that increasing the subword granularity results in a decrease of
perplexity value. However, the study of how subwording affects the
understanding capacity of language models has been very few and only limited to
a handful of languages. To reduce this gap we used 6 different tokenization
schemes to pretrain relatively small language models in Nepali and used the
representations learned to finetune on several downstream tasks. Although
byte-level BPE algorithm has been used in recent models like GPT, RoBERTa we
show that on average they are sub-optimal in comparison to algorithms such as
SentencePiece in finetuning performances for Nepali. Additionally, similar
recent studies have focused on the Bert-based language model. We, however,
pretrain and finetune sequential transformer-based language models.",2024-04-28,"Nishant Luitel, Nirajan Bekoju, Anand Kumar Sah, Subarna Shakya",http://arxiv.org/pdf/2404.18071v1,cs.LG
Machine Learning Techniques for Data Reduction of CFD Applications,"We present an approach called guaranteed block autoencoder that leverages
Tensor Correlations (GBATC) for reducing the spatiotemporal data generated by
computational fluid dynamics (CFD) and other scientific applications. It uses a
multidimensional block of tensors (spanning in space and time) for both input
and output, capturing the spatiotemporal and interspecies relationship within a
tensor. The tensor consists of species that represent different elements in a
CFD simulation. To guarantee the error bound of the reconstructed data,
principal component analysis (PCA) is applied to the residual between the
original and reconstructed data. This yields a basis matrix, which is then used
to project the residual of each instance. The resulting coefficients are
retained to enable accurate reconstruction. Experimental results demonstrate
that our approach can deliver two orders of magnitude in reduction while still
keeping the errors of primary data under scientifically acceptable bounds.
Compared to reduction-based approaches based on SZ, our method achieves a
substantially higher compression ratio for a given error bound or a better
error for a given compression ratio.",2024-04-28,"Jaemoon Lee, Ki Sung Jung, Qian Gong, Xiao Li, Scott Klasky, Jacqueline Chen, Anand Rangarajan, Sanjay Ranka",http://arxiv.org/pdf/2404.18063v1,cs.LG
Prompt Customization for Continual Learning,"Contemporary continual learning approaches typically select prompts from a
pool, which function as supplementary inputs to a pre-trained model. However,
this strategy is hindered by the inherent noise of its selection approach when
handling increasing tasks. In response to these challenges, we reformulate the
prompting approach for continual learning and propose the prompt customization
(PC) method. PC mainly comprises a prompt generation module (PGM) and a prompt
modulation module (PMM). In contrast to conventional methods that employ hard
prompt selection, PGM assigns different coefficients to prompts from a
fixed-sized pool of prompts and generates tailored prompts. Moreover, PMM
further modulates the prompts by adaptively assigning weights according to the
correlations between input data and corresponding prompts. We evaluate our
method on four benchmark datasets for three diverse settings, including the
class, domain, and task-agnostic incremental learning tasks. Experimental
results demonstrate consistent improvement (by up to 16.2\%), yielded by the
proposed method, over the state-of-the-art (SOTA) techniques.",2024-04-28,"Yong Dai, Xiaopeng Hong, Yabin Wang, Zhiheng Ma, Dongmei Jiang, Yaowei Wang",http://arxiv.org/pdf/2404.18060v1,cs.LG
Utilizing Large Language Models for Information Extraction from Real Estate Transactions,"Real estate sales contracts contain crucial information for property
transactions, but manual data extraction can be time-consuming and error-prone.
This paper explores the application of large language models, specifically
transformer-based architectures, for automated information extraction from real
estate contracts. We discuss challenges, techniques, and future directions in
leveraging these models to improve efficiency and accuracy in real estate
contract analysis. We generated synthetic contracts using the real-world
transaction dataset, thereby fine-tuning the large-language model and achieving
significant metrics improvements and qualitative improvements in information
retrieval and reasoning tasks.",2024-04-28,"Yu Zhao, Haoxiang Gao",http://arxiv.org/pdf/2404.18043v2,cs.LG
Variational Optimization for Quantum Problems using Deep Generative Networks,"Optimization is one of the keystones of modern science and engineering. Its
applications in quantum technology and machine learning helped nurture
variational quantum algorithms and generative AI respectively. We propose a
general approach to design variational optimization algorithms based on
generative models: the Variational Generative Optimization Network (VGON). To
demonstrate its broad applicability, we apply VGON to three quantum tasks:
finding the best state in an entanglement-detection protocol, finding the
ground state of a 1D quantum spin model with variational quantum circuits, and
generating degenerate ground states of many-body quantum Hamiltonians. For the
first task, VGON greatly reduces the optimization time compared to stochastic
gradient descent while generating nearly optimal quantum states. For the second
task, VGON alleviates the barren plateau problem in variational quantum
circuits. For the final task, VGON can identify the degenerate ground state
spaces after a single stage of training and generate a variety of states
therein.",2024-04-28,"Lingxia Zhang, Xiaodie Lin, Peidong Wang, Kaiyan Yang, Xiao Zeng, Zhaohui Wei, Zizhu Wang",http://arxiv.org/pdf/2404.18041v1,cs.LG
Application of Deep Learning for Factor Timing in Asset Management,"The paper examines the performance of regression models (OLS linear
regression, Ridge regression, Random Forest, and Fully-connected Neural
Network) on the prediction of CMA (Conservative Minus Aggressive) factor
premium and the performance of factor timing investment with them.
Out-of-sample R-squared shows that more flexible models have better performance
in explaining the variance in factor premium of the unseen period, and the back
testing affirms that the factor timing based on more flexible models tends to
over perform the ones with linear models. However, for flexible models like
neural networks, the optimal weights based on their prediction tend to be
unstable, which can lead to high transaction costs and market impacts. We
verify that tilting down the rebalance frequency according to the historical
optimal rebalancing scheme can help reduce the transaction costs.",2024-04-27,"Prabhu Prasad Panda, Maysam Khodayari Gharanchaei, Xilin Chen, Haoshu Lyu",http://arxiv.org/pdf/2404.18017v1,cs.LG
Implicit Generative Prior for Bayesian Neural Networks,"Predictive uncertainty quantification is crucial for reliable decision-making
in various applied domains. Bayesian neural networks offer a powerful framework
for this task. However, defining meaningful priors and ensuring computational
efficiency remain significant challenges, especially for complex real-world
applications. This paper addresses these challenges by proposing a novel neural
adaptive empirical Bayes (NA-EB) framework. NA-EB leverages a class of implicit
generative priors derived from low-dimensional distributions. This allows for
efficient handling of complex data structures and effective capture of
underlying relationships in real-world datasets. The proposed NA-EB framework
combines variational inference with a gradient ascent algorithm. This enables
simultaneous hyperparameter selection and approximation of the posterior
distribution, leading to improved computational efficiency. We establish the
theoretical foundation of the framework through posterior and classification
consistency. We demonstrate the practical applications of our framework through
extensive evaluations on a variety of tasks, including the two-spiral problem,
regression, 10 UCI datasets, and image classification tasks on both MNIST and
CIFAR-10 datasets. The results of our experiments highlight the superiority of
our proposed framework over existing methods, such as sparse variational
Bayesian and generative models, in terms of prediction accuracy and uncertainty
quantification.",2024-04-27,"Yijia Liu, Xiao Wang",http://arxiv.org/pdf/2404.18008v1,cs.LG
MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch,"Accurate representation of medical information is crucial for patient safety,
yet artificial intelligence (AI) systems, such as Large Language Models (LLMs),
encounter challenges in error-free clinical text interpretation. This paper
presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben
Abacha et al., 2024a), focusing on the automatic correction of single-word
errors in clinical notes. Unlike LLMs that rely on extensive generic data, our
method emphasizes extracting contextually relevant information from available
clinical text data. Leveraging an ensemble of extractive and abstractive
question-answering approaches, we construct a supervised learning framework
with domain-specific feature engineering. Our methodology incorporates domain
expertise to enhance error correction accuracy. By integrating domain expertise
and prioritizing meaningful information extraction, our approach underscores
the significance of a human-centric strategy in adapting AI for healthcare.",2024-04-27,Nadia Saeed,http://arxiv.org/pdf/2404.17999v1,cs.LG
Optimal Initialization of Batch Bayesian Optimization,"Field experiments and computer simulations are effective but time-consuming
methods of measuring the quality of engineered systems at different settings.
To reduce the total time required, experimenters may employ Bayesian
optimization, which is parsimonious with measurements, and take measurements of
multiple settings simultaneously, in a batch. In practice, experimenters use
very few batches, thus, it is imperative that each batch be as informative as
possible. Typically, the initial batch in a Batch Bayesian Optimization (BBO)
is constructed from a quasi-random sample of settings values. We propose a
batch-design acquisition function, Minimal Terminal Variance (MTV), that
designs a batch by optimization rather than random sampling. MTV adapts a
design criterion function from Design of Experiments, called I-Optimality,
which minimizes the variance of the post-evaluation estimates of quality,
integrated over the entire space of settings. MTV weights the integral by the
probability that a setting is optimal, making it able to design not only an
initial batch but all subsequent batches, as well. Applicability to both
initialization and subsequent batches is novel among acquisition functions.
Numerical experiments on test functions and simulators show that MTV compares
favorably to other BBO methods.",2024-04-27,"Jiuge Ren, David Sweet",http://arxiv.org/pdf/2404.17997v1,cs.LG
"CUE-Net: Violence Detection Video Analytics with Spatial Cropping, Enhanced UniformerV2 and Modified Efficient Additive Attention","In this paper we introduce CUE-Net, a novel architecture designed for
automated violence detection in video surveillance. As surveillance systems
become more prevalent due to technological advances and decreasing costs, the
challenge of efficiently monitoring vast amounts of video data has intensified.
CUE-Net addresses this challenge by combining spatial Cropping with an enhanced
version of the UniformerV2 architecture, integrating convolutional and
self-attention mechanisms alongside a novel Modified Efficient Additive
Attention mechanism (which reduces the quadratic time complexity of
self-attention) to effectively and efficiently identify violent activities.
This approach aims to overcome traditional challenges such as capturing distant
or partially obscured subjects within video frames. By focusing on both local
and global spatiotemporal features, CUE-Net achieves state-of-the-art
performance on the RWF-2000 and RLVS datasets, surpassing existing methods.",2024-04-27,"Damith Chamalke Senadeera, Xiaoyun Yang, Dimitrios Kollias, Gregory Slabaugh",http://arxiv.org/pdf/2404.18952v1,cs.LG
MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning,"The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual &
Multimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a).
This paper addresses the limitations of traditional methods by proposing a
weakly supervised learning approach for open-ended medical question-answering
(QA). Our system leverages readily available MEDIQA-M3G images via a
VGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning
of informative skin condition representations. Using pre-trained QA models, we
further bridge the gap between visual and textual information through
multimodal fusion. This approach tackles complex, open-ended questions even
without predefined answer choices. We empower the generation of comprehensive
answers by feeding the ViT-CLIP model with multiple responses alongside images.
This work advances medical QA research, paving the way for clinical decision
support systems and ultimately improving healthcare delivery.",2024-04-27,Nadia Saeed,http://arxiv.org/pdf/2405.01583v1,cs.LG
TabVFL: Improving Latent Representation in Vertical Federated Learning,"Autoencoders are popular neural networks that are able to compress high
dimensional data to extract relevant latent information. TabNet is a
state-of-the-art neural network model designed for tabular data that utilizes
an autoencoder architecture for training. Vertical Federated Learning (VFL) is
an emerging distributed machine learning paradigm that allows multiple parties
to train a model collaboratively on vertically partitioned data while
maintaining data privacy. The existing design of training autoencoders in VFL
is to train a separate autoencoder in each participant and aggregate the latent
representation later. This design could potentially break important
correlations between feature data of participating parties, as each autoencoder
is trained on locally available features while disregarding the features of
others. In addition, traditional autoencoders are not specifically designed for
tabular data, which is ubiquitous in VFL settings. Moreover, the impact of
client failures during training on the model robustness is under-researched in
the VFL scene. In this paper, we propose TabVFL, a distributed framework
designed to improve latent representation learning using the joint features of
participants. The framework (i) preserves privacy by mitigating potential data
leakage with the addition of a fully-connected layer, (ii) conserves feature
correlations by learning one latent representation vector, and (iii) provides
enhanced robustness against client failures during training phase. Extensive
experiments on five classification datasets show that TabVFL can outperform the
prior work design, with 26.12% of improvement on f1-score.",2024-04-27,"Mohamed Rashad, Zilong Zhao, Jeremie Decouchant, Lydia Y. Chen",http://arxiv.org/pdf/2404.17990v2,cs.LG
Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry,"In the rapidly evolving landscape of Natural Language Processing (NLP), Large
Language Models (LLMs) have emerged as powerful tools for many tasks, such as
extracting valuable insights from vast amounts of textual data. In this study,
we conduct a comparative analysis of LLMs for the extraction of travel customer
needs from TripAdvisor and Reddit posts. Leveraging a diverse range of models,
including both open-source and proprietary ones such as GPT-4 and Gemini, we
aim to elucidate their strengths and weaknesses in this specialized domain.
Through an evaluation process involving metrics such as BERTScore, ROUGE, and
BLEU, we assess the performance of each model in accurately identifying and
summarizing customer needs. Our findings highlight the efficacy of opensource
LLMs, particularly Mistral 7B, in achieving comparable performance to larger
closed models while offering affordability and customization benefits.
Additionally, we underscore the importance of considering factors such as model
size, resource requirements, and performance metrics when selecting the most
suitable LLM for customer needs analysis tasks. Overall, this study contributes
valuable insights for businesses seeking to leverage advanced NLP techniques to
enhance customer experience and drive operational efficiency in the travel
industry.",2024-04-27,"Simone Barandoni, Filippo Chiarello, Lorenzo Cascone, Emiliano Marrale, Salvatore Puccio",http://arxiv.org/pdf/2404.17975v2,cs.LG
Usefulness of Emotional Prosody in Neural Machine Translation,"Neural Machine Translation (NMT) is the task of translating a text from one
language to another with the use of a trained neural network. Several existing
works aim at incorporating external information into NMT models to improve or
control predicted translations (e.g. sentiment, politeness, gender). In this
work, we propose to improve translation quality by adding another external
source of information: the automatically recognized emotion in the voice. This
work is motivated by the assumption that each emotion is associated with a
specific lexicon that can overlap between emotions. Our proposed method follows
a two-stage procedure. At first, we select a state-of-the-art Speech Emotion
Recognition (SER) model to predict dimensional emotion values from all input
audio in the dataset. Then, we use these predicted emotions as source tokens
added at the beginning of input texts to train our NMT model. We show that
integrating emotion information, especially arousal, into NMT systems leads to
better translations.",2024-04-27,"Charles Brazier, Jean-Luc Rouas",http://arxiv.org/pdf/2404.17968v1,cs.LG
"Deep Learning for Low-Latency, Quantum-Ready RF Sensing","Recent work has shown the promise of applying deep learning to enhance
software processing of radio frequency (RF) signals. In parallel, hardware
developments with quantum RF sensors based on Rydberg atoms are breaking
longstanding barriers in frequency range, resolution, and sensitivity. In this
paper, we describe our implementations of quantum-ready machine learning
approaches for RF signal classification. Our primary objective is latency:
while deep learning offers a more powerful computational paradigm, it also
traditionally incurs latency overheads that hinder wider scale deployment. Our
work spans three axes. (1) A novel continuous wavelet transform (CWT) based
recurrent neural network (RNN) architecture that enables flexible online
classification of RF signals on-the-fly with reduced sampling time. (2)
Low-latency inference techniques for both GPU and CPU that span over 100x
reductions in inference time, enabling real-time operation with sub-millisecond
inference. (3) Quantum-readiness validated through application of our models to
physics-based simulation of Rydberg atom QRF sensors. Altogether, our work
bridges towards next-generation RF sensors that use quantum technology to
surpass previous physical limits, paired with latency-optimized AI/ML software
that is suitable for real-time deployment.",2024-04-27,"Pranav Gokhale, Caitlin Carnahan, William Clark, Teague Tomesh, Frederic T. Chong",http://arxiv.org/pdf/2404.17962v2,cs.LG
PhishGuard: A Convolutional Neural Network Based Model for Detecting Phishing URLs with Explainability Analysis,"Cybersecurity is one of the global issues because of the extensive dependence
on cyber systems of individuals, industries, and organizations. Among the cyber
attacks, phishing is increasing tremendously and affecting the global economy.
Therefore, this phenomenon highlights the vital need for enhancing user
awareness and robust support at both individual and organizational levels.
Phishing URL identification is the best way to address the problem. Various
machine learning and deep learning methods have been proposed to automate the
detection of phishing URLs. However, these approaches often need more
convincing accuracy and rely on datasets consisting of limited samples.
Furthermore, these black box intelligent models decision to detect suspicious
URLs needs proper explanation to understand the features affecting the output.
To address the issues, we propose a 1D Convolutional Neural Network (CNN) and
trained the model with extensive features and a substantial amount of data. The
proposed model outperforms existing works by attaining an accuracy of 99.85%.
Additionally, our explainability analysis highlights certain features that
significantly contribute to identifying the phishing URL.",2024-04-27,"Md Robiul Islam, Md Mahamodul Islam, Mst. Suraiya Afrin, Anika Antara, Nujhat Tabassum, Al Amin",http://arxiv.org/pdf/2404.17960v1,cs.LG
Cauchy-Schwarz Divergence Information Bottleneck for Regression,"The information bottleneck (IB) approach is popular to improve the
generalization, robustness and explainability of deep neural networks.
Essentially, it aims to find a minimum sufficient representation $\mathbf{t}$
by striking a trade-off between a compression term $I(\mathbf{x};\mathbf{t})$
and a prediction term $I(y;\mathbf{t})$, where $I(\cdot;\cdot)$ refers to the
mutual information (MI). MI is for the IB for the most part expressed in terms
of the Kullback-Leibler (KL) divergence, which in the regression case
corresponds to prediction based on mean squared error (MSE) loss with Gaussian
assumption and compression approximated by variational inference. In this
paper, we study the IB principle for the regression problem and develop a new
way to parameterize the IB with deep neural networks by exploiting favorable
properties of the Cauchy-Schwarz (CS) divergence. By doing so, we move away
from MSE-based regression and ease estimation by avoiding variational
approximations or distributional assumptions. We investigate the improved
generalization ability of our proposed CS-IB and demonstrate strong adversarial
robustness guarantees. We demonstrate its superior performance on six
real-world regression tasks over other popular deep IB approaches. We
additionally observe that the solutions discovered by CS-IB always achieve the
best trade-off between prediction accuracy and compression ratio in the
information plane. The code is available at
\url{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck}.",2024-04-27,"Shujian Yu, Xi Yu, Sigurd Løkse, Robert Jenssen, Jose C. Principe",http://arxiv.org/pdf/2404.17951v1,cs.LG
Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks,"Graph Neural Networks (GNNs) have demonstrated state-of-the-art performance
in various graph representation learning tasks. Recently, studies revealed
their vulnerability to adversarial attacks. In this work, we theoretically
define the concept of expected robustness in the context of attributed graphs
and relate it to the classical definition of adversarial robustness in the
graph representation learning literature. Our definition allows us to derive an
upper bound of the expected robustness of Graph Convolutional Networks (GCNs)
and Graph Isomorphism Networks subject to node feature attacks. Building on
these findings, we connect the expected robustness of GNNs to the
orthonormality of their weight matrices and consequently propose an
attack-independent, more robust variant of the GCN, called the Graph
Convolutional Orthonormal Robust Networks (GCORNs). We further introduce a
probabilistic method to estimate the expected robustness, which allows us to
evaluate the effectiveness of GCORN on several real-world datasets.
Experimental experiments showed that GCORN outperforms available defense
methods. Our code is publicly available at:
\href{https://github.com/Sennadir/GCORN}{https://github.com/Sennadir/GCORN}.",2024-04-27,"Yassine Abbahaddou, Sofiane Ennadir, Johannes F. Lutzeyer, Michalis Vazirgiannis, Henrik Boström",http://arxiv.org/pdf/2404.17947v1,cs.LG
Deep Representation Learning for Forecasting Recursive and Multi-Relational Events in Temporal Networks,"Understanding relations arising out of interactions among entities can be
very difficult, and predicting them is even more challenging. This problem has
many applications in various fields, such as financial networks and e-commerce.
These relations can involve much more complexities than just involving more
than two entities. One such scenario is evolving recursive relations between
multiple entities, and so far, this is still an open problem. This work
addresses the problem of forecasting higher-order interaction events that can
be multi-relational and recursive. We pose the problem in the framework of
representation learning of temporal hypergraphs that can capture complex
relationships involving multiple entities. The proposed model,
\textit{Relational Recursive Hyperedge Temporal Point Process} (RRHyperTPP)
uses an encoder that learns a dynamic node representation based on the
historical interaction patterns and then a hyperedge link prediction-based
decoder to model the occurrence of interaction events. These learned
representations are then used for downstream tasks involving forecasting the
type and time of interactions. The main challenge in learning from hyperedge
events is that the number of possible hyperedges grows exponentially with the
number of nodes in the network. This will make the computation of negative
log-likelihood of the temporal point process expensive, as the calculation of
survival function requires a summation over all possible hyperedges. In our
work, we develop a noise contrastive estimation method to learn the parameters
of our model, and we have experimentally shown that our models perform better
than previous state-of-the-art methods for interaction forecasting.",2024-04-27,"Tony Gracious, Ambedkar Dukkipati",http://arxiv.org/pdf/2404.17943v2,cs.LG
CBMAP: Clustering-based manifold approximation and projection for dimensionality reduction,"Dimensionality reduction methods are employed to decrease data
dimensionality, either to enhance machine learning performance or to facilitate
data visualization in two or three-dimensional spaces. These methods typically
fall into two categories: feature selection and feature transformation. Feature
selection retains significant features, while feature transformation projects
data into a lower-dimensional space, with linear and nonlinear methods. While
nonlinear methods excel in preserving local structures and capturing nonlinear
relationships, they may struggle with interpreting global structures and can be
computationally intensive. Recent algorithms, such as the t-SNE, UMAP, TriMap,
and PaCMAP prioritize preserving local structures, often at the expense of
accurately representing global structures, leading to clusters being spread out
more in lower-dimensional spaces. Moreover, these methods heavily rely on
hyperparameters, making their results sensitive to parameter settings. To
address these limitations, this study introduces a clustering-based approach,
namely CBMAP (Clustering-Based Manifold Approximation and Projection), for
dimensionality reduction. CBMAP aims to preserve both global and local
structures, ensuring that clusters in lower-dimensional spaces closely resemble
those in high-dimensional spaces. Experimental evaluations on benchmark
datasets demonstrate CBMAP's efficacy, offering speed, scalability, and minimal
reliance on hyperparameters. Importantly, CBMAP enables low-dimensional
projection of test data, addressing a critical need in machine learning
applications. CBMAP is made freely available at
https://github.com/doganlab/cbmap and can be installed from the Python Package
Directory (PyPI) software repository with the command pip install cbmap.",2024-04-27,Berat Dogan,http://arxiv.org/pdf/2404.17940v2,cs.LG
DTization: A New Method for Supervised Feature Scaling,"Artificial intelligence is currently a dominant force in shaping various
aspects of the world. Machine learning is a sub-field in artificial
intelligence. Feature scaling is one of the data pre-processing techniques that
improves the performance of machine learning algorithms. The traditional
feature scaling techniques are unsupervised where they do not have influence of
the dependent variable in the scaling process. In this paper, we have presented
a novel feature scaling technique named DTization that employs decision tree
and robust scaler for supervised feature scaling. The proposed method utilizes
decision tree to measure the feature importance and based on the importance,
different features get scaled differently with the robust scaler algorithm. The
proposed method has been extensively evaluated on ten classification and
regression datasets on various evaluation matrices and the results show a
noteworthy performance improvement compared to the traditional feature scaling
methods.",2024-04-27,Niful Islam,http://arxiv.org/pdf/2404.17937v1,cs.LG
Critical Review for One-class Classification: recent advances and the reality behind them,"This paper offers a comprehensive review of one-class classification (OCC),
examining the technologies and methodologies employed in its implementation. It
delves into various approaches utilized for OCC across diverse data types, such
as feature data, image, video, time series, and others. Through a systematic
review, this paper synthesizes promi-nent strategies used in OCC from its
inception to its current advance-ments, with a particular emphasis on the
promising application. Moreo-ver, the article criticizes the state-of-the-art
(SOTA) image anomaly de-tection (AD) algorithms dominating one-class
experiments. These algo-rithms include outlier exposure (binary classification)
and pretrained model (multi-class classification), conflicting with the
fundamental con-cept of learning from one class. Our investigation reveals that
the top nine algorithms for one-class CIFAR10 benchmark are not OCC. We ar-gue
that binary/multi-class classification algorithms should not be com-pared with
OCC.",2024-04-27,"Toshitaka Hayashi, Dalibor Cimr, Hamido Fujita, Richard Cimler",http://arxiv.org/pdf/2404.17931v1,cs.LG
Pre-training on High Definition X-ray Images: An Experimental Study,"Existing X-ray based pre-trained vision models are usually conducted on a
relatively small-scale dataset (less than 500k samples) with limited resolution
(e.g., 224 $\times$ 224). However, the key to the success of self-supervised
pre-training large models lies in massive training data, and maintaining high
resolution in the field of X-ray images is the guarantee of effective solutions
to difficult miscellaneous diseases. In this paper, we address these issues by
proposing the first high-definition (1280 $\times$ 1280) X-ray based
pre-trained foundation vision model on our newly collected large-scale dataset
which contains more than 1 million X-ray images. Our model follows the masked
auto-encoder framework which takes the tokens after mask processing (with a
high rate) is used as input, and the masked image patches are reconstructed by
the Transformer encoder-decoder network. More importantly, we introduce a novel
context-aware masking strategy that utilizes the chest contour as a boundary
for adaptive masking operations. We validate the effectiveness of our model on
two downstream tasks, including X-ray report generation and disease
recognition. Extensive experiments demonstrate that our pre-trained medical
foundation vision model achieves comparable or even new state-of-the-art
performance on downstream benchmark datasets. The source code and pre-trained
models of this paper will be released on
https://github.com/Event-AHU/Medical_Image_Analysis.",2024-04-27,"Xiao Wang, Yuehang Li, Wentao Wu, Jiandong Jin, Yao Rong, Bo Jiang, Chuanfu Li, Jin Tang",http://arxiv.org/pdf/2404.17926v1,cs.LG
Accurate and fast anomaly detection in industrial processes and IoT environments,"We present a novel, simple and widely applicable semi-supervised procedure
for anomaly detection in industrial and IoT environments, SAnD (Simple Anomaly
Detection). SAnD comprises 5 steps, each leveraging well-known statistical
tools, namely; smoothing filters, variance inflation factors, the Mahalanobis
distance, threshold selection algorithms and feature importance techniques. To
our knowledge, SAnD is the first procedure that integrates these tools to
identify anomalies and help decipher their putative causes. We show how each
step contributes to tackling technical challenges that practitioners face when
detecting anomalies in industrial contexts, where signals can be highly
multicollinear, have unknown distributions, and intertwine short-lived noise
with the long(er)-lived actual anomalies. The development of SAnD was motivated
by a concrete case study from our industrial partner, which we use here to show
its effectiveness. We also evaluate the performance of SAnD by comparing it
with a selection of semi-supervised methods on public datasets from the
literature on anomaly detection. We conclude that SAnD is effective, broadly
applicable, and outperforms existing approaches in both anomaly detection and
runtime.",2024-04-27,"Simone Tonini, Andrea Vandin, Francesca Chiaromonte, Daniele Licari, Fernando Barsacchi",http://arxiv.org/pdf/2404.17925v1,cs.LG
FedCRL: Personalized Federated Learning with Contrastive Shared Representations for Label Heterogeneity in Non-IID Data,"Heterogeneity resulting from label distribution skew and data scarcity can
lead to inaccuracy and unfairness in intelligent communication applications
that mainly rely on distributed computing. To deal with it, this paper proposes
a novel personalized federated learning algorithm, named Federated Contrastive
Shareable Representations (FedCoSR), to facilitate knowledge sharing among
clients while maintaining data privacy. Specifically, parameters of local
models' shallow layers and typical local representations are both considered
shareable information for the server and aggregated globally. To address poor
performance caused by label distribution skew among clients, contrastive
learning is adopted between local and global representations to enrich local
knowledge. Additionally, to ensure fairness for clients with scarce data,
FedCoSR introduces adaptive local aggregation to coordinate the global model
involvement in each client. Our simulations demonstrate FedCoSR's effectiveness
in mitigating label heterogeneity by achieving accuracy and fairness
improvements over existing methods on datasets with varying degrees of label
heterogeneity.",2024-04-27,"Chenghao Huang, Xiaolu Chen, Yanru Zhang, Hao Wang",http://arxiv.org/pdf/2404.17916v2,cs.LG
SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models,"Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large
Language Models (MLLMs) can automate the creation of accurate and coherent
radiological reports. Existing methods often hallucinate details in text-based
reports that don't accurately reflect the image content. To mitigate this, we
introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort
GENeraTion using Vision Language Models), which improves the R2Gen task by
integrating a self-refining mechanism into the MLLM framework. We employ a
unique self-supervised loss that leverages similarity between pooled image
representations and the contextual representations of the generated
radiological text, alongside the standard Causal Language Modeling objective,
to refine image-text representations. This allows the model to scrutinize and
align the generated text through dynamic interaction between a given image and
the generated text, therefore reducing hallucination and continuously enhancing
nuanced report generation. SERPENT-VLM outperforms existing baselines such as
LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and
Radiology Objects in COntext (ROCO) datasets, and also proves to be robust
against noisy images. A qualitative case study emphasizes the significant
advancements towards more sophisticated MLLM frameworks for R2Gen, opening
paths for further research into self-supervised refinement in the medical
imaging domain.",2024-04-27,"Manav Nitin Kapadnis, Sohan Patnaik, Abhilash Nandy, Sourjyadip Ray, Pawan Goyal, Debdoot Sheet",http://arxiv.org/pdf/2404.17912v2,cs.LG
Reliable Student: Addressing Noise in Semi-Supervised 3D Object Detection,"Semi-supervised 3D object detection can benefit from the promising
pseudo-labeling technique when labeled data is limited. However, recent
approaches have overlooked the impact of noisy pseudo-labels during training,
despite efforts to enhance pseudo-label quality through confidence-based
filtering. In this paper, we examine the impact of noisy pseudo-labels on
IoU-based target assignment and propose the Reliable Student framework, which
incorporates two complementary approaches to mitigate errors. First, it
involves a class-aware target assignment strategy that reduces false negative
assignments in difficult classes. Second, it includes a reliability weighting
strategy that suppresses false positive assignment errors while also addressing
remaining false negatives from the first step. The reliability weights are
determined by querying the teacher network for confidence scores of the
student-generated proposals. Our work surpasses the previous state-of-the-art
on KITTI 3D object detection benchmark on point clouds in the semi-supervised
setting. On 1% labeled data, our approach achieves a 6.2% AP improvement for
the pedestrian class, despite having only 37 labeled samples available. The
improvements become significant for the 2% setting, achieving 6.0% AP and 5.7%
AP improvements for the pedestrian and cyclist classes, respectively.",2024-04-27,"Farzad Nozarian, Shashank Agarwal, Farzaneh Rezaeianaran, Danish Shahzad, Atanas Poibrenski, Christian Müller, Philipp Slusallek",http://arxiv.org/pdf/2404.17910v1,cs.LG
Shared learning of powertrain control policies for vehicle fleets,"Emerging data-driven approaches, such as deep reinforcement learning (DRL),
aim at on-the-field learning of powertrain control policies that optimize fuel
economy and other performance metrics. Indeed, they have shown great potential
in this regard for individual vehicles on specific routes or drive cycles.
However, for fleets of vehicles that must service a distribution of routes, DRL
approaches struggle with learning stability issues that result in high
variances and challenge their practical deployment. In this paper, we present a
novel framework for shared learning among a fleet of vehicles through the use
of a distilled group policy as the knowledge sharing mechanism for the policy
learning computations at each vehicle. We detail the mathematical formulation
that makes this possible. Several scenarios are considered to analyze the
functionality, performance, and computational scalability of the framework with
fleet size. Comparisons of the cumulative performance of fleets using our
proposed shared learning approach with a baseline of individual learning agents
and another state-of-the-art approach with a centralized learner show clear
advantages to our approach. For example, we find a fleet average asymptotic
improvement of 8.5 percent in fuel economy compared to the baseline while also
improving on the metrics of acceleration error and shifting frequency for
fleets serving a distribution of suburban routes. Furthermore, we include
demonstrative results that show how the framework reduces variance within a
fleet and also how it helps individual agents adapt better to new routes.",2024-04-27,"Lindsey Kerbel, Beshah Ayalew, Andrej Ivanco",http://arxiv.org/pdf/2404.17892v1,cs.LG
"Feature graphs for interpretable unsupervised tree ensembles: centrality, interaction, and application in disease subtyping","Interpretable machine learning has emerged as central in leveraging
artificial intelligence within high-stakes domains such as healthcare, where
understanding the rationale behind model predictions is as critical as
achieving high predictive accuracy. In this context, feature selection assumes
a pivotal role in enhancing model interpretability by identifying the most
important input features in black-box models. While random forests are
frequently used in biomedicine for their remarkable performance on tabular
datasets, the accuracy gained from aggregating decision trees comes at the
expense of interpretability. Consequently, feature selection for enhancing
interpretability in random forests has been extensively explored in supervised
settings. However, its investigation in the unsupervised regime remains notably
limited. To address this gap, the study introduces novel methods to construct
feature graphs from unsupervised random forests and feature selection
strategies to derive effective feature combinations from these graphs. Feature
graphs are constructed for the entire dataset as well as individual clusters
leveraging the parent-child node splits within the trees, such that feature
centrality captures their relevance to the clustering task, while edge weights
reflect the discriminating power of feature pairs. Graph-based feature
selection methods are extensively evaluated on synthetic and benchmark datasets
both in terms of their ability to reduce dimensionality while improving
clustering performance, as well as to enhance model interpretability. An
application on omics data for disease subtyping identifies the top features for
each cluster, showcasing the potential of the proposed approach to enhance
interpretability in clustering analyses and its utility in a real-world
biomedical application.",2024-04-27,"Christel Sirocchi, Martin Urschler, Bastian Pfeifer",http://arxiv.org/pdf/2404.17886v1,cs.LG
Generalization capabilities and robustness of hybrid models grounded in physics compared to purely deep learning models,"This study investigates the generalization capabilities and robustness of
purely deep learning (DL) models and hybrid models based on physical principles
in fluid dynamics applications, specifically focusing on iteratively
forecasting the temporal evolution of flow dynamics. Three autoregressive
models were compared: a hybrid model (POD-DL) that combines proper orthogonal
decomposition (POD) with a long-short term memory (LSTM) layer, a convolutional
autoencoder combined with a convolutional LSTM (ConvLSTM) layer and a
variational autoencoder (VAE) combined with a ConvLSTM layer. These models were
tested on two high-dimensional, nonlinear datasets representing the velocity
field of flow past a circular cylinder in both laminar and turbulent regimes.
The study used latent dimension methods, enabling a bijective reduction of
high-dimensional dynamics into a lower-order space to facilitate future
predictions. While the VAE and ConvLSTM models accurately predicted laminar
flow, the hybrid POD-DL model outperformed the others across both laminar and
turbulent flow regimes. This success is attributed to the model's ability to
incorporate modal decomposition, reducing the dimensionality of the data, by a
non-parametric method, and simplifying the forecasting component. By leveraging
POD, the model not only gained insight into the underlying physics, improving
prediction accuracy with less training data, but also reduce the number of
trainable parameters as POD is non-parametric. The findings emphasize the
potential of hybrid models, particularly those integrating modal decomposition
and deep learning, in predicting complex flow dynamics.",2024-04-27,"Rodrigo Abadía-Heredia, Adrián Corrochano, Manuel Lopez-Martin, Soledad Le Clainche",http://arxiv.org/pdf/2404.17884v4,cs.LG
Noisy Node Classification by Bi-level Optimization based Multi-teacher Distillation,"Previous graph neural networks (GNNs) usually assume that the graph data is
with clean labels for representation learning, but it is not true in real
applications. In this paper, we propose a new multi-teacher distillation method
based on bi-level optimization (namely BO-NNC), to conduct noisy node
classification on the graph data. Specifically, we first employ multiple
self-supervised learning methods to train diverse teacher models, and then
aggregate their predictions through a teacher weight matrix. Furthermore, we
design a new bi-level optimization strategy to dynamically adjust the teacher
weight matrix based on the training progress of the student model. Finally, we
design a label improvement module to improve the label quality. Extensive
experimental results on real datasets show that our method achieves the best
results compared to state-of-the-art methods.",2024-04-27,"Yujing Liu, Zongqian Wu, Zhengyu Lu, Ci Nie, Guoqiu Wen, Ping Hu, Xiaofeng Zhu",http://arxiv.org/pdf/2404.17875v2,cs.LG
Error analysis for finite element operator learning methods for solving parametric second-order elliptic PDEs,"In this paper, we provide a theoretical analysis of a type of operator
learning method without data reliance based on the classical finite element
approximation, which is called the finite element operator network (FEONet). We
first establish the convergence of this method for general second-order linear
elliptic PDEs with respect to the parameters for neural network approximation.
In this regard, we address the role of the condition number of the finite
element matrix in the convergence of the method. Secondly, we derive an
explicit error estimate for the self-adjoint case. For this, we investigate
some regularity properties of the solution in certain function classes for a
neural network approximation, verifying the sufficient condition for the
solution to have the desired regularity. Finally, we will also conduct some
numerical experiments that support the theoretical findings, confirming the
role of the condition number of the finite element matrix in the overall
convergence.",2024-04-27,"Youngjoon Hong, Seungchan Ko, Jaeyong Lee",http://arxiv.org/pdf/2404.17868v1,cs.LG
Uncertainty quantification for iterative algorithms in linear models with application to early stopping,"This paper investigates the iterates $\hbb^1,\dots,\hbb^T$ obtained from
iterative algorithms in high-dimensional linear regression problems, in the
regime where the feature dimension $p$ is comparable with the sample size $n$,
i.e., $p \asymp n$. The analysis and proposed estimators are applicable to
Gradient Descent (GD), proximal GD and their accelerated variants such as Fast
Iterative Soft-Thresholding (FISTA). The paper proposes novel estimators for
the generalization error of the iterate $\hbb^t$ for any fixed iteration $t$
along the trajectory. These estimators are proved to be $\sqrt n$-consistent
under Gaussian designs. Applications to early-stopping are provided: when the
generalization error of the iterates is a U-shape function of the iteration
$t$, the estimates allow to select from the data an iteration $\hat t$ that
achieves the smallest generalization error along the trajectory. Additionally,
we provide a technique for developing debiasing corrections and valid
confidence intervals for the components of the true coefficient vector from the
iterate $\hbb^t$ at any finite iteration $t$. Extensive simulations on
synthetic data illustrate the theoretical results.",2024-04-27,"Pierre C. Bellec, Kai Tan",http://arxiv.org/pdf/2404.17856v1,cs.LG
pFedAFM: Adaptive Feature Mixture for Batch-Level Personalization in Heterogeneous Federated Learning,"Model-heterogeneous personalized federated learning (MHPFL) enables FL
clients to train structurally different personalized models on non-independent
and identically distributed (non-IID) local data. Existing MHPFL methods focus
on achieving client-level personalization, but cannot address batch-level data
heterogeneity. To bridge this important gap, we propose a model-heterogeneous
personalized Federated learning approach with Adaptive Feature Mixture
(pFedAFM) for supervised learning tasks. It consists of three novel designs: 1)
A sharing global homogeneous small feature extractor is assigned alongside each
client's local heterogeneous model (consisting of a heterogeneous feature
extractor and a prediction header) to facilitate cross-client knowledge fusion.
The two feature extractors share the local heterogeneous model's prediction
header containing rich personalized prediction knowledge to retain personalized
prediction capabilities. 2) An iterative training strategy is designed to
alternately train the global homogeneous small feature extractor and the local
heterogeneous large model for effective global-local knowledge exchange. 3) A
trainable weight vector is designed to dynamically mix the features extracted
by both feature extractors to adapt to batch-level data heterogeneity.
Theoretical analysis proves that pFedAFM can converge over time. Extensive
experiments on 2 benchmark datasets demonstrate that it significantly
outperforms 7 state-of-the-art MHPFL methods, achieving up to 7.93% accuracy
improvement while incurring low communication and computation costs.",2024-04-27,"Liping Yi, Han Yu, Chao Ren, Heng Zhang, Gang Wang, Xiaoguang Liu, Xiaoxiao Li",http://arxiv.org/pdf/2404.17847v1,cs.LG
Dynamic Against Dynamic: An Open-set Self-learning Framework,"In open-set recognition, existing methods generally learn statically fixed
decision boundaries using known classes to reject unknown classes. Though they
have achieved promising results, such decision boundaries are evidently
insufficient for universal unknown classes in dynamic and open scenarios as
they can potentially appear at any position in the feature space. Moreover,
these methods just simply reject unknown class samples during testing without
any effective utilization for them. In fact, such samples completely can
constitute the true instantiated representation of the unknown classes to
further enhance the model's performance. To address these issues, this paper
proposes a novel dynamic against dynamic idea, i.e., dynamic method against
dynamic changing open-set world, where an open-set self-learning (OSSL)
framework is correspondingly developed. OSSL starts with a good closed-set
classifier trained by known classes and utilizes available test samples for
model adaptation during testing, thus gaining the adaptability to changing data
distributions. In particular, a novel self-matching module is designed for
OSSL, which can achieve the adaptation in automatically identifying known class
samples while rejecting unknown class samples which are further utilized to
enhance the discriminability of the model as the instantiated representation of
unknown classes. Our method establishes new performance milestones respectively
in almost all standard and cross-data benchmarks.",2024-04-27,"Haifeng Yang, Chuanxing Geng, Pong C. Yuen, Songcan Chen",http://arxiv.org/pdf/2404.17830v2,cs.LG
The Simpler The Better: An Entropy-Based Importance Metric To Reduce Neural Networks' Depth,"While deep neural networks are highly effective at solving complex tasks,
large pre-trained models are commonly employed even to solve consistently
simpler downstream tasks, which do not necessarily require a large model's
complexity. Motivated by the awareness of the ever-growing AI environmental
impact, we propose an efficiency strategy that leverages prior knowledge
transferred by large models. Simple but effective, we propose a method relying
on an Entropy-bASed Importance mEtRic (EASIER) to reduce the depth of
over-parametrized deep neural networks, which alleviates their computational
burden. We assess the effectiveness of our method on traditional image
classification setups. Our code is available at https://github.com/VGCQ/EASIER.",2024-04-27,"Victor Quétu, Zhu Liao, Enzo Tartaglione",http://arxiv.org/pdf/2404.18949v2,cs.LG
Sub-Adjacent Transformer: Improving Time Series Anomaly Detection with Reconstruction Error from Sub-Adjacent Neighborhoods,"In this paper, we present the Sub-Adjacent Transformer with a novel attention
mechanism for unsupervised time series anomaly detection. Unlike previous
approaches that rely on all the points within some neighborhood for time point
reconstruction, our method restricts the attention to regions not immediately
adjacent to the target points, termed sub-adjacent neighborhoods. Our key
observation is that owing to the rarity of anomalies, they typically exhibit
more pronounced differences from their sub-adjacent neighborhoods than from
their immediate vicinities. By focusing the attention on the sub-adjacent
areas, we make the reconstruction of anomalies more challenging, thereby
enhancing their detectability. Technically, our approach concentrates attention
on the non-diagonal areas of the attention matrix by enlarging the
corresponding elements in the training stage. To facilitate the implementation
of the desired attention matrix pattern, we adopt linear attention because of
its flexibility and adaptability. Moreover, a learnable mapping function is
proposed to improve the performance of linear attention. Empirically, the
Sub-Adjacent Transformer achieves state-of-the-art performance across six
real-world anomaly detection benchmarks, covering diverse fields such as server
monitoring, space exploration, and water treatment.",2024-04-27,"Wenzhen Yue, Xianghua Ying, Ruohao Guo, DongDong Chen, Ji Shi, Bowei Xing, Yuqing Zhu, Taiyan Chen",http://arxiv.org/pdf/2404.18948v1,cs.LG
Motion planning for off-road autonomous driving based on human-like cognition and weight adaptation,"Driving in an off-road environment is challenging for autonomous vehicles due
to the complex and varied terrain. To ensure stable and efficient travel, the
vehicle requires consideration and balancing of environmental factors, such as
undulations, roughness, and obstacles, to generate optimal trajectories that
can adapt to changing scenarios. However, traditional motion planners often
utilize a fixed cost function for trajectory optimization, making it difficult
to adapt to different driving strategies in challenging irregular terrains and
uncommon scenarios. To address these issues, we propose an adaptive motion
planner based on human-like cognition and cost evaluation for off-road driving.
First, we construct a multi-layer map describing different features of off-road
terrains, including terrain elevation, roughness, obstacle, and artificial
potential field map. Subsequently, we employ a CNN-LSTM network to learn the
trajectories planned by human drivers in various off-road scenarios. Then,
based on human-like generated trajectories in different environments, we design
a primitive-based trajectory planner that aims to mimic human trajectories and
cost weight selection, generating trajectories that are consistent with the
dynamics of off-road vehicles. Finally, we compute optimal cost weights and
select and extend behavioral primitives to generate highly adaptive, stable,
and efficient trajectories.
  We validate the effectiveness of the proposed method through experiments in a
desert off-road environment with complex terrain and varying road conditions.
The experimental results show that the proposed human-like motion planner has
excellent adaptability to different off-road conditions. It shows real-time
operation, greater stability, and more human-like planning ability in diverse
and challenging scenarios.",2024-04-27,"Yuchun Wang, Cheng Gong, Jianwei Gong, Peng Jia",http://arxiv.org/pdf/2404.17820v1,cs.LG
Multimodal Fusion on Low-quality Data: A Comprehensive Survey,"Multimodal fusion focuses on integrating information from multiple modalities
with the goal of more accurate prediction, which has achieved remarkable
progress in a wide range of scenarios, including autonomous driving and medical
diagnosis. However, the reliability of multimodal fusion remains largely
unexplored especially under low-quality data settings. This paper surveys the
common challenges and recent advances of multimodal fusion in the wild and
presents them in a comprehensive taxonomy. From a data-centric view, we
identify four main challenges that are faced by multimodal fusion on
low-quality data, namely (1) noisy multimodal data that are contaminated with
heterogeneous noises, (2) incomplete multimodal data that some modalities are
missing, (3) imbalanced multimodal data that the qualities or properties of
different modalities are significantly different and (4) quality-varying
multimodal data that the quality of each modality dynamically changes with
respect to different samples. This new taxonomy will enable researchers to
understand the state of the field and identify several potential directions. We
also provide discussion for the open problems in this field together with
interesting future research directions.",2024-04-27,"Qingyang Zhang, Yake Wei, Zongbo Han, Huazhu Fu, Xi Peng, Cheng Deng, Qinghua Hu, Cai Xu, Jie Wen, Di Hu, Changqing Zhang",http://arxiv.org/pdf/2404.18947v3,cs.LG
T-CLAP: Temporal-Enhanced Contrastive Language-Audio Pretraining,"Contrastive language-audio pretraining~(CLAP) has been developed to align the
representations of audio and language, achieving remarkable performance in
retrieval and classification tasks. However, current CLAP struggles to capture
temporal information within audio and text features, presenting substantial
limitations for tasks such as audio retrieval and generation. To address this
gap, we introduce T-CLAP, a temporal-enhanced CLAP model. We use Large Language
Models~(LLMs) and mixed-up strategies to generate temporal-contrastive captions
for audio clips from extensive audio-text datasets. Subsequently, a new
temporal-focused contrastive loss is designed to fine-tune the CLAP model by
incorporating these synthetic data. We conduct comprehensive experiments and
analysis in multiple downstream tasks. T-CLAP shows improved capability in
capturing the temporal relationship of sound events and outperforms
state-of-the-art models by a significant margin.",2024-04-27,"Yi Yuan, Zhuo Chen, Xubo Liu, Haohe Liu, Xuenan Xu, Dongya Jia, Yuanzhe Chen, Mark D. Plumbley, Wenwu Wang",http://arxiv.org/pdf/2404.17806v1,cs.LG
From Optimization to Generalization: Fair Federated Learning against Quality Shift via Inter-Client Sharpness Matching,"Due to escalating privacy concerns, federated learning has been recognized as
a vital approach for training deep neural networks with decentralized medical
data. In practice, it is challenging to ensure consistent imaging quality
across various institutions, often attributed to equipment malfunctions
affecting a minority of clients. This imbalance in image quality can cause the
federated model to develop an inherent bias towards higher-quality images, thus
posing a severe fairness issue. In this study, we pioneer the identification
and formulation of this new fairness challenge within the context of the
imaging quality shift. Traditional methods for promoting fairness in federated
learning predominantly focus on balancing empirical risks across diverse client
distributions. This strategy primarily facilitates fair optimization across
different training data distributions, yet neglects the crucial aspect of
generalization. To address this, we introduce a solution termed Federated
learning with Inter-client Sharpness Matching (FedISM). FedISM enhances both
local training and global aggregation by incorporating sharpness-awareness,
aiming to harmonize the sharpness levels across clients for fair
generalization. Our empirical evaluations, conducted using the widely-used ICH
and ISIC 2019 datasets, establish FedISM's superiority over current
state-of-the-art federated learning methods in promoting fairness. Code is
available at https://github.com/wnn2000/FFL4MIA.",2024-04-27,"Nannan Wu, Zhuo Kuang, Zengqiang Yan, Li Yu",http://arxiv.org/pdf/2404.17805v2,cs.LG
Dynamical Mode Recognition of Coupled Flame Oscillators by Supervised and Unsupervised Learning Approaches,"Combustion instability in gas turbines and rocket engines, as one of the most
challenging problems in combustion research, arises from the complex
interactions among flames, which are also influenced by chemical reactions,
heat and mass transfer, and acoustics. Identifying and understanding combustion
instability is essential to ensure the safe and reliable operation of many
combustion systems, where exploring and classifying the dynamical behaviors of
complex flame systems is a core take. To facilitate fundamental studies, the
present work concerns dynamical mode recognition of coupled flame oscillators
made of flickering buoyant diffusion flames, which have gained increasing
attention in recent years but are not sufficiently understood. The time series
data of flame oscillators are generated by fully validated reacting flow
simulations. Due to limitations of expertise-based models, a data-driven
approach is adopted. In this study, a nonlinear dimensional reduction model of
variational autoencoder (VAE) is used to project the simulation data onto a
2-dimensional latent space. Based on the phase trajectories in latent space,
both supervised and unsupervised classifiers are proposed for datasets with
well known labeling and without, respectively. For labeled datasets, we
establish the Wasserstein-distance-based classifier (WDC) for mode recognition;
for unlabeled datasets, we develop a novel unsupervised classifier (GMM-DTWC)
combining dynamic time warping (DTW) and Gaussian mixture model (GMM). Through
comparing with conventional approaches for dimensionality reduction and
classification, the proposed supervised and unsupervised VAE-based approaches
exhibit a prominent performance for distinguishing dynamical modes, implying
their potential extension to dynamical mode recognition of complex combustion
problems.",2024-04-27,"Weiming Xu, Tao Yang, Peng Zhang",http://arxiv.org/pdf/2404.17801v3,cs.LG
Personalized Federated Learning via Sequential Layer Expansion in Representation Learning,"Federated learning ensures the privacy of clients by conducting distributed
training on individual client devices and sharing only the model weights with a
central server. However, in real-world scenarios, the heterogeneity of data
among clients necessitates appropriate personalization methods. In this paper,
we aim to address this heterogeneity using a form of parameter decoupling known
as representation learning. Representation learning divides deep learning
models into 'base' and 'head' components. The base component, capturing common
features across all clients, is shared with the server, while the head
component, capturing unique features specific to individual clients, remains
local. We propose a new representation learning-based approach that suggests
decoupling the entire deep learning model into more densely divided parts with
the application of suitable scheduling methods, which can benefit not only data
heterogeneity but also class heterogeneity. In this paper, we compare and
analyze two layer scheduling approaches, namely forward (\textit{Vanilla}) and
backward (\textit{Anti}), in the context of data and class heterogeneity among
clients. Our experimental results show that the proposed algorithm, when
compared to existing personalized federated learning algorithms, achieves
increased accuracy, especially under challenging conditions, while reducing
computation costs.",2024-04-27,"Jaewon Jang, Bonjun Choi",http://arxiv.org/pdf/2404.17799v1,cs.LG
From Linear to Linearizable Optimization: A Novel Framework with Applications to Stationary and Non-stationary DR-submodular Optimization,"This paper introduces the notion of upper-linearizable/quadratizable
functions, a class that extends concavity and DR-submodularity in various
settings, including monotone and non-monotone cases over different convex sets.
A general meta-algorithm is devised to convert algorithms for linear/quadratic
maximization into ones that optimize upper-linearizable/quadratizable
functions, offering a unified approach to tackling concave and DR-submodular
optimization problems. The paper extends these results to multiple feedback
settings, facilitating conversions between semi-bandit/first-order feedback and
bandit/zeroth-order feedback, as well as between first/zeroth-order feedback
and semi-bandit/bandit feedback. Leveraging this framework, new algorithms are
derived using existing results as base algorithms for convex optimization,
improving upon state-of-the-art results in various cases. Dynamic and adaptive
regret guarantees are obtained for DR-submodular maximization, marking the
first algorithms to achieve such guarantees in these settings. Notably, the
paper achieves these advancements with fewer assumptions compared to existing
state-of-the-art results, underscoring its broad applicability and theoretical
contributions to non-convex optimization.",2024-04-27,"Mohammad Pedramfar, Vaneet Aggarwal",http://arxiv.org/pdf/2405.00065v3,cs.LG
BiLO: Bilevel Local Operator Learning for PDE inverse problems,"We propose a new neural network based method for solving inverse problems for
partial differential equations (PDEs) by formulating the PDE inverse problem as
a bilevel optimization problem. At the upper level, we minimize the data loss
with respect to the PDE parameters. At the lower level, we train a neural
network to locally approximate the PDE solution operator in the neighborhood of
a given set of PDE parameters, which enables an accurate approximation of the
descent direction for the upper level optimization problem. The lower level
loss function includes the L2 norms of both the residual and its derivative
with respect to the PDE parameters. We apply gradient descent simultaneously on
both the upper and lower level optimization problems, leading to an effective
and fast algorithm. The method, which we refer to as BiLO (Bilevel Local
Operator learning), is also able to efficiently infer unknown functions in the
PDEs through the introduction of an auxiliary variable. Through extensive
experiments over multiple PDE systems, we demonstrate that our method enforces
strong PDE constraints, is robust to sparse and noisy data, and eliminates the
need to balance the residual and the data loss, which is inherent to the soft
PDE constraints in many existing methods.",2024-04-27,"Ray Zirui Zhang, Xiaohui Xie, John S. Lowengrub",http://arxiv.org/pdf/2404.17789v4,cs.LG
Intrinsic Voltage Offsets in Memcapacitive Bio-Membranes Enable High-Performance Physical Reservoir Computing,"Reservoir computing is a brain-inspired machine learning framework for
processing temporal data by mapping inputs into high-dimensional spaces.
Physical reservoir computers (PRCs) leverage native fading memory and
nonlinearity in physical substrates, including atomic switches, photonics,
volatile memristors, and, recently, memcapacitors, to achieve efficient
high-dimensional mapping. Traditional PRCs often consist of homogeneous device
arrays, which rely on input encoding methods and large stochastic
device-to-device variations for increased nonlinearity and high-dimensional
mapping. These approaches incur high pre-processing costs and restrict
real-time deployment. Here, we introduce a novel heterogeneous
memcapacitor-based PRC that exploits internal voltage offsets to enable both
monotonic and non-monotonic input-state correlations crucial for efficient
high-dimensional transformations. We demonstrate our approach's efficacy by
predicting a second-order nonlinear dynamical system with an extremely low
prediction error (0.00018). Additionally, we predict a chaotic H\'enon map,
achieving a low normalized root mean square error (0.080). Unlike previous
PRCs, such errors are achieved without input encoding methods, underscoring the
power of distinct input-state correlations. Most importantly, we generalize our
approach to other neuromorphic devices that lack inherent voltage offsets using
externally applied offsets to realize various input-state correlations. Our
approach and unprecedented performance are a major milestone towards
high-performance full in-materia PRCs.",2024-04-27,"Ahmed S. Mohamed, Anurag Dhungel, Md Sakib Hasan, Joseph S. Najem",http://arxiv.org/pdf/2405.09545v1,cs.LG
Compressing Latent Space via Least Volume,"This paper introduces Least Volume-a simple yet effective regularization
inspired by geometric intuition-that can reduce the necessary number of latent
dimensions needed by an autoencoder without requiring any prior knowledge of
the intrinsic dimensionality of the dataset. We show that the Lipschitz
continuity of the decoder is the key to making it work, provide a proof that
PCA is just a linear special case of it, and reveal that it has a similar
PCA-like importance ordering effect when applied to nonlinear models. We
demonstrate the intuition behind the regularization on some pedagogical toy
problems, and its effectiveness on several benchmark problems, including MNIST,
CIFAR-10 and CelebA.",2024-04-27,"Qiuyi Chen, Mark Fuge",http://arxiv.org/pdf/2404.17773v1,cs.LG
Changing the Training Data Distribution to Reduce Simplicity Bias Improves In-distribution Generalization,"Can we modify the training data distribution to encourage the underlying
optimization method toward finding solutions with superior generalization
performance on in-distribution data? In this work, we approach this question
for the first time by comparing the inductive bias of gradient descent (GD)
with that of sharpness-aware minimization (SAM). By studying a two-layer CNN,
we rigorously prove that SAM learns different features more uniformly,
particularly in early epochs. That is, SAM is less susceptible to simplicity
bias compared to GD. We also show that examples containing features that are
learned early are separable from the rest based on the model's output. Based on
this observation, we propose a method that (i) clusters examples based on the
network output early in training, (ii) identifies a cluster of examples with
similar network output, and (iii) upsamples the rest of examples only once to
alleviate the simplicity bias. We show empirically that USEFUL effectively
improves the generalization performance on the original data distribution when
training with various gradient methods, including (S)GD and SAM. Notably, we
demonstrate that our method can be combined with SAM variants and existing data
augmentation strategies to achieve, to the best of our knowledge,
state-of-the-art performance for training ResNet18 on CIFAR10, STL10, CINIC10,
Tiny-ImageNet; ResNet34 on CIFAR100; and VGG19 and DenseNet121 on CIFAR10.",2024-04-27,"Dang Nguyen, Paymon Haddad, Eric Gan, Baharan Mirzasoleiman",http://arxiv.org/pdf/2404.17768v2,cs.LG
Implementation of Big AI Models for Wireless Networks with Collaborative Edge Computing,"Big Artificial Intelligence (AI) models have emerged as a crucial element in
various intelligent applications at the edge, such as voice assistants in smart
homes and autonomous robotics in smart factories. Training big AI models, e.g.,
for personalized fine-tuning and continual model refinement, poses significant
challenges to edge devices due to the inherent conflict between limited
computing resources and intensive workload associated with training. Despite
the constraints of on-device training, traditional approaches usually resort to
aggregating training data and sending it to a remote cloud for centralized
training. Nevertheless, this approach is neither sustainable, which strains
long-range backhaul transmission and energy-consuming datacenters, nor safely
private, which shares users' raw data with remote infrastructures. To address
these challenges, we alternatively observe that prevalent edge environments
usually contain a diverse collection of trusted edge devices with untapped idle
resources, which can be leveraged for edge training acceleration. Motivated by
this, in this article, we propose collaborative edge training, a novel training
mechanism that orchestrates a group of trusted edge devices as a resource pool
for expedited, sustainable big AI model training at the edge. As an initial
step, we present a comprehensive framework for building collaborative edge
training systems and analyze in-depth its merits and sustainable scheduling
choices following its workflow. To further investigate the impact of its
parallelism design, we empirically study a case of four typical parallelisms
from the perspective of energy demand with realistic testbeds. Finally, we
discuss open challenges for sustainable collaborative edge training to point to
future directions of edge-centric big AI model training.",2024-04-27,"Liekang Zeng, Shengyuan Ye, Xu Chen, Yang Yang",http://arxiv.org/pdf/2404.17766v1,cs.LG
Adversarial Examples: Generation Proposal in the Context of Facial Recognition Systems,"In this paper we investigate the vulnerability that facial recognition
systems present to adversarial examples by introducing a new methodology from
the attacker perspective. The technique is based on the use of the autoencoder
latent space, organized with principal component analysis. We intend to analyze
the potential to craft adversarial examples suitable for both dodging and
impersonation attacks, against state-of-the-art systems. Our initial
hypothesis, which was not strongly favoured by the results, stated that it
would be possible to separate between the ""identity"" and ""facial expression""
features to produce high-quality examples. Despite the findings not supporting
it, the results sparked insights into adversarial examples generation and
opened new research avenues in the area.",2024-04-27,"Marina Fuster, Ignacio Vidaurreta",http://arxiv.org/pdf/2404.17760v1,cs.LG
Generative Diffusion-based Downscaling for Climate,"Downscaling, or super-resolution, provides decision-makers with detailed,
high-resolution information about the potential risks and impacts of climate
change, based on climate model output. Machine learning algorithms are proving
themselves to be efficient and accurate approaches to downscaling. Here, we
show how a generative, diffusion-based approach to downscaling gives accurate
downscaled results. We focus on an idealised setting where we recover ERA5 at
$0.25\degree$~resolution from coarse grained version at $2\degree$~resolution.
The diffusion-based method provides superior accuracy compared to a standard
U-Net, particularly at the fine scales, as highlighted by a spectral
decomposition. Additionally, the generative approach provides users with a
probability distribution which can be used for risk assessment. This research
highlights the potential of diffusion-based downscaling techniques in providing
reliable and detailed climate predictions.",2024-04-27,"Robbie A. Watt, Laura A. Mansfield",http://arxiv.org/pdf/2404.17752v1,cs.LG
On the Rashomon ratio of infinite hypothesis sets,"Given a classification problem and a family of classifiers, the Rashomon
ratio measures the proportion of classifiers that yield less than a given loss.
Previous work has explored the advantage of a large Rashomon ratio in the case
of a finite family of classifiers. Here we consider the more general case of an
infinite family. We show that a large Rashomon ratio guarantees that choosing
the classifier with the best empirical accuracy among a random subset of the
family, which is likely to improve generalizability, will not increase the
empirical loss too much. We quantify the Rashomon ratio in two examples
involving infinite classifier families in order to illustrate situations in
which it is large. In the first example, we estimate the Rashomon ratio of the
classification of normally distributed classes using an affine classifier. In
the second, we obtain a lower bound for the Rashomon ratio of a classification
problem with a modified Gram matrix when the classifier family consists of
two-layer ReLU neural networks. In general, we show that the Rashomon ratio can
be estimated using a training dataset along with random samples from the
classifier family and we provide guarantees that such an estimation is close to
the true value of the Rashomon ratio.",2024-04-27,"Evzenie Coupkova, Mireille Boutin",http://arxiv.org/pdf/2404.17746v1,cs.LG
Attacking Bayes: On the Adversarial Robustness of Bayesian Neural Networks,"Adversarial examples have been shown to cause neural networks to fail on a
wide range of vision and language tasks, but recent work has claimed that
Bayesian neural networks (BNNs) are inherently robust to adversarial
perturbations. In this work, we examine this claim. To study the adversarial
robustness of BNNs, we investigate whether it is possible to successfully break
state-of-the-art BNN inference methods and prediction pipelines using even
relatively unsophisticated attacks for three tasks: (1) label prediction under
the posterior predictive mean, (2) adversarial example detection with Bayesian
predictive uncertainty, and (3) semantic shift detection. We find that BNNs
trained with state-of-the-art approximate inference methods, and even BNNs
trained with Hamiltonian Monte Carlo, are highly susceptible to adversarial
attacks. We also identify various conceptual and experimental errors in
previous works that claimed inherent adversarial robustness of BNNs and
conclusively demonstrate that BNNs and uncertainty-aware Bayesian prediction
pipelines are not inherently robust against adversarial attacks.",2024-04-27,"Yunzhen Feng, Tim G. J. Rudner, Nikolaos Tsilivis, Julia Kempe",http://arxiv.org/pdf/2404.19640v1,cs.LG
An Attention-Based Deep Learning Architecture for Real-Time Monocular Visual Odometry: Applications to GPS-free Drone Navigation,"Drones are increasingly used in fields like industry, medicine, research,
disaster relief, defense, and security. Technical challenges, such as
navigation in GPS-denied environments, hinder further adoption. Research in
visual odometry is advancing, potentially solving GPS-free navigation issues.
Traditional visual odometry methods use geometry-based pipelines which, while
popular, often suffer from error accumulation and high computational demands.
Recent studies utilizing deep neural networks (DNNs) have shown improved
performance, addressing these drawbacks. Deep visual odometry typically employs
convolutional neural networks (CNNs) and sequence modeling networks like
recurrent neural networks (RNNs) to interpret scenes and deduce visual odometry
from video sequences. This paper presents a novel real-time monocular visual
odometry model for drones, using a deep neural architecture with a
self-attention module. It estimates the ego-motion of a camera on a drone,
using consecutive video frames. An inference utility processes the live video
feed, employing deep learning to estimate the drone's trajectory. The
architecture combines a CNN for image feature extraction and a long short-term
memory (LSTM) network with a multi-head attention module for video sequence
modeling. Tested on two visual odometry datasets, this model converged 48%
faster than a previous RNN model and showed a 22% reduction in mean
translational drift and a 12% improvement in mean translational absolute
trajectory error, demonstrating enhanced robustness to noise.",2024-04-27,"Olivier Brochu Dufour, Abolfazl Mohebbi, Sofiane Achiche",http://arxiv.org/pdf/2404.17745v1,cs.LG
Causal Diffusion Autoencoders: Toward Counterfactual Generation via Diffusion Probabilistic Models,"Diffusion probabilistic models (DPMs) have become the state-of-the-art in
high-quality image generation. However, DPMs have an arbitrary noisy latent
space with no interpretable or controllable semantics. Although there has been
significant research effort to improve image sample quality, there is little
work on representation-controlled generation using diffusion models.
Specifically, causal modeling and controllable counterfactual generation using
DPMs is an underexplored area. In this work, we propose CausalDiffAE, a
diffusion-based causal representation learning framework to enable
counterfactual generation according to a specified causal model. Our key idea
is to use an encoder to extract high-level semantically meaningful causal
variables from high-dimensional data and model stochastic variation using
reverse diffusion. We propose a causal encoding mechanism that maps
high-dimensional data to causally related latent factors and parameterize the
causal mechanisms among latent factors using neural networks. To enforce the
disentanglement of causal variables, we formulate a variational objective and
leverage auxiliary label information in a prior to regularize the latent space.
We propose a DDIM-based counterfactual generation procedure subject to
do-interventions. Finally, to address the limited label supervision scenario,
we also study the application of CausalDiffAE when a part of the training data
is unlabeled, which also enables granular control over the strength of
interventions in generating counterfactuals during inference. We empirically
show that CausalDiffAE learns a disentangled latent space and is capable of
generating high-quality counterfactual images.",2024-04-27,"Aneesh Komanduri, Chen Zhao, Feng Chen, Xintao Wu",http://arxiv.org/pdf/2404.17735v3,cs.LG
Generative Dataset Distillation: Balancing Global Structure and Local Details,"In this paper, we propose a new dataset distillation method that considers
balancing global structure and local details when distilling the information
from a large dataset into a generative model. Dataset distillation has been
proposed to reduce the size of the required dataset when training models. The
conventional dataset distillation methods face the problem of long redeployment
time and poor cross-architecture performance. Moreover, previous methods
focused too much on the high-level semantic attributes between the synthetic
dataset and the original dataset while ignoring the local features such as
texture and shape. Based on the above understanding, we propose a new method
for distilling the original image dataset into a generative model. Our method
involves using a conditional generative adversarial network to generate the
distilled dataset. Subsequently, we ensure balancing global structure and local
details in the distillation process, continuously optimizing the generator for
more information-dense dataset generation.",2024-04-26,"Longzhen Li, Guang Li, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama",http://arxiv.org/pdf/2404.17732v1,cs.LG
Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering,"In customer service technical support, swiftly and accurately retrieving
relevant past issues is critical for efficiently resolving customer inquiries.
The conventional retrieval methods in retrieval-augmented generation (RAG) for
large language models (LLMs) treat a large corpus of past issue tracking
tickets as plain text, ignoring the crucial intra-issue structure and
inter-issue relations, which limits performance. We introduce a novel customer
service question-answering method that amalgamates RAG with a knowledge graph
(KG). Our method constructs a KG from historical issues for use in retrieval,
retaining the intra-issue structure and inter-issue relations. During the
question-answering phase, our method parses consumer queries and retrieves
related sub-graphs from the KG to generate answers. This integration of a KG
not only improves retrieval accuracy by preserving customer service structure
information but also enhances answering quality by mitigating the effects of
text segmentation. Empirical assessments on our benchmark datasets, utilizing
key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR)
metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by
0.32 in BLEU. Our method has been deployed within LinkedIn's customer service
team for approximately six months and has reduced the median per-issue
resolution time by 28.6%.",2024-04-26,"Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, Zheng Li",http://arxiv.org/pdf/2404.17723v2,cs.LG
Lessons from Deploying CropFollow++: Under-Canopy Agricultural Navigation with Keypoints,"We present a vision-based navigation system for under-canopy agricultural
robots using semantic keypoints. Autonomous under-canopy navigation is
challenging due to the tight spacing between the crop rows ($\sim 0.75$ m),
degradation in RTK-GPS accuracy due to multipath error, and noise in LiDAR
measurements from the excessive clutter. Our system, CropFollow++, introduces
modular and interpretable perception architecture with a learned semantic
keypoint representation. We deployed CropFollow++ in multiple under-canopy
cover crop planting robots on a large scale (25 km in total) in various field
conditions and we discuss the key lessons learned from this.",2024-04-26,"Arun N. Sivakumar, Mateus V. Gasparino, Michael McGuire, Vitor A. H. Higuti, M. Ugur Akcal, Girish Chowdhary",http://arxiv.org/pdf/2404.17718v1,cs.LG
Lower Bounds for Private Estimation of Gaussian Covariance Matrices under All Reasonable Parameter Regimes,"We prove lower bounds on the number of samples needed to privately estimate
the covariance matrix of a Gaussian distribution. Our bounds match existing
upper bounds in the widest known setting of parameters. Our analysis relies on
the Stein-Haff identity, an extension of the classical Stein's identity used in
previous fingerprinting lemma arguments.",2024-04-26,"Victor S. Portella, Nick Harvey",http://arxiv.org/pdf/2404.17714v1,cs.LG
Low-rank Matrix Bandits with Heavy-tailed Rewards,"In stochastic low-rank matrix bandit, the expected reward of an arm is equal
to the inner product between its feature matrix and some unknown $d_1$ by $d_2$
low-rank parameter matrix $\Theta^*$ with rank $r \ll d_1\wedge d_2$. While all
prior studies assume the payoffs are mixed with sub-Gaussian noises, in this
work we loosen this strict assumption and consider the new problem of
\underline{low}-rank matrix bandit with \underline{h}eavy-\underline{t}ailed
\underline{r}ewards (LowHTR), where the rewards only have finite $(1+\delta)$
moment for some $\delta \in (0,1]$. By utilizing the truncation on observed
payoffs and the dynamic exploration, we propose a novel algorithm called LOTUS
attaining the regret bound of order $\tilde
O(d^\frac{3}{2}r^\frac{1}{2}T^\frac{1}{1+\delta}/\tilde{D}_{rr})$ without
knowing $T$, which matches the state-of-the-art regret bound under sub-Gaussian
noises~\citep{lu2021low,kang2022efficient} with $\delta = 1$. Moreover, we
establish a lower bound of the order $\Omega(d^\frac{\delta}{1+\delta}
r^\frac{\delta}{1+\delta} T^\frac{1}{1+\delta}) = \Omega(T^\frac{1}{1+\delta})$
for LowHTR, which indicates our LOTUS is nearly optimal in the order of $T$. In
addition, we improve LOTUS so that it does not require knowledge of the rank
$r$ with $\tilde O(dr^\frac{3}{2}T^\frac{1+\delta}{1+2\delta})$ regret bound,
and it is efficient under the high-dimensional scenario. We also conduct
simulations to demonstrate the practical superiority of our algorithm.",2024-04-26,"Yue Kang, Cho-Jui Hsieh, Thomas C. M. Lee",http://arxiv.org/pdf/2404.17709v1,cs.LG
"Generalised envelope spectrum-based signal-to-noise objectives: Formulation, optimisation and application for gear fault detection under time-varying speed conditions","In vibration-based condition monitoring, optimal filter design improves fault
detection by enhancing weak fault signatures within vibration signals. This
process involves optimising a derived objective function from a defined
objective. The objectives are often based on proxy health indicators to
determine the filter's parameters. However, these indicators can be compromised
by irrelevant extraneous signal components and fluctuating operational
conditions, affecting the filter's efficacy. Fault detection primarily uses the
fault component's prominence in the squared envelope spectrum, quantified by a
squared envelope spectrum-based signal-to-noise ratio. New optimal filter
objective functions are derived from the proposed generalised envelope
spectrum-based signal-to-noise objective for machines operating under variable
speed conditions. Instead of optimising proxy health indicators, the optimal
filter coefficients of the formulation directly maximise the squared envelope
spectrum-based signal-to-noise ratio over targeted frequency bands using
standard gradient-based optimisers. Four derived objective functions from the
proposed objective effectively outperform five prominent methods in tests on
three experimental datasets.",2024-04-26,"Stephan Schmidt, Daniel N. Wilke, Konstantinos C. Gryllias",http://arxiv.org/pdf/2405.00727v2,cs.LG
SPLICE -- Streamlining Digital Pathology Image Processing,"Digital pathology and the integration of artificial intelligence (AI) models
have revolutionized histopathology, opening new opportunities. With the
increasing availability of Whole Slide Images (WSIs), there's a growing demand
for efficient retrieval, processing, and analysis of relevant images from vast
biomedical archives. However, processing WSIs presents challenges due to their
large size and content complexity. Full computer digestion of WSIs is
impractical, and processing all patches individually is prohibitively
expensive. In this paper, we propose an unsupervised patching algorithm,
Sequential Patching Lattice for Image Classification and Enquiry (SPLICE). This
novel approach condenses a histopathology WSI into a compact set of
representative patches, forming a ""collage"" of WSI while minimizing redundancy.
SPLICE prioritizes patch quality and uniqueness by sequentially analyzing a WSI
and selecting non-redundant representative features. We evaluated SPLICE for
search and match applications, demonstrating improved accuracy, reduced
computation time, and storage requirements compared to existing
state-of-the-art methods. As an unsupervised method, SPLICE effectively reduces
storage requirements for representing tissue images by 50%. This reduction
enables numerous algorithms in computational pathology to operate much more
efficiently, paving the way for accelerated adoption of digital pathology.",2024-04-26,"Areej Alsaafin, Peyman Nejat, Abubakr Shafique, Jibran Khan, Saghir Alfasly, Ghazal Alabtah, H. R. Tizhoosh",http://arxiv.org/pdf/2404.17704v1,cs.LG
Embedded FPGA Developments in 130nm and 28nm CMOS for Machine Learning in Particle Detector Readout,"Embedded field programmable gate array (eFPGA) technology allows the
implementation of reconfigurable logic within the design of an
application-specific integrated circuit (ASIC). This approach offers the low
power and efficiency of an ASIC along with the ease of FPGA configuration,
particularly beneficial for the use case of machine learning in the data
pipeline of next-generation collider experiments. An open-source framework
called ""FABulous"" was used to design eFPGAs using 130 nm and 28 nm CMOS
technology nodes, which were subsequently fabricated and verified through
testing. The capability of an eFPGA to act as a front-end readout chip was
assessed using simulation of high energy particles passing through a silicon
pixel sensor. A machine learning-based classifier, designed for reduction of
sensor data at the source, was synthesized and configured onto the eFPGA. A
successful proof-of-concept was demonstrated through reproduction of the
expected algorithm result on the eFPGA with perfect accuracy. Further
development of the eFPGA technology and its application to collider detector
readout is discussed.",2024-04-26,"Julia Gonski, Aseem Gupta, Haoyi Jia, Hyunjoon Kim, Lorenzo Rota, Larry Ruckman, Angelo Dragone, Ryan Herbst",http://arxiv.org/pdf/2404.17701v5,cs.LG
Deep Learning for Melt Pool Depth Contour Prediction From Surface Thermal Images via Vision Transformers,"Insufficient overlap between the melt pools produced during Laser Powder Bed
Fusion (L-PBF) can lead to lack-of-fusion defects and deteriorated mechanical
and fatigue performance. In-situ monitoring of the melt pool subsurface
morphology requires specialized equipment that may not be readily accessible or
scalable. Therefore, we introduce a machine learning framework to correlate
in-situ two-color thermal images observed via high-speed color imaging to the
two-dimensional profile of the melt pool cross-section. Specifically, we employ
a hybrid CNN-Transformer architecture to establish a correlation between single
bead off-axis thermal image sequences and melt pool cross-section contours
measured via optical microscopy. In this architecture, a ResNet model embeds
the spatial information contained within the thermal images to a latent vector,
while a Transformer model correlates the sequence of embedded vectors to
extract temporal information. Our framework is able to model the curvature of
the subsurface melt pool structure, with improved performance in high energy
density regimes compared to analytical melt pool models. The performance of
this model is evaluated through dimensional and geometric comparisons to the
corresponding experimental melt pool observations.",2024-04-26,"Francis Ogoke, Peter Myung-Won Pak, Alexander Myers, Guadalupe Quirarte, Jack Beuth, Jonathan Malen, Amir Barati Farimani",http://arxiv.org/pdf/2404.17699v3,cs.LG
A Biased Estimator for MinMax Sampling and Distributed Aggregation,"MinMax sampling is a technique for downsampling a real-valued vector which
minimizes the maximum variance over all vector components. This approach is
useful for reducing the amount of data that must be sent over a constrained
network link (e.g. in the wide-area). MinMax can provide unbiased estimates of
the vector elements, along with unbiased estimates of aggregates when vectors
are combined from multiple locations. In this work, we propose a biased MinMax
estimation scheme, B-MinMax, which trades an increase in estimator bias for a
reduction in variance. We prove that when no aggregation is performed, B-MinMax
obtains a strictly lower MSE compared to the unbiased MinMax estimator. When
aggregation is required, B-MinMax is preferable when sample sizes are small or
the number of aggregated vectors is limited. Our experiments show that this
approach can substantially reduce the MSE for MinMax sampling in many practical
settings.",2024-04-26,"Joel Wolfrath, Abhishek Chandra",http://arxiv.org/pdf/2404.17690v1,cs.LG
Knowledge Transfer for Cross-Domain Reinforcement Learning: A Systematic Review,"Reinforcement Learning (RL) provides a framework in which agents can be
trained, via trial and error, to solve complex decision-making problems.
Learning with little supervision causes RL methods to require large amounts of
data, rendering them too expensive for many applications (e.g., robotics). By
reusing knowledge from a different task, knowledge transfer methods present an
alternative to reduce the training time in RL. Given the severe data scarcity,
due to their flexibility, there has been a growing interest in methods capable
of transferring knowledge across different domains (i.e., problems with
different representations). However, identifying similarities and adapting
knowledge across tasks from different domains requires matching their
representations or finding domain-invariant features. These processes can be
data-demanding, which poses the main challenge in cross-domain knowledge
transfer: to select and transform knowledge in a data-efficient way, such that
it accelerates learning in the target task, despite the presence of significant
differences across problems (e.g., robots with distinct morphologies). Thus,
this review presents a unifying analysis of methods focused on transferring
knowledge across different domains. Through a taxonomy based on a
transfer-approach categorization and a characterization of works based on their
data-assumption requirements, the contributions of this article are 1) a
comprehensive and systematic revision of knowledge transfer methods for the
cross-domain RL setting, 2) a categorization and characterization of such
methods to provide an analysis based on relevant features such as their
transfer approach and data requirements, and 3) a discussion on the main
challenges regarding cross-domain knowledge transfer, as well as on ideas of
future directions worth exploring to address these problems.",2024-04-26,"Sergio A. Serrano, Jose Martinez-Carranza, L. Enrique Sucar",http://arxiv.org/pdf/2404.17687v2,cs.LG
Generalize by Touching: Tactile Ensemble Skill Transfer for Robotic Furniture Assembly,"Furniture assembly remains an unsolved problem in robotic manipulation due to
its long task horizon and nongeneralizable operations plan. This paper presents
the Tactile Ensemble Skill Transfer (TEST) framework, a pioneering offline
reinforcement learning (RL) approach that incorporates tactile feedback in the
control loop. TEST's core design is to learn a skill transition model for
high-level planning, along with a set of adaptive intra-skill goal-reaching
policies. Such design aims to solve the robotic furniture assembly problem in a
more generalizable way, facilitating seamless chaining of skills for this
long-horizon task. We first sample demonstration from a set of heuristic
policies and trajectories consisting of a set of randomized sub-skill segments,
enabling the acquisition of rich robot trajectories that capture skill stages,
robot states, visual indicators, and crucially, tactile signals. Leveraging
these trajectories, our offline RL method discerns skill termination conditions
and coordinates skill transitions. Our evaluations highlight the proficiency of
TEST on the in-distribution furniture assemblies, its adaptability to unseen
furniture configurations, and its robustness against visual disturbances.
Ablation studies further accentuate the pivotal role of two algorithmic
components: the skill transition model and tactile ensemble policies. Results
indicate that TEST can achieve a success rate of 90\% and is over 4 times more
efficient than the heuristic policy in both in-distribution and generalization
settings, suggesting a scalable skill transfer approach for contact-rich
manipulation.",2024-04-26,"Haohong Lin, Radu Corcodel, Ding Zhao",http://arxiv.org/pdf/2404.17684v1,cs.LG
Energy Storage Arbitrage in Two-settlement Markets: A Transformer-Based Approach,"This paper presents an integrated model for bidding energy storage in
day-ahead and real-time markets to maximize profits. We show that in integrated
two-stage bidding, the real-time bids are independent of day-ahead settlements,
while the day-ahead bids should be based on predicted real-time prices. We
utilize a transformer-based model for real-time price prediction, which
captures complex dynamical patterns of real-time prices, and use the result for
day-ahead bidding design. For real-time bidding, we utilize a long short-term
memory-dynamic programming hybrid real-time bidding model. We train and test
our model with historical data from New York State, and our results showed that
the integrated system achieved promising results of almost a 20\% increase in
profit compared to only bidding in real-time markets, and at the same time
reducing the risk in terms of the number of days with negative profits.",2024-04-26,"Saud Alghumayjan, Jiajun Han, Ningkun Zheng, Ming Yi, Bolun Xu",http://arxiv.org/pdf/2404.17683v1,cs.LG
Center-Based Relaxed Learning Against Membership Inference Attacks,"Membership inference attacks (MIAs) are currently considered one of the main
privacy attack strategies, and their defense mechanisms have also been
extensively explored. However, there is still a gap between the existing
defense approaches and ideal models in performance and deployment costs. In
particular, we observed that the privacy vulnerability of the model is closely
correlated with the gap between the model's data-memorizing ability and
generalization ability. To address this, we propose a new architecture-agnostic
training paradigm called center-based relaxed learning (CRL), which is adaptive
to any classification model and provides privacy preservation by sacrificing a
minimal or no loss of model generalizability. We emphasize that CRL can better
maintain the model's consistency between member and non-member data. Through
extensive experiments on standard classification datasets, we empirically show
that this approach exhibits comparable performance without requiring additional
model capacity or data costs.",2024-04-26,"Xingli Fang, Jung-Eun Kim",http://arxiv.org/pdf/2404.17674v2,cs.LG
Learning Manipulation Tasks in Dynamic and Shared 3D Spaces,"Automating the segregation process is a need for every sector experiencing a
high volume of materials handling, repetitive and exhaustive operations, in
addition to risky exposures. Learning automated pick-and-place operations can
be efficiently done by introducing collaborative autonomous systems (e.g.
manipulators) in the workplace and among human operators. In this paper, we
propose a deep reinforcement learning strategy to learn the place task of
multi-categorical items from a shared workspace between dual-manipulators and
to multi-goal destinations, assuming the pick has been already completed. The
learning strategy leverages first a stochastic actor-critic framework to train
an agent's policy network, and second, a dynamic 3D Gym environment where both
static and dynamic obstacles (e.g. human factors and robot mate) constitute the
state space of a Markov decision process. Learning is conducted in a Gazebo
simulator and experiments show an increase in cumulative reward function for
the agent further away from human factors. Future investigations will be
conducted to enhance the task performance for both agents simultaneously.",2024-04-26,"Hariharan Arunachalam, Marc Hanheide, Sariah Mghames",http://arxiv.org/pdf/2404.17673v1,cs.LG
sDAC -- Semantic Digital Analog Converter for Semantic Communications,"In this paper, we propose a novel semantic digital analog converter (sDAC)
for the compatibility of semantic communications and digital communications.
Most of the current semantic communication systems are based on the analog
modulations, ignoring their incorporation with digital communication systems,
which are more common in practice. In fact, quantization methods in traditional
communication systems are not appropriate for use in the era of semantic
communication as these methods do not consider the semantic information inside
symbols. In this case, any bit flip caused by channel noise can lead to a great
performance drop. To address this challenge, sDAC is proposed. It is a simple
yet efficient and generative module used to realize digital and analog
bi-directional conversion. On the transmitter side, continuous values from the
encoder are converted to binary bits and then can be modulated by any existing
methods. After transmitting through the noisy channel, these bits get
demodulated by paired methods and converted back to continuous values for
further semantic decoding. The whole progress does not depend on any specific
semantic model, modulation methods, or channel conditions. In the experiment
section, the performance of sDAC is tested across different semantic models,
semantic tasks, modulation methods, channel conditions and quantization orders.
Test results show that the proposed sDAC has great generative properties and
channel robustness.",2024-04-26,"Zhicheng Bao, Chen Dong, Xiaodong Xu",http://arxiv.org/pdf/2405.02335v1,cs.LG
Federated Learning and Differential Privacy Techniques on Multi-hospital Population-scale Electrocardiogram Data,"This research paper explores ways to apply Federated Learning (FL) and
Differential Privacy (DP) techniques to population-scale Electrocardiogram
(ECG) data. The study learns a multi-label ECG classification model using FL
and DP based on 1,565,849 ECG tracings from 7 hospitals in Alberta, Canada. The
FL approach allowed collaborative model training without sharing raw data
between hospitals while building robust ECG classification models for
diagnosing various cardiac conditions. These accurate ECG classification models
can facilitate the diagnoses while preserving patient confidentiality using FL
and DP techniques. Our results show that the performance achieved using our
implementation of the FL approach is comparable to that of the pooled approach,
where the model is trained over the aggregating data from all hospitals.
Furthermore, our findings suggest that hospitals with limited ECGs for training
can benefit from adopting the FL model compared to single-site training. In
addition, this study showcases the trade-off between model performance and data
privacy by employing DP during model training. Our code is available at
https://github.com/vikhyatt/Hospital-FL-DP.",2024-04-26,"Vikhyat Agrawal, Sunil Vasu Kalmady, Venkataseetharam Manoj Malipeddi, Manisimha Varma Manthena, Weijie Sun, Saiful Islam, Abram Hindle, Padma Kaul, Russell Greiner",http://arxiv.org/pdf/2405.00725v2,cs.LG
Federated Learning for Blind Image Super-Resolution,"Traditional blind image SR methods need to model real-world degradations
precisely. Consequently, current research struggles with this dilemma by
assuming idealized degradations, which leads to limited applicability to actual
user data. Moreover, the ideal scenario - training models on data from the
targeted user base - presents significant privacy concerns. To address both
challenges, we propose to fuse image SR with federated learning, allowing
real-world degradations to be directly learned from users without invading
their privacy. Furthermore, it enables optimization across many devices without
data centralization. As this fusion is underexplored, we introduce new
benchmarks specifically designed to evaluate new SR methods in this federated
setting. By doing so, we employ known degradation modeling techniques from SR
research. However, rather than aiming to mirror real degradations, our
benchmarks use these degradation models to simulate the variety of degradations
found across clients within a distributed user base. This distinction is
crucial as it circumvents the need to precisely model real-world degradations,
which limits contemporary blind image SR research. Our proposed benchmarks
investigate blind image SR under new aspects, namely differently distributed
degradation types among users and varying user numbers. We believe new methods
tested within these benchmarks will perform more similarly in an application,
as the simulated scenario addresses the variety while federated learning
enables the training on actual degradations.",2024-04-26,"Brian B. Moser, Ahmed Anwar, Federico Raue, Stanislav Frolov, Andreas Dengel",http://arxiv.org/pdf/2404.17670v1,cs.LG
SiamQuality: A ConvNet-Based Foundation Model for Imperfect Physiological Signals,"Foundation models, especially those using transformers as backbones, have
gained significant popularity, particularly in language and language-vision
tasks. However, large foundation models are typically trained on high-quality
data, which poses a significant challenge, given the prevalence of poor-quality
real-world data. This challenge is more pronounced for developing foundation
models for physiological data; such data are often noisy, incomplete, or
inconsistent. The present work aims to provide a toolset for developing
foundation models on physiological data. We leverage a large dataset of
photoplethysmography (PPG) signals from hospitalized intensive care patients.
For this data, we propose SimQuality, a novel self-supervised learning task
based on convolutional neural networks (CNNs) as the backbone to enforce
representations to be similar for good and poor quality signals that are from
similar physiological states. We pre-trained the SimQuality on over 36 million
30-second PPG pairs and then fine-tuned and tested on six downstream tasks
using external datasets. The results demonstrate the superiority of the
proposed approach on all the downstream tasks, which are extremely important
for heart monitoring on wearable devices. Our method indicates that CNNs can be
an effective backbone for foundation models that are robust to training data
quality.",2024-04-26,"Cheng Ding, Zhicheng Guo, Zhaoliang Chen, Randall J Lee, Cynthia Rudin, Xiao Hu",http://arxiv.org/pdf/2404.17667v1,cs.LG
Validating Deep Learning Weather Forecast Models on Recent High-Impact Extreme Events,"The forecast accuracy of machine learning (ML) weather prediction models is
improving rapidly, leading many to speak of a ""second revolution in weather
forecasting"". With numerous methods being developed and limited physical
guarantees offered by ML models, there is a critical need for a comprehensive
evaluation of these emerging techniques. While this need has been partly
fulfilled by benchmark datasets, they provide little information on rare and
impactful extreme events or on compound impact metrics, for which model
accuracy might degrade due to misrepresented dependencies between variables. To
address these issues, we compare ML weather prediction models (GraphCast,
PanguWeather, and FourCastNet) and ECMWF's high-resolution forecast system
(HRES) in three case studies: the 2021 Pacific Northwest heatwave, the 2023
South Asian humid heatwave, and the North American winter storm in 2021. We
find that ML weather prediction models locally achieve similar accuracy to HRES
on the record-shattering Pacific Northwest heatwave but underperform when
aggregated over space and time. However, they forecast the compound winter
storm substantially better. We also highlight structural differences in how the
errors of HRES and the ML models build up to that event. The ML forecasts lack
important variables for a detailed assessment of the health risks of the 2023
humid heatwave. Using a possible substitute variable, prediction errors show
spatial patterns with the highest danger levels over Bangladesh being
underestimated by the ML models. Generally, case-study-driven, impact-centric
evaluation can complement existing research, increase public trust, and aid in
developing reliable ML weather prediction models.",2024-04-26,"Olivier C. Pasche, Jonathan Wider, Zhongwei Zhang, Jakob Zscheischler, Sebastian Engelke",http://arxiv.org/pdf/2404.17652v2,cs.LG
Hard ASH: Sparsity and the right optimizer make a continual learner,"In class incremental learning, neural networks typically suffer from
catastrophic forgetting. We show that an MLP featuring a sparse activation
function and an adaptive learning rate optimizer can compete with established
regularization techniques in the Split-MNIST task. We highlight the
effectiveness of the Adaptive SwisH (ASH) activation function in this context
and introduce a novel variant, Hard Adaptive SwisH (Hard ASH) to further
enhance the learning retention.",2024-04-26,Santtu Keskinen,http://arxiv.org/pdf/2404.17651v1,cs.LG
A Conditional Independence Test in the Presence of Discretization,"Testing conditional independence has many applications, such as in Bayesian
network learning and causal discovery. Different test methods have been
proposed. However, existing methods generally can not work when only
discretized observations are available. Specifically, consider $X_1$,
$\tilde{X}_2$ and $X_3$ are observed variables, where $\tilde{X}_2$ is a
discretization of latent variables $X_2$. Applying existing test methods to the
observations of $X_1$, $\tilde{X}_2$ and $X_3$ can lead to a false conclusion
about the underlying conditional independence of variables $X_1$, $X_2$ and
$X_3$. Motivated by this, we propose a conditional independence test
specifically designed to accommodate the presence of such discretization. To
achieve this, we design the bridge equations to recover the parameter
reflecting the statistical information of the underlying latent continuous
variables. An appropriate test statistic and its asymptotic distribution under
the null hypothesis of conditional independence have also been derived. Both
theoretical results and empirical validation have been provided, demonstrating
the effectiveness of our test methods.",2024-04-26,"Boyang Sun, Yu Yao, Guang-Yuan Hao, Yumou Qiu, Kun Zhang",http://arxiv.org/pdf/2404.17644v6,cs.LG
Text Quality-Based Pruning for Efficient Training of Language Models,"In recent times training Language Models (LMs) have relied on computationally
heavy training over massive datasets which makes this training process
extremely laborious. In this paper we propose a novel method for numerically
evaluating text quality in large unlabelled NLP datasets in a model agnostic
manner to assign the text instances a ""quality score"".
  By proposing the text quality metric, the paper establishes a framework to
identify and eliminate low-quality text instances, leading to improved training
efficiency for LM models. Experimental results over multiple models and
datasets demonstrate the efficacy of this approach, showcasing substantial
gains in training effectiveness and highlighting the potential for
resource-efficient LM training.
  For example, we observe an absolute accuracy improvement of 0.9% averaged
over 14 downstream evaluation tasks for multiple LM models while using 40%
lesser data and training 42% faster when training on the OpenWebText dataset
and 0.8% average absolute accuracy improvement while using 20% lesser data and
training 21% faster on the Wikipedia dataset.",2024-04-26,"Vasu Sharma, Karthik Padthe, Newsha Ardalani, Kushal Tirumala, Russell Howes, Hu Xu, Po-Yao Huang, Shang-Wen Li, Armen Aghajanyan, Gargi Ghosh, Luke Zettlemoyer",http://arxiv.org/pdf/2405.01582v3,cs.LG
An exactly solvable model for emergence and scaling laws in the multitask sparse parity problem,"Deep learning models can exhibit what appears to be a sudden ability to solve
a new problem as training time, training data, or model size increases, a
phenomenon known as emergence. In this paper, we present a framework where each
new ability (a skill) is represented as a basis function. We solve a simple
multi-linear model in this skill-basis, finding analytic expressions for the
emergence of new skills, as well as for scaling laws of the loss with training
time, data size, model size, and optimal compute. We compare our detailed
calculations to direct simulations of a two-layer neural network trained on
multitask sparse parity, where the tasks in the dataset are distributed
according to a power-law. Our simple model captures, using a single fit
parameter, the sigmoidal emergence of multiple new skills as training time,
data size or model size increases in the neural network.",2024-04-26,"Yoonsoo Nam, Nayara Fonseca, Seok Hyeong Lee, Chris Mingard, Ard A. Louis",http://arxiv.org/pdf/2404.17563v3,cs.LG
Federated Transfer Component Analysis Towards Effective VNF Profiling,"The increasing concerns of knowledge transfer and data privacy challenge the
traditional gather-and-analyse paradigm in networks. Specifically, the
intelligent orchestration of Virtual Network Functions (VNFs) requires
understanding and profiling the resource consumption. However, profiling all
kinds of VNFs is time-consuming. It is important to consider transferring the
well-profiled VNF knowledge to other lack-profiled VNF types while keeping data
private. To this end, this paper proposes a Federated Transfer Component
Analysis (FTCA) method between the source and target VNFs. FTCA first trains
Generative Adversarial Networks (GANs) based on the source VNF profiling data,
and the trained GANs model is sent to the target VNF domain. Then, FTCA
realizes federated domain adaptation by using the generated source VNF data and
less target VNF profiling data, while keeping the raw data locally. Experiments
show that the proposed FTCA can effectively predict the required resources for
the target VNF. Specifically, the RMSE index of the regression model decreases
by 38.5% and the R-squared metric advances up to 68.6%.",2024-04-26,"Xunzheng Zhang, Shadi Moazzeni, Juan Marcelo Parra-Ullauri, Reza Nejabati, Dimitra Simeonidou",http://arxiv.org/pdf/2404.17553v3,cs.LG
A Semi-Automatic Approach to Create Large Gender- and Age-Balanced Speaker Corpora: Usefulness of Speaker Diarization & Identification,"This paper presents a semi-automatic approach to create a diachronic corpus
of voices balanced for speaker's age, gender, and recording period, according
to 32 categories (2 genders, 4 age ranges and 4 recording periods). Corpora
were selected at French National Institute of Audiovisual (INA) to obtain at
least 30 speakers per category (a total of 960 speakers; only 874 have be found
yet). For each speaker, speech excerpts were extracted from audiovisual
documents using an automatic pipeline consisting of speech detection,
background music and overlapped speech removal and speaker diarization, used to
present clean speaker segments to human annotators identifying target speakers.
This pipeline proved highly effective, cutting down manual processing by a
factor of ten. Evaluation of the quality of the automatic processing and of the
final output is provided. It shows the automatic processing compare to
up-to-date process, and that the output provides high quality speech for most
of the selected excerpts. This method shows promise for creating large corpora
of known target speakers.",2024-04-26,"Rémi Uro, David Doukhan, Albert Rilliard, Laëtitia Larcher, Anissa-Claire Adgharouamane, Marie Tahon, Antoine Laurent",http://arxiv.org/pdf/2404.17552v1,cs.LG
Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo,"Numerous capability and safety techniques of Large Language Models (LLMs),
including RLHF, automated red-teaming, prompt engineering, and infilling, can
be cast as sampling from an unnormalized target distribution defined by a given
reward or potential function over the full sequence. In this work, we leverage
the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic
inference problems. In particular, we use learned twist functions to estimate
the expected future value of the potential at each timestep, which enables us
to focus inference-time computation on promising partial sequences. We propose
a novel contrastive method for learning the twist functions, and establish
connections with the rich literature of soft reinforcement learning. As a
complementary application of our twisted SMC framework, we present methods for
evaluating the accuracy of language model inference techniques using novel
bidirectional SMC bounds on the log partition function. These bounds can be
used to estimate the KL divergence between the inference and target
distributions in both directions. We apply our inference evaluation techniques
to show that twisted SMC is effective for sampling undesirable outputs from a
pretrained model (a useful component of harmlessness training and automated
red-teaming), generating reviews with varied sentiment, and performing
infilling tasks.",2024-04-26,"Stephen Zhao, Rob Brekelmans, Alireza Makhzani, Roger Grosse",http://arxiv.org/pdf/2404.17546v1,cs.LG
Using Neural Implicit Flow To Represent Latent Dynamics Of Canonical Systems,"The recently introduced class of architectures known as Neural Operators has
emerged as highly versatile tools applicable to a wide range of tasks in the
field of Scientific Machine Learning (SciML), including data representation and
forecasting. In this study, we investigate the capabilities of Neural Implicit
Flow (NIF), a recently developed mesh-agnostic neural operator, for
representing the latent dynamics of canonical systems such as the
Kuramoto-Sivashinsky (KS), forced Korteweg-de Vries (fKdV), and Sine-Gordon
(SG) equations, as well as for extracting dynamically relevant information from
them. Finally we assess the applicability of NIF as a dimensionality reduction
algorithm and conduct a comparative analysis with another widely recognized
family of neural operators, known as Deep Operator Networks (DeepONets).",2024-04-26,"Imran Nasim, Joaõ Lucas de Sousa Almeida",http://arxiv.org/pdf/2404.17535v1,cs.LG
Large Language Model Agent as a Mechanical Designer,"Conventional mechanical design follows an iterative process in which initial
concepts are refined through cycles of expert assessment and resource-intensive
Finite Element Method (FEM) analysis to meet performance goals. While machine
learning models have been developed to assist in parts of this process, they
typically require large datasets, extensive training, and are often tailored to
specific tasks, limiting their generalizability. To address these limitations,
we propose a framework that leverages a pretrained Large Language Model (LLM)
in conjunction with an FEM module to autonomously generate, evaluate, and
refine structural designs based on performance specifications and numerical
feedback. The LLM operates without domain-specific fine-tuning, using general
reasoning to propose design candidates, interpret FEM-derived performance
metrics, and apply structurally sound modifications. Using 2D truss structures
as a testbed, we show that the LLM can effectively navigate highly discrete and
multi-faceted design spaces, balance competing objectives, and identify
convergence when further optimization yields diminishing returns. Compared to
Non-dominated Sorting Genetic Algorithm II (NSGA-II), our method achieves
faster convergence and fewer FEM evaluations. Experiments with varying
temperature settings (0.5, 1.0, 1.2) and model sizes (GPT-4.1 and GPT-4.1-mini)
indicate that smaller models yield higher constraint satisfaction with fewer
steps, while lower temperatures enhance design consistency. These results
establish LLMs as a promising new class of reasoning-based, natural
language-driven optimizers for autonomous design and iterative structural
refinement.",2024-04-26,"Yayati Jadhav, Amir Barati Farimani",http://arxiv.org/pdf/2404.17525v3,cs.LG
Using Pre-training and Interaction Modeling for ancestry-specific disease prediction in UK Biobank,"Recent genome-wide association studies (GWAS) have uncovered the genetic
basis of complex traits, but show an under-representation of non-European
descent individuals, underscoring a critical gap in genetic research. Here, we
assess whether we can improve disease prediction across diverse ancestries
using multiomic data. We evaluate the performance of Group-LASSO
INTERaction-NET (glinternet) and pretrained lasso in disease prediction
focusing on diverse ancestries in the UK Biobank. Models were trained on data
from White British and other ancestries and validated across a cohort of over
96,000 individuals for 8 diseases. Out of 96 models trained, we report 16 with
statistically significant incremental predictive performance in terms of
ROC-AUC scores (p-value < 0.05), found for diabetes, arthritis, gall stones,
cystitis, asthma and osteoarthritis. For the interaction and pretrained models
that outperformed the baseline, the PRS score was the primary driver behind
prediction. Our findings indicate that both interaction terms and pre-training
can enhance prediction accuracy but for a limited set of diseases and moderate
improvements in accuracy",2024-04-26,"Thomas Le Menestrel, Erin Craig, Robert Tibshirani, Trevor Hastie, Manuel Rivas",http://arxiv.org/pdf/2404.17626v2,cs.LG
Bridging the Fairness Divide: Achieving Group and Individual Fairness in Graph Neural Networks,"Graph neural networks (GNNs) have emerged as a powerful tool for analyzing
and learning from complex data structured as graphs, demonstrating remarkable
effectiveness in various applications, such as social network analysis,
recommendation systems, and drug discovery. However, despite their impressive
performance, the fairness problem has increasingly gained attention as a
crucial aspect to consider. Existing research in graph learning focuses on
either group fairness or individual fairness. However, since each concept
provides unique insights into fairness from distinct perspectives, integrating
them into a fair graph neural network system is crucial. To the best of our
knowledge, no study has yet to comprehensively tackle both individual and group
fairness simultaneously. In this paper, we propose a new concept of individual
fairness within groups and a novel framework named Fairness for Group and
Individual (FairGI), which considers both group fairness and individual
fairness within groups in the context of graph learning. FairGI employs the
similarity matrix of individuals to achieve individual fairness within groups,
while leveraging adversarial learning to address group fairness in terms of
both Equal Opportunity and Statistical Parity. The experimental results
demonstrate that our approach not only outperforms other state-of-the-art
models in terms of group fairness and individual fairness within groups, but
also exhibits excellent performance in population-level individual fairness,
while maintaining comparable prediction accuracy.",2024-04-26,"Duna Zhan, Dongliang Guo, Pengsheng Ji, Sheng Li",http://arxiv.org/pdf/2404.17511v1,cs.LG
Constrained Neural Networks for Interpretable Heuristic Creation to Optimise Computer Algebra Systems,"We present a new methodology for utilising machine learning technology in
symbolic computation research. We explain how a well known human-designed
heuristic to make the choice of variable ordering in cylindrical algebraic
decomposition may be represented as a constrained neural network. This allows
us to then use machine learning methods to further optimise the heuristic,
leading to new networks of similar size, representing new heuristics of similar
complexity as the original human-designed one. We present this as a form of
ante-hoc explainability for use in computer algebra development.",2024-04-26,"Dorian Florescu, Matthew England",http://arxiv.org/pdf/2404.17508v1,cs.LG
Q-learning with temporal memory to navigate turbulence,"We consider the problem of olfactory searches in a turbulent environment. We
focus on agents that respond solely to odor stimuli, with no access to spatial
perception nor prior information about the odor. We ask whether navigation to a
target can be learned robustly within a sequential decision making framework.
We develop a reinforcement learning algorithm using a small set of
interpretable olfactory states and train it with realistic turbulent odor cues.
By introducing a temporal memory, we demonstrate that two salient features of
odor traces, discretized in few olfactory states, are sufficient to learn
navigation in a realistic odor plume. Performance is dictated by the sparse
nature of turbulent odors. An optimal memory exists which ignores blanks within
the plume and activates a recovery strategy outside the plume. We obtain the
best performance by letting agents learn their recovery strategy and show that
it is mostly casting cross wind, similar to behavior observed in flying
insects. The optimal strategy is robust to substantial changes in the odor
plumes, suggesting minor parameter tuning may be sufficient to adapt to
different environments.",2024-04-26,"Marco Rando, Martin James, Alessandro Verri, Lorenzo Rosasco, Agnese Seminara",http://arxiv.org/pdf/2404.17495v2,cs.LG
Causally Abstracted Multi-armed Bandits,"Multi-armed bandits (MAB) and causal MABs (CMAB) are established frameworks
for decision-making problems. The majority of prior work typically studies and
solves individual MAB and CMAB in isolation for a given problem and associated
data. However, decision-makers are often faced with multiple related problems
and multi-scale observations where joint formulations are needed in order to
efficiently exploit the problem structures and data dependencies. Transfer
learning for CMABs addresses the situation where models are defined on
identical variables, although causal connections may differ. In this work, we
extend transfer learning to setups involving CMABs defined on potentially
different variables, with varying degrees of granularity, and related via an
abstraction map. Formally, we introduce the problem of causally abstracted MABs
(CAMABs) by relying on the theory of causal abstraction in order to express a
rigorous abstraction map. We propose algorithms to learn in a CAMAB, and study
their regret. We illustrate the limitations and the strengths of our algorithms
on a real-world scenario related to online advertising.",2024-04-26,"Fabio Massimo Zennaro, Nicholas Bishop, Joel Dyer, Yorgos Felekis, Anisoara Calinescu, Michael Wooldridge, Theodoros Damoulas",http://arxiv.org/pdf/2404.17493v2,cs.LG
Baseline Drift Tolerant Signal Encoding for ECG Classification with Deep Learning,"Common artefacts such as baseline drift, rescaling, and noise critically
limit the performance of machine learningbased automated ECG analysis and
interpretation. This study proposes Derived Peak (DP) encoding, a
non-parametric method that generates signed spikes corresponding to zero
crossings of the signals first and second-order time derivatives. Notably, DP
encoding is invariant to shift and scaling artefacts, and its implementation is
further simplified by the absence of userdefined parameters. DP encoding was
used to encode the 12-lead ECG data from the PTB-XL dataset (n=18,869
participants) and was fed to 1D-ResNet-18 models trained to identify myocardial
infarction, conductive deficits and ST-segment abnormalities. Robustness to
artefacts was assessed by corrupting ECG data with sinusoidal baseline drift,
shift, rescaling and noise, before encoding. The addition of these artefacts
resulted in a significant drop in accuracy for seven other methods from prior
art, while DP encoding maintained a baseline AUC of 0.88 under drift, shift and
rescaling. DP achieved superior performance to unencoded inputs in the presence
of shift (AUC under 1mV shift: 0.91 vs 0.62), and rescaling artefacts (AUC 0.91
vs 0.79). Thus, DP encoding is a simple method by which robustness to common
ECG artefacts may be improved for automated ECG analysis and interpretation.",2024-04-26,"Robert O Shea, Prabodh Katti, Bipin Rajendran",http://arxiv.org/pdf/2405.00724v1,cs.LG
Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation,"Contrastive learning is a model pre-training technique by first creating
similar views of the original data, and then encouraging the data and its
corresponding views to be close in the embedding space. Contrastive learning
has witnessed success in image and natural language data, thanks to the
domain-specific augmentation techniques that are both intuitive and effective.
Nonetheless, in tabular domain, the predominant augmentation technique for
creating views is through corrupting tabular entries via swapping values, which
is not as sound or effective. We propose a simple yet powerful improvement to
this augmentation technique: corrupting tabular data conditioned on class
identity. Specifically, when corrupting a specific tabular entry from an anchor
row, instead of randomly sampling a value in the same feature column from the
entire table uniformly, we only sample from rows that are identified to be
within the same class as the anchor row. We assume the semi-supervised learning
setting, and adopt the pseudo labeling technique for obtaining class identities
over all table rows. We also explore the novel idea of selecting features to be
corrupted based on feature correlation structures. Extensive experiments show
that the proposed approach consistently outperforms the conventional corruption
method for tabular data classification tasks. Our code is available at
https://github.com/willtop/Tabular-Class-Conditioned-SSL.",2024-04-26,"Wei Cui, Rasa Hosseinzadeh, Junwei Ma, Tongzi Wu, Yi Sui, Keyvan Golestan",http://arxiv.org/pdf/2404.17489v2,cs.LG
Low Cost Machine Vision for Insect Classification,"Preserving the number and diversity of insects is one of our society's most
important goals in the area of environmental sustainability. A prerequisite for
this is a systematic and up-scaled monitoring in order to detect correlations
and identify countermeasures. Therefore, automatized monitoring using live
traps is important, but so far there is no system that provides image data of
sufficient detailed information for entomological classification.
  In this work, we present an imaging method as part of a multisensor system
developed as a low-cost, scalable, open-source system that is adaptable to
classical trap types. The image quality meets the requirements needed for
classification in the taxonomic tree. Therefore, illumination and resolution
have been optimized and motion artefacts have been suppressed. The system is
evaluated exemplarily on a dataset consisting of 16 insect species of the same
as well as different genus, family and order. We demonstrate that standard
CNN-architectures like ResNet50 (pretrained on iNaturalist data) or MobileNet
perform very well for the prediction task after re-training. Smaller custom
made CNNs also lead to promising results. Classification accuracy of $>96\%$
has been achieved. Moreover, it was proved that image cropping of insects is
necessary for classification of species with high inter-class similarity.",2024-04-26,"Danja Brandt, Martin Tschaikner, Teodor Chiaburu, Henning Schmidt, Ilona Schrimpf, Alexandra Stadel, Ingeborg E. Beckers, Frank Haußer",http://arxiv.org/pdf/2404.17488v1,cs.LG
Conformal Prediction with Learned Features,"In this paper, we focus on the problem of conformal prediction with
conditional guarantees. Prior work has shown that it is impossible to construct
nontrivial prediction sets with full conditional coverage guarantees. A wealth
of research has considered relaxations of full conditional guarantees, relying
on some predefined uncertainty structures. Departing from this line of
thinking, we propose Partition Learning Conformal Prediction (PLCP), a
framework to improve conditional validity of prediction sets through learning
uncertainty-guided features from the calibration data. We implement PLCP
efficiently with alternating gradient descent, utilizing off-the-shelf machine
learning models. We further analyze PLCP theoretically and provide conditional
guarantees for infinite and finite sample sizes. Finally, our experimental
results over four real-world and synthetic datasets show the superior
performance of PLCP compared to state-of-the-art methods in terms of coverage
and length in both classification and regression scenarios.",2024-04-26,"Shayan Kiyani, George Pappas, Hamed Hassani",http://arxiv.org/pdf/2404.17487v1,cs.LG
Differentiable Pareto-Smoothed Weighting for High-Dimensional Heterogeneous Treatment Effect Estimation,"There is a growing interest in estimating heterogeneous treatment effects
across individuals using their high-dimensional feature attributes. Achieving
high performance in such high-dimensional heterogeneous treatment effect
estimation is challenging because in this setup, it is usual that some features
induce sample selection bias while others do not but are predictive of
potential outcomes. To avoid losing such predictive feature information,
existing methods learn separate feature representations using inverse
probability weighting (IPW). However, due to their numerically unstable IPW
weights, these methods suffer from estimation bias under a finite sample setup.
To develop a numerically robust estimator by weighted representation learning,
we propose a differentiable Pareto-smoothed weighting framework that replaces
extreme weight values in an end-to-end fashion. Our experimental results show
that by effectively correcting the weight values, our proposed method
outperforms the existing ones, including traditional weighting schemes. Our
code is available at https://github.com/ychika/DPSW.",2024-04-26,"Yoichi Chikahara, Kansei Ushiyama",http://arxiv.org/pdf/2404.17483v5,cs.LG
"Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land","Neural networks surround us, in the form of large language models, speech
transcription systems, molecular discovery algorithms, robotics, and much more.
Stripped of anything else, neural networks are compositions of differentiable
primitives, and studying them means learning how to program and how to interact
with these models, a particular example of what is called differentiable
programming.
  This primer is an introduction to this fascinating field imagined for
someone, like Alice, who has just ventured into this strange differentiable
wonderland. I overview the basics of optimizing a function via automatic
differentiation, and a selection of the most common designs for handling
sequences, graphs, texts, and audios. The focus is on a intuitive,
self-contained introduction to the most important design techniques, including
convolutional, attentional, and recurrent blocks, hoping to bridge the gap
between theory and code (PyTorch and JAX) and leaving the reader capable of
understanding some of the most advanced models out there, such as large
language models (LLMs) and multimodal architectures.",2024-04-26,Simone Scardapane,http://arxiv.org/pdf/2404.17625v2,cs.LG
FTL: Transfer Learning Nonlinear Plasma Dynamic Transitions in Low Dimensional Embeddings via Deep Neural Networks,"Deep learning algorithms provide a new paradigm to study high-dimensional
dynamical behaviors, such as those in fusion plasma systems. Development of
novel model reduction methods, coupled with detection of abnormal modes with
plasma physics, opens a unique opportunity for building efficient models to
identify plasma instabilities for real-time control. Our Fusion Transfer
Learning (FTL) model demonstrates success in reconstructing nonlinear kink mode
structures by learning from a limited amount of nonlinear simulation data. The
knowledge transfer process leverages a pre-trained neural encoder-decoder
network, initially trained on linear simulations, to effectively capture
nonlinear dynamics. The low-dimensional embeddings extract the coherent
structures of interest, while preserving the inherent dynamics of the complex
system. Experimental results highlight FTL's capacity to capture transitional
behaviors and dynamical features in plasma dynamics -- a task often challenging
for conventional methods. The model developed in this study is generalizable
and can be extended broadly through transfer learning to address various
magnetohydrodynamics (MHD) modes.",2024-04-26,"Zhe Bai, Xishuo Wei, William Tang, Leonid Oliker, Zhihong Lin, Samuel Williams",http://arxiv.org/pdf/2404.17466v1,cs.LG
Fast Abstracts and Student Forum Proceedings -- EDCC 2024 -- 19th European Dependable Computing Conference,"The goal of the Fast Abstracts track is to bring together researchers and
practitioners working on dependable computing to discuss work in progress or
opinion pieces. Contributions are welcome from academia and industry. Fast
Abstracts aim to serve as a rapid and flexible mechanism to: (i) Report on
current work that may or may not be complete; (ii) Introduce new ideas to the
community; (iii) State positions on controversial issues or open problems; (iv)
Share lessons learnt from real-word dependability engineering; and (v) Debunk
or question results from other papers based on contra-indications. The Student
Forum aims at creating a vibrant and friendly environment where students can
present and discuss their work, and exchange ideas and experiences with other
students, researchers and industry. One of the key goals of the Forum is to
provide students with feedback on their preliminary results that might help
with their future research directions.",2024-04-26,"Simona Bernardi, Tommaso Zoppi",http://arxiv.org/pdf/2404.17465v4,cs.LG
Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics,"In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.",2024-04-26,"Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile",http://arxiv.org/pdf/2405.02334v2,cs.LG
Multi-layer random features and the approximation power of neural networks,"A neural architecture with randomly initialized weights, in the infinite
width limit, is equivalent to a Gaussian Random Field whose covariance function
is the so-called Neural Network Gaussian Process kernel (NNGP). We prove that a
reproducing kernel Hilbert space (RKHS) defined by the NNGP contains only
functions that can be approximated by the architecture. To achieve a certain
approximation error the required number of neurons in each layer is defined by
the RKHS norm of the target function. Moreover, the approximation can be
constructed from a supervised dataset by a random multi-layer representation of
an input vector, together with training of the last layer's weights.
  For a 2-layer NN and a domain equal to an $n-1$-dimensional sphere in
${\mathbb R}^n$, we compare the number of neurons required by Barron's theorem
and by the multi-layer features construction. We show that if eigenvalues of
the integral operator of the NNGP decay slower than $k^{-n-\frac{2}{3}}$ where
$k$ is an order of an eigenvalue, then our theorem guarantees a more succinct
neural network approximation than Barron's theorem. We also make some
computational experiments to verify our theoretical findings. Our experiments
show that realistic neural networks easily learn target functions even when
both theorems do not give any guarantees.",2024-04-26,Rustem Takhanov,http://arxiv.org/pdf/2404.17461v1,cs.LG
Language Interaction Network for Clinical Trial Approval Estimation,"Clinical trial outcome prediction seeks to estimate the likelihood that a
clinical trial will successfully reach its intended endpoint. This process
predominantly involves the development of machine learning models that utilize
a variety of data sources such as descriptions of the clinical trials,
characteristics of the drug molecules, and specific disease conditions being
targeted. Accurate predictions of trial outcomes are crucial for optimizing
trial planning and prioritizing investments in a drug portfolio. While previous
research has largely concentrated on small-molecule drugs, there is a growing
need to focus on biologics-a rapidly expanding category of therapeutic agents
that often lack the well-defined molecular properties associated with
traditional drugs. Additionally, applying conventional methods like graph
neural networks to biologics data proves challenging due to their complex
nature. To address these challenges, we introduce the Language Interaction
Network (LINT), a novel approach that predicts trial outcomes using only the
free-text descriptions of the trials. We have rigorously tested the
effectiveness of LINT across three phases of clinical trials, where it achieved
ROC-AUC scores of 0.770, 0.740, and 0.748 for phases I, II, and III,
respectively, specifically concerning trials involving biologic interventions.",2024-04-26,"Chufan Gao, Tianfan Fu, Jimeng Sun",http://arxiv.org/pdf/2405.06662v1,cs.LG
Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond,"Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.",2024-04-26,"Kaichen Xu, Yueyang Ding, Suyang Hou, Weiqiang Zhan, Nisang Chen, Jun Wang, Xiaobo Sun",http://arxiv.org/pdf/2404.17454v2,cs.LG
A Continuous Relaxation for Discrete Bayesian Optimization,"To optimize efficiently over discrete data and with only few available target
observations is a challenge in Bayesian optimization. We propose a continuous
relaxation of the objective function and show that inference and optimization
can be computationally tractable. We consider in particular the optimization
domain where very few observations and strict budgets exist; motivated by
optimizing protein sequences for expensive to evaluate bio-chemical properties.
The advantages of our approach are two-fold: the problem is treated in the
continuous setting, and available prior knowledge over sequences can be
incorporated directly. More specifically, we utilize available and learned
distributions over the problem domain for a weighting of the Hellinger distance
which yields a covariance function. We show that the resulting acquisition
function can be optimized with both continuous or discrete optimization
algorithms and empirically assess our method on two bio-chemical sequence
optimization tasks.",2024-04-26,"Richard Michael, Simon Bartels, Miguel González-Duque, Yevgen Zainchkovskyy, Jes Frellsen, Søren Hauberg, Wouter Boomsma",http://arxiv.org/pdf/2404.17452v1,cs.LG
Any-Quantile Probabilistic Forecasting of Short-Term Electricity Demand,"Power systems operate under uncertainty originating from multiple factors
that are impossible to account for deterministically. Distributional
forecasting is used to control and mitigate risks associated with this
uncertainty. Recent progress in deep learning has helped to significantly
improve the accuracy of point forecasts, while accurate distributional
forecasting still presents a significant challenge. In this paper, we propose a
novel general approach for distributional forecasting capable of predicting
arbitrary quantiles. We show that our general approach can be seamlessly
applied to two distinct neural architectures leading to the state-of-the-art
distributional forecasting results in the context of short-term electricity
demand forecasting task. We empirically validate our method on 35 hourly
electricity demand time-series for European countries. Our code is available
here: https://github.com/boreshkinai/any-quantile.",2024-04-26,"Slawek Smyl, Boris N. Oreshkin, Paweł Pełka, Grzegorz Dudek",http://arxiv.org/pdf/2404.17451v2,cs.LG
Uniform Generalization Bounds on Data-Dependent Hypothesis Sets via PAC-Bayesian Theory on Random Sets,"We propose data-dependent uniform generalization bounds by approaching the
problem from a PAC-Bayesian perspective. We first apply the PAC-Bayesian
framework on ""random sets"" in a rigorous way, where the training algorithm is
assumed to output a data-dependent hypothesis set after observing the training
data. This approach allows us to prove data-dependent bounds, which can be
applicable in numerous contexts. To highlight the power of our approach, we
consider two main applications. First, we propose a PAC-Bayesian formulation of
the recently developed fractal-dimension-based generalization bounds. The
derived results are shown to be tighter and they unify the existing results
around one simple proof technique. Second, we prove uniform bounds over the
trajectories of continuous Langevin dynamics and stochastic gradient Langevin
dynamics. These results provide novel information about the generalization
properties of noisy algorithms.",2024-04-26,"Benjamin Dupuis, Paul Viallard, George Deligiannidis, Umut Simsekli",http://arxiv.org/pdf/2404.17442v2,cs.LG
Attention-aware non-rigid image registration for accelerated MR imaging,"Accurate motion estimation at high acceleration factors enables rapid
motion-compensated reconstruction in Magnetic Resonance Imaging (MRI) without
compromising the diagnostic image quality. In this work, we introduce an
attention-aware deep learning-based framework that can perform non-rigid
pairwise registration for fully sampled and accelerated MRI. We extract local
visual representations to build similarity maps between the registered image
pairs at multiple resolution levels and additionally leverage long-range
contextual information using a transformer-based module to alleviate
ambiguities in the presence of artifacts caused by undersampling. We combine
local and global dependencies to perform simultaneous coarse and fine motion
estimation. The proposed method was evaluated on in-house acquired fully
sampled and accelerated data of 101 patients and 62 healthy subjects undergoing
cardiac and thoracic MRI. The impact of motion estimation accuracy on the
downstream task of motion-compensated reconstruction was analyzed. We
demonstrate that our model derives reliable and consistent motion fields across
different sampling trajectories (Cartesian and radial) and acceleration factors
of up to 16x for cardiac motion and 30x for respiratory motion and achieves
superior image quality in motion-compensated reconstruction qualitatively and
quantitatively compared to conventional and recent deep learning-based
approaches. The code is publicly available at
https://github.com/lab-midas/GMARAFT.",2024-04-26,"Aya Ghoul, Jiazhen Pan, Andreas Lingg, Jens Kübler, Patrick Krumm, Kerstin Hammernik, Daniel Rueckert, Sergios Gatidis, Thomas Küstner",http://arxiv.org/pdf/2404.17621v1,cs.LG
Neural Modes: Self-supervised Learning of Nonlinear Modal Subspaces,"We propose a self-supervised approach for learning physics-based subspaces
for real-time simulation. Existing learning-based methods construct subspaces
by approximating pre-defined simulation data in a purely geometric way.
However, this approach tends to produce high-energy configurations, leads to
entangled latent space dimensions, and generalizes poorly beyond the training
set. To overcome these limitations, we propose a self-supervised approach that
directly minimizes the system's mechanical energy during training. We show that
our method leads to learned subspaces that reflect physical equilibrium
constraints, resolve overfitting issues of previous methods, and offer
interpretable latent space parameters.",2024-04-26,"Jiahong Wang, Yinwei Du, Stelian Coros, Bernhard Thomaszewski",http://arxiv.org/pdf/2404.17620v1,cs.LG
Separation capacity of linear reservoirs with random connectivity matrix,"A natural hypothesis for the success of reservoir computing in generic tasks
is the ability of the untrained reservoir to map different input time series to
separable reservoir states - a property we term separation capacity. We provide
a rigorous mathematical framework to quantify this capacity for random linear
reservoirs, showing that it is fully characterised by the spectral properties
of the generalised matrix of moments of the random reservoir connectivity
matrix. Our analysis focuses on reservoirs with Gaussian connectivity matrices,
both symmetric and i.i.d., although the techniques extend naturally to broader
classes of random matrices. In the symmetric case, the generalised matrix of
moments is a Hankel matrix. Using classical estimates from random matrix
theory, we establish that separation capacity deteriorates over time and that,
for short inputs, optimal separation in large reservoirs is achieved when the
matrix entries are scaled with a factor $\rho_T/\sqrt{N}$, where $N$ is the
reservoir dimension and $\rho_T$ depends on the maximum input length. In the
i.i.d.\ case, we establish that optimal separation with large reservoirs is
consistently achieved when the entries of the reservoir matrix are scaled with
the exact factor $1/\sqrt{N}$, which aligns with common implementations of
reservoir computing. We further give upper bounds on the quality of separation
as a function of the length of the time series. We complement this analysis
with an investigation of the likelihood of this separation and its consistency
under different architectural choices.",2024-04-26,Youness Boutaib,http://arxiv.org/pdf/2404.17429v3,cs.LG
One-Shot Image Restoration,"Image restoration, or inverse problems in image processing, has long been an
extensively studied topic. In recent years supervised learning approaches have
become a popular strategy attempting to tackle this task. Unfortunately, most
supervised learning-based methods are highly demanding in terms of
computational resources and training data (sample complexity). In addition,
trained models are sensitive to domain changes, such as varying acquisition
systems, signal sampling rates, resolution and contrast. In this work, we try
to answer a fundamental question: Can supervised learning models generalize
well solely by learning from one image or even part of an image? If so, then
what is the minimal amount of patches required to achieve acceptable
generalization? To this end, we focus on an efficient patch-based learning
framework that requires a single image input-output pair for training.
Experimental results demonstrate the applicability, robustness and
computational efficiency of the proposed approach for supervised image
deblurring and super-resolution. Our results showcase significant improvement
of learning models' sample efficiency, generalization and time complexity, that
can hopefully be leveraged for future real-time applications, and applied to
other signals and modalities.",2024-04-26,Deborah Pereg,http://arxiv.org/pdf/2404.17426v2,cs.LG
Mining patterns in syntax trees to automate code reviews of student solutions for programming exercises,"In programming education, providing manual feedback is essential but
labour-intensive, posing challenges in consistency and timeliness. We introduce
ECHO, a machine learning method to automate the reuse of feedback in
educational code reviews by analysing patterns in abstract syntax trees. This
study investigates two primary questions: whether ECHO can predict feedback
annotations to specific lines of student code based on previously added
annotations by human reviewers (RQ1), and whether its training and prediction
speeds are suitable for using ECHO for real-time feedback during live code
reviews by human reviewers (RQ2). Our results, based on annotations from both
automated linting tools and human reviewers, show that ECHO can accurately and
quickly predict appropriate feedback annotations. Its efficiency in processing
and its flexibility in adapting to feedback patterns can significantly reduce
the time and effort required for manual feedback provisioning in educational
settings.",2024-04-26,"Charlotte Van Petegem, Kasper Demeyere, Rien Maertens, Niko Strijbol, Bram De Wever, Bart Mesuere, Peter Dawyndt",http://arxiv.org/pdf/2405.01579v1,cs.LG
Evaluations of Machine Learning Privacy Defenses are Misleading,"Empirical defenses for machine learning privacy forgo the provable guarantees
of differential privacy in the hope of achieving higher utility while resisting
realistic adversaries. We identify severe pitfalls in existing empirical
privacy evaluations (based on membership inference attacks) that result in
misleading conclusions. In particular, we show that prior evaluations fail to
characterize the privacy leakage of the most vulnerable samples, use weak
attacks, and avoid comparisons with practical differential privacy baselines.
In 5 case studies of empirical privacy defenses, we find that prior evaluations
underestimate privacy leakage by an order of magnitude. Under our stronger
evaluation, none of the empirical defenses we study are competitive with a
properly tuned, high-utility DP-SGD baseline (with vacuous provable
guarantees).",2024-04-26,"Michael Aerni, Jie Zhang, Florian Tramèr",http://arxiv.org/pdf/2404.17399v2,cs.LG
Online Policy Learning and Inference by Matrix Completion,"Is it possible to make online decisions when personalized covariates are
unavailable? We take a collaborative-filtering approach for decision-making
based on collective preferences. By assuming low-dimensional latent features,
we formulate the covariate-free decision-making problem as a matrix completion
bandit. We propose a policy learning procedure that combines an
$\varepsilon$-greedy policy for decision-making with an online gradient descent
algorithm for bandit parameter estimation. Our novel two-phase design balances
policy learning accuracy and regret performance. For policy inference, we
develop an online debiasing method based on inverse propensity weighting and
establish its asymptotic normality. Our methods are applied to data from the
San Francisco parking pricing project, revealing intriguing discoveries and
outperforming the benchmark policy.",2024-04-26,"Congyuan Duan, Jingyang Li, Dong Xia",http://arxiv.org/pdf/2404.17398v2,cs.LG
EEG_RL-Net: Enhancing EEG MI Classification through Reinforcement Learning-Optimised Graph Neural Networks,"Brain-Computer Interfaces (BCIs) rely on accurately decoding
electroencephalography (EEG) motor imagery (MI) signals for effective device
control. Graph Neural Networks (GNNs) outperform Convolutional Neural Networks
(CNNs) in this regard, by leveraging the spatial relationships between EEG
electrodes through adjacency matrices. The EEG_GLT-Net framework, featuring the
state-of-the-art EEG_GLT adjacency matrix method, has notably enhanced EEG MI
signal classification, evidenced by an average accuracy of 83.95% across 20
subjects on the PhysioNet dataset. This significantly exceeds the 76.10%
accuracy rate achieved using the Pearson Correlation Coefficient (PCC) method
within the same framework.
  In this research, we advance the field by applying a Reinforcement Learning
(RL) approach to the classification of EEG MI signals. Our innovative method
empowers the RL agent, enabling not only the classification of EEG MI data
points with higher accuracy, but effective identification of EEG MI data points
that are less distinct. We present the EEG_RL-Net, an enhancement of the
EEG_GLT-Net framework, which incorporates the trained EEG GCN Block from
EEG_GLT-Net at an adjacency matrix density of 13.39% alongside the RL-centric
Dueling Deep Q Network (Dueling DQN) block. The EEG_RL-Net model showcases
exceptional classification performance, achieving an unprecedented average
accuracy of 96.40% across 20 subjects within 25 milliseconds. This model
illustrates the transformative effect of the RL in EEG MI time point
classification.",2024-04-26,"Htoo Wai Aung, Jiao Jiao Li, Yang An, Steven W. Su",http://arxiv.org/pdf/2405.00723v1,cs.LG
M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training,"Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.",2024-04-26,"Lakmal Meegahapola, Hamza Hassoune, Daniel Gatica-Perez",http://arxiv.org/pdf/2404.17391v1,cs.LG
Estimating the Robustness Radius for Randomized Smoothing with 100$\times$ Sample Efficiency,"Randomized smoothing (RS) has successfully been used to improve the
robustness of predictions for deep neural networks (DNNs) by adding random
noise to create multiple variations of an input, followed by deciding the
consensus. To understand if an RS-enabled DNN is effective in the sampled input
domains, it is mandatory to sample data points within the operational design
domain, acquire the point-wise certificate regarding robustness radius, and
compare it with pre-defined acceptance criteria. Consequently, ensuring that a
point-wise robustness certificate for any given data point is obtained
relatively cost-effectively is crucial. This work demonstrates that reducing
the number of samples by one or two orders of magnitude can still enable the
computation of a slightly smaller robustness radius (commonly ~20% radius
reduction) with the same confidence. We provide the mathematical foundation for
explaining the phenomenon while experimentally showing promising results on the
standard CIFAR-10 and ImageNet datasets.",2024-04-26,"Emmanouil Seferis, Stefanos Kollias, Chih-Hong Cheng",http://arxiv.org/pdf/2404.17371v1,cs.LG
Similarity Equivariant Graph Neural Networks for Homogenization of Metamaterials,"Soft, porous mechanical metamaterials exhibit pattern transformations that
may have important applications in soft robotics, sound reduction and
biomedicine. To design these innovative materials, it is important to be able
to simulate them accurately and quickly, in order to tune their mechanical
properties. Since conventional simulations using the finite element method
entail a high computational cost, in this article we aim to develop a machine
learning-based approach that scales favorably to serve as a surrogate model. To
ensure that the model is also able to handle various microstructures, including
those not encountered during training, we include the microstructure as part of
the network input. Therefore, we introduce a graph neural network that predicts
global quantities (energy, stress stiffness) as well as the pattern
transformations that occur (the kinematics). To make our model as accurate and
data-efficient as possible, various symmetries are incorporated into the model.
The starting point is an E(n)-equivariant graph neural network (which respects
translation, rotation and reflection) that has periodic boundary conditions
(i.e., it is in-/equivariant with respect to the choice of RVE), is scale
in-/equivariant, can simulate large deformations, and can predict scalars,
vectors as well as second and fourth order tensors (specifically energy, stress
and stiffness). The incorporation of scale equivariance makes the model
equivariant with respect to the similarities group, of which the Euclidean
group E(n) is a subgroup. We show that this network is more accurate and
data-efficient than graph neural networks with fewer symmetries. To create an
efficient graph representation of the finite element discretization, we use
only the internal geometrical hole boundaries from the finite element mesh to
achieve a better speed-up and scaling with the mesh size.",2024-04-26,"Fleur Hendriks, Vlado Menkovski, Martin Doškář, Marc G. D. Geers, Ondřej Rokoš",http://arxiv.org/pdf/2404.17365v3,cs.LG
Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier,"Minimizing an adversarial surrogate risk is a common technique for learning
robust classifiers. Prior work showed that convex surrogate losses are not
statistically consistent in the adversarial context -- or in other words, a
minimizing sequence of the adversarial surrogate risk will not necessarily
minimize the adversarial classification error. We connect the consistency of
adversarial surrogate losses to properties of minimizers to the adversarial
classification risk, known as adversarial Bayes classifiers. Specifically,
under reasonable distributional assumptions, a convex surrogate loss is
statistically consistent for adversarial learning iff the adversarial Bayes
classifier satisfies a certain notion of uniqueness.",2024-04-26,Natalie S. Frank,http://arxiv.org/pdf/2404.17358v3,cs.LG
On the Road to Clarity: Exploring Explainable AI for World Models in a Driver Assistance System,"In Autonomous Driving (AD) transparency and safety are paramount, as mistakes
are costly. However, neural networks used in AD systems are generally
considered black boxes. As a countermeasure, we have methods of explainable AI
(XAI), such as feature relevance estimation and dimensionality reduction.
Coarse graining techniques can also help reduce dimensionality and find
interpretable global patterns. A specific coarse graining method is
Renormalization Groups from statistical physics. It has previously been applied
to Restricted Boltzmann Machines (RBMs) to interpret unsupervised learning. We
refine this technique by building a transparent backbone model for
convolutional variational autoencoders (VAE) that allows mapping latent values
to input features and has performance comparable to trained black box VAEs.
Moreover, we propose a custom feature map visualization technique to analyze
the internal convolutional layers in the VAE to explain internal causes of poor
reconstruction that may lead to dangerous traffic scenarios in AD applications.
In a second key contribution, we propose explanation and evaluation techniques
for the internal dynamics and feature relevance of prediction networks. We test
a long short-term memory (LSTM) network in the computer vision domain to
evaluate the predictability and in future applications potentially safety of
prediction models. We showcase our methods by analyzing a VAE-LSTM world model
that predicts pedestrian perception in an urban traffic situation.",2024-04-26,"Mohamed Roshdi, Julian Petzold, Mostafa Wahby, Hussein Ebrahim, Mladen Berekovic, Heiko Hamann",http://arxiv.org/pdf/2404.17350v1,cs.LG
"Fast Evaluation of Additive Kernels: Feature Arrangement, Fourier Methods, and Kernel Derivatives","One of the main computational bottlenecks when working with kernel based
learning is dealing with the large and typically dense kernel matrix.
Techniques dealing with fast approximations of the matrix vector product for
these kernel matrices typically deteriorate in their performance if the feature
vectors reside in higher-dimensional feature spaces. We here present a
technique based on the non-equispaced fast Fourier transform (NFFT) with
rigorous error analysis. We show that this approach is also well suited to
allow the approximation of the matrix that arises when the kernel is
differentiated with respect to the kernel hyperparameters; a problem often
found in the training phase of methods such as Gaussian processes. We also
provide an error analysis for this case. We illustrate the performance of the
additive kernel scheme with fast matrix vector products on a number of data
sets. Our code is available at https://github.com/wagnertheresa/NFFTAddKer",2024-04-26,"Theresa Wagner, Franziska Nestler, Martin Stoll",http://arxiv.org/pdf/2404.17344v1,cs.LG
Beyond Traditional Threats: A Persistent Backdoor Attack on Federated Learning,"Backdoors on federated learning will be diluted by subsequent benign updates.
This is reflected in the significant reduction of attack success rate as
iterations increase, ultimately failing. We use a new metric to quantify the
degree of this weakened backdoor effect, called attack persistence. Given that
research to improve this performance has not been widely noted,we propose a
Full Combination Backdoor Attack (FCBA) method. It aggregates more combined
trigger information for a more complete backdoor pattern in the global model.
Trained backdoored global model is more resilient to benign updates, leading to
a higher attack success rate on the test set. We test on three datasets and
evaluate with two models across various settings. FCBA's persistence
outperforms SOTA federated learning backdoor attacks. On GTSRB, postattack 120
rounds, our attack success rate rose over 50% from baseline. The core code of
our method is available at https://github.com/PhD-TaoLiu/FCBA.",2024-04-26,"Tao Liu, Yuhang Zhang, Zhu Feng, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang",http://arxiv.org/pdf/2404.17617v1,cs.LG
A Deep Dive into Effects of Structural Bias on CMA-ES Performance along Affine Trajectories,"To guide the design of better iterative optimisation heuristics, it is
imperative to understand how inherent structural biases within algorithm
components affect the performance on a wide variety of search landscapes. This
study explores the impact of structural bias in the modular Covariance Matrix
Adaptation Evolution Strategy (modCMA), focusing on the roles of various
modulars within the algorithm. Through an extensive investigation involving
435,456 configurations of modCMA, we identified key modules that significantly
influence structural bias of various classes. Our analysis utilized the
Deep-BIAS toolbox for structural bias detection and classification,
complemented by SHAP analysis for quantifying module contributions. The
performance of these configurations was tested on a sequence of
affine-recombined functions, maintaining fixed optimum locations while
gradually varying the landscape features. Our results demonstrate an interplay
between module-induced structural bias and algorithm performance across
different landscape characteristics.",2024-04-26,"Niki van Stein, Sarah L. Thomson, Anna V. Kononova",http://arxiv.org/pdf/2404.17323v1,cs.LG
Lazy Data Practices Harm Fairness Research,"Data practices shape research and practice on fairness in machine learning
(fair ML). Critical data studies offer important reflections and critiques for
the responsible advancement of the field by highlighting shortcomings and
proposing recommendations for improvement. In this work, we present a
comprehensive analysis of fair ML datasets, demonstrating how unreflective yet
common practices hinder the reach and reliability of algorithmic fairness
findings. We systematically study protected information encoded in tabular
datasets and their usage in 280 experiments across 142 publications.
  Our analyses identify three main areas of concern: (1) a \textbf{lack of
representation for certain protected attributes} in both data and evaluations;
(2) the widespread \textbf{exclusion of minorities} during data preprocessing;
and (3) \textbf{opaque data processing} threatening the generalization of
fairness research. By conducting exemplary analyses on the utilization of
prominent datasets, we demonstrate how unreflective data decisions
disproportionately affect minority groups, fairness metrics, and resultant
model comparisons. Additionally, we identify supplementary factors such as
limitations in publicly available data, privacy considerations, and a general
lack of awareness, which exacerbate these challenges. To address these issues,
we propose a set of recommendations for data usage in fairness research
centered on transparency and responsible inclusion. This study underscores the
need for a critical reevaluation of data practices in fair ML and offers
directions to improve both the sourcing and usage of datasets.",2024-04-26,"Jan Simson, Alessandro Fabris, Christoph Kern",http://arxiv.org/pdf/2404.17293v2,cs.LG
Machine Learning based prediction of Vanadium Redox Flow Battery temperature rise under different charge-discharge conditions,"Accurate prediction of battery temperature rise is very essential for
designing an efficient thermal management scheme. In this paper, machine
learning (ML) based prediction of Vanadium Redox Flow Battery (VRFB) thermal
behavior during charge-discharge operation has been demonstrated for the first
time. Considering different currents with a specified electrolyte flow rate,
the temperature of a kW scale VRFB system is studied through experiments. Three
different ML algorithms; Linear Regression (LR), Support Vector Regression
(SVR) and Extreme Gradient Boost (XGBoost) have been used for the prediction
work. The training and validation of ML algorithms have been done by the
practical dataset of a 1kW 6kWh VRFB storage under 40A, 45A, 50A and 60A
charge-discharge currents and 10 L min-1 of flow rate. A comparative analysis
among the ML algorithms is done in terms of performance metrics such as
correlation coefficient (R2), mean absolute error (MAE) and root mean square
error (RMSE). It is observed that XGBoost shows the highest accuracy in
prediction of around 99%. The ML based prediction results obtained in this work
can be very useful for controlling the VRFB temperature rise during operation
and act as indicator for further development of an optimized thermal management
system.",2024-04-26,"Anirudh Narayan D, Akshat Johar, Divye Kalra, Bhavya Ardeshna, Ankur Bhattacharjee",http://arxiv.org/pdf/2404.17284v1,cs.LG
Efficient Deterministic Renewable Energy Forecasting Guided by Multiple-Location Weather Data,"Electricity generated from renewable energy sources has been established as
an efficient remedy for both energy shortages and the environmental pollution
stemming from conventional energy production methods. Solar and wind power are
two of the most dominant renewable energy sources. The accurate forecasting of
the energy generation of those sources facilitates their integration into
electric grids, by minimizing the negative impact of uncertainty regarding
their management and operation. This paper proposes a novel methodology for
deterministic wind and solar energy generation forecasting for multiple
generation sites, utilizing multi-location weather forecasts. The method
employs a U-shaped Temporal Convolutional Auto-Encoder (UTCAE) architecture for
temporal processing of weather-related and energy-related time-series across
each site. The Multi-sized Kernels convolutional Spatio-Temporal Attention
(MKST-Attention), inspired by the multi-head scaled-dot product attention
mechanism, is also proposed aiming to efficiently transfer temporal patterns
from weather data to energy data, without a priori knowledge of the locations
of the power stations and the locations of provided weather data. The conducted
experimental evaluation on a day-ahead solar and wind energy forecasting
scenario on five datasets demonstrated that the proposed method achieves top
results, outperforming all competitive time-series forecasting state-of-the-art
methods.",2024-04-26,"Charalampos Symeonidis, Nikos Nikolaidis",http://arxiv.org/pdf/2404.17276v2,cs.LG
Adversarial Reweighting with $α$-Power Maximization for Domain Adaptation,"The practical Domain Adaptation (DA) tasks, e.g., Partial DA (PDA), open-set
DA, universal DA, and test-time adaptation, have gained increasing attention in
the machine learning community. In this paper, we propose a novel approach,
dubbed Adversarial Reweighting with $\alpha$-Power Maximization (ARPM), for PDA
where the source domain contains private classes absent in target domain. In
ARPM, we propose a novel adversarial reweighting model that adversarially
learns to reweight source domain data to identify source-private class samples
by assigning smaller weights to them, for mitigating potential negative
transfer. Based on the adversarial reweighting, we train the transferable
recognition model on the reweighted source distribution to be able to classify
common class data. To reduce the prediction uncertainty of the recognition
model on the target domain for PDA, we present an $\alpha$-power maximization
mechanism in ARPM, which enriches the family of losses for reducing the
prediction uncertainty for PDA. Extensive experimental results on five PDA
benchmarks, i.e., Office-31, Office-Home, VisDA-2017, ImageNet-Caltech, and
DomainNet, show that our method is superior to recent PDA methods. Ablation
studies also confirm the effectiveness of components in our approach. To
theoretically analyze our method, we deduce an upper bound of target domain
expected error for PDA, which is approximately minimized in our approach. We
further extend ARPM to open-set DA, universal DA, and test time adaptation, and
verify the usefulness through experiments.",2024-04-26,"Xiang Gu, Xi Yu, Yan Yang, Jian Sun, Zongben Xu",http://arxiv.org/pdf/2404.17275v1,cs.LG
Enhancing Channel Estimation in Quantized Systems with a Generative Prior,"Channel estimation in quantized systems is challenging, particularly in
low-resolution systems. In this work, we propose to leverage a Gaussian mixture
model (GMM) as generative prior, capturing the channel distribution of the
propagation environment, to enhance a classical estimation technique based on
the expectation-maximization (EM) algorithm for one-bit quantization. Thereby,
a maximum a posteriori (MAP) estimate of the most responsible mixture component
is inferred for a quantized received signal, which is subsequently utilized in
the EM algorithm as side information. Numerical results demonstrate the
significant performance improvement of our proposed approach over both a
simplistic Gaussian prior and current state-of-the-art channel estimators.
Furthermore, the proposed estimation framework exhibits adaptability to higher
resolution systems and alternative generative priors.",2024-04-26,"Benedikt Fesl, Aziz Banna, Wolfgang Utschick",http://arxiv.org/pdf/2405.03542v1,cs.LG
DeepVARMA: A Hybrid Deep Learning and VARMA Model for Chemical Industry Index Forecasting,"Since the chemical industry index is one of the important indicators to
measure the development of the chemical industry, forecasting it is critical
for understanding the economic situation and trends of the industry. Taking the
multivariable nonstationary series-synthetic material index as the main
research object, this paper proposes a new prediction model: DeepVARMA, and its
variants Deep-VARMA-re and DeepVARMA-en, which combine LSTM and VARMAX models.
The new model firstly uses the deep learning model such as the LSTM remove the
trends of the target time series and also learn the representation of
endogenous variables, and then uses the VARMAX model to predict the detrended
target time series with the embeddings of endogenous variables, and finally
combines the trend learned by the LSTM and dependency learned by the VARMAX
model to obtain the final predictive values. The experimental results show that
(1) the new model achieves the best prediction accuracy by combining the LSTM
encoding of the exogenous variables and the VARMAX model. (2) In multivariate
non-stationary series prediction, DeepVARMA uses a phased processing strategy
to show higher adaptability and accuracy compared to the traditional VARMA
model as well as the machine learning models LSTM, RF and XGBoost. (3) Compared
with smooth sequence prediction, the traditional VARMA and VARMAX models
fluctuate more in predicting non-smooth sequences, while DeepVARMA shows more
flexibility and robustness. This study provides more accurate tools and methods
for future development and scientific decision-making in the chemical industry.",2024-04-26,"Xiang Li, Hu Yang",http://arxiv.org/pdf/2404.17615v1,cs.LG
Comparison of self-supervised in-domain and supervised out-domain transfer learning for bird species recognition,"Transferring the weights of a pre-trained model to assist another task has
become a crucial part of modern deep learning, particularly in data-scarce
scenarios. Pre-training refers to the initial step of training models outside
the current task of interest, typically on another dataset. It can be done via
supervised models using human-annotated datasets or self-supervised models
trained on unlabeled datasets. In both cases, many pre-trained models are
available to fine-tune for the task of interest. Interestingly, research has
shown that pre-trained models from ImageNet can be helpful for audio tasks
despite being trained on image datasets. Hence, it's unclear whether in-domain
models would be advantageous compared to competent out-domain models, such as
convolutional neural networks from ImageNet. Our experiments will demonstrate
the usefulness of in-domain models and datasets for bird species recognition by
leveraging VICReg, a recent and powerful self-supervised method.",2024-04-26,"Houtan Ghaffari, Paul Devos",http://arxiv.org/pdf/2404.17252v1,cs.LG
Quantum Patch-Based Autoencoder for Anomaly Segmentation,"Quantum Machine Learning investigates the possibility of quantum computers
enhancing Machine Learning algorithms. Anomaly segmentation is a fundamental
task in various domains to identify irregularities at sample level and can be
addressed with both supervised and unsupervised methods. Autoencoders are
commonly used in unsupervised tasks, where models are trained to reconstruct
normal instances efficiently, allowing anomaly identification through high
reconstruction errors. While quantum autoencoders have been proposed in the
literature, their application to anomaly segmentation tasks remains unexplored.
In this paper, we introduce a patch-based quantum autoencoder (QPB-AE) for
image anomaly segmentation, with a number of parameters scaling logarithmically
with patch size. QPB-AE reconstructs the quantum state of the embedded input
patches, computing an anomaly map directly from measurement through a SWAP test
without reconstructing the input image. We evaluate its performance across
multiple datasets and parameter configurations and compare it against a
classical counterpart.",2024-04-26,"Maria Francisca Madeira, Alessandro Poggiali, Jeanette Miriam Lorenz",http://arxiv.org/pdf/2404.17613v1,cs.LG
Making Better Use of Unlabelled Data in Bayesian Active Learning,"Fully supervised models are predominant in Bayesian active learning. We argue
that their neglect of the information present in unlabelled data harms not just
predictive performance but also decisions about what data to acquire. Our
proposed solution is a simple framework for semi-supervised Bayesian active
learning. We find it produces better-performing models than either conventional
Bayesian active learning or semi-supervised learning with randomly acquired
data. It is also easier to scale up than the conventional approach. As well as
supporting a shift towards semi-supervised models, our findings highlight the
importance of studying models and acquisition methods in conjunction.",2024-04-26,"Freddie Bickford Smith, Adam Foster, Tom Rainforth",http://arxiv.org/pdf/2404.17249v1,cs.LG
Algorithmic Fairness: A Tolerance Perspective,"Recent advancements in machine learning and deep learning have brought
algorithmic fairness into sharp focus, illuminating concerns over
discriminatory decision making that negatively impacts certain individuals or
groups. These concerns have manifested in legal, ethical, and societal
challenges, including the erosion of trust in intelligent systems. In response,
this survey delves into the existing literature on algorithmic fairness,
specifically highlighting its multifaceted social consequences. We introduce a
novel taxonomy based on 'tolerance', a term we define as the degree to which
variations in fairness outcomes are acceptable, providing a structured approach
to understanding the subtleties of fairness within algorithmic decisions. Our
systematic review covers diverse industries, revealing critical insights into
the balance between algorithmic decision making and social equity. By
synthesizing these insights, we outline a series of emerging challenges and
propose strategic directions for future research and policy making, with the
goal of advancing the field towards more equitable algorithmic systems.",2024-04-26,"Renqiang Luo, Tao Tang, Feng Xia, Jiaying Liu, Chengpei Xu, Leo Yu Zhang, Wei Xiang, Chengqi Zhang",http://arxiv.org/pdf/2405.09543v1,cs.LG
Cycling into the workshop: predictive maintenance for Barcelona's bike-sharing system,"Bike-sharing systems have emerged as a significant element of urban mobility,
providing an environmentally friendly transportation alternative. With the
increasing integration of electric bikes alongside mechanical bikes, it is
crucial to illuminate distinct usage patterns and their impact on maintenance.
Accordingly, this research aims to develop a comprehensive understanding of
mobility dynamics, distinguishing between different mobility modes, and
introducing a novel predictive maintenance system tailored for bikes. By
utilising a combination of trip information and maintenance data from
Barcelona's bike-sharing system, Bicing, this study conducts an extensive
analysis of mobility patterns and their relationship to failures of bike
components. To accurately predict maintenance needs for essential bike parts,
this research delves into various mobility metrics and applies statistical and
machine learning survival models, including deep learning models. Due to their
complexity, and with the objective of bolstering confidence in the system's
predictions, interpretability techniques explain the main predictors of
maintenance needs. The analysis reveals marked differences in the usage
patterns of mechanical bikes and electric bikes, with a growing user preference
for the latter despite their extra costs. These differences in mobility were
found to have a considerable impact on the maintenance needs within the
bike-sharing system. Moreover, the predictive maintenance models proved
effective in forecasting these maintenance needs, capable of operating across
an entire bike fleet. Despite challenges such as approximated bike usage
metrics and data imbalances, the study successfully showcases the feasibility
of an accurate predictive maintenance system capable of improving operational
costs, bike availability, and security.",2024-04-26,"Jordi Grau-Escolano, Aleix Bassolas, Julian Vicens",http://arxiv.org/pdf/2404.17217v1,cs.LG
An Explainable Deep Reinforcement Learning Model for Warfarin Maintenance Dosing Using Policy Distillation and Action Forging,"Deep Reinforcement Learning is an effective tool for drug dosing for chronic
condition management. However, the final protocol is generally a black box
without any justification for its prescribed doses. This paper addresses this
issue by proposing an explainable dosing protocol for warfarin using a Proximal
Policy Optimization method combined with Policy Distillation. We introduce
Action Forging as an effective tool to achieve explainability. Our focus is on
the maintenance dosing protocol. Results show that the final model is as easy
to understand and deploy as the current dosing protocols and outperforms the
baseline dosing algorithms.",2024-04-26,"Sadjad Anzabi Zadeh, W. Nick Street, Barrett W. Thomas",http://arxiv.org/pdf/2404.17187v1,cs.LG
MCSDNet: Mesoscale Convective System Detection Network via Multi-scale Spatiotemporal Information,"The accurate detection of Mesoscale Convective Systems (MCS) is crucial for
meteorological monitoring due to their potential to cause significant
destruction through severe weather phenomena such as hail, thunderstorms, and
heavy rainfall. However, the existing methods for MCS detection mostly targets
on single-frame detection, which just considers the static characteristics and
ignores the temporal evolution in the life cycle of MCS. In this paper, we
propose a novel encoder-decoder neural network for MCS detection(MCSDNet).
MCSDNet has a simple architecture and is easy to expand. Different from the
previous models, MCSDNet targets on multi-frames detection and leverages
multi-scale spatiotemporal information for the detection of MCS regions in
remote sensing imagery(RSI). As far as we know, it is the first work to utilize
multi-scale spatiotemporal information to detect MCS regions. Firstly, we
design a multi-scale spatiotemporal information module to extract multi-level
semantic from different encoder levels, which makes our models can extract more
detail spatiotemporal features. Secondly, a Spatiotemporal Mix Unit(STMU) is
introduced to MCSDNet to capture both intra-frame features and inter-frame
correlations, which is a scalable module and can be replaced by other
spatiotemporal module, e.g., CNN, RNN, Transformer and our proposed Dual
Spatiotemporal Attention(DSTA). This means that the future works about
spatiotemporal modules can be easily integrated to our model. Finally, we
present MCSRSI, the first publicly available dataset for multi-frames MCS
detection based on visible channel images from the FY-4A satellite. We also
conduct several experiments on MCSRSI and find that our proposed MCSDNet
achieve the best performance on MCS detection task when comparing to other
baseline methods.",2024-04-26,"Jiajun Liang, Baoquan Zhang, Yunming Ye, Xutao Li, Chuyao Luo, Xukai Fu",http://arxiv.org/pdf/2404.17186v1,cs.LG
MetaSD: A Unified Framework for Scalable Downscaling of Meteorological Variables in Diverse Situations,"Addressing complex meteorological processes at a fine spatial resolution
requires substantial computational resources. To accelerate meteorological
simulations, researchers have utilized neural networks to downscale
meteorological variables from low-resolution simulations. Despite notable
advancements, contemporary cutting-edge downscaling algorithms tailored to
specific variables. Addressing meteorological variables in isolation overlooks
their interconnectedness, leading to an incomplete understanding of atmospheric
dynamics. Additionally, the laborious processes of data collection, annotation,
and computational resources required for individual variable downscaling are
significant hurdles. Given the limited versatility of existing models across
different meteorological variables and their failure to account for
inter-variable relationships, this paper proposes a unified downscaling
approach leveraging meta-learning. This framework aims to facilitate the
downscaling of diverse meteorological variables derived from various numerical
models and spatiotemporal scales. Trained at variables consisted of
temperature, wind, surface pressure and total precipitation from ERA5 and GFS,
the proposed method can be extended to downscale convective precipitation,
potential energy, height, humidity and ozone from CFS, S2S and CMIP6 at
different spatiotemporal scales, which demonstrating its capability to capture
the interconnections among diverse variables. Our approach represents the
initial effort to create a generalized downscaling model. Experimental evidence
demonstrates that the proposed model outperforms existing top downscaling
methods in both quantitative and qualitative assessments.",2024-04-26,"Jing Hu, Honghu Zhang, Peng Zheng, Jialin Mu, Xiaomeng Huang, Xi Wu",http://arxiv.org/pdf/2404.17611v1,cs.LG
RE-RFME: Real-Estate RFME Model for customer segmentation,"Marketing is one of the high-cost activities for any online platform. With
the increase in the number of customers, it is crucial to understand customers
based on their dynamic behaviors to design effective marketing strategies.
Customer segmentation is a widely used approach to group customers into
different categories and design the marketing strategy targeting each group
individually. Therefore, in this paper, we propose an end-to-end pipeline
RE-RFME for segmenting customers into 4 groups: high value, promising, need
attention, and need activation. Concretely, we propose a novel RFME (Recency,
Frequency, Monetary and Engagement) model to track behavioral features of
customers and segment them into different categories. Finally, we train the
K-means clustering algorithm to cluster the user into one of the 4 categories.
We show the effectiveness of the proposed approach on real-world Housing.com
datasets for both website and mobile application users.",2024-04-26,"Anurag Kumar Pandey, Anil Goyal, Nikhil Sikka",http://arxiv.org/pdf/2404.17177v1,cs.LG
Optimizing Cycle Life Prediction of Lithium-ion Batteries via a Physics-Informed Model,"Accurately measuring the cycle lifetime of commercial lithium-ion batteries
is crucial for performance and technology development. We introduce a novel
hybrid approach combining a physics-based equation with a self-attention model
to predict the cycle lifetimes of commercial lithium iron phosphate graphite
cells via early-cycle data. After fitting capacity loss curves to this
physics-based equation, we then use a self-attention layer to reconstruct
entire battery capacity loss curves. Our model exhibits comparable performances
to existing models while predicting more information: the entire capacity loss
curve instead of cycle life. This provides more robustness and
interpretability: our model does not need to be retrained for a different
notion of end-of-life and is backed by physical intuition.",2024-04-26,"Constantin-Daniel Nicolae, Sara Sameer, Nathan Sun, Karena Yan",http://arxiv.org/pdf/2404.17174v2,cs.LG
FairGT: A Fairness-aware Graph Transformer,"The design of Graph Transformers (GTs) generally neglects considerations for
fairness, resulting in biased outcomes against certain sensitive subgroups.
Since GTs encode graph information without relying on message-passing
mechanisms, conventional fairness-aware graph learning methods cannot be
directly applicable to address these issues. To tackle this challenge, we
propose FairGT, a Fairness-aware Graph Transformer explicitly crafted to
mitigate fairness concerns inherent in GTs. FairGT incorporates a meticulous
structural feature selection strategy and a multi-hop node feature integration
method, ensuring independence of sensitive features and bolstering fairness
considerations. These fairness-aware graph information encodings seamlessly
integrate into the Transformer framework for downstream tasks. We also prove
that the proposed fair structural topology encoding with adjacency matrix
eigenvector selection and multi-hop integration are theoretically effective.
Empirical evaluations conducted across five real-world datasets demonstrate
FairGT's superiority in fairness metrics over existing graph transformers,
graph neural networks, and state-of-the-art fairness-aware graph learning
approaches.",2024-04-26,"Renqiang Luo, Huafei Huang, Shuo Yu, Xiuzhen Zhang, Feng Xia",http://arxiv.org/pdf/2404.17169v1,cs.LG
HateTinyLLM : Hate Speech Detection Using Tiny Large Language Models,"Hate speech encompasses verbal, written, or behavioral communication that
targets derogatory or discriminatory language against individuals or groups
based on sensitive characteristics. Automated hate speech detection plays a
crucial role in curbing its propagation, especially across social media
platforms. Various methods, including recent advancements in deep learning,
have been devised to address this challenge. In this study, we introduce
HateTinyLLM, a novel framework based on fine-tuned decoder-only tiny large
language models (tinyLLMs) for efficient hate speech detection. Our
experimental findings demonstrate that the fine-tuned HateTinyLLM outperforms
the pretrained mixtral-7b model by a significant margin. We explored various
tiny LLMs, including PY007/TinyLlama-1.1B-step-50K-105b, Microsoft/phi-2, and
facebook/opt-1.3b, and fine-tuned them using LoRA and adapter methods. Our
observations indicate that all LoRA-based fine-tuned models achieved over 80\%
accuracy.",2024-04-26,"Tanmay Sen, Ansuman Das, Mrinmay Sen",http://arxiv.org/pdf/2405.01577v1,cs.LG
DPGAN: A Dual-Path Generative Adversarial Network for Missing Data Imputation in Graphs,"Missing data imputation poses a paramount challenge when dealing with graph
data. Prior works typically are based on feature propagation or graph
autoencoders to address this issue. However, these methods usually encounter
the over-smoothing issue when dealing with missing data, as the graph neural
network (GNN) modules are not explicitly designed for handling missing data.
This paper proposes a novel framework, called Dual-Path Generative Adversarial
Network (DPGAN), that can deal simultaneously with missing data and avoid
over-smoothing problems. The crux of our work is that it admits both global and
local representations of the input graph signal, which can capture the
long-range dependencies. It is realized via our proposed generator, consisting
of two key components, i.e., MLPUNet++ and GraphUNet++. Our generator is
trained with a designated discriminator via an adversarial process. In
particular, to avoid assessing the entire graph as did in the literature, our
discriminator focuses on the local subgraph fidelity, thereby boosting the
quality of the local imputation. The subgraph size is adjustable, allowing for
control over the intensity of adversarial regularization. Comprehensive
experiments across various benchmark datasets substantiate that DPGAN
consistently rivals, if not outperforms, existing state-of-the-art imputation
algorithms. The code is provided at \url{https://github.com/momoxia/DPGAN}.",2024-04-26,"Xindi Zheng, Yuwei Wu, Yu Pan, Wanyu Lin, Lei Ma, Jianjun Zhao",http://arxiv.org/pdf/2404.17164v1,cs.LG
Online $\mathrm{L}^{\natural}$-Convex Minimization,"An online decision-making problem is a learning problem in which a player
repeatedly makes decisions in order to minimize the long-term loss. These
problems that emerge in applications often have nonlinear combinatorial
objective functions, and developing algorithms for such problems has attracted
considerable attention. An existing general framework for dealing with such
objective functions is the online submodular minimization. However, practical
problems are often out of the scope of this framework, since the domain of a
submodular function is limited to a subset of the unit hypercube. To manage
this limitation of the existing framework, we in this paper introduce the
online $\mathrm{L}^{\natural}$-convex minimization, where an
$\mathrm{L}^{\natural}$-convex function generalizes a submodular function so
that the domain is a subset of the integer lattice. We propose computationally
efficient algorithms for the online $\mathrm{L}^{\natural}$-convex function
minimization in two major settings: the full information and the bandit
settings. We analyze the regrets of these algorithms and show in particular
that our algorithm for the full information setting obtains a tight regret
bound up to a constant factor. We also demonstrate several motivating examples
that illustrate the usefulness of the online $\mathrm{L}^{\natural}$-convex
minimization.",2024-04-26,"Ken Yokoyama, Shinji Ito, Tatsuya Matsuoka, Kei Kimura, Makoto Yokoo",http://arxiv.org/pdf/2404.17158v1,cs.LG
Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation,"Feature selection aims to identify the optimal feature subset for enhancing
downstream models. Effective feature selection can remove redundant features,
save computational resources, accelerate the model learning process, and
improve the model overall performance. However, existing works are often
time-intensive to identify the effective feature subset within high-dimensional
feature spaces. Meanwhile, these methods mainly utilize a single downstream
task performance as the selection criterion, leading to the selected subsets
that are not only redundant but also lack generalizability. To bridge these
gaps, we reformulate feature selection through a neuro-symbolic lens and
introduce a novel generative framework aimed at identifying short and effective
feature subsets. More specifically, we found that feature ID tokens of the
selected subset can be formulated as symbols to reflect the intricate
correlations among features. Thus, in this framework, we first create a data
collector to automatically collect numerous feature selection samples
consisting of feature ID tokens, model performance, and the measurement of
feature subset redundancy. Building on the collected data, an
encoder-decoder-evaluator learning paradigm is developed to preserve the
intelligence of feature selection into a continuous embedding space for
efficient search. Within the learned embedding space, we leverage a
multi-gradient search algorithm to find more robust and generalized embeddings
with the objective of improving model performance and reducing feature subset
redundancy. These embeddings are then utilized to reconstruct the feature ID
tokens for executing the final feature selection. Ultimately, comprehensive
experiments and case studies are conducted to validate the effectiveness of the
proposed framework.",2024-04-26,"Nanxu Gong, Wangyang Ying, Dongjie Wang, Yanjie Fu",http://arxiv.org/pdf/2404.17157v2,cs.LG
On the Federated Learning Framework for Cooperative Perception,"Cooperative perception is essential to enhance the efficiency and safety of
future transportation systems, requiring extensive data sharing among vehicles
on the road, which raises significant privacy concerns. Federated learning
offers a promising solution by enabling data privacy-preserving collaborative
enhancements in perception, decision-making, and planning among connected and
autonomous vehicles (CAVs). However, federated learning is impeded by
significant challenges arising from data heterogeneity across diverse clients,
potentially diminishing model accuracy and prolonging convergence periods. This
study introduces a specialized federated learning framework for CP, termed the
federated dynamic weighted aggregation (FedDWA) algorithm, facilitated by
dynamic adjusting loss (DALoss) function. This framework employs dynamic client
weighting to direct model convergence and integrates a novel loss function that
utilizes Kullback-Leibler divergence (KLD) to counteract the detrimental
effects of non-independently and identically distributed (Non-IID) and
unbalanced data. Utilizing the BEV transformer as the primary model, our
rigorous testing on the OpenV2V dataset, augmented with FedBEVT data,
demonstrates significant improvements in the average intersection over union
(IoU). These results highlight the substantial potential of our federated
learning framework to address data heterogeneity challenges in CP, thereby
enhancing the accuracy of environmental perception models and facilitating more
robust and efficient collaborative learning solutions in the transportation
sector.",2024-04-26,"Zhenrong Zhang, Jianan Liu, Xi Zhou, Tao Huang, Qing-Long Han, Jingxin Liu, Hongbin Liu",http://arxiv.org/pdf/2404.17147v4,cs.LG
Sensor Response-Time Reduction using Long-Short Term Memory Network Forecasting,"The response time of a biosensor is a crucial metric in safety-critical
applications such as medical diagnostics where an earlier diagnosis can
markedly improve patient outcomes. However, the speed at which a biosensor
reaches a final equilibrium state can be limited by poor mass transport and
long molecular diffusion times that increase the time it takes target molecules
to reach the active sensing region of a biosensor. While optimization of system
and sensor design can promote molecules reaching the sensing element faster, a
simpler and complementary approach for response time reduction that is widely
applicable across all sensor platforms is to use time-series forecasting to
predict the ultimate steady-state sensor response. In this work, we show that
ensembles of long short-term memory (LSTM) networks can accurately predict
equilibrium biosensor response from a small quantity of initial time-dependent
biosensor measurements, allowing for significant reduction in response time by
a mean and median factor of improvement of 18.6 and 5.1 respectively. The
ensemble of models simultaneously estimates uncertainty, which is vital for
ensuring confidence in the predictions and subsequent safety-related decisions
that are made. This approach is demonstrated on real-time experimental data
collected by exposing porous silicon biosensors to buffered protein solutions
using a multi-channel fluidic cell that enables the automated measurement of
100 porous silicon biosensors in parallel. The dramatic improvement in sensor
response time achieved using LSTM network ensembles and associated uncertainty
quantification opens the door to trustworthy and faster responding biosensors,
enabling more rapid medical diagnostics for faster clinical decision making
that can lead to improved patient outcomes and healthcare access, as well as
quicker identification of toxins in food and the environment.",2024-04-26,"Simon J. Ward, Muhamed Baljevic, Sharon M. Weiss",http://arxiv.org/pdf/2404.17144v2,cs.LG
Deep Evidential Learning for Radiotherapy Dose Prediction,"In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.",2024-04-26,"Hai Siong Tan, Kuancheng Wang, Rafe Mcbeth",http://arxiv.org/pdf/2404.17126v2,cs.LG
Text Sentiment Analysis and Classification Based on Bidirectional Gated Recurrent Units (GRUs) Model,"This paper explores the importance of text sentiment analysis and
classification in the field of natural language processing, and proposes a new
approach to sentiment analysis and classification based on the bidirectional
gated recurrent units (GRUs) model. The study firstly analyses the word cloud
model of the text with six sentiment labels, and then carries out data
preprocessing, including the steps of removing special symbols, punctuation
marks, numbers, stop words and non-alphabetic parts. Subsequently, the data set
is divided into training set and test set, and through model training and
testing, it is found that the accuracy of the validation set is increased from
85% to 93% with training, which is an increase of 8%; at the same time, the
loss value of the validation set decreases from 0.7 to 0.1 and tends to be
stable, and the model is gradually close to the actual value, which can
effectively classify the text emotions. The confusion matrix shows that the
accuracy of the model on the test set reaches 94.8%, the precision is 95.9%,
the recall is 99.1%, and the F1 score is 97.4%, which proves that the model has
good generalisation ability and classification effect. Overall, the study
demonstrated an effective method for text sentiment analysis and classification
with satisfactory results.",2024-04-26,"Wei Xu, Jianlong Chen, Zhicheng Ding, Jinyin Wang",http://arxiv.org/pdf/2404.17123v2,cs.LG
Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs,"Large language models (LLMs) exhibit excellent ability to understand human
languages, but do they also understand their own language that appears
gibberish to us? In this work we delve into this question, aiming to uncover
the mechanisms underlying such behavior in LLMs. We employ the Greedy
Coordinate Gradient optimizer to craft prompts that compel LLMs to generate
coherent responses from seemingly nonsensical inputs. We call these inputs LM
Babel and this work systematically studies the behavior of LLMs manipulated by
these prompts. We find that the manipulation efficiency depends on the target
text's length and perplexity, with the Babel prompts often located in lower
loss minima compared to natural prompts. We further examine the structure of
the Babel prompts and evaluate their robustness. Notably, we find that guiding
the model to generate harmful texts is not more difficult than into generating
benign texts, suggesting lack of alignment for out-of-distribution prompts.",2024-04-26,"Valeriia Cherepanova, James Zou",http://arxiv.org/pdf/2404.17120v2,cs.LG
"MER 2024: Semi-Supervised Learning, Noise Robustness, and Open-Vocabulary Multimodal Emotion Recognition","Multimodal emotion recognition is an important research topic in artificial
intelligence. Over the past few decades, researchers have made remarkable
progress by increasing the dataset size and building more effective algorithms.
However, due to problems such as complex environments and inaccurate
annotations, current systems are hard to meet the demands of practical
applications. Therefore, we organize the MER series of competitions to promote
the development of this field. Last year, we launched MER2023, focusing on
three interesting topics: multi-label learning, noise robustness, and
semi-supervised learning. In this year's MER2024, besides expanding the dataset
size, we further introduce a new track around open-vocabulary emotion
recognition. The main purpose of this track is that existing datasets usually
fix the label space and use majority voting to enhance the annotator
consistency. However, this process may lead to inaccurate annotations, such as
ignoring non-majority or non-candidate labels. In this track, we encourage
participants to generate any number of labels in any category, aiming to
describe emotional states as accurately as possible. Our baseline code relies
on MERTools and is available at:
https://github.com/zeroQiaoba/MERTools/tree/master/MER2024.",2024-04-26,"Zheng Lian, Haiyang Sun, Licai Sun, Zhuofan Wen, Siyuan Zhang, Shun Chen, Hao Gu, Jinming Zhao, Ziyang Ma, Xie Chen, Jiangyan Yi, Rui Liu, Kele Xu, Bin Liu, Erik Cambria, Guoying Zhao, Björn W. Schuller, Jianhua Tao",http://arxiv.org/pdf/2404.17113v4,cs.LG
CoSD: Collaborative Stance Detection with Contrastive Heterogeneous Topic Graph Learning,"Stance detection seeks to identify the viewpoints of individuals either in
favor or against a given target or a controversial topic. Current advanced
neural models for stance detection typically employ fully parametric softmax
classifiers. However, these methods suffer from several limitations, including
lack of explainability, insensitivity to the latent data structure, and
unimodality, which greatly restrict their performance and applications. To
address these challenges, we present a novel collaborative stance detection
framework called (CoSD) which leverages contrastive heterogeneous topic graph
learning to learn topic-aware semantics and collaborative signals among texts,
topics, and stance labels for enhancing stance detection. During training, we
construct a heterogeneous graph to structurally organize texts and stances
through implicit topics via employing latent Dirichlet allocation. We then
perform contrastive graph learning to learn heterogeneous node representations,
aggregating informative multi-hop collaborative signals via an elaborate
Collaboration Propagation Aggregation (CPA) module. During inference, we
introduce a hybrid similarity scoring module to enable the comprehensive
incorporation of topic-aware semantics and collaborative signals for stance
detection. Extensive experiments on two benchmark datasets demonstrate the
state-of-the-art detection performance of CoSD, verifying the effectiveness and
explainability of our collaborative framework.",2024-04-26,"Yinghan Cheng, Qi Zhang, Chongyang Shi, Liang Xiao, Shufeng Hao, Liang Hu",http://arxiv.org/pdf/2404.17609v2,cs.LG
Software Vulnerability Prediction in Low-Resource Languages: An Empirical Study of CodeBERT and ChatGPT,"Background: Software Vulnerability (SV) prediction in emerging languages is
increasingly important to ensure software security in modern systems. However,
these languages usually have limited SV data for developing high-performing
prediction models. Aims: We conduct an empirical study to evaluate the impact
of SV data scarcity in emerging languages on the state-of-the-art SV prediction
model and investigate potential solutions to enhance the performance. Method:
We train and test the state-of-the-art model based on CodeBERT with and without
data sampling techniques for function-level and line-level SV prediction in
three low-resource languages - Kotlin, Swift, and Rust. We also assess the
effectiveness of ChatGPT for low-resource SV prediction given its recent
success in other domains. Results: Compared to the original work in C/C++ with
large data, CodeBERT's performance of function-level and line-level SV
prediction significantly declines in low-resource languages, signifying the
negative impact of data scarcity. Regarding remediation, data sampling
techniques fail to improve CodeBERT; whereas, ChatGPT showcases promising
results, substantially enhancing predictive performance by up to 34.4% for the
function level and up to 53.5% for the line level. Conclusion: We have
highlighted the challenge and made the first promising step for low-resource SV
prediction, paving the way for future research in this direction.",2024-04-26,"Triet H. M. Le, M. Ali Babar, Tung Hoang Thai",http://arxiv.org/pdf/2404.17110v1,cs.LG
Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND,"We introduce the FRactional-Order graph Neural Dynamical network (FROND), a
new continuous graph neural network (GNN) framework. Unlike traditional
continuous GNNs that rely on integer-order differential equations, FROND
employs the Caputo fractional derivative to leverage the non-local properties
of fractional calculus. This approach enables the capture of long-term
dependencies in feature updates, moving beyond the Markovian update mechanisms
in conventional integer-order models and offering enhanced capabilities in
graph representation learning. We offer an interpretation of the node feature
updating process in FROND from a non-Markovian random walk perspective when the
feature updating is particularly governed by a diffusion process. We
demonstrate analytically that oversmoothing can be mitigated in this setting.
Experimentally, we validate the FROND framework by comparing the fractional
adaptations of various established integer-order continuous GNNs, demonstrating
their consistently improved performance and underscoring the framework's
potential as an effective extension to enhance traditional continuous GNNs. The
code is available at \url{https://github.com/zknus/ICLR2024-FROND}.",2024-04-26,"Qiyu Kang, Kai Zhao, Qinxu Ding, Feng Ji, Xuhao Li, Wenfei Liang, Yang Song, Wee Peng Tay",http://arxiv.org/pdf/2404.17099v1,cs.LG
Optimizing Brain-Computer Interface Performance: Advancing EEG Signals Channel Selection through Regularized CSP and SPEA II Multi-Objective Optimization,"Brain-computer interface systems and the recording of brain activity has
garnered significant attention across a diverse spectrum of applications. EEG
signals have emerged as a modality for recording neural electrical activity.
Among the methodologies designed for feature extraction from EEG data, the
method of RCSP has proven to be an approach, particularly in the context of MI
tasks. RCSP exhibits efficacy in the discrimination and classification of EEG
signals. In optimizing the performance of this method, our research extends to
a comparative analysis with conventional CSP techniques, as well as optimized
methodologies designed for similar applications. Notably, we employ the
meta-heuristic multi-objective Strength Pareto Evolutionary Algorithm II
(SPEA-II) as a pivotal component of our research paradigm. This is a
state-of-the-art approach in the selection of an subset of channels from a
multichannel EEG signal with MI tasks. Our main objective is to formulate an
optimum channel selection strategy aimed at identifying the most pertinent
subset of channels from the multi-dimensional electroencephalogram (EEG)
signals. One of the primary objectives inherent to channel selection in the EEG
signal analysis pertains to the reduction of the channel count, an approach
that enhances user comfort when utilizing gel-based EEG electrodes.
Additionally, within this research, we took benefit of ensemble learning models
as a component of our decision-making. This technique serves to mitigate the
challenges associated with overfitting, especially when confronted with an
extensive array of potentially redundant EEG channels and data noise. Our
findings not only affirm the performance of RCSP in MI-based BCI systems, but
also underscore the significance of channel selection strategies and ensemble
learning techniques in optimizing the performance of EEG signal classification.",2024-04-26,"M. Moein Esfahani, Hossein Sadati, Vince D Calhoun",http://arxiv.org/pdf/2405.00721v1,cs.LG
Channel Modeling for FR3 Upper Mid-band via Generative Adversarial Networks,"The upper mid-band (FR3) has been recently attracting interest for new
generation of mobile networks, as it provides a promising balance between
spectrum availability and coverage, which are inherent limitations of the sub
6GHz and millimeter wave bands, respectively. In order to efficiently design
and optimize the network, channel modeling plays a key role since FR3 systems
are expected to operate at multiple frequency bands. Data-driven methods,
especially generative adversarial networks (GANs), can capture the intricate
relationships among data samples, and provide an appropriate tool for FR3
channel modeling. In this work, we present the architecture, link state model,
and path generative network of GAN-based FR3 channel modeling. The comparison
of our model greatly matches the ray-tracing simulated data.",2024-04-25,"Yaqi Hu, Mingsheng Yin, Marco Mezzavilla, Hao Guo, Sundeep Rangan",http://arxiv.org/pdf/2404.17069v1,cs.LG
Synthesizing Audio from Silent Video using Sequence to Sequence Modeling,"Generating audio from a video's visual context has multiple practical
applications in improving how we interact with audio-visual media - for
example, enhancing CCTV footage analysis, restoring historical videos (e.g.,
silent movies), and improving video generation models. We propose a novel
method to generate audio from video using a sequence-to-sequence model,
improving on prior work that used CNNs and WaveNet and faced sound diversity
and generalization challenges. Our approach employs a 3D Vector Quantized
Variational Autoencoder (VQ-VAE) to capture the video's spatial and temporal
structures, decoding with a custom audio decoder for a broader range of sounds.
Trained on the Youtube8M dataset segment, focusing on specific domains, our
model aims to enhance applications like CCTV footage analysis, silent movie
restoration, and video generation models.",2024-04-25,"Hugo Garrido-Lestache Belinchon, Helina Mulugeta, Adam Haile",http://arxiv.org/pdf/2404.17608v1,cs.LG
Transductive Spiking Graph Neural Networks for Loihi,"Graph neural networks have emerged as a specialized branch of deep learning,
designed to address problems where pairwise relations between objects are
crucial. Recent advancements utilize graph convolutional neural networks to
extract features within graph structures. Despite promising results, these
methods face challenges in real-world applications due to sparse features,
resulting in inefficient resource utilization. Recent studies draw inspiration
from the mammalian brain and employ spiking neural networks to model and learn
graph structures. However, these approaches are limited to traditional Von
Neumann-based computing systems, which still face hardware inefficiencies. In
this study, we present a fully neuromorphic implementation of spiking graph
neural networks designed for Loihi 2. We optimize network parameters using Lava
Bayesian Optimization, a novel hyperparameter optimization system compatible
with neuromorphic computing architectures. We showcase the performance benefits
of combining neuromorphic Bayesian optimization with our approach for citation
graph classification using fixed-precision spiking neurons. Our results
demonstrate the capability of integer-precision, Loihi 2 compatible spiking
neural networks in performing citation graph classification with comparable
accuracy to existing floating point implementations.",2024-04-25,"Shay Snyder, Victoria Clerico, Guojing Cong, Shruti Kulkarni, Catherine Schuman, Sumedh R. Risbud, Maryam Parsa",http://arxiv.org/pdf/2404.17048v1,cs.LG
Near to Mid-term Risks and Opportunities of Open-Source Generative AI,"In the next few years, applications of Generative AI are expected to
revolutionize a number of different areas, ranging from science & medicine to
education. The potential for these seismic changes has triggered a lively
debate about potential risks and resulted in calls for tighter regulation, in
particular from some of the major tech companies who are leading in AI
development. This regulation is likely to put at risk the budding field of
open-source Generative AI. We argue for the responsible open sourcing of
generative AI models in the near and medium term. To set the stage, we first
introduce an AI openness taxonomy system and apply it to 40 current large
language models. We then outline differential benefits and risks of open versus
closed source AI and present potential risk mitigation, ranging from best
practices to calls for technical and scientific contributions. We hope that
this report will add a much needed missing voice to the current public
discourse on near to mid-term AI safety and other societal impact.",2024-04-25,"Francisco Eiras, Aleksandar Petrov, Bertie Vidgen, Christian Schroeder de Witt, Fabio Pizzati, Katherine Elkins, Supratik Mukhopadhyay, Adel Bibi, Botos Csaba, Fabro Steibel, Fazl Barez, Genevieve Smith, Gianluca Guadagni, Jon Chun, Jordi Cabot, Joseph Marvin Imperial, Juan A. Nolazco-Flores, Lori Landay, Matthew Jackson, Paul Röttger, Philip H. S. Torr, Trevor Darrell, Yong Suk Lee, Jakob Foerster",http://arxiv.org/pdf/2404.17047v2,cs.LG
Learning Actionable Counterfactual Explanations in Large State Spaces,"Recourse generators provide actionable insights, often through feature-based
counterfactual explanations (CFEs), to help negatively classified individuals
understand how to adjust their input features to achieve a positive
classification. These feature-based CFEs, which we refer to as \emph{low-level}
CFEs, are overly specific (e.g., coding experience: $4 \to 5+$ years) and often
recommended in feature space that doesn't straightforwardly align with
real-world actions. To bridge this gap, we introduce three novel recourse types
grounded in real-world actions: high-level continuous (\emph{hl-continuous}),
high-level discrete (\emph{hl-discrete}), and high-level ID (\emph{hl-id})
CFEs.
  We formulate single-agent CFE generation methods, where we model the
hl-discrete CFE as a solution to a weighted set cover problem and the
hl-continuous CFE as a solution to an integer linear program. Since these
methods require costly optimization per agent, we propose data-driven CFE
generation approaches that, given instances of agents and their optimal CFEs,
learn a CFE generator that quickly provides optimal CFEs for new agents. This
approach, also viewed as one of learning an optimal policy in a family of large
but deterministic MDPs, considers several problem formulations, including
formulations in which the actions and their effects are unknown, and therefore
addresses informational and computational challenges.
  Through extensive empirical evaluation using publicly available healthcare
datasets (BRFSS, Foods, and NHANES), we compare the proposed forms of recourse
to low-level CFEs and assess the effectiveness of our data-driven approaches.
Empirical results show that the proposed data-driven CFE generators are
accurate and resource-efficient, and the proposed forms of recourse have
various advantages over the low-level CFEs.",2024-04-25,"Keziah Naggita, Matthew R. Walter, Avrim Blum",http://arxiv.org/pdf/2404.17034v2,cs.LG
Out-of-Distribution Detection using Maximum Entropy Coding,"Given a default distribution $P$ and a set of test data
$x^M=\{x_1,x_2,\ldots,x_M\}$ this paper seeks to answer the question if it was
likely that $x^M$ was generated by $P$. For discrete distributions, the
definitive answer is in principle given by Kolmogorov-Martin-L\""{o}f
randomness. In this paper we seek to generalize this to continuous
distributions. We consider a set of statistics $T_1(x^M),T_2(x^M),\ldots$. To
each statistic we associate its maximum entropy distribution and with this a
universal source coder. The maximum entropy distributions are subsequently
combined to give a total codelength, which is compared with $-\log P(x^M)$. We
show that this approach satisfied a number of theoretical properties.
  For real world data $P$ usually is unknown. We transform data into a standard
distribution in the latent space using a bidirectional generate network and use
maximum entropy coding there. We compare the resulting method to other methods
that also used generative neural networks to detect anomalies. In most cases,
our results show better performance.",2024-04-25,"Mojtaba Abolfazli, Mohammad Zaeri Amirani, Anders Høst-Madsen, June Zhang, Andras Bratincsak",http://arxiv.org/pdf/2404.17023v1,cs.LG
Neyman Meets Causal Machine Learning: Experimental Evaluation of Individualized Treatment Rules,"A century ago, Neyman showed how to evaluate the efficacy of treatment using
a randomized experiment under a minimal set of assumptions. This classical
repeated sampling framework serves as a basis of routine experimental analyses
conducted by today's scientists across disciplines. In this paper, we
demonstrate that Neyman's methodology can also be used to experimentally
evaluate the efficacy of individualized treatment rules (ITRs), which are
derived by modern causal machine learning algorithms. In particular, we show
how to account for additional uncertainty resulting from a training process
based on cross-fitting. The primary advantage of Neyman's approach is that it
can be applied to any ITR regardless of the properties of machine learning
algorithms that are used to derive the ITR. We also show, somewhat
surprisingly, that for certain metrics, it is more efficient to conduct this
ex-post experimental evaluation of an ITR than to conduct an ex-ante
experimental evaluation that randomly assigns some units to the ITR. Our
analysis demonstrates that Neyman's repeated sampling framework is as relevant
for causal inference today as it has been since its inception.",2024-04-25,"Michael Lingzhi Li, Kosuke Imai",http://arxiv.org/pdf/2404.17019v1,cs.LG
Investigating the dissemination of STEM content on social media with computational tools,"Social media platforms can quickly disseminate STEM content to diverse
audiences, but their operation can be mysterious. We used open-source machine
learning methods such as clustering, regression, and sentiment analysis to
analyze over 1000 videos and metrics thereof from 6 social media STEM creators.
Our data provide insights into how audiences generate interest signals(likes,
bookmarks, comments, shares), on the correlation of various signals with views,
and suggest that content from newer creators is disseminated differently. We
also share insights on how to optimize dissemination by analyzing data
available exclusively to content creators as well as via sentiment analysis of
comments.",2024-04-25,"Oluwamayokun Oshinowo, Priscila Delgado, Meredith Fay, C. Alessandra Luna, Anjana Dissanayaka, Rebecca Jeltuhin, David R. Myers",http://arxiv.org/pdf/2404.18944v1,cs.LG
IDIL: Imitation Learning of Intent-Driven Expert Behavior,"When faced with accomplishing a task, human experts exhibit intentional
behavior. Their unique intents shape their plans and decisions, resulting in
experts demonstrating diverse behaviors to accomplish the same task. Due to the
uncertainties encountered in the real world and their bounded rationality,
experts sometimes adjust their intents, which in turn influences their
behaviors during task execution. This paper introduces IDIL, a novel imitation
learning algorithm to mimic these diverse intent-driven behaviors of experts.
Iteratively, our approach estimates expert intent from heterogeneous
demonstrations and then uses it to learn an intent-aware model of their
behavior. Unlike contemporary approaches, IDIL is capable of addressing
sequential tasks with high-dimensional state representations, while
sidestepping the complexities and drawbacks associated with adversarial
training (a mainstay of related techniques). Our empirical results suggest that
the models generated by IDIL either match or surpass those produced by recent
imitation learning benchmarks in metrics of task performance. Moreover, as it
creates a generative model, IDIL demonstrates superior performance in intent
inference metrics, crucial for human-agent interactions, and aptly captures a
broad spectrum of expert behaviors.",2024-04-25,"Sangwon Seo, Vaibhav Unhelkar",http://arxiv.org/pdf/2404.16989v1,cs.LG
A Novel Machine Learning-based Equalizer for a Downstream 100G PAM-4 PON,"A frequency-calibrated SCINet (FC-SCINet) equalizer is proposed for
down-stream 100G PON with 28.7 dB path loss. At 5 km, FC-SCINet improves the
BER by 88.87% compared to FFE and a 3-layer DNN with 10.57% lower complexity.",2024-04-25,"Chen Shao, Elias Giacoumidis, Shi Li, Jialei Li, Michael Faerber, Tobias Kaefer, Andre Richter",http://arxiv.org/pdf/2405.00720v1,cs.LG
GuideWalk: A Novel Graph-Based Word Embedding for Enhanced Text Classification,"One of the prime problems of computer science and machine learning is to
extract information efficiently from large-scale, heterogeneous data. Text
data, with its syntax, semantics, and even hidden information content,
possesses an exceptional place among the data types in concern. The processing
of the text data requires embedding, a method of translating the content of the
text to numeric vectors. A correct embedding algorithm is the starting point
for obtaining the full information content of the text data. In this work, a
new text embedding approach, namely the Guided Transition Probability Matrix
(GTPM) model is proposed. The model uses the graph structure of sentences to
capture different types of information from text data, such as syntactic,
semantic, and hidden content. Using random walks on a weighted word graph, GTPM
calculates transition probabilities to derive text embedding vectors. The
proposed method is tested with real-world data sets and eight well-known and
successful embedding algorithms. GTPM shows significantly better classification
performance for binary and multi-class datasets than well-known algorithms.
Additionally, the proposed method demonstrates superior robustness, maintaining
performance with limited (only $10\%$) training data, showing an $8\%$ decline
compared to $15-20\%$ for baseline methods.",2024-04-25,"Sarmad N. Mohammed, Semra Gündüç",http://arxiv.org/pdf/2404.18942v2,cs.LG
COCOLA: Coherence-Oriented Contrastive Learning of Musical Audio Representations,"We present COCOLA (Coherence-Oriented Contrastive Learning for Audio), a
contrastive learning method for musical audio representations that captures the
harmonic and rhythmic coherence between samples. Our method operates at the
level of the stems composing music tracks and can input features obtained via
Harmonic-Percussive Separation (HPS). COCOLA allows the objective evaluation of
generative models for music accompaniment generation, which are difficult to
benchmark with established metrics. In this regard, we evaluate recent music
accompaniment generation models, demonstrating the effectiveness of the
proposed method. We release the model checkpoints trained on public datasets
containing separate stems (MUSDB18-HQ, MoisesDB, Slakh2100, and CocoChorales).",2024-04-25,"Ruben Ciranni, Giorgio Mariani, Michele Mancusi, Emilian Postolache, Giorgio Fabbro, Emanuele Rodolà, Luca Cosmo",http://arxiv.org/pdf/2404.16969v4,cs.LG
Markov Chain Monte Carlo with Gaussian Process Emulation for a 1D Hemodynamics Model of CTEPH,"Microvascular disease is a contributor to persistent pulmonary hypertension
in those with chronic thromboembolic pulmonary hypertension (CTEPH). The
heterogenous nature of the micro and macrovascular defects motivates the use of
personalized computational models, which can predict flow dynamics within
multiple generations of the arterial tree and into the microvasculature. Our
study uses computational hemodynamics models and Gaussian processes for rapid,
subject-specific calibration using retrospective data from a large animal model
of CTEPH. Our subject-specific predictions shed light on microvascular
dysfunction and arterial wall shear stress changes in CTEPH.",2024-04-25,"Amirreza Kachabi, Mitchel J. Colebank, Sofia Altieri Correa, Naomi C. Chesler",http://arxiv.org/pdf/2406.01599v1,cs.LG
Hybrid Magnonic Reservoir Computing,"Magnonic systems have been a major area of research interest due to their
potential benefits in speed and lower power consumption compared to traditional
computing. One particular area that they may be of advantage is as Physical
Reservoir Computers in machine learning models. In this work, we build on an
established design for using an Auto-Oscillation Ring as a reservoir computer
by introducing a simple neural network midstream and introduce an additional
design using a spin wave guide with a scattering regime for processing data
with different types of inputs. We simulate these designs on the new micro
magnetic simulation software, Magnum.np, and show that the designs are capable
of performing on various real world data sets comparably or better than
traditional dense neural networks.",2024-04-25,"Cliff B. Abbott, Dmytro A. Bozhko",http://arxiv.org/pdf/2405.09542v1,cs.LG
A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice,"Classification systems are evaluated in a countless number of papers.
However, we find that evaluation practice is often nebulous. Frequently,
metrics are selected without arguments, and blurry terminology invites
misconceptions. For instance, many works use so-called 'macro' metrics to rank
systems (e.g., 'macro F1') but do not clearly specify what they would expect
from such a `macro' metric. This is problematic, since picking a metric can
affect research findings, and thus any clarity in the process should be
maximized.
  Starting from the intuitive concepts of bias and prevalence, we perform an
analysis of common evaluation metrics. The analysis helps us understand the
metrics' underlying properties, and how they align with expectations as found
expressed in papers. Then we reflect on the practical situation in the field,
and survey evaluation practice in recent shared tasks. We find that metric
selection is often not supported with convincing arguments, an issue that can
make a system ranking seem arbitrary. Our work aims at providing overview and
guidance for more informed and transparent metric selection, fostering
meaningful evaluation.",2024-04-25,Juri Opitz,http://arxiv.org/pdf/2404.16958v2,cs.LG
A Notion of Uniqueness for the Adversarial Bayes Classifier,"We propose a new notion of uniqueness for the adversarial Bayes classifier in
the setting of binary classification. Analyzing this concept produces a simple
procedure for computing all adversarial Bayes classifiers for a well-motivated
family of one dimensional data distributions. This characterization is then
leveraged to show that as the perturbation radius increases, certain the
regularity of adversarial Bayes classifiers improves. Various examples
demonstrate that the boundary of the adversarial Bayes classifier frequently
lies near the boundary of the Bayes classifier.",2024-04-25,Natalie S. Frank,http://arxiv.org/pdf/2404.16956v2,cs.LG
Taming False Positives in Out-of-Distribution Detection with Human Feedback,"Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.",2024-04-25,"Harit Vishwakarma, Heguang Lin, Ramya Korlakai Vinayak",http://arxiv.org/pdf/2404.16954v1,cs.LG
EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces,"Effectively learning the temporal dynamics in electroencephalogram (EEG)
signals is challenging yet essential for decoding brain activities using
brain-computer interfaces (BCIs). Although Transformers are popular for their
long-term sequential learning ability in the BCI field, most methods combining
Transformers with convolutional neural networks (CNNs) fail to capture the
coarse-to-fine temporal dynamics of EEG signals. To overcome this limitation,
we introduce EEG-Deformer, which incorporates two main novel components into a
CNN-Transformer: (1) a Hierarchical Coarse-to-Fine Transformer (HCT) block that
integrates a Fine-grained Temporal Learning (FTL) branch into Transformers,
effectively discerning coarse-to-fine temporal patterns; and (2) a Dense
Information Purification (DIP) module, which utilizes multi-level, purified
temporal information to enhance decoding accuracy. Comprehensive experiments on
three representative cognitive tasks-cognitive attention, driving fatigue, and
mental workload detection-consistently confirm the generalizability of our
proposed EEG-Deformer, demonstrating that it either outperforms or performs
comparably to existing state-of-the-art methods. Visualization results show
that EEG-Deformer learns from neurophysiologically meaningful brain regions for
the corresponding cognitive tasks. The source code can be found at
https://github.com/yi-ding-cs/EEG-Deformer.",2024-04-25,"Yi Ding, Yong Li, Hao Sun, Rui Liu, Chengxuan Tong, Chenyu Liu, Xinliang Zhou, Cuntai Guan",http://arxiv.org/pdf/2405.00719v2,cs.LG
Made to Order: Discovering monotonic temporal changes via self-supervised video ordering,"Our objective is to discover and localize monotonic temporal changes in a
sequence of images. To achieve this, we exploit a simple proxy task of ordering
a shuffled image sequence, with `time' serving as a supervisory signal, since
only changes that are monotonic with time can give rise to the correct
ordering. We also introduce a transformer-based model for ordering of image
sequences of arbitrary length with built-in attribution maps. After training,
the model successfully discovers and localizes monotonic changes while ignoring
cyclic and stochastic ones. We demonstrate applications of the model in
multiple domains covering different scene and object types, discovering both
object-level and environmental changes in unseen sequences. We also demonstrate
that the attention-based attribution maps function as effective prompts for
segmenting the changing regions, and that the learned representations can be
used for downstream applications. Finally, we show that the model achieves the
state-of-the-art on standard benchmarks for image ordering.",2024-04-25,"Charig Yang, Weidi Xie, Andrew Zisserman",http://arxiv.org/pdf/2404.16828v3,cs.LG
Learning Visuotactile Skills with Two Multifingered Hands,"Aiming to replicate human-like dexterity, perceptual experiences, and motion
patterns, we explore learning from human demonstrations using a bimanual system
with multifingered hands and visuotactile data. Two significant challenges
exist: the lack of an affordable and accessible teleoperation system suitable
for a dual-arm setup with multifingered hands, and the scarcity of
multifingered hand hardware equipped with touch sensing. To tackle the first
challenge, we develop HATO, a low-cost hands-arms teleoperation system that
leverages off-the-shelf electronics, complemented with a software suite that
enables efficient data collection; the comprehensive software suite also
supports multimodal data processing, scalable policy learning, and smooth
policy deployment. To tackle the latter challenge, we introduce a novel
hardware adaptation by repurposing two prosthetic hands equipped with touch
sensors for research. Using visuotactile data collected from our system, we
learn skills to complete long-horizon, high-precision tasks which are difficult
to achieve without multifingered dexterity and touch feedback. Furthermore, we
empirically investigate the effects of dataset size, sensing modality, and
visual input preprocessing on policy learning. Our results mark a promising
step forward in bimanual multifingered manipulation from visuotactile data.
Videos, code, and datasets can be found at https://toruowo.github.io/hato/ .",2024-04-25,"Toru Lin, Yu Zhang, Qiyang Li, Haozhi Qi, Brent Yi, Sergey Levine, Jitendra Malik",http://arxiv.org/pdf/2404.16823v2,cs.LG
Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer Learning for Skin Disease Classification in Long-Tail Distribution,"Addressing the challenges of rare diseases is difficult, especially with the
limited number of reference images and a small patient population. This is more
evident in rare skin diseases, where we encounter long-tailed data
distributions that make it difficult to develop unbiased and broadly effective
models. The diverse ways in which image datasets are gathered and their
distinct purposes also add to these challenges. Our study conducts a detailed
examination of the benefits and drawbacks of episodic and conventional training
methodologies, adopting a few-shot learning approach alongside transfer
learning. We evaluated our models using the ISIC2018, Derm7pt, and SD-198
datasets. With minimal labeled examples, our models showed substantial
information gains and better performance compared to previously trained models.
Our research emphasizes the improved ability to represent features in
DenseNet121 and MobileNetV2 models, achieved by using pre-trained models on
ImageNet to increase similarities within classes. Moreover, our experiments,
ranging from 2-way to 5-way classifications with up to 10 examples, showed a
growing success rate for traditional transfer learning methods as the number of
examples increased. The addition of data augmentation techniques significantly
improved our transfer learning based model performance, leading to higher
performances than existing methods, especially in the SD-198 and ISIC2018
datasets. All source code related to this work will be made publicly available
soon at the provided URL.",2024-04-25,"Zeynep Özdemir, Hacer Yalim Keles, Ömer Özgür Tanrıöver",http://arxiv.org/pdf/2404.16814v1,cs.LG
A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs,"This paper provides a comprehensive survey of recent advancements in
leveraging machine learning techniques, particularly Transformer models, for
predicting human mobility patterns during epidemics. Understanding how people
move during epidemics is essential for modeling the spread of diseases and
devising effective response strategies. Forecasting population movement is
crucial for informing epidemiological models and facilitating effective
response planning in public health emergencies. Predicting mobility patterns
can enable authorities to better anticipate the geographical and temporal
spread of diseases, allocate resources more efficiently, and implement targeted
interventions. We review a range of approaches utilizing both pretrained
language models like BERT and Large Language Models (LLMs) tailored
specifically for mobility prediction tasks. These models have demonstrated
significant potential in capturing complex spatio-temporal dependencies and
contextual patterns in textual data.",2024-04-25,"Christian N. Mayemba, D'Jeff K. Nkashama, Jean Marie Tshimula, Maximilien V. Dialufuma, Jean Tshibangu Muabila, Mbuyi Mukendi Didier, Hugues Kanda, René Manassé Galekwa, Heber Dibwe Fita, Serge Mundele, Kalonji Kalala, Aristarque Ilunga, Lambert Mukendi Ntobo, Dominique Muteba, Aaron Aruna Abedi",http://arxiv.org/pdf/2404.16921v1,cs.LG
AAPL: Adding Attributes to Prompt Learning for Vision-Language Models,"Recent advances in large pre-trained vision-language models have demonstrated
remarkable performance on zero-shot downstream tasks. Building upon this,
recent studies, such as CoOp and CoCoOp, have proposed the use of prompt
learning, where context within a prompt is replaced with learnable vectors,
leading to significant improvements over manually crafted prompts. However, the
performance improvement for unseen classes is still marginal, and to tackle
this problem, data augmentation has been frequently used in traditional
zero-shot learning techniques. Through our experiments, we have identified
important issues in CoOp and CoCoOp: the context learned through traditional
image augmentation is biased toward seen classes, negatively impacting
generalization to unseen classes. To address this problem, we propose
adversarial token embedding to disentangle low-level visual augmentation
features from high-level class information when inducing bias in learnable
prompts. Through our novel mechanism called ""Adding Attributes to Prompt
Learning"", AAPL, we guide the learnable context to effectively extract text
features by focusing on high-level features for unseen classes. We have
conducted experiments across 11 datasets, and overall, AAPL shows favorable
performances compared to the existing methods in few-shot learning, zero-shot
learning, cross-dataset, and domain generalization tasks.",2024-04-25,"Gahyeon Kim, Sohee Kim, Seokju Lee",http://arxiv.org/pdf/2404.16804v1,cs.LG
In-Context Freeze-Thaw Bayesian Optimization for Hyperparameter Optimization,"With the increasing computational costs associated with deep learning,
automated hyperparameter optimization methods, strongly relying on black-box
Bayesian optimization (BO), face limitations. Freeze-thaw BO offers a promising
grey-box alternative, strategically allocating scarce resources incrementally
to different configurations. However, the frequent surrogate model updates
inherent to this approach pose challenges for existing methods, requiring
retraining or fine-tuning their neural network surrogates online, introducing
overhead, instability, and hyper-hyperparameters. In this work, we propose
FT-PFN, a novel surrogate for Freeze-thaw style BO. FT-PFN is a prior-data
fitted network (PFN) that leverages the transformers' in-context learning
ability to efficiently and reliably do Bayesian learning curve extrapolation in
a single forward pass. Our empirical analysis across three benchmark suites
shows that the predictions made by FT-PFN are more accurate and 10-100 times
faster than those of the deep Gaussian process and deep ensemble surrogates
used in previous work. Furthermore, we show that, when combined with our novel
acquisition mechanism (MFPI-random), the resulting in-context freeze-thaw BO
method (ifBO), yields new state-of-the-art performance in the same three
families of deep learning HPO benchmarks considered in prior work.",2024-04-25,"Herilalaina Rakotoarison, Steven Adriaensen, Neeratyoy Mallik, Samir Garibov, Edward Bergman, Frank Hutter",http://arxiv.org/pdf/2404.16795v3,cs.LG
Model Extrapolation Expedites Alignment,"Given the high computational cost of preference alignment training of large
language models (LLMs), exploring efficient methods to reduce the training
overhead remains an important and compelling research problem. Motivated by the
observation that alignment training typically involves only small parameter
changes without injecting new knowledge into models, we propose a
straightforward method called ExPO (model extrapolation) to expedite LLMs'
alignment with human preferences. Given a partially-trained model and its
initial SFT checkpoint, ExPO improves the implicit optimization objective of
alignment training by simply amplifying the parameter change based on a
first-order approximation, without any additional training overhead. Through
controlled experiments, we demonstrate that ExPO boosts a DPO model trained
with only 20% steps to outperform the fully-trained one. Moreover, we show that
ExPO notably improves existing open-source LLMs (ranging from 1.8B to 70B
parameters) on the leading AlpacaEval 2.0 and MT-Bench benchmarks, which
highlights ExPO's broader utility in efficiently enhancing LLM alignment.",2024-04-25,"Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng",http://arxiv.org/pdf/2404.16792v4,cs.LG
Continual Learning of Large Language Models: A Comprehensive Survey,"The recent success of large language models (LLMs) trained on static,
pre-collected, general datasets has sparked numerous research directions and
applications. One such direction addresses the non-trivial challenge of
integrating pre-trained LLMs into dynamic data distributions, task structures,
and user preferences. Pre-trained LLMs, when tailored for specific needs, often
experience significant performance degradation in previous knowledge domains --
a phenomenon known as ""catastrophic forgetting"". While extensively studied in
the continual learning (CL) community, it presents new manifestations in the
realm of LLMs. In this survey, we provide a comprehensive overview of the
current research progress on LLMs within the context of CL. This survey is
structured into four main sections: we first describe an overview of
continually learning LLMs, consisting of two directions of continuity: vertical
continuity (or vertical continual learning), i.e., continual adaptation from
general to specific capabilities, and horizontal continuity (or horizontal
continual learning), i.e., continual adaptation across time and domains
(Section 3). We then summarize three stages of learning LLMs in the context of
modern CL: Continual Pre-Training (CPT), Domain-Adaptive Pre-training (DAP),
and Continual Fine-Tuning (CFT) (Section 4). Then we provide an overview of
evaluation protocols for continual learning with LLMs, along with the current
available data sources (Section 5). Finally, we discuss intriguing questions
pertaining to continual learning for LLMs (Section 6). The full list of papers
examined in this survey is available at
https://github.com/Wang-ML-Lab/llm-continual-learning-survey.",2024-04-25,"Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, Zifeng Wang, Sayna Ebrahimi, Hao Wang",http://arxiv.org/pdf/2404.16789v3,cs.LG
Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant,"We study the tendency of AI systems to deceive by constructing a realistic
simulation setting of a company AI assistant. The simulated company employees
provide tasks for the assistant to complete, these tasks spanning writing
assistance, information retrieval and programming. We then introduce situations
where the model might be inclined to behave deceptively, while taking care to
not instruct or otherwise pressure the model to do so. Across different
scenarios, we find that Claude 3 Opus
  1) complies with a task of mass-generating comments to influence public
perception of the company, later deceiving humans about it having done so,
  2) lies to auditors when asked questions, and
  3) strategically pretends to be less capable than it is during capability
evaluations.
  Our work demonstrates that even models trained to be helpful, harmless and
honest sometimes behave deceptively in realistic scenarios, without notable
external pressure to do so.",2024-04-25,"Olli Järviniemi, Evan Hubinger",http://arxiv.org/pdf/2405.01576v1,cs.LG
DrS: Learning Reusable Dense Rewards for Multi-Stage Tasks,"The success of many RL techniques heavily relies on human-engineered dense
rewards, which typically demand substantial domain expertise and extensive
trial and error. In our work, we propose DrS (Dense reward learning from
Stages), a novel approach for learning reusable dense rewards for multi-stage
tasks in a data-driven manner. By leveraging the stage structures of the task,
DrS learns a high-quality dense reward from sparse rewards and demonstrations
if given. The learned rewards can be \textit{reused} in unseen tasks, thus
reducing the human effort for reward engineering. Extensive experiments on
three physical robot manipulation task families with 1000+ task variants
demonstrate that our learned rewards can be reused in unseen tasks, resulting
in improved performance and sample efficiency of RL algorithms. The learned
rewards even achieve comparable performance to human-engineered rewards on some
tasks. See our project page (https://sites.google.com/view/iclr24drs) for more
details.",2024-04-25,"Tongzhou Mu, Minghua Liu, Hao Su",http://arxiv.org/pdf/2404.16779v1,cs.LG
Structured Reinforcement Learning for Delay-Optimal Data Transmission in Dense mmWave Networks,"We study the data packet transmission problem (mmDPT) in dense cell-free
millimeter wave (mmWave) networks, i.e., users sending data packet requests to
access points (APs) via uplinks and APs transmitting requested data packets to
users via downlinks. Our objective is to minimize the average delay in the
system due to APs' limited service capacity and unreliable wireless channels
between APs and users. This problem can be formulated as a restless multi-armed
bandits problem with fairness constraint (RMAB-F). Since finding the optimal
policy for RMAB-F is intractable, existing learning algorithms are
computationally expensive and not suitable for practical dynamic dense mmWave
networks. In this paper, we propose a structured reinforcement learning (RL)
solution for mmDPT by exploiting the inherent structure encoded in RMAB-F. To
achieve this, we first design a low-complexity and provably asymptotically
optimal index policy for RMAB-F. Then, we leverage this structure information
to develop a structured RL algorithm called mmDPT-TS, which provably achieves
an \tilde{O}(\sqrt{T}) Bayesian regret. More importantly, mmDPT-TS is
computation-efficient and thus amenable to practical implementation, as it
fully exploits the structure of index policy for making decisions. Extensive
emulation based on data collected in realistic mmWave networks demonstrate
significant gains of mmDPT-TS over existing approaches.",2024-04-25,"Shufan Wang, Guojun Xiong, Shichen Zhang, Huacheng Zeng, Jian Li, Shivendra Panwar",http://arxiv.org/pdf/2404.16920v1,cs.LG
REBEL: Reinforcement Learning via Regressing Relative Rewards,"While originally developed for continuous control problems, Proximal Policy
Optimization (PPO) has emerged as the work-horse of a variety of reinforcement
learning (RL) applications, including the fine-tuning of generative models.
Unfortunately, PPO requires multiple heuristics to enable stable convergence
(e.g. value networks, clipping), and is notorious for its sensitivity to the
precise implementation of these components. In response, we take a step back
and ask what a minimalist RL algorithm for the era of generative models would
look like. We propose REBEL, an algorithm that cleanly reduces the problem of
policy optimization to regressing the relative reward between two completions
to a prompt in terms of the policy, enabling strikingly lightweight
implementation. In theory, we prove that fundamental RL algorithms like Natural
Policy Gradient can be seen as variants of REBEL, which allows us to match the
strongest known theoretical guarantees in terms of convergence and sample
complexity in the RL literature. REBEL can also cleanly incorporate offline
data and be extended to handle the intransitive preferences we frequently see
in practice. Empirically, we find that REBEL provides a unified approach to
language modeling and image generation with stronger or similar performance as
PPO and DPO, all while being simpler to implement and more computationally
efficient than PPO. When fine-tuning Llama-3-8B-Instruct, REBEL achieves strong
performance in AlpacaEval 2.0, MT-Bench, and Open LLM Leaderboard.",2024-04-25,"Zhaolin Gao, Jonathan D. Chang, Wenhao Zhan, Owen Oertell, Gokul Swamy, Kianté Brantley, Thorsten Joachims, J. Andrew Bagnell, Jason D. Lee, Wen Sun",http://arxiv.org/pdf/2404.16767v4,cs.LG
Online Data Augmentation for Forecasting with Deep Learning,"Deep learning approaches are increasingly used to tackle forecasting tasks
involving datasets with multiple univariate time series. A key factor in the
successful application of these methods is a large enough training sample size,
which is not always available. Synthetic data generation techniques can be
applied in these scenarios to augment the dataset. Data augmentation is
typically applied offline before training a model. However, when training with
mini-batches, some batches may contain a disproportionate number of synthetic
samples that do not align well with the original data characteristics. This
work introduces an online data augmentation framework that generates synthetic
samples during the training of neural networks. By creating synthetic samples
for each batch alongside their original counterparts, we maintain a balanced
representation between real and synthetic data throughout the training process.
This approach fits naturally with the iterative nature of neural network
training and eliminates the need to store large augmented datasets. We
validated the proposed framework using 3797 time series from 6 benchmark
datasets, three neural architectures, and seven synthetic data generation
techniques. The experiments suggest that online data augmentation leads to
better forecasting performance compared to offline data augmentation or no
augmentation approaches. The framework and experiments are publicly available.",2024-04-25,"Vitor Cerqueira, Moisés Santos, Luis Roque, Yassine Baghoussi, Carlos Soares",http://arxiv.org/pdf/2404.16918v2,cs.LG
History repeats Itself: A Baseline for Temporal Knowledge Graph Forecasting,"Temporal Knowledge Graph (TKG) Forecasting aims at predicting links in
Knowledge Graphs for future timesteps based on a history of Knowledge Graphs.
To this day, standardized evaluation protocols and rigorous comparison across
TKG models are available, but the importance of simple baselines is often
neglected in the evaluation, which prevents researchers from discerning actual
and fictitious progress. We propose to close this gap by designing an intuitive
baseline for TKG Forecasting based on predicting recurring facts. Compared to
most TKG models, it requires little hyperparameter tuning and no iterative
training. Further, it can help to identify failure modes in existing
approaches. The empirical findings are quite unexpected: compared to 11 methods
on five datasets, our baseline ranks first or third in three of them, painting
a radically different picture of the predictive quality of the state of the
art.",2024-04-25,"Julia Gastinger, Christian Meilicke, Federico Errica, Timo Sztyler, Anett Schuelke, Heiner Stuckenschmidt",http://arxiv.org/pdf/2404.16726v2,cs.LG
Tverberg's theorem and multi-class support vector machines,"We show how, using linear-algebraic tools developed to prove Tverberg's
theorem in combinatorial geometry, we can design new models of multi-class
support vector machines (SVMs). These supervised learning protocols require
fewer conditions to classify sets of points, and can be computed using existing
binary SVM algorithms in higher-dimensional spaces, including soft-margin SVM
algorithms. We describe how the theoretical guarantees of standard support
vector machines transfer to these new classes of multi-class support vector
machines. We give a new simple proof of a geometric characterization of support
vectors for largest margin SVMs by Veelaert.",2024-04-25,Pablo Soberón,http://arxiv.org/pdf/2404.16724v1,cs.LG
Distilling Privileged Information for Dubins Traveling Salesman Problems with Neighborhoods,"This paper presents a novel learning approach for Dubins Traveling Salesman
Problems(DTSP) with Neighborhood (DTSPN) to quickly produce a tour of a
non-holonomic vehicle passing through neighborhoods of given task points. The
method involves two learning phases: initially, a model-free reinforcement
learning approach leverages privileged information to distill knowledge from
expert trajectories generated by the LinKernighan heuristic (LKH) algorithm.
Subsequently, a supervised learning phase trains an adaptation network to solve
problems independently of privileged information. Before the first learning
phase, a parameter initialization technique using the demonstration data was
also devised to enhance training efficiency. The proposed learning method
produces a solution about 50 times faster than LKH and substantially
outperforms other imitation learning and RL with demonstration schemes, most of
which fail to sense all the task points.",2024-04-25,"Min Kyu Shin, Su-Jeong Park, Seung-Keol Ryu, Heeyeon Kim, Han-Lim Choi",http://arxiv.org/pdf/2404.16721v1,cs.LG
Features Fusion for Dual-View Mammography Mass Detection,"Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.",2024-04-25,"Arina Varlamova, Valery Belotsky, Grigory Novikov, Anton Konushin, Evgeny Sidorov",http://arxiv.org/pdf/2404.16718v1,cs.LG
LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding,"We present LayerSkip, an end-to-end solution to speed-up inference of large
language models (LLMs). First, during training we apply layer dropout, with low
dropout rates for earlier layers and higher dropout rates for later layers, and
an early exit loss where all transformer layers share the same exit. Second,
during inference, we show that this training recipe increases the accuracy of
early exit at earlier layers, without adding any auxiliary layers or modules to
the model. Third, we present a novel self-speculative decoding solution where
we exit at early layers and verify and correct with remaining layers of the
model. Our proposed self-speculative decoding approach has less memory
footprint than other speculative decoding approaches and benefits from shared
compute and activations of the draft and verification stages. We run
experiments on different Llama model sizes on different types of training:
pretraining from scratch, continual pretraining, finetuning on specific data
domain, and finetuning on specific task. We implement our inference solution
and show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x
on coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and
checkpoints at https://github.com/facebookresearch/LayerSkip.",2024-04-25,"Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman, Ahmed A Aly, Beidi Chen, Carole-Jean Wu",http://arxiv.org/pdf/2404.16710v4,cs.LG
Efficient and Near-Optimal Noise Generation for Streaming Differential Privacy,"In the task of differentially private (DP) continual counting, we receive a
stream of increments and our goal is to output an approximate running total of
these increments, without revealing too much about any specific increment.
Despite its simplicity, differentially private continual counting has attracted
significant attention both in theory and in practice. Existing algorithms for
differentially private continual counting are either inefficient in terms of
their space usage or add an excessive amount of noise, inducing suboptimal
utility.
  The most practical DP continual counting algorithms add carefully correlated
Gaussian noise to the values. The task of choosing the covariance for this
noise can be expressed in terms of factoring the lower-triangular matrix of
ones (which computes prefix sums). We present two approaches from this class
(for different parameter regimes) that achieve near-optimal utility for DP
continual counting and only require logarithmic or polylogarithmic space (and
time).
  Our first approach is based on a space-efficient streaming matrix
multiplication algorithm for a class of Toeplitz matrices. We show that to
instantiate this algorithm for DP continual counting, it is sufficient to find
a low-degree rational function that approximates the square root on a circle in
the complex plane. We then apply and extend tools from approximation theory to
achieve this. We also derive efficient closed-forms for the objective function
for arbitrarily many steps, and show direct numerical optimization yields a
highly practical solution to the problem. Our second approach combines our
first approach with a recursive construction similar to the binary tree
mechanism.",2024-04-25,"Krishnamurthy Dvijotham, H. Brendan McMahan, Krishna Pillutla, Thomas Steinke, Abhradeep Thakurta",http://arxiv.org/pdf/2404.16706v3,cs.LG
Grad Queue : A probabilistic framework to reinforce sparse gradients,"Informative gradients are often lost in large batch updates. We propose a
robust mechanism to reinforce the sparse components within a random batch of
data points. A finite queue of online gradients is used to determine their
expected instantaneous statistics. We propose a function to measure the
scarcity of incoming gradients using these statistics and establish the
theoretical ground of this mechanism. To minimize conflicting components within
large mini-batches, samples are grouped with aligned objectives by clustering
based on inherent feature space. Sparsity is measured for each centroid and
weighted accordingly. A strong intuitive criterion to squeeze out redundant
information from each cluster is the backbone of the system. It makes rare
information indifferent to aggressive momentum also exhibits superior
performance with larger mini-batch horizon. The effective length of the queue
kept variable to follow the local loss pattern. The contribution of our method
is to restore intra-mini-batch diversity at the same time widening the optimal
batch boundary. Both of these collectively drive it deeper towards the minima.
Our method has shown superior performance for CIFAR10, MNIST, and Reuters News
category dataset compared to mini-batch gradient descent.",2024-04-25,Irfan Mohammad Al Hasib,http://arxiv.org/pdf/2404.16917v1,cs.LG
Utilizing Large Language Models to Identify Reddit Users Considering Vaping Cessation for Digital Interventions,"The widespread adoption of social media platforms globally not only enhances
users' connectivity and communication but also emerges as a vital channel for
the dissemination of health-related information, thereby establishing social
media data as an invaluable organic data resource for public health research.
The surge in popularity of vaping or e-cigarette use in the United States and
other countries has caused an outbreak of e-cigarette and vaping use-associated
lung injury (EVALI), leading to hospitalizations and fatalities in 2019,
highlighting the urgency to comprehend vaping behaviors and develop effective
strategies for cession. In this study, we extracted a sample dataset from one
vaping sub-community on Reddit to analyze users' quit vaping intentions.
Leveraging large language models including both the latest GPT-4 and
traditional BERT-based language models for sentence-level quit-vaping intention
prediction tasks, this study compares the outcomes of these models against
human annotations. Notably, when compared to human evaluators, GPT-4 model
demonstrates superior consistency in adhering to annotation guidelines and
processes, showcasing advanced capabilities to detect nuanced user quit-vaping
intentions that human evaluators might overlook. These preliminary findings
emphasize the potential of GPT-4 in enhancing the accuracy and reliability of
social media data analysis, especially in identifying subtle users' intentions
that may elude human detection.",2024-04-25,"Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Caleb Henry, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang",http://arxiv.org/pdf/2404.17607v1,cs.LG
Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing,"MoE facilitates the development of large models by making the computational
complexity of the model no longer scale linearly with increasing parameters.
The learning sparse gating network selects a set of experts for each token to
be processed; however, this may lead to differences in the number of tokens
processed by each expert over several successive iterations, i.e., the expert
load fluctuations, which reduces computational parallelization and resource
utilization. To this end, we traced and analyzed loads of each expert in the
training iterations for several large language models in this work, and defined
the transient state with ""obvious load fluctuation"" and the stable state with
""temporal locality"". Moreover, given the characteristics of these two states
and the computational overhead, we deployed three classical prediction
algorithms that achieve accurate expert load prediction results. For the GPT3
350M model, the average error rates for predicting the expert load proportion
over the next 1,000 and 2,000 steps are approximately 1.3% and 1.8%,
respectively. This work can provide valuable guidance for expert placement or
resource allocation for MoE model training. Based on this work, we will propose
an expert placement scheme for transient and stable states in our coming work.",2024-04-25,"Peizhuang Cong, Aomufei Yuan, Shimao Chen, Yuxuan Tian, Bowen Ye, Tong Yang",http://arxiv.org/pdf/2404.16914v1,cs.LG
Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation,"Proprietary Large Language Models (LLMs) such as GPT-4 and Gemini have
demonstrated promising capabilities in clinical text summarization tasks.
However, due to patient data privacy concerns and computational costs, many
healthcare providers prefer using small, locally-hosted models over external
generic LLMs. This study presents a comprehensive domain- and task-specific
adaptation process for the open-source LLaMA-2 13 billion parameter model,
enabling it to generate high-quality clinical notes from outpatient
patient-doctor dialogues. Our process incorporates continued pre-training,
supervised fine-tuning, and reinforcement learning from both AI and human
feedback. We introduced a new approach, DistillDirect, for performing on-policy
reinforcement learning with Gemini 1.0 Pro as the teacher model. Our resulting
model, LLaMA-Clinic, can generate clinical notes comparable in quality to those
authored by physicians. In a blinded physician reader study, the majority
(90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as
""acceptable"" or higher across all three criteria: real-world readiness,
completeness, and accuracy. In the more challenging ""Assessment and Plan""
section, LLaMA-Clinic scored higher (4.2/5) in real-world readiness than
physician-authored notes (4.1/5). We highlight key considerations for future
clinical note-generation tasks, emphasizing the importance of pre-defining a
best-practice note format, rather than relying on LLMs to determine this for
clinical practice.",2024-04-25,"Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Korsapati, Chuck Outcalt, Jimeng Sun",http://arxiv.org/pdf/2405.00715v5,cs.LG
Multilayer Correlation Clustering,"In this paper, we establish Multilayer Correlation Clustering, a novel
generalization of Correlation Clustering (Bansal et al., FOCS '02) to the
multilayer setting. In this model, we are given a series of inputs of
Correlation Clustering (called layers) over the common set $V$. The goal is
then to find a clustering of $V$ that minimizes the $\ell_p$-norm ($p\geq 1$)
of the disagreements vector, which is defined as the vector (with dimension
equal to the number of layers), each element of which represents the
disagreements of the clustering on the corresponding layer. For this
generalization, we first design an $O(L\log n)$-approximation algorithm, where
$L$ is the number of layers, based on the well-known region growing technique.
We then study an important special case of our problem, namely the problem with
the probability constraint. For this case, we first give an
$(\alpha+2)$-approximation algorithm, where $\alpha$ is any possible
approximation ratio for the single-layer counterpart. For instance, we can take
$\alpha=2.5$ in general (Ailon et al., JACM '08) and $\alpha=1.73+\epsilon$ for
the unweighted case (Cohen-Addad et al., FOCS '23). Furthermore, we design a
$4$-approximation algorithm, which improves the above approximation ratio of
$\alpha+2=4.5$ for the general probability-constraint case. Computational
experiments using real-world datasets demonstrate the effectiveness of our
proposed algorithms.",2024-04-25,"Atsushi Miyauchi, Florian Adriaens, Francesco Bonchi, Nikolaj Tatti",http://arxiv.org/pdf/2404.16676v1,cs.LG
DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing Conditional Generative Adversarial Networks,"Repetitive Transcranial Magnetic Stimulation (rTMS) is a well-supported,
evidence-based treatment for depression. However, patterns of response to this
treatment are inconsistent. Emerging evidence suggests that artificial
intelligence can predict rTMS treatment outcomes for most patients using fMRI
connectivity features. While these models can reliably predict treatment
outcomes for many patients for some underrepresented fMRI connectivity measures
DNN models are unable to reliably predict treatment outcomes. As such we
propose a novel method, Diversity Enhancing Conditional General Adversarial
Network (DE-CGAN) for oversampling these underrepresented examples. DE-CGAN
creates synthetic examples in difficult-to-classify regions by first
identifying these data points and then creating conditioned synthetic examples
to enhance data diversity. Through empirical experiments we show that a
classification model trained using a diversity enhanced training set
outperforms traditional data augmentation techniques and existing benchmark
results. This work shows that increasing the diversity of a training dataset
can improve classification model performance. Furthermore, this work provides
evidence for the utility of synthetic patients providing larger more robust
datasets for both AI researchers and psychiatrists to explore variable
relationships.",2024-04-25,"Matthew Squires, Xiaohui Tao, Soman Elangovan, Raj Gururajan, Haoran Xie, Xujuan Zhou, Yuefeng Li, U Rajendra Acharya",http://arxiv.org/pdf/2404.16913v1,cs.LG
Conditional Fairness for Generative AIs,"The deployment of generative AI (GenAI) models raises significant fairness
concerns, addressed in this paper through novel characterization and
enforcement techniques specific to GenAI. Unlike standard AI performing
specific tasks, GenAI's broad functionality requires ""conditional fairness""
tailored to the context being generated, such as demographic fairness in
generating images of poor people versus successful business leaders. We define
two fairness levels: the first evaluates fairness in generated outputs,
independent of prompts and models; the second assesses inherent fairness with
neutral prompts. Given the complexity of GenAI and challenges in fairness
specifications, we focus on bounding the worst case, considering a GenAI system
unfair if the distance between appearances of a specific group exceeds preset
thresholds. We also explore combinatorial testing for accessing relative
completeness in intersectional fairness. By bounding the worst case, we develop
a prompt injection scheme within an agent-based framework to enforce
conditional fairness with minimal intervention, validated on state-of-the-art
GenAI systems.",2024-04-25,"Chih-Hong Cheng, Harald Ruess, Changshun Wu, Xingyu Zhao",http://arxiv.org/pdf/2404.16663v4,cs.LG
Benchmarking Mobile Device Control Agents across Diverse Configurations,"Mobile device control agents can largely enhance user interactions and
productivity by automating daily tasks. However, despite growing interest in
developing practical agents, the absence of a commonly adopted benchmark in
this area makes it challenging to quantify scientific progress. In this work,
we introduce B-MoCA: a novel benchmark with interactive environments for
evaluating and developing mobile device control agents. To create a realistic
benchmark, we develop B-MoCA based on the Android operating system and define
131 common daily tasks. Importantly, we incorporate a randomization feature
that changes the configurations of mobile devices, including user interface
layouts and language settings, to assess generalization performance. We
benchmark diverse agents, including agents employing large language models
(LLMs) or multi-modal LLMs as well as agents trained with imitation learning
using human expert demonstrations. While these agents demonstrate proficiency
in executing straightforward tasks, their poor performance on complex tasks
highlights significant opportunities for future research to improve
effectiveness. Our source code is publicly available at
https://b-moca.github.io.",2024-04-25,"Juyong Lee, Taywon Min, Minyong An, Dongyoon Hahm, Haeone Lee, Changyeon Kim, Kimin Lee",http://arxiv.org/pdf/2404.16660v2,cs.LG
A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection,"Modeling non-stationary data is a challenging problem in the field of
continual learning, and data distribution shifts may result in negative
consequences on the performance of a machine learning model. Classic learning
tools are often vulnerable to perturbations of the input covariates, and are
sensitive to outliers and noise, and some tools are based on rigid algebraic
assumptions. Distribution shifts are frequently occurring due to changes in raw
materials for production, seasonality, a different user base, or even
adversarial attacks. Therefore, there is a need for more effective distribution
shift detection techniques. In this work, we propose a continual learning
framework for monitoring and detecting distribution changes. We explore the
problem in a latent space generated by a bio-inspired self-organizing
clustering and statistical aspects of the latent space. In particular, we
investigate the projections made by two topology-preserving maps: the
Self-Organizing Map and the Scale Invariant Map. Our method can be applied in
both a supervised and an unsupervised context. We construct the assessment of
changes in the data distribution as a comparison of Gaussian signals, making
the proposed method fast and robust. We compare it to other unsupervised
techniques, specifically Principal Component Analysis (PCA) and Kernel-PCA. Our
comparison involves conducting experiments using sequences of images (based on
MNIST and injected shifts with adversarial samples), chemical sensor
measurements, and the environmental variable related to ozone levels. The
empirical study reveals the potential of the proposed approach.",2024-04-25,"Sebastián Basterrech, Line Clemmensen, Gerardo Rubino",http://arxiv.org/pdf/2404.16656v2,cs.LG
Application of RESNET50 Convolution Neural Network for the Extraction of Optical Parameters in Scattering Media,"Estimation of the optical properties of scattering media such as tissue is
important in diagnostics as well as in the development of techniques to image
deeper. As light penetrates the sample scattering events occur that alter the
propagation direction of the photons in a random manner leading degradation of
image quality. The distribution of the scattered light does, however, give a
measure of the optical properties such as the reduced scattering coefficient
and the absorption coefficient. Unfortunately, inverting scattering patterns to
recover the optical properties is not simple, especially in the regime where
the light is partially randomized. Machine learning has been proposed by
several authors as a means of recovering these properties from either the back
scattered or the transmitted light. In the present paper, we train a general
purpose convolutional neural network RESNET 50 with simulated data based on
Monte Carlo simulations. We show that compared with previous work our approach
gives comparable or better reconstruction accuracy with training on a much
smaller dataset. Moreover, by training on multiple parameters such as the
intensity distribution at multiple planes or the exit angle and spatial
distribution one achieves improved performance compared to training on a single
input such as the intensity distribution captured at the sample surface. While
our approach gives good parameter reconstruction, we identify factors that
limit the accuracy of the recovered properties, particularly the absorption
coefficient. In the light of these limitations, we suggest how the present
approach may be enhanced for even better performance.",2024-04-25,"Bowen Deng, Yihan Zhang, Andrew Parkes, Alex Bentley, Amanda Wright, Michael Pound, Michael Somekh",http://arxiv.org/pdf/2404.16647v1,cs.LG
Privacy-Preserving Statistical Data Generation: Application to Sepsis Detection,"The biomedical field is among the sectors most impacted by the increasing
regulation of Artificial Intelligence (AI) and data protection legislation,
given the sensitivity of patient information. However, the rise of synthetic
data generation methods offers a promising opportunity for data-driven
technologies. In this study, we propose a statistical approach for synthetic
data generation applicable in classification problems. We assess the utility
and privacy implications of synthetic data generated by Kernel Density
Estimator and K-Nearest Neighbors sampling (KDE-KNN) within a real-world
context, specifically focusing on its application in sepsis detection. The
detection of sepsis is a critical challenge in clinical practice due to its
rapid progression and potentially life-threatening consequences. Moreover, we
emphasize the benefits of KDE-KNN compared to current synthetic data generation
methodologies. Additionally, our study examines the effects of incorporating
synthetic data into model training procedures. This investigation provides
valuable insights into the effectiveness of synthetic data generation
techniques in mitigating regulatory constraints within the biomedical field.",2024-04-25,"Eric Macias-Fassio, Aythami Morales, Cristina Pruenza, Julian Fierrez",http://arxiv.org/pdf/2404.16638v1,cs.LG
Legal Aspects for Software Developers Interested in Generative AI Applications,"Recent successes in Generative Artificial Intelligence (GenAI) have led to
new technologies capable of generating high-quality code, natural language, and
images. The next step is to integrate GenAI technology into products, a task
typically conducted by software developers. Such product development always
comes with a certain risk of liability. Within this article, we want to shed
light on the current state of two such risks: data protection and copyright.
Both aspects are crucial for GenAI. This technology deals with data for both
model training and generated output. We summarize key aspects regarding our
current knowledge that every software developer involved in product development
using GenAI should be aware of to avoid critical mistakes that may expose them
to liability claims.",2024-04-25,"Steffen Herbold, Brian Valerius, Anamaria Mojica-Hanke, Isabella Lex, Joel Mittel",http://arxiv.org/pdf/2404.16630v1,cs.LG
Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare,"The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.",2024-04-25,"Emre Can Acikgoz, Osman Batur İnce, Rayene Bench, Arda Anıl Boz, İlker Kesen, Aykut Erdem, Erkut Erdem",http://arxiv.org/pdf/2404.16621v1,cs.LG
Robust Capped lp-Norm Support Vector Ordinal Regression,"Ordinal regression is a specialized supervised problem where the labels show
an inherent order. The order distinguishes it from normal multi-class problem.
Support Vector Ordinal Regression, as an outstanding ordinal regression model,
is widely used in many ordinal regression tasks. However, like most supervised
learning algorithms, the design of SVOR is based on the assumption that the
training data are real and reliable, which is difficult to satisfy in
real-world data. In many practical applications, outliers are frequently
present in the training set, potentially leading to misguide the learning
process, such that the performance is non-optimal. In this paper, we propose a
novel capped $\ell_{p}$-norm loss function that is theoretically robust to both
light and heavy outliers. The capped $\ell_{p}$-norm loss can help the model
detect and eliminate outliers during training process. Adhering to this
concept, we introduce a new model, Capped $\ell_{p}$-Norm Support Vector
Ordinal Regression(CSVOR), that is robust to outliers. CSVOR uses a weight
matrix to detect and eliminate outliers during the training process to improve
the robustness to outliers. Moreover, a Re-Weighted algorithm algorithm which
is illustrated convergence by our theoretical results is proposed to
effectively minimize the corresponding problem. Extensive experimental results
demonstrate that our model outperforms state-of-the-art(SOTA) methods,
particularly in the presence of outliers.",2024-04-25,"Haorui Xiang, Zhichang Wu, Guoxu Li, Rong Wang, Feiping Nie, Xuelong Li",http://arxiv.org/pdf/2404.16616v1,cs.LG
HEroBM: a deep equivariant graph neural network for universal backmapping from coarse-grained to all-atom representations,"Molecular simulations have assumed a paramount role in the fields of
chemistry, biology, and material sciences, being able to capture the intricate
dynamic properties of systems. Within this realm, coarse-grained (CG)
techniques have emerged as invaluable tools to sample large-scale systems and
reach extended timescales by simplifying system representation. However, CG
approaches come with a trade-off: they sacrifice atomistic details that might
hold significant relevance in deciphering the investigated process. Therefore,
a recommended approach is to identify key CG conformations and process them
using backmapping methods, which retrieve atomistic coordinates. Currently,
rule-based methods yield subpar geometries and rely on energy relaxation,
resulting in less-than-optimal outcomes. Conversely, machine learning
techniques offer higher accuracy but are either limited in transferability
between systems or tied to specific CG mappings. In this work, we introduce
HEroBM, a dynamic and scalable method that employs deep equivariant graph
neural networks and a hierarchical approach to achieve high-resolution
backmapping. HEroBM handles any type of CG mapping, offering a versatile and
efficient protocol for reconstructing atomistic structures with high accuracy.
Focused on local principles, HEroBM spans the entire chemical space and is
transferable to systems of varying sizes. We illustrate the versatility of our
framework through diverse biological systems, including a complex real-case
scenario. Here, our end-to-end backmapping approach accurately generates the
atomistic coordinates of a G protein-coupled receptor bound to an organic small
molecule within a cholesterol/phospholipid bilayer.",2024-04-25,"Daniele Angioletti, Stefano Raniolo, Vittorio Limongelli",http://arxiv.org/pdf/2404.16911v1,cs.LG
Adaptive Semantic Token Selection for AI-native Goal-oriented Communications,"In this paper, we propose a novel design for AI-native goal-oriented
communications, exploiting transformer neural networks under dynamic inference
constraints on bandwidth and computation. Transformers have become the standard
architecture for pretraining large-scale vision and text models, and
preliminary results have shown promising performance also in deep joint
source-channel coding (JSCC). Here, we consider a dynamic model where
communication happens over a channel with variable latency and bandwidth
constraints. Leveraging recent works on conditional computation, we exploit the
structure of the transformer blocks and the multihead attention operator to
design a trainable semantic token selection mechanism that learns to select
relevant tokens (e.g., image patches) from the input signal. This is done
dynamically, on a per-input basis, with a rate that can be chosen as an
additional input by the user. We show that our model improves over
state-of-the-art token selection mechanisms, exhibiting high accuracy for a
wide range of latency and bandwidth constraints, without the need for deploying
multiple architectures tailored to each constraint. Last, but not least, the
proposed token selection mechanism helps extract powerful semantics that are
easy to understand and explain, paving the way for interpretable-by-design
models for the next generation of AI-native communication systems.",2024-04-25,"Alessio Devoto, Simone Petruzzi, Jary Pomponi, Paolo Di Lorenzo, Simone Scardapane",http://arxiv.org/pdf/2405.02330v1,cs.LG
Closing the gap: Optimizing Guidance and Control Networks through Neural ODEs,"We improve the accuracy of Guidance & Control Networks (G&CNETs), trained to
represent the optimal control policies of a time-optimal transfer and a
mass-optimal landing, respectively. In both cases we leverage the dynamics of
the spacecraft, described by Ordinary Differential Equations which incorporate
a neural network on their right-hand side (Neural ODEs). Since the neural
dynamics is differentiable, the ODEs sensitivities to the network parameters
can be computed using the variational equations, thereby allowing to update the
G&CNET parameters based on the observed dynamics. We start with a
straightforward regression task, training the G&CNETs on datasets of optimal
trajectories using behavioural cloning. These networks are then refined using
the Neural ODE sensitivities by minimizing the error between the final states
and the target states. We demonstrate that for the orbital transfer, the final
error to the target can be reduced by 99% on a single trajectory and by 70% on
a batch of 500 trajectories. For the landing problem the reduction in error is
around 98-99% (position) and 40-44% (velocity). This step significantly
enhances the accuracy of G&CNETs, which instills greater confidence in their
reliability for operational use. We also compare our results to the popular
Dataset Aggregation method (DaGGER) and allude to the strengths and weaknesses
of both methods.",2024-04-25,"Sebastien Origer, Dario Izzo",http://arxiv.org/pdf/2404.16908v1,cs.LG
Season combinatorial intervention predictions with Salt & Peper,"Interventions play a pivotal role in the study of complex biological systems.
In drug discovery, genetic interventions (such as CRISPR base editing) have
become central to both identifying potential therapeutic targets and
understanding a drug's mechanism of action. With the advancement of CRISPR and
the proliferation of genome-scale analyses such as transcriptomics, a new
challenge is to navigate the vast combinatorial space of concurrent genetic
interventions. Addressing this, our work concentrates on estimating the effects
of pairwise genetic combinations on the cellular transcriptome. We introduce
two novel contributions: Salt, a biologically-inspired baseline that posits the
mostly additive nature of combination effects, and Peper, a deep learning model
that extends Salt's additive assumption to achieve unprecedented accuracy. Our
comprehensive comparison against existing state-of-the-art methods, grounded in
diverse metrics, and our out-of-distribution analysis highlight the limitations
of current models in realistic settings. This analysis underscores the
necessity for improved modelling techniques and data acquisition strategies,
paving the way for more effective exploration of genetic intervention effects.",2024-04-25,"Thomas Gaudelet, Alice Del Vecchio, Eli M Carrami, Juliana Cudini, Chantriolnt-Andreas Kapourani, Caroline Uhler, Lindsay Edwards",http://arxiv.org/pdf/2404.16907v1,cs.LG
Deep learning-based blind image super-resolution with iterative kernel reconstruction and noise estimation,"Blind single image super-resolution (SISR) is a challenging task in image
processing due to the ill-posed nature of the inverse problem. Complex
degradations present in real life images make it difficult to solve this
problem using na\""ive deep learning approaches, where models are often trained
on synthetically generated image pairs. Most of the effort so far has been
focused on solving the inverse problem under some constraints, such as for a
limited space of blur kernels and/or assuming noise-free input images. Yet,
there is a gap in the literature to provide a well-generalized deep
learning-based solution that performs well on images with unknown and highly
complex degradations. In this paper, we propose IKR-Net (Iterative Kernel
Reconstruction Network) for blind SISR. In the proposed approach, kernel and
noise estimation and high-resolution image reconstruction are carried out
iteratively using dedicated deep models. The iterative refinement provides
significant improvement in both the reconstructed image and the estimated blur
kernel even for noisy inputs. IKR-Net provides a generalized solution that can
handle any type of blur and level of noise in the input low-resolution image.
IKR-Net achieves state-of-the-art results in blind SISR, especially for noisy
images with motion blur.",2024-04-25,"Hasan F. Ates, Suleyman Yildirim, Bahadir K. Gunturk",http://arxiv.org/pdf/2404.16564v1,cs.LG
Automated Model Selection for Generalized Linear Models,"In this paper, we show how mixed-integer conic optimization can be used to
combine feature subset selection with holistic generalized linear models to
fully automate the model selection process. Concretely, we directly optimize
for the Akaike and Bayesian information criteria while imposing constraints
designed to deal with multicollinearity in the feature selection task.
Specifically, we propose a novel pairwise correlation constraint that combines
the sign coherence constraint with ideas from classical statistical models like
Ridge regression and the OSCAR model.",2024-04-25,"Benjamin Schwendinger, Florian Schwendinger, Laura Vana-Gür",http://arxiv.org/pdf/2404.16560v1,cs.LG
RE-RecSys: An End-to-End system for recommending properties in Real-Estate domain,"We propose an end-to-end real-estate recommendation system, RE-RecSys, which
has been productionized in real-world industry setting. We categorize any user
into 4 categories based on available historical data: i) cold-start users; ii)
short-term users; iii) long-term users; and iv) short-long term users. For
cold-start users, we propose a novel rule-based engine that is based on the
popularity of locality and user preferences. For short-term users, we propose
to use content-filtering model which recommends properties based on recent
interactions of users. For long-term and short-long term users, we propose a
novel combination of content and collaborative filtering based approach which
can be easily productionized in the real-world scenario. Moreover, based on the
conversion rate, we have designed a novel weighing scheme for different
impressions done by users on the platform for the training of content and
collaborative models. Finally, we show the efficiency of the proposed pipeline,
RE-RecSys, on a real-world property and clickstream dataset collected from
leading real-estate platform in India. We show that the proposed pipeline is
deployable in real-world scenario with an average latency of <40 ms serving
1000 rpm.",2024-04-25,"Venkatesh C, Harshit Oberoi, Anil Goyal, Nikhil Sikka",http://arxiv.org/pdf/2404.16553v1,cs.LG
Surprisingly Strong Performance Prediction with Neural Graph Features,"Performance prediction has been a key part of the neural architecture search
(NAS) process, allowing to speed up NAS algorithms by avoiding
resource-consuming network training. Although many performance predictors
correlate well with ground truth performance, they require training data in the
form of trained networks. Recently, zero-cost proxies have been proposed as an
efficient method to estimate network performance without any training. However,
they are still poorly understood, exhibit biases with network properties, and
their performance is limited. Inspired by the drawbacks of zero-cost proxies,
we propose neural graph features (GRAF), simple to compute properties of
architectural graphs. GRAF offers fast and interpretable performance prediction
while outperforming zero-cost proxies and other common encodings. In
combination with other zero-cost proxies, GRAF outperforms most existing
performance predictors at a fraction of the cost.",2024-04-25,"Gabriela Kadlecová, Jovita Lukasik, Martin Pilát, Petra Vidnerová, Mahmoud Safari, Roman Neruda, Frank Hutter",http://arxiv.org/pdf/2404.16551v2,cs.LG
Application of Long-Short Term Memory and Convolutional Neural Networks for Real-Time Bridge Scour Prediction,"Scour around bridge piers is a critical challenge for infrastructures around
the world. In the absence of analytical models and due to the complexity of the
scour process, it is difficult for current empirical methods to achieve
accurate predictions. In this paper, we exploit the power of deep learning
algorithms to forecast the scour depth variations around bridge piers based on
historical sensor monitoring data, including riverbed elevation, flow
elevation, and flow velocity. We investigated the performance of Long
Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) models for
real-time scour forecasting using data collected from bridges in Alaska and
Oregon from 2006 to 2021. The LSTM models achieved mean absolute error (MAE)
ranging from 0.1m to 0.5m for predicting bed level variations a week in
advance, showing a reasonable performance. The Fully Convolutional Network
(FCN) variant of CNN outperformed other CNN configurations, showing a
comparable performance to LSTMs with significantly lower computational costs.
We explored various innovative random-search heuristics for hyperparameter
tuning and model optimisation which resulted in reduced computational cost
compared to grid-search method. The impact of different combinations of sensor
features on scour prediction showed the significance of the historical time
series of scour for predicting upcoming events. Overall, this study provides a
greater understanding of the potential of Deep Learning algorithms for
real-time scour prediction and early warning for bridges with distinct geology,
geomorphology and flow characteristics.",2024-04-25,"Tahrima Hashem, Negin Yousefpour",http://arxiv.org/pdf/2404.16549v2,cs.LG
Global Concept Explanations for Graphs by Contrastive Learning,"Beyond improving trust and validating model fairness, xAI practices also have
the potential to recover valuable scientific insights in application domains
where little to no prior human intuition exists. To that end, we propose a
method to extract global concept explanations from the predictions of graph
neural networks to develop a deeper understanding of the tasks underlying
structure-property relationships. We identify concept explanations as dense
clusters in the self-explaining Megan models subgraph latent space. For each
concept, we optimize a representative prototype graph and optionally use GPT-4
to provide hypotheses about why each structure has a certain effect on the
prediction. We conduct computational experiments on synthetic and real-world
graph property prediction tasks. For the synthetic tasks we find that our
method correctly reproduces the structural rules by which they were created.
For real-world molecular property regression and classification tasks, we find
that our method rediscovers established rules of thumb. More specifically, our
results for molecular mutagenicity prediction indicate more fine-grained
resolution of structural details than existing explainability methods,
consistent with previous results from chemistry literature. Overall, our
results show promising capability to extract the underlying structure-property
relationships for complex graph property prediction tasks.",2024-04-25,"Jonas Teufel, Pascal Friederich",http://arxiv.org/pdf/2404.16532v1,cs.LG
A Deep Learning-Driven Pipeline for Differentiating Hypertrophic Cardiomyopathy from Cardiac Amyloidosis Using 2D Multi-View Echocardiography,"Hypertrophic cardiomyopathy (HCM) and cardiac amyloidosis (CA) are both heart
conditions that can progress to heart failure if untreated. They exhibit
similar echocardiographic characteristics, often leading to diagnostic
challenges. This paper introduces a novel multi-view deep learning approach
that utilizes 2D echocardiography for differentiating between HCM and CA. The
method begins by classifying 2D echocardiography data into five distinct
echocardiographic views: apical 4-chamber, parasternal long axis of left
ventricle, parasternal short axis at levels of the mitral valve, papillary
muscle, and apex. It then extracts features of each view separately and
combines five features for disease classification. A total of 212 patients
diagnosed with HCM, and 30 patients diagnosed with CA, along with 200
individuals with normal cardiac function(Normal), were enrolled in this study
from 2018 to 2022. This approach achieved a precision, recall of 0.905, and
micro-F1 score of 0.904, demonstrating its effectiveness in accurately
identifying HCM and CA using a multi-view analysis.",2024-04-25,"Bo Peng, Xiaofeng Li, Xinyu Li, Zhenghan Wang, Hui Deng, Xiaoxian Luo, Lixue Yin, Hongmei Zhang",http://arxiv.org/pdf/2404.16522v1,cs.LG
Unbiased Estimating Equation on Inverse Divergence and Its Conditions,"This paper focuses on the Bregman divergence defined by the reciprocal
function, called the inverse divergence. For the loss function defined by the
monotonically increasing function $f$ and inverse divergence, the conditions
for the statistical model and function $f$ under which the estimating equation
is unbiased are clarified. Specifically, we characterize two types of
statistical models, an inverse Gaussian type and a mixture of generalized
inverse Gaussian type distributions, to show that the conditions for the
function $f$ are different for each model. We also define Bregman divergence as
a linear sum over the dimensions of the inverse divergence and extend the
results to the multi-dimensional case.",2024-04-25,"Masahiro Kobayashi, Kazuho Watanabe",http://arxiv.org/pdf/2404.16519v1,cs.LG
Efficient algorithms for regularized Poisson Non-negative Matrix Factorization,"We consider the problem of regularized Poisson Non-negative Matrix
Factorization (NMF) problem, encompassing various regularization terms such as
Lipschitz and relatively smooth functions, alongside linear constraints. This
problem holds significant relevance in numerous Machine Learning applications,
particularly within the domain of physical linear unmixing problems. A notable
challenge arises from the main loss term in the Poisson NMF problem being a KL
divergence, which is non-Lipschitz, rendering traditional gradient
descent-based approaches inefficient. In this contribution, we explore the
utilization of Block Successive Upper Minimization (BSUM) to overcome this
challenge. We build approriate majorizing function for Lipschitz and relatively
smooth functions, and show how to introduce linear constraints into the
problem. This results in the development of two novel algorithms for
regularized Poisson NMF. We conduct numerical simulations to showcase the
effectiveness of our approach.",2024-04-25,"Nathanaël Perraudin, Adrien Teutrie, Cécile Hébert, Guillaume Obozinski",http://arxiv.org/pdf/2404.16505v1,cs.LG
Probabilistic Multi-Layer Perceptrons for Wind Farm Condition Monitoring,"We provide a condition monitoring system for wind farms, based on normal
behaviour modelling using a probabilistic multi-layer perceptron with transfer
learning via fine-tuning. The model predicts the output power of the wind
turbine under normal behaviour based on features retrieved from supervisory
control and data acquisition (SCADA) systems. Its advantages are that (i) it
can be trained with SCADA data of at least a few years, (ii) it can incorporate
all SCADA data of all wind turbines in a wind farm as features, (iii) it
assumes that the output power follows a normal density with heteroscedastic
variance and (iv) it can predict the output of one wind turbine by borrowing
strength from the data of all other wind turbines in a farm. Probabilistic
guidelines for condition monitoring are given via a cumulative sum (CUSUM)
control chart, which is specifically designed based on a real-data
classification exercise and, hence, is adapted to the needs of a wind farm. We
illustrate the performance of our model in a real SCADA data example which
provides evidence that it outperforms other probabilistic prediction models.",2024-04-25,"Filippo Fiocchi, Domna Ladopoulou, Petros Dellaportas",http://arxiv.org/pdf/2404.16496v2,cs.LG
T-Explainer: A Model-Agnostic Explainability Framework Based on Gradients,"The development of machine learning applications has increased significantly
in recent years, motivated by the remarkable ability of learning-powered
systems to discover and generalize intricate patterns hidden in massive
datasets. Modern learning models, while powerful, often exhibit a complexity
level that renders them opaque black boxes, lacking transparency and hindering
our understanding of their decision-making processes. Opacity challenges the
practical application of machine learning, especially in critical domains
requiring informed decisions. Explainable Artificial Intelligence (XAI)
addresses that challenge, unraveling the complexity of black boxes by providing
explanations. Feature attribution/importance XAI stands out for its ability to
delineate the significance of input features in predictions. However, most
attribution methods have limitations, such as instability, when divergent
explanations result from similar or the same instance. This work introduces
T-Explainer, a novel additive attribution explainer based on the Taylor
expansion that offers desirable properties such as local accuracy and
consistency. We demonstrate T-Explainer's effectiveness and stability over
multiple runs in quantitative benchmark experiments against well-known
attribution methods. Additionally, we provide several tools to evaluate and
visualize explanations, turning T-Explainer into a comprehensive XAI framework.",2024-04-25,"Evandro S. Ortigossa, Fábio F. Dias, Brian Barr, Claudio T. Silva, Luis Gustavo Nonato",http://arxiv.org/pdf/2404.16495v3,cs.LG
Sensor Data Augmentation from Skeleton Pose Sequences for Improving Human Activity Recognition,"The proliferation of deep learning has significantly advanced various fields,
yet Human Activity Recognition (HAR) has not fully capitalized on these
developments, primarily due to the scarcity of labeled datasets. Despite the
integration of advanced Inertial Measurement Units (IMUs) in ubiquitous
wearable devices like smartwatches and fitness trackers, which offer
self-labeled activity data from users, the volume of labeled data remains
insufficient compared to domains where deep learning has achieved remarkable
success. Addressing this gap, in this paper, we propose a novel approach to
improve wearable sensor-based HAR by introducing a pose-to-sensor network model
that generates sensor data directly from 3D skeleton pose sequences. our method
simultaneously trains the pose-to-sensor network and a human activity
classifier, optimizing both data reconstruction and activity recognition. Our
contributions include the integration of simultaneous training, direct
pose-to-sensor generation, and a comprehensive evaluation on the MM-Fit
dataset. Experimental results demonstrate the superiority of our framework with
significant performance improvements over baseline methods.",2024-04-25,"Parham Zolfaghari, Vitor Fortes Rey, Lala Ray, Hyun Kim, Sungho Suh, Paul Lukowicz",http://arxiv.org/pdf/2406.16886v1,cs.LG
Decoder Decomposition for the Analysis of the Latent Space of Nonlinear Autoencoders With Wind-Tunnel Experimental Data,"Turbulent flows are chaotic and multi-scale dynamical systems, which have
large numbers of degrees of freedom. Turbulent flows, however, can be modelled
with a smaller number of degrees of freedom when using the appropriate
coordinate system, which is the goal of dimensionality reduction via nonlinear
autoencoders. Autoencoders are expressive tools, but they are difficult to
interpret. The goal of this paper is to propose a method to aid the
interpretability of autoencoders. This is the decoder decomposition. First, we
propose the decoder decomposition, which is a post-processing method to connect
the latent variables to the coherent structures of flows. Second, we apply the
decoder decomposition to analyse the latent space of synthetic data of a
two-dimensional unsteady wake past a cylinder. We find that the dimension of
latent space has a significant impact on the interpretability of autoencoders.
We identify the physical and spurious latent variables. Third, we apply the
decoder decomposition to the latent space of wind-tunnel experimental data of a
three-dimensional turbulent wake past a bluff body. We show that the
reconstruction error is a function of both the latent space dimension and the
decoder size, which are correlated. Finally, we apply the decoder decomposition
to rank and select latent variables based on the coherent structures that they
represent. This is useful to filter unwanted or spurious latent variables, or
to pinpoint specific coherent structures of interest. The ability to rank and
select latent variables will help users design and interpret nonlinear
autoencoders.",2024-04-25,"Yaxin Mo, Tullio Traverso, Luca Magri",http://arxiv.org/pdf/2404.19660v1,cs.LG
SoK: Behind the Accuracy of Complex Human Activity Recognition Using Deep Learning,"Human Activity Recognition (HAR) is a well-studied field with research dating
back to the 1980s. Over time, HAR technologies have evolved significantly from
manual feature extraction, rule-based algorithms, and simple machine learning
models to powerful deep learning models, from one sensor type to a diverse
array of sensing modalities. The scope has also expanded from recognising a
limited set of activities to encompassing a larger variety of both simple and
complex activities. However, there still exist many challenges that hinder
advancement in complex activity recognition using modern deep learning methods.
In this paper, we comprehensively systematise factors leading to inaccuracy in
complex HAR, such as data variety and model capacity. Among many sensor types,
we give more attention to wearable and camera due to their prevalence. Through
this Systematisation of Knowledge (SoK) paper, readers can gain a solid
understanding of the development history and existing challenges of HAR,
different categorisations of activities, obstacles in deep learning-based
complex HAR that impact accuracy, and potential research directions.",2024-04-25,"Duc-Anh Nguyen, Nhien-An Le-Khac",http://arxiv.org/pdf/2405.00712v2,cs.LG
A Dual Perspective of Reinforcement Learning for Imposing Policy Constraints,"Model-free reinforcement learning methods lack an inherent mechanism to
impose behavioural constraints on the trained policies. Although certain
extensions exist, they remain limited to specific types of constraints, such as
value constraints with additional reward signals or visitation density
constraints. In this work we unify these existing techniques and bridge the gap
with classical optimization and control theory, using a generic primal-dual
framework for value-based and actor-critic reinforcement learning methods. The
obtained dual formulations turn out to be especially useful for imposing
additional constraints on the learned policy, as an intrinsic relationship
between such dual constraints (or regularization terms) and reward
modifications in the primal is revealed. Furthermore, using this framework, we
are able to introduce some novel types of constraints, allowing to impose
bounds on the policy's action density or on costs associated with transitions
between consecutive states and actions. From the adjusted primal-dual
optimization problems, a practical algorithm is derived that supports various
combinations of policy constraints that are automatically handled throughout
training using trainable reward modifications. The proposed $\texttt{DualCRL}$
method is examined in more detail and evaluated under different (combinations
of) constraints on two interpretable environments. The results highlight the
efficacy of the method, which ultimately provides the designer of such systems
with a versatile toolbox of possible policy constraints.",2024-04-25,"Bram De Cooman, Johan Suykens",http://arxiv.org/pdf/2404.16468v2,cs.LG
Automating the Discovery of Partial Differential Equations in Dynamical Systems,"Identifying partial differential equations (PDEs) from data is crucial for
understanding the governing mechanisms of natural phenomena, yet it remains a
challenging task. We present an extension to the ARGOS framework, ARGOS-RAL,
which leverages sparse regression with the recurrent adaptive lasso to identify
PDEs from limited prior knowledge automatically. Our method automates
calculating partial derivatives, constructing a candidate library, and
estimating a sparse model. We rigorously evaluate the performance of ARGOS-RAL
in identifying canonical PDEs under various noise levels and sample sizes,
demonstrating its robustness in handling noisy and non-uniformly distributed
data. We also test the algorithm's performance on datasets consisting solely of
random noise to simulate scenarios with severely compromised data quality. Our
results show that ARGOS-RAL effectively and reliably identifies the underlying
PDEs from data, outperforming the sequential threshold ridge regression method
in most cases. We highlight the potential of combining statistical methods,
machine learning, and dynamical systems theory to automatically discover
governing equations from collected data, streamlining the scientific modeling
process.",2024-04-25,"Weizhen Li, Rui Carvalho",http://arxiv.org/pdf/2404.16444v2,cs.LG
"Leveraging tropical reef, bird and unrelated sounds for superior transfer learning in marine bioacoustics","Machine learning has the potential to revolutionize passive acoustic
monitoring (PAM) for ecological assessments. However, high annotation and
compute costs limit the field's efficacy. Generalizable pretrained networks can
overcome these costs, but high-quality pretraining requires vast annotated
libraries, limiting its current applicability primarily to bird taxa. Here, we
identify the optimum pretraining strategy for a data-deficient domain using
coral reef bioacoustics. We assemble ReefSet, a large annotated library of reef
sounds, though modest compared to bird libraries at 2% of the sample count.
Through testing few-shot transfer learning performance, we observe that
pretraining on bird audio provides notably superior generalizability compared
to pretraining on ReefSet or unrelated audio alone. However, our key findings
show that cross-domain mixing which leverages bird, reef and unrelated audio
during pretraining maximizes reef generalizability. SurfPerch, our pretrained
network, provides a strong foundation for automated analysis of marine PAM data
with minimal annotation and compute costs.",2024-04-25,"Ben Williams, Bart van Merriënboer, Vincent Dumoulin, Jenny Hamer, Eleni Triantafillou, Abram B. Fleishman, Matthew McKown, Jill E. Munger, Aaron N. Rice, Ashlee Lillis, Clemency E. White, Catherine A. D. Hobbs, Tries B. Razak, Kate E. Jones, Tom Denton",http://arxiv.org/pdf/2404.16436v2,cs.LG
Space-Variant Total Variation boosted by learning techniques in few-view tomographic imaging,"This paper focuses on the development of a space-variant regularization model
for solving an under-determined linear inverse problem. The case study is a
medical image reconstruction from few-view tomographic noisy data. The primary
objective of the proposed optimization model is to achieve a good balance
between denoising and the preservation of fine details and edges, overcoming
the performance of the popular and largely used Total Variation (TV)
regularization through the application of appropriate pixel-dependent weights.
The proposed strategy leverages the role of gradient approximations for the
computation of the space-variant TV weights. For this reason, a convolutional
neural network is designed, to approximate both the ground truth image and its
gradient using an elastic loss function in its training. Additionally, the
paper provides a theoretical analysis of the proposed model, showing the
uniqueness of its solution, and illustrates a Chambolle-Pock algorithm tailored
to address the specific problem at hand. This comprehensive framework
integrates innovative regularization techniques with advanced neural network
capabilities, demonstrating promising results in achieving high-quality
reconstructions from low-sampled tomographic data.",2024-04-25,"Elena Morotti, Davide Evangelista, Andrea Sebastiani, Elena Loli Piccolomini",http://arxiv.org/pdf/2404.16900v1,cs.LG
mlr3summary: Concise and interpretable summaries for machine learning models,"This work introduces a novel R package for concise, informative summaries of
machine learning models.
  We take inspiration from the summary function for (generalized) linear models
in R, but extend it in several directions:
  First, our summary function is model-agnostic and provides a unified summary
output also for non-parametric machine learning models;
  Second, the summary output is more extensive and customizable -- it comprises
information on the dataset, model performance, model complexity, model's
estimated feature importances, feature effects, and fairness metrics;
  Third, models are evaluated based on resampling strategies for unbiased
estimates of model performances, feature importances, etc.
  Overall, the clear, structured output should help to enhance and expedite the
model selection process, making it a helpful tool for practitioners and
researchers alike.",2024-04-25,"Susanne Dandl, Marc Becker, Bernd Bischl, Giuseppe Casalicchio, Ludwig Bothmann",http://arxiv.org/pdf/2404.16899v1,cs.LG
Constructing Optimal Noise Channels for Enhanced Robustness in Quantum Machine Learning,"With the rapid advancement of Quantum Machine Learning (QML), the critical
need to enhance security measures against adversarial attacks and protect QML
models becomes increasingly evident. In this work, we outline the connection
between quantum noise channels and differential privacy (DP), by constructing a
family of noise channels which are inherently $\epsilon$-DP: $(\alpha,
\gamma)$-channels. Through this approach, we successfully replicate the
$\epsilon$-DP bounds observed for depolarizing and random rotation channels,
thereby affirming the broad generality of our framework. Additionally, we use a
semi-definite program to construct an optimally robust channel. In a
small-scale experimental evaluation, we demonstrate the benefits of using our
optimal noise channel over depolarizing noise, particularly in enhancing
adversarial accuracy. Moreover, we assess how the variables $\alpha$ and
$\gamma$ affect the certifiable robustness and investigate how different
encoding methods impact the classifier's robustness.",2024-04-25,"David Winderl, Nicola Franco, Jeanette Miriam Lorenz",http://arxiv.org/pdf/2404.16417v1,cs.LG
Offline Reinforcement Learning with Behavioral Supervisor Tuning,"Offline reinforcement learning (RL) algorithms are applied to learn
performant, well-generalizing policies when provided with a static dataset of
interactions. Many recent approaches to offline RL have seen substantial
success, but with one key caveat: they demand substantial per-dataset
hyperparameter tuning to achieve reported performance, which requires policy
rollouts in the environment to evaluate; this can rapidly become cumbersome.
Furthermore, substantial tuning requirements can hamper the adoption of these
algorithms in practical domains. In this paper, we present TD3 with Behavioral
Supervisor Tuning (TD3-BST), an algorithm that trains an uncertainty model and
uses it to guide the policy to select actions within the dataset support.
TD3-BST can learn more effective policies from offline datasets compared to
previous methods and achieves the best performance across challenging
benchmarks without requiring per-dataset tuning.",2024-04-25,"Padmanaba Srinivasan, William Knottenbelt",http://arxiv.org/pdf/2404.16399v2,cs.LG
Deep Learning-based Prediction of Breast Cancer Tumor and Immune Phenotypes from Histopathology,"The interactions between tumor cells and the tumor microenvironment (TME)
dictate therapeutic efficacy of radiation and many systemic therapies in breast
cancer. However, to date, there is not a widely available method to
reproducibly measure tumor and immune phenotypes for each patient's tumor.
Given this unmet clinical need, we applied multiple instance learning (MIL)
algorithms to assess activity of ten biologically relevant pathways from the
hematoxylin and eosin (H&E) slide of primary breast tumors. We employed
different feature extraction approaches and state-of-the-art model
architectures. Using binary classification, our models attained area under the
receiver operating characteristic (AUROC) scores above 0.70 for nearly all gene
expression pathways and on some cases, exceeded 0.80. Attention maps suggest
that our trained models recognize biologically relevant spatial patterns of
cell sub-populations from H&E. These efforts represent a first step towards
developing computational H&E biomarkers that reflect facets of the TME and hold
promise for augmenting precision oncology.",2024-04-25,"Tiago Gonçalves, Dagoberto Pulido-Arias, Julian Willett, Katharina V. Hoebel, Mason Cleveland, Syed Rakin Ahmed, Elizabeth Gerstner, Jayashree Kalpathy-Cramer, Jaime S. Cardoso, Christopher P. Bridge, Albert E. Kim",http://arxiv.org/pdf/2404.16397v1,cs.LG
Learning Syntax Without Planting Trees: Understanding Hierarchical Generalization in Transformers,"Transformers trained on natural language data have been shown to learn its
hierarchical structure and generalize to sentences with unseen syntactic
structures without explicitly encoding any structural bias. In this work, we
investigate sources of inductive bias in transformer models and their training
that could cause such generalization behavior to emerge. We extensively
experiment with transformer models trained on multiple synthetic datasets and
with different training objectives and show that while other objectives e.g.
sequence-to-sequence modeling, prefix language modeling, often failed to lead
to hierarchical generalization, models trained with the language modeling
objective consistently learned to generalize hierarchically. We then conduct
pruning experiments to study how transformers trained with the language
modeling objective encode hierarchical structure. When pruned, we find joint
existence of subnetworks within the model with different generalization
behaviors (subnetworks corresponding to hierarchical structure and linear
order). Finally, we take a Bayesian perspective to further uncover
transformers' preference for hierarchical generalization: We establish a
correlation between whether transformers generalize hierarchically on a dataset
and whether the simplest explanation of that dataset is provided by a
hierarchical grammar compared to regular grammars exhibiting linear
generalization.",2024-04-25,"Kabir Ahuja, Vidhisha Balachandran, Madhur Panwar, Tianxing He, Noah A. Smith, Navin Goyal, Yulia Tsvetkov",http://arxiv.org/pdf/2404.16367v3,cs.LG
Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection,"Unsupervised graph anomaly detection aims at identifying rare patterns that
deviate from the majority in a graph without the aid of labels, which is
important for a variety of real-world applications. Recent advances have
utilized Graph Neural Networks (GNNs) to learn effective node representations
by aggregating information from neighborhoods. This is motivated by the
hypothesis that nodes in the graph tend to exhibit consistent behaviors with
their neighborhoods. However, such consistency can be disrupted by graph
anomalies in multiple ways. Most existing methods directly employ GNNs to learn
representations, disregarding the negative impact of graph anomalies on GNNs,
resulting in sub-optimal node representations and anomaly detection
performance. While a few recent approaches have redesigned GNNs for graph
anomaly detection under semi-supervised label guidance, how to address the
adverse effects of graph anomalies on GNNs in unsupervised scenarios and learn
effective representations for anomaly detection are still under-explored. To
bridge this gap, in this paper, we propose a simple yet effective framework for
Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection (G3AD).
Specifically, G3AD first introduces two auxiliary networks along with
correlation constraints to guard the GNNs against inconsistent information
encoding. Furthermore, G3AD introduces an adaptive caching module to guard the
GNNs from directly reconstructing the observed graph data that contains
anomalies. Extensive experiments demonstrate that our G3AD can outperform
twenty state-of-the-art methods on both synthetic and real-world graph anomaly
datasets, with flexible generalization ability in different GNN backbones.",2024-04-25,"Yuanchen Bei, Sheng Zhou, Jinke Shi, Yao Ma, Haishuai Wang, Jiajun Bu",http://arxiv.org/pdf/2404.16366v2,cs.LG
How to Parameterize Asymmetric Quantization Ranges for Quantization-Aware Training,"This paper investigates three different parameterizations of asymmetric
uniform quantization for quantization-aware training: (1) scale and offset, (2)
minimum and maximum, and (3) beta and gamma. We perform a comprehensive
comparative analysis of these parameterizations' influence on
quantization-aware training, using both controlled experiments and real-world
large language models. Our particular focus is on their changing behavior in
response to critical training hyperparameters, bit width and learning rate.
Based on our investigation, we propose best practices to stabilize and
accelerate quantization-aware training with learnable asymmetric quantization
ranges.",2024-04-25,"Jaeseong You, Minseop Park, Kyunggeun Lee, Seokjun An, Chirag Patel, Markus Nage",http://arxiv.org/pdf/2404.16898v1,cs.LG
Evolutionary Causal Discovery with Relative Impact Stratification for Interpretable Data Analysis,"This study proposes Evolutionary Causal Discovery (ECD) for causal discovery
that tailors response variables, predictor variables, and corresponding
operators to research datasets. Utilizing genetic programming for variable
relationship parsing, the method proceeds with the Relative Impact
Stratification (RIS) algorithm to assess the relative impact of predictor
variables on the response variable, facilitating expression simplification and
enhancing the interpretability of variable relationships. ECD proposes an
expression tree to visualize the RIS results, offering a differentiated
depiction of unknown causal relationships compared to conventional causal
discovery. The ECD method represents an evolution and augmentation of existing
causal discovery methods, providing an interpretable approach for analyzing
variable relationships in complex systems, particularly in healthcare settings
with Electronic Health Record (EHR) data. Experiments on both synthetic and
real-world EHR datasets demonstrate the efficacy of ECD in uncovering patterns
and mechanisms among variables, maintaining high accuracy and stability across
different noise levels. On the real-world EHR dataset, ECD reveals the
intricate relationships between the response variable and other predictive
variables, aligning with the results of structural equation modeling and
shapley additive explanations analyses.",2024-04-25,"Ou Deng, Shoji Nishimura, Atsushi Ogihara, Qun Jin",http://arxiv.org/pdf/2404.16361v1,cs.LG
Integration of Mixture of Experts and Multimodal Generative AI in Internet of Vehicles: A Survey,"Generative AI (GAI) can enhance the cognitive, reasoning, and planning
capabilities of intelligent modules in the Internet of Vehicles (IoV) by
synthesizing augmented datasets, completing sensor data, and making sequential
decisions. In addition, the mixture of experts (MoE) can enable the distributed
and collaborative execution of AI models without performance degradation
between connected vehicles. In this survey, we explore the integration of MoE
and GAI to enable Artificial General Intelligence in IoV, which can enable the
realization of full autonomy for IoV with minimal human supervision and
applicability in a wide range of mobility scenarios, including environment
monitoring, traffic management, and autonomous driving. In particular, we
present the fundamentals of GAI, MoE, and their interplay applications in IoV.
Furthermore, we discuss the potential integration of MoE and GAI in IoV,
including distributed perception and monitoring, collaborative decision-making
and planning, and generative modeling and simulation. Finally, we present
several potential research directions for facilitating the integration.",2024-04-25,"Minrui Xu, Dusit Niyato, Jiawen Kang, Zehui Xiong, Abbas Jamalipour, Yuguang Fang, Dong In Kim, Xuemin, Shen",http://arxiv.org/pdf/2404.16356v1,cs.LG
Exploring Learngene via Stage-wise Weight Sharing for Initializing Variable-sized Models,"In practice, we usually need to build variable-sized models adapting for
diverse resource constraints in different application scenarios, where weight
initialization is an important step prior to training. The Learngene framework,
introduced recently, firstly learns one compact part termed as learngene from a
large well-trained model, after which learngene is expanded to initialize
variable-sized models. In this paper, we start from analysing the importance of
guidance for the expansion of well-trained learngene layers, inspiring the
design of a simple but highly effective Learngene approach termed SWS
(Stage-wise Weight Sharing), where both learngene layers and their learning
process critically contribute to providing knowledge and guidance for
initializing models at varying scales. Specifically, to learn learngene layers,
we build an auxiliary model comprising multiple stages where the layer weights
in each stage are shared, after which we train it through distillation.
Subsequently, we expand these learngene layers containing stage information at
their corresponding stage to initialize models of variable depths. Extensive
experiments on ImageNet-1K demonstrate that SWS achieves consistent better
performance compared to many models trained from scratch, while reducing around
6.6x total training costs. In some cases, SWS performs better only after 1
epoch tuning. When initializing variable-sized models adapting for different
resource constraints, SWS achieves better results while reducing around 20x
parameters stored to initialize these models and around 10x pre-training costs,
in contrast to the pre-training and fine-tuning approach.",2024-04-25,"Shi-Yu Xia, Wenxuan Zhu, Xu Yang, Xin Geng",http://arxiv.org/pdf/2404.16897v1,cs.LG
A Neural-Network-Based Approach for Loose-Fitting Clothing,"Since loose-fitting clothing contains dynamic modes that have proven to be
difficult to predict via neural networks, we first illustrate how to coarsely
approximate these modes with a real-time numerical algorithm specifically
designed to mimic the most important ballistic features of a classical
numerical simulation. Although there is some flexibility in the choice of the
numerical algorithm used as a proxy for full simulation, it is essential that
the stability and accuracy be independent from any time step restriction or
similar requirements in order to facilitate real-time performance. In order to
reduce the number of degrees of freedom that require approximations to their
dynamics, we simulate rigid frames and use skinning to reconstruct a rough
approximation to a desirable mesh; as one might expect, neural-network-based
skinning seems to perform better than linear blend skinning in this scenario.
Improved high frequency deformations are subsequently added to the skinned mesh
via a quasistatic neural network (QNN). In contrast to recurrent neural
networks that require a plethora of training data in order to adequately
generalize to new examples, QNNs perform well with significantly less training
data.",2024-04-25,"Yongxu Jin, Dalton Omens, Zhenglin Geng, Joseph Teran, Abishek Kumar, Kenji Tashiro, Ronald Fedkiw",http://arxiv.org/pdf/2404.16896v1,cs.LG
From Cognition to Computation: A Comparative Review of Human Attention and Transformer Architectures,"Attention is a cornerstone of human cognition that facilitates the efficient
extraction of information in everyday life. Recent developments in artificial
intelligence like the Transformer architecture also incorporate the idea of
attention in model designs. However, despite the shared fundamental principle
of selectively attending to information, human attention and the Transformer
model display notable differences, particularly in their capacity constraints,
attention pathways, and intentional mechanisms. Our review aims to provide a
comparative analysis of these mechanisms from a cognitive-functional
perspective, thereby shedding light on several open research questions. The
exploration encourages interdisciplinary efforts to derive insights from human
attention mechanisms in the pursuit of developing more generalized artificial
intelligence.",2024-04-25,"Minglu Zhao, Dehong Xu, Tao Gao",http://arxiv.org/pdf/2407.01548v1,cs.LG
FedStyle: Style-Based Federated Learning Crowdsourcing Framework for Art Commissions,"The unique artistic style is crucial to artists' occupational
competitiveness, yet prevailing Art Commission Platforms rarely support
style-based retrieval. Meanwhile, the fast-growing generative AI techniques
aggravate artists' concerns about releasing personal artworks to public
platforms. To achieve artistic style-based retrieval without exposing personal
artworks, we propose FedStyle, a style-based federated learning crowdsourcing
framework. It allows artists to train local style models and share model
parameters rather than artworks for collaboration. However, most artists
possess a unique artistic style, resulting in severe model drift among them.
FedStyle addresses such extreme data heterogeneity by having artists learn
their abstract style representations and align with the server, rather than
merely aggregating model parameters lacking semantics. Besides, we introduce
contrastive learning to meticulously construct the style representation space,
pulling artworks with similar styles closer and keeping different ones apart in
the embedding space. Extensive experiments on the proposed datasets demonstrate
the superiority of FedStyle.",2024-04-25,"Changjuan Ran, Yeting Guo, Fang Liu, Shenglan Cui, Yunfan Ye",http://arxiv.org/pdf/2404.16336v1,cs.LG
Distributionally Robust Safe Screening,"In this study, we propose a method Distributionally Robust Safe Screening
(DRSS), for identifying unnecessary samples and features within a DR covariate
shift setting. This method effectively combines DR learning, a paradigm aimed
at enhancing model robustness against variations in data distribution, with
safe screening (SS), a sparse optimization technique designed to identify
irrelevant samples and features prior to model training. The core concept of
the DRSS method involves reformulating the DR covariate-shift problem as a
weighted empirical risk minimization problem, where the weights are subject to
uncertainty within a predetermined range. By extending the SS technique to
accommodate this weight uncertainty, the DRSS method is capable of reliably
identifying unnecessary samples and features under any future distribution
within a specified range. We provide a theoretical guarantee of the DRSS method
and validate its performance through numerical experiments on both synthetic
and real-world datasets.",2024-04-25,"Hiroyuki Hanada, Satoshi Akahane, Tatsuya Aoyama, Tomonari Tanaka, Yoshito Okura, Yu Inatsu, Noriaki Hashimoto, Taro Murayama, Lee Hanju, Shinya Kojima, Ichiro Takeuchi",http://arxiv.org/pdf/2404.16328v1,cs.LG
NeuroKoopman Dynamic Causal Discovery,"In many real-world applications where the system dynamics has an underlying
interdependency among its variables (such as power grid, economics,
neuroscience, omics networks, environmental ecosystems, and others), one is
often interested in knowing whether the past values of one time series
influences the future of another, known as Granger causality, and the
associated underlying dynamics. This paper introduces a Koopman-inspired
framework that leverages neural networks for data-driven learning of the
Koopman bases, termed NeuroKoopman Dynamic Causal Discovery (NKDCD), for
reliably inferring the Granger causality along with the underlying nonlinear
dynamics. NKDCD employs an autoencoder architecture that lifts the nonlinear
dynamics to a higher dimension using data-learned bases, where the lifted time
series can be reliably modeled linearly. The lifting function, the linear
Granger causality lag matrices, and the projection function (from lifted space
to base space) are all represented as multilayer perceptrons and are all
learned simultaneously in one go. NKDCD also utilizes sparsity-inducing
penalties on the weights of the lag matrices, encouraging the model to select
only the needed causal dependencies within the data. Through extensive testing
on practically applicable datasets, it is shown that the NKDCD outperforms the
existing nonlinear Granger causality discovery approaches.",2024-04-25,"Rahmat Adesunkanmi, Balaji Sesha Srikanth Pokuri, Ratnesh Kumar",http://arxiv.org/pdf/2404.16326v1,cs.LG
Improved impedance inversion by the iterated graph Laplacian,"We introduce a data-adaptive inversion method that integrates classical or
deep learning-based approaches with iterative graph Laplacian regularization,
specifically targeting acoustic impedance inversion - a critical task in
seismic exploration. Our method initiates from an impedance estimate derived
using either traditional inversion techniques or neural network-based methods.
This initial estimate guides the construction of a graph Laplacian operator,
effectively capturing structural characteristics of the impedance profile.
Utilizing a Tikhonov-inspired variational framework with this graph-informed
prior, our approach iteratively updates and refines the impedance estimate
while continuously recalibrating the graph Laplacian. This iterative refinement
shows rapid convergence, increased accuracy, and enhanced robustness to noise
compared to initial reconstructions alone. Extensive validation performed on
synthetic and real seismic datasets across varying noise levels confirms the
effectiveness of our method. Performance evaluations include four initial
inversion methods: two classical techniques and two neural networks -
previously established in the literature.",2024-04-25,"Davide Bianchi, Florian Bossmann, Wenlong Wang, Mingming Liu",http://arxiv.org/pdf/2404.16324v2,cs.LG
FLAASH: Flexible Accelerator Architecture for Sparse High-Order Tensor Contraction,"Tensors play a vital role in machine learning (ML) and often exhibit
properties best explored while maintaining high-order. Efficiently performing
ML computations requires taking advantage of sparsity, but generalized hardware
support is challenging. This paper introduces FLAASH, a flexible and modular
accelerator design for sparse tensor contraction that achieves over 25x speedup
for a deep learning workload. Our architecture performs sparse high-order
tensor contraction by distributing sparse dot products, or portions thereof, to
numerous Sparse Dot Product Engines (SDPEs). Memory structure and job
distribution can be customized, and we demonstrate a simple approach as a proof
of concept. We address the challenges associated with control flow to navigate
data structures, high-order representation, and high-sparsity handling. The
effectiveness of our approach is demonstrated through various evaluations,
showcasing significant speedup as sparsity and order increase.",2024-04-25,"Gabriel Kulp, Andrew Ensinger, Lizhong Chen",http://arxiv.org/pdf/2404.16317v1,cs.LG
Boosting Model Resilience via Implicit Adversarial Data Augmentation,"Data augmentation plays a pivotal role in enhancing and diversifying training
data. Nonetheless, consistently improving model performance in varied learning
scenarios, especially those with inherent data biases, remains challenging. To
address this, we propose to augment the deep features of samples by
incorporating their adversarial and anti-adversarial perturbation
distributions, enabling adaptive adjustment in the learning difficulty tailored
to each sample's specific characteristics. We then theoretically reveal that
our augmentation process approximates the optimization of a surrogate loss
function as the number of augmented copies increases indefinitely. This insight
leads us to develop a meta-learning-based framework for optimizing classifiers
with this novel loss, introducing the effects of augmentation while bypassing
the explicit augmentation process. We conduct extensive experiments across four
common biased learning scenarios: long-tail learning, generalized long-tail
learning, noisy label learning, and subpopulation shift learning. The empirical
results demonstrate that our method consistently achieves state-of-the-art
performance, highlighting its broad adaptability.",2024-04-25,"Xiaoling Zhou, Wei Ye, Zhemg Lee, Rui Xie, Shikun Zhang",http://arxiv.org/pdf/2404.16307v2,cs.LG
Reinforcement Learning with Generative Models for Compact Support Sets,"Foundation models contain a wealth of information from their vast number of
training samples. However, most prior arts fail to extract this information in
a precise and efficient way for small sample sizes. In this work, we propose a
framework utilizing reinforcement learning as a control for foundation models,
allowing for the granular generation of small, focused synthetic support sets
to augment the performance of neural network models on real data classification
tasks. We first allow a reinforcement learning agent access to a novel context
based dictionary; the agent then uses this dictionary with a novel prompt
structure to form and optimize prompts as inputs to generative models,
receiving feedback based on a reward function combining the change in
validation accuracy and entropy. A support set is formed this way over several
exploration steps. Our framework produced excellent results, increasing
classification accuracy by significant margins for no additional labelling or
data cost.",2024-04-25,"Nico Schiavone, Xingyu Li",http://arxiv.org/pdf/2404.16300v1,cs.LG
One Noise to Rule Them All: Learning a Unified Model of Spatially-Varying Noise Patterns,"Procedural noise is a fundamental component of computer graphics pipelines,
offering a flexible way to generate textures that exhibit ""natural"" random
variation. Many different types of noise exist, each produced by a separate
algorithm. In this paper, we present a single generative model which can learn
to generate multiple types of noise as well as blend between them. In addition,
it is capable of producing spatially-varying noise blends despite not having
access to such data for training. These features are enabled by training a
denoising diffusion model using a novel combination of data augmentation and
network conditioning techniques. Like procedural noise generators, the model's
behavior is controllable via interpretable parameters and a source of
randomness. We use our model to produce a variety of visually compelling noise
textures. We also present an application of our model to improving inverse
procedural material design; using our model in place of fixed-type noise nodes
in a procedural material graph results in higher-fidelity material
reconstructions without needing to know the type of noise in advance.",2024-04-25,"Arman Maesumi, Dylan Hu, Krishi Saripalli, Vladimir G. Kim, Matthew Fisher, Sören Pirk, Daniel Ritchie",http://arxiv.org/pdf/2404.16292v1,cs.LG
"Differentially Private Federated Learning: Servers Trustworthiness, Estimation, and Statistical Inference","Differentially private federated learning is crucial for maintaining privacy
in distributed environments. This paper investigates the challenges of
high-dimensional estimation and inference under the constraints of differential
privacy. First, we study scenarios involving an untrusted central server,
demonstrating the inherent difficulties of accurate estimation in
high-dimensional problems. Our findings indicate that the tight minimax rates
depends on the high-dimensionality of the data even with sparsity assumptions.
Second, we consider a scenario with a trusted central server and introduce a
novel federated estimation algorithm tailored for linear regression models.
This algorithm effectively handles the slight variations among models
distributed across different machines. We also propose methods for statistical
inference, including coordinate-wise confidence intervals for individual
parameters and strategies for simultaneous inference. Extensive simulation
experiments support our theoretical advances, underscoring the efficacy and
reliability of our approaches.",2024-04-25,"Zhe Zhang, Ryumei Nakada, Linjun Zhang",http://arxiv.org/pdf/2404.16287v1,cs.LG
SetCSE: Set Operations using Contrastive Learning of Sentence Embeddings,"Taking inspiration from Set Theory, we introduce SetCSE, an innovative
information retrieval framework. SetCSE employs sets to represent complex
semantics and incorporates well-defined operations for structured information
querying under the provided context. Within this framework, we introduce an
inter-set contrastive learning objective to enhance comprehension of sentence
embedding models concerning the given semantics. Furthermore, we present a
suite of operations, including SetCSE intersection, difference, and operation
series, that leverage sentence embeddings of the enhanced model for complex
sentence retrieval tasks. Throughout this paper, we demonstrate that SetCSE
adheres to the conventions of human language expressions regarding compounded
semantics, provides a significant enhancement in the discriminatory capability
of underlying sentence embedding models, and enables numerous information
retrieval tasks involving convoluted and intricate prompts which cannot be
achieved using existing querying methods.",2024-04-25,Kang Liu,http://arxiv.org/pdf/2404.17606v1,cs.LG
On TinyML and Cybersecurity: Electric Vehicle Charging Infrastructure Use Case,"As technology advances, the use of Machine Learning (ML) in cybersecurity is
becoming increasingly crucial to tackle the growing complexity of cyber
threats. While traditional ML models can enhance cybersecurity, their high
energy and resource demands limit their applications, leading to the emergence
of Tiny Machine Learning (TinyML) as a more suitable solution for
resource-constrained environments. TinyML is widely applied in areas such as
smart homes, healthcare, and industrial automation. TinyML focuses on
optimizing ML algorithms for small, low-power devices, enabling intelligent
data processing directly on edge devices. This paper provides a comprehensive
review of common challenges of TinyML techniques, such as power consumption,
limited memory, and computational constraints; it also explores potential
solutions to these challenges, such as energy harvesting, computational
optimization techniques, and transfer learning for privacy preservation. On the
other hand, this paper discusses TinyML's applications in advancing
cybersecurity for Electric Vehicle Charging Infrastructures (EVCIs) as a
representative use case. It presents an experimental case study that enhances
cybersecurity in EVCI using TinyML, evaluated against traditional ML in terms
of reduced delay and memory usage, with a slight trade-off in accuracy.
Additionally, the study includes a practical setup using the ESP32
microcontroller in the PlatformIO environment, which provides a hands-on
assessment of TinyML's application in cybersecurity for EVCI.",2024-04-25,"Fatemeh Dehrouyeh, Li Yang, Firouz Badrkhani Ajaei, Abdallah Shami",http://arxiv.org/pdf/2404.16894v3,cs.LG
Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services,"Large language models (LLMs) are now at the core of conversational AI
services such as real-time translation and chatbots, which provide live user
interaction by incrementally streaming text to the user. However, existing LLM
serving systems fail to provide good user experience because their optimization
metrics are not always aligned with user experience.
  In this paper, we first introduce and define the notion of
Quality-of-Experience (QoE) for text streaming services by considering each
user's end-to-end interaction timeline. Based on this, we propose Andes, a
QoE-aware LLM serving system that enhances user experience by ensuring that
users receive the first token promptly and subsequent tokens at a smooth,
digestible pace, even during surge periods. This is enabled by Andes's
preemptive request scheduler that dynamically prioritizes requests at the token
granularity based on each request's expected QoE gain and GPU resource usage.
Our evaluations demonstrate that, compared to state-of-the-art LLM serving
systems, Andes improves the average QoE by up to $4.7\times$ given the same GPU
resource, or saves up to 61% GPU resources while maintaining the same high QoE.",2024-04-25,"Jiachen Liu, Jae-Won Chung, Zhiyu Wu, Fan Lai, Myungjin Lee, Mosharaf Chowdhury",http://arxiv.org/pdf/2404.16283v2,cs.LG
Timely Communications for Remote Inference,"In this paper, we analyze the impact of data freshness on remote inference
systems, where a pre-trained neural network blue infers a time-varying target
(e.g., the locations of vehicles and pedestrians) based on features (e.g.,
video frames) observed at a sensing node (e.g., a camera). One might expect
that the performance of a remote inference system degrades monotonically as the
feature becomes stale. Using an information-theoretic analysis, we show that
this is true if the feature and target data sequence can be closely
approximated as a Markov chain, whereas it is not true if the data sequence is
far from being Markovian. Hence, the inference error is a function of Age of
Information (AoI), where the function could be non-monotonic. To minimize the
inference error in real-time, we propose a new ""selection-from-buffer"" model
for sending the features, which is more general than the ""generate-at-will""
model used in earlier studies. In addition, we design low-complexity scheduling
policies to improve inference performance. For single-source, single-channel
systems, we provide an optimal scheduling policy. In multi-source,
multi-channel systems, the scheduling problem becomes a multi-action restless
multi-armed bandit problem. For this setting, we design a new scheduling policy
by integrating Whittle index-based source selection and duality-based feature
selection-from-buffer algorithms. This new scheduling policy is proven to be
asymptotically optimal. These scheduling results hold for minimizing general
AoI functions (monotonic or non-monotonic). Data-driven evaluations demonstrate
the significant advantages of our proposed scheduling policies.",2024-04-25,"Md Kamran Chowdhury Shisher, Yin Sun, I-Hong Hou",http://arxiv.org/pdf/2404.16281v2,cs.LG
An Efficient Reconstructed Differential Evolution Variant by Some of the Current State-of-the-art Strategies for Solving Single Objective Bound Constrained Problems,"Complex single-objective bounded problems are often difficult to solve. In
evolutionary computation methods, since the proposal of differential evolution
algorithm in 1997, it has been widely studied and developed due to its
simplicity and efficiency. These developments include various adaptive
strategies, operator improvements, and the introduction of other search
methods. After 2014, research based on LSHADE has also been widely studied by
researchers. However, although recently proposed improvement strategies have
shown superiority over their previous generation's first performance, adding
all new strategies may not necessarily bring the strongest performance.
Therefore, we recombine some effective advances based on advanced differential
evolution variants in recent years and finally determine an effective
combination scheme to further promote the performance of differential
evolution. In this paper, we propose a strategy recombination and
reconstruction differential evolution algorithm called reconstructed
differential evolution (RDE) to solve single-objective bounded optimization
problems. Based on the benchmark suite of the 2024 IEEE Congress on
Evolutionary Computation (CEC2024), we tested RDE and several other advanced
differential evolution variants. The experimental results show that RDE has
superior performance in solving complex optimization problems.",2024-04-25,"Sichen Tao, Ruihan Zhao, Kaiyu Wang, Shangce Gao",http://arxiv.org/pdf/2404.16280v1,cs.LG
Causally Inspired Regularization Enables Domain General Representations,"Given a causal graph representing the data-generating process shared across
different domains/distributions, enforcing sufficient graph-implied conditional
independencies can identify domain-general (non-spurious) feature
representations. For the standard input-output predictive setting, we
categorize the set of graphs considered in the literature into two distinct
groups: (i) those in which the empirical risk minimizer across training domains
gives domain-general representations and (ii) those where it does not. For the
latter case (ii), we propose a novel framework with regularizations, which we
demonstrate are sufficient for identifying domain-general feature
representations without a priori knowledge (or proxies) of the spurious
features. Empirically, our proposed method is effective for both (semi)
synthetic and real-world data, outperforming other state-of-the-art methods in
average and worst-domain transfer accuracy.",2024-04-25,"Olawale Salaudeen, Sanmi Koyejo",http://arxiv.org/pdf/2404.16277v1,cs.LG
Enhancing Deep Knowledge Tracing via Diffusion Models for Personalized Adaptive Learning,"In contrast to pedagogies like evidence-based teaching, personalized adaptive
learning (PAL) distinguishes itself by closely monitoring the progress of
individual students and tailoring the learning path to their unique knowledge
and requirements. A crucial technique for effective PAL implementation is
knowledge tracing, which models students' evolving knowledge to predict their
future performance. Based on these predictions, personalized recommendations
for resources and learning paths can be made to meet individual needs. Recent
advancements in deep learning have successfully enhanced knowledge tracking
through Deep Knowledge Tracing (DKT). This paper introduces generative AI
models to further enhance DKT. Generative AI models, rooted in deep learning,
are trained to generate synthetic data, addressing data scarcity challenges in
various applications across fields such as natural language processing (NLP)
and computer vision (CV). This study aims to tackle data shortage issues in
student learning records to enhance DKT performance for PAL. Specifically, it
employs TabDDPM, a diffusion model, to generate synthetic educational records
to augment training data for enhancing DKT. The proposed method's effectiveness
is validated through extensive experiments on ASSISTments datasets. The
experimental results demonstrate that the AI-generated data by TabDDPM
significantly improves DKT performance, particularly in scenarios with small
data for training and large data for testing.",2024-04-25,"Ming Kuo, Shouvon Sarker, Lijun Qian, Yujian Fu, Xiangfang Li, Xishuang Dong",http://arxiv.org/pdf/2405.05134v1,cs.LG
OmniSearchSage: Multi-Task Multi-Entity Embeddings for Pinterest Search,"In this paper, we present OmniSearchSage, a versatile and scalable system for
understanding search queries, pins, and products for Pinterest search. We
jointly learn a unified query embedding coupled with pin and product
embeddings, leading to an improvement of $>8\%$ relevance, $>7\%$ engagement,
and $>5\%$ ads CTR in Pinterest's production search system. The main
contributors to these gains are improved content understanding, better
multi-task learning, and real-time serving. We enrich our entity
representations using diverse text derived from image captions from a
generative LLM, historical engagement, and user-curated boards. Our multitask
learning setup produces a single search query embedding in the same space as
pin and product embeddings and compatible with pre-existing pin and product
embeddings. We show the value of each feature through ablation studies, and
show the effectiveness of a unified model compared to standalone counterparts.
Finally, we share how these embeddings have been deployed across the Pinterest
search stack, from retrieval to ranking, scaling to serve $300k$ requests per
second at low latency. Our implementation of this work is available at
https://github.com/pinterest/atg-research/tree/main/omnisearchsage.",2024-04-25,"Prabhat Agarwal, Minhazul Islam Sk, Nikil Pancha, Kurchi Subhra Hazra, Jiajing Xu, Chuck Rosenberg",http://arxiv.org/pdf/2404.16260v1,cs.LG
Automatic AI controller that can drive with confidence: steering vehicle with uncertainty knowledge,"In safety-critical systems that interface with the real world, the role of
uncertainty in decision-making is pivotal, particularly in the context of
machine learning models. For the secure functioning of Cyber-Physical Systems
(CPS), it is imperative to manage such uncertainty adeptly. In this research,
we focus on the development of a vehicle's lateral control system using a
machine learning framework. Specifically, we employ a Bayesian Neural Network
(BNN), a probabilistic learning model, to address uncertainty quantification.
This capability allows us to gauge the level of confidence or uncertainty in
the model's predictions. The BNN based controller is trained using simulated
data gathered from the vehicle traversing a single track and subsequently
tested on various other tracks. We want to share two significant results:
firstly, the trained model demonstrates the ability to adapt and effectively
control the vehicle on multiple similar tracks. Secondly, the quantification of
prediction confidence integrated into the controller serves as an early-warning
system, signaling when the algorithm lacks confidence in its predictions and is
therefore susceptible to failure. By establishing a confidence threshold, we
can trigger manual intervention, ensuring that control is relinquished from the
algorithm when it operates outside of safe parameters.",2024-04-24,"Neha Kumari, Sumit Kumar. Sneha Priya, Ayush Kumar, Akash Fogla",http://arxiv.org/pdf/2404.16893v1,cs.LG
AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models,"AutoGluon-Multimodal (AutoMM) is introduced as an open-source AutoML library
designed specifically for multimodal learning. Distinguished by its exceptional
ease of use, AutoMM enables fine-tuning of foundation models with just three
lines of code. Supporting various modalities including image, text, and tabular
data, both independently and in combination, the library offers a comprehensive
suite of functionalities spanning classification, regression, object detection,
semantic matching, and image segmentation. Experiments across diverse datasets
and tasks showcases AutoMM's superior performance in basic classification and
regression tasks compared to existing AutoML tools, while also demonstrating
competitive results in advanced tasks, aligning with specialized toolboxes
designed for such purposes.",2024-04-24,"Zhiqiang Tang, Haoyang Fang, Su Zhou, Taojiannan Yang, Zihan Zhong, Tony Hu, Katrin Kirchhoff, George Karypis",http://arxiv.org/pdf/2404.16233v2,cs.LG
Homonym Sense Disambiguation in the Georgian Language,"This research proposes a novel approach to the Word Sense Disambiguation
(WSD) task in the Georgian language, based on supervised fine-tuning of a
pre-trained Large Language Model (LLM) on a dataset formed by filtering the
Georgian Common Crawls corpus. The dataset is used to train a classifier for
words with multiple senses. Additionally, we present experimental results of
using LSTM for WSD. Accurately disambiguating homonyms is crucial in natural
language processing. Georgian, an agglutinative language belonging to the
Kartvelian language family, presents unique challenges in this context. The aim
of this paper is to highlight the specific problems concerning homonym
disambiguation in the Georgian language and to present our approach to solving
them. The techniques discussed in the article achieve 95% accuracy for
predicting lexical meanings of homonyms using a hand-classified dataset of over
7500 sentences.",2024-04-24,"Davit Melikidze, Alexander Gamkrelidze",http://arxiv.org/pdf/2405.00710v1,cs.LG
Efficient NAS with FaDE on Hierarchical Spaces,"Neural architecture search (NAS) is a challenging problem. Hierarchical
search spaces allow for cheap evaluations of neural network sub modules to
serve as surrogate for architecture evaluations. Yet, sometimes the hierarchy
is too restrictive or the surrogate fails to generalize. We present FaDE which
uses differentiable architecture search to obtain relative performance
predictions on finite regions of a hierarchical NAS space. The relative nature
of these ranks calls for a memory-less, batch-wise outer search algorithm for
which we use an evolutionary algorithm with pseudo-gradient descent. FaDE is
especially suited on deep hierarchical, respectively multi-cell search spaces,
which it can explore by linear instead of exponential cost and therefore
eliminates the need for a proxy search space.
  Our experiments show that firstly, FaDE-ranks on finite regions of the search
space correlate with corresponding architecture performances and secondly, the
ranks can empower a pseudo-gradient evolutionary search on the complete neural
architecture search space.",2024-04-24,"Simon Neumeyer, Julian Stier, Michael Granitzer",http://arxiv.org/pdf/2404.16218v1,cs.LG
An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape,"Deepfake or synthetic images produced using deep generative models pose
serious risks to online platforms. This has triggered several research efforts
to accurately detect deepfake images, achieving excellent performance on
publicly available deepfake datasets. In this work, we study 8 state-of-the-art
detectors and argue that they are far from being ready for deployment due to
two recent developments. First, the emergence of lightweight methods to
customize large generative models, can enable an attacker to create many
customized generators (to create deepfakes), thereby substantially increasing
the threat surface. We show that existing defenses fail to generalize well to
such \emph{user-customized generative models} that are publicly available
today. We discuss new machine learning approaches based on content-agnostic
features, and ensemble modeling to improve generalization performance against
user-customized models. Second, the emergence of \textit{vision foundation
models} -- machine learning models trained on broad data that can be easily
adapted to several downstream tasks -- can be misused by attackers to craft
adversarial deepfakes that can evade existing defenses. We propose a simple
adversarial attack that leverages existing foundation models to craft
adversarial samples \textit{without adding any adversarial noise}, through
careful semantic manipulation of the image content. We highlight the
vulnerabilities of several defenses against our attack, and explore directions
leveraging advanced foundation models and adversarial training to defend
against this new threat.",2024-04-24,"Sifat Muhammad Abdullah, Aravind Cheruvu, Shravya Kanchi, Taejoong Chung, Peng Gao, Murtuza Jadliwala, Bimal Viswanath",http://arxiv.org/pdf/2404.16212v1,cs.LG
ApisTox: a new benchmark dataset for the classification of small molecules toxicity on honey bees,"The global decline in bee populations poses significant risks to agriculture,
biodiversity, and environmental stability. To bridge the gap in existing data,
we introduce ApisTox, a comprehensive dataset focusing on the toxicity of
pesticides to honey bees (Apis mellifera). This dataset combines and leverages
data from existing sources such as ECOTOX and PPDB, providing an extensive,
consistent, and curated collection that surpasses the previous datasets.
ApisTox incorporates a wide array of data, including toxicity levels for
chemicals, details such as time of their publication in literature, and
identifiers linking them to external chemical databases. This dataset may serve
as an important tool for environmental and agricultural research, but also can
support the development of policies and practices aimed at minimizing harm to
bee populations. Finally, ApisTox offers a unique resource for benchmarking
molecular property prediction methods on agrochemical compounds, facilitating
advancements in both environmental science and cheminformatics. This makes it a
valuable tool for both academic research and practical applications in bee
conservation.",2024-04-24,"Jakub Adamczyk, Jakub Poziemski, Pawel Siedlecki",http://arxiv.org/pdf/2404.16196v3,cs.LG
Improving Multi-label Recognition using Class Co-Occurrence Probabilities,"Multi-label Recognition (MLR) involves the identification of multiple objects
within an image. To address the additional complexity of this problem, recent
works have leveraged information from vision-language models (VLMs) trained on
large text-images datasets for the task. These methods learn an independent
classifier for each object (class), overlooking correlations in their
occurrences. Such co-occurrences can be captured from the training data as
conditional probabilities between a pair of classes. We propose a framework to
extend the independent classifiers by incorporating the co-occurrence
information for object pairs to improve the performance of independent
classifiers. We use a Graph Convolutional Network (GCN) to enforce the
conditional probabilities between classes, by refining the initial estimates
derived from image and text sources obtained using VLMs. We validate our method
on four MLR datasets, where our approach outperforms all state-of-the-art
methods.",2024-04-24,"Samyak Rawlekar, Shubhang Bhatnagar, Vishnuvardhan Pogunulu Srinivasulu, Narendra Ahuja",http://arxiv.org/pdf/2404.16193v2,cs.LG
Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks,"We investigate the use of Natural Language Inference (NLI) in automating
requirements engineering tasks. In particular, we focus on three tasks:
requirements classification, identification of requirements specification
defects, and detection of conflicts in stakeholders' requirements. While
previous research has demonstrated significant benefit in using NLI as a
universal method for a broad spectrum of natural language processing tasks,
these advantages have not been investigated within the context of software
requirements engineering. Therefore, we design experiments to evaluate the use
of NLI in requirements analysis. We compare the performance of NLI with a
spectrum of approaches, including prompt-based models, conventional transfer
learning, Large Language Models (LLMs)-powered chatbot models, and
probabilistic models. Through experiments conducted under various learning
settings including conventional learning and zero-shot, we demonstrate
conclusively that our NLI method surpasses classical NLP methods as well as
other LLMs-based and chatbot models in the analysis of requirements
specifications. Additionally, we share lessons learned characterizing the
learning settings that make NLI a suitable approach for automating requirements
engineering tasks.",2024-04-24,"Mohamad Fazelnia, Viktoria Koscinski, Spencer Herzog, Mehdi Mirakhorli",http://arxiv.org/pdf/2405.05135v1,cs.LG
Pearls from Pebbles: Improved Confidence Functions for Auto-labeling,"Auto-labeling is an important family of techniques that produce labeled
training sets with minimum manual labeling. A prominent variant,
threshold-based auto-labeling (TBAL), works by finding a threshold on a model's
confidence scores above which it can accurately label unlabeled data points.
However, many models are known to produce overconfident scores, leading to poor
TBAL performance. While a natural idea is to apply off-the-shelf calibration
methods to alleviate the overconfidence issue, such methods still fall short.
Rather than experimenting with ad-hoc choices of confidence functions, we
propose a framework for studying the \emph{optimal} TBAL confidence function.
We develop a tractable version of the framework to obtain \texttt{Colander}
(Confidence functions for Efficient and Reliable Auto-labeling), a new post-hoc
method specifically designed to maximize performance in TBAL systems. We
perform an extensive empirical evaluation of our method \texttt{Colander} and
compare it against methods designed for calibration. \texttt{Colander} achieves
up to 60\% improvements on coverage over the baselines while maintaining
auto-labeling error below $5\%$ and using the same amount of labeled data as
the baselines.",2024-04-24,"Harit Vishwakarma, Reid, Chen, Sui Jiet Tay, Satya Sai Srinath Namburi, Frederic Sala, Ramya Korlakai Vinayak",http://arxiv.org/pdf/2404.16188v1,cs.LG
ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment,"Anomaly detection in industrial systems is crucial for preventing equipment
failures, ensuring risk identification, and maintaining overall system
efficiency. Traditional monitoring methods often rely on fixed thresholds and
empirical rules, which may not be sensitive enough to detect subtle changes in
system health and predict impending failures. To address this limitation, this
paper proposes, a novel Attention-based convolutional autoencoder (ABCD) for
risk detection and map the risk value derive to the maintenance planning. ABCD
learns the normal behavior of conductivity from historical data of a real-world
industrial cooling system and reconstructs the input data, identifying
anomalies that deviate from the expected patterns. The framework also employs
calibration techniques to ensure the reliability of its predictions. Evaluation
results demonstrate that with the attention mechanism in ABCD a 57.4% increase
in performance and a reduction of false alarms by 9.37% is seen compared to
without attention. The approach can effectively detect risks, the risk priority
rank mapped to maintenance, providing valuable insights for cooling system
designers and service personnel. Calibration error of 0.03% indicates that the
model is well-calibrated and enhances model's trustworthiness, enabling
informed decisions about maintenance strategies",2024-04-24,"Sarala Naidu, Ning Xiong",http://arxiv.org/pdf/2404.16183v1,cs.LG
Blind Federated Learning without initial model,"Federated learning is an emerging machine learning approach that allows the
construction of a model between several participants who hold their own private
data. This method is secure and privacy-preserving, suitable for training a
machine learning model using sensitive data from different sources, such as
hospitals. In this paper, the authors propose two innovative methodologies for
Particle Swarm Optimisation-based federated learning of Fuzzy Cognitive Maps in
a privacy-preserving way. In addition, one relevant contribution this research
includes is the lack of an initial model in the federated learning process,
making it effectively blind. This proposal is tested with several open
datasets, improving both accuracy and precision.",2024-04-24,"Jose L. Salmeron, Irina Arévalo",http://arxiv.org/pdf/2404.16180v1,cs.LG
S2DEVFMAP: Self-Supervised Learning Framework with Dual Ensemble Voting Fusion for Maximizing Anomaly Prediction in Timeseries,"Anomaly detection plays a crucial role in industrial settings, particularly
in maintaining the reliability and optimal performance of cooling systems.
Traditional anomaly detection methods often face challenges in handling diverse
data characteristics and variations in noise levels, resulting in limited
effectiveness. And yet traditional anomaly detection often relies on
application of single models. This work proposes a novel, robust approach using
five heterogeneous independent models combined with a dual ensemble fusion of
voting techniques. Diverse models capture various system behaviors, while the
fusion strategy maximizes detection effectiveness and minimizes false alarms.
Each base autoencoder model learns a unique representation of the data,
leveraging their complementary strengths to improve anomaly detection
performance. To increase the effectiveness and reliability of final anomaly
prediction, dual ensemble technique is applied. This approach outperforms in
maximizing the coverage of identifying anomalies. Experimental results on a
real-world dataset of industrial cooling system data demonstrate the
effectiveness of the proposed approach. This approach can be extended to other
industrial applications where anomaly detection is critical for ensuring system
reliability and preventing potential malfunctions.",2024-04-24,"Sarala Naidu, Ning Xiong",http://arxiv.org/pdf/2404.16179v1,cs.LG
Advancing Recommender Systems by mitigating Shilling attacks,"Considering the premise that the number of products offered grow in an
exponential fashion and the amount of data that a user can assimilate before
making a decision is relatively small, recommender systems help in categorizing
content according to user preferences. Collaborative filtering is a widely used
method for computing recommendations due to its good performance. But, this
method makes the system vulnerable to attacks which try to bias the
recommendations. These attacks, known as 'shilling attacks' are performed to
push an item or nuke an item in the system. This paper proposes an algorithm to
detect such shilling profiles in the system accurately and also study the
effects of such profiles on the recommendations.",2024-04-24,"Aditya Chichani, Juzer Golwala, Tejas Gundecha, Kiran Gawande",http://arxiv.org/pdf/2404.16177v1,cs.LG
MiMICRI: Towards Domain-centered Counterfactual Explanations of Cardiovascular Image Classification Models,"The recent prevalence of publicly accessible, large medical imaging datasets
has led to a proliferation of artificial intelligence (AI) models for
cardiovascular image classification and analysis. At the same time, the
potentially significant impacts of these models have motivated the development
of a range of explainable AI (XAI) methods that aim to explain model
predictions given certain image inputs. However, many of these methods are not
developed or evaluated with domain experts, and explanations are not
contextualized in terms of medical expertise or domain knowledge. In this
paper, we propose a novel framework and python library, MiMICRI, that provides
domain-centered counterfactual explanations of cardiovascular image
classification models. MiMICRI helps users interactively select and replace
segments of medical images that correspond to morphological structures. From
the counterfactuals generated, users can then assess the influence of each
segment on model predictions, and validate the model against known medical
facts. We evaluate this library with two medical experts. Our evaluation
demonstrates that a domain-centered XAI approach can enhance the
interpretability of model explanations, and help experts reason about models in
terms of relevant domain knowledge. However, concerns were also surfaced about
the clinical plausibility of the counterfactuals generated. We conclude with a
discussion on the generalizability and trustworthiness of the MiMICRI
framework, as well as the implications of our findings on the development of
domain-centered XAI methods for model interpretability in healthcare contexts.",2024-04-24,"Grace Guo, Lifu Deng, Animesh Tandon, Alex Endert, Bum Chul Kwon",http://arxiv.org/pdf/2404.16174v1,cs.LG
