title,summary,published,authors,pdf_url,category
REFFLY: Melody-Constrained Lyrics Editing Model,"Automatic melody-to-lyric (M2L) generation aims to create lyrics that align
with a given melody. While most previous approaches generate lyrics from
scratch, revision, editing plain text draft to fit it into the melody, offers a
much more flexible and practical alternative. This enables broad applications,
such as generating lyrics from flexible inputs (keywords, themes, or full text
that needs refining to be singable), song translation (preserving meaning
across languages while keeping the melody intact), or style transfer (adapting
lyrics to different genres). This paper introduces REFFLY (REvision Framework
For LYrics), the first revision framework for editing and generating
melody-aligned lyrics. We train the lyric revision module using our curated
synthesized melody-aligned lyrics dataset, enabling it to transform plain text
into lyrics that align with a given melody. To further enhance the revision
ability, we propose training-free heuristics aimed at preserving both semantic
meaning and musical consistency throughout the editing process. Experimental
results demonstrate the effectiveness of REFFLY across various tasks (e.g.
lyrics generation, song translation), showing that our model outperforms strong
baselines, including Lyra (Tian et al., 2023) and GPT-4, by 25% in both
musicality and text quality.",2024-08-30,"Songyan Zhao, Bingxuan Li, Yufei Tian, Nanyun Peng",http://arxiv.org/pdf/2409.00292v2,cs.CL
OnlySportsLM: Optimizing Sports-Domain Language Models with SOTA Performance under Billion Parameters,"This paper explores the potential of a small, domain-specific language model
trained exclusively on sports-related data. We investigate whether extensive
training data with specially designed small model structures can overcome model
size constraints. The study introduces the OnlySports collection, comprising
OnlySportsLM, OnlySports Dataset, and OnlySports Benchmark. Our approach
involves: 1) creating a massive 600 billion tokens OnlySports Dataset from
FineWeb, 2) optimizing the RWKV architecture for sports-related tasks,
resulting in a 196M parameters model with 20-layer, 640-dimension structure, 3)
training the OnlySportsLM on part of OnlySports Dataset, and 4) testing the
resultant model on OnlySports Benchmark. OnlySportsLM achieves a 37.62%/34.08%
accuracy improvement over previous 135M/360M state-of-the-art models and
matches the performance of larger models such as SomlLM 1.7B and Qwen 1.5B in
the sports domain. Additionally, the OnlySports collection presents a
comprehensive workflow for building high-quality, domain-specific language
models, providing a replicable blueprint for efficient AI development across
various specialized fields.",2024-08-30,"Zexin Chen, Chengxi Li, Xiangyu Xie, Parijat Dube",http://arxiv.org/pdf/2409.00286v1,cs.CL
Reframing Data Value for Large Language Models Through the Lens of Plausibility,"Data valuation seeks to answer the important question, ""How much is this data
worth?"" Existing data valuation methods have largely focused on discriminative
models, primarily examining data value through the lens of its utility in
training. However, with the push for ever-larger language models, relying on
valuation methods that require training becomes increasingly expensive and
dependent on specific techniques. We propose an alternative perspective on the
data value problem for language models, centering around the plausibility of
the data. We posit that data holds lesser value if it can be plausibly
generated by the model itself. Starting from some intuitive criteria that align
with our notions of valuable data, we develop a novel value function that is
computationally tractable and derived from first principles with provable
properties. We conduct a theoretical analysis of our value function and
evaluate it across multiple scenarios and datasets.",2024-08-30,"Mohamad Rida Rammal, Ruida Zhou, Suhas Diggavi",http://arxiv.org/pdf/2409.00284v2,cs.CL
Simple stochastic processes behind Menzerath's Law,"This paper revisits Menzerath's Law, also known as the Menzerath-Altmann Law,
which models a relationship between the length of a linguistic construct and
the average length of its constituents. Recent findings indicate that simple
stochastic processes can display Menzerathian behaviour, though existing models
fail to accurately reflect real-world data. If we adopt the basic principle
that a word can change its length in both syllables and phonemes, where the
correlation between these variables is not perfect and these changes are of a
multiplicative nature, we get bivariate log-normal distribution. The present
paper shows, that from this very simple principle, we obtain the classic
Altmann model of the Menzerath-Altmann Law. If we model the joint distribution
separately and independently from the marginal distributions, we can obtain an
even more accurate model by using a Gaussian copula. The models are confronted
with empirical data, and alternative approaches are discussed.",2024-08-30,Jiří Milička,http://arxiv.org/pdf/2409.00279v1,cs.CL
Towards a dynamical model of English vowels. Evidence from diphthongisation,"Diphthong vowels exhibit a degree of inherent dynamic change, the extent of
which can vary synchronically and diachronically, such that diphthong vowels
can become monophthongs and vice versa. Modelling this type of change requires
defining diphthongs in opposition to monophthongs. However, formulating an
explicit definition has proven elusive in acoustics and articulation, as
diphthongisation is often gradient in these domains. In this study, we consider
whether diphthong vowels form a coherent phonetic category from the
articulatory point of view. We present articulometry and acoustic data from six
speakers of Northern Anglo-English producing a full set of phonologically long
vowels. We analyse several measures of diphthongisation, all of which suggest
that diphthongs are not categorically distinct from long monophthongs. We
account for this observation with an Articulatory Phonology/Task Dynamic model
in which diphthongs and long monophthongs have a common gestural
representation, comprising two articulatory targets in each case, but they
differ according to gestural constriction and location of the component
gestures. We argue that a two-target representation for all long vowels is
independently supported by phonological weight, as well as by the nature of
historical diphthongisation and present-day dynamic vowel variation in British
English.",2024-08-30,"Patrycja Strycharczuk, Sam Kirkham, Emily Gorman, Takayuki Nagamine",http://arxiv.org/pdf/2409.00275v1,cs.CL
Finding frames with BERT: A transformer-based approach to generic news frame detection,"Framing is among the most extensively used concepts in the field of
communication science. The availability of digital data offers new
possibilities for studying how specific aspects of social reality are made more
salient in online communication but also raises challenges related to the
scaling of framing analysis and its adoption to new research areas (e.g.
studying the impact of artificial intelligence-powered systems on
representation of societally relevant issues). To address these challenges, we
introduce a transformer-based approach for generic news frame detection in
Anglophone online content. While doing so, we discuss the composition of the
training and test datasets, the model architecture, and the validation of the
approach and reflect on the possibilities and limitations of the automated
detection of generic news frames.",2024-08-30,"Vihang Jumle, Mykola Makhortykh, Maryna Sydorova, Victoria Vziatysheva",http://arxiv.org/pdf/2409.00272v1,cs.CL
Leveraging a Cognitive Model to Measure Subjective Similarity of Human and GPT-4 Written Content,"Cosine similarity between two documents can be computed using token
embeddings formed by Large Language Models (LLMs) such as GPT-4, and used to
categorize those documents across a range of uses. However, these similarities
are ultimately dependent on the corpora used to train these LLMs, and may not
reflect subjective similarity of individuals or how their biases and
constraints impact similarity metrics. This lack of cognitively-aware
personalization of similarity metrics can be particularly problematic in
educational and recommendation settings where there is a limited number of
individual judgements of category or preference, and biases can be particularly
relevant. To address this, we rely on an integration of an Instance-Based
Learning (IBL) cognitive model with LLM embeddings to develop the
Instance-Based Individualized Similarity (IBIS) metric. This similarity metric
is beneficial in that it takes into account individual biases and constraints
in a manner that is grounded in the cognitive mechanisms of decision making. To
evaluate the IBIS metric, we also introduce a dataset of human categorizations
of emails as being either dangerous (phishing) or safe (ham). This dataset is
used to demonstrate the benefits of leveraging a cognitive model to measure the
subjective similarity of human participants in an educational setting.",2024-08-30,"Tailia Malloy, Maria José Ferreira, Fei Fang, Cleotilde Gonzalez",http://arxiv.org/pdf/2409.00269v2,cs.CL
"Explainable Artificial Intelligence: A Survey of Needs, Techniques, Applications, and Future Direction","Artificial intelligence models encounter significant challenges due to their
black-box nature, particularly in safety-critical domains such as healthcare,
finance, and autonomous vehicles. Explainable Artificial Intelligence (XAI)
addresses these challenges by providing explanations for how these models make
decisions and predictions, ensuring transparency, accountability, and fairness.
Existing studies have examined the fundamental concepts of XAI, its general
principles, and the scope of XAI techniques. However, there remains a gap in
the literature as there are no comprehensive reviews that delve into the
detailed mathematical representations, design methodologies of XAI models, and
other associated aspects. This paper provides a comprehensive literature review
encompassing common terminologies and definitions, the need for XAI,
beneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI
methods in different application areas. The survey is aimed at XAI researchers,
XAI practitioners, AI model developers, and XAI beneficiaries who are
interested in enhancing the trustworthiness, transparency, accountability, and
fairness of their AI models.",2024-08-30,"Melkamu Mersha, Khang Lam, Joseph Wood, Ali AlShami, Jugal Kalita",http://arxiv.org/pdf/2409.00265v2,cs.CL
DiverseDialogue: A Methodology for Designing Chatbots with Human-Like Diversity,"Large Language Models (LLMs), which simulate human users, are frequently
employed to evaluate chatbots in applications such as tutoring and customer
service. Effective evaluation necessitates a high degree of human-like
diversity within these simulations. In this paper, we demonstrate that
conversations generated by GPT-4o mini, when used as simulated human
participants, systematically differ from those between actual humans across
multiple linguistic features. These features include topic variation, lexical
attributes, and both the average behavior and diversity (variance) of the
language used. To address these discrepancies, we propose an approach that
automatically generates prompts for user simulations by incorporating features
derived from real human interactions, such as age, gender, emotional tone, and
the topics discussed. We assess our approach using differential language
analysis combined with deep linguistic inquiry. Our method of prompt
optimization, tailored to target specific linguistic features, shows
significant improvements. Specifically, it enhances the human-likeness of LLM
chatbot conversations, increasing their linguistic diversity. On average, we
observe a 54 percent reduction in the error of average features between human
and LLM-generated conversations. This method of constructing chatbot sets with
human-like diversity holds great potential for enhancing the evaluation process
of user-facing bots.",2024-08-30,"Xiaoyu Lin, Xinkai Yu, Ankit Aich, Salvatore Giorgi, Lyle Ungar",http://arxiv.org/pdf/2409.00262v1,cs.CL
MAPWise: Evaluating Vision-Language Models for Advanced Map Queries,"Vision-language models (VLMs) excel at tasks requiring joint understanding of
visual and linguistic information. A particularly promising yet under-explored
application for these models lies in answering questions based on various kinds
of maps. This study investigates the efficacy of VLMs in answering questions
based on choropleth maps, which are widely used for data analysis and
representation. To facilitate and encourage research in this area, we introduce
a novel map-based question-answering benchmark, consisting of maps from three
geographical regions (United States, India, China), each containing 1000
questions. Our benchmark incorporates 43 diverse question templates, requiring
nuanced understanding of relative spatial relationships, intricate map
features, and complex reasoning. It also includes maps with discrete and
continuous values, encompassing variations in color-mapping, category ordering,
and stylistic patterns, enabling comprehensive analysis. We evaluate the
performance of multiple VLMs on this benchmark, highlighting gaps in their
abilities and providing insights for improving such models.",2024-08-30,"Srija Mukhopadhyay, Abhishek Rajgaria, Prerana Khatiwada, Vivek Gupta, Dan Roth",http://arxiv.org/pdf/2409.00255v1,cs.CL
Pre-Training Multimodal Hallucination Detectors with Corrupted Grounding Data,"Multimodal language models can exhibit hallucinations in their outputs, which
limits their reliability. The ability to automatically detect these errors is
important for mitigating them, but has been less explored and existing efforts
do not localize hallucinations, instead framing this as a classification task.
In this work, we first pose multimodal hallucination detection as a sequence
labeling task where models must localize hallucinated text spans and present a
strong baseline model. Given the high cost of human annotations for this task,
we propose an approach to improve the sample efficiency of these models by
creating corrupted grounding data, which we use for pre-training. Leveraging
phrase grounding data, we generate hallucinations to replace grounded spans and
create hallucinated text. Experiments show that pre-training on this data
improves sample efficiency when fine-tuning, and that the learning signal from
the grounding data plays an important role in these improvements.",2024-08-30,"Spencer Whitehead, Jacob Phillips, Sean Hendryx",http://arxiv.org/pdf/2409.00238v1,cs.CL
Can Large Language Models Address Open-Target Stance Detection?,"Stance detection (SD) identifies the text position towards a target,
typically labeled as favor, against, or none. We introduce Open-Target Stance
Detection (OTSD), the most realistic task where targets are neither seen during
training nor provided as input. We evaluate Large Language Models (LLMs) from
GPT, Gemini, Llama, and Mistral families, comparing their performance to the
only existing work, Target-Stance Extraction (TSE), which benefits from
predefined targets. Unlike TSE, OTSD removes the dependency of a predefined
list, making target generation and evaluation more challenging. We also provide
a metric for evaluating target quality that correlates well with human
judgment. Our experiments reveal that LLMs outperform TSE in target generation,
both when the real target is explicitly and not explicitly mentioned in the
text. Similarly, LLMs overall surpass TSE in stance detection for both explicit
and non-explicit cases. However, LLMs struggle in both target generation and
stance detection when the target is not explicit.",2024-08-30,"Abu Ubaida Akash, Ahmed Fahmy, Amine Trabelsi",http://arxiv.org/pdf/2409.00222v6,cs.CL
ProGRes: Prompted Generative Rescoring on ASR n-Best,"Large Language Models (LLMs) have shown their ability to improve the
performance of speech recognizers by effectively rescoring the n-best
hypotheses generated during the beam search process. However, the best way to
exploit recent generative instruction-tuned LLMs for hypothesis rescoring is
still unclear. This paper proposes a novel method that uses instruction-tuned
LLMs to dynamically expand the n-best speech recognition hypotheses with new
hypotheses generated through appropriately-prompted LLMs. Specifically, we
introduce a new zero-shot method for ASR n-best rescoring, which combines
confidence scores, LLM sequence scoring, and prompt-based hypothesis
generation. We compare Llama-3-Instruct, GPT-3.5 Turbo, and GPT-4 Turbo as
prompt-based generators with Llama-3 as sequence scorer LLM. We evaluated our
approach using different speech recognizers and observed significant relative
improvement in the word error rate (WER) ranging from 5% to 25%.",2024-08-30,"Ada Defne Tur, Adel Moumen, Mirco Ravanelli",http://arxiv.org/pdf/2409.00217v2,cs.CL
Enhancing Document-level Argument Extraction with Definition-augmented Heuristic-driven Prompting for LLMs,"Event Argument Extraction (EAE) is pivotal for extracting structured
information from unstructured text, yet it remains challenging due to the
complexity of real-world document-level EAE. We propose a novel
Definition-augmented Heuristic-driven Prompting (DHP) method to enhance the
performance of Large Language Models (LLMs) in document-level EAE. Our method
integrates argument extraction-related definitions and heuristic rules to guide
the extraction process, reducing error propagation and improving task accuracy.
We also employ the Chain-of-Thought (CoT) method to simulate human reasoning,
breaking down complex problems into manageable sub-problems. Experiments have
shown that our method achieves a certain improvement in performance over
existing prompting methods and few-shot supervised learning on document-level
EAE datasets. The DHP method enhances the generalization capability of LLMs and
reduces reliance on large annotated datasets, offering a novel research
perspective for document-level EAE.",2024-08-30,"Tongyue Sun, Jiayi Xiao",http://arxiv.org/pdf/2409.00214v1,cs.CL
Enhancing Event Reasoning in Large Language Models through Instruction Fine-Tuning with Semantic Causal Graphs,"Event detection and text reasoning have become critical applications across
various domains. While LLMs have recently demonstrated impressive progress in
reasoning abilities, they often struggle with event detection, particularly due
to the absence of training methods that consider causal relationships between
event triggers and types. To address this challenge, we propose a novel
approach for instruction fine-tuning LLMs for event detection. Our method
introduces Semantic Causal Graphs (SCGs) to capture both causal relationships
and contextual information within text. Building off of SCGs, we propose SCG
Instructions for fine-tuning LLMs by focusing on event triggers and their
relationships to event types, and employ Low-Rank Adaptation (LoRA) to help
preserve the general reasoning abilities of LLMs. Our evaluations demonstrate
that training LLMs with SCG Instructions outperforms standard instruction
fine-tuning by an average of 35.69\% on Event Trigger Classification. Notably,
our fine-tuned Mistral 7B model also outperforms GPT-4 on key event detection
metrics by an average of 31.01\% on Event Trigger Identification, 37.40\% on
Event Trigger Classification, and 16.43\% on Event Classification. We analyze
the retention of general capabilities, observing only a minimal average drop of
2.03 points across six benchmarks. This comprehensive study investigates
multiple LLMs for the event detection task across various datasets, prompting
strategies, and training approaches.",2024-08-30,"Mazal Bethany, Emet Bethany, Brandon Wherry, Cho-Yu Chiang, Nishant Vishwamitra, Anthony Rios, Peyman Najafirad",http://arxiv.org/pdf/2409.00209v1,cs.CL
The creative psychometric item generator: a framework for item generation and validation using large language models,"Increasingly, large language models (LLMs) are being used to automate
workplace processes requiring a high degree of creativity. While much prior
work has examined the creativity of LLMs, there has been little research on
whether they can generate valid creativity assessments for humans despite the
increasingly central role of creativity in modern economies. We develop a
psychometrically inspired framework for creating test items (questions) for a
classic free-response creativity test: the creative problem-solving (CPS) task.
Our framework, the creative psychometric item generator (CPIG), uses a mixture
of LLM-based item generators and evaluators to iteratively develop new prompts
for writing CPS items, such that items from later iterations will elicit more
creative responses from test takers. We find strong empirical evidence that
CPIG generates valid and reliable items and that this effect is not
attributable to known biases in the evaluation process. Our findings have
implications for employing LLMs to automatically generate valid and reliable
creativity tests for humans and AI.",2024-08-30,"Antonio Laverghetta Jr., Simone Luchini, Averie Linell, Roni Reiter-Palmon, Roger Beaty",http://arxiv.org/pdf/2409.00202v1,cs.CL
HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics,"Existing research often treats long-form videos as extended short videos,
leading to several limitations: inadequate capture of long-range dependencies,
inefficient processing of redundant information, and failure to extract
high-level semantic concepts. To address these issues, we propose a novel
approach that more accurately reflects human cognition. This paper introduces
HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics,
a model that simulates episodic memory accumulation to capture action sequences
and reinforces them with semantic knowledge dispersed throughout the video. Our
work makes two key contributions: First, we develop an Episodic COmpressor
(ECO) that efficiently aggregates crucial representations from micro to
semi-macro levels, overcoming the challenge of long-range dependencies. Second,
we propose a Semantics ReTRiever (SeTR) that enhances these aggregated
representations with semantic information by focusing on the broader context,
dramatically reducing feature dimensionality while preserving relevant
macro-level information. This addresses the issues of redundancy and lack of
high-level concept extraction. Extensive experiments demonstrate that HERMES
achieves state-of-the-art performance across multiple long-video understanding
benchmarks in both zero-shot and fully-supervised settings.",2024-08-30,"Gueter Josmy Faure, Jia-Fong Yeh, Min-Hung Chen, Hung-Ting Su, Shang-Hong Lai, Winston H. Hsu",http://arxiv.org/pdf/2408.17443v3,cs.CL
SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists,"Traditional benchmarking in NLP typically involves using static held-out test
sets. However, this approach often results in an overestimation of performance
and lacks the ability to offer comprehensive, interpretable, and dynamic
assessments of NLP models. Recently, works like DynaBench (Kiela et al., 2021)
and CheckList (Ribeiro et al., 2020) have addressed these limitations through
behavioral testing of NLP models with test types generated by a multistep
human-annotated pipeline. Unfortunately, manually creating a variety of test
types requires much human labor, often at prohibitive cost. In this work, we
propose SYNTHEVAL, a hybrid behavioral testing framework that leverages large
language models (LLMs) to generate a wide range of test types for a
comprehensive evaluation of NLP models. SYNTHEVAL first generates sentences via
LLMs using controlled generation, and then identifies challenging examples by
comparing the predictions made by LLMs with task-specific NLP models. In the
last stage, human experts investigate the challenging examples, manually design
templates, and identify the types of failures the taskspecific models
consistently exhibit. We apply SYNTHEVAL to two classification tasks, sentiment
analysis and toxic language detection, and show that our framework is effective
in identifying weaknesses of strong models on these tasks. We share our code in
https://github.com/Loreley99/SynthEval_CheckList.",2024-08-30,"Raoyuan Zhao, Abdullatif Köksal, Yihong Liu, Leonie Weissweiler, Anna Korhonen, Hinrich Schütze",http://arxiv.org/pdf/2408.17437v2,cs.CL
CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language Models,"The digitisation of historical print media archives is crucial for increasing
accessibility to contemporary records. However, the process of Optical
Character Recognition (OCR) used to convert physical records to digital text is
prone to errors, particularly in the case of newspapers and periodicals due to
their complex layouts. This paper introduces Context Leveraging OCR Correction
(CLOCR-C), which utilises the infilling and context-adaptive abilities of
transformer-based language models (LMs) to improve OCR quality. The study aims
to determine if LMs can perform post-OCR correction, improve downstream NLP
tasks, and the value of providing the socio-cultural context as part of the
correction process. Experiments were conducted using seven LMs on three
datasets: the 19th Century Serials Edition (NCSE) and two datasets from the
Overproof collection. The results demonstrate that some LMs can significantly
reduce error rates, with the top-performing model achieving over a 60\%
reduction in character error rate on the NCSE dataset. The OCR improvements
extend to downstream tasks, such as Named Entity Recognition, with increased
Cosine Named Entity Similarity. Furthermore, the study shows that providing
socio-cultural context in the prompts improves performance, while misleading
prompts lower performance. In addition to the findings, this study releases a
dataset of 91 transcribed articles from the NCSE, containing a total of 40
thousand words, to support further research in this area. The findings suggest
that CLOCR-C is a promising approach for enhancing the quality of existing
digital archives by leveraging the socio-cultural information embedded in the
LMs and the text requiring correction.",2024-08-30,Jonathan Bourne,http://arxiv.org/pdf/2408.17428v2,cs.CL
Facilitating phenotyping from clinical texts: the medkit library,"Phenotyping consists in applying algorithms to identify individuals
associated with a specific, potentially complex, trait or condition, typically
out of a collection of Electronic Health Records (EHRs). Because a lot of the
clinical information of EHRs are lying in texts, phenotyping from text takes an
important role in studies that rely on the secondary use of EHRs. However, the
heterogeneity and highly specialized aspect of both the content and form of
clinical texts makes this task particularly tedious, and is the source of time
and cost constraints in observational studies. To facilitate the development,
evaluation and reproductibility of phenotyping pipelines, we developed an
open-source Python library named medkit. It enables composing data processing
pipelines made of easy-to-reuse software bricks, named medkit operations. In
addition to the core of the library, we share the operations and pipelines we
already developed and invite the phenotyping community for their reuse and
enrichment. medkit is available at https://github.com/medkit-lib/medkit",2024-08-30,"Antoine Neuraz, Ghislain Vaillant, Camila Arias, Olivier Birot, Kim-Tam Huynh, Thibaut Fabacher, Alice Rogier, Nicolas Garcelon, Ivan Lerner, Bastien Rance, Adrien Coulet",http://arxiv.org/pdf/2409.00164v1,cs.CL
Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback,"Aligning the behavior of Large language models (LLMs) with human intentions
and values remains a critical challenge. Reinforcement learning from human
feedback (RLHF) aligns LLMs by training a reward model (RM) on human
preferences and fine-tuning the LLMs to maximize RM feedback. Despite its
effectiveness and popularity, RLHF is prone to biased local optimization. It
means RM fails to provide feedback that accurately aligns with human
preference, causing LLMs to explore unexpected generalizations, and failing to
achieve alignment objectives. To mitigate this issue, we propose a novel
\textit{sequence-to-sequence (seq2seq) reward modeling} method. Its key insight
is that learning from language feedback rather than scalar feedback improves
RLHF without additional annotations. We replaced the reward modeling target
from binary maximum likelihood estimation (MLE) with sequence MLE. This method
enables richer and fine-grained language feedback without additional
annotations, models, or training stages. Our experiments demonstrated its
effectiveness, specifically, reducing the refusal-to-response paradigm in
single-turn safety dialogues and the long-response bias in text summarization
tasks. We provide further analysis that seq2seq RM improves RLHF performance
across 2B and 7B LLMs on 3 NLP tasks, achieving an average win rate of 76.9\%.
We further show that seq2seq RM can still improve the performance of RLHF under
out-of-distribution prompts.",2024-08-30,"Jiayi Zhou, Jiaming Ji, Juntao Dai, Yaodong Yang",http://arxiv.org/pdf/2409.00162v1,cs.CL
NDP: Next Distribution Prediction as a More Broad Target,"Large language models (LLMs) trained on next-token prediction (NTP) paradigm
have demonstrated powerful capabilities. However, the existing NTP paradigm
contains several limitations, particularly related to planned task
complications and error propagation during inference. In our work, we extend
the critique of NTP, highlighting its limitation also due to training with a
narrow objective: the prediction of a sub-optimal one-hot distribution. To
support this critique, we conducted a pre-experiment treating the output
distribution from powerful LLMs as efficient world data compression. By
evaluating the similarity between the $n$-gram distribution and the one-hot
distribution with LLMs, we observed that the $n$-gram distributions align more
closely with the output distribution of LLMs. Based on this insight, we
introduce Next Distribution Prediction (NDP), which uses $n$-gram distributions
to replace the one-hot targets, enhancing learning without extra online
training time. We conducted experiments across translation, general task,
language transfer, and medical domain adaptation. Compared to NTP, NDP can
achieve up to +2.97 COMET improvement in translation tasks, +0.61 average
improvement in general tasks, and incredible +10.75 average improvement in the
medical domain. This demonstrates the concrete benefits of addressing the
target narrowing problem, pointing to a new direction for future work on
improving NTP.",2024-08-30,"Junhao Ruan, Abudukeyumu Abudula, Xinyu Liu, Bei Li, Yinqiao Li, Chenglong Wang, Yuchun Fan, Yuan Ge, Tong Xiao, Jingbo Zhu",http://arxiv.org/pdf/2408.17377v1,cs.CL
Assessing Generative Language Models in Classification Tasks: Performance and Self-Evaluation Capabilities in the Environmental and Climate Change Domain,"This paper examines the performance of two Large Language Models (LLMs),
GPT3.5 and Llama2 and one Small Language Model (SLM) Gemma, across three
different classification tasks within the climate change (CC) and environmental
domain. Employing BERT-based models as a baseline, we compare their efficacy
against these transformer-based models. Additionally, we assess the models'
self-evaluation capabilities by analyzing the calibration of verbalized
confidence scores in these text classification tasks. Our findings reveal that
while BERT-based models generally outperform both the LLMs and SLM, the
performance of the large generative models is still noteworthy. Furthermore,
our calibration analysis reveals that although Gemma is well-calibrated in
initial tasks, it thereafter produces inconsistent results; Llama is reasonably
calibrated, and GPT consistently exhibits strong calibration. Through this
research, we aim to contribute to the ongoing discussion on the utility and
effectiveness of generative LMs in addressing some of the planet's most urgent
issues, highlighting their strengths and limitations in the context of ecology
and CC.",2024-08-30,"Francesca Grasso, Stefano Locci",http://arxiv.org/pdf/2408.17362v1,cs.CL
LLMs Prompted for Graphs: Hallucinations and Generative Capabilities,"Large Language Models (LLMs) are nowadays prompted for a wide variety of
tasks. In this article, we investigate their ability in reciting and generating
graphs. We first study the ability of LLMs to regurgitate well known graphs
from the literature (e.g. Karate club or the graph atlas)4. Secondly, we
question the generative capabilities of LLMs by asking for Erdos-Renyi random
graphs. As opposed to the possibility that they could memorize some Erdos-Renyi
graphs included in their scraped training set, this second investigation aims
at studying a possible emergent property of LLMs. For both tasks, we propose a
metric to assess their errors with the lens of hallucination (i.e. incorrect
information returned as facts). We most notably find that the amplitude of
graph hallucinations can characterize the superiority of some LLMs. Indeed, for
the recitation task, we observe that graph hallucinations correlate with the
Hallucination Leaderboard, a hallucination rank that leverages 10, 000 times
more prompts to obtain its ranking. For the generation task, we find
surprisingly good and reproducible results in most of LLMs. We believe this to
constitute a starting point for more in-depth studies of this emergent
capability and a challenging benchmark for their improvements. Altogether,
these two aspects of LLMs capabilities bridge a gap between the network science
and machine learning communities.",2024-08-30,"Gurvan Richardeau, Samy Chali, Erwan Le Merrer, Camilla Penzo, Gilles Tredan",http://arxiv.org/pdf/2409.00159v3,cs.CL
Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder,"Autism Spectrum Disorder (ASD) is a lifelong condition that significantly
influencing an individual's communication abilities and their social
interactions. Early diagnosis and intervention are critical due to the profound
impact of ASD's characteristic behaviors on foundational developmental stages.
However, limitations of standardized diagnostic tools necessitate the
development of objective and precise diagnostic methodologies. This paper
proposes an end-to-end framework for automatically predicting the social
communication severity of children with ASD from raw speech data. This
framework incorporates an automatic speech recognition model, fine-tuned with
speech data from children with ASD, followed by the application of fine-tuned
pre-trained language models to generate a final prediction score. Achieving a
Pearson Correlation Coefficient of 0.6566 with human-rated scores, the proposed
method showcases its potential as an accessible and objective tool for the
assessment of ASD.",2024-08-30,"Jihyun Mun, Sunhee Kim, Minhwa Chung",http://arxiv.org/pdf/2409.00158v1,cs.CL
Impact of ChatGPT on the writing style of condensed matter physicists,"We apply a state-of-the-art difference-in-differences approach to estimate
the impact of ChatGPT's release on the writing style of condensed matter papers
on arXiv. Our analysis reveals a statistically significant improvement in the
English quality of abstracts written by non-native English speakers.
Importantly, this improvement remains robust even after accounting for other
potential factors, confirming that it can be attributed to the release of
ChatGPT. This indicates widespread adoption of the tool. Following the release
of ChatGPT, there is a significant increase in the use of unique words, while
the frequency of rare words decreases. Across language families, the changes in
writing style are significant for authors from the Latin and Ural-Altaic
groups, but not for those from the Germanic or other Indo-European groups.",2024-08-30,"Shaojun Xu, Xiaohui Ye, Mengqi Zhang, Pei Wang",http://arxiv.org/pdf/2408.17325v1,cs.CL
Modularity in Transformers: Investigating Neuron Separability & Specialization,"Transformer models are increasingly prevalent in various applications, yet
our understanding of their internal workings remains limited. This paper
investigates the modularity and task specialization of neurons within
transformer architectures, focusing on both vision (ViT) and language (Mistral
7B) models. Using a combination of selective pruning and MoEfication clustering
techniques, we analyze the overlap and specialization of neurons across
different tasks and data subsets. Our findings reveal evidence of task-specific
neuron clusters, with varying degrees of overlap between related tasks. We
observe that neuron importance patterns persist to some extent even in randomly
initialized models, suggesting an inherent structure that training refines.
Additionally, we find that neuron clusters identified through MoEfication
correspond more strongly to task-specific neurons in earlier and later layers
of the models. This work contributes to a more nuanced understanding of
transformer internals and offers insights into potential avenues for improving
model interpretability and efficiency.",2024-08-30,"Nicholas Pochinkov, Thomas Jones, Mohammed Rashidur Rahman",http://arxiv.org/pdf/2408.17324v1,cs.CL
Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering,"The use of transformer-based models is growing rapidly throughout society.
With this growth, it is important to understand how they work, and in
particular, how the attention mechanisms represent concepts. Though there are
many interpretability methods, many look at models through their neuronal
activations, which are poorly understood. We describe different lenses through
which to view neuron activations, and investigate the effectiveness in language
models and vision transformers through various methods of neural ablation: zero
ablation, mean ablation, activation resampling, and a novel approach we term
'peak ablation'. Through experimental analysis, we find that in different
regimes and models, each method can offer the lowest degradation of model
performance compared to other methods, with resampling usually causing the most
significant performance deterioration. We make our code available at
https://github.com/nickypro/investigating-ablation.",2024-08-30,"Nicholas Pochinkov, Ben Pasero, Skylar Shibayama",http://arxiv.org/pdf/2408.17322v1,cs.CL
Bridging Domain Knowledge and Process Discovery Using Large Language Models,"Discovering good process models is essential for different process analysis
tasks such as conformance checking and process improvements. Automated process
discovery methods often overlook valuable domain knowledge. This knowledge,
including insights from domain experts and detailed process documentation,
remains largely untapped during process discovery. This paper leverages Large
Language Models (LLMs) to integrate such knowledge directly into process
discovery. We use rules derived from LLMs to guide model construction, ensuring
alignment with both domain knowledge and actual process executions. By
integrating LLMs, we create a bridge between process knowledge expressed in
natural language and the discovery of robust process models, advancing process
discovery methodologies significantly. To showcase the usability of our
framework, we conducted a case study with the UWV employee insurance agency,
demonstrating its practical benefits and effectiveness.",2024-08-30,"Ali Norouzifar, Humam Kourani, Marcus Dees, Wil van der Aalst",http://arxiv.org/pdf/2408.17316v1,cs.CL
Towards Tailored Recovery of Lexical Diversity in Literary Machine Translation,"Machine translations are found to be lexically poorer than human
translations. The loss of lexical diversity through MT poses an issue in the
automatic translation of literature, where it matters not only what is written,
but also how it is written. Current methods for increasing lexical diversity in
MT are rigid. Yet, as we demonstrate, the degree of lexical diversity can vary
considerably across different novels. Thus, rather than aiming for the rigid
increase of lexical diversity, we reframe the task as recovering what is lost
in the machine translation process. We propose a novel approach that consists
of reranking translation candidates with a classifier that distinguishes
between original and translated text. We evaluate our approach on 31
English-to-Dutch book translations, and find that, for certain books, our
approach retrieves lexical diversity scores that are close to human
translation.",2024-08-30,"Esther Ploeger, Huiyuan Lai, Rik van Noord, Antonio Toral",http://arxiv.org/pdf/2408.17308v1,cs.CL
Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts,"We present a toolkit for creating low-cost Mixture-of-Domain-Experts (MOE)
from trained models. The toolkit can be used for creating a mixture from models
or from adapters. We perform extensive tests and offer guidance on defining the
architecture of the resulting MOE using the toolkit. A public repository is
available.",2024-08-30,"Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti",http://arxiv.org/pdf/2408.17280v2,cs.CL
"""Is This It?"": Towards Ecologically Valid Benchmarks for Situated Collaboration","We report initial work towards constructing ecologically valid benchmarks to
assess the capabilities of large multimodal models for engaging in situated
collaboration. In contrast to existing benchmarks, in which question-answer
pairs are generated post hoc over preexisting or synthetic datasets via
templates, human annotators, or large language models (LLMs), we propose and
investigate an interactive system-driven approach, where the questions are
generated by users in context, during their interactions with an end-to-end
situated AI system. We illustrate how the questions that arise are different in
form and content from questions typically found in existing embodied question
answering (EQA) benchmarks and discuss new real-world challenge problems
brought to the fore.",2024-08-30,"Dan Bohus, Sean Andrist, Yuwei Bao, Eric Horvitz, Ann Paradiso",http://arxiv.org/pdf/2409.10525v1,cs.CL
Speaker Tagging Correction With Non-Autoregressive Language Models,"Speech applications dealing with conversations require not only recognizing
the spoken words but also determining who spoke when. The task of assigning
words to speakers is typically addressed by merging the outputs of two separate
systems, namely, an automatic speech recognition (ASR) system and a speaker
diarization (SD) system. In practical settings, speaker diarization systems can
experience significant degradation in performance due to a variety of factors,
including uniform segmentation with a high temporal resolution, inaccurate word
timestamps, incorrect clustering and estimation of speaker numbers, as well as
background noise.
  Therefore, it is important to automatically detect errors and make
corrections if possible. We used a second-pass speaker tagging correction
system based on a non-autoregressive language model to correct mistakes in
words placed at the borders of sentences spoken by different speakers. We first
show that the employed error correction approach leads to reductions in word
diarization error rate (WDER) on two datasets: TAL and test set of Fisher.
Additionally, we evaluated our system in the Post-ASR Speaker Tagging
Correction challenge and observed significant improvements in cpWER compared to
baseline methods.",2024-08-30,"Grigor Kirakosyan, Davit Karamyan",http://arxiv.org/pdf/2409.00151v1,cs.CL
Improving Extraction of Clinical Event Contextual Properties from Electronic Health Records: A Comparative Study,"Electronic Health Records are large repositories of valuable clinical data,
with a significant portion stored in unstructured text format. This textual
data includes clinical events (e.g., disorders, symptoms, findings, medications
and procedures) in context that if extracted accurately at scale can unlock
valuable downstream applications such as disease prediction. Using an existing
Named Entity Recognition and Linking methodology, MedCAT, these identified
concepts need to be further classified (contextualised) for their relevance to
the patient, and their temporal and negated status for example, to be useful
downstream. This study performs a comparative analysis of various natural
language models for medical text classification. Extensive experimentation
reveals the effectiveness of transformer-based language models, particularly
BERT. When combined with class imbalance mitigation techniques, BERT
outperforms Bi-LSTM models by up to 28% and the baseline BERT model by up to
16% for recall of the minority classes. The method has been implemented as part
of CogStack/MedCAT framework and made available to the community for further
research.",2024-08-30,"Shubham Agarwal, Thomas Searle, Mart Ratas, Anthony Shek, James Teo, Richard Dobson",http://arxiv.org/pdf/2408.17181v1,cs.CL
Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model,"Recent advancements in audio generation have been significantly propelled by
the capabilities of Large Language Models (LLMs). The existing research on
audio LLM has primarily focused on enhancing the architecture and scale of
audio language models, as well as leveraging larger datasets, and generally,
acoustic codecs, such as EnCodec, are used for audio tokenization. However,
these codecs were originally designed for audio compression, which may lead to
suboptimal performance in the context of audio LLM. Our research aims to
address the shortcomings of current audio LLM codecs, particularly their
challenges in maintaining semantic integrity in generated audio. For instance,
existing methods like VALL-E, which condition acoustic token generation on text
transcriptions, often suffer from content inaccuracies and elevated word error
rates (WER) due to semantic misinterpretations of acoustic tokens, resulting in
word skipping and errors. To overcome these issues, we propose a
straightforward yet effective approach called X-Codec. X-Codec incorporates
semantic features from a pre-trained semantic encoder before the Residual
Vector Quantization (RVQ) stage and introduces a semantic reconstruction loss
after RVQ. By enhancing the semantic ability of the codec, X-Codec
significantly reduces WER in speech synthesis tasks and extends these benefits
to non-speech applications, including music and sound generation. Our
experiments in text-to-speech, music continuation, and text-to-sound tasks
demonstrate that integrating semantic information substantially improves the
overall performance of language models in audio generation. Our code and demo
are available (Demo: https://x-codec-audio.github.io Code:
https://github.com/zhenye234/xcodec)",2024-08-30,"Zhen Ye, Peiwen Sun, Jiahe Lei, Hongzhan Lin, Xu Tan, Zheqi Dai, Qiuqiang Kong, Jianyi Chen, Jiahao Pan, Qifeng Liu, Yike Guo, Wei Xue",http://arxiv.org/pdf/2408.17175v3,cs.CL
MaFeRw: Query Rewriting with Multi-Aspect Feedbacks for Retrieval-Augmented Large Language Models,"In a real-world RAG system, the current query often involves spoken ellipses
and ambiguous references from dialogue contexts, necessitating query rewriting
to better describe user's information needs. However, traditional context-based
rewriting has minimal enhancement on downstream generation tasks due to the
lengthy process from query rewriting to response generation. Some researchers
try to utilize reinforcement learning with generation feedback to assist the
rewriter, but these sparse rewards provide little guidance in most cases,
leading to unstable training and generation results. We find that user's needs
are also reflected in the gold document, retrieved documents and ground truth.
Therefore, by feeding back these multi-aspect dense rewards to query rewriting,
more stable and satisfactory responses can be achieved. In this paper, we
propose a novel query rewriting method MaFeRw, which improves RAG performance
by integrating multi-aspect feedback from both the retrieval process and
generated results. Specifically, we first use manual data to train a T5 model
for the rewriter initialization. Next, we design three metrics as reinforcement
learning feedback: the similarity between the rewritten query and the gold
document, the ranking metrics, and ROUGE between the generation and the ground
truth. Inspired by RLAIF, we train three kinds of reward models for the above
metrics to achieve more efficient training. Finally, we combine the scores of
these reward models as feedback, and use PPO algorithm to explore the optimal
query rewriting strategy. Experimental results on two conversational RAG
datasets demonstrate that MaFeRw achieves superior generation metrics and more
stable training compared to baselines.",2024-08-30,"Yujing Wang, Hainan Zhang, Liang Pang, Binghui Guo, Hongwei Zheng, Zhiming Zheng",http://arxiv.org/pdf/2408.17072v2,cs.CL
Novel-WD: Exploring acquisition of Novel World Knowledge in LLMs Using Prefix-Tuning,"Teaching new information to pre-trained large language models (PLM) is a
crucial but challenging task. Model adaptation techniques, such as fine-tuning
and parameter-efficient training have been shown to store new facts at a slow
rate; continual learning is an option but is costly and prone to catastrophic
forgetting. This work studies and quantifies how PLM may learn and remember new
world knowledge facts that do not occur in their pre-training corpus, which
only contains world knowledge up to a certain date. To that purpose, we first
propose Novel-WD, a new dataset consisting of sentences containing novel facts
extracted from recent Wikidata updates, along with two evaluation tasks in the
form of causal language modeling and multiple choice questions (MCQ). We make
this dataset freely available to the community, and release a procedure to
later build new versions of similar datasets with up-to-date information. We
also explore the use of prefix-tuning for novel information learning, and
analyze how much information can be stored within a given prefix. We show that
a single fact can reliably be encoded within a single prefix, and that the
prefix capacity increases with its length and with the base model size.",2024-08-30,"Maxime Méloux, Christophe Cerisara",http://arxiv.org/pdf/2408.17070v1,cs.CL
MultiMath: Bridging Visual and Mathematical Reasoning for Large Language Models,"The rapid development of large language models (LLMs) has spurred extensive
research into their domain-specific capabilities, particularly mathematical
reasoning. However, most open-source LLMs focus solely on mathematical
reasoning, neglecting the integration with visual injection, despite the fact
that many mathematical tasks rely on visual inputs such as geometric diagrams,
charts, and function plots. To fill this gap, we introduce
\textbf{MultiMath-7B}, a multimodal large language model that bridges the gap
between math and vision. \textbf{MultiMath-7B} is trained through a four-stage
process, focusing on vision-language alignment, visual and math
instruction-tuning, and process-supervised reinforcement learning. We also
construct a novel, diverse and comprehensive multimodal mathematical dataset,
\textbf{MultiMath-300K}, which spans K-12 levels with image captions and
step-wise solutions. MultiMath-7B achieves state-of-the-art (SOTA) performance
among open-source models on existing multimodal mathematical benchmarks and
also excels on text-only mathematical benchmarks. Our model and dataset are
available at
{\textcolor{blue}{\url{https://github.com/pengshuai-rin/MultiMath}}}.",2024-08-30,"Shuai Peng, Di Fu, Liangcai Gao, Xiuqin Zhong, Hongguang Fu, Zhi Tang",http://arxiv.org/pdf/2409.00147v1,cs.CL
From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs,"Training emotion recognition models has relied heavily on human annotated
data, which present diversity, quality, and cost challenges. In this paper, we
explore the potential of Large Language Models (LLMs), specifically GPT4, in
automating or assisting emotion annotation. We compare GPT4 with supervised
models and or humans in three aspects: agreement with human annotations,
alignment with human perception, and impact on model training. We find that
common metrics that use aggregated human annotations as ground truth can
underestimate the performance, of GPT-4 and our human evaluation experiment
reveals a consistent preference for GPT-4 annotations over humans across
multiple datasets and evaluators. Further, we investigate the impact of using
GPT-4 as an annotation filtering process to improve model training. Together,
our findings highlight the great potential of LLMs in emotion annotation tasks
and underscore the need for refined evaluation methodologies.",2024-08-30,"Minxue Niu, Mimansa Jaiswal, Emily Mower Provost",http://arxiv.org/pdf/2408.17026v1,cs.CL
InkubaLM: A small language model for low-resource African languages,"High-resource language models often fall short in the African context, where
there is a critical need for models that are efficient, accessible, and locally
relevant, even amidst significant computing and data constraints. This paper
introduces InkubaLM, a small language model with 0.4 billion parameters, which
achieves performance comparable to models with significantly larger parameter
counts and more extensive training data on tasks such as machine translation,
question-answering, AfriMMLU, and the AfriXnli task. Notably, InkubaLM
outperforms many larger models in sentiment analysis and demonstrates
remarkable consistency across multiple languages. This work represents a
pivotal advancement in challenging the conventional paradigm that effective
language models must rely on substantial resources. Our model and datasets are
publicly available at https://huggingface.co/lelapa to encourage research and
development on low-resource languages.",2024-08-30,"Atnafu Lambebo Tonja, Bonaventure F. P. Dossou, Jessica Ojo, Jenalea Rajab, Fadel Thior, Eric Peter Wairagala, Anuoluwapo Aremu, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, Benjamin Rosman",http://arxiv.org/pdf/2408.17024v2,cs.CL
Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling,"Self-Consistency mitigates hallucinations in Large Language Models (LLMs) by
sampling multiple reasoning paths,but it lacks a systematic approach to
determine the optimal number of samples or select the most faithful rationale.
To address this limitation, we introduce Reasoning-Aware Self-Consistency
(RASC), a novel framework that enhances sampling efficiency and reasoning
faithfulness by dynamically evaluating both outputs and rationales. RASC
assesses the quality of reasoning and the consistency of answers for each
generated sample, using these assessments to guide early stopping decisions and
rationale selection. The framework employs criteria-based stopping and weighted
majority voting, enabling more informed choices on when to halt sampling and
which rationale to select. Our comprehensive experiments across diverse
question-answering datasets demonstrate that RASC outperforms existing methods,
reducing sample usage by approximately 70% while maintaining accuracy.
Moreover, RASC facilitates the selection of high-fidelity rationales, thereby
improving the faithfulness of LLM outputs. Our approach effectively addresses
the efficiency-accuracy trade-off in LLM reasoning tasks, offering a new
perspective for more nuanced, faithful, and effective utilization of LLMs in
resource-constrained environments.",2024-08-30,"Guangya Wan, Yuqi Wu, Jie Chen, Sheng Li",http://arxiv.org/pdf/2408.17017v3,cs.CL
Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios,"Recent Text-to-SQL methods leverage large language models (LLMs) by
incorporating feedback from the database management system. While these methods
effectively address execution errors in SQL queries, they struggle with
database mismatches -- errors that do not trigger execution exceptions.
Database mismatches include issues such as condition mismatches and stricter
constraint mismatches, both of which are more prevalent in real-world
scenarios. To address these challenges, we propose a tool-assisted agent
framework for SQL inspection and refinement, equipping the LLM-based agent with
two specialized tools: a retriever and a detector, designed to diagnose and
correct SQL queries with database mismatches. These tools enhance the
capability of LLMs to handle real-world queries more effectively. We also
introduce Spider-Mismatch, a new dataset specifically constructed to reflect
the condition mismatch problems encountered in real-world scenarios.
Experimental results demonstrate that our method achieves the highest
performance on the averaged results of the Spider and Spider-Realistic datasets
in few-shot settings, and it significantly outperforms baseline methods on the
more realistic dataset, Spider-Mismatch.",2024-08-30,"Zhongyuan Wang, Richong Zhang, Zhijie Nie, Jaein Kim",http://arxiv.org/pdf/2408.16991v1,cs.CL
Dynamic Depth Decoding: Faster Speculative Decoding for LLMs,"The acceleration of Large Language Models (LLMs) with speculative decoding
provides a significant runtime improvement without any loss of accuracy.
Currently, EAGLE-2 is the state-of-the-art speculative decoding method,
improving on EAGLE with a dynamic draft tree. We introduce Dynamic Depth
Decoding (DDD), which optimises EAGLE-2's tree drafting method using a dynamic
depth. This extends the average speedup that EAGLE-2 achieves over EAGLE by
$44\%$, giving DDD an average speedup of $3.16$x.",2024-08-30,"Oscar Brown, Zhengjie Wang, Andrea Do, Nikhil Mathew, Cheng Yu",http://arxiv.org/pdf/2409.00142v1,cs.CL
MemLong: Memory-Augmented Retrieval for Long Text Modeling,"Recent advancements in Large Language Models (LLMs) have yielded remarkable
success across diverse fields. However, handling long contexts remains a
significant challenge for LLMs due to the quadratic time and space complexity
of attention mechanisms and the growing memory consumption of the key-value
cache during generation. This work introduces MemLong: Memory-Augmented
Retrieval for Long Text Generation, a method designed to enhance the
capabilities of long-context language modeling by utilizing an external
retriever for historical information retrieval. MemLong combines a
non-differentiable ``ret-mem'' module with a partially trainable decoder-only
language model and introduces a fine-grained, controllable retrieval attention
mechanism that leverages semantic-level relevant chunks. Comprehensive
evaluations on multiple long-context language modeling benchmarks demonstrate
that MemLong consistently outperforms other state-of-the-art LLMs. More
importantly, MemLong can extend the context length on a single 3090 GPU from 4k
up to 80k. Our code is available at https://github.com/Bui1dMySea/MemLong",2024-08-30,"Weijie Liu, Zecheng Tang, Juntao Li, Kehai Chen, Min Zhang",http://arxiv.org/pdf/2408.16967v1,cs.CL
UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches,"Large language models (LLMs) have shown remarkable capabilities in generating
user summaries from a long list of raw user activity data. These summaries
capture essential user information such as preferences and interests, and
therefore are invaluable for LLM-based personalization applications, such as
explainable recommender systems. However, the development of new summarization
techniques is hindered by the lack of ground-truth labels, the inherent
subjectivity of user summaries, and human evaluation which is often costly and
time-consuming. To address these challenges, we introduce \UserSumBench, a
benchmark framework designed to facilitate iterative development of LLM-based
summarization approaches. This framework offers two key components: (1) A
reference-free summary quality metric. We show that this metric is effective
and aligned with human preferences across three diverse datasets (MovieLens,
Yelp and Amazon Review). (2) A novel robust summarization method that leverages
time-hierarchical summarizer and self-critique verifier to produce high-quality
summaries while eliminating hallucination. This method serves as a strong
baseline for further innovation in summarization techniques.",2024-08-30,"Chao Wang, Neo Wu, Lin Ning, Jiaxing Wu, Luyang Liu, Jun Xie, Shawn O'Banion, Bradley Green",http://arxiv.org/pdf/2408.16966v2,cs.CL
A longitudinal sentiment analysis of Sinophobia during COVID-19 using large language models,"The COVID-19 pandemic has exacerbated xenophobia, particularly Sinophobia,
leading to widespread discrimination against individuals of Chinese descent.
Large language models (LLMs) are pre-trained deep learning models used for
natural language processing (NLP) tasks. The ability of LLMs to understand and
generate human-like text makes them particularly useful for analysing social
media data to detect and evaluate sentiments. We present a sentiment analysis
framework utilising LLMs for longitudinal sentiment analysis of the Sinophobic
sentiments expressed in X (Twitter) during the COVID-19 pandemic. The results
show a significant correlation between the spikes in Sinophobic tweets,
Sinophobic sentiments and surges in COVID-19 cases, revealing that the
evolution of the pandemic influenced public sentiment and the prevalence of
Sinophobic discourse. Furthermore, the sentiment analysis revealed a
predominant presence of negative sentiments, such as annoyance and denial,
which underscores the impact of political narratives and misinformation shaping
public opinion. The lack of empathetic sentiment which was present in previous
studies related to COVID-19 highlights the way the political narratives in
media viewed the pandemic and how it blamed the Chinese community. Our study
highlights the importance of transparent communication in mitigating xenophobic
sentiments during global crises.",2024-08-29,"Chen Wang, Rohitash Chandra",http://arxiv.org/pdf/2408.16942v1,cs.CL
Plausible-Parrots @ MSP2023: Enhancing Semantic Plausibility Modeling using Entity and Event Knowledge,"In this work, we investigate the effectiveness of injecting external
knowledge to a large language model (LLM) to identify semantic plausibility of
simple events. Specifically, we enhance the LLM with fine-grained entity types,
event types and their definitions extracted from an external knowledge base.
These knowledge are injected into our system via designed templates. We also
augment the data to balance the label distribution and adapt the task setting
to real world scenarios in which event mentions are expressed as natural
language sentences. The experimental results show the effectiveness of the
injected knowledge on modeling semantic plausibility of events. An error
analysis further emphasizes the importance of identifying non-trivial entity
and event types.",2024-08-29,"Chong Shen, Chenyue Zhou",http://arxiv.org/pdf/2408.16937v1,cs.CL
Tiny-Toxic-Detector: A compact transformer-based model for toxic content detection,"This paper presents Tiny-toxic-detector, a compact transformer-based model
designed for toxic content detection. Despite having only 2.1 million
parameters, Tiny-toxic-detector achieves competitive performance on benchmark
datasets, with 90.97% accuracy on ToxiGen and 86.98% accuracy on the Jigsaw
dataset, rivaling models over 50 times its size. This efficiency enables
deployment in resource-constrained environments, addressing the need for
effective content moderation tools that balance performance with computational
efficiency. The model architecture features 4 transformer encoder layers, each
with 2 attention heads, an embedding dimension of 64, and a feedforward
dimension of 128. Trained on both public and private datasets,
Tiny-toxic-detector demonstrates the potential of efficient, task-specific
models for addressing online toxicity. The paper covers the model architecture,
training process, performance benchmarks, and limitations, underscoring its
suitability for applications such as social media monitoring and content
moderation. By achieving results comparable to much larger models while
significantly reducing computational demands, Tiny-toxic-detector represents
progress toward more sustainable and scalable AI-driven content moderation
solutions.",2024-08-29,Michiel Kamphuis,http://arxiv.org/pdf/2409.02114v1,cs.CL
Event Extraction for Portuguese: A QA-driven Approach using ACE-2005,"Event extraction is an Information Retrieval task that commonly consists of
identifying the central word for the event (trigger) and the event's arguments.
This task has been extensively studied for English but lags behind for
Portuguese, partly due to the lack of task-specific annotated corpora. This
paper proposes a framework in which two separated BERT-based models were
fine-tuned to identify and classify events in Portuguese documents. We
decompose this task into two sub-tasks. Firstly, we use a token classification
model to detect event triggers. To extract event arguments, we train a Question
Answering model that queries the triggers about their corresponding event
argument roles. Given the lack of event annotated corpora in Portuguese, we
translated the original version of the ACE-2005 dataset (a reference in the
field) into Portuguese, producing a new corpus for Portuguese event extraction.
To accomplish this, we developed an automatic translation pipeline. Our
framework obtains F1 marks of 64.4 for trigger classification and 46.7 for
argument classification setting, thus a new state-of-the-art reference for
these tasks in Portuguese.",2024-08-29,"Luís Filipe Cunha, Ricardo Campos, Alípio Jorge",http://arxiv.org/pdf/2408.16932v1,cs.CL
ACE-2005-PT: Corpus for Event Extraction in Portuguese,"Event extraction is an NLP task that commonly involves identifying the
central word (trigger) for an event and its associated arguments in text.
ACE-2005 is widely recognised as the standard corpus in this field. While other
corpora, like PropBank, primarily focus on annotating predicate-argument
structure, ACE-2005 provides comprehensive information about the overall event
structure and semantics. However, its limited language coverage restricts its
usability. This paper introduces ACE-2005-PT, a corpus created by translating
ACE-2005 into Portuguese, with European and Brazilian variants. To speed up the
process of obtaining ACE-2005-PT, we rely on automatic translators. This,
however, poses some challenges related to automatically identifying the correct
alignments between multi-word annotations in the original text and in the
corresponding translated sentence. To achieve this, we developed an alignment
pipeline that incorporates several alignment techniques: lemmatization, fuzzy
matching, synonym matching, multiple translations and a BERT-based word
aligner. To measure the alignment effectiveness, a subset of annotations from
the ACE-2005-PT corpus was manually aligned by a linguist expert. This subset
was then compared against our pipeline results which achieved exact and relaxed
match scores of 70.55\% and 87.55\% respectively. As a result, we successfully
generated a Portuguese version of the ACE-2005 corpus, which has been accepted
for publication by LDC.",2024-08-29,"Luís Filipe Cunha, Purificação Silvano, Ricardo Campos, Alípio Jorge",http://arxiv.org/pdf/2408.16928v1,cs.CL
Exploring Multiple Strategies to Improve Multilingual Coreference Resolution in CorefUD,"Coreference resolution, the task of identifying expressions in text that
refer to the same entity, is a critical component in various natural language
processing applications. This paper presents a novel end-to-end neural
coreference resolution system utilizing the CorefUD 1.1 dataset, which spans 17
datasets across 12 languages. The proposed model is based on the standard
end-to-end neural coreference resolution system. We first establish baseline
models, including monolingual and cross-lingual variations, and then propose
several extensions to enhance performance across diverse linguistic contexts.
These extensions include cross-lingual training, incorporation of syntactic
information, a Span2Head model for optimized headword prediction, and advanced
singleton modeling. We also experiment with headword span representation and
long-documents modeling through overlapping segments. The proposed extensions,
particularly the heads-only approach, singleton modeling, and long document
prediction, significantly improve performance across most datasets. We also
perform zero-shot cross-lingual experiments, highlighting the potential and
limitations of cross-lingual transfer in coreference resolution. Our findings
contribute to the development of robust and scalable coreference systems for
multilingual coreference resolution. Finally, we evaluate our model on the
CorefUD 1.1 test set and surpass the best model from the CRAC 2023 shared task
of comparable size by a large margin.",2024-08-29,"Ondřej Pražák, Miloslav Konopík, Pavel Král",http://arxiv.org/pdf/2408.16893v3,cs.CL
LLaVA-Chef: A Multi-modal Generative Model for Food Recipes,"In the rapidly evolving landscape of online recipe sharing within a
globalized context, there has been a notable surge in research towards
comprehending and generating food recipes. Recent advancements in large
language models (LLMs) like GPT-2 and LLaVA have paved the way for Natural
Language Processing (NLP) approaches to delve deeper into various facets of
food-related tasks, encompassing ingredient recognition and comprehensive
recipe generation. Despite impressive performance and multi-modal adaptability
of LLMs, domain-specific training remains paramount for their effective
application. This work evaluates existing LLMs for recipe generation and
proposes LLaVA-Chef, a novel model trained on a curated dataset of diverse
recipe prompts in a multi-stage approach. First, we refine the mapping of
visual food image embeddings to the language space. Second, we adapt LLaVA to
the food domain by fine-tuning it on relevant recipe data. Third, we utilize
diverse prompts to enhance the model's recipe comprehension. Finally, we
improve the linguistic quality of generated recipes by penalizing the model
with a custom loss function. LLaVA-Chef demonstrates impressive improvements
over pretrained LLMs and prior works. A detailed qualitative analysis reveals
that LLaVA-Chef generates more detailed recipes with precise ingredient
mentions, compared to existing approaches.",2024-08-29,"Fnu Mohbat, Mohammed J. Zaki",http://arxiv.org/pdf/2408.16889v1,cs.CL
WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks,"Embeddings-as-a-Service (EaaS) is a service offered by large language model
(LLM) developers to supply embeddings generated by LLMs. Previous research
suggests that EaaS is prone to imitation attacks -- attacks that clone the
underlying EaaS model by training another model on the queried embeddings. As a
result, EaaS watermarks are introduced to protect the intellectual property of
EaaS providers. In this paper, we first show that existing EaaS watermarks can
be removed by paraphrasing when attackers clone the model. Subsequently, we
propose a novel watermarking technique that involves linearly transforming the
embeddings, and show that it is empirically and theoretically robust against
paraphrasing.",2024-08-29,"Anudeex Shetty, Qiongkai Xu, Jey Han Lau",http://arxiv.org/pdf/2409.04459v1,cs.CL
Modeling offensive content detection for TikTok,"The advent of social media transformed interpersonal communication and
information consumption processes. This digital landscape accommodates user
intentions, also resulting in an increase of offensive language and harmful
behavior. Concurrently, social media platforms collect vast datasets comprising
user-generated content and behavioral information. These datasets are
instrumental for platforms deploying machine learning and data-driven
strategies, facilitating customer insights and countermeasures against social
manipulation mechanisms like disinformation and offensive content.
Nevertheless, the availability of such datasets, along with the application of
various machine learning techniques, to researchers and practitioners, for
specific social media platforms regarding particular events, is limited. In
particular for TikTok, which offers unique tools for personalized content
creation and sharing, the existing body of knowledge would benefit from having
diverse comprehensive datasets and associated data analytics solutions on
offensive content. While efforts from social media platforms, research, and
practitioner communities are seen on this behalf, such content continues to
proliferate. This translates to an essential need to make datasets publicly
available and build corresponding intelligent solutions. On this behalf, this
research undertakes the collection and analysis of TikTok data containing
offensive content, building a series of machine learning and deep learning
models for offensive content detection. This is done aiming at answering the
following research question: ""How to develop a series of computational models
to detect offensive content on TikTok?"". To this end, a Data Science
methodological approach is considered, 120.423 TikTok comments are collected,
and on a balanced, binary classification approach, F1 score performance results
of 0.863 is obtained.",2024-08-29,"Kasper Cools, Gideon Mailette de Buy Wenniger, Clara Maathuis",http://arxiv.org/pdf/2408.16857v2,cs.CL
See or Guess: Counterfactually Regularized Image Captioning,"Image captioning, which generates natural language descriptions of the visual
information in an image, is a crucial task in vision-language research.
Previous models have typically addressed this task by aligning the generative
capabilities of machines with human intelligence through statistical fitting of
existing datasets. While effective for normal images, they may struggle to
accurately describe those where certain parts of the image are obscured or
edited, unlike humans who excel in such cases. These weaknesses they exhibit,
including hallucinations and limited interpretability, often hinder performance
in scenarios with shifted association patterns. In this paper, we present a
generic image captioning framework that employs causal inference to make
existing models more capable of interventional tasks, and counterfactually
explainable. Our approach includes two variants leveraging either total effect
or natural direct effect. Integrating them into the training process enables
models to handle counterfactual scenarios, increasing their generalizability.
Extensive experiments on various datasets show that our method effectively
reduces hallucinations and improves the model's faithfulness to images,
demonstrating high portability across both small-scale and large-scale
image-to-text models. The code is available at
https://github.com/Aman-4-Real/See-or-Guess.",2024-08-29,"Qian Cao, Xu Chen, Ruihua Song, Xiting Wang, Xinting Huang, Yuchen Ren",http://arxiv.org/pdf/2408.16809v1,cs.CL
SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners,"We introduce SAM2Point, a preliminary exploration adapting Segment Anything
Model 2 (SAM 2) for zero-shot and promptable 3D segmentation. SAM2Point
interprets any 3D data as a series of multi-directional videos, and leverages
SAM 2 for 3D-space segmentation, without further training or 2D-3D projection.
Our framework supports various prompt types, including 3D points, boxes, and
masks, and can generalize across diverse scenarios, such as 3D objects, indoor
scenes, outdoor environments, and raw sparse LiDAR. Demonstrations on multiple
3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight
the robust generalization capabilities of SAM2Point. To our best knowledge, we
present the most faithful implementation of SAM in 3D, which may serve as a
starting point for future research in promptable 3D segmentation. Online Demo:
https://huggingface.co/spaces/ZiyuG/SAM2Point . Code:
https://github.com/ZiyuGuo99/SAM2Point .",2024-08-29,"Ziyu Guo, Renrui Zhang, Xiangyang Zhu, Chengzhuo Tong, Peng Gao, Chunyuan Li, Pheng-Ann Heng",http://arxiv.org/pdf/2408.16768v1,cs.CL
PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in Action,"As language models (LMs) are widely utilized in personalized communication
scenarios (e.g., sending emails, writing social media posts) and endowed with a
certain level of agency, ensuring they act in accordance with the contextual
privacy norms becomes increasingly critical. However, quantifying the privacy
norm awareness of LMs and the emerging privacy risk in LM-mediated
communication is challenging due to (1) the contextual and long-tailed nature
of privacy-sensitive cases, and (2) the lack of evaluation approaches that
capture realistic application scenarios. To address these challenges, we
propose PrivacyLens, a novel framework designed to extend privacy-sensitive
seeds into expressive vignettes and further into agent trajectories, enabling
multi-level evaluation of privacy leakage in LM agents' actions. We instantiate
PrivacyLens with a collection of privacy norms grounded in privacy literature
and crowdsourced seeds. Using this dataset, we reveal a discrepancy between LM
performance in answering probing questions and their actual behavior when
executing user instructions in an agent setup. State-of-the-art LMs, like GPT-4
and Llama-3-70B, leak sensitive information in 25.68% and 38.69% of cases, even
when prompted with privacy-enhancing instructions. We also demonstrate the
dynamic nature of PrivacyLens by extending each seed into multiple trajectories
to red-team LM privacy leakage risk. Dataset and code are available at
https://github.com/SALT-NLP/PrivacyLens.",2024-08-29,"Yijia Shao, Tianshi Li, Weiyan Shi, Yanchen Liu, Diyi Yang",http://arxiv.org/pdf/2409.00138v3,cs.CL
How Well Do LLMs Handle Cantonese? Benchmarking Cantonese Capabilities of Large Language Models,"The rapid evolution of large language models (LLMs) has transformed the
competitive landscape in natural language processing (NLP), particularly for
English and other data-rich languages. However, underrepresented languages like
Cantonese, spoken by over 85 million people, face significant development gaps,
which is particularly concerning given the economic significance of the
Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial
Cantonese-speaking populations in places like Singapore and North America.
Despite its wide use, Cantonese has scant representation in NLP research,
especially compared to other languages from similarly developed regions. To
bridge these gaps, we outline current Cantonese NLP methods and introduce new
benchmarks designed to evaluate LLM performance in factual generation,
mathematical logic, complex reasoning, and general knowledge in Cantonese,
which aim to advance open-source Cantonese LLM technology. We also propose
future research directions and recommended models to enhance Cantonese LLM
development.",2024-08-29,"Jiyue Jiang, Pengan Chen, Liheng Chen, Sheng Wang, Qinghang Bao, Lingpeng Kong, Yu Li, Chuan Wu",http://arxiv.org/pdf/2408.16756v3,cs.CL
Reinforcement Learning without Human Feedback for Last Mile Fine-Tuning of Large Language Models,"Reinforcement learning is used to align language models with human preference
signals after first pre-training the model to predict the next token of text
within a large corpus using likelihood maximization. Before being deployed in a
specific domain, models are often further fine-tuned on task specific data.
Since human preferences are often unavailable for the last step, it is
performed using likelihood maximization as that is the typical default method.
However, reinforcement learning has other advantages besides facilitating
alignment to a human derived reward function. For one, whereas likelihood
maximization is a form of imitation learning in which the model is trained on
what to do under ideal conditions, reinforcement learning is not limited to
demonstrating actions just for optimally reached states and trains a model what
to do under a range of scenarios as it explores the policy space. In addition,
it also trains a model what not to do, suppressing competitive but poor
actions. This work develops a framework for last-mile fine-tuning using
reinforcement learning and tests whether it garners performance gains. The
experiments center on abstractive summarization, but the framework is general
and broadly applicable. Use of the procedure produced significantly better
results than likelihood maximization when comparing raw predictions. For the
specific data tested, the gap could be bridged by employing post-processing of
the maximum likelihood outputs. Nonetheless, the framework offers a new avenue
for model optimization in situations where post-processing may be less
straightforward or effective, and it can be extended to include more complex
classes of undesirable outputs to penalize and train against, such as
hallucinations.",2024-08-29,Alec Solway,http://arxiv.org/pdf/2408.16753v1,cs.CL
A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models,"Beyond maximum likelihood estimation (MLE), the standard objective of a
language model (LM) that optimizes good examples probabilities, many studies
have explored ways that also penalize bad examples for enhancing the quality of
output distribution, including unlikelihood training, exponential maximizing
average treatment effect (ExMATE), and direct preference optimization (DPO). To
systematically compare these methods and further provide a unified recipe for
LM optimization, in this paper, we present a unique angle of gradient analysis
of loss functions that simultaneously reward good examples and penalize bad
ones in LMs. Through both mathematical results and experiments on
CausalDialogue and Anthropic HH-RLHF datasets, we identify distinct functional
characteristics among these methods. We find that ExMATE serves as a superior
surrogate for MLE, and that combining DPO with ExMATE instead of MLE further
enhances both the statistical (5-7%) and generative (+18% win rate)
performance.",2024-08-29,"Yi-Lin Tuan, William Yang Wang",http://arxiv.org/pdf/2408.16751v1,cs.CL
"Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge","The United States has experienced a significant increase in violent
extremism, prompting the need for automated tools to detect and limit the
spread of extremist ideology online. This study evaluates the performance of
Bidirectional Encoder Representations from Transformers (BERT) and Generative
Pre-Trained Transformers (GPT) in detecting and classifying online domestic
extremist posts. We collected social media posts containing ""far-right"" and
""far-left"" ideological keywords and manually labeled them as extremist or
non-extremist. Extremist posts were further classified into one or more of five
contributing elements of extremism based on a working definitional framework.
The BERT model's performance was evaluated based on training data size and
knowledge transfer between categories. We also compared the performance of GPT
3.5 and GPT 4 models using different prompts: na\""ive, layperson-definition,
role-playing, and professional-definition. Results showed that the best
performing GPT models outperformed the best performing BERT models, with more
detailed prompts generally yielding better results. However, overly complex
prompts may impair performance. Different versions of GPT have unique
sensitives to what they consider extremist. GPT 3.5 performed better at
classifying far-left extremist posts, while GPT 4 performed better at
classifying far-right extremist posts. Large language models, represented by
GPT models, hold significant potential for online extremism classification
tasks, surpassing traditional BERT models in a zero-shot setting. Future
research should explore human-computer interactions in optimizing GPT models
for extremist detection and classification tasks to develop more efficient
(e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes)
methods for identifying extremist content.",2024-08-29,"Beidi Dong, Jin R. Lee, Ziwei Zhu, Balassubramanian Srinivasan",http://arxiv.org/pdf/2408.16749v1,cs.CL
Theoretical and Methodological Framework for Studying Texts Produced by Large Language Models,"This paper addresses the conceptual, methodological and technical challenges
in studying large language models (LLMs) and the texts they produce from a
quantitative linguistics perspective. It builds on a theoretical framework that
distinguishes between the LLM as a substrate and the entities the model
simulates. The paper advocates for a strictly non-anthropomorphic approach to
models while cautiously applying methodologies used in studying human
linguistic behavior to the simulated entities. While natural language
processing researchers focus on the models themselves, their architecture,
evaluation, and methods for improving performance, we as quantitative linguists
should strive to build a robust theory concerning the characteristics of texts
produced by LLMs, how they differ from human-produced texts, and the properties
of simulated entities. Additionally, we should explore the potential of LLMs as
an instrument for studying human culture, of which language is an integral
part.",2024-08-29,Jiří Milička,http://arxiv.org/pdf/2408.16740v1,cs.CL
"Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling","Training on high-quality synthetic data from strong language models (LMs) is
a common strategy to improve the reasoning performance of LMs. In this work, we
revisit whether this strategy is compute-optimal under a fixed inference budget
(e.g., FLOPs). To do so, we investigate the trade-offs between generating
synthetic data using a stronger but more expensive (SE) model versus a weaker
but cheaper (WC) model. We evaluate the generated data across three key
metrics: coverage, diversity, and false positive rate, and show that the data
from WC models may have higher coverage and diversity, but also exhibit higher
false positive rates. We then finetune LMs on data from SE and WC models in
different settings: knowledge distillation, self-improvement, and a novel
weak-to-strong improvement setup where a weaker LM teaches reasoning to a
stronger LM. Our findings reveal that models finetuned on WC-generated data
consistently outperform those trained on SE-generated data across multiple
benchmarks and multiple choices of WC and SE models. These results challenge
the prevailing practice of relying on SE models for synthetic data generation,
suggesting that WC may be the compute-optimal approach for training advanced LM
reasoners.",2024-08-29,"Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, Mehran Kazemi",http://arxiv.org/pdf/2408.16737v2,cs.CL
Emerging Vulnerabilities in Frontier Models: Multi-Turn Jailbreak Attacks,"Large language models (LLMs) are improving at an exceptional rate. However,
these models are still susceptible to jailbreak attacks, which are becoming
increasingly dangerous as models become increasingly powerful. In this work, we
introduce a dataset of jailbreaks where each example can be input in both a
single or a multi-turn format. We show that while equivalent in content, they
are not equivalent in jailbreak success: defending against one structure does
not guarantee defense against the other. Similarly, LLM-based filter guardrails
also perform differently depending on not just the input content but the input
structure. Thus, vulnerabilities of frontier models should be studied in both
single and multi-turn settings; this dataset provides a tool to do so.",2024-08-29,"Tom Gibbs, Ethan Kosak-Hine, George Ingebretsen, Jason Zhang, Julius Broomfield, Sara Pieri, Reihaneh Iranmanesh, Reihaneh Rabbany, Kellin Pelrine",http://arxiv.org/pdf/2409.00137v1,cs.CL
"Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming","Recent advances in language models have achieved significant progress.
GPT-4o, as a new milestone, has enabled real-time conversations with humans,
demonstrating near-human natural fluency. Such human-computer interaction
necessitates models with the capability to perform reasoning directly with the
audio modality and generate output in streaming. However, this remains beyond
the reach of current academic models, as they typically depend on extra TTS
systems for speech synthesis, resulting in undesirable latency. This paper
introduces the Mini-Omni, an audio-based end-to-end conversational model,
capable of real-time speech interaction. To achieve this capability, we propose
a text-instructed speech generation method, along with batch-parallel
strategies during inference to further boost the performance. Our method also
helps to retain the original model's language capabilities with minimal
degradation, enabling other works to establish real-time interaction
capabilities. We call this training method ""Any Model Can Talk"". We also
introduce the VoiceAssistant-400K dataset to fine-tune models optimized for
speech output. To our best knowledge, Mini-Omni is the first fully end-to-end,
open-source model for real-time speech interaction, offering valuable potential
for future research.",2024-08-29,"Zhifei Xie, Changqiao Wu",http://arxiv.org/pdf/2408.16725v3,cs.CL
Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever,"Multi-vector dense models, such as ColBERT, have proven highly effective in
information retrieval. ColBERT's late interaction scoring approximates the
joint query-document attention seen in cross-encoders while maintaining
inference efficiency closer to traditional dense retrieval models, thanks to
its bi-encoder architecture and recent optimizations in indexing and search. In
this work we propose a number of incremental improvements to the ColBERT model
architecture and training pipeline, using methods shown to work in the more
mature single-vector embedding model training paradigm, particularly those that
apply to heterogeneous multilingual data or boost efficiency with little
tradeoff. Our new model, Jina-ColBERT-v2, demonstrates strong performance
across a range of English and multilingual retrieval tasks.",2024-08-29,"Rohan Jha, Bo Wang, Michael Günther, Georgios Mastrapas, Saba Sturua, Isabelle Mohr, Andreas Koukounas, Mohammad Kalim Akram, Nan Wang, Han Xiao",http://arxiv.org/pdf/2408.16672v4,cs.CL
Iterative Graph Alignment,"By compressing diverse narratives, LLMs go beyond memorization, achieving
intelligence by capturing generalizable causal relationships. However, they
suffer from local 'representation gaps' due to insufficient training data
diversity, limiting their real-world utility, especially in tasks requiring
strict alignment to rules. Traditional alignment methods relying on heavy human
annotations are inefficient and unscalable. Recent self-alignment techniques
also fall short, as they often depend on self-selection based prompting and
memorization-based learning. To address these issues, we introduce Iterative
Graph Alignment (IGA), an annotation-free rule-based alignment algorithm. A
teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical
graphs and reference answers. The student model (LLM) identifies local
knowledge gaps by attempting to align its responses with these references,
collaborating with helper models to generate diverse answers. These aligned
responses are then used for iterative supervised fine-tuning (SFT). Our
evaluations across five rule-based scenarios demonstrate IGP's effectiveness,
with a 73.12\% alignment improvement in Claude Sonnet 3.5, and
Llama3-8B-Instruct achieving an 86.20\% improvement, outperforming Claude
Sonnet 3.5 in rule-based alignment.",2024-08-29,"Fangyuan Yu, Hardeep Singh Arora, Matt Johnson",http://arxiv.org/pdf/2408.16667v1,cs.CL
United in Diversity? Contextual Biases in LLM-Based Predictions of the 2024 European Parliament Elections,"""Synthetic samples"" based on large language models (LLMs) have been argued to
serve as efficient alternatives to surveys of humans, assuming that their
training data includes information on human attitudes and behavior. However,
LLM-synthetic samples might exhibit bias, for example due to training data and
fine-tuning processes being unrepresentative of diverse contexts. Such biases
risk reinforcing existing biases in research, policymaking, and society.
Therefore, researchers need to investigate if and under which conditions
LLM-generated synthetic samples can be used for public opinion prediction. In
this study, we examine to what extent LLM-based predictions of individual
public opinion exhibit context-dependent biases by predicting the results of
the 2024 European Parliament elections. Prompting three LLMs with
individual-level background information of 26,000 eligible European voters, we
ask the LLMs to predict each person's voting behavior. By comparing them to the
actual results, we show that LLM-based predictions of future voting behavior
largely fail, their accuracy is unequally distributed across national and
linguistic contexts, and they require detailed attitudinal information in the
prompt. The findings emphasize the limited applicability of LLM-synthetic
samples to public opinion prediction. In investigating their contextual biases,
this study contributes to the understanding and mitigation of inequalities in
the development of LLMs and their applications in computational social science.",2024-08-29,"Leah von der Heyde, Anna-Carolina Haensch, Alexander Wenz, Bolei Ma",http://arxiv.org/pdf/2409.09045v2,cs.CL
HoneyComb: A Flexible LLM-Based Agent System for Materials Science,"The emergence of specialized large language models (LLMs) has shown promise
in addressing complex tasks for materials science. Many LLMs, however, often
struggle with distinct complexities of material science tasks, such as
materials science computational tasks, and often rely heavily on outdated
implicit knowledge, leading to inaccuracies and hallucinations. To address
these challenges, we introduce HoneyComb, the first LLM-based agent system
specifically designed for materials science. HoneyComb leverages a novel,
high-quality materials science knowledge base (MatSciKB) and a sophisticated
tool hub (ToolHub) to enhance its reasoning and computational capabilities
tailored to materials science. MatSciKB is a curated, structured knowledge
collection based on reliable literature, while ToolHub employs an Inductive
Tool Construction method to generate, decompose, and refine API tools for
materials science. Additionally, HoneyComb leverages a retriever module that
adaptively selects the appropriate knowledge source or tools for specific
tasks, thereby ensuring accuracy and relevance. Our results demonstrate that
HoneyComb significantly outperforms baseline models across various tasks in
materials science, effectively bridging the gap between current LLM
capabilities and the specialized needs of this domain. Furthermore, our
adaptable framework can be easily extended to other scientific domains,
highlighting its potential for broad applicability in advancing scientific
research and applications.",2024-08-29,"Huan Zhang, Yu Song, Ziyu Hou, Santiago Miret, Bang Liu",http://arxiv.org/pdf/2409.00135v1,cs.CL
Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies,"Recent advancements in natural language processing, particularly with large
language models (LLMs) like GPT-4, have significantly enhanced dialogue
systems, enabling them to generate more natural and fluent conversations.
Despite these improvements, challenges persist, such as managing continuous
dialogues, memory retention, and minimizing hallucinations. The AIWolfDial2024
addresses these challenges by employing the Werewolf Game, an incomplete
information game, to test the capabilities of LLMs in complex interactive
environments. This paper introduces a LLM-based Werewolf Game AI, where each
role is supported by situation analysis to aid response generation.
Additionally, for the werewolf role, various persuasion strategies, including
logical appeal, credibility appeal, and emotional appeal, are employed to
effectively persuade other players to align with its actions.",2024-08-29,"Zhiyang Qi, Michimasa Inaba",http://arxiv.org/pdf/2408.16586v2,cs.CL
Predictability maximization and the origins of word order harmony,"We address the linguistic problem of the sequential arrangement of a head and
its dependents from an information theoretic perspective. In particular, we
consider the optimal placement of a head that maximizes the predictability of
the sequence. We assume that dependents are statistically independent given a
head, in line with the open-choice principle and the core assumptions of
dependency grammar. We demonstrate the optimality of harmonic order, i.e.,
placing the head last maximizes the predictability of the head whereas placing
the head first maximizes the predictability of dependents. We also show that
postponing the head is the optimal strategy to maximize its predictability
while bringing it forward is the optimal strategy to maximize the
predictability of dependents. We unravel the advantages of the strategy of
maximizing the predictability of the head over maximizing the predictability of
dependents. Our findings shed light on the placements of the head adopted by
real languages or emerging in different kinds of experiments.",2024-08-29,Ramon Ferrer-i-Cancho,http://arxiv.org/pdf/2408.16570v5,cs.CL
SALSA: Speedy ASR-LLM Synchronous Aggregation,"Harnessing pre-trained LLMs to improve ASR systems, particularly for
low-resource languages, is now an emerging area of research. Existing methods
range from using LLMs for ASR error correction to tightly coupled systems that
replace the ASR decoder with the LLM. These approaches either increase decoding
time or require expensive training of the cross-attention layers. We propose
SALSA, which couples the decoder layers of the ASR to the LLM decoder, while
synchronously advancing both decoders. Such coupling is performed with a simple
projection of the last decoder state, and is thus significantly more training
efficient than earlier approaches. A challenge of our proposed coupling is
handling the mismatch between the tokenizers of the LLM and ASR systems. We
handle this mismatch using cascading tokenization with respect to the LLM and
ASR vocabularies. We evaluate SALSA on 8 low-resource languages in the FLEURS
benchmark, yielding substantial WER reductions of up to 38%.",2024-08-29,"Ashish Mittal, Darshan Prabhu, Sunita Sarawagi, Preethi Jyothi",http://arxiv.org/pdf/2408.16542v1,cs.CL
An Interpretable and Crosslingual Method for Evaluating Second-Language Dialogues,"We analyse the cross-lingual transferability of a dialogue evaluation
framework that assesses the relationships between micro-level linguistic
features (e.g. backchannels) and macro-level interactivity labels (e.g. topic
management), originally designed for English-as-a-second-language dialogues. To
this end, we develop CNIMA (Chinese Non-Native Interactivity Measurement and
Automation), a Chinese-as-a-second-language labelled dataset with 10K
dialogues. We found the evaluation framework to be robust across distinct
languages: English and Chinese, revealing language-specific and
language-universal relationships between micro-level and macro-level features.
Next, we propose an automated, interpretable approach with low data requirement
that scores the overall quality of a second-language dialogue based on the
framework. Our approach is interpretable in that it reveals the key linguistic
and interactivity features that contributed to the overall quality score. As
our approach does not require labelled data, it can also be adapted to other
languages for second-language dialogue evaluation.",2024-08-29,"Rena Gao, Jingxuan Wu, Xuetong Wu, Carsten Roever, Jing Wu, Long Lv, Jey Han Lau",http://arxiv.org/pdf/2408.16518v2,cs.CL
LLMs vs Established Text Augmentation Techniques for Classification: When do the Benefits Outweight the Costs?,"The generative large language models (LLMs) are increasingly being used for
data augmentation tasks, where text samples are LLM-paraphrased and then used
for classifier fine-tuning. However, a research that would confirm a clear
cost-benefit advantage of LLMs over more established augmentation methods is
largely missing. To study if (and when) is the LLM-based augmentation
advantageous, we compared the effects of recent LLM augmentation methods with
established ones on 6 datasets, 3 classifiers and 2 fine-tuning methods. We
also varied the number of seeds and collected samples to better explore the
downstream model accuracy space. Finally, we performed a cost-benefit analysis
and show that LLM-based methods are worthy of deployment only when very small
number of seeds is used. Moreover, in many cases, established methods lead to
similar or better model accuracies.",2024-08-29,"Jan Cegin, Jakub Simko, Peter Brusilovsky",http://arxiv.org/pdf/2408.16502v1,cs.CL
Learning from Negative Samples in Generative Biomedical Entity Linking,"Generative models have become widely used in biomedical entity linking
(BioEL) due to their excellent performance and efficient memory usage. However,
these models are usually trained only with positive samples--entities that
match the input mention's identifier--and do not explicitly learn from hard
negative samples, which are entities that look similar but have different
meanings. To address this limitation, we introduce ANGEL (Learning from
Negative Samples in Generative Biomedical Entity Linking), the first framework
that trains generative BioEL models using negative samples. Specifically, a
generative model is initially trained to generate positive samples from the
knowledge base for given input entities. Subsequently, both correct and
incorrect outputs are gathered from the model's top-k predictions. The model is
then updated to prioritize the correct predictions through direct preference
optimization. Our models fine-tuned with ANGEL outperform the previous best
baseline models by up to an average top-1 accuracy of 1.4% on five benchmarks.
When incorporating our framework into pre-training, the performance improvement
further increases to 1.7%, demonstrating its effectiveness in both the
pre-training and fine-tuning stages. Our code is available at
https://github.com/dmis-lab/ANGEL.",2024-08-29,"Chanhwi Kim, Hyunjae Kim, Sihyeon Park, Jiwoo Lee, Mujeen Sung, Jaewoo Kang",http://arxiv.org/pdf/2408.16493v1,cs.CL
A Survey for Large Language Models in Biomedicine,"Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.",2024-08-29,"Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen",http://arxiv.org/pdf/2409.00133v1,cs.CL
Self-Alignment: Improving Alignment of Cultural Values in LLMs via In-Context Learning,"Improving the alignment of Large Language Models (LLMs) with respect to the
cultural values that they encode has become an increasingly important topic. In
this work, we study whether we can exploit existing knowledge about cultural
values at inference time to adjust model responses to cultural value probes. We
present a simple and inexpensive method that uses a combination of in-context
learning (ICL) and human survey data, and show that we can improve the
alignment to cultural values across 5 models that include both English-centric
and multilingual LLMs. Importantly, we show that our method could prove useful
in test languages other than English and can improve alignment to the cultural
values that correspond to a range of culturally diverse countries.",2024-08-29,"Rochelle Choenni, Ekaterina Shutova",http://arxiv.org/pdf/2408.16482v1,cs.CL
Is text normalization relevant for classifying medieval charters?,"This study examines the impact of historical text normalization on the
classification of medieval charters, specifically focusing on document dating
and locating. Using a data set of Middle High German charters from a digital
archive, we evaluate various classifiers, including traditional and
transformer-based models, with and without normalization. Our results indicate
that the given normalization minimally improves locating tasks but reduces
accuracy for dating, implying that original texts contain crucial features that
normalization may obscure. We find that support vector machines and gradient
boosting outperform other models, questioning the efficiency of transformers
for this use case. Results suggest a selective approach to historical text
normalization, emphasizing the significance of preserving some textual
characteristics that are critical for classification tasks in document
analysis.",2024-08-29,"Florian Atzenhofer-Baumgartner, Tamás Kovács",http://arxiv.org/pdf/2408.16446v1,cs.CL
SurveySum: A Dataset for Summarizing Multiple Scientific Articles into a Survey Section,"Document summarization is a task to shorten texts into concise and
informative summaries. This paper introduces a novel dataset designed for
summarizing multiple scientific articles into a section of a survey. Our
contributions are: (1) SurveySum, a new dataset addressing the gap in
domain-specific summarization tools; (2) two specific pipelines to summarize
scientific articles into a section of a survey; and (3) the evaluation of these
pipelines using multiple metrics to compare their performance. Our results
highlight the importance of high-quality retrieval stages and the impact of
different configurations on the quality of generated summaries.",2024-08-29,"Leandro Carísio Fernandes, Gustavo Bartz Guedes, Thiago Soares Laitz, Thales Sales Almeida, Rodrigo Nogueira, Roberto Lotufo, Jayr Pereira",http://arxiv.org/pdf/2408.16444v1,cs.CL
Instruction-tuned Large Language Models for Machine Translation in the Medical Domain,"Large Language Models (LLMs) have shown promising results on machine
translation for high resource language pairs and domains. However, in
specialised domains (e.g. medical) LLMs have shown lower performance compared
to standard neural machine translation models. The consistency in the machine
translation of terminology is crucial for users, researchers, and translators
in specialised domains. In this study, we compare the performance between
baseline LLMs and instruction-tuned LLMs in the medical domain. In addition, we
introduce terminology from specialised medical dictionaries into the
instruction formatted datasets for fine-tuning LLMs. The instruction-tuned LLMs
significantly outperform the baseline models with automatic metrics.",2024-08-29,Miguel Rios,http://arxiv.org/pdf/2408.16440v1,cs.CL
MQM-Chat: Multidimensional Quality Metrics for Chat Translation,"The complexities of chats pose significant challenges for machine translation
models. Recognizing the need for a precise evaluation metric to address the
issues of chat translation, this study introduces Multidimensional Quality
Metrics for Chat Translation (MQM-Chat). Through the experiments of five models
using MQM-Chat, we observed that all models generated certain fundamental
errors, while each of them has different shortcomings, such as omission, overly
correcting ambiguous source content, and buzzword issues, resulting in the loss
of stylized information. Our findings underscore the effectiveness of MQM-Chat
in evaluating chat translation, emphasizing the importance of stylized content
and dialogue consistency for future studies.",2024-08-29,"Yunmeng Li, Jun Suzuki, Makoto Morishita, Kaori Abe, Kentaro Inui",http://arxiv.org/pdf/2408.16390v2,cs.CL
The Unreasonable Ineffectiveness of Nucleus Sampling on Mitigating Text Memorization,"This work analyses the text memorization behavior of large language models
(LLMs) when subjected to nucleus sampling. Stochastic decoding methods like
nucleus sampling are typically applied to overcome issues such as monotonous
and repetitive text generation, which are often observed with
maximization-based decoding techniques. We hypothesize that nucleus sampling
might also reduce the occurrence of memorization patterns, because it could
lead to the selection of tokens outside the memorized sequence. To test this
hypothesis we create a diagnostic dataset with a known distribution of
duplicates that gives us some control over the likelihood of memorization of
certain parts of the training data. Our analysis of two GPT-Neo models
fine-tuned on this dataset interestingly shows that (i) an increase of the
nucleus size reduces memorization only modestly, and (ii) even when models do
not engage in ""hard"" memorization -- a verbatim reproduction of training
samples -- they may still display ""soft"" memorization whereby they generate
outputs that echo the training data but without a complete one-by-one
resemblance.",2024-08-29,"Luka Borec, Philipp Sadler, David Schlangen",http://arxiv.org/pdf/2408.16345v1,cs.CL
Logic Contrastive Reasoning with Lightweight Large Language Model for Math Word Problems,"This study focuses on improving the performance of lightweight Large Language
Models (LLMs) in mathematical reasoning tasks. We introduce a novel method for
measuring mathematical logic similarity and design an automatic screening
mechanism to construct a set of reference problems that integrate both semantic
and logical similarity. By employing carefully crafted positive and negative
example prompts, we guide the model towards adopting sound reasoning logic. To
the best of our knowledge, this is the first attempt to utilize
retrieval-enhanced generation for mathematical problem-solving. Experimental
results demonstrate that our method achieves a 15.8% improvement over the Chain
of Thought approach on the SVAMP dataset and a 21.5 % improvement on the GSM8K
dataset. Further application of this method to a large-scale model with 175
billion parameters yields performance comparable to the best results on both
aforementioned datasets. Finally, we conduct an analysis of errors during the
reasoning process, providing valuable insights and directions for future
research on reasoning tasks using large language models.",2024-08-29,"Ding Kai, Ma Zhenguo, Yan Xiaoran",http://arxiv.org/pdf/2409.00131v1,cs.CL
Critic-CoT: Boosting the reasoning abilities of large language model via Chain-of-thoughts Critic,"Self-critic has become a crucial mechanism for enhancing the reasoning
performance of LLMs. However, current approaches mainly involve basic prompts
for intuitive instance-level feedback, which resembles System-1 processes and
limits the reasoning capabilities. Moreover, there is a lack of in-depth
investigations into the relationship between LLM's ability to criticize and its
task-solving performance. To address these issues, we propose Critic-CoT, a
novel framework that pushes LLMs toward System-2-like critic capability.
Through a step-wise CoT reasoning paradigm and the automatic construction of
distant-supervision data without human annotation, Critic-CoT enables LLMs to
engage in slow, analytic self-critique and refinement, thereby improving their
reasoning abilities. Experiments on GSM8K and MATH demonstrate that our
enhanced model significantly boosts task-solving performance by filtering out
invalid solutions or iterative refinement. Furthermore, we investigate the
intrinsic correlation between critique and task-solving abilities within LLMs,
discovering that these abilities can mutually reinforce each other rather than
conflict.",2024-08-29,"Xin Zheng, Jie Lou, Boxi Cao, Xueru Wen, Yuqiu Ji, Hongyu Lin, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun",http://arxiv.org/pdf/2408.16326v2,cs.CL
"Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems","Language models have demonstrated remarkable performance in solving reasoning
tasks; however, even the strongest models still occasionally make reasoning
mistakes. Recently, there has been active research aimed at improving reasoning
accuracy, particularly by using pretrained language models to ""self-correct""
their mistakes via multi-round prompting. In this paper, we follow this line of
work but focus on understanding the usefulness of incorporating
""error-correction"" data directly into the pretraining stage. This data consists
of erroneous solution steps immediately followed by their corrections. Using a
synthetic math dataset, we show promising results: this type of pretrain data
can help language models achieve higher reasoning accuracy directly (i.e.,
through simple auto-regression, without multi-round prompting) compared to
pretraining on the same amount of error-free data. We also delve into many
details, such as (1) how this approach differs from beam search, (2) how such
data can be prepared, (3) whether masking is needed on the erroneous tokens,
(4) the amount of error required, (5) whether such data can be deferred to the
fine-tuning stage, and many others.",2024-08-29,"Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu",http://arxiv.org/pdf/2408.16293v1,cs.CL
Measuring the Accuracy of Automatic Speech Recognition Solutions,"For d/Deaf and hard of hearing (DHH) people, captioning is an essential
accessibility tool. Significant developments in artificial intelligence (AI)
mean that Automatic Speech Recognition (ASR) is now a part of many popular
applications. This makes creating captions easy and broadly available - but
transcription needs high levels of accuracy to be accessible. Scientific
publications and industry report very low error rates, claiming AI has reached
human parity or even outperforms manual transcription. At the same time the DHH
community reports serious issues with the accuracy and reliability of ASR.
There seems to be a mismatch between technical innovations and the real-life
experience for people who depend on transcription. Independent and
comprehensive data is needed to capture the state of ASR. We measured the
performance of eleven common ASR services with recordings of Higher Education
lectures. We evaluated the influence of technical conditions like streaming,
the use of vocabularies, and differences between languages. Our results show
that accuracy ranges widely between vendors and for the individual audio
samples. We also measured a significant lower quality for streaming ASR, which
is used for live events. Our study shows that despite the recent improvements
of ASR, common services lack reliability in accuracy.",2024-08-29,"Korbinian Kuhn, Verena Kersken, Benedikt Reuter, Niklas Egger, Gottfried Zimmermann",http://arxiv.org/pdf/2408.16287v1,cs.CL
Acceptable Use Policies for Foundation Models,"As foundation models have accumulated hundreds of millions of users,
developers have begun to take steps to prevent harmful types of uses. One
salient intervention that foundation model developers adopt is acceptable use
policies: legally binding policies that prohibit users from using a model for
specific purposes. This paper identifies acceptable use policies from 30
foundation model developers, analyzes the use restrictions they contain, and
argues that acceptable use policies are an important lens for understanding the
regulation of foundation models. Taken together, developers' acceptable use
policies include 127 distinct use restrictions; the wide variety in the number
and type of use restrictions may create fragmentation across the AI supply
chain. Developers also employ acceptable use policies to prevent competitors or
specific industries from making use of their models. Developers alone decide
what constitutes acceptable use, and rarely provide transparency about how they
enforce their policies. In practice, acceptable use policies are difficult to
enforce, and scrupulous enforcement can act as a barrier to researcher access
and limit beneficial uses of foundation models. Nevertheless, acceptable use
policies for foundation models are an early example of self-regulation that
have a significant impact on the market for foundation models and the overall
AI ecosystem.",2024-08-29,Kevin Klyman,http://arxiv.org/pdf/2409.09041v1,cs.CL
Enhancing AI-Driven Psychological Consultation: Layered Prompts with Large Language Models,"Psychological consultation is essential for improving mental health and
well-being, yet challenges such as the shortage of qualified professionals and
scalability issues limit its accessibility. To address these challenges, we
explore the use of large language models (LLMs) like GPT-4 to augment
psychological consultation services. Our approach introduces a novel layered
prompting system that dynamically adapts to user input, enabling comprehensive
and relevant information gathering. We also develop empathy-driven and
scenario-based prompts to enhance the LLM's emotional intelligence and
contextual understanding in therapeutic settings. We validated our approach
through experiments using a newly collected dataset of psychological
consultation dialogues, demonstrating significant improvements in response
quality. The results highlight the potential of our prompt engineering
techniques to enhance AI-driven psychological consultation, offering a scalable
and accessible solution to meet the growing demand for mental health support.",2024-08-29,"Rafael Souza, Jia-Hao Lim, Alexander Davis",http://arxiv.org/pdf/2408.16276v1,cs.CL
Can AI Replace Human Subjects? A Large-Scale Replication of Psychological Experiments with LLMs,"Artificial Intelligence (AI) is increasingly being integrated into scientific
research, particularly in the social sciences, where understanding human
behavior is critical. Large Language Models (LLMs) like GPT-4 have shown
promise in replicating human-like responses in various psychological
experiments. However, the extent to which LLMs can effectively replace human
subjects across diverse experimental contexts remains unclear. Here, we conduct
a large-scale study replicating 154 psychological experiments from top social
science journals with 618 main effects and 138 interaction effects using GPT-4
as a simulated participant. We find that GPT-4 successfully replicates 76.0
percent of main effects and 47.0 percent of interaction effects observed in the
original studies, closely mirroring human responses in both direction and
significance. However, only 19.44 percent of GPT-4's replicated confidence
intervals contain the original effect sizes, with the majority of replicated
effect sizes exceeding the 95 percent confidence interval of the original
studies. Additionally, there is a 71.6 percent rate of unexpected significant
results where the original studies reported null findings, suggesting potential
overestimation or false positives. Our results demonstrate the potential of
LLMs as powerful tools in psychological research but also emphasize the need
for caution in interpreting AI-driven findings. While LLMs can complement human
studies, they cannot yet fully replace the nuanced insights provided by human
subjects.",2024-08-29,"Ziyan Cui, Ning Li, Huaikang Zhou",http://arxiv.org/pdf/2409.00128v2,cs.CL
LoraMap: Harnessing the Power of LoRA Connections,"Fact-checking techniques can mitigate hallucinations in Large Language Models
(LLMs), a prominent issue in specialized domains. As parameter-efficient
techniques such as Low-Rank Adaptation (LoRA) can overcome substantial
computational overhead, some studies have explored the integration of multiple
LoRAs. While previous studies focus on parallel integration, this paper
investigates methods to establish connections among multiple LoRAs. We create
three reasoning datasets tailored to fact-checking and fine-tune individual
LoRAs, allowing them to view and reason from diverse perspectives. Then, we
explore strategies for allocating these reasoning LoRAs and introduce LoraMap,
an approach to map connections between them. The results of the fact-checking
task demonstrate that the performance of LoraMap is superior to LoraHub, an
existing method for integrating LoRAs. LoraMap also outperforms with
significantly fewer trainable parameters than LoraConcat, which concatenates
LoRAs and further fine-tunes them.",2024-08-29,"Hyeryun Park, Jeongwon Kwak, Dongsuk Jang, Sumin Park, Jinwook Choi",http://arxiv.org/pdf/2408.16264v2,cs.CL
ChatSUMO: Large Language Model for Automating Traffic Scenario Generation in Simulation of Urban MObility,"Large Language Models (LLMs), capable of handling multi-modal input and
outputs such as text, voice, images, and video, are transforming the way we
process information. Beyond just generating textual responses to prompts, they
can integrate with different software platforms to offer comprehensive
solutions across diverse applications. In this paper, we present ChatSUMO, a
LLM-based agent that integrates language processing skills to generate abstract
and real-world simulation scenarios in the widely-used traffic simulator -
Simulation of Urban MObility (SUMO). Our methodology begins by leveraging the
LLM for user input which converts to relevant keywords needed to run python
scripts. These scripts are designed to convert specified regions into
coordinates, fetch data from OpenStreetMap, transform it into a road network,
and subsequently run SUMO simulations with the designated traffic conditions.
The outputs of the simulations are then interpreted by the LLM resulting in
informative comparisons and summaries. Users can continue the interaction and
generate a variety of customized scenarios without prior traffic simulation
expertise. For simulation generation, we created a real-world simulation for
the city of Albany with an accuracy of 96\%. ChatSUMO also realizes the
customizing of edge edit, traffic light optimization, and vehicle edit by users
effectively.",2024-08-29,"Shuyang Li, Talha Azfar, Ruimin Ke",http://arxiv.org/pdf/2409.09040v1,cs.CL
Making the Most of your Model: Methods for Finetuning and Applying Pretrained Transformers,"This thesis provides methods and analysis of models which make progress on
this goal. The techniques outlined are task agnostic, and should provide
benefit when used with nearly any transformer LM. We introduce two new
finetuning methods which add new capabilities to the models they are used on.
The first adds a recurrence mechanism, which removes the fixed-window sized
constraint and improves the efficiency of a transformer decoder. The second
allows masked language models (MLMs) to be used for initialization of both the
encoder and decoder of a non-autoregressive sequence-to-sequence transformer,
opening up generative applications of models which were previously only used
for natural language understanding tasks.
  We also introduce two new techniques for improving the quality of predictions
of any transformer decoder without additional finetuning. One, hidden state
optimization, can be applied to any transformer decoder to improve the quality
of predictions at inference time, especially for few-shot classification. The
other, conditional beam search, allows practitioners to search for natural
language generation (NLG) model outputs with high likelihood while conditioning
on the event that the output is not degenerate (e.g. empty, repetitive, etc.).
  Finally, we provide theoretical and empirical insights on the divergence of
model-likelihood and output quality which has widely been observed in prior
work. These insights apply to any model which represents a distribution over
text, and apply to language models which are not transformers or even
autoregressive. We argue that the NLP community has, to some extent,
misunderstood the implications of these findings, and encourage a point of view
which has more nuance.",2024-08-29,Davis Yoshida,http://arxiv.org/pdf/2408.16241v1,cs.CL
SSDM: Scalable Speech Dysfluency Modeling,"Speech dysfluency modeling is the core module for spoken language learning,
and speech therapy. However, there are three challenges. First, current
state-of-the-art solutions\cite{lian2023unconstrained-udm,
lian-anumanchipalli-2024-towards-hudm} suffer from poor scalability. Second,
there is a lack of a large-scale dysfluency corpus. Third, there is not an
effective learning framework. In this paper, we propose \textit{SSDM: Scalable
Speech Dysfluency Modeling}, which (1) adopts articulatory gestures as scalable
forced alignment; (2) introduces connectionist subsequence aligner (CSA) to
achieve dysfluency alignment; (3) introduces a large-scale simulated dysfluency
corpus called Libri-Dys; and (4) develops an end-to-end system by leveraging
the power of large language models (LLMs). We expect SSDM to serve as a
standard in the area of dysfluency modeling. Demo is available at
\url{https://berkeley-speech-group.github.io/SSDM/}.",2024-08-29,"Jiachen Lian, Xuanru Zhou, Zoe Ezzes, Jet Vonk, Brittany Morin, David Baquirin, Zachary Mille, Maria Luisa Gorno Tempini, Gopala Krishna Anumanchipalli",http://arxiv.org/pdf/2408.16221v3,cs.CL
M4CXR: Exploring Multi-task Potentials of Multi-modal Large Language Models for Chest X-ray Interpretation,"The rapid evolution of artificial intelligence, especially in large language
models (LLMs), has significantly impacted various domains, including
healthcare. In chest X-ray (CXR) analysis, previous studies have employed LLMs,
but with limitations: either underutilizing the multi-tasking capabilities of
LLMs or lacking clinical accuracy. This paper presents M4CXR, a multi-modal LLM
designed to enhance CXR interpretation. The model is trained on a visual
instruction-following dataset that integrates various task-specific datasets in
a conversational format. As a result, the model supports multiple tasks such as
medical report generation (MRG), visual grounding, and visual question
answering (VQA). M4CXR achieves state-of-the-art clinical accuracy in MRG by
employing a chain-of-thought prompting strategy, in which it identifies
findings in CXR images and subsequently generates corresponding reports. The
model is adaptable to various MRG scenarios depending on the available inputs,
such as single-image, multi-image, and multi-study contexts. In addition to
MRG, M4CXR performs visual grounding at a level comparable to specialized
models and also demonstrates outstanding performance in VQA. Both quantitative
and qualitative assessments reveal M4CXR's versatility in MRG, visual
grounding, and VQA, while consistently maintaining clinical accuracy.",2024-08-29,"Jonggwon Park, Soobum Kim, Byungmu Yoon, Jihun Hyun, Kyoyun Choi",http://arxiv.org/pdf/2408.16213v1,cs.CL
From cart to truck: meaning shift through words in English in the last two centuries,"This onomasiological study uses diachronic word embeddings to explore how
different words represented the same concepts over time, using historical word
data from 1800 to 2000. We identify shifts in energy, transport, entertainment,
and computing domains, revealing connections between language and societal
changes.
  Our approach consisted in using diachronic word embeddings trained using
word2vec with skipgram and aligning them using orthogonal Procrustes. We
discuss possible difficulties linked to the relationships the method
identifies. Moreover, we look at the ethical aspects of interpreting results,
highlighting the need for expert insights to understand the method's
significance.",2024-08-29,"Esteban Rodríguez Betancourt, Edgar Casasola Murillo",http://arxiv.org/pdf/2408.16209v1,cs.CL
ReXamine-Global: A Framework for Uncovering Inconsistencies in Radiology Report Generation Metrics,"Given the rapidly expanding capabilities of generative AI models for
radiology, there is a need for robust metrics that can accurately measure the
quality of AI-generated radiology reports across diverse hospitals. We develop
ReXamine-Global, a LLM-powered, multi-site framework that tests metrics across
different writing styles and patient populations, exposing gaps in their
generalization. First, our method tests whether a metric is undesirably
sensitive to reporting style, providing different scores depending on whether
AI-generated reports are stylistically similar to ground-truth reports or not.
Second, our method measures whether a metric reliably agrees with experts, or
whether metric and expert scores of AI-generated report quality diverge for
some sites. Using 240 reports from 6 hospitals around the world, we apply
ReXamine-Global to 7 established report evaluation metrics and uncover serious
gaps in their generalizability. Developers can apply ReXamine-Global when
designing new report evaluation metrics, ensuring their robustness across
sites. Additionally, our analysis of existing metrics can guide users of those
metrics towards evaluation procedures that work reliably at their sites of
interest.",2024-08-29,"Oishi Banerjee, Agustina Saenz, Kay Wu, Warren Clements, Adil Zia, Dominic Buensalido, Helen Kavnoudias, Alain S. Abi-Ghanem, Nour El Ghawi, Cibele Luna, Patricia Castillo, Khaled Al-Surimi, Rayyan A. Daghistani, Yuh-Min Chen, Heng-sheng Chao, Lars Heiliger, Moon Kim, Johannes Haubold, Frederic Jonske, Pranav Rajpurkar",http://arxiv.org/pdf/2408.16208v1,cs.CL
Benchmarking Japanese Speech Recognition on ASR-LLM Setups with Multi-Pass Augmented Generative Error Correction,"With the strong representational power of large language models (LLMs),
generative error correction (GER) for automatic speech recognition (ASR) aims
to provide semantic and phonetic refinements to address ASR errors. This work
explores how LLM-based GER can enhance and expand the capabilities of Japanese
language processing, presenting the first GER benchmark for Japanese ASR with
0.9-2.6k text utterances. We also introduce a new multi-pass augmented
generative error correction (MPA GER) by integrating multiple system hypotheses
on the input side with corrections from multiple LLMs on the output side and
then merging them. To the best of our knowledge, this is the first
investigation of the use of LLMs for Japanese GER, which involves second-pass
language modeling on the output transcriptions generated by the ASR system
(e.g., N-best hypotheses). Our experiments demonstrated performance improvement
in the proposed methods of ASR quality and generalization both in SPREDS-U1-ja
and CSJ data.",2024-08-29,"Yuka Ko, Sheng Li, Chao-Han Huck Yang, Tatsuya Kawahara",http://arxiv.org/pdf/2408.16180v2,cs.CL
FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench (Automated Multi-shot Jailbreaks),"This paper introduces FRACTURED-SORRY-Bench, a framework for evaluating the
safety of Large Language Models (LLMs) against multi-turn conversational
attacks. Building upon the SORRY-Bench dataset, we propose a simple yet
effective method for generating adversarial prompts by breaking down harmful
queries into seemingly innocuous sub-questions. Our approach achieves a maximum
increase of +46.22\% in Attack Success Rates (ASRs) across GPT-4, GPT-4o,
GPT-4o-mini, and GPT-3.5-Turbo models compared to baseline methods. We
demonstrate that this technique poses a challenge to current LLM safety
measures and highlights the need for more robust defenses against subtle,
multi-turn attacks.",2024-08-28,"Aman Priyanshu, Supriti Vijay",http://arxiv.org/pdf/2408.16163v2,cs.CL
Evaluating Computational Representations of Character: An Austen Character Similarity Benchmark,"Several systems have been developed to extract information about characters
to aid computational analysis of English literature. We propose character
similarity grouping as a holistic evaluation task for these pipelines. We
present AustenAlike, a benchmark suite of character similarities in Jane
Austen's novels. Our benchmark draws on three notions of character similarity:
a structurally defined notion of similarity; a socially defined notion of
similarity; and an expert defined set extracted from literary criticism.
  We use AustenAlike to evaluate character features extracted using two
pipelines, BookNLP and FanfictionNLP. We build character representations from
four kinds of features and compare them to the three AustenAlike benchmarks and
to GPT-4 similarity rankings. We find that though computational representations
capture some broad similarities based on shared social and narrative roles, the
expert pairings in our third benchmark are challenging for all systems,
highlighting the subtler aspects of similarity noted by human readers.",2024-08-28,"Funing Yang, Carolyn Jane Anderson",http://arxiv.org/pdf/2408.16131v1,cs.CL
Structured Event Reasoning with Large Language Models,"Reasoning about real-life events is a unifying challenge in AI and NLP that
has profound utility in a variety of domains, while fallacy in high-stake
applications could be catastrophic. Able to work with diverse text in these
domains, large language models (LLMs) have proven capable of answering
questions and solving problems. However, I show that end-to-end LLMs still
systematically fail to reason about complex events, and they lack
interpretability due to their black-box nature. To address these issues, I
propose three general approaches to use LLMs in conjunction with a structured
representation of events. The first is a language-based representation
involving relations of sub-events that can be learned by LLMs via fine-tuning.
The second is a semi-symbolic representation involving states of entities that
can be predicted and leveraged by LLMs via few-shot prompting. The third is a
fully symbolic representation that can be predicted by LLMs trained with
structured data and be executed by symbolic solvers. On a suite of event
reasoning tasks spanning common-sense inference and planning, I show that each
approach greatly outperforms end-to-end LLMs with more interpretability. These
results suggest manners of synergy between LLMs and structured representations
for event reasoning and beyond.",2024-08-28,Li Zhang,http://arxiv.org/pdf/2408.16098v1,cs.CL
Is Personality Prediction Possible Based on Reddit Comments?,"In this assignment, we examine whether there is a correlation between the
personality type of a person and the texts they wrote. In order to do this, we
aggregated datasets of Reddit comments labeled with the Myers-Briggs Type
Indicator (MBTI) of the author and built different supervised classifiers based
on BERT to try to predict the personality of an author given a text. Despite
experiencing issues with the unfiltered character of the dataset, we can
observe potential in the classification.",2024-08-28,"Robert Deimann, Till Preidt, Shaptarshi Roy, Jan Stanicki",http://arxiv.org/pdf/2408.16089v1,cs.CL
Logic-Enhanced Language Model Agents for Trustworthy Social Simulations,"We introduce the Logic-Enhanced Language Model Agents (LELMA) framework, a
novel approach to enhance the trustworthiness of social simulations that
utilize large language models (LLMs). While LLMs have gained attention as
agents for simulating human behaviour, their applicability in this role is
limited by issues such as inherent hallucinations and logical inconsistencies.
LELMA addresses these challenges by integrating LLMs with symbolic AI, enabling
logical verification of the reasoning generated by LLMs. This verification
process provides corrective feedback, refining the reasoning output. The
framework consists of three main components: an LLM-Reasoner for producing
strategic reasoning, an LLM-Translator for mapping natural language reasoning
to logic queries, and a Solver for evaluating these queries. This study focuses
on decision-making in game-theoretic scenarios as a model of human interaction.
Experiments involving the Hawk-Dove game, Prisoner's Dilemma, and Stag Hunt
highlight the limitations of state-of-the-art LLMs, GPT-4 Omni and Gemini 1.0
Pro, in producing correct reasoning in these contexts. LELMA demonstrates high
accuracy in error detection and improves the reasoning correctness of LLMs via
self-refinement, particularly in GPT-4 Omni.",2024-08-28,"Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi",http://arxiv.org/pdf/2408.16081v1,cs.CL
"Using Large Language Models to Create AI Personas for Replication, Generalization and Prediction of Media Effects: An Empirical Test of 133 Published Experimental Research Findings","This report analyzes the potential for large language models (LLMs) to
expedite accurate replication and generalization of published research about
message effects in marketing. LLM-powered participants (personas) were tested
by replicating 133 experimental findings from 14 papers containing 45 recent
studies published in the Journal of Marketing. For each study, the measures,
stimuli, and sampling specifications were used to generate prompts for LLMs to
act as unique personas. The AI personas, 19,447 in total across all of the
studies, generated complete datasets and statistical analyses were then
compared with the original human study results. The LLM replications
successfully reproduced 76% of the original main effects (84 out of 111),
demonstrating strong potential for AI-assisted replication. The overall
replication rate including interaction effects was 68% (90 out of 133).
Furthermore, a test of how human results generalized to different participant
samples, media stimuli, and measures showed that replication results can change
when tests go beyond the parameters of the original human studies. Implications
are discussed for the replication and generalizability crises in social
science, the acceleration of theory building in media and marketing psychology,
and the practical advantages of rapid message testing for consumer products.
Limitations of AI replications are addressed with respect to complex
interaction effects, biases in AI models, and establishing benchmarks for AI
metrics in marketing research.",2024-08-28,"Leo Yeykelis, Kaavya Pichai, James J. Cummings, Byron Reeves",http://arxiv.org/pdf/2408.16073v2,cs.CL
CoGen: Learning from Feedback with Coupled Comprehension and Generation,"Systems with both language comprehension and generation capabilities can
benefit from the tight connection between the two. This work studies coupling
comprehension and generation with focus on continually learning from
interaction with users. We propose techniques to tightly integrate the two
capabilities for both learning and inference. We situate our studies in
two-player reference games, and deploy various models for thousands of
interactions with human users, while learning from interaction feedback
signals. We show dramatic improvements in performance over time, with
comprehension-generation coupling leading to performance improvements up to 26%
in absolute terms and up to 17% higher accuracies compared to a non-coupled
system. Our analysis also shows coupling has substantial qualitative impact on
the system's language, making it significantly more human-like.",2024-08-28,"Mustafa Omer Gul, Yoav Artzi",http://arxiv.org/pdf/2408.15992v1,cs.CL
BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems,"Large Language Models (LLMs) are becoming increasingly powerful and capable
of handling complex tasks, e.g., building single agents and multi-agent
systems. Compared to single agents, multi-agent systems have higher
requirements for the collaboration capabilities of language models. Many
benchmarks are proposed to evaluate their collaborative abilities. However,
these benchmarks lack fine-grained evaluations of LLM collaborative
capabilities. Additionally, multi-agent collaborative and competitive scenarios
are ignored in existing works. To address these two problems, we propose a
benchmark, called BattleAgentBench, which defines seven sub-stages of three
varying difficulty levels and conducts a fine-grained evaluation of language
models in terms of single-agent scenario navigation capabilities, paired-agent
task execution abilities, and multi-agent collaboration and competition
capabilities. We conducted extensive evaluations on leading four closed-source
and seven open-source models. Experimental results indicate that API-based
models perform excellently on simple tasks but open-source small models
struggle with simple tasks. Regarding difficult tasks that require
collaborative and competitive abilities, although API-based models have
demonstrated some collaborative capabilities, there is still enormous room for
improvement.",2024-08-28,"Wei Wang, Dan Zhang, Tao Feng, Boyan Wang, Jie Tang",http://arxiv.org/pdf/2408.15971v1,cs.CL
"More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding","Enabling Large Language Models (LLMs) to comprehend the 3D physical world
remains a significant challenge. Due to the lack of large-scale 3D-text pair
datasets, the success of LLMs has yet to be replicated in 3D understanding. In
this paper, we rethink this issue and propose a new task: 3D Data-Efficient
Point-Language Understanding. The goal is to enable LLMs to achieve robust 3D
object understanding with minimal 3D point cloud and text data pairs. To
address this task, we introduce GreenPLM, which leverages more text data to
compensate for the lack of 3D data. First, inspired by using CLIP to align
images and text, we utilize a pre-trained point cloud-text encoder to map the
3D point cloud space to the text space. This mapping leaves us to seamlessly
connect the text space with LLMs. Once the point-text-LLM connection is
established, we further enhance text-LLM alignment by expanding the
intermediate text space, thereby reducing the reliance on 3D point cloud data.
Specifically, we generate 6M free-text descriptions of 3D objects, and design a
three-stage training strategy to help LLMs better explore the intrinsic
connections between different modalities. To achieve efficient modality
alignment, we design a zero-parameter cross-attention module for token pooling.
Extensive experimental results show that GreenPLM requires only 12% of the 3D
training data used by existing state-of-the-art models to achieve superior 3D
understanding. Remarkably, GreenPLM also achieves competitive performance using
text-only data. The code and weights are available at:
https://github.com/TangYuan96/GreenPLM.",2024-08-28,"Yuan Tang, Xu Han, Xianzhi Li, Qiao Yu, Jinfeng Xu, Yixue Hao, Long Hu, Min Chen",http://arxiv.org/pdf/2408.15966v3,cs.CL
Leveraging Large Language Models for Wireless Symbol Detection via In-Context Learning,"Deep neural networks (DNNs) have made significant strides in tackling
challenging tasks in wireless systems, especially when an accurate wireless
model is not available. However, when available data is limited, traditional
DNNs often yield subpar results due to underfitting. At the same time, large
language models (LLMs) exemplified by GPT-3, have remarkably showcased their
capabilities across a broad range of natural language processing tasks. But
whether and how LLMs can benefit challenging non-language tasks in wireless
systems is unexplored. In this work, we propose to leverage the in-context
learning ability (a.k.a. prompting) of LLMs to solve wireless tasks in the low
data regime without any training or fine-tuning, unlike DNNs which require
training. We further demonstrate that the performance of LLMs varies
significantly when employed with different prompt templates. To solve this
issue, we employ the latest LLM calibration methods. Our results reveal that
using LLMs via ICL methods generally outperforms traditional DNNs on the symbol
demodulation task and yields highly confident predictions when coupled with
calibration techniques.",2024-08-28,"Momin Abbas, Koushik Kar, Tianyi Chen",http://arxiv.org/pdf/2409.00124v2,cs.CL
Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models,"The cultivation of expertise for large language models (LLMs) to solve tasks
of specific areas often requires special-purpose tuning with calibrated
behaviors on the expected stable outputs. To avoid huge cost brought by manual
preparation of instruction datasets and training resources up to hundreds of
hours, the exploitation of open knowledge including a wealth of low rank
adaptation (LoRA) models and instruction datasets serves as a good starting
point. However, existing methods on model and data selection focus on the
performance of general-purpose capabilities while neglecting the knowledge gap
exposed in domain-specific deployment. In the present study, we propose to
bridge such gap by introducing few human-annotated samples (i.e., K-shot) for
advancing task expertise of LLMs with open knowledge. Specifically, we develop
an efficient and scalable pipeline to cost-efficiently produce task experts
where K-shot data intervene in selecting the most promising expert candidates
and the task-relevant instructions. A mixture-of-expert (MoE) system is built
to make the best use of individual-yet-complementary knowledge between multiple
experts. We unveil the two keys to the success of a MoE system, 1) the abidance
by K-shot, and 2) the insistence on diversity. For the former, we ensure that
models that truly possess problem-solving abilities on K-shot are selected
rather than those blind guessers. Besides, during data selection, instructions
that share task-relevant contexts with K-shot are prioritized. For the latter,
we highlight the diversity of constituting experts and that of the fine-tuning
instructions throughout the model and data selection process. Extensive
experimental results confirm the superiority of our approach over existing
methods on utilization of open knowledge across various tasks. Our codes will
be available at https://github.com/Yaphabates/Rocket.",2024-08-28,"Yuncheng Yang, Yulei Qin, Tong Wu, Zihan Xu, Gang Li, Pengcheng Guo, Hang Shao, Yuchen Shi, Ke Li, Xing Sun, Jie Yang, Yun Gu",http://arxiv.org/pdf/2408.15915v2,cs.CL
LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments,"The important challenge of keeping knowledge in Large Language Models (LLMs)
up-to-date has led to the development of various methods for incorporating new
facts. However, existing methods for such knowledge editing still face
difficulties with multi-hop questions that require accurate fact identification
and sequential logical reasoning, particularly among numerous fact updates. To
tackle these challenges, this paper introduces Graph Memory-based Editing for
Large Language Models (GMeLLo), a straightforward and effective method that
merges the explicit knowledge representation of Knowledge Graphs (KGs) with the
linguistic flexibility of LLMs. Beyond merely leveraging LLMs for question
answering, GMeLLo employs these models to convert free-form language into
structured queries and fact triples, facilitating seamless interaction with KGs
for rapid updates and precise multi-hop reasoning. Our results show that GMeLLo
significantly surpasses current state-of-the-art (SOTA) knowledge editing
methods in the multi-hop question answering benchmark, MQuAKE, especially in
scenarios with extensive knowledge edits.",2024-08-28,"Ruirui Chen, Weifeng Jiang, Chengwei Qin, Ishaan Singh Rawal, Cheston Tan, Dongkyu Choi, Bo Xiong, Bo Ai",http://arxiv.org/pdf/2408.15903v2,cs.CL
Nexus: Specialization meets Adaptability for Efficiently Training Mixture of Experts,"Efficiency, specialization, and adaptability to new data distributions are
qualities that are hard to combine in current Large Language Models. The
Mixture of Experts (MoE) architecture has been the focus of significant
research because its inherent conditional computation enables such desirable
properties. In this work, we focus on ""upcycling"" dense expert models into an
MoE, aiming to improve specialization while also adding the ability to adapt to
new tasks easily. We introduce Nexus, an enhanced MoE architecture with
adaptive routing where the model learns to project expert embeddings from
domain representations. This approach allows Nexus to flexibly add new experts
after the initial upcycling through separately trained dense models, without
requiring large-scale MoE training for unseen data domains. Our experiments
show that Nexus achieves a relative gain of up to 2.1% over the baseline for
initial upcycling, and a 18.8% relative gain for extending the MoE with a new
expert by using limited finetuning data. This flexibility of Nexus is crucial
to enable an open-source ecosystem where every user continuously assembles
their own MoE-mix according to their needs.",2024-08-28,"Nikolas Gritsch, Qizhen Zhang, Acyr Locatelli, Sara Hooker, Ahmet Üstün",http://arxiv.org/pdf/2408.15901v1,cs.CL
A New Method for Cross-Lingual-based Semantic Role Labeling,"Semantic role labeling is a crucial task in natural language processing,
enabling better comprehension of natural language. However, the lack of
annotated data in multiple languages has posed a challenge for researchers. To
address this, a deep learning algorithm based on model transfer has been
proposed. The algorithm utilizes a dataset consisting of the English portion of
CoNLL2009 and a corpus of semantic roles in Persian. To optimize the efficiency
of training, only ten percent of the educational data from each language is
used. The results of the proposed model demonstrate significant improvements
compared to Niksirt et al.'s model. In monolingual mode, the proposed model
achieved a 2.05 percent improvement on F1-score, while in cross-lingual mode,
the improvement was even more substantial, reaching 6.23 percent. Worth noting
is that the compared model only trained two of the four stages of semantic role
labeling and employed golden data for the remaining two stages. This suggests
that the actual superiority of the proposed model surpasses the reported
numbers by a significant margin. The development of cross-lingual methods for
semantic role labeling holds promise, particularly in addressing the scarcity
of annotated data for various languages. These advancements pave the way for
further research in understanding and processing natural language across
different linguistic contexts.",2024-08-28,"Mohammad Ebrahimi, Behrouz Minaei Bidgoli, Nasim Khozouei",http://arxiv.org/pdf/2408.15896v1,cs.CL
Bias in LLMs as Annotators: The Effect of Party Cues on Labelling Decision by Large Language Models,"Human coders are biased. We test similar biases in Large Language Models
(LLMs) as annotators. By replicating an experiment run by Ennser-Jedenastik and
Meyer (2018), we find evidence that LLMs use political information, and
specifically party cues, to judge political statements. Not only do LLMs use
relevant information to contextualize whether a statement is positive,
negative, or neutral based on the party cue, they also reflect the biases of
the human-generated data upon which they have been trained. We also find that
unlike humans, who are only biased when faced with statements from extreme
parties, LLMs exhibit significant bias even when prompted with statements from
center-left and center-right parties. The implications of our findings are
discussed in the conclusion.",2024-08-28,"Sebastian Vallejo Vera, Hunter Driggers",http://arxiv.org/pdf/2408.15895v1,cs.CL
Persuasion Games using Large Language Models,"Large Language Models (LLMs) have emerged as formidable instruments capable
of comprehending and producing human-like text. This paper explores the
potential of LLMs, to shape user perspectives and subsequently influence their
decisions on particular tasks. This capability finds applications in diverse
domains such as Investment, Credit cards and Insurance, wherein they assist
users in selecting appropriate insurance policies, investment plans, Credit
cards, Retail, as well as in Behavioral Change Support Systems (BCSS).
  We present a sophisticated multi-agent framework wherein a consortium of
agents operate in collaborative manner. The primary agent engages directly with
user agents through persuasive dialogue, while the auxiliary agents perform
tasks such as information retrieval, response analysis, development of
persuasion strategies, and validation of facts. Empirical evidence from our
experiments demonstrates that this collaborative methodology significantly
enhances the persuasive efficacy of the LLM. We continuously analyze the
resistance of the user agent to persuasive efforts and counteract it by
employing a combination of rule-based and LLM-based resistance-persuasion
mapping techniques.
  We employ simulated personas and generate conversations in insurance,
banking, and retail domains to evaluate the proficiency of large language
models (LLMs) in recognizing, adjusting to, and influencing various personality
types. Concurrently, we examine the resistance mechanisms employed by LLM
simulated personas. Persuasion is quantified via measurable surveys before and
after interaction, LLM-generated scores on conversation, and user decisions
(purchase or non-purchase).",2024-08-28,"Ganesh Prasath Ramani, Shirish Karande, Santhosh V, Yash Bhatia",http://arxiv.org/pdf/2408.15879v2,cs.CL
Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature,"The exponential growth of scientific literature necessitates advanced tools
for effective knowledge exploration. We present Knowledge Navigator, a system
designed to enhance exploratory search abilities by organizing and structuring
the retrieved documents from broad topical queries into a navigable, two-level
hierarchy of named and descriptive scientific topics and subtopics. This
structured organization provides an overall view of the research themes in a
domain, while also enabling iterative search and deeper knowledge discovery
within specific subtopics by allowing users to refine their focus and retrieve
additional relevant documents. Knowledge Navigator combines LLM capabilities
with cluster-based methods to enable an effective browsing method. We
demonstrate our approach's effectiveness through automatic and manual
evaluations on two novel benchmarks, CLUSTREC-COVID and SCITOC. Our code,
prompts, and benchmarks are made publicly available.",2024-08-28,"Uri Katz, Mosh Levy, Yoav Goldberg",http://arxiv.org/pdf/2408.15836v1,cs.CL
Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification,"As the field of artificial intelligence progresses, assistive technologies
are becoming more widely used across all industries. The healthcare industry is
no different, with numerous studies being done to develop assistive tools for
healthcare professionals. Automatic diagnostic systems are one such beneficial
tool that can assist with a variety of tasks, including collecting patient
information, analyzing test results, and diagnosing patients. However, the idea
of developing systems that can provide a differential diagnosis has been
largely overlooked in most of these research studies. In this study, we propose
a transformer-based approach for providing differential diagnoses based on a
patient's age, sex, medical history, and symptoms. We use the DDXPlus dataset,
which provides differential diagnosis information for patients based on 49
disease types. Firstly, we propose a method to process the tabular patient data
from the dataset and engineer them into patient reports to make them suitable
for our research. In addition, we introduce two data modification modules to
diversify the training data and consequently improve the robustness of the
models. We approach the task as a multi-label classification problem and
conduct extensive experiments using four transformer models. All the models
displayed promising results by achieving over 97% F1 score on the held-out test
set. Moreover, we design additional behavioral tests to get a broader
understanding of the models. In particular, for one of our test cases, we
prepared a custom test set of 100 samples with the assistance of a doctor. The
results on the custom set showed that our proposed data modification modules
improved the model's generalization capabilities. We hope our findings will
provide future researchers with valuable insights and inspire them to develop
reliable systems for automatic differential diagnosis.",2024-08-28,"Abu Adnan Sadi, Mohammad Ashrafuzzaman Khan, Lubaba Binte Saber",http://arxiv.org/pdf/2408.15827v1,cs.CL
Scaling Up Summarization: Leveraging Large Language Models for Long Text Extractive Summarization,"In an era where digital text is proliferating at an unprecedented rate,
efficient summarization tools are becoming indispensable. While Large Language
Models (LLMs) have been successfully applied in various NLP tasks, their role
in extractive text summarization remains underexplored. This paper introduces
EYEGLAXS (Easy Yet Efficient larGe LAnguage model for eXtractive
Summarization), a framework that leverages LLMs, specifically LLAMA2-7B and
ChatGLM2-6B, for extractive summarization of lengthy text documents. Instead of
abstractive methods, which often suffer from issues like factual inaccuracies
and hallucinations, EYEGLAXS focuses on extractive summarization to ensure
factual and grammatical integrity. Utilizing state-of-the-art techniques such
as Flash Attention and Parameter-Efficient Fine-Tuning (PEFT), EYEGLAXS
addresses the computational and resource challenges typically associated with
LLMs. The system sets new performance benchmarks on well-known datasets like
PubMed and ArXiv. Furthermore, we extend our research through additional
analyses that explore the adaptability of LLMs in handling different sequence
lengths and their efficiency in training on smaller datasets. These
contributions not only set a new standard in the field but also open up
promising avenues for future research in extractive text summarization.",2024-08-28,"Léo Hemamou, Mehdi Debiane",http://arxiv.org/pdf/2408.15801v1,cs.CL
Language Adaptation on a Tight Academic Compute Budget: Tokenizer Swapping Works and Pure bfloat16 Is Enough,"We investigate continued pretraining of LLMs for language adaptation on a
tight academic budget: a setting in which only a few GPUs can be used in
parallel, for a heavily constrained duration. We focus on adapting Mistral-7B
to German or Arabic and evaluate several techniques to improve efficiency and
effectiveness in this setting. Our German models adapted on this tight compute
budget underperform compared to the base Mistral-7B, while our Arabic models
outperform several baselines, showing that for sufficiently well-represented
languages, continued pretraining for specialization is not always helpful. Our
main findings focus on training precision and tokenizer swapping. Our results
show that pure bfloat16 training is a viable alternative to mixed-precision
training, while being much faster when only using a few GPUs. Swapping the
tokenizer for a specialized one yields more efficient tokenization and is
competitive with the original tokenizer, which already contains some German
tokens, but did not significantly increase performance for German. Code and
model weights are available at on GitHub.",2024-08-28,"Konstantin Dobler, Gerard de Melo",http://arxiv.org/pdf/2408.15793v1,cs.CL
Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions,"Virtual counselors powered by large language models (LLMs) aim to create
interactive support systems that effectively assist clients struggling with
mental health challenges. To replicate counselor-client conversations,
researchers have built an online mental health platform that allows
professional counselors to provide clients with text-based counseling services
for about an hour per session. Notwithstanding its effectiveness, challenges
exist as human annotation is time-consuming, cost-intensive, privacy-protected,
and not scalable. To address this issue and investigate the applicability of
LLMs in psychological counseling conversation simulation, we propose a
framework that employs two LLMs via role-playing for simulating
counselor-client interactions. Our framework involves two LLMs, one acting as a
client equipped with a specific and real-life user profile and the other
playing the role of an experienced counselor, generating professional responses
using integrative therapy techniques. We implement both the counselor and the
client by zero-shot prompting the GPT-4 model. In order to assess the
effectiveness of LLMs in simulating counselor-client interactions and
understand the disparities between LLM- and human-generated conversations, we
evaluate the synthetic data from various perspectives. We begin by assessing
the client's performance through automatic evaluations. Next, we analyze and
compare the disparities between dialogues generated by the LLM and those
generated by professional counselors. Furthermore, we conduct extensive
experiments to thoroughly examine the performance of our LLM-based counselor
trained with synthetic interactive dialogues by benchmarking against
state-of-the-art models for mental health.",2024-08-28,"Huachuan Qiu, Zhenzhong Lan",http://arxiv.org/pdf/2408.15787v1,cs.CL
LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models,"Large Language Models (LLMs) have demonstrated notable capabilities across
various tasks, showcasing complex problem-solving abilities. Understanding and
executing complex rules, along with multi-step planning, are fundamental to
logical reasoning and critical for practical LLM agents and decision-making
systems. However, evaluating LLMs as effective rule-based executors and
planners remains underexplored. In this paper, we introduce LogicGame, a novel
benchmark designed to evaluate the comprehensive rule understanding, execution,
and planning capabilities of LLMs. Unlike traditional benchmarks, LogicGame
provides diverse games that contain a series of rules with an initial state,
requiring models to comprehend and apply predefined regulations to solve
problems. We create simulated scenarios in which models execute or plan
operations to achieve specific outcomes. These game scenarios are specifically
designed to distinguish logical reasoning from mere knowledge by relying
exclusively on predefined rules. This separation allows for a pure assessment
of rule-based reasoning capabilities. The evaluation considers not only final
outcomes but also intermediate steps, providing a comprehensive assessment of
model performance. Moreover, these intermediate steps are deterministic and can
be automatically verified. LogicGame defines game scenarios with varying
difficulty levels, from simple rule applications to complex reasoning chains,
in order to offer a precise evaluation of model performance on rule
understanding and multi-step execution. Utilizing LogicGame, we test various
LLMs and identify notable shortcomings in their rule-based logical reasoning
abilities.",2024-08-28,"Jiayi Gui, Yiming Liu, Jiale Cheng, Xiaotao Gu, Xiao Liu, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang",http://arxiv.org/pdf/2408.15778v4,cs.CL
A Survey on Evaluation of Multimodal Large Language Models,"Multimodal Large Language Models (MLLMs) mimic human perception and reasoning
system by integrating powerful Large Language Models (LLMs) with various
modality encoders (e.g., vision, audio), positioning LLMs as the ""brain"" and
various modality encoders as sensory organs. This framework endows MLLMs with
human-like capabilities, and suggests a potential pathway towards achieving
artificial general intelligence (AGI). With the emergence of all-round MLLMs
like GPT-4V and Gemini, a multitude of evaluation methods have been developed
to assess their capabilities across different dimensions. This paper presents a
systematic and comprehensive review of MLLM evaluation methods, covering the
following key aspects: (1) the background of MLLMs and their evaluation; (2)
""what to evaluate"" that reviews and categorizes existing MLLM evaluation tasks
based on the capabilities assessed, including general multimodal recognition,
perception, reasoning and trustworthiness, and domain-specific applications
such as socioeconomic, natural sciences and engineering, medical usage, AI
agent, remote sensing, video and audio processing, 3D point cloud analysis, and
others; (3) ""where to evaluate"" that summarizes MLLM evaluation benchmarks into
general and specific benchmarks; (4) ""how to evaluate"" that reviews and
illustrates MLLM evaluation steps and metrics; Our overarching goal is to
provide valuable insights for researchers in the field of MLLM evaluation,
thereby facilitating the development of more capable and reliable MLLMs. We
emphasize that evaluation should be regarded as a critical discipline,
essential for advancing the field of MLLMs.",2024-08-28,"Jiaxing Huang, Jingyi Zhang",http://arxiv.org/pdf/2408.15769v1,cs.CL
Learning Harmonized Representations for Speculative Sampling,"Speculative sampling is a promising approach to accelerate the decoding stage
for Large Language Models (LLMs). Recent advancements that leverage target
LLM's contextual information, such as hidden states and KV cache, have shown
significant practical improvements. However, these approaches suffer from
inconsistent context between training and decoding. We also observe another
discrepancy between the training and decoding objectives in existing
speculative sampling methods. In this work, we propose a solution named
HArmonized Speculative Sampling (HASS) that learns harmonized representations
to address these issues. HASS accelerates the decoding stage without adding
inference overhead through harmonized objective distillation and harmonized
context alignment. Experiments on four LLaMA models demonstrate that HASS
achieves 2.81x-4.05x wall-clock time speedup ratio averaging across three
datasets, surpassing EAGLE-2 by 8%-20%. The code is available at
https://github.com/HArmonizedSS/HASS.",2024-08-28,"Lefan Zhang, Xiaodan Wang, Yanhua Huang, Ruiwen Xu",http://arxiv.org/pdf/2408.15766v3,cs.CL
Form and meaning co-determine the realization of tone in Taiwan Mandarin spontaneous speech: the case of Tone 3 sandhi,"In Standard Chinese, Tone 3 (the dipping tone) becomes Tone 2 (rising tone)
when followed by another Tone 3. Previous studies have noted that this sandhi
process may be incomplete, in the sense that the assimilated Tone 3 is still
distinct from a true Tone 2. While Mandarin Tone 3 sandhi is widely studied
using carefully controlled laboratory speech (Xu, 1997) and more formal
registers of Beijing Mandarin (Yuan and Chen, 2014), less is known about its
realization in spontaneous speech, and about the effect of contextual factors
on tonal realization. The present study investigates the pitch contours of
two-character words with T2-T3 and T3-T3 tone patterns in spontaneous Taiwan
Mandarin conversations. Our analysis makes use of the Generative Additive Mixed
Model (GAMM, Wood, 2017) to examine fundamental frequency (f0) contours as a
function of normalized time. We consider various factors known to influence
pitch contours, including gender, speaking rate, speaker, neighboring tones,
word position, bigram probability, and also novel predictors, word and word
sense (Chuang et al., 2024). Our analyses revealed that in spontaneous Taiwan
Mandarin, T3-T3 words become indistinguishable from T2-T3 words, indicating
complete sandhi, once the strong effect of word (or word sense) is taken into
account. For our data, the shape of f0 contours is not co-determined by word
frequency. In contrast, the effect of word meaning on f0 contours is robust, as
strong as the effect of adjacent tones, and is present for both T2-T3 and T3-T3
words.",2024-08-28,"Yuxin Lu, Yu-Ying Chuang, R. Harald Baayen",http://arxiv.org/pdf/2408.15747v1,cs.CL
LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of Relational Knowledge in Language Models,"Knowledge probing evaluates the extent to which a language model (LM) has
acquired relational knowledge during its pre-training phase. It provides a
cost-effective means of comparing LMs of different sizes and training setups
and is useful for monitoring knowledge gained or lost during continual learning
(CL). In prior work, we presented an improved knowledge probe called BEAR
(Wiland et al., 2024), which enables the comparison of LMs trained with
different pre-training objectives (causal and masked LMs) and addresses issues
of skewed distributions in previous probes to deliver a more unbiased reading
of LM knowledge. With this paper, we present LM-PUB- QUIZ, a Python framework
and leaderboard built around the BEAR probing mechanism that enables
researchers and practitioners to apply it in their work. It provides options
for standalone evaluation and direct integration into the widely-used training
pipeline of the Hugging Face TRANSFORMERS library. Further, it provides a
fine-grained analysis of different knowledge types to assist users in better
understanding the knowledge in each evaluated LM. We publicly release
LM-PUB-QUIZ as an open-source project.",2024-08-28,"Max Ploner, Jacek Wiland, Sebastian Pohl, Alan Akbik",http://arxiv.org/pdf/2408.15729v1,cs.CL
Responsible AI for Test Equity and Quality: The Duolingo English Test as a Case Study,"Artificial intelligence (AI) creates opportunities for assessments, such as
efficiencies for item generation and scoring of spoken and written responses.
At the same time, it poses risks (such as bias in AI-generated item content).
Responsible AI (RAI) practices aim to mitigate risks associated with AI. This
chapter addresses the critical role of RAI practices in achieving test quality
(appropriateness of test score inferences), and test equity (fairness to all
test takers). To illustrate, the chapter presents a case study using the
Duolingo English Test (DET), an AI-powered, high-stakes English language
assessment. The chapter discusses the DET RAI standards, their development and
their relationship to domain-agnostic RAI principles. Further, it provides
examples of specific RAI practices, showing how these practices meaningfully
address the ethical principles of validity and reliability, fairness, privacy
and security, and transparency and accountability standards to ensure test
equity and quality.",2024-08-28,"Jill Burstein, Geoffrey T. LaFlair, Kevin Yancey, Alina A. von Davier, Ravit Dotan",http://arxiv.org/pdf/2409.07476v1,cs.CL
An Evaluation of Sindhi Word Embedding in Semantic Analogies and Downstream Tasks,"In this paper, we propose a new word embedding based corpus consisting of
more than 61 million words crawled from multiple web resources. We design a
preprocessing pipeline for the filtration of unwanted text from crawled data.
Afterwards, the cleaned vocabulary is fed to state-of-the-art
continuous-bag-of-words, skip-gram, and GloVe word embedding algorithms. For
the evaluation of pretrained embeddings, we use popular intrinsic and extrinsic
evaluation approaches. The evaluation results reveal that
continuous-bag-of-words and skip-gram perform better than GloVe and existing
Sindhi fastText word embedding on both intrinsic and extrinsic evaluation
approaches",2024-08-28,"Wazir Ali, Saifullah Tumrani, Jay Kumar, Tariq Rahim Soomro",http://arxiv.org/pdf/2408.15720v1,cs.CL
ConCSE: Unified Contrastive Learning and Augmentation for Code-Switched Embeddings,"This paper examines the Code-Switching (CS) phenomenon where two languages
intertwine within a single utterance. There exists a noticeable need for
research on the CS between English and Korean. We highlight that the current
Equivalence Constraint (EC) theory for CS in other languages may only partially
capture English-Korean CS complexities due to the intrinsic grammatical
differences between the languages. We introduce a novel Koglish dataset
tailored for English-Korean CS scenarios to mitigate such challenges. First, we
constructed the Koglish-GLUE dataset to demonstrate the importance and need for
CS datasets in various tasks. We found the differential outcomes of various
foundation multilingual language models when trained on a monolingual versus a
CS dataset. Motivated by this, we hypothesized that SimCSE, which has shown
strengths in monolingual sentence embedding, would have limitations in CS
scenarios. We construct a novel Koglish-NLI (Natural Language Inference)
dataset using a CS augmentation-based approach to verify this. From this
CS-augmented dataset Koglish-NLI, we propose a unified contrastive learning and
augmentation method for code-switched embeddings, ConCSE, highlighting the
semantics of CS sentences. Experimental results validate the proposed ConCSE
with an average performance enhancement of 1.77\% on the Koglish-STS(Semantic
Textual Similarity) tasks.",2024-08-28,"Jangyeong Jeon, Sangyeon Cho, Minuk Ma, Junyoung Kim",http://arxiv.org/pdf/2409.00120v2,cs.CL
Conan-embedding: General Text Embedding with More and Better Negative Samples,"With the growing popularity of RAG, the capabilities of embedding models are
gaining increasing attention. Embedding models are primarily trained through
contrastive loss learning, with negative examples being a key component.
Previous work has proposed various hard negative mining strategies, but these
strategies are typically employed as preprocessing steps. In this paper, we
propose the conan-embedding model, which maximizes the utilization of more and
higher-quality negative examples. Specifically, since the model's ability to
handle preprocessed negative examples evolves during training, we propose
dynamic hard negative mining method to expose the model to more challenging
negative examples throughout the training process. Secondly, contrastive
learning requires as many negative examples as possible but is limited by GPU
memory constraints. Therefore, we use a Cross-GPU balancing Loss to provide
more negative examples for embedding training and balance the batch size across
multiple tasks. Moreover, we also discovered that the prompt-response pairs
from LLMs can be used for embedding training. Our approach effectively enhances
the capabilities of embedding models, currently ranking first on the Chinese
leaderboard of Massive text embedding benchmark",2024-08-28,"Shiyu Li, Yang Tang, Shizhe Chen, Xi Chen",http://arxiv.org/pdf/2408.15710v2,cs.CL
TempoFormer: A Transformer for Temporally-aware Representations in Change Detection,"Dynamic representation learning plays a pivotal role in understanding the
evolution of linguistic content over time. On this front both context and time
dynamics as well as their interplay are of prime importance. Current approaches
model context via pre-trained representations, which are typically temporally
agnostic. Previous work on modelling context and temporal dynamics has used
recurrent methods, which are slow and prone to overfitting. Here we introduce
TempoFormer, the first task-agnostic transformer-based and temporally-aware
model for dynamic representation learning. Our approach is jointly trained on
inter and intra context dynamics and introduces a novel temporal variation of
rotary positional embeddings. The architecture is flexible and can be used as
the temporal representation foundation of other models or applied to different
transformer-based architectures. We show new SOTA performance on three
different real-time change detection tasks.",2024-08-28,"Talia Tseriotou, Adam Tsakalidis, Maria Liakata",http://arxiv.org/pdf/2408.15689v2,cs.CL
StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements,"Authorship obfuscation, rewriting a text to intentionally obscure the
identity of the author, is an important but challenging task. Current methods
using large language models (LLMs) lack interpretability and controllability,
often ignoring author-specific stylistic features, resulting in less robust
performance overall.
  To address this, we develop StyleRemix, an adaptive and interpretable
obfuscation method that perturbs specific, fine-grained style elements of the
original input text. StyleRemix uses pre-trained Low Rank Adaptation (LoRA)
modules to rewrite an input specifically along various stylistic axes (e.g.,
formality and length) while maintaining low computational cost. StyleRemix
outperforms state-of-the-art baselines and much larger LLMs in a variety of
domains as assessed by both automatic and human evaluation.
  Additionally, we release AuthorMix, a large set of 30K high-quality,
long-form texts from a diverse set of 14 authors and 4 domains, and DiSC, a
parallel corpus of 1,500 texts spanning seven style axes in 16 unique
directions",2024-08-28,"Jillian Fisher, Skyler Hallinan, Ximing Lu, Mitchell Gordon, Zaid Harchaoui, Yejin Choi",http://arxiv.org/pdf/2408.15666v1,cs.CL
Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts,"For Mixture-of-Experts (MoE) models, an unbalanced expert load will lead to
routing collapse or increased computational overhead. Existing methods commonly
employ an auxiliary loss to encourage load balance, but a large auxiliary loss
will introduce non-negligible interference gradients into training and thus
impair the model performance. In order to control load balance while not
producing undesired gradients during training, we propose Loss-Free Balancing,
featured by an auxiliary-loss-free load balancing strategy. To be specific,
before the top-K routing decision, Loss-Free Balancing will first apply an
expert-wise bias to the routing scores of each expert. By dynamically updating
the bias of each expert according to its recent load, Loss-Free Balancing can
consistently maintain a balanced distribution of expert load. In addition,
since Loss-Free Balancing does not produce any interference gradients, it also
elevates the upper bound of model performance gained from MoE training. We
validate the performance of Loss-Free Balancing on MoE models with up to 3B
parameters trained on up to 200B tokens. Experimental results show that
Loss-Free Balancing achieves both better performance and better load balance
compared with traditional auxiliary-loss-controlled load balancing strategies.",2024-08-28,"Lean Wang, Huazuo Gao, Chenggang Zhao, Xu Sun, Damai Dai",http://arxiv.org/pdf/2408.15664v1,cs.CL
Harnessing the Intrinsic Knowledge of Pretrained Language Models for Challenging Text Classification Settings,"Text classification is crucial for applications such as sentiment analysis
and toxic text filtering, but it still faces challenges due to the complexity
and ambiguity of natural language. Recent advancements in deep learning,
particularly transformer architectures and large-scale pretraining, have
achieved inspiring success in NLP fields. Building on these advancements, this
thesis explores three challenging settings in text classification by leveraging
the intrinsic knowledge of pretrained language models (PLMs). Firstly, to
address the challenge of selecting misleading yet incorrect distractors for
cloze questions, we develop models that utilize features based on
contextualized word representations from PLMs, achieving performance that
rivals or surpasses human accuracy. Secondly, to enhance model generalization
to unseen labels, we create small finetuning datasets with domain-independent
task label descriptions, improving model performance and robustness. Lastly, we
tackle the sensitivity of large language models to in-context learning prompts
by selecting effective demonstrations, focusing on misclassified examples and
resolving model ambiguity regarding test example labels.",2024-08-28,Lingyu Gao,http://arxiv.org/pdf/2408.15650v1,cs.CL
"3-in-1: 2D Rotary Adaptation for Efficient Finetuning, Efficient Batching and Composability","Parameter-efficient finetuning (PEFT) methods effectively adapt large
language models (LLMs) to diverse downstream tasks, reducing storage and GPU
memory demands. Despite these advantages, several applications pose new
challenges to PEFT beyond mere parameter efficiency. One notable challenge
involves the efficient deployment of LLMs equipped with multiple task- or
user-specific adapters, particularly when different adapters are needed for
distinct requests within the same batch. Another challenge is the
interpretability of LLMs, which is crucial for understanding how LLMs function.
Previous studies introduced various approaches to address different challenges.
In this paper, we introduce a novel method, RoAd, which employs a
straightforward 2D rotation to adapt LLMs and addresses all the above
challenges: (1) RoAd is remarkably parameter-efficient, delivering optimal
performance on GLUE, eight commonsense reasoning tasks and four arithmetic
reasoning tasks with $<0.1\%$ trainable parameters; (2) RoAd facilitates the
efficient serving of requests requiring different adapters within a batch, with
an overhead comparable to element-wise multiplication instead of batch matrix
multiplication; (3) RoAd enhances LLM's interpretability through integration
within a framework of distributed interchange intervention, demonstrated via
composition experiments.",2024-08-28,"Baohao Liao, Christof Monz",http://arxiv.org/pdf/2409.00119v2,cs.CL
CBF-LLM: Safe Control for LLM Alignment,"This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the safety
filter, designed based on the CBF, to the output generation of the baseline
LLM, i.e., the sequence of the token, with the aim of intervening in the
generated text. The overall text-generation system is implemented with Llama 3
and a RoBERTa model, and the source code is available at
https://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control
ability and effectiveness in reducing the number of interventions needed for
user-specified alignment tasks.",2024-08-28,"Yuya Miyaoka, Masaki Inoue",http://arxiv.org/pdf/2408.15625v2,cs.CL
Beyond Levenshtein: Leveraging Multiple Algorithms for Robust Word Error Rate Computations And Granular Error Classifications,"The Word Error Rate (WER) is the common measure of accuracy for Automatic
Speech Recognition (ASR). Transcripts are usually pre-processed by substituting
specific characters to account for non-semantic differences. As a result of
this normalisation, information on the accuracy of punctuation or
capitalisation is lost. We present a non-destructive, token-based approach
using an extended Levenshtein distance algorithm to compute a robust WER and
additional orthographic metrics. Transcription errors are also classified more
granularly by existing string similarity and phonetic algorithms. An evaluation
on several datasets demonstrates the practical equivalence of our approach
compared to common WER computations. We also provide an exemplary analysis of
derived use cases, such as a punctuation error rate, and a web application for
interactive use and visualisation of our implementation. The code is available
open-source.",2024-08-28,"Korbinian Kuhn, Verena Kersken, Gottfried Zimmermann",http://arxiv.org/pdf/2408.15616v1,cs.CL
SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models,"There is a growing trend of teaching large language models (LLMs) to solve
mathematical problems through coding. Existing studies primarily focus on
prompting powerful, closed-source models to generate seed training data
followed by in-domain data augmentation, equipping LLMs with considerable
capabilities for code-aided mathematical reasoning. However, continually
training these models on augmented data derived from a few datasets such as
GSM8K may impair their generalization abilities and restrict their
effectiveness to a narrow range of question types. Conversely, the potential of
improving such LLMs by leveraging large-scale, expert-written, diverse math
question-answer pairs remains unexplored. To utilize these resources and tackle
unique challenges such as code response assessment, we propose a novel paradigm
that uses a code-based critic model to guide steps including question-code data
construction, quality control, and complementary evaluation. We also explore
different alignment algorithms with self-generated instruction/preference data
to foster continuous improvement. Experiments across both in-domain (up to
+5.7%) and out-of-domain (+4.4%) benchmarks in English and Chinese demonstrate
the effectiveness of the proposed paradigm.",2024-08-28,"Dian Yu, Baolin Peng, Ye Tian, Linfeng Song, Haitao Mi, Dong Yu",http://arxiv.org/pdf/2408.15565v1,cs.CL
Boosting Lossless Speculative Decoding via Feature Sampling and Partial Alignment Distillation,"Lossless speculative decoding accelerates target large language model (LLM)
inference by employing a lightweight draft model for generating tree-structured
candidates, which are subsequently verified in parallel by the target LLM.
Currently, effective approaches leverage feature-level rather than token-level
autoregression within the draft model to facilitate more straightforward
predictions and enhanced knowledge distillation. In this paper, we reassess
these approaches and propose FSPAD (Feature Sampling and Partial Alignment
Distillation for Lossless Speculative Decoding), which introduces two
straightforward and effective components within the existing framework to boost
lossless speculative decoding. Firstly, FSPAD utilizes token embeddings to
sample features of the target LLM in high-dimensional space before feeding them
into the draft model, due to the inherent uncertainty of the features
preventing the draft model from obtaining the specific token output by the
target LLM. Secondly, FSPAD introduces partial alignment distillation to weaken
the draft model's connection between features and logits, aiming to reduce the
conflict between feature alignment and logit confidence during training. Our
experiments include both greedy and non-greedy decoding on the largest and
smallest models from the Vicuna and LLaMA3-Instruct series, as well as tasks in
multi-turn conversation, translation, summarization, question answering,
mathematical reasoning, and retrieval-augmented generation. The results show
that FSPAD outperforms the state-of-the-art method across all the
aforementioned tasks and target LLMs.",2024-08-28,"Lujun Gui, Bin Xiao, Lei Su, Weipeng Chen",http://arxiv.org/pdf/2408.15562v1,cs.CL
WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback,"As large language models (LLMs) continue to advance, aligning these models
with human preferences has emerged as a critical challenge. Traditional
alignment methods, relying on human or LLM annotated datasets, are limited by
their resource-intensive nature, inherent subjectivity, misalignment with
real-world user preferences, and the risk of feedback loops that amplify model
biases. To overcome these limitations, we introduce WildFeedback, a novel
framework that leverages in-situ user feedback during conversations with LLMs
to create preference datasets automatically. Given a corpus of multi-turn
user-LLM conversation, WildFeedback identifies and classifies user feedback to
LLM responses between conversation turns. The user feedback is then used to
create examples of preferred and dispreferred responses according to users'
preference. Our experiments demonstrate that LLMs fine-tuned on WildFeedback
dataset exhibit significantly improved alignment with user preferences, as
evidenced by both traditional benchmarks and our proposed checklist-guided
evaluation. By incorporating in-situ feedback from actual users, WildFeedback
addresses the scalability, subjectivity, and bias challenges that plague
existing approaches, marking a significant step toward developing LLMs that are
more responsive to the diverse and evolving needs of their users.",2024-08-28,"Taiwei Shi, Zhuoer Wang, Longqi Yang, Ying-Chun Lin, Zexue He, Mengting Wan, Pei Zhou, Sujay Jauhar, Sihao Chen, Shan Xia, Hongfei Zhang, Jieyu Zhao, Xiaofeng Xu, Xia Song, Jennifer Neville",http://arxiv.org/pdf/2408.15549v3,cs.CL
SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding,"Scientific literature understanding is crucial for extracting targeted
information and garnering insights, thereby significantly advancing scientific
discovery. Despite the remarkable success of Large Language Models (LLMs), they
face challenges in scientific literature understanding, primarily due to (1) a
lack of scientific knowledge and (2) unfamiliarity with specialized scientific
tasks.
  To develop an LLM specialized in scientific literature understanding, we
propose a hybrid strategy that integrates continual pre-training (CPT) and
supervised fine-tuning (SFT), to simultaneously infuse scientific domain
knowledge and enhance instruction-following capabilities for domain-specific
tasks.cIn this process, we identify two key challenges: (1) constructing
high-quality CPT corpora, and (2) generating diverse SFT instructions. We
address these challenges through a meticulous pipeline, including PDF text
extraction, parsing content error correction, quality filtering, and synthetic
instruction creation. Applying this strategy, we present a suite of LLMs:
SciLitLLM, specialized in scientific literature understanding. These models
demonstrate promising performance on scientific literature understanding
benchmarks.
  Our contributions are threefold: (1) We present an effective framework that
integrates CPT and SFT to adapt LLMs to scientific literature understanding,
which can also be easily adapted to other domains. (2) We propose an LLM-based
synthesis method to generate diverse and high-quality scientific instructions,
resulting in a new instruction set -- SciLitIns -- for supervised fine-tuning
in less-represented scientific domains. (3) SciLitLLM achieves promising
performance improvements on scientific literature understanding benchmarks.",2024-08-28,"Sihang Li, Jin Huang, Jiaxi Zhuang, Yaorui Shi, Xiaochen Cai, Mingjun Xu, Xiang Wang, Linfeng Zhang, Guolin Ke, Hengxing Cai",http://arxiv.org/pdf/2408.15545v5,cs.CL
An Investigation of Warning Erroneous Chat Translations in Cross-lingual Communication,"Machine translation models are still inappropriate for translating chats,
despite the popularity of translation software and plug-in applications. The
complexity of dialogues poses significant challenges and can hinder
crosslingual communication. Instead of pursuing a flawless translation system,
a more practical approach would be to issue warning messages about potential
mistranslations to reduce confusion. However, it is still unclear how
individuals perceive these warning messages and whether they benefit the crowd.
This paper tackles to investigate this question and demonstrates the warning
messages' contribution to making chat translation systems effective.",2024-08-28,"Yunmeng Li, Jun Suzuki, Makoto Morishita, Kaori Abe, Kentaro Inui",http://arxiv.org/pdf/2408.15543v2,cs.CL
LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation,"Retrieval-Augmented Generation (RAG) has become a primary technique for
mitigating hallucinations in large language models (LLMs). However, incomplete
knowledge extraction and insufficient understanding can still mislead LLMs to
produce irrelevant or even contradictory responses, which means hallucinations
persist in RAG. In this paper, we propose LRP4RAG, a method based on the
Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations
in RAG. Specifically, we first utilize LRP to compute the relevance between the
input and output of the RAG generator. We then apply further extraction and
resampling to the relevance matrix. The processed relevance data are input into
multiple classifiers to determine whether the output contains hallucinations.
To the best of our knowledge, this is the first time that LRP has been used for
detecting RAG hallucinations, and extensive experiments demonstrate that
LRP4RAG outperforms existing baselines.",2024-08-28,"Haichuan Hu, Yuhan Sun, Quanjun Zhang",http://arxiv.org/pdf/2408.15533v2,cs.CL
FedMCP: Parameter-Efficient Federated Learning with Model-Contrastive Personalization,"With increasing concerns and regulations on data privacy, fine-tuning
pretrained language models (PLMs) in federated learning (FL) has become a
common paradigm for NLP tasks. Despite being extensively studied, the existing
methods for this problem still face two primary challenges. First, the huge
number of parameters in large-scale PLMs leads to excessive communication and
computational overhead. Second, the heterogeneity of data and tasks across
clients poses a significant obstacle to achieving the desired fine-tuning
performance. To address the above problems, we propose FedMCP, a novel
parameter-efficient fine-tuning method with model-contrastive personalization
for FL. Specifically, FedMCP adds two lightweight adapter modules, i.e., the
global adapter and the private adapter, to the frozen PLMs within clients. In a
communication round, each client sends only the global adapter to the server
for federated aggregation. Furthermore, FedMCP introduces a model-contrastive
regularization term between the two adapters. This, on the one hand, encourages
the global adapter to assimilate universal knowledge and, on the other hand,
the private adapter to capture client-specific knowledge. By leveraging both
adapters, FedMCP can effectively provide fine-tuned personalized models
tailored to individual clients. Extensive experiments on highly heterogeneous
cross-task, cross-silo datasets show that FedMCP achieves substantial
performance improvements over state-of-the-art FL fine-tuning approaches for
PLMs.",2024-08-28,"Qianyi Zhao, Chen Qu, Cen Chen, Mingyuan Fan, Yanhao Wang",http://arxiv.org/pdf/2409.00116v1,cs.CL
Squid: Long Context as a New Modality for Energy-Efficient On-Device Language Models,"This paper presents Dolphin, a novel decoder-decoder architecture for
energy-efficient processing of long contexts in language models. Our approach
addresses the significant energy consumption and latency challenges inherent in
on-device models. Dolphin employs a compact 0.5B parameter decoder to distill
extensive contextual information into a memory embedding, substantially
reducing the input length for the primary 7B parameter decoder model. Inspired
by vision-language models, we repurpose the image embedding projector to encode
long textual contexts, effectively treating extended context as a distinct
modality. This innovative method enables processing of substantially longer
contexts without the typical computational overhead associated with extended
input sequences. Empirical evaluations demonstrate a 10-fold improvement in
energy efficiency and a 5-fold reduction in latency compared to conventional
full-length context processing methods without losing quality of the response.
Our work contributes to the development of more sustainable and scalable
language models for on-device applications, addressing the critical need for
energy-efficient and responsive AI technologies in resource-constrained
environments while maintaining the accuracy to understand long contexts. This
research has implications for the broader field of natural language processing,
particularly in the domain of efficient model design for resource-limited
settings. By enabling more sophisticated AI capabilities on edge devices,
Dolphin paves the way for advanced language processing in a wide range of
applications where computational resources are at a premium. The Dolphin model
is publicly available at https://huggingface.co/NexaAIDev/Dolphin.",2024-08-28,"Wei Chen, Zhiyuan Li, Shuo Xin, Yihao Wang",http://arxiv.org/pdf/2408.15518v2,cs.CL
Toward Automated Simulation Research Workflow through LLM Prompt Engineering Design,"The advent of Large Language Models (LLMs) has created new opportunities for
the automation of scientific research spanning both experimental processes and
computational simulations. This study explores the feasibility of constructing
an autonomous simulation agent (ASA) powered by LLMs through prompt engineering
and automated program design to automate the entire simulation research process
according to a human-provided research plan. This process includes experimental
design, remote upload and simulation execution, data analysis, and report
compilation. Using a well-studied simulation problem of polymer chain
conformations as a test case, we assessed the long-task completion and
reliability of ASAs powered by different LLMs, including GPT-4o, Claude-3.5,
etc. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on
designated research missions, underscoring the potential of methods like ASA to
achieve automation in simulation research processes to enhance research
efficiency. The outlined automation can be iteratively performed for up to 20
cycles without human intervention, illustrating the potential of ASA for
long-task workflow automation. Additionally, we discussed the intrinsic traits
of ASA in managing extensive tasks, focusing on self-validation mechanisms, and
the balance between local attention and global oversight.",2024-08-28,"Zhihan Liu, Yubo Chai, Jianfeng Li",http://arxiv.org/pdf/2408.15512v3,cs.CL
How Reliable are Causal Probing Interventions?,"Causal probing aims to analyze foundation models by examining how intervening
on their representation of various latent properties impacts their outputs.
Recent works have cast doubt on the theoretical basis of several leading causal
probing methods, but it has been unclear how to systematically evaluate the
effectiveness of these methods in practice. To address this, we define two key
causal probing desiderata: completeness (how thoroughly the representation of
the target property has been transformed) and selectivity (how little
non-targeted properties have been impacted). We find that there is an inherent
tradeoff between the two, which we define as reliability, their harmonic mean.
We introduce an empirical analysis framework to measure and evaluate these
quantities, allowing us to make the first direct comparisons between different
families of leading causal probing methods (e.g., linear vs. nonlinear, or
concept removal vs. counterfactual interventions). We find that: (1) no method
is reliable across all layers; (2) more reliable methods have a greater impact
on LLM behavior; (3) nonlinear interventions are more reliable in early and
intermediate layers, and linear interventions are more reliable in later
layers; and (4) concept removal methods are far less reliable than
counterfactual interventions, suggesting that they may not be an effective
approach to causal probing.",2024-08-28,"Marc Canby, Adam Davies, Chirag Rastogi, Julia Hockenmaier",http://arxiv.org/pdf/2408.15510v3,cs.CL
ReMamba: Equip Mamba with Effective Long-Sequence Modeling,"While the Mamba architecture demonstrates superior inference efficiency and
competitive performance on short-context natural language processing (NLP)
tasks, empirical evidence suggests its capacity to comprehend long contexts is
limited compared to transformer-based models. In this study, we investigate the
long-context efficiency issues of the Mamba models and propose ReMamba, which
enhances Mamba's ability to comprehend long contexts. ReMamba incorporates
selective compression and adaptation techniques within a two-stage re-forward
process, incurring minimal additional inference costs overhead. Experimental
results on the LongBench and L-Eval benchmarks demonstrate ReMamba's efficacy,
improving over the baselines by 3.2 and 1.6 points, respectively, and attaining
performance almost on par with same-size transformer models.",2024-08-28,"Danlong Yuan, Jiahao Liu, Bei Li, Huishuai Zhang, Jingang Wang, Xunliang Cai, Dongyan Zhao",http://arxiv.org/pdf/2408.15496v4,cs.CL
Enhancing and Accelerating Large Language Models via Instruction-Aware Contextual Compression,"Large Language Models (LLMs) have garnered widespread attention due to their
remarkable performance across various tasks. However, to mitigate the issue of
hallucinations, LLMs often incorporate retrieval-augmented pipeline to provide
them with rich external knowledge and context. Nevertheless, challenges stem
from inaccurate and coarse-grained context retrieved from the retriever.
Supplying irrelevant context to the LLMs can result in poorer responses,
increased inference latency, and higher costs. This paper introduces a method
called Instruction-Aware Contextual Compression, which filters out less
informative content, thereby accelerating and enhancing the use of LLMs. The
experimental results demonstrate that Instruction-Aware Contextual Compression
notably reduces memory consumption and minimizes generation latency while
maintaining performance levels comparable to those achieved with the use of the
full context. Specifically, we achieved a 50% reduction in context-related
costs, resulting in a 5% reduction in inference memory usage and a 2.2-fold
increase in inference speed, with only a minor drop of 0.047 in Rouge-1. These
findings suggest that our method strikes an effective balance between
efficiency and performance.",2024-08-28,"Haowen Hou, Fei Ma, Binwen Bai, Xinxin Zhu, Fei Yu",http://arxiv.org/pdf/2408.15491v1,cs.CL
Legilimens: Practical and Unified Content Moderation for Large Language Model Services,"Given the societal impact of unsafe content generated by large language
models (LLMs), ensuring that LLM services comply with safety standards is a
crucial concern for LLM service providers. Common content moderation methods
are limited by an effectiveness-and-efficiency dilemma, where simple models are
fragile while sophisticated models consume excessive computational resources.
In this paper, we reveal for the first time that effective and efficient
content moderation can be achieved by extracting conceptual features from
chat-oriented LLMs, despite their initial fine-tuning for conversation rather
than content moderation. We propose a practical and unified content moderation
framework for LLM services, named Legilimens, which features both effectiveness
and efficiency. Our red-team model-based data augmentation enhances the
robustness of Legilimens against state-of-the-art jailbreaking. Additionally,
we develop a framework to theoretically analyze the cost-effectiveness of
Legilimens compared to other methods. We have conducted extensive experiments
on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify
the effectiveness, efficiency, and robustness of Legilimens against normal and
adaptive adversaries. A comparison of Legilimens with both commercial and
academic baselines demonstrates the superior performance of Legilimens.
Furthermore, we confirm that Legilimens can be applied to few-shot scenarios
and extended to multi-label classification tasks.",2024-08-28,"Jialin Wu, Jiangyi Deng, Shengyuan Pang, Yanjiao Chen, Jiayang Xu, Xinfeng Li, Wenyuan Xu",http://arxiv.org/pdf/2408.15488v2,cs.CL
Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns to Model Representations,"Next-token prediction (NTP) over large text corpora has become the go-to
paradigm to train large language models. Yet, it remains unclear how NTP
influences the mapping of linguistic patterns to geometric properties of the
resulting model representations. We frame training of large language models as
soft-label classification over sparse probabilistic label vectors, coupled with
an analytical approximation that allows unrestricted generation of context
embeddings. This approach links NTP training to rank-constrained, nuclear-norm
regularized optimization in the logit domain, offering a framework for
analyzing the geometry of word and context embeddings. In large embedding
spaces, we find that NTP implicitly favors learning logits with a sparse plus
low-rank structure. While the sparse component captures the co-occurrence
frequency of context-word pairs, the orthogonal low-rank component, which
becomes dominant as training progresses, depends solely on the sparsity pattern
of the co-occurrence matrix. Consequently, when projected onto an appropriate
subspace, representations of contexts that are followed by the same set of
next-tokens collapse, a phenomenon we term subspace-collapse. We validate our
findings on synthetic and small-scale real language datasets. Finally, we
outline potential research directions aimed at deepening the understanding of
NTP's influence on the learning of linguistic patterns and regularities.",2024-08-27,"Yize Zhao, Tina Behnia, Vala Vakilian, Christos Thrampoulidis",http://arxiv.org/pdf/2408.15417v2,cs.CL
"Awes, Laws, and Flaws From Today's LLM Research","We perform a critical examination of the scientific methodology behind
contemporary large language model (LLM) research. For this we assess over 2,000
research works based on criteria typical of what is considered good research
(e.g. presence of statistical tests and reproducibility) and cross-validate it
with arguments that are at the centre of controversy (e.g., claims of emergent
behaviour, the use of LLMs as evaluators). We find multiple trends, such as
declines in claims of emergent behaviour and ethics disclaimers; the rise of
LLMs as evaluators in spite of a lack of consensus from the community about
their useability; and an increase of claims of LLM reasoning abilities,
typically without leveraging human evaluation. This paper underscores the need
for more scrutiny and rigour by and from this field to live up to the
fundamentals of a responsible scientific method that is ethical, reproducible,
systematic, and open to criticism.",2024-08-27,Adrian de Wynter,http://arxiv.org/pdf/2408.15409v2,cs.CL
Intertwined Biases Across Social Media Spheres: Unpacking Correlations in Media Bias Dimensions,"Media bias significantly shapes public perception by reinforcing stereotypes
and exacerbating societal divisions. Prior research has often focused on
isolated media bias dimensions such as \textit{political bias} or
\textit{racial bias}, neglecting the complex interrelationships among various
bias dimensions across different topic domains. Moreover, we observe that
models trained on existing media bias benchmarks fail to generalize effectively
on recent social media posts, particularly in certain bias identification
tasks. This shortfall primarily arises because these benchmarks do not
adequately reflect the rapidly evolving nature of social media content, which
is characterized by shifting user behaviors and emerging trends. In response to
these limitations, our research introduces a novel dataset collected from
YouTube and Reddit over the past five years. Our dataset includes automated
annotations for YouTube content across a broad spectrum of bias dimensions,
such as gender, racial, and political biases, as well as hate speech, among
others. It spans diverse domains including politics, sports, healthcare,
education, and entertainment, reflecting the complex interplay of biases across
different societal sectors. Through comprehensive statistical analysis, we
identify significant differences in bias expression patterns and intra-domain
bias correlations across these domains. By utilizing our understanding of the
correlations among various bias dimensions, we lay the groundwork for creating
advanced systems capable of detecting multiple biases simultaneously. Overall,
our dataset advances the field of media bias identification, contributing to
the development of tools that promote fairer media consumption. The
comprehensive awareness of existing media bias fosters more ethical journalism,
promotes cultural sensitivity, and supports a more informed and equitable
public discourse.",2024-08-27,"Yifan Liu, Yike Li, Dong Wang",http://arxiv.org/pdf/2408.15406v1,cs.CL
A Statistical Framework for Data-dependent Retrieval-Augmented Models,"Modern ML systems increasingly augment input instances with additional
relevant information to enhance final prediction. Despite growing interest in
such retrieval-augmented models, their fundamental properties and training are
not well understood. We propose a statistical framework to study such models
with two components: 1) a {\em retriever} to identify the relevant information
out of a large corpus via a data-dependent metric; and 2) a {\em predictor}
that consumes the input instances along with the retrieved information to make
the final predictions. We present a principled method for end-to-end training
of both components and draw connections with various training approaches in the
literature. Furthermore, we establish excess risk bounds for
retrieval-augmented models while delineating the contributions of both
retriever and predictor towards the model performance. We validate the utility
of our proposed training methods along with the key takeaways from our
statistical analysis on open domain question answering task where retrieval
augmentation is important.",2024-08-27,"Soumya Basu, Ankit Singh Rawat, Manzil Zaheer",http://arxiv.org/pdf/2408.15399v1,cs.CL
DualKanbaFormer: An Efficient Selective Sparse Framework for Multimodal Aspect-based Sentiment Analysis,"Multimodal Aspect-based Sentiment Analysis (MABSA) enhances sentiment
detection by integrating textual data with complementary modalities, such as
images, to provide a more refined and comprehensive understanding of sentiment.
However, conventional attention mechanisms, despite notable benchmarks, are
hindered by quadratic complexity, limiting their ability to fully capture
global contextual dependencies and rich semantic information in both
modalities. To address this limitation, we introduce DualKanbaFormer, a novel
framework that leverages parallel Textual and Visual KanbaFormer modules for
robust multimodal analysis. Our approach incorporates Aspect-Driven Sparse
Attention (ADSA) to dynamically balance coarse-grained aggregation and
fine-grained selection for aspect-focused precision, ensuring the preservation
of both global context awareness and local precision in textual and visual
representations. Additionally, we utilize the Selective State Space Model
(Mamba) to capture extensive global semantic information across both
modalities. Furthermore, We replace traditional feed-forward networks and
normalization with Kolmogorov-Arnold Networks (KANs) and Dynamic Tanh (DyT) to
enhance non-linear expressivity and inference stability. To facilitate the
effective integration of textual and visual features, we design a multimodal
gated fusion layer that dynamically optimizes inter-modality interactions,
significantly enhancing the models efficacy in MABSA tasks. Comprehensive
experiments on two publicly available datasets reveal that DualKanbaFormer
consistently outperforms several state-of-the-art (SOTA) models.",2024-08-27,"Adamu Lawan, Juhua Pu, Haruna Yunusa, Muhammad Lawan, Aliyu Umar, Adamu Sani Yahya, Mahmoud Basi",http://arxiv.org/pdf/2408.15379v3,cs.CL
"Wait, that's not an option: LLMs Robustness with Incorrect Multiple-Choice Options","Decision-making under full alignment requires balancing between reasoning and
faithfulness - a challenge for large language models (LLMs). This study
explores whether LLMs prioritize following instructions over reasoning and
truth when given ""misleading"" instructions, such as ""Respond solely with A or
B"", even when neither option is correct. We introduce a new metric called
""reflective judgment"", which sheds new light on the relationship between the
pre-training and post-training alignment schemes. In tasks ranging from basic
arithmetic to domain-specific assessments, models like GPT-4o, o1-mini, or
Claude 3 Opus adhered to instructions correctly but failed to reflect on the
validity of the provided options. Contrary, models from the Llama 3.1 family
(8B, 70B, 405B) or base Qwen2.5 (7B, 14B, 32B) families exhibit improved
refusal rates with size, indicating a scaling effect. We also observed that
alignment techniques, though intended to enhance reasoning, sometimes weakened
the models' ability to reject incorrect instructions, leading them to follow
flawed prompts uncritically. Finally, we have also conducted a parallel human
study revealing similar patterns in human behavior and annotations. We
highlight how popular RLHF datasets might disrupt either training or evaluation
due to annotations exhibiting poor reflective judgement.",2024-08-27,"Gracjan Góral, Emilia Wiśnios, Piotr Sankowski, Paweł Budzianowski",http://arxiv.org/pdf/2409.00113v2,cs.CL
Pitfalls and Outlooks in Using COMET,"The COMET metric has blazed a trail in the machine translation community,
given its strong correlation with human judgements of translation quality. Its
success stems from being a modified pre-trained multilingual model finetuned
for quality assessment. However, it being a machine learning model also gives
rise to a new set of pitfalls that may not be widely known. We investigate
these unexpected behaviours from three aspects: 1) technical: obsolete software
versions and compute precision; 2) data: empty content, language mismatch, and
translationese at test time as well as distribution and domain biases in
training; 3) usage and reporting: multi-reference support and model referencing
in the literature. All of these problems imply that COMET scores are not
comparable between papers or even technical setups and we put forward our
perspective on fixing each issue. Furthermore, we release the sacreCOMET
package that can generate a signature for the software and model configuration
as well as an appropriate citation. The goal of this work is to help the
community make more sound use of the COMET metric.",2024-08-27,"Vilém Zouhar, Pinzhen Chen, Tsz Kin Lam, Nikita Moghe, Barry Haddow",http://arxiv.org/pdf/2408.15366v3,cs.CL
"UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function","An LLM is pretrained on trillions of tokens, but the pretrained LLM may still
generate undesired responses. To solve this problem, alignment techniques such
as RLHF, DPO and KTO are proposed. However, these alignment techniques have
limitations. For example, RLHF requires training the reward model and policy
separately, which is complex, time-consuming, memory intensive and unstable
during training processes. DPO proposes a mapping between an optimal policy and
a reward, greatly simplifying the training process of RLHF. However, it can not
take full advantages of a reward model and it is limited to pairwise preference
data.
  In this paper, we propose \textbf{UN}ified \textbf{A}lignment (UNA) which
unifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the
classical RLHF objective, the optimal policy is induced by a generalize
implicit reward function. With this novel mapping between a reward model and an
optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised
learning of minimizing the difference between an implicit reward and an
explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and
reduce memory burden of RL fine-tuning process; 3. accommodate different
feedback types including pairwise, binary and scalar feedback. Downstream
experiments show UNA outperforms DPO, KTO and RLHF.",2024-08-27,"Zhichao Wang, Bin Bi, Can Huang, Shiva Kumar Pentyala, Zixu James Zhu, Sitaram Asur, Na Claire Cheng",http://arxiv.org/pdf/2408.15339v3,cs.CL
Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations,"While language model (LM)-powered chatbots and generative search engines
excel at answering concrete queries, discovering information in the terrain of
unknown unknowns remains challenging for users. To emulate the common
educational scenario where children/students learn by listening to and
participating in conversations of their parents/teachers, we create
Collaborative STORM (Co-STORM). Unlike QA systems that require users to ask all
the questions, Co-STORM lets users observe and occasionally steer the discourse
among several LM agents. The agents ask questions on the user's behalf,
allowing the user to discover unknown unknowns serendipitously. To facilitate
user interaction, Co-STORM assists users in tracking the discourse by
organizing the uncovered information into a dynamic mind map, ultimately
generating a comprehensive report as takeaways. For automatic evaluation, we
construct the WildSeek dataset by collecting real information-seeking records
with user goals. Co-STORM outperforms baseline methods on both discourse trace
and report quality. In a further human evaluation, 70% of participants prefer
Co-STORM over a search engine, and 78% favor it over a RAG chatbot.",2024-08-27,"Yucheng Jiang, Yijia Shao, Dekun Ma, Sina J. Semnani, Monica S. Lam",http://arxiv.org/pdf/2408.15232v2,cs.CL
LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet,"Recent large language model (LLM) defenses have greatly improved models'
ability to refuse harmful queries, even when adversarially attacked. However,
LLM defenses are primarily evaluated against automated adversarial attacks in a
single turn of conversation, an insufficient threat model for real-world
malicious use. We demonstrate that multi-turn human jailbreaks uncover
significant vulnerabilities, exceeding 70% attack success rate (ASR) on
HarmBench against defenses that report single-digit ASRs with automated
single-turn attacks. Human jailbreaks also reveal vulnerabilities in machine
unlearning defenses, successfully recovering dual-use biosecurity knowledge
from unlearned models. We compile these results into Multi-Turn Human
Jailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks.
We publicly release MHJ alongside a compendium of jailbreak tactics developed
across dozens of commercial red teaming engagements, supporting research
towards stronger LLM defenses.",2024-08-27,"Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, Summer Yue",http://arxiv.org/pdf/2408.15221v2,cs.CL
Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models,"Fine-tuning large language models (LLMs) on human preferences, typically
through reinforcement learning from human feedback (RLHF), has proven
successful in enhancing their capabilities. However, ensuring the safety of
LLMs during fine-tuning remains a critical concern, and mitigating the
potential conflicts in safety and helpfulness is costly in RLHF. To address
this issue, we propose a supervised learning framework called Bi-Factorial
Preference Optimization (BFPO), which re-parameterizes a joint RLHF objective
of both safety and helpfulness into a single supervised learning objective. In
supervised optimization, a labeling function is used to capture the global
preferences ranking to balance both safety and helpfulness. To evaluate BFPO,
we develop a benchmark that includes comprehensive discriminative and
generative tasks for helpfulness and harmlessness. The results indicate that
our method significantly outperforms existing approaches in both safety and
helpfulness. Moreover, BFPO achieves the same level of safety as methods that
heavily rely on human labor with less than 10\% of the computational resources
and human prompting and annotation process. The training recipes can be found
here: https://github.com/wx-zhang/bfpo.",2024-08-27,"Wenxuan Zhang, Philip H. S. Torr, Mohamed Elhoseiny, Adel Bibi",http://arxiv.org/pdf/2408.15313v2,cs.CL
Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy,"While Large Language Models (LLMs) are being quickly adapted to many domains,
including healthcare, their strengths and pitfalls remain under-explored. In
our study, we examine the effects of prompt engineering to guide Large Language
Models (LLMs) in delivering parts of a Problem-Solving Therapy (PST) session
via text, particularly during the symptom identification and assessment phase
for personalized goal setting. We present evaluation results of the models'
performances by automatic metrics and experienced medical professionals. We
demonstrate that the models' capability to deliver protocolized therapy can be
improved with the proper use of prompt engineering methods, albeit with
limitations. To our knowledge, this study is among the first to assess the
effects of various prompting techniques in enhancing a generalist model's
ability to deliver psychotherapy, focusing on overall quality, consistency, and
empathy. Exploring LLMs' potential in delivering psychotherapy holds promise
with the current shortage of mental health professionals amid significant
needs, enhancing the potential utility of AI-based and AI-enhanced care
services.",2024-08-27,"Daniil Filienko, Yinzhou Wang, Caroline El Jazmi, Serena Xie, Trevor Cohen, Martine De Cock, Weichao Yuwen",http://arxiv.org/pdf/2409.00112v1,cs.CL
Classifying populist language in American presidential and governor speeches using automatic text analysis,"Populism is a concept that is often used but notoriously difficult to
measure. Common qualitative measurements like holistic grading or content
analysis require great amounts of time and labour, making it difficult to
quickly scope out which politicians should be classified as populist and which
should not, while quantitative methods show mixed results when it comes to
classifying populist rhetoric. In this paper, we develop a pipeline to train
and validate an automated classification model to estimate the use of populist
language. We train models based on sentences that were identified as populist
and pluralist in 300 US governors' speeches from 2010 to 2018 and in 45
speeches of presidential candidates in 2016. We find that these models classify
most speeches correctly, including 84% of governor speeches and 89% of
presidential speeches. These results extend to different time periods (with 92%
accuracy on more recent American governors), different amounts of data (with as
few as 70 training sentences per category achieving similar results), and when
classifying politicians instead of individual speeches. This pipeline is thus
an effective tool that can optimise the systematic and swift classification of
the use of populist language in politicians' speeches.",2024-08-27,"Olaf van der Veen, Semir Dzebo, Levi Littvay, Kirk Hawkins, Oren Dar",http://arxiv.org/pdf/2408.15213v1,cs.CL
Can Unconfident LLM Annotations Be Used for Confident Conclusions?,"Large language models (LLMs) have shown high agreement with human raters
across a variety of tasks, demonstrating potential to ease the challenges of
human data collection. In computational social science (CSS), researchers are
increasingly leveraging LLM annotations to complement slow and expensive human
annotations. Still, guidelines for collecting and using LLM annotations,
without compromising the validity of downstream conclusions, remain limited. We
introduce Confidence-Driven Inference: a method that combines LLM annotations
and LLM confidence indicators to strategically select which human annotations
should be collected, with the goal of producing accurate statistical estimates
and provably valid confidence intervals while reducing the number of human
annotations needed. Our approach comes with safeguards against LLM annotations
of poor quality, guaranteeing that the conclusions will be both valid and no
less accurate than if we only relied on human annotations. We demonstrate the
effectiveness of Confidence-Driven Inference over baselines in statistical
estimation tasks across three CSS settings--text politeness, stance, and
bias--reducing the needed number of human annotations by over 25% in each.
Although we use CSS settings for demonstration, Confidence-Driven Inference can
be used to estimate most standard quantities across a broad range of NLP
problems.",2024-08-27,"Kristina Gligorić, Tijana Zrnic, Cinoo Lee, Emmanuel J. Candès, Dan Jurafsky",http://arxiv.org/pdf/2408.15204v2,cs.CL
Infusing Acoustic Pause Context into Text-Based Dementia Assessment,"Speech pauses, alongside content and structure, offer a valuable and
non-invasive biomarker for detecting dementia. This work investigates the use
of pause-enriched transcripts in transformer-based language models to
differentiate the cognitive states of subjects with no cognitive impairment,
mild cognitive impairment, and Alzheimer's dementia based on their speech from
a clinical assessment. We address three binary classification tasks: Onset,
monitoring, and dementia exclusion. The performance is evaluated through
experiments on a German Verbal Fluency Test and a Picture Description Test,
comparing the model's effectiveness across different speech production
contexts. Starting from a textual baseline, we investigate the effect of
incorporation of pause information and acoustic context. We show the test
should be chosen depending on the task, and similarly, lexical pause
information and acoustic cross-attention contribute differently.",2024-08-27,"Franziska Braun, Sebastian P. Bayerl, Florian Hönig, Hartmut Lehfeld, Thomas Hillemacher, Tobias Bocklet, Korbinian Riedhammer",http://arxiv.org/pdf/2408.15188v1,cs.CL
Unifying Multitrack Music Arrangement via Reconstruction Fine-Tuning and Efficient Tokenization,"Automatic music arrangement streamlines the creation of musical variants for
composers and arrangers, reducing reliance on extensive music expertise.
However, existing methods suffer from inefficient tokenization,
underutilization of pre-trained music language models (LMs), and suboptimal
fidelity and coherence in generated arrangements. This paper introduces an
efficient multitrack music tokenizer for unconditional and conditional symbolic
music generation, along with a unified sequence-to-sequence reconstruction
fine-tuning objective for pre-trained music LMs that balances task-specific
needs with coherence constraints. Our approach achieves state-of-the-art
results on band arrangement, piano reduction, and drum arrangement, surpassing
task-specific models in both objective metrics and perceptual quality.
Additionally, we demonstrate that generative pretraining significantly
contributes to the performance across these arrangement tasks, especially when
handling long segments with complex alignment.",2024-08-27,"Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Ye Wang",http://arxiv.org/pdf/2408.15176v2,cs.CL
X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation,"Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been
shown to enhance the effectiveness of enriching item descriptions, thereby
improving the accuracy of recommendation systems. However, most existing
approaches either rely on text-only prompting or employ basic multimodal
strategies that do not fully exploit the complementary information available
from both textual and visual modalities. This paper introduces a novel
framework, Cross-Reflection Prompting, termed X-Reflect, designed to address
these limitations by prompting LMMs to explicitly identify and reconcile
supportive and conflicting information between text and images. By capturing
nuanced insights from both modalities, this approach generates more
comprehensive and contextually richer item representations. Extensive
experiments conducted on two widely used benchmarks demonstrate that our method
outperforms existing prompting baselines in downstream recommendation accuracy.
Additionally, we evaluate the generalizability of our framework across
different LMM backbones and the robustness of the prompting strategies,
offering insights for optimization. This work underscores the importance of
integrating multimodal information and presents a novel solution for improving
item understanding in multimodal recommendation systems.",2024-08-27,"Hanjia Lyu, Ryan Rossi, Xiang Chen, Md Mehrab Tanjim, Stefano Petrangeli, Somdeb Sarkhel, Jiebo Luo",http://arxiv.org/pdf/2408.15172v1,cs.CL
Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation,"The use of large language models (LLMs) has significantly increased since the
introduction of ChatGPT in 2022, demonstrating their value across various
applications. However, a major challenge for enterprise and commercial adoption
of LLMs is their tendency to generate inaccurate information, a phenomenon
known as ""hallucination."" This project proposes a method for estimating the
factuality of a summary generated by LLMs when compared to a source text. Our
approach utilizes Naive Bayes classification to assess the accuracy of the
content produced.",2024-08-27,N. E. Kriman,http://arxiv.org/pdf/2408.15171v1,cs.CL
How transformers learn structured data: insights from hierarchical filtering,"Understanding the learning process and the embedded computation in
transformers is becoming a central goal for the development of interpretable
AI. In the present study, we introduce a hierarchical filtering procedure for
generative models of sequences on trees, allowing us to hand-tune the range of
positional correlations in the data. Leveraging this controlled setting, we
provide evidence that vanilla encoder-only transformers can approximate the
exact inference algorithm when trained on root classification and masked
language modeling tasks, and study how this computation is discovered and
implemented. We find that correlations at larger distances, corresponding to
increasing layers of the hierarchy, are sequentially included by the network
during training. Moreover, by comparing attention maps from models trained with
varying degrees of filtering and by probing the different encoder levels, we
find clear evidence of a reconstruction of correlations on successive length
scales corresponding to the various levels of the hierarchy, which we relate to
a plausible implementation of the exact inference algorithm within the same
architecture.",2024-08-27,"Jerome Garnier-Brun, Marc Mézard, Emanuele Moscato, Luca Saglietti",http://arxiv.org/pdf/2408.15138v2,cs.CL
Zero-Shot Visual Reasoning by Vision-Language Models: Benchmarking and Analysis,"Vision-language models (VLMs) have shown impressive zero- and few-shot
performance on real-world visual question answering (VQA) benchmarks, alluding
to their capabilities as visual reasoning engines. However, the benchmarks
being used conflate ""pure"" visual reasoning with world knowledge, and also have
questions that involve a limited number of reasoning steps. Thus, it remains
unclear whether a VLM's apparent visual reasoning performance is due to its
world knowledge, or due to actual visual reasoning capabilities.
  To clarify this ambiguity, we systematically benchmark and dissect the
zero-shot visual reasoning capabilities of VLMs through synthetic datasets that
require minimal world knowledge, and allow for analysis over a broad range of
reasoning steps. We focus on two novel aspects of zero-shot visual reasoning:
i) evaluating the impact of conveying scene information as either visual
embeddings or purely textual scene descriptions to the underlying large
language model (LLM) of the VLM, and ii) comparing the effectiveness of
chain-of-thought prompting to standard prompting for zero-shot visual
reasoning.
  We find that the underlying LLMs, when provided textual scene descriptions,
consistently perform better compared to being provided visual embeddings. In
particular, 18% higher accuracy is achieved on the PTR dataset. We also find
that CoT prompting performs marginally better than standard prompting only for
the comparatively large GPT-3.5-Turbo (175B) model, and does worse for
smaller-scale models. This suggests the emergence of CoT abilities for visual
reasoning in LLMs at larger scales even when world knowledge is limited.
Overall, we find limitations in the abilities of VLMs and LLMs for more complex
visual reasoning, and highlight the important role that LLMs can play in visual
reasoning.",2024-08-27,"Aishik Nagar, Shantanu Jaiswal, Cheston Tan",http://arxiv.org/pdf/2409.00106v1,cs.CL
Negation Blindness in Large Language Models: Unveiling the NO Syndrome in Image Generation,"Foundational Large Language Models (LLMs) have changed the way we perceive
technology. They have been shown to excel in tasks ranging from poem writing
and coding to essay generation and puzzle solving. With the incorporation of
image generation capability, they have become more comprehensive and versatile
AI tools. At the same time, researchers are striving to identify the
limitations of these tools to improve them further. Currently identified flaws
include hallucination, biases, and bypassing restricted commands to generate
harmful content. In the present work, we have identified a fundamental
limitation related to the image generation ability of LLMs, and termed it The
NO Syndrome. This negation blindness refers to LLMs inability to correctly
comprehend NO related natural language prompts to generate the desired images.
Interestingly, all tested LLMs including GPT-4, Gemini, and Copilot were found
to be suffering from this syndrome. To demonstrate the generalization of this
limitation, we carried out simulation experiments and conducted entropy-based
and benchmark statistical analysis tests on various LLMs in multiple languages,
including English, Hindi, and French. We conclude that the NO syndrome is a
significant flaw in current LLMs that needs to be addressed. A related finding
of this study showed a consistent discrepancy between image and textual
responses as a result of this NO syndrome. We posit that the introduction of a
negation context-aware reinforcement learning based feedback loop between the
LLMs textual response and generated image could help ensure the generated text
is based on both the LLMs correct contextual understanding of the negation
query and the generated visual output.",2024-08-27,"Mohammad Nadeem, Shahab Saquib Sohail, Erik Cambria, Björn W. Schuller, Amir Hussain",http://arxiv.org/pdf/2409.00105v2,cs.CL
Relation Also Knows: Rethinking the Recall and Editing of Factual Associations in Auto-Regressive Transformer Language Models,"The storage and recall of factual associations in auto-regressive transformer
language models (LMs) have drawn a great deal of attention, inspiring knowledge
editing by directly modifying the located model weights. Most editing works
achieve knowledge editing under the guidance of existing interpretations of
knowledge recall that mainly focus on subject knowledge. However, these
interpretations are seriously flawed, neglecting relation information and
leading to the over-generalizing problem for editing. In this work, we discover
a novel relation-focused perspective to interpret the knowledge recall of
transformer LMs during inference and apply it on single knowledge editing to
avoid over-generalizing. Experimental results on the dataset supplemented with
a new R-Specificity criterion demonstrate that our editing approach
significantly alleviates over-generalizing while remaining competitive on other
criteria, breaking the domination of subject-focused editing for future
research.",2024-08-27,"Xiyu Liu, Zhengxiao Liu, Naibin Gu, Zheng Lin, Wanli Ma, Ji Xiang, Weiping Wang",http://arxiv.org/pdf/2408.15091v3,cs.CL
BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline,"The general capabilities of Large Language Models (LLM) highly rely on the
composition and selection on extensive pretraining datasets, treated as
commercial secrets by several institutions. To mitigate this issue, we
open-source the details of a universally applicable data processing pipeline
and validate its effectiveness and potential by introducing a competitive LLM
baseline. Specifically, the data processing pipeline consists of broad
collection to scale up and reweighting to improve quality. We then pretrain a
7B model BaichuanSEED with 3T tokens processed by our pipeline without any
deliberate downstream task-related optimization, followed by an easy but
effective supervised fine-tuning stage. BaichuanSEED demonstrates consistency
and predictability throughout training and achieves comparable performance on
comprehensive benchmarks with several commercial advanced large language
models, such as Qwen1.5 and Llama3. We also conduct several heuristic
experiments to discuss the potential for further optimization of downstream
tasks, such as mathematics and coding.",2024-08-27,"Guosheng Dong, Da Pan, Yiding Sun, Shusen Zhang, Zheng Liang, Xin Wu, Yanjun Shen, Fan Yang, Haoze Sun, Tianpeng Li, Mingan Lin, Jianhua Xu, Yufan Zhang, Xiaonan Nie, Lei Su, Bingning Wang, Wentao Zhang, Jiaxin Mao, Zenan Zhou, Weipeng Chen",http://arxiv.org/pdf/2408.15079v1,cs.CL
Nuance Matters: Probing Epistemic Consistency in Causal Reasoning,"To address this gap, our study introduces the concept of causal epistemic
consistency, which focuses on the self-consistency of Large Language Models
(LLMs) in differentiating intermediates with nuanced differences in causal
reasoning. We propose a suite of novel metrics -- intensity ranking
concordance, cross-group position agreement, and intra-group clustering -- to
evaluate LLMs on this front. Through extensive empirical studies on 21
high-profile LLMs, including GPT-4, Claude3, and LLaMA3-70B, we have favoring
evidence that current models struggle to maintain epistemic consistency in
identifying the polarity and intensity of intermediates in causal reasoning.
Additionally, we explore the potential of using internal token probabilities as
an auxiliary tool to maintain causal epistemic consistency. In summary, our
study bridges a critical gap in AI research by investigating the
self-consistency over fine-grained intermediates involved in causal reasoning.",2024-08-27,"Shaobo Cui, Junyou Li, Luca Mouchel, Yiyang Feng, Boi Faltings",http://arxiv.org/pdf/2409.00103v1,cs.CL
Self-supervised Topic Taxonomy Discovery in the Box Embedding Space,"Topic taxonomy discovery aims at uncovering topics of different abstraction
levels and constructing hierarchical relations between them. Unfortunately,
most of prior work can hardly model semantic scopes of words and topics by
holding the Euclidean embedding space assumption. What's worse, they infer
asymmetric hierarchical relations by symmetric distances between topic
embeddings. As a result, existing methods suffer from problems of low-quality
topics at high abstraction levels and inaccurate hierarchical relations. To
alleviate these problems, this paper develops a Box embedding-based Topic Model
(BoxTM) that maps words and topics into the box embedding space, where the
asymmetric metric is defined to properly infer hierarchical relations among
topics. Additionally, our BoxTM explicitly infers upper-level topics based on
correlation between specific topics through recursive clustering on topic
boxes. Finally, extensive experiments validate high-quality of the topic
taxonomy learned by BoxTM.",2024-08-27,"Yuyin Lu, Hegang Chen, Pengbo Mao, Yanghui Rao, Haoran Xie, Fu Lee Wang, Qing Li",http://arxiv.org/pdf/2408.15050v1,cs.CL
A Survey of Large Language Models for European Languages,"Large Language Models (LLMs) have gained significant attention due to their
high performance on a wide range of natural language tasks since the release of
ChatGPT. The LLMs learn to understand and generate language by training
billions of model parameters on vast volumes of text data. Despite being a
relatively new field, LLM research is rapidly advancing in various directions.
In this paper, we present an overview of LLM families, including LLaMA, PaLM,
GPT, and MoE, and the methods developed to create and enhance LLMs for official
European Union (EU) languages. We provide a comprehensive summary of common
monolingual and multilingual datasets used for pretraining large language
models.",2024-08-27,"Wazir Ali, Sampo Pyysalo",http://arxiv.org/pdf/2408.15040v2,cs.CL
Evidence-Enhanced Triplet Generation Framework for Hallucination Alleviation in Generative Question Answering,"To address the hallucination in generative question answering (GQA) where the
answer can not be derived from the document, we propose a novel
evidence-enhanced triplet generation framework, EATQA, encouraging the model to
predict all the combinations of (Question, Evidence, Answer) triplet by
flipping the source pair and the target label to understand their logical
relationships, i.e., predict Answer(A), Question(Q), and Evidence(E) given a
QE, EA, and QA pairs, respectively. Furthermore, we bridge the distribution gap
to distill the knowledge from evidence in inference stage. Our framework
ensures the model to learn the logical relation between query, evidence and
answer, which simultaneously improves the evidence generation and query
answering. In this paper, we apply EATQA to LLama and it outperforms other
LLMs-based methods and hallucination mitigation approaches on two challenging
GQA benchmarks. Further analysis shows that our method not only keeps prior
knowledge within LLM, but also mitigates hallucination and generates faithful
answers.",2024-08-27,"Haowei Du, Huishuai Zhang, Dongyan Zhao",http://arxiv.org/pdf/2408.15037v1,cs.CL
Speech Recognition Transformers: Topological-lingualism Perspective,"Transformers have evolved with great success in various artificial
intelligence tasks. Thanks to our recent prevalence of self-attention
mechanisms, which capture long-term dependency, phenomenal outcomes in speech
processing and recognition tasks have been produced. The paper presents a
comprehensive survey of transformer techniques oriented in speech modality. The
main contents of this survey include (1) background of traditional ASR,
end-to-end transformer ecosystem, and speech transformers (2) foundational
models in a speech via lingualism paradigm, i.e., monolingual, bilingual,
multilingual, and cross-lingual (3) dataset and languages, acoustic features,
architecture, decoding, and evaluation metric from a specific topological
lingualism perspective (4) popular speech transformer toolkit for building
end-to-end ASR systems. Finally, highlight the discussion of open challenges
and potential research directions for the community to conduct further research
in this domain.",2024-08-27,"Shruti Singh, Muskaan Singh, Virender Kadyan",http://arxiv.org/pdf/2408.14991v1,cs.CL
YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection,"Dysfluent speech detection is the bottleneck for disordered speech analysis
and spoken language learning. Current state-of-the-art models are governed by
rule-based systems which lack efficiency and robustness, and are sensitive to
template design. In this paper, we propose YOLO-Stutter: a first end-to-end
method that detects dysfluencies in a time-accurate manner. YOLO-Stutter takes
imperfect speech-text alignment as input, followed by a spatial feature
aggregator, and a temporal dependency extractor to perform region-wise boundary
and class predictions. We also introduce two dysfluency corpus, VCTK-Stutter
and VCTK-TTS, that simulate natural spoken dysfluencies including repetition,
block, missing, replacement, and prolongation. Our end-to-end method achieves
state-of-the-art performance with a minimum number of trainable parameters for
on both simulated data and real aphasia speech. Code and datasets are
open-sourced at https://github.com/rorizzz/YOLO-Stutter",2024-08-27,"Xuanru Zhou, Anshul Kashyap, Steve Li, Ayati Sharma, Brittany Morin, David Baquirin, Jet Vonk, Zoe Ezzes, Zachary Miller, Maria Luisa Gorno Tempini, Jiachen Lian, Gopala Krishna Anumanchipalli",http://arxiv.org/pdf/2408.15297v3,cs.CL
AgentMonitor: A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems,"The rapid advancement of large language models (LLMs) has led to the rise of
LLM-based agents. Recent research shows that multi-agent systems (MAS), where
each agent plays a specific role, can outperform individual LLMs. However,
configuring an MAS for a task remains challenging, with performance only
observable post-execution. Inspired by scaling laws in LLM development, we
investigate whether MAS performance can be predicted beforehand. We introduce
AgentMonitor, a framework that integrates at the agent level to capture inputs
and outputs, transforming them into statistics for training a regression model
to predict task performance. Additionally, it can further apply real-time
corrections to address security risks posed by malicious agents, mitigating
negative impacts and enhancing MAS security. Experiments demonstrate that an
XGBoost model achieves a Spearman correlation of 0.89 in-domain and 0.58 in
more challenging scenarios. Furthermore, using AgentMonitor reduces harmful
content by 6.2% and increases helpful content by 1.8% on average, enhancing
safety and reliability. Code is available at
\url{https://github.com/chanchimin/AgentMonitor}.",2024-08-27,"Chi-Min Chan, Jianxuan Yu, Weize Chen, Chunyang Jiang, Xinyu Liu, Weijie Shi, Zhiyuan Liu, Wei Xue, Yike Guo",http://arxiv.org/pdf/2408.14972v1,cs.CL
MRSE: An Efficient Multi-modality Retrieval System for Large Scale E-commerce,"Providing high-quality item recall for text queries is crucial in large-scale
e-commerce search systems. Current Embedding-based Retrieval Systems (ERS)
embed queries and items into a shared low-dimensional space, but uni-modality
ERS rely too heavily on textual features, making them unreliable in complex
contexts. While multi-modality ERS incorporate various data sources, they often
overlook individual preferences for different modalities, leading to suboptimal
results. To address these issues, we propose MRSE, a Multi-modality Retrieval
System that integrates text, item images, and user preferences through
lightweight mixture-of-expert (LMoE) modules to better align features across
and within modalities. MRSE also builds user profiles at a multi-modality level
and introduces a novel hybrid loss function that enhances consistency and
robustness using hard negative sampling. Experiments on a large-scale dataset
from Shopee and online A/B testing show that MRSE achieves an 18.9% improvement
in offline relevance and a 3.7% gain in online core metrics compared to
Shopee's state-of-the-art uni-modality system.",2024-08-27,"Hao Jiang, Haoxiang Zhang, Qingshan Hou, Chaofeng Chen, Weisi Lin, Jingchang Zhang, Annan Wang",http://arxiv.org/pdf/2408.14968v1,cs.CL
Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual Progress,"The use of synthetic data has played a critical role in recent state-of-art
breakthroughs. However, overly relying on a single oracle teacher model to
generate data has been shown to lead to model collapse and invite propagation
of biases. These limitations are particularly evident in multilingual settings,
where the absence of a universally effective teacher model that excels across
all languages presents significant challenges. In this work, we address these
extreme difference by introducing ""multilingual arbitrage"", which capitalizes
on performance variations between multiple models for a given language. To do
so, we strategically route samples through a diverse pool of models, each with
unique strengths in different languages. Across exhaustive experiments on
state-of-art models, our work suggests that arbitrage techniques allow for
spectacular gains in performance that far outperform relying on a single
teacher. In particular, compared to the best single teacher, we observe gains
of up to 56.5% improvement in win rates averaged across all languages when
switching to multilingual arbitrage. We observe the most significant gains for
the least resourced languages in our pool.",2024-08-27,"Ayomide Odumakinde, Daniel D'souza, Pat Verga, Beyza Ermis, Sara Hooker",http://arxiv.org/pdf/2408.14960v1,cs.CL
SpikingSSMs: Learning Long Sequences with Sparse and Parallel Spiking State Space Models,"Known as low energy consumption networks, spiking neural networks (SNNs) have
gained a lot of attention within the past decades. While SNNs are increasing
competitive with artificial neural networks (ANNs) for vision tasks, they are
rarely used for long sequence tasks, despite their intrinsic temporal dynamics.
In this work, we develop spiking state space models (SpikingSSMs) for long
sequence learning by leveraging on the sequence learning abilities of state
space models (SSMs). Inspired by dendritic neuron structure, we hierarchically
integrate neuronal dynamics with the original SSM block, meanwhile realizing
sparse synaptic computation. Furthermore, to solve the conflict of event-driven
neuronal dynamics with parallel computing, we propose a light-weight surrogate
dynamic network which accurately predicts the after-reset membrane potential
and compatible to learnable thresholds, enabling orders of acceleration in
training speed compared with conventional iterative methods. On the long range
arena benchmark task, SpikingSSM achieves competitive performance to
state-of-the-art SSMs meanwhile realizing on average 90\% of network sparsity.
On language modeling, our network significantly surpasses existing spiking
large language models (spikingLLMs) on the WikiText-103 dataset with only a
third of the model size, demonstrating its potential as backbone architecture
for low computation cost LLMs.",2024-08-27,"Shuaijie Shen, Chao Wang, Renzhuo Huang, Yan Zhong, Qinghai Guo, Zhichao Lu, Jianguo Zhang, Luziwei Leng",http://arxiv.org/pdf/2408.14909v2,cs.CL
Triplètoile: Extraction of Knowledge from Microblogging Text,"Numerous methods and pipelines have recently emerged for the automatic
extraction of knowledge graphs from documents such as scientific publications
and patents. However, adapting these methods to incorporate alternative text
sources like micro-blogging posts and news has proven challenging as they
struggle to model open-domain entities and relations, typically found in these
sources. In this paper, we propose an enhanced information extraction pipeline
tailored to the extraction of a knowledge graph comprising open-domain entities
from micro-blogging posts on social media platforms. Our pipeline leverages
dependency parsing and classifies entity relations in an unsupervised manner
through hierarchical clustering over word embeddings. We provide a use case on
extracting semantic triples from a corpus of 100 thousand tweets about digital
transformation and publicly release the generated knowledge graph. On the same
dataset, we conduct two experimental evaluations, showing that the system
produces triples with precision over 95% and outperforms similar pipelines of
around 5% in terms of precision, while generating a comparatively higher number
of triples.",2024-08-27,"Vanni Zavarella, Sergio Consoli, Diego Reforgiato Recupero, Gianni Fenu, Simone Angioni, Davide Buscaldi, Danilo Dessì, Francesco Osborne",http://arxiv.org/pdf/2408.14908v1,cs.CL
Writing in the Margins: Better Inference Pattern for Long Context Retrieval,"In this paper, we introduce Writing in the Margins (WiM), a new inference
pattern for Large Language Models designed to optimize the handling of long
input sequences in retrieval-oriented tasks. This approach leverages the
chunked prefill of the key-value cache to perform segment-wise inference, which
enables efficient processing of extensive contexts along with the generation
and classification of intermediate information (""margins"") that guide the model
towards specific tasks. This method increases computational overhead marginally
while significantly enhancing the performance of off-the-shelf models without
the need for fine-tuning. Specifically, we observe that WiM provides an average
enhancement of 7.5% in accuracy for reasoning skills (HotpotQA, MultiHop-RAG)
and more than a 30.0% increase in the F1-score for aggregation tasks (CWE).
Additionally, we show how the proposed pattern fits into an interactive
retrieval design that provides end-users with ongoing updates about the
progress of context processing, and pinpoints the integration of relevant
information into the final response. We release our implementation of WiM using
Hugging Face Transformers library at
https://github.com/writer/writing-in-the-margins.",2024-08-27,"Melisa Russak, Umar Jamil, Christopher Bryant, Kiran Kamble, Axel Magnuson, Mateusz Russak, Waseem AlShikh",http://arxiv.org/pdf/2408.14906v1,cs.CL
VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities,"Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data
(e.g., images and videos) into symbols, have attracted attention as resources
enabling knowledge processing and machine learning across modalities. However,
the construction of MMKGs for videos consisting of multiple events, such as
daily activities, is still in the early stages. In this paper, we construct an
MMKG based on synchronized multi-view simulated videos of daily activities.
Besides representing the content of daily life videos as event-centric
knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as
bounding boxes within video frames. In addition, we provide support tools for
querying our MMKG. As an application example, we demonstrate that our MMKG
facilitates benchmarking vision-language models by providing the necessary
vision-language datasets for a tailored task.",2024-08-27,"Shusaku Egami, Takahiro Ugai, Swe Nwe Nwe Htun, Ken Fukuda",http://arxiv.org/pdf/2408.14895v2,cs.CL
A Functional Trade-off between Prosodic and Semantic Cues in Conveying Sarcasm,"This study investigates the acoustic features of sarcasm and disentangles the
interplay between the propensity of an utterance being used sarcastically and
the presence of prosodic cues signaling sarcasm. Using a dataset of sarcastic
utterances compiled from television shows, we analyze the prosodic features
within utterances and key phrases belonging to three distinct sarcasm
categories (embedded, propositional, and illocutionary), which vary in the
degree of semantic cues present, and compare them to neutral expressions.
Results show that in phrases where the sarcastic meaning is salient from the
semantics, the prosodic cues are less relevant than when the sarcastic meaning
is not evident from the semantics, suggesting a trade-off between prosodic and
semantic cues of sarcasm at the phrase level. These findings highlight a
lessened reliance on prosodic modulation in semantically dense sarcastic
expressions and a nuanced interaction that shapes the communication of
sarcastic intent.",2024-08-27,"Zhu Li, Xiyuan Gao, Yuqing Zhang, Shekhar Nayak, Matt Coler",http://arxiv.org/pdf/2408.14892v1,cs.CL
Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data,"Reinforcement Learning from Human Feedback (RLHF) has proven effective in
aligning large language models with human intentions, yet it often relies on
complex methodologies like Proximal Policy Optimization (PPO) that require
extensive hyper-parameter tuning and present challenges in sample efficiency
and stability. In this paper, we introduce Inverse-Q*, an innovative framework
that transcends traditional RL methods by optimizing token-level reinforcement
learning without the need for additional reward or value models. Inverse-Q*
leverages direct preference optimization techniques but extends them by
estimating the conditionally optimal policy directly from the model's
responses, facilitating more granular and flexible policy shaping. Our approach
reduces reliance on human annotation and external supervision, making it
especially suitable for low-resource settings. We present extensive
experimental results demonstrating that Inverse-Q* not only matches but
potentially exceeds the effectiveness of PPO in terms of convergence speed and
the alignment of model responses with human preferences. Our findings suggest
that Inverse-Q* offers a practical and robust alternative to conventional RLHF
approaches, paving the way for more efficient and adaptable model training
approaches.",2024-08-27,"Han Xia, Songyang Gao, Qiming Ge, Zhiheng Xi, Qi Zhang, Xuanjing Huang",http://arxiv.org/pdf/2408.14874v2,cs.CL
Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models,"Language Language Models (LLMs) face safety concerns due to potential misuse
by malicious users. Recent red-teaming efforts have identified adversarial
suffixes capable of jailbreaking LLMs using the gradient-based search algorithm
Greedy Coordinate Gradient (GCG). However, GCG struggles with computational
inefficiency, limiting further investigations regarding suffix transferability
and scalability across models and data. In this work, we bridge the connection
between search efficiency and suffix transferability. We propose a two-stage
transfer learning framework, DeGCG, which decouples the search process into
behavior-agnostic pre-searching and behavior-relevant post-searching.
Specifically, we employ direct first target token optimization in pre-searching
to facilitate the search process. We apply our approach to cross-model,
cross-data, and self-transfer scenarios. Furthermore, we introduce an
interleaved variant of our approach, i-DeGCG, which iteratively leverages
self-transferability to accelerate the search process. Experiments on HarmBench
demonstrate the efficiency of our approach across various models and domains.
Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of
$43.9$ ($+22.2$) and $39.0$ ($+19.5$) on valid and test sets, respectively.
Further analysis on cross-model transfer indicates the pivotal role of first
target token optimization in leveraging suffix transferability for efficient
searching.",2024-08-27,"Hongfu Liu, Yuxi Xie, Ye Wang, Michael Shieh",http://arxiv.org/pdf/2408.14866v2,cs.CL
Learning Granularity Representation for Temporal Knowledge Graph Completion,"Temporal Knowledge Graphs (TKGs) incorporate temporal information to reflect
the dynamic structural knowledge and evolutionary patterns of real-world facts.
Nevertheless, TKGs are still limited in downstream applications due to the
problem of incompleteness. Consequently, TKG completion (also known as link
prediction) has been widely studied, with recent research focusing on
incorporating independent embeddings of time or combining them with entities
and relations to form temporal representations. However, most existing methods
overlook the impact of history from a multi-granularity aspect. The inherent
semantics of human-defined temporal granularities, such as ordinal dates,
reveal general patterns to which facts typically adhere. To counter this
limitation, this paper proposes \textbf{L}earning \textbf{G}ranularity
\textbf{Re}presentation (termed $\mathsf{LGRe}$) for TKG completion. It
comprises two main components: Granularity Representation Learning (GRL) and
Adaptive Granularity Balancing (AGB). Specifically, GRL employs time-specific
multi-layer convolutional neural networks to capture interactions between
entities and relations at different granularities. After that, AGB generates
adaptive weights for these embeddings according to temporal semantics,
resulting in expressive representations of predictions. Moreover, to reflect
similar semantics of adjacent timestamps, a temporal loss function is
introduced. Extensive experimental results on four event benchmarks demonstrate
the effectiveness of $\mathsf{LGRe}$ in learning time-related representations.
To ensure reproducibility, our code is available at
https://github.com/KcAcoZhang/LGRe.",2024-08-27,"Jinchuan Zhang, Tianqi Wan, Chong Mu, Guangxi Lu, Ling Tian",http://arxiv.org/pdf/2408.15293v1,cs.CL
Atoxia: Red-teaming Large Language Models with Target Toxic Answers,"Despite the substantial advancements in artificial intelligence, large
language models (LLMs) remain being challenged by generation safety. With
adversarial jailbreaking prompts, one can effortlessly induce LLMs to output
harmful content, causing unexpected negative social impacts. This vulnerability
highlights the necessity for robust LLM red-teaming strategies to identify and
mitigate such risks before large-scale application. To detect specific types of
risks, we propose a novel red-teaming method that $\textbf{A}$ttacks LLMs with
$\textbf{T}$arget $\textbf{Toxi}$c $\textbf{A}$nswers ($\textbf{Atoxia}$).
Given a particular harmful answer, Atoxia generates a corresponding user query
and a misleading answer opening to examine the internal defects of a given LLM.
The proposed attacker is trained within a reinforcement learning scheme with
the LLM outputting probability of the target answer as the reward. We verify
the effectiveness of our method on various red-teaming benchmarks, such as
AdvBench and HH-Harmless. The empirical results demonstrate that Atoxia can
successfully detect safety risks in not only open-source models but also
state-of-the-art black-box models such as GPT-4o.",2024-08-27,"Yuhao Du, Zhuo Li, Pengyu Cheng, Xiang Wan, Anningzhe Gao",http://arxiv.org/pdf/2408.14853v2,cs.CL
Project SHADOW: Symbolic Higher-order Associative Deductive reasoning On Wikidata using LM probing,"We introduce SHADOW, a fine-tuned language model trained on an intermediate
task using associative deductive reasoning, and measure its performance on a
knowledge base construction task using Wikidata triple completion. We evaluate
SHADOW on the LM-KBC 2024 challenge and show that it outperforms the baseline
solution by 20% with a F1 score of 68.72%.",2024-08-27,Hanna Abi Akl,http://arxiv.org/pdf/2408.14849v2,cs.CL
AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark,"Detecting biases in natural language understanding (NLU) for African American
Vernacular English (AAVE) is crucial to developing inclusive natural language
processing (NLP) systems. To address dialect-induced performance discrepancies,
we introduce AAVENUE ({AAVE} {N}atural Language {U}nderstanding {E}valuation),
a benchmark for evaluating large language model (LLM) performance on NLU tasks
in AAVE and Standard American English (SAE). AAVENUE builds upon and extends
existing benchmarks like VALUE, replacing deterministic syntactic and
morphological transformations with a more flexible methodology leveraging
LLM-based translation with few-shot prompting, improving performance across our
evaluation metrics when translating key tasks from the GLUE and SuperGLUE
benchmarks. We compare AAVENUE and VALUE translations using five popular LLMs
and a comprehensive set of metrics including fluency, BARTScore, quality,
coherence, and understandability. Additionally, we recruit fluent AAVE speakers
to validate our translations for authenticity. Our evaluations reveal that LLMs
consistently perform better on SAE tasks than AAVE-translated versions,
underscoring inherent biases and highlighting the need for more inclusive NLP
models. We have open-sourced our source code on GitHub and created a website to
showcase our work at https://aavenue.live.",2024-08-27,"Abhay Gupta, Philip Meng, Ece Yurtseven, Sean O'Brien, Kevin Zhu",http://arxiv.org/pdf/2408.14845v2,cs.CL
CL4KGE: A Curriculum Learning Method for Knowledge Graph Embedding,"Knowledge graph embedding (KGE) constitutes a foundational task, directed
towards learning representations for entities and relations within knowledge
graphs (KGs), with the objective of crafting representations comprehensive
enough to approximate the logical and symbolic interconnections among entities.
In this paper, we define a metric Z-counts to measure the difficulty of
training each triple ($<$head entity, relation, tail entity$>$) in KGs with
theoretical analysis. Based on this metric, we propose \textbf{CL4KGE}, an
efficient \textbf{C}urriculum \textbf{L}earning based training strategy for
\textbf{KGE}. This method includes a difficulty measurer and a training
scheduler that aids in the training of KGE models. Our approach possesses the
flexibility to act as a plugin within a wide range of KGE models, with the
added advantage of adaptability to the majority of KGs in existence. The
proposed method has been evaluated on popular KGE models, and the results
demonstrate that it enhances the state-of-the-art methods. The use of Z-counts
as a metric has enabled the identification of challenging triples in KGs, which
helps in devising effective training strategies.",2024-08-27,"Yang Liu, Chuan Zhou, Peng Zhang, Yanan Cao, Yongchao Liu, Zhao Li, Hongyang Chen",http://arxiv.org/pdf/2408.14840v2,cs.CL
PolicyLR: A Logic Representation For Privacy Policies,"Privacy policies are crucial in the online ecosystem, defining how services
handle user data and adhere to regulations such as GDPR and CCPA. However,
their complexity and frequent updates often make them difficult for
stakeholders to understand and analyze. Current automated analysis methods,
which utilize natural language processing, have limitations. They typically
focus on individual tasks and fail to capture the full context of the policies.
We propose PolicyLR, a new paradigm that offers a comprehensive
machine-readable representation of privacy policies, serving as an all-in-one
solution for multiple downstream tasks. PolicyLR converts privacy policies into
a machine-readable format using valuations of atomic formulae, allowing for
formal definitions of tasks like compliance and consistency. We have developed
a compiler that transforms unstructured policy text into this format using
off-the-shelf Large Language Models (LLMs). This compiler breaks down the
transformation task into a two-stage translation and entailment procedure. This
procedure considers the full context of the privacy policy to infer a complex
formula, where each formula consists of simpler atomic formulae. The advantage
of this model is that PolicyLR is interpretable by design and grounded in
segments of the privacy policy. We evaluated the compiler using ToS;DR, a
community-annotated privacy policy entailment dataset. Utilizing open-source
LLMs, our compiler achieves precision and recall values of 0.91 and 0.88,
respectively. Finally, we demonstrate the utility of PolicyLR in three privacy
tasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison
Shopping.",2024-08-27,"Ashish Hooda, Rishabh Khandelwal, Prasad Chalasani, Kassem Fawaz, Somesh Jha",http://arxiv.org/pdf/2408.14830v1,cs.CL
"From Rule-Based Models to Deep Learning Transformers Architectures for Natural Language Processing and Sign Language Translation Systems: Survey, Taxonomy and Performance Evaluation","With the growing Deaf and Hard of Hearing population worldwide and the
persistent shortage of certified sign language interpreters, there is a
pressing need for an efficient, signs-driven, integrated end-to-end translation
system, from sign to gloss to text and vice-versa. There has been a wealth of
research on machine translations and related reviews. However, there are few
works on sign language machine translation considering the particularity of the
language being continuous and dynamic. This paper aims to address this void,
providing a retrospective analysis of the temporal evolution of sign language
machine translation algorithms and a taxonomy of the Transformers
architectures, the most used approach in language translation. We also present
the requirements of a real-time Quality-of-Service sign language ma-chine
translation system underpinned by accurate deep learning algorithms. We propose
future research directions for sign language translation systems.",2024-08-27,"Nada Shahin, Leila Ismail",http://arxiv.org/pdf/2408.14825v1,cs.CL
GSIFN: A Graph-Structured and Interlaced-Masked Multimodal Transformer-based Fusion Network for Multimodal Sentiment Analysis,"Multimodal Sentiment Analysis (MSA) leverages multiple data modals to analyze
human sentiment. Existing MSA models generally employ cutting-edge multimodal
fusion and representation learning-based methods to promote MSA capability.
However, there are two key challenges: (i) in existing multimodal fusion
methods, the decoupling of modal combinations and tremendous parameter
redundancy, lead to insufficient fusion performance and efficiency; (ii) a
challenging trade-off exists between representation capability and
computational overhead in unimodal feature extractors and encoders. Our
proposed GSIFN incorporates two main components to solve these problems: (i) a
graph-structured and interlaced-masked multimodal Transformer. It adopts the
Interlaced Mask mechanism to construct robust multimodal graph embedding,
achieve all-modal-in-one Transformer-based fusion, and greatly reduce the
computational overhead; (ii) a self-supervised learning framework with low
computational overhead and high performance, which utilizes a parallelized LSTM
with matrix memory to enhance non-verbal modal features for unimodal label
generation. Evaluated on the MSA datasets CMU-MOSI, CMU-MOSEI, and CH-SIMS,
GSIFN demonstrates superior performance with significantly lower computational
overhead compared with previous state-of-the-art models.",2024-08-27,Yijie Jin,http://arxiv.org/pdf/2408.14809v4,cs.CL
Measuring Human Contribution in AI-Assisted Content Generation,"With the growing prevalence of generative artificial intelligence (AI), an
increasing amount of content is no longer exclusively generated by humans but
by generative AI models with human guidance. This shift presents notable
challenges for the delineation of originality due to the varying degrees of
human contribution in AI-assisted works. This study raises the research
question of measuring human contribution in AI-assisted content generation and
introduces a framework to address this question that is grounded in information
theory. By calculating mutual information between human input and AI-assisted
output relative to self-information of AI-assisted output, we quantify the
proportional information contribution of humans in content generation. Our
experimental results demonstrate that the proposed measure effectively
discriminates between varying degrees of human contribution across multiple
creative domains. We hope that this work lays a foundation for measuring human
contributions in AI-assisted content generation in the era of generative AI.",2024-08-27,"Yueqi Xie, Tao Qi, Jingwei Yi, Xiyuan Yang, Ryan Whalen, Junming Huang, Qian Ding, Yu Xie, Xing Xie, Fangzhao Wu",http://arxiv.org/pdf/2408.14792v2,cs.CL
Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning,"We introduce Instruct-SkillMix, an automated approach for creating diverse,
high quality SFT data. The Instruct-SkillMix pipeline involves two stages, each
leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to
extract core ""skills"" for instruction-following, either from existing datasets,
or by directly prompting the model; (2) Data generation: uses the powerful LLM
to generate (instruction, response) data that exhibit a randomly chosen pair of
these skills. Here, the use of random skill combinations promotes diversity and
difficulty.
  Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from
Instruct-SkillMix leads to strong gains on instruction following benchmarks
such as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples,
LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.
To our knowledge, this achieves state-of-the-art performance among all models
that have only undergone SFT (no RL methods) and competes with proprietary
models such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.
  Ablation studies also suggest plausible reasons for why creating open
instruction-tuning datasets via naive crowd-sourcing has proved difficult.
Introducing low quality answers (""shirkers"") in $20\%$ of Instruct-SkillMix
examples causes performance to plummet, sometimes catastrophically.
  The Instruct-SkillMix pipeline is flexible and is adaptable to other
settings.",2024-08-27,"Simran Kaur, Simon Park, Anirudh Goyal, Sanjeev Arora",http://arxiv.org/pdf/2408.14774v3,cs.CL
A global AI community requires language-diverse publishing,"In this provocation, we discuss the English dominance of the AI research
community, arguing that the requirement for English language publishing upholds
and reinforces broader regimes of extraction in AI. While large language models
and machine translation have been celebrated as a way to break down barriers,
we regard their use as a symptom of linguistic exclusion of scientists and
potential readers. We propose alternative futures for a healthier publishing
culture, organized around three themes: administering conferences in the
languages of the country in which they are held, instructing peer reviewers not
to adjudicate the language appropriateness of papers, and offering
opportunities to publish and present in multiple languages. We welcome new
translations of this piece. Please contact the authors if you would like to
contribute one.",2024-08-27,"Haley Lepp, Parth Sarin",http://arxiv.org/pdf/2408.14772v2,cs.CL
Query-by-Example Keyword Spotting Using Spectral-Temporal Graph Attentive Pooling and Multi-Task Learning,"Existing keyword spotting (KWS) systems primarily rely on predefined keyword
phrases. However, the ability to recognize customized keywords is crucial for
tailoring interactions with intelligent devices. In this paper, we present a
novel Query-by-Example (QbyE) KWS system that employs spectral-temporal graph
attentive pooling and multi-task learning. This framework aims to effectively
learn speaker-invariant and linguistic-informative embeddings for QbyE KWS
tasks. Within this framework, we investigate three distinct network
architectures for encoder modeling: LiCoNet, Conformer and ECAPA_TDNN. The
experimental results on a substantial internal dataset of $629$ speakers have
demonstrated the effectiveness of the proposed QbyE framework in maximizing the
potential of simpler models such as LiCoNet. Particularly, LiCoNet, which is
13x more efficient, achieves comparable performance to the computationally
intensive Conformer model (1.98% vs. 1.63\% FRR at 0.3 FAs/Hr).",2024-08-27,"Zhenyu Wang, Shuyu Kong, Li Wan, Biqiao Zhang, Yiteng Huang, Mumin Jin, Ming Sun, Xin Lei, Zhaojun Yang",http://arxiv.org/pdf/2409.00099v2,cs.CL
LyCon: Lyrics Reconstruction from the Bag-of-Words Using Large Language Models,"This paper addresses the unique challenge of conducting research in lyric
studies, where direct use of lyrics is often restricted due to copyright
concerns. Unlike typical data, internet-sourced lyrics are frequently protected
under copyright law, necessitating alternative approaches. Our study introduces
a novel method for generating copyright-free lyrics from publicly available
Bag-of-Words (BoW) datasets, which contain the vocabulary of lyrics but not the
lyrics themselves. Utilizing metadata associated with BoW datasets and large
language models, we successfully reconstructed lyrics. We have compiled and
made available a dataset of reconstructed lyrics, LyCon, aligned with metadata
from renowned sources including the Million Song Dataset, Deezer Mood Detection
Dataset, and AllMusic Genre Dataset, available for public access. We believe
that the integration of metadata such as mood annotations or genres enables a
variety of academic experiments on lyrics, such as conditional lyric
generation.",2024-08-27,"Haven Kim, Kahyun Choi",http://arxiv.org/pdf/2408.14750v1,cs.CL
How to Train Text Summarization Model with Weak Supervisions,"Currently, machine learning techniques have seen significant success across
various applications. Most of these techniques rely on supervision from
human-generated labels or a mixture of noisy and imprecise labels from multiple
sources. However, for certain complex tasks, even noisy or inexact labels are
unavailable due to the intricacy of the objectives. To tackle this issue, we
propose a method that breaks down the complex objective into simpler tasks and
generates supervision signals for each one. We then integrate these supervision
signals into a manageable form, resulting in a straightforward learning
procedure. As a case study, we demonstrate a system used for topic-based
summarization. This system leverages rich supervision signals to promote both
summarization and topic relevance. Remarkably, we can train the model
end-to-end without any labels. Experimental results indicate that our approach
performs exceptionally well on the CNN and DailyMail datasets.",2024-08-27,"Yanbo Wang, Wenyu Chen, Shimin Shan",http://arxiv.org/pdf/2409.00098v1,cs.CL
Large Language Models for Disease Diagnosis: A Scoping Review,"Automatic disease diagnosis has become increasingly valuable in clinical
practice. The advent of large language models (LLMs) has catalyzed a paradigm
shift in artificial intelligence, with growing evidence supporting the efficacy
of LLMs in diagnostic tasks. Despite the increasing attention in this field, a
holistic view is still lacking. Many critical aspects remain unclear, such as
the diseases and clinical data to which LLMs have been applied, the LLM
techniques employed, and the evaluation methods used. In this article, we
perform a comprehensive review of LLM-based methods for disease diagnosis. Our
review examines the existing literature across various dimensions, including
disease types and associated clinical specialties, clinical data, LLM
techniques, and evaluation methods. Additionally, we offer recommendations for
applying and evaluating LLMs for diagnostic tasks. Furthermore, we assess the
limitations of current research and discuss future directions. To our
knowledge, this is the first comprehensive review for LLM-based disease
diagnosis.",2024-08-27,"Shuang Zhou, Zidu Xu, Mian Zhang, Chunpu Xu, Yawen Guo, Zaifu Zhan, Sirui Ding, Jiashuo Wang, Kaishuai Xu, Yi Fang, Liqiao Xia, Jeremy Yeung, Daochen Zha, Genevieve B. Melton, Mingquan Lin, Rui Zhang",http://arxiv.org/pdf/2409.00097v2,cs.CL
Non-instructional Fine-tuning: Enabling Instruction-Following Capabilities in Pre-trained Language Models without Instruction-Following Data,"Instruction fine-tuning is crucial for today's large language models (LLMs)
to learn to follow instructions and align with human preferences.
Conventionally, supervised data, including the instruction and the correct
response, is required for instruction fine-tuning. To obtain such data, some
researchers prompted well-trained models like GPT-4 to generate instructions
and correct responses. In this paper, we propose a novel approach that uses the
first half of a random text from OpenWebText as the instruction and
GPT-3.5-turbo or GPT-4-turbo to complete the text as the response. Despite the
data being ""non-instructional"", we found that pre-trained LLMs fine-tuned on
this data can gain instruction-following capabilities. This observation is
verified by fine-tuning several well-known pre-trained LLMs (e.g., LLaMA-2-7B,
LLaMA-3-8B, LLaMA-3-70B, Mistral-7B-v0.1). The ""non-instructional data"" also
improved some models that underwent supervised fine-tuning and human preference
alignment. Our LLaMA-3-70B-Instruct fine-tuned through ""non-instructional data""
is comparable with LLaMA-3.1-70B-Instruct on the Arena Hard leaderboard. We
analyzed the ""non-instructional data"" and ensured it is devoid of content
related to instruction fine-tuning. Our findings will inspire further
investigation into how to develop instruction-following capabilities without
explicit instruction-related data.",2024-08-27,"Juncheng Xie, Shensian Syu, Hung-yi Lee",http://arxiv.org/pdf/2409.00096v1,cs.CL
PAT: Pruning-Aware Tuning for Large Language Models,"Large language models (LLMs) excel in language tasks, especially with
supervised fine-tuning after pre-training. However, their substantial memory
and computational requirements hinder practical applications. Structural
pruning, which reduces less significant weight dimensions, is one solution.
Yet, traditional post-hoc pruning often leads to significant performance loss,
with limited recovery from further fine-tuning due to reduced capacity. Since
the model fine-tuning refines the general and chaotic knowledge in pre-trained
models, we aim to incorporate structural pruning with the fine-tuning, and
propose the Pruning-Aware Tuning (PAT) paradigm to eliminate model redundancy
while preserving the model performance to the maximum extend. Specifically, we
insert the innovative Hybrid Sparsification Modules (HSMs) between the
Attention and FFN components to accordingly sparsify the upstream and
downstream linear modules. The HSM comprises a lightweight operator and a
globally shared trainable mask. The lightweight operator maintains a training
overhead comparable to that of LoRA, while the trainable mask unifies the
channels to be sparsified, ensuring structural pruning. Additionally, we
propose the Identity Loss which decouples the transformation and scaling
properties of the HSMs to enhance training robustness. Extensive experiments
demonstrate that PAT excels in both performance and efficiency. For example,
our Llama2-7b model with a 25\% pruning ratio achieves 1.33$\times$ speedup
while outperforming the LoRA-finetuned model by up to 1.26\% in accuracy with a
similar training cost. Code:
https://github.com/kriskrisliu/PAT_Pruning-Aware-Tuning",2024-08-27,"Yijiang Liu, Huanrui Yang, Youxin Chen, Rongyu Zhang, Miao Wang, Yuan Du, Li Du",http://arxiv.org/pdf/2408.14721v2,cs.CL
Smart Multi-Modal Search: Contextual Sparse and Dense Embedding Integration in Adobe Express,"As user content and queries become increasingly multi-modal, the need for
effective multi-modal search systems has grown. Traditional search systems
often rely on textual and metadata annotations for indexed images, while
multi-modal embeddings like CLIP enable direct search using text and image
embeddings. However, embedding-based approaches face challenges in integrating
contextual features such as user locale and recency. Building a scalable
multi-modal search system requires fine-tuning several components. This paper
presents a multi-modal search architecture and a series of AB tests that
optimize embeddings and multi-modal technologies in Adobe Express template
search. We address considerations such as embedding model selection, the roles
of embeddings in matching and ranking, and the balance between dense and sparse
embeddings. Our iterative approach demonstrates how utilizing sparse, dense,
and contextual features enhances short and long query search, significantly
reduces null rates (over 70\%), and increases click-through rates (CTR). Our
findings provide insights into developing robust multi-modal search systems,
thereby enhancing relevance for complex queries.",2024-08-26,"Cherag Aroraa, Tracy Holloway King, Jayant Kumar, Yi Lu, Sanat Sharma, Arvind Srikantan, David Uvalle, Josep Valls-Vargas, Harsha Vardhan",http://arxiv.org/pdf/2408.14698v2,cs.CL
Training-Free Activation Sparsity in Large Language Models,"Activation sparsity can enable practical inference speedups in large language
models (LLMs) by reducing the compute and memory-movement required for matrix
multiplications during the forward pass. However, existing methods face
limitations that inhibit widespread adoption. Some approaches are tailored
towards older models with ReLU-based sparsity, while others require extensive
continued pre-training on up to hundreds of billions of tokens. This paper
describes TEAL, a simple training-free method that applies magnitude-based
activation sparsity to hidden states throughout the entire model. TEAL achieves
40-50% model-wide sparsity with minimal performance degradation across Llama-2,
Llama-3, and Mistral families, with sizes varying from 7B to 70B. We improve
existing sparse kernels and demonstrate wall-clock decoding speed-ups of up to
1.53$\times$ and 1.8$\times$ at 40% and 50% model-wide sparsity. TEAL is
compatible with weight quantization, enabling further efficiency gains.",2024-08-26,"James Liu, Pragaash Ponnusamy, Tianle Cai, Han Guo, Yoon Kim, Ben Athiwaratkun",http://arxiv.org/pdf/2408.14690v3,cs.CL
Relationships are Complicated! An Analysis of Relationships Between Datasets on the Web,"The Web today has millions of datasets, and the number of datasets continues
to grow at a rapid pace. These datasets are not standalone entities; rather,
they are intricately connected through complex relationships. Semantic
relationships between datasets provide critical insights for research and
decision-making processes. In this paper, we study dataset relationships from
the perspective of users who discover, use, and share datasets on the Web: what
relationships are important for different tasks? What contextual information
might users want to know? We first present a comprehensive taxonomy of
relationships between datasets on the Web and map these relationships to user
tasks performed during dataset discovery. We develop a series of methods to
identify these relationships and compare their performance on a large corpus of
datasets generated from Web pages with schema.org markup. We demonstrate that
machine-learning based methods that use dataset metadata achieve multi-class
classification accuracy of 90%. Finally, we highlight gaps in available
semantic markup for datasets and discuss how incorporating comprehensive
semantics can facilitate the identification of dataset relationships. By
providing a comprehensive overview of dataset relationships at scale, this
paper sets a benchmark for future research.",2024-08-26,"Kate Lin, Tarfah Alrashed, Natasha Noy",http://arxiv.org/pdf/2408.14636v1,cs.CL
MODOC: A Modular Interface for Flexible Interlinking of Text Retrieval and Text Generation Functions,"Large Language Models (LLMs) produce eloquent texts but often the content
they generate needs to be verified. Traditional information retrieval systems
can assist with this task, but most systems have not been designed with
LLM-generated queries in mind. As such, there is a compelling need for
integrated systems that provide both retrieval and generation functionality
within a single user interface.
  We present MODOC, a modular user interface that leverages the capabilities of
LLMs and provides assistance with detecting their confabulations, promoting
integrity in scientific writing. MODOC represents a significant step forward in
scientific writing assistance. Its modular architecture supports flexible
functions for retrieving information and for writing and generating text in a
single, user-friendly interface.",2024-08-26,"Yingqiang Gao, Jhony Prada, Nianlong Gu, Jessica Lam, Richard H. R. Hahnloser",http://arxiv.org/pdf/2408.14623v1,cs.CL
What Makes a Good Story and How Can We Measure It? A Comprehensive Survey of Story Evaluation,"With the development of artificial intelligence, particularly the success of
Large Language Models (LLMs), the quantity and quality of automatically
generated stories have significantly increased. This has led to the need for
automatic story evaluation to assess the generative capabilities of computing
systems and analyze the quality of both automatic-generated and human-written
stories. Evaluating a story can be more challenging than other generation
evaluation tasks. While tasks like machine translation primarily focus on
assessing the aspects of fluency and accuracy, story evaluation demands complex
additional measures such as overall coherence, character development,
interestingness, etc. This requires a thorough review of relevant research. In
this survey, we first summarize existing storytelling tasks, including
text-to-text, visual-to-text, and text-to-visual. We highlight their evaluation
challenges, identify various human criteria to measure stories, and present
existing benchmark datasets. Then, we propose a taxonomy to organize evaluation
metrics that have been developed or can be adopted for story evaluation. We
also provide descriptions of these metrics, along with the discussion of their
merits and limitations. Later, we discuss the human-AI collaboration for story
evaluation and generation. Finally, we suggest potential future research
directions, extending from story evaluation to general evaluations.",2024-08-26,"Dingyi Yang, Qin Jin",http://arxiv.org/pdf/2408.14622v1,cs.CL
Surprisingly Fragile: Assessing and Addressing Prompt Instability in Multimodal Foundation Models,"Multimodal foundation models (MFMs) such as OFASys show the potential to
unlock analysis of complex data such as images, videos, and audio data via text
prompts alone. However, their performance may suffer in the face of text input
that differs even slightly from their training distribution, which is
surprising considering the use of modality-specific data to ""ground"" the text
input. This study demonstrates that prompt instability is a major concern for
MFMs, leading to a consistent drop in performance across all modalities, but
that instability can be mitigated with additional training with augmented data.
We evaluate several methods for grounded prompt perturbation, where we generate
perturbations and filter based on similarity to text and/or modality data.
After re-training the models on the augmented data, we find improved accuracy
and more stable performance on the perturbed test data regardless of
perturbation condition, suggesting that the data augmentation strategy helps
the models handle domain shifts more effectively. In error analysis, we find
consistent patterns of performance improvement across domains, suggesting that
retraining on prompt perturbations tends to help general reasoning capabilities
in MFMs.",2024-08-26,"Ian Stewart, Sameera Horawalavithana, Brendan Kennedy, Sai Munikoti, Karl Pazdernik",http://arxiv.org/pdf/2408.14595v1,cs.CL
CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation,"This paper introduces CURLoRA, a novel approach to fine-tuning large language
models (LLMs) that leverages CUR matrix decomposition in the context of
Low-Rank Adaptation (LoRA). Our method addresses two critical challenges in LLM
fine-tuning: mitigating catastrophic forgetting during continual learning and
reducing the number of trainable parameters. We propose a unique modification
to the CUR decomposition process, utilizing inverted probabilities for column
and row selection which acts as an implicit regularization, and initializing
the $U$ matrix as a zero matrix, and only fine-tuning it. We demonstrate
through experiments on multiple datasets that CURLoRA outperforms standard LoRA
in mitigating catastrophic forgetting. It maintains model stability and
performance across tasks while significantly reducing the number of trainable
parameters. Our results show that CURLoRA achieves very good and stable task
accuracy while maintaining base model's perplexity scores fixed compared to
LoRA upon continual fine-tuning, particularly in scenarios with limited data.",2024-08-26,Muhammad Fawi,http://arxiv.org/pdf/2408.14572v1,cs.CL
Improving Clinical Note Generation from Complex Doctor-Patient Conversation,"Writing clinical notes and documenting medical exams is a critical task for
healthcare professionals, serving as a vital component of patient care
documentation. However, manually writing these notes is time-consuming and can
impact the amount of time clinicians can spend on direct patient interaction
and other tasks. Consequently, the development of automated clinical note
generation systems has emerged as a clinically meaningful area of research
within AI for health. In this paper, we present three key contributions to the
field of clinical note generation using large language models (LLMs). First, we
introduce CliniKnote, a comprehensive dataset consisting of 1,200 complex
doctor-patient conversations paired with their full clinical notes. This
dataset, created and curated by medical experts with the help of modern neural
networks, provides a valuable resource for training and evaluating models in
clinical note generation tasks. Second, we propose the K-SOAP (Keyword,
Subjective, Objective, Assessment, and Plan) note format, which enhances
traditional SOAP~\cite{podder2023soap} (Subjective, Objective, Assessment, and
Plan) notes by adding a keyword section at the top, allowing for quick
identification of essential information. Third, we develop an automatic
pipeline to generate K-SOAP notes from doctor-patient conversations and
benchmark various modern LLMs using various metrics. Our results demonstrate
significant improvements in efficiency and performance compared to standard LLM
finetuning methods.",2024-08-26,"Yizhan Li, Sifan Wu, Christopher Smith, Thomas Lo, Bang Liu",http://arxiv.org/pdf/2408.14568v1,cs.CL
Revisiting Image Captioning Training Paradigm via Direct CLIP-based Optimization,"The conventional training approach for image captioning involves pre-training
a network using teacher forcing and subsequent fine-tuning with Self-Critical
Sequence Training to maximize hand-crafted captioning metrics. However, when
attempting to optimize modern and higher-quality metrics like CLIP-Score and
PAC-Score, this training method often encounters instability and fails to
acquire the genuine descriptive capabilities needed to produce fluent and
informative captions. In this paper, we propose a new training paradigm termed
Direct CLIP-Based Optimization (DiCO). Our approach jointly learns and
optimizes a reward model that is distilled from a learnable captioning
evaluator with high human correlation. This is done by solving a weighted
classification problem directly inside the captioner. At the same time, DiCO
prevents divergence from the original model, ensuring that fluency is
maintained. DiCO not only exhibits improved stability and enhanced quality in
the generated captions but also aligns more closely with human preferences
compared to existing methods, especially in modern metrics. Additionally, it
maintains competitive performance in traditional metrics. Our source code and
trained models are publicly available at https://github.com/aimagelab/DiCO.",2024-08-26,"Nicholas Moratelli, Davide Caffagni, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara",http://arxiv.org/pdf/2408.14547v1,cs.CL
A Practitioner's Guide to Continual Multimodal Pretraining,"Multimodal foundation models serve numerous applications at the intersection
of vision and language. Still, despite being pretrained on extensive data, they
become outdated over time. To keep models updated, research into continual
pretraining mainly explores scenarios with either (1) infrequent,
indiscriminate updates on large-scale new data, or (2) frequent, sample-level
updates. However, practical model deployment often operates in the gap between
these two limit cases, as real-world applications often demand adaptation to
specific subdomains, tasks or concepts -- spread over the entire, varying life
cycle of a model. In this work, we complement current perspectives on continual
pretraining through a research test bed as well as provide comprehensive
guidance for effective continual model updates in such scenarios. We first
introduce FoMo-in-Flux, a continual multimodal pretraining benchmark with
realistic compute constraints and practical deployment requirements,
constructed over 63 datasets with diverse visual and semantic coverage. Using
FoMo-in-Flux, we explore the complex landscape of practical continual
pretraining through multiple perspectives: (1) A data-centric investigation of
data mixtures and stream orderings that emulate real-world deployment
situations, (2) a method-centric investigation ranging from simple fine-tuning
and traditional continual learning strategies to parameter-efficient updates
and model merging, (3) meta learning rate schedules and mechanistic design
choices, and (4) the influence of model and compute scaling. Together, our
insights provide a practitioner's guide to continual multimodal pretraining for
real-world deployment. Our benchmark and code is here:
https://github.com/ExplainableML/fomo_in_flux.",2024-08-26,"Karsten Roth, Vishaal Udandarao, Sebastian Dziadzio, Ameya Prabhu, Mehdi Cherti, Oriol Vinyals, Olivier Hénaff, Samuel Albanie, Matthias Bethge, Zeynep Akata",http://arxiv.org/pdf/2408.14471v2,cs.CL
Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models,"Fine-tuning large language models (LLMs) on downstream tasks requires
substantial computational resources. A class of parameter-efficient fine-tuning
(PEFT) aims to mitigate these computational challenges by selectively
fine-tuning only a small fraction of the model parameters. Although
computationally efficient, these techniques often fail to match the performance
of fully fine-tuned models, primarily due to inherent biases introduced during
parameter selection. Traditional selective PEFT techniques use a fixed set of
parameters based on a predefined budget (a process also known as unmasking),
failing to capture parameter importance dynamically and often ending up
exceeding the budget. We introduce $\text{ID}^3$, a novel selective PEFT method
that calculates parameter importance continually and dynamically unmasks
parameters by balancing exploration and exploitation in parameter selection.
Our empirical study on 15 tasks spanning natural language understanding and
generative tasks demonstrates the effectiveness of our method compared to
fixed-masking-based PEFT techniques. We analytically show that $\text{ID}^3$
reduces the number of gradient updates by a factor of two, enhancing
computational efficiency. $\text{ID}^3$ is robust to random initialization of
neurons and, therefore, can be seamlessly integrated into existing additive and
reparametrization-based PEFT modules such as adapters and LoRA for dynamic
sparsification.",2024-08-26,"Aradhye Agarwal, Suhas K Ramesh, Ayan Sengupta, Tanmoy Chakraborty",http://arxiv.org/pdf/2408.14470v2,cs.CL
Explicit Inductive Inference using Large Language Models,"Large Language Models (LLMs) are reported to hold undesirable attestation
bias on inference tasks: when asked to predict if a premise P entails a
hypothesis H, instead of considering H's conditional truthfulness entailed by
P, LLMs tend to use the out-of-context truth label of H as a fragile proxy. In
this paper, we propose a pipeline that exploits this bias to do explicit
inductive inference. Our pipeline uses an LLM to transform a premise into a set
of attested alternatives, and then aggregate answers of the derived new
entailment inquiries to support the original inference prediction. On a
directional predicate entailment benchmark, we demonstrate that by applying
this simple pipeline, we can improve the overall performance of LLMs on
inference and substantially alleviate the impact of their attestation bias.",2024-08-26,"Tianyang Liu, Tianyi Li, Liang Cheng, Mark Steedman",http://arxiv.org/pdf/2408.14467v1,cs.CL
Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study,"The emergence of large language models such as ChatGPT, Gemini, and others
highlights the importance of evaluating their diverse capabilities, ranging
from natural language understanding to code generation. However, their
performance on spatial tasks has not been thoroughly assessed. This study
addresses this gap by introducing a new multi-task spatial evaluation dataset
designed to systematically explore and compare the performance of several
advanced models on spatial tasks. The dataset includes twelve distinct task
types, such as spatial understanding and simple route planning, each with
verified and accurate answers. We evaluated multiple models, including OpenAI's
gpt-3.5-turbo, gpt-4-turbo, gpt-4o, ZhipuAI's glm-4, Anthropic's
claude-3-sonnet-20240229, and MoonShot's moonshot-v1-8k, using a two-phase
testing approach. First, we conducted zero-shot testing. Then, we categorized
the dataset by difficulty and performed prompt-tuning tests. Results show that
gpt-4o achieved the highest overall accuracy in the first phase, with an
average of 71.3%. Although moonshot-v1-8k slightly underperformed overall, it
outperformed gpt-4o in place name recognition tasks. The study also highlights
the impact of prompt strategies on model performance in specific tasks. For
instance, the Chain-of-Thought (CoT) strategy increased gpt-4o's accuracy in
simple route planning from 12.4% to 87.5%, while a one-shot strategy improved
moonshot-v1-8k's accuracy in mapping tasks from 10.1% to 76.3%.",2024-08-26,"Liuchang Xu, Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen Wu, Xinyue Ye, Hailin Feng, Zhenhong Du",http://arxiv.org/pdf/2408.14438v4,cs.CL
CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models,"We introduce CHARTOM, a visual theory-of-mind benchmark for multimodal large
language models. CHARTOM consists of specially designed data visualizing
charts. Given a chart, a language model needs to not only correctly comprehend
the chart (the FACT question) but also judge if the chart will be misleading to
a human reader (the MIND question). Both questions have significant societal
benefits. We detail the construction of the CHARTOM benchmark including its
calibration on human performance. We benchmark leading LLMs as of late 2024 -
including GPT, Claude, Gemini, Qwen, Llama, and Llava - on the CHARTOM dataset
and found that our benchmark was challenging to all of them, suggesting room
for future large language models to improve.",2024-08-26,"Shubham Bharti, Shiyun Cheng, Jihyun Rho, Jianrui Zhang, Mu Cai, Yong Jae Lee, Martina Rau, Xiaojin Zhu",http://arxiv.org/pdf/2408.14419v2,cs.CL
MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues,"Automatic Speech Recognition (ASR) systems are pivotal in transcribing speech
into text, yet the errors they introduce can significantly degrade the
performance of downstream tasks like summarization. This issue is particularly
pronounced in clinical dialogue summarization, a low-resource domain where
supervised data for fine-tuning is scarce, necessitating the use of ASR models
as black-box solutions. Employing conventional data augmentation for enhancing
the noise robustness of summarization models is not feasible either due to the
unavailability of sufficient medical dialogue audio recordings and
corresponding ASR transcripts. To address this challenge, we propose MEDSAGE,
an approach for generating synthetic samples for data augmentation using Large
Language Models (LLMs). Specifically, we leverage the in-context learning
capabilities of LLMs and instruct them to generate ASR-like errors based on a
few available medical dialogue examples with audio recordings. Experimental
results show that LLMs can effectively model ASR noise, and incorporating this
noisy data into the training process significantly improves the robustness and
accuracy of medical dialogue summarization systems. This approach addresses the
challenges of noisy ASR outputs in critical applications, offering a robust
solution to enhance the reliability of clinical dialogue summarization.",2024-08-26,"Kuluhan Binici, Abhinav Ramesh Kashyap, Viktor Schlegel, Andy T. Liu, Vijay Prakash Dwivedi, Thanh-Tung Nguyen, Xiaoxue Gao, Nancy F. Chen, Stefan Winkler",http://arxiv.org/pdf/2408.14418v3,cs.CL
Investigating Language-Specific Calibration For Pruning Multilingual Large Language Models,"Recent advances in large language model (LLM) pruning have shown
state-of-the-art (SotA) compression results in post-training and
retraining-free settings while maintaining high predictive performance.
However, previous research mainly considered calibrating based on English text,
despite the multilingual nature of modern LLMs and their frequent use in
non-English languages. In this paper, we set out to investigate calibrating the
pruning of multilingual language models for monolingual applications. We
present the first comprehensive empirical study, comparing different
calibration languages for pruning multilingual models across diverse languages,
tasks, models, and SotA pruning techniques. Our results offer practical
suggestions, for example, calibrating in the target language can efficiently
retain the language modeling capability but does not necessarily benefit
downstream tasks. Through further analysis of latent subspaces, pruning masks,
and individual neurons within pruned models, we find that while pruning
generally preserves strong language-specific features, it may fail to retain
language-specific neuron activation patterns and subtle, language-agnostic
features associated with knowledge and reasoning that are needed for complex
tasks.",2024-08-26,"Simon Kurz, Jian-Jia Chen, Lucie Flek, Zhixue Zhao",http://arxiv.org/pdf/2408.14398v3,cs.CL
Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs,"Recent advancements in artificial intelligence have significantly improved
the automatic generation of radiology reports. However, existing evaluation
methods fail to reveal the models' understanding of radiological images and
their capacity to achieve human-level granularity in descriptions. To bridge
this gap, we introduce a system, named ReXKG, which extracts structured
information from processed reports to construct a comprehensive radiology
knowledge graph. We then propose three metrics to evaluate the similarity of
nodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs
(ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparative
analysis of AI-generated and human-written radiology reports, assessing the
performance of both specialist and generalist models. Our study provides a
deeper understanding of the capabilities and limitations of current AI models
in radiology report generation, offering valuable insights for improving model
performance and clinical applicability.",2024-08-26,"Xiaoman Zhang, Julián N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar",http://arxiv.org/pdf/2408.14397v1,cs.CL
Probing Causality Manipulation of Large Language Models,"Large language models (LLMs) have shown various ability on natural language
processing, including problems about causality. It is not intuitive for LLMs to
command causality, since pretrained models usually work on statistical
associations, and do not focus on causes and effects in sentences. So that
probing internal manipulation of causality is necessary for LLMs. This paper
proposes a novel approach to probe causality manipulation hierarchically, by
providing different shortcuts to models and observe behaviors. We exploit
retrieval augmented generation (RAG) and in-context learning (ICL) for models
on a designed causality classification task. We conduct experiments on
mainstream LLMs, including GPT-4 and some smaller and domain-specific models.
Our results suggest that LLMs can detect entities related to causality and
recognize direct causal relationships. However, LLMs lack specialized cognition
for causality, merely treating them as part of the global semantic of the
sentence.",2024-08-26,"Chenyang Zhang, Haibo Tong, Bin Zhang, Dongyu Zhang",http://arxiv.org/pdf/2408.14380v1,cs.CL
SWE-bench-java: A GitHub Issue Resolving Benchmark for Java,"GitHub issue resolving is a critical task in software engineering, recently
gaining significant attention in both industry and academia. Within this task,
SWE-bench has been released to evaluate issue resolving capabilities of large
language models (LLMs), but has so far only focused on Python version. However,
supporting more programming languages is also important, as there is a strong
demand in industry. As a first step toward multilingual support, we have
developed a Java version of SWE-bench, called SWE-bench-java. We have publicly
released the dataset, along with the corresponding Docker-based evaluation
environment and leaderboard, which will be continuously maintained and updated
in the coming months. To verify the reliability of SWE-bench-java, we implement
a classic method SWE-agent and test several powerful LLMs on it. As is well
known, developing a high-quality multi-lingual benchmark is time-consuming and
labor-intensive, so we welcome contributions through pull requests or
collaboration to accelerate its iteration and refinement, paving the way for
fully automated programming.",2024-08-26,"Daoguang Zan, Zhirong Huang, Ailun Yu, Shaoxin Lin, Yifan Shi, Wei Liu, Dong Chen, Zongshuai Qi, Hao Yu, Lei Yu, Dezhi Ran, Muhan Zeng, Bo Shen, Pan Bian, Guangtai Liang, Bei Guan, Pengjie Huang, Tao Xie, Yongji Wang, Qianxiang Wang",http://arxiv.org/pdf/2408.14354v1,cs.CL
Assessing Contamination in Large Language Models: Introducing the LogProber method,"In machine learning, contamination refers to situations where testing data
leak into the training set. The issue is particularly relevant for the
evaluation of the performance of Large Language Models (LLMs), which are
generally trained on gargantuan, and generally opaque, corpora of text scraped
from the world wide web. Developing tools to detect contamination is therefore
crucial to be able to fairly and properly track the evolution of the
performance of LLMs. Most recent works in the field are not tailored to
quantify contamination on short sequences of text like we find in psychology
questionnaires. In the present paper we introduce LogProber, a novel,
efficient, algorithm that we show able to detect contamination using token
probability in given sentences. In the second part we investigate the
limitations of the method and discuss how different training methods can
contaminate models without leaving traces in the token probabilities.",2024-08-26,"Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri",http://arxiv.org/pdf/2408.14352v1,cs.CL
Foundation Models for Music: A Survey,"In recent years, foundation models (FMs) such as large language models (LLMs)
and latent diffusion models (LDMs) have profoundly impacted diverse sectors,
including music. This comprehensive review examines state-of-the-art (SOTA)
pre-trained models and foundation models in music, spanning from representation
learning, generative learning and multimodal learning. We first contextualise
the significance of music in various industries and trace the evolution of AI
in music. By delineating the modalities targeted by foundation models, we
discover many of the music representations are underexplored in FM development.
Then, emphasis is placed on the lack of versatility of previous methods on
diverse music applications, along with the potential of FMs in music
understanding, generation and medical application. By comprehensively exploring
the details of the model pre-training paradigm, architectural choices,
tokenisation, finetuning methodologies and controllability, we emphasise the
important topics that should have been well explored, like instruction tuning
and in-context learning, scaling law and emergent ability, as well as
long-sequence modelling etc. A dedicated section presents insights into music
agents, accompanied by a thorough analysis of datasets and evaluations
essential for pre-training and downstream tasks. Finally, by underscoring the
vital importance of ethical considerations, we advocate that following research
on FM for music should focus more on such issues as interpretability,
transparency, human responsibility, and copyright issues. The paper offers
insights into future challenges and trends on FMs for music, aiming to shape
the trajectory of human-AI collaboration in the music realm.",2024-08-26,"Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wenhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang",http://arxiv.org/pdf/2408.14340v3,cs.CL
Claim Verification in the Age of Large Language Models: A Survey,"The large and ever-increasing amount of data available on the Internet
coupled with the laborious task of manual claim and fact verification has
sparked the interest in the development of automated claim verification
systems. Several deep learning and transformer-based models have been proposed
for this task over the years. With the introduction of Large Language Models
(LLMs) and their superior performance in several NLP tasks, we have seen a
surge of LLM-based approaches to claim verification along with the use of novel
methods such as Retrieval Augmented Generation (RAG). In this survey, we
present a comprehensive account of recent claim verification frameworks using
LLMs. We describe the different components of the claim verification pipeline
used in these frameworks in detail including common approaches to retrieval,
prompting, and fine-tuning. Finally, we describe publicly available English
datasets created for this task.",2024-08-26,"Alphaeus Dmonte, Roland Oruche, Marcos Zampieri, Prasad Calyam, Isabelle Augenstein",http://arxiv.org/pdf/2408.14317v2,cs.CL
LLM-3D Print: Large Language Models To Monitor and Control 3D Printing,"Industry 4.0 has revolutionized manufacturing by driving digitalization and
shifting the paradigm toward additive manufacturing (AM). Fused Deposition
Modeling (FDM), a key AM technology, enables the creation of highly customized,
cost-effective products with minimal material waste through layer-by-layer
extrusion, posing a significant challenge to traditional subtractive methods.
However, the susceptibility of material extrusion techniques to errors often
requires expert intervention to detect and mitigate defects that can severely
compromise product quality. While automated error detection and machine
learning models exist, their generalizability across diverse 3D printer setups,
firmware, and sensors is limited, and deep learning methods require extensive
labeled datasets, hindering scalability and adaptability. To address these
challenges, we present a process monitoring and control framework that
leverages pre-trained Large Language Models (LLMs) alongside 3D printers to
detect and address printing defects. The LLM evaluates print quality by
analyzing images captured after each layer or print segment, identifying
failure modes and querying the printer for relevant parameters. It then
generates and executes a corrective action plan. We validated the effectiveness
of the proposed framework in identifying defects by comparing it against a
control group of engineers with diverse AM expertise. Our evaluation
demonstrated that LLM-based agents not only accurately identify common 3D
printing errors, such as inconsistent extrusion, stringing, warping, and layer
adhesion, but also effectively determine the parameters causing these failures
and autonomously correct them without any need for human intervention.",2024-08-26,"Yayati Jadhav, Peter Pak, Amir Barati Farimani",http://arxiv.org/pdf/2408.14307v2,cs.CL
Predictability and Causality in Spanish and English Natural Language Generation,"In recent years, the field of Natural Language Generation (NLG) has been
boosted by the recent advances in deep learning technologies. Nonetheless,
these new data-intensive methods introduce language-dependent disparities in
NLG as the main training data sets are in English. Also, most neural NLG
systems use decoder-only (causal) transformer language models, which work well
for English, but were not designed with other languages in mind. In this work
we depart from the hypothesis that they may introduce generation bias in target
languages with less rigid word ordering, subject omission, or different
attachment preferences for relative clauses, so that for these target languages
other language generation strategies may be more desirable. This paper first
compares causal and non-causal language modeling for English and Spanish, two
languages with different grammatical structures and over 1.5 billion and 0.5
billion speakers, respectively. For this purpose, we define a novel metric of
average causal and non-causal context-conditioned entropy of the grammatical
category distribution for both languages as an information-theoretic a priori
approach. The evaluation of natural text sources (such as training data) in
both languages reveals lower average non-causal conditional entropy in Spanish
and lower causal conditional entropy in English. According to this experiment,
Spanish is more predictable than English given a non-causal context. Then, by
applying a conditional relative entropy metric to text generation experiments,
we obtain as insights that the best performance is respectively achieved with
causal NLG in English, and with non-causal NLG in Spanish. These insights
support further research in NLG in Spanish using bidirectional transformer
language models.",2024-08-26,"Andrea Busto-Castiñeira, Francisco J. González-Castaño, Silvia García-Méndez, Francisco de Arriba-Pérez",http://arxiv.org/pdf/2408.14283v1,cs.CL
Examining Independence in Ensemble Sentiment Analysis: A Study on the Limits of Large Language Models Using the Condorcet Jury Theorem,"This paper explores the application of the Condorcet Jury theorem to the
domain of sentiment analysis, specifically examining the performance of various
large language models (LLMs) compared to simpler natural language processing
(NLP) models. The theorem posits that a majority vote classifier should enhance
predictive accuracy, provided that individual classifiers' decisions are
independent. Our empirical study tests this theoretical framework by
implementing a majority vote mechanism across different models, including
advanced LLMs such as ChatGPT 4. Contrary to expectations, the results reveal
only marginal improvements in performance when incorporating larger models,
suggesting a lack of independence among them. This finding aligns with the
hypothesis that despite their complexity, LLMs do not significantly outperform
simpler models in reasoning tasks within sentiment analysis, showing the
practical limits of model independence in the context of advanced NLP tasks.",2024-08-26,"Baptiste Lefort, Eric Benhamou, Jean-Jacques Ohana, Beatrice Guez, David Saltiel, Thomas Jacquot",http://arxiv.org/pdf/2409.00094v1,cs.CL
Epidemic Information Extraction for Event-Based Surveillance using Large Language Models,"This paper presents a novel approach to epidemic surveillance, leveraging the
power of Artificial Intelligence and Large Language Models (LLMs) for effective
interpretation of unstructured big data sources, like the popular ProMED and
WHO Disease Outbreak News. We explore several LLMs, evaluating their
capabilities in extracting valuable epidemic information. We further enhance
the capabilities of the LLMs using in-context learning, and test the
performance of an ensemble model incorporating multiple open-source LLMs. The
findings indicate that LLMs can significantly enhance the accuracy and
timeliness of epidemic modelling and forecasting, offering a promising tool for
managing future pandemic events.",2024-08-26,"Sergio Consoli, Peter Markov, Nikolaos I. Stilianakis, Lorenzo Bertolini, Antonio Puertas Gallardo, Mario Ceresa",http://arxiv.org/pdf/2408.14277v1,cs.CL
Self-supervised Speech Representations Still Struggle with African American Vernacular English,"Underperformance of ASR systems for speakers of African American Vernacular
English (AAVE) and other marginalized language varieties is a well-documented
phenomenon, and one that reinforces the stigmatization of these varieties. We
investigate whether or not the recent wave of Self-Supervised Learning (SSL)
speech models can close the gap in ASR performance between AAVE and Mainstream
American English (MAE). We evaluate four SSL models (wav2vec 2.0, HuBERT,
WavLM, and XLS-R) on zero-shot Automatic Speech Recognition (ASR) for these two
varieties and find that these models perpetuate the bias in performance against
AAVE. Additionally, the models have higher word error rates on utterances with
more phonological and morphosyntactic features of AAVE. Despite the success of
SSL speech models in improving ASR for low resource varieties, SSL pre-training
alone may not bridge the gap between AAVE and MAE. Our code is publicly
available at https://github.com/cmu-llab/s3m-aave.",2024-08-26,"Kalvin Chang, Yi-Hui Chou, Jiatong Shi, Hsuan-Ming Chen, Nicole Holliday, Odette Scharenborg, David R. Mortensen",http://arxiv.org/pdf/2408.14262v1,cs.CL
An Evaluation of Explanation Methods for Black-Box Detectors of Machine-Generated Text,"The increasing difficulty to distinguish language-model-generated from
human-written text has led to the development of detectors of machine-generated
text (MGT). However, in many contexts, a black-box prediction is not
sufficient, it is equally important to know on what grounds a detector made
that prediction. Explanation methods that estimate feature importance promise
to provide indications of which parts of an input are used by classifiers for
prediction. However, the quality of different explanation methods has not
previously been assessed for detectors of MGT. This study conducts the first
systematic evaluation of explanation quality for this task. The dimensions of
faithfulness and stability are assessed with five automated experiments, and
usefulness is evaluated in a user study. We use a dataset of ChatGPT-generated
and human-written documents, and pair predictions of three existing
language-model-based detectors with the corresponding SHAP, LIME, and Anchor
explanations. We find that SHAP performs best in terms of faithfulness,
stability, and in helping users to predict the detector's behavior. In
contrast, LIME, perceived as most useful by users, scores the worst in terms of
user performance at predicting the detectors' behavior.",2024-08-26,"Loris Schoenegger, Yuxi Xia, Benjamin Roth",http://arxiv.org/pdf/2408.14252v1,cs.CL
DSTI at LLMs4OL 2024 Task A: Intrinsic versus extrinsic knowledge for type classification,"We introduce semantic towers, an extrinsic knowledge representation method,
and compare it to intrinsic knowledge in large language models for ontology
learning. Our experiments show a trade-off between performance and semantic
grounding for extrinsic knowledge compared to a fine-tuned model intrinsic
knowledge. We report our findings on the Large Language Models for Ontology
Learning (LLMs4OL) 2024 challenge.",2024-08-26,Hanna Abi Akl,http://arxiv.org/pdf/2408.14236v1,cs.CL
Large Language Model for Patent Concept Generation,"In traditional innovation practices, concept and IP generation are often
iteratively integrated. Both processes demand an intricate understanding of
advanced technical domain knowledge. Existing large language models (LLMs),
while possessing massive pre-trained knowledge, often fall short in the
innovative concept generation due to a lack of specialized knowledge necessary
for the generation. To bridge this critical gap, we propose a novel knowledge
finetuning (KFT) framework to endow LLM-based AI with the ability to
autonomously mine, understand, and apply domain-specific knowledge and concepts
for invention generation, i.e., concept and patent generation together. Our
proposed PatentGPT integrates knowledge injection pre-training (KPT),
domain-specific supervised finetuning (SFT), and reinforcement learning from
human feedback (RLHF). Extensive evaluation shows that PatentGPT significantly
outperforms the state-of-the-art models on patent-related benchmark tests. Our
method not only provides new insights into data-driven innovation but also
paves a new path to fine-tune LLMs for applications in the context of
technology. We also discuss the managerial and policy implications of
AI-generating inventions in the future.",2024-08-26,"Runtao Ren, Jian Ma, Jianxi Luo",http://arxiv.org/pdf/2409.00092v3,cs.CL
Investigating the effect of Mental Models in User Interaction with an Adaptive Dialog Agent,"Mental models play an important role in whether user interaction with
intelligent systems, such as dialog systems is successful or not. Adaptive
dialog systems present the opportunity to align a dialog agent's behavior with
heterogeneous user expectations. However, there has been little research into
what mental models users form when interacting with a task-oriented dialog
system, how these models affect users' interactions, or what role system
adaptation can play in this process, making it challenging to avoid damage to
human-AI partnership. In this work, we collect a new publicly available dataset
for exploring user mental models about information seeking dialog systems. We
demonstrate that users have a variety of conflicting mental models about such
systems, the validity of which directly impacts the success of their
interactions and perceived usability of system. Furthermore, we show that
adapting a dialog agent's behavior to better align with users' mental models,
even when done implicitly, can improve perceived usability, dialog efficiency,
and success. To this end, we argue that implicit adaptation can be a valid
strategy for task-oriented dialog systems, so long as developers first have a
solid understanding of users' mental models.",2024-08-26,"Lindsey Vanderlyn, Dirk Väth, Ngoc Thang Vu",http://arxiv.org/pdf/2408.14154v1,cs.CL
Explaining Caption-Image Interactions in CLIP models with Second-Order Attributions,"Dual encoder architectures like CLIP models map two types of inputs into a
shared embedding space and predict similarities between them. Despite their
success, it is, however, not understood how these models compare their two
inputs. Common first-order feature-attribution methods can only provide limited
insights into dual-encoders since their predictions depend on
feature-interactions rather than on individual features. In this paper, we
first derive a second-order method enabling the attribution of predictions by
any differentiable dual encoder onto feature-interactions between its inputs.
Second, we apply our method to CLIP models and show that they learn
fine-grained correspondences between parts of captions and regions in images.
They match objects across input modes also account for mismatches. This
visual-linguistic grounding ability, however, varies heavily between object
classes and exhibits pronounced out-of-domain effects. We can identify
individual errors as well as systematic failure categories including object
coverage, unusual scenes and correlated contexts.",2024-08-26,"Lucas Möller, Pascal Tilli, Ngoc Thang Vu, Sebastian Padó",http://arxiv.org/pdf/2408.14153v3,cs.CL
Crowd-Calibrator: Can Annotator Disagreement Inform Calibration in Subjective Tasks?,"Subjective tasks in NLP have been mostly relegated to objective standards,
where the gold label is decided by taking the majority vote. This obfuscates
annotator disagreement and the inherent uncertainty of the label. We argue that
subjectivity should factor into model decisions and play a direct role via
calibration under a selective prediction setting. Specifically, instead of
calibrating confidence purely from the model's perspective, we calibrate models
for subjective tasks based on crowd worker agreement. Our method,
Crowd-Calibrator, models the distance between the distribution of crowd worker
labels and the model's own distribution over labels to inform whether the model
should abstain from a decision. On two highly subjective tasks, hate speech
detection and natural language inference, our experiments show Crowd-Calibrator
either outperforms or achieves competitive performance with existing selective
prediction baselines. Our findings highlight the value of bringing human
decision-making into model predictions.",2024-08-26,"Urja Khurana, Eric Nalisnick, Antske Fokkens, Swabha Swayamdipta",http://arxiv.org/pdf/2408.14141v1,cs.CL
Multi-Faceted Evaluation of Modeling Languages for Augmented Reality Applications -- The Case of ARWFML,"The evaluation of modeling languages for augmented reality applications poses
particular challenges due to the three-dimensional environment they target. The
previously introduced Augmented Reality Workflow Modeling Language (ARWFML)
enables the model-based creation of augmented reality scenarios without
programming knowledge. Building upon the first design cycle of the language's
specification, this paper presents two further design iterations for refining
the language based on multi-faceted evaluations. These include a comparative
evaluation of implementation options and workflow capabilities, the
introduction of a 3D notation, and the development of a new 3D modeling
environment. On this basis, a comprehensibility study of the language was
conducted. Thereby, we show how modeling languages for augmented reality can be
evolved towards a maturity level suitable for empirical evaluations.",2024-08-26,"Fabian Muff, Hans-Georg Fill",http://arxiv.org/pdf/2408.14137v1,cs.CL
Exploring the Potential of Large Language Models for Heterophilic Graphs,"Large language models (LLMs) have presented significant opportunities to
enhance various machine learning applications, including graph neural networks
(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more
effectively interpret and utilize textual data to better characterize
heterophilic graphs, where neighboring nodes often have different labels.
However, existing approaches for heterophilic graphs overlook the rich textual
data associated with nodes, which could unlock deeper insights into their
heterophilic contexts. In this work, we explore the potential of LLMs for
modeling heterophilic graphs and propose a novel two-stage framework:
LLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first
stage, we fine-tune the LLM to better identify homophilic and heterophilic
edges based on the textual content of their nodes. In the second stage, we
adaptively manage message propagation in GNNs for different edge types based on
node features, structures, and heterophilic or homophilic characteristics. To
cope with the computational demands when deploying LLMs in practical scenarios,
we further explore model distillation techniques to fine-tune smaller, more
efficient models that maintain competitive performance. Extensive experiments
validate the effectiveness of our framework, demonstrating the feasibility of
using LLMs to enhance node classification on heterophilic graphs.",2024-08-26,"Yuxia Wu, Shujie Li, Yuan Fang, Chuan Shi",http://arxiv.org/pdf/2408.14134v3,cs.CL
Contrastive Learning Subspace for Text Clustering,"Contrastive learning has been frequently investigated to learn effective
representations for text clustering tasks. While existing contrastive
learning-based text clustering methods only focus on modeling instance-wise
semantic similarity relationships, they ignore contextual information and
underlying relationships among all instances that needs to be clustered. In
this paper, we propose a novel text clustering approach called Subspace
Contrastive Learning (SCL) which models cluster-wise relationships among
instances. Specifically, the proposed SCL consists of two main modules: (1) a
self-expressive module that constructs virtual positive samples and (2) a
contrastive learning module that further learns a discriminative subspace to
capture task-specific cluster-wise relationships among texts. Experimental
results show that the proposed SCL method not only has achieved superior
results on multiple task clustering datasets but also has less complexity in
positive sample construction.",2024-08-26,"Qian Yong, Chen Chen, Xiabing Zhou",http://arxiv.org/pdf/2408.14119v1,cs.CL
Classification of Safety Events at Nuclear Sites using Large Language Models,"This paper proposes the development of a Large Language Model (LLM) based
machine learning classifier designed to categorize Station Condition Records
(SCRs) at nuclear power stations into safety-related and non-safety-related
categories. The primary objective is to augment the existing manual review
process by enhancing the efficiency and accuracy of the safety classification
process at nuclear stations. The paper discusses experiments performed to
classify a labeled SCR dataset and evaluates the performance of the classifier.
It explores the construction of several prompt variations and their observed
effects on the LLM's decision-making process. Additionally, it introduces a
numerical scoring mechanism that could offer a more nuanced and flexible
approach to SCR safety classification. This method represents an innovative
step in nuclear safety management, providing a scalable tool for the
identification of safety events.",2024-08-26,"Mishca de Costa, Muhammad Anwar, Daniel Lau, Issam Hammad",http://arxiv.org/pdf/2409.00091v1,cs.CL
Evaluating ChatGPT on Nuclear Domain-Specific Data,"This paper examines the application of ChatGPT, a large language model (LLM),
for question-and-answer (Q&A) tasks in the highly specialized field of nuclear
data. The primary focus is on evaluating ChatGPT's performance on a curated
test dataset, comparing the outcomes of a standalone LLM with those generated
through a Retrieval Augmented Generation (RAG) approach. LLMs, despite their
recent advancements, are prone to generating incorrect or 'hallucinated'
information, which is a significant limitation in applications requiring high
accuracy and reliability. This study explores the potential of utilizing RAG in
LLMs, a method that integrates external knowledge bases and sophisticated
retrieval techniques to enhance the accuracy and relevance of generated
outputs. In this context, the paper evaluates ChatGPT's ability to answer
domain-specific questions, employing two methodologies: A) direct response from
the LLM, and B) response from the LLM within a RAG framework. The effectiveness
of these methods is assessed through a dual mechanism of human and LLM
evaluation, scoring the responses for correctness and other metrics. The
findings underscore the improvement in performance when incorporating a RAG
pipeline in an LLM, particularly in generating more accurate and contextually
appropriate responses for nuclear domain-specific queries. Additionally, the
paper highlights alternative approaches to further refine and improve the
quality of answers in such specialized domains.",2024-08-26,"Muhammad Anwar, Mischa de Costa, Issam Hammad, Daniel Lau",http://arxiv.org/pdf/2409.00090v1,cs.CL
Enhancing Depression Diagnosis with Chain-of-Thought Prompting,"When using AI to detect signs of depressive disorder, AI models habitually
draw preemptive conclusions. We theorize that using chain-of-thought (CoT)
prompting to evaluate Patient Health Questionnaire-8 (PHQ-8) scores will
improve the accuracy of the scores determined by AI models. In our findings,
when the models reasoned with CoT, the estimated PHQ-8 scores were consistently
closer on average to the accepted true scores reported by each participant
compared to when not using CoT. Our goal is to expand upon AI models'
understanding of the intricacies of human conversation, allowing them to more
effectively assess a patient's feelings and tone, therefore being able to more
accurately discern mental disorder symptoms; ultimately, we hope to augment AI
models' abilities, so that they can be widely accessible and used in the
medical field.",2024-08-26,"Elysia Shi, Adithri Manda, London Chowdhury, Runeema Arun, Kevin Zhu, Michael Lam",http://arxiv.org/pdf/2408.14053v2,cs.CL
MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents,"Machine learning research, crucial for technological advancements and
innovation, often faces significant challenges due to its inherent complexity,
slow pace of experimentation, and the necessity for specialized expertise.
Motivated by this, we present a new systematic framework, autonomous Machine
Learning Research with large language models (MLR-Copilot), designed to enhance
machine learning research productivity through the automatic generation and
implementation of research ideas using Large Language Model (LLM) agents. The
framework consists of three phases: research idea generation, experiment
implementation, and implementation execution. First, existing research papers
are used to generate hypotheses and experimental plans vis IdeaAgent powered by
LLMs. Next, the implementation generation phase translates these plans into
executables with ExperimentAgent. This phase leverages retrieved prototype code
and optionally retrieves candidate models and data. Finally, the execution
phase, also managed by ExperimentAgent, involves running experiments with
mechanisms for human feedback and iterative debugging to enhance the likelihood
of achieving executable research outcomes. We evaluate our framework on five
machine learning research tasks and the experimental results show the
framework's potential to facilitate the research progress and innovations.",2024-08-26,"Ruochen Li, Teerth Patel, Qingyun Wang, Xinya Du",http://arxiv.org/pdf/2408.14033v2,cs.CL
SurGen: Text-Guided Diffusion Model for Surgical Video Generation,"Diffusion-based video generation models have made significant strides,
producing outputs with improved visual fidelity, temporal coherence, and user
control. These advancements hold great promise for improving surgical education
by enabling more realistic, diverse, and interactive simulation environments.
In this study, we introduce SurGen, a text-guided diffusion model tailored for
surgical video synthesis. SurGen produces videos with the highest resolution
and longest duration among existing surgical video generation models. We
validate the visual and temporal quality of the outputs using standard image
and video generation metrics. Additionally, we assess their alignment to the
corresponding text prompts through a deep learning classifier trained on
surgical data. Our results demonstrate the potential of diffusion models to
serve as valuable educational tools for surgical trainees.",2024-08-26,"Joseph Cho, Samuel Schmidgall, Cyril Zakka, Mrudang Mathur, Dhamanpreet Kaur, Rohan Shad, William Hiesinger",http://arxiv.org/pdf/2408.14028v3,cs.CL
Empowering Low-Resource Language ASR via Large-Scale Pseudo Labeling,"In this study, we tackle the challenge of limited labeled data for
low-resource languages in ASR, focusing on Hindi. Specifically, we explore
pseudo-labeling, by proposing a generic framework combining multiple ideas from
existing works. Our framework integrates multiple base models for transcription
and evaluators for assessing audio-transcript pairs, resulting in robust
pseudo-labeling for low resource languages. We validate our approach with a new
benchmark, IndicYT, comprising diverse YouTube audio files from multiple
content categories. Our findings show that augmenting pseudo labeled data from
YouTube with existing training data leads to significant performance
improvements on IndicYT, without affecting performance on out-of-domain
benchmarks, demonstrating the efficacy of pseudo-labeled data in enhancing ASR
capabilities for low-resource languages. The benchmark, code and models
developed as a part of this work will be made publicly available.",2024-08-26,"Kaushal Santosh Bhogale, Deovrat Mehendale, Niharika Parasa, Sathish Kumar Reddy G, Tahir Javed, Pratyush Kumar, Mitesh M. Khapra",http://arxiv.org/pdf/2408.14026v1,cs.CL
On-Device Language Models: A Comprehensive Review,"The advent of large language models (LLMs) revolutionized natural language
processing applications, and running LLMs on edge devices has become
increasingly attractive for reasons including reduced latency, data
localization, and personalized user experiences. This comprehensive review
examines the challenges of deploying computationally expensive LLMs on
resource-constrained devices and explores innovative solutions across multiple
domains. The paper investigates the development of on-device language models,
their efficient architectures, including parameter sharing and modular designs,
as well as state-of-the-art compression techniques like quantization, pruning,
and knowledge distillation. Hardware acceleration strategies and collaborative
edge-cloud deployment approaches are analyzed, highlighting the intricate
balance between performance and resource utilization. Case studies of on-device
language models from major mobile manufacturers demonstrate real-world
applications and potential benefits. The review also addresses critical aspects
such as adaptive learning, multi-modal capabilities, and personalization. By
identifying key research directions and open challenges, this paper provides a
roadmap for future advancements in on-device language models, emphasizing the
need for interdisciplinary efforts to realize the full potential of ubiquitous,
intelligent computing while ensuring responsible and ethical deployment. For a
comprehensive review of research work and educational resources on on-device
large language models (LLMs), please visit
https://github.com/NexaAI/Awesome-LLMs-on-device. To download and run on-device
LLMs, visit https://www.nexaai.com/models.",2024-08-26,"Jiajun Xu, Zhiyuan Li, Wei Chen, Qun Wang, Xin Gao, Qi Cai, Ziyuan Ling",http://arxiv.org/pdf/2409.00088v2,cs.CL
Question answering system of bridge design specification based on large language model,"This paper constructs question answering system for bridge design
specification based on large language model. Three implementation schemes are
tried: full fine-tuning of the Bert pretrained model, parameter-efficient
fine-tuning of the Bert pretrained model, and self-built language model from
scratch. Through the self-built question and answer task dataset, based on the
tensorflow and keras deep learning platform framework, the model is constructed
and trained to predict the start position and end position of the answer in the
bridge design specification given by the user. The experimental results show
that full fine-tuning of the Bert pretrained model achieves 100% accuracy in
the training-dataset, validation-dataset and test-dataset, and the system can
extract the answers from the bridge design specification given by the user to
answer various questions of the user; While parameter-efficient fine-tuning of
the Bert pretrained model and self-built language model from scratch perform
well in the training-dataset, their generalization ability in the test-dataset
needs to be improved. The research of this paper provides a useful reference
for the development of question answering system in professional field.",2024-08-26,"Leye Zhang, Xiangxiang Tian, Hongjun Zhang",http://arxiv.org/pdf/2408.13282v1,cs.CL
Focused Large Language Models are Stable Many-Shot Learners,"In-Context Learning (ICL) enables large language models (LLMs) to achieve
rapid task adaptation by learning from demonstrations. With the increase in
available context length of LLMs, recent experiments have shown that the
performance of ICL does not necessarily scale well in many-shot (demonstration)
settings. We theoretically and experimentally confirm that the reason lies in
more demonstrations dispersing the model attention from the query, hindering
its understanding of key content. Inspired by how humans learn from examples,
we propose a training-free method FocusICL, which conducts triviality filtering
to avoid attention being diverted by unimportant contents at token-level and
operates hierarchical attention to further ensure sufficient attention towards
current query at demonstration-level. We also design an efficient
hyperparameter searching strategy for FocusICL based on model perplexity of
demonstrations. Comprehensive experiments validate that FocusICL achieves an
average performance improvement of 5.2% over vanilla ICL and scales well with
many-shot demonstrations.",2024-08-26,"Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Heda Wang, Yao Hu, Kan Li",http://arxiv.org/pdf/2408.13987v1,cs.CL
AgentMove: A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction,"Next location prediction plays a crucial role in various real-world
applications. Recently, due to the limitation of existing deep learning
methods, attempts have been made to apply large language models (LLMs) to
zero-shot next location prediction task. However, they directly generate the
final output using LLMs without systematic design, which limits the potential
of LLMs to uncover complex mobility patterns and underestimates their extensive
reserve of global geospatial knowledge. In this paper, we introduce AgentMove,
a systematic agentic prediction framework to achieve generalized next location
prediction. In AgentMove, we first decompose the mobility prediction task and
design specific modules to complete them, including spatial-temporal memory for
individual mobility pattern mining, world knowledge generator for modeling the
effects of urban structure and collective knowledge extractor for capturing the
shared patterns among population. Finally, we combine the results of three
modules and conduct a reasoning step to generate the final predictions.
Extensive experiments utilizing mobility data from two distinct sources reveal
that AgentMove surpasses the leading baseline by 3.33% to 8.57% across 8 out of
12 metrics and it shows robust predictions with various LLMs as base and also
less geographical bias across cities. Our codes are available via
https://github.com/tsinghua-fib-lab/AgentMove.",2024-08-26,"Jie Feng, Yuwei Du, Jie Zhao, Yong Li",http://arxiv.org/pdf/2408.13986v2,cs.CL
TF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models,"With the great advancements in large language models (LLMs), adversarial
attacks against LLMs have recently attracted increasing attention. We found
that pre-existing adversarial attack methodologies exhibit limited
transferability and are notably inefficient, particularly when applied to LLMs.
In this paper, we analyze the core mechanisms of previous predominant
adversarial attack methods, revealing that 1) the distributions of importance
score differ markedly among victim models, restricting the transferability; 2)
the sequential attack processes induces substantial time overheads. Based on
the above two insights, we introduce a new scheme, named TF-Attack, for
Transferable and Fast adversarial attacks on LLMs. TF-Attack employs an
external LLM as a third-party overseer rather than the victim model to identify
critical units within sentences. Moreover, TF-Attack introduces the concept of
Importance Level, which allows for parallel substitutions of attacks. We
conduct extensive experiments on 6 widely adopted benchmarks, evaluating the
proposed method through both automatic and human metrics. Results show that our
method consistently surpasses previous methods in transferability and delivers
significant speed improvements, up to 20 times faster than earlier attack
strategies.",2024-08-26,"Zelin Li, Kehai Chen, Lemao Liu, Xuefeng Bai, Mingming Yang, Yang Xiang, Min Zhang",http://arxiv.org/pdf/2408.13985v3,cs.CL
Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models,"With the prevalence of large-scale pretrained vision-language models (VLMs),
such as CLIP, soft-prompt tuning has become a popular method for adapting these
models to various downstream tasks. However, few works delve into the inherent
properties of learnable soft-prompt vectors, specifically the impact of their
norms to the performance of VLMs. This motivates us to pose an unexplored
research question: ``Do we need to normalize the soft prompts in VLMs?'' To
fill this research gap, we first uncover a phenomenon, called the
\textbf{Low-Norm Effect} by performing extensive corruption experiments,
suggesting that reducing the norms of certain learned prompts occasionally
enhances the performance of VLMs, while increasing them often degrades it. To
harness this effect, we propose a novel method named \textbf{N}ormalizing
th\textbf{e} soft-pro\textbf{m}pt v\textbf{e}ctors of vi\textbf{si}on-language
model\textbf{s} (\textbf{Nemesis}) to normalize soft-prompt vectors in VLMs. To
the best of our knowledge, our work is the first to systematically investigate
the role of norms of soft-prompt vector in VLMs, offering valuable insights for
future research in soft-prompt tuning. The code is available at
\texttt{\href{https://github.com/ShyFoo/Nemesis}{https://github.com/ShyFoo/Nemesis}}.",2024-08-26,"Shuai Fu, Xiequn Wang, Qiushi Huang, Yu Zhang",http://arxiv.org/pdf/2408.13979v1,cs.CL
Reducing the Cost: Cross-Prompt Pre-Finetuning for Short Answer Scoring,"Automated Short Answer Scoring (SAS) is the task of automatically scoring a
given input to a prompt based on rubrics and reference answers. Although SAS is
useful in real-world applications, both rubrics and reference answers differ
between prompts, thus requiring a need to acquire new data and train a model
for each new prompt. Such requirements are costly, especially for schools and
online courses where resources are limited and only a few prompts are used. In
this work, we attempt to reduce this cost through a two-phase approach: train a
model on existing rubrics and answers with gold score signals and finetune it
on a new prompt. Specifically, given that scoring rubrics and reference answers
differ for each prompt, we utilize key phrases, or representative expressions
that the answer should contain to increase scores, and train a SAS model to
learn the relationship between key phrases and answers using already annotated
prompts (i.e., cross-prompts). Our experimental results show that finetuning on
existing cross-prompt data with key phrases significantly improves scoring
accuracy, especially when the training data is limited. Finally, our extensive
analysis shows that it is crucial to design the model so that it can learn the
task's general property.",2024-08-26,"Hiroaki Funayama, Yuya Asazuma, Yuichiroh Matsubayashi, Tomoya Mizumoto, Kentaro Inui",http://arxiv.org/pdf/2408.13966v1,cs.CL
Bidirectional Awareness Induction in Autoregressive Seq2Seq Models,"Autoregressive Sequence-To-Sequence models are the foundation of many Deep
Learning achievements in major research fields such as Vision and Natural
Language Processing. Despite that, they still present significant limitations.
For instance, when errors occur in the early steps of the prediction, the whole
output is severely affected. Such reliance on previously predicted tokens and
the inherent computational unfriendliness of sequential algorithms, motivated
researchers to explore different architectures and methods in the search for
bidirectional approaches. In this work, we introduce the Bidirectional
Awareness Induction (BAI), a training method that leverages a subset of
elements in the network, the Pivots, to perform bidirectional learning without
breaking the autoregressive constraints. To showcase its flexibility, we apply
the method to three architectures, the Transformer, ExpansionNet v2 and GPT,
then perform experiments over three tasks. Experimental results showcase BAI's
effectiveness on all selected tasks and architectures. In particular, we
observed an increase of up to 2.4 CIDEr in Image-Captioning, 4.96 BLEU in
Neural Machine Translation, and 1.16 ROUGE in Text Summarization compared to
the respective baselines. Notably, BAI not only has a positive impact on models
trained from scratch but on pre-trained models as well. Such an aspect,
combined with the absence of architectural requirements synergizes well with
the current trend of LLMs.",2024-08-25,"Jia Cheng Hu, Roberto Cavicchioli, Alessandro Capotondi",http://arxiv.org/pdf/2408.13959v1,cs.CL
"Prediction of COPD Using Machine Learning, Clinical Summary Notes, and Vital Signs","Chronic obstructive pulmonary disease (COPD) is a chronic inflammatory lung
disease that causes obstructed airflow from the lungs. In the United States,
more than 15.7 million Americans have been diagnosed with COPD, with 96% of
individuals living with at least one other chronic health condition. It is the
4th leading cause of death in the country. Over 2.2 million patients are
admitted to hospitals annually due to COPD exacerbations. Monitoring and
predicting patient exacerbations on-time could save their life. This paper
presents two different predictive models to predict COPD exacerbation using AI
and natural language processing (NLP) approaches. These models use respiration
summary notes, symptoms, and vital signs. To train and test these models, data
records containing physiologic signals and vital signs time series were used.
These records were captured from patient monitors and comprehensive clinical
data obtained from hospital medical information systems for tens of thousands
of Intensive Care Unit (ICU) patients. We achieved an area under the Receiver
operating characteristic (ROC) curve of 0.82 in detection and prediction of
COPD exacerbation.",2024-08-25,Negar Orangi-Fard,http://arxiv.org/pdf/2408.13958v2,cs.CL
Derailer-Rerailer: Adaptive Verification for Efficient and Reliable Language Model Reasoning,"Large Language Models (LLMs) have shown impressive reasoning capabilities,
yet existing prompting methods face a critical trade-off: simple approaches
often struggle with complex tasks and reasoning stability, while more
sophisticated methods require multiple inferences and substantial computational
resources, limiting their practical deployment. To address this challenge, we
propose Derailer-Rerailer, a novel framework that adaptively balances reasoning
accuracy and computational efficiency. At its core, our framework employs a
lightweight Derailer mechanism to assess reasoning stability and selectively
triggers an advanced Rerailer verification process only when necessary, thereby
optimizing computational resource usage. Extensive evaluation across both open
and closed-source models on more than 20 categories of mathematical, symbolic,
and commonsense reasoning tasks demonstrates our framework's effectiveness:
Derailer-Rerailer achieves significant accuracy improvements (8-11\% across
various reasoning tasks) while maintaining 2-3 times better efficiency than
existing verification methods, with particularly strong performance in
mathematical and symbolic reasoning, offering a practical solution for
enhancing LLM reasoning reliability while significantly reducing computational
overhead.",2024-08-25,"Guangya Wan, Yuqi Wu, Hao Wang, Shengming Zhao, Jie Chen, Sheng Li",http://arxiv.org/pdf/2408.13940v3,cs.CL
MobileQuant: Mobile-friendly Quantization for On-device Language Models,"Large language models (LLMs) have revolutionized language processing,
delivering outstanding results across multiple applications. However, deploying
LLMs on edge devices poses several challenges with respect to memory, energy,
and compute costs, limiting their widespread use in devices such as mobile
phones. A promising solution is to reduce the number of bits used to represent
weights and activations. While existing works have found partial success at
quantizing LLMs to lower bitwidths, e.g. 4-bit weights, quantizing activations
beyond 16 bits often leads to large computational overheads due to poor
on-device quantization support, or a considerable accuracy drop. Yet, 8-bit
activations are very attractive for on-device deployment as they would enable
LLMs to fully exploit mobile-friendly hardware, e.g. Neural Processing Units
(NPUs). In this work, we make a first attempt to facilitate the on-device
deployment of LLMs using integer-only quantization. We first investigate the
limitations of existing quantization methods for on-device deployment, with a
special focus on activation quantization. We then address these limitations by
introducing a simple post-training quantization method, named MobileQuant, that
extends previous weight equivalent transformation works by jointly optimizing
the weight transformation and activation range parameters in an end-to-end
manner. MobileQuant demonstrates superior capabilities over existing methods by
1) achieving near-lossless quantization on a wide range of LLM benchmarks, 2)
reducing latency and energy consumption by 20\%-50\% compared to current
on-device quantization strategies, 3) requiring limited compute budget, 4)
being compatible with mobile-friendly compute units, e.g. NPU.",2024-08-25,"Fuwen Tan, Royson Lee, Łukasz Dudziak, Shell Xu Hu, Sourav Bhattacharya, Timothy Hospedales, Georgios Tzimiropoulos, Brais Martinez",http://arxiv.org/pdf/2408.13933v2,cs.CL
Genetic Approach to Mitigate Hallucination in Generative IR,"Generative language models hallucinate. That is, at times, they generate
factually flawed responses. These inaccuracies are particularly insidious
because the responses are fluent and well-articulated. We focus on the task of
Grounded Answer Generation (part of Generative IR), which aims to produce
direct answers to a user's question based on results retrieved from a search
engine. We address hallucination by adapting an existing genetic generation
approach with a new 'balanced fitness function' consisting of a cross-encoder
model for relevance and an n-gram overlap metric to promote grounding. Our
balanced fitness function approach quadruples the grounded answer generation
accuracy while maintaining high relevance.",2024-08-25,"Hrishikesh Kulkarni, Nazli Goharian, Ophir Frieder, Sean MacAvaney",http://arxiv.org/pdf/2409.00085v1,cs.CL
LLMs are Superior Feedback Providers: Bootstrapping Reasoning for Lie Detection with Self-Generated Feedback,"Large Language Models (LLMs) excel at generating human-like dialogues and
comprehending text. However, understanding the subtleties of complex exchanges
in language remains a challenge. We propose a bootstrapping framework that
leverages self-generated feedback to enhance LLM reasoning capabilities for lie
detection. The framework consists of three stages: suggestion, feedback
collection, and modification. In the suggestion stage, a cost-effective
language model generates initial predictions based on game state and dialogue.
The feedback-collection stage involves a language model providing feedback on
these predictions. In the modification stage, a more advanced language model
refines the initial predictions using the auto-generated feedback. We
investigate the application of the proposed framework for detecting betrayal
and deception in Diplomacy games, and compare it with feedback from
professional human players. The LLM-generated feedback exhibits superior
quality and significantly enhances the performance of the model. Our approach
achieves a 39% improvement over the zero-shot baseline in lying-F1 without the
need for any training data, rivaling state-of-the-art supervised learning
results.",2024-08-25,"Tanushree Banerjee, Richard Zhu, Runzhe Yang, Karthik Narasimhan",http://arxiv.org/pdf/2408.13915v1,cs.CL
LowCLIP: Adapting the CLIP Model Architecture for Low-Resource Languages in Multimodal Image Retrieval Task,"This research explores the development of multimodal vision-language models
for image retrieval in low-resource languages, specifically Azerbaijani.
Existing vision-language models primarily support high-resource languages, and
fine-tuning them remains computationally demanding. To address challenges in
vision-language retrieval for low-resource languages, we integrated the CLIP
model architecture and employed several techniques to balance computational
efficiency with performance. These techniques include synthetic data generation
through machine translation, image augmentation, and further training the
attention mechanisms of transformer-based models with domain-specific data. We
integrated Multilingual BERT as a text encoder with image encoders like
ResNet50, EfficientNet0, Vision Transformer (ViT), and Tiny Swin Transformer.
Our study found that models like EfficientNet0 and Tiny Swin Transformer
perform best on the datasets they were trained on, such as COCO, Flickr30k, and
Flickr8k. Augmentation techniques boosted EfficientNet0 MAP on Flickr30k from
0.84 to 0.87 and ResNet50 MAP on MSCOCO from 0.70 to 0.80, contributing to a
new state of the art in vision-language retrieval. We share our configurations
and results to support further research. Code and pre-trained models are
available at https://github.com/aliasgerovs/azclip.",2024-08-25,"Ali Asgarov, Samir Rustamov",http://arxiv.org/pdf/2408.13909v1,cs.CL
SimpleSpeech 2: Towards Simple and Efficient Text-to-Speech with Flow-based Scalar Latent Transformer Diffusion Models,"Scaling Text-to-speech (TTS) to large-scale datasets has been demonstrated as
an effective method for improving the diversity and naturalness of synthesized
speech. At the high level, previous large-scale TTS models can be categorized
into either Auto-regressive (AR) based (\textit{e.g.}, VALL-E) or
Non-auto-regressive (NAR) based models (\textit{e.g.}, NaturalSpeech 2/3).
Although these works demonstrate good performance, they still have potential
weaknesses. For instance, AR-based models are plagued by unstable generation
quality and slow generation speed; meanwhile, some NAR-based models need
phoneme-level duration alignment information, thereby increasing the complexity
of data pre-processing, model design, and loss design. In this work, we build
upon our previous publication by implementing a simple and efficient
non-autoregressive (NAR) TTS framework, termed SimpleSpeech 2. SimpleSpeech 2
effectively combines the strengths of both autoregressive (AR) and
non-autoregressive (NAR) methods, offering the following key advantages: (1)
simplified data preparation; (2) straightforward model and loss design; and (3)
stable, high-quality generation performance with fast inference speed. Compared
to our previous publication, we present ({\romannumeral1}) a detailed analysis
of the influence of speech tokenizer and noisy label for TTS performance;
({\romannumeral2}) four distinct types of sentence duration predictors;
({\romannumeral3}) a novel flow-based scalar latent transformer diffusion
model. With these improvement, we show a significant improvement in generation
performance and generation speed compared to our previous work and other
state-of-the-art (SOTA) large-scale TTS models. Furthermore, we show that
SimpleSpeech 2 can be seamlessly extended to multilingual TTS by training it on
multilingual speech datasets. Demos are available on:
{https://dongchaoyang.top/SimpleSpeech2\_demo/}.",2024-08-25,"Dongchao Yang, Rongjie Huang, Yuanyuan Wang, Haohan Guo, Dading Chong, Songxiang Liu, Xixin Wu, Helen Meng",http://arxiv.org/pdf/2408.13893v2,cs.CL
SpeechCaps: Advancing Instruction-Based Universal Speech Models with Multi-Talker Speaking Style Captioning,"Instruction-based speech processing is becoming popular. Studies show that
training with multiple tasks boosts performance, but collecting diverse,
large-scale tasks and datasets is expensive. Thus, it is highly desirable to
design a fundamental task that benefits other downstream tasks. This paper
introduces a multi-talker speaking style captioning task to enhance the
understanding of speaker and prosodic information. We used large language
models to generate descriptions for multi-talker speech. Then, we trained our
model with pre-training on this captioning task followed by instruction tuning.
Evaluation on Dynamic-SUPERB shows our model outperforming the baseline
pre-trained only on single-talker tasks, particularly in speaker and emotion
recognition. Additionally, tests on a multi-talker QA task reveal that current
models struggle with attributes such as gender, pitch, and speaking rate. The
code and dataset are available at https://github.com/cyhuang-tw/speechcaps.",2024-08-25,"Chien-yu Huang, Min-Han Shih, Ke-Han Lu, Chi-Yuan Hsiao, Hung-yi Lee",http://arxiv.org/pdf/2408.13891v1,cs.CL
LLM with Relation Classifier for Document-Level Relation Extraction,"Large language models (LLMs) have created a new paradigm for natural language
processing. Despite their advancement, LLM-based methods still lag behind
traditional approaches in document-level relation extraction (DocRE), a
critical task for understanding complex entity relations within long context.
This paper investigates the causes of this performance gap, identifying the
dispersion of attention by LLMs due to entity pairs without relations as a key
factor. We then introduce a novel classifier-LLM approach to DocRE.
Particularly, the proposed approach begins with a classifier designed to select
entity pair candidates that exhibit potential relations and then feed them to
LLM for final relation classification. This method ensures that the LLM's
attention is directed at relation-expressing entity pairs instead of those
without relations during inference. Experiments on DocRE benchmarks reveal that
our method significantly outperforms recent LLM-based DocRE models and narrows
the performance gap with state-of-the-art BERT-based models.",2024-08-25,"Xingzuo Li, Kehai Chen, Yunfei Long, Min Zhang",http://arxiv.org/pdf/2408.13889v2,cs.CL
CodeGraph: Enhancing Graph Reasoning of LLMs with Code,"With the increasing popularity of large language models (LLMs), reasoning on
basic graph algorithm problems is an essential intermediate step in assessing
their abilities to process and infer complex graph reasoning tasks. Existing
methods usually convert graph-structured data to textual descriptions and then
use LLMs for reasoning and computation. However, LLMs often produce computation
errors on arithmetic parts in basic graph algorithm problems, such as counting
number of edges. In addition, they struggle to control or understand the output
of the reasoning process, raising concerns about whether LLMs are simply
guessing. In this paper, we introduce CodeGraph, a method that encodes graph
problem solutions as code. The methods solve new graph problems by learning
from exemplars, generating programs, and executing them via a program
interpreter. Using the few-shot setting, we evaluate CodeGraph with the base
LLM being GPT-3.5 Turbo, Llama3-70B Instruct, Mixtral-8x22B Instruct, and
Mixtral-8x7B Instruct. Experimental results on six tasks with six graph
encoding methods in the GraphQA dataset demonstrate that CodeGraph can boost
performance on graph reasoning tasks inside LLMs by 1.3% to 58.6%, depending on
the task. Compared to the existing methods, CodeGraph demonstrates strong
performance on arithmetic problems in graph tasks and offers a more
controllable and interpretable approach to the reasoning process.",2024-08-25,"Qiaolong Cai, Zhaowei Wang, Shizhe Diao, James Kwok, Yangqiu Song",http://arxiv.org/pdf/2408.13863v1,cs.CL
Knowledge-Aware Reasoning over Multimodal Semi-structured Tables,"Existing datasets for tabular question answering typically focus exclusively
on text within cells. However, real-world data is inherently multimodal, often
blending images such as symbols, faces, icons, patterns, and charts with
textual content in tables. With the evolution of AI models capable of
multimodal reasoning, it is pertinent to assess their efficacy in handling such
structured data. This study investigates whether current AI models can perform
knowledge-aware reasoning on multimodal structured data. We explore their
ability to reason on tables that integrate both images and text, introducing
MMTabQA, a new dataset designed for this purpose. Our experiments highlight
substantial challenges for current AI models in effectively integrating and
interpreting multiple text and image inputs, understanding visual context, and
comparing visual content across images. These findings establish our dataset as
a robust benchmark for advancing AI's comprehension and capabilities in
analyzing multimodal structured data.",2024-08-25,"Suyash Vardhan Mathur, Jainit Sushil Bafna, Kunal Kartik, Harshita Khandelwal, Manish Shrivastava, Vivek Gupta, Mohit Bansal, Dan Roth",http://arxiv.org/pdf/2408.13860v1,cs.CL
"Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models","Background and Aims: This study evaluates the medical reasoning performance
of large language models (LLMs) and vision language models (VLMs) in
gastroenterology.
  Methods: We used 300 gastroenterology board exam-style multiple-choice
questions, 138 of which contain images to systematically assess the impact of
model configurations and parameters and prompt engineering strategies utilizing
GPT-3.5. Next, we assessed the performance of proprietary and open-source LLMs
(versions), including GPT (3.5, 4, 4o, 4omini), Claude (3, 3.5), Gemini (1.0),
Mistral, Llama (2, 3, 3.1), Mixtral, and Phi (3), across different interfaces
(web and API), computing environments (cloud and local), and model precisions
(with and without quantization). Finally, we assessed accuracy using a
semiautomated pipeline.
  Results: Among the proprietary models, GPT-4o (73.7%) and Claude3.5-Sonnet
(74.0%) achieved the highest accuracy, outperforming the top open-source
models: Llama3.1-405b (64%), Llama3.1-70b (58.3%), and Mixtral-8x7b (54.3%).
Among the quantized open-source models, the 6-bit quantized Phi3-14b (48.7%)
performed best. The scores of the quantized models were comparable to those of
the full-precision models Llama2-7b, Llama2--13b, and Gemma2-9b. Notably, VLM
performance on image-containing questions did not improve when the images were
provided and worsened when LLM-generated captions were provided. In contrast, a
10% increase in accuracy was observed when images were accompanied by
human-crafted image descriptions.
  Conclusion: In conclusion, while LLMs exhibit robust zero-shot performance in
medical reasoning, the integration of visual data remains a challenge for VLMs.
Effective deployment involves carefully determining optimal model
configurations, encouraging users to consider either the high performance of
proprietary models or the flexible adaptability of open-source models.",2024-08-25,"Seyed Amir Ahmad Safavi-Naini, Shuhaib Ali, Omer Shahab, Zahra Shahhoseini, Thomas Savage, Sara Rafiee, Jamil S Samaan, Reem Al Shabeeb, Farah Ladak, Jamie O Yang, Juan Echavarria, Sumbal Babar, Aasma Shaukat, Samuel Margolis, Nicholas P Tatonetti, Girish Nadkarni, Bara El Kurdi, Ali Soroush",http://arxiv.org/pdf/2409.00084v2,cs.CL
Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data,"Large language models (LLMs) have shown potential in biomedical applications,
leading to efforts to fine-tune them on domain-specific data. However, the
effectiveness of this approach remains unclear. This study evaluates the
performance of biomedically fine-tuned LLMs against their general-purpose
counterparts on a variety of clinical tasks. We evaluated their performance on
clinical case challenges from the New England Journal of Medicine (NEJM) and
the Journal of the American Medical Association (JAMA) and on several clinical
tasks (e.g., information extraction, document summarization, and clinical
coding). Using benchmarks specifically chosen to be likely outside the
fine-tuning datasets of biomedical models, we found that biomedical LLMs mostly
perform inferior to their general-purpose counterparts, especially on tasks not
focused on medical knowledge. While larger models showed similar performance on
case tasks (e.g., OpenBioLLM-70B: 66.4% vs. Llama-3-70B-Instruct: 65% on JAMA
cases), smaller biomedical models showed more pronounced underperformance
(e.g., OpenBioLLM-8B: 30% vs. Llama-3-8B-Instruct: 64.3% on NEJM cases).
Similar trends were observed across the CLUE (Clinical Language Understanding
Evaluation) benchmark tasks, with general-purpose models often performing
better on text generation, question answering, and coding tasks. Our results
suggest that fine-tuning LLMs to biomedical data may not provide the expected
benefits and may potentially lead to reduced performance, challenging
prevailing assumptions about domain-specific adaptation of LLMs and
highlighting the need for more rigorous evaluation frameworks in healthcare AI.
Alternative approaches, such as retrieval-augmented generation, may be more
effective in enhancing the biomedical capabilities of LLMs without compromising
their general knowledge.",2024-08-25,"Felix J. Dorfner, Amin Dada, Felix Busch, Marcus R. Makowski, Tianyu Han, Daniel Truhn, Jens Kleesiek, Madhumita Sushil, Jacqueline Lammert, Lisa C. Adams, Keno K. Bressem",http://arxiv.org/pdf/2408.13833v1,cs.CL
Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!,"Annually, at the Conference of Machine Translation (WMT), the Metrics Shared
Task organizers conduct the meta-evaluation of Machine Translation (MT)
metrics, ranking them according to their correlation with human judgments.
Their results guide researchers toward enhancing the next generation of metrics
and MT systems. With the recent introduction of neural metrics, the field has
witnessed notable advancements. Nevertheless, the inherent opacity of these
metrics has posed substantial challenges to the meta-evaluation process. This
work highlights two issues with the meta-evaluation framework currently
employed in WMT, and assesses their impact on the metrics rankings. To do this,
we introduce the concept of sentinel metrics, which are designed explicitly to
scrutinize the meta-evaluation process's accuracy, robustness, and fairness. By
employing sentinel metrics, we aim to validate our findings, and shed light on
and monitor the potential biases or inconsistencies in the rankings. We
discover that the present meta-evaluation framework favors two categories of
metrics: i) those explicitly trained to mimic human quality assessments, and
ii) continuous metrics. Finally, we raise concerns regarding the evaluation
capabilities of state-of-the-art metrics, emphasizing that they might be basing
their assessments on spurious correlations found in their training data.",2024-08-25,"Stefano Perrella, Lorenzo Proietti, Alessandro Scirè, Edoardo Barba, Roberto Navigli",http://arxiv.org/pdf/2408.13831v1,cs.CL
Revisiting the Exit from Nuclear Energy in Germany with NLP,"Annotation of political discourse is resource-intensive, but recent
developments in NLP promise to automate complex annotation tasks. Fine-tuned
transformer-based models outperform human annotators in some annotation tasks,
but they require large manually annotated training datasets. In our
contribution, we explore to which degree a manually annotated dataset can be
automatically replicated with today's NLP methods, using unsupervised machine
learning and zero- and few-shot learning.",2024-08-25,"Sebastian Haunss, André Blessing",http://arxiv.org/pdf/2408.13810v1,cs.CL
Towards Reliable Medical Question Answering: Techniques and Challenges in Mitigating Hallucinations in Language Models,"The rapid advancement of large language models (LLMs) has significantly
impacted various domains, including healthcare and biomedicine. However, the
phenomenon of hallucination, where LLMs generate outputs that deviate from
factual accuracy or context, poses a critical challenge, especially in
high-stakes domains. This paper conducts a scoping study of existing techniques
for mitigating hallucinations in knowledge-based task in general and especially
for medical domains. Key methods covered in the paper include
Retrieval-Augmented Generation (RAG)-based techniques, iterative feedback
loops, supervised fine-tuning, and prompt engineering. These techniques, while
promising in general contexts, require further adaptation and optimization for
the medical domain due to its unique demands for up-to-date, specialized
knowledge and strict adherence to medical guidelines. Addressing these
challenges is crucial for developing trustworthy AI systems that enhance
clinical decision-making and patient safety as well as accuracy of biomedical
scientific research.",2024-08-25,"Duy Khoa Pham, Bao Quoc Vo",http://arxiv.org/pdf/2408.13808v1,cs.CL
DOCE: Finding the Sweet Spot for Execution-Based Code Generation,"Recently, a diverse set of decoding and reranking procedures have been shown
effective for LLM-based code generation. However, a comprehensive framework
that links and experimentally compares these methods is missing. We address
this by proposing Decoding Objectives for Code Execution, a comprehensive
framework that includes candidate generation, $n$-best reranking, minimum Bayes
risk (MBR) decoding, and self-debugging as the core components. We then study
the contributions of these components through execution-based evaluation
metrics. Our findings highlight the importance of execution-based methods and
the difference gap between execution-based and execution-free methods.
Furthermore, we assess the impact of filtering based on trial unit tests, a
simple and effective strategy that has been often overlooked in prior works. We
also propose self-debugging on multiple candidates, obtaining state-of-the-art
performance on reranking for code generation. We expect our framework to
provide a solid guideline for future research on code generation.",2024-08-25,"Haau-Sing Li, Patrick Fernandes, Iryna Gurevych, André F. T. Martins",http://arxiv.org/pdf/2408.13745v4,cs.CL
Literary and Colloquial Tamil Dialect Identification,"Culture and language evolve together. The old literary form of Tamil is used
commonly for writing and the contemporary colloquial Tamil is used for
speaking. Human-computer interaction applications require Colloquial Tamil (CT)
to make it more accessible and easy for the everyday user and, it requires
Literary Tamil (LT) when information is needed in a formal written format.
Continuing the use of LT alongside CT in computer aided language learning
applications will both preserve LT, and provide ease of use via CT, at the same
time. Hence there is a need for the conversion between LT and CT dialects,
which demands as a first step, dialect identification. Dialect Identification
(DID) of LT and CT is an unexplored area of research. In the current work,
keeping the nuances of both these dialects in mind, five methods are explored
which include two implicit methods - Gaussian Mixture Model (GMM) and
Convolutional Neural Network (CNN); two explicit methods - Parallel Phone
Recognition (PPR) and Parallel Large Vocabulary Continuous Speech Recognition
(P-LVCSR); two versions of the proposed explicit Unified Phone Recognition
method (UPR-1 and UPR-2). These methods vary based on: the need for annotated
data, the size of the unit, the way in which modelling is carried out, and the
way in which the final decision is made. Even though the average duration of
the test utterances is less - 4.9s for LT and 2.5s for CT - the systems
performed well, offering the following identification accuracies: 87.72% (GMM),
93.97% (CNN), 89.24% (PPR), 94.21% (P-LVCSR), 88.57% (UPR-1), 93.53% (UPR-1
with P-LVCSR), 94.55% (UPR-2), and 95.61% (UPR-2 with P-LVCSR).",2024-08-25,"M. Nanmalar, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.13739v1,cs.CL
Poor-Supervised Evaluation for SuperLLM via Mutual Consistency,"The guidance from capability evaluations has greatly propelled the progress
of both human society and Artificial Intelligence. However, as LLMs evolve, it
becomes challenging to construct evaluation benchmarks for them with accurate
labels on hard tasks that approach the boundaries of human capabilities. To
credibly conduct evaluation without accurate labels (denoted as poor-supervised
evaluation), we propose the PoEM framework. We first prove that the capability
of a model can be equivalently assessed by the consistency between it and
certain reference model, when their prediction distributions are independent
and the sample size is infinite. To alleviate the insufficiencies of the
conditions in reality, we further introduce an algorithm that treats humans
(when available) and the models under evaluation as reference models,
alternately conducting model weights calibration and filtering during E-step
and M-step. Comprehensive experiments across 3 types of tasks with 16
mainstream LLMs have shown that PoEM under poor supervision can achieve an
average of 0.98 Pearson correlation coefficient with supervised evaluation
results, demonstrating good effectiveness, efficiency and generalizability.
More generally, PoEM has advanced the evaluation paradigm evolution from
human-centric to human&model-centric by treating both of them as reference
models, mitigating the limitations of human evaluation in the era of LLMs.",2024-08-25,"Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Yao Hu, Kan Li",http://arxiv.org/pdf/2408.13738v1,cs.CL
LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings,"Zero-shot graph machine learning, especially with graph neural networks
(GNNs), has garnered significant interest due to the challenge of scarce
labeled data. While methods like self-supervised learning and graph prompt
learning have been extensively explored, they often rely on fine-tuning with
task-specific labels, limiting their effectiveness in zero-shot scenarios.
Inspired by the zero-shot capabilities of instruction-fine-tuned large language
models (LLMs), we introduce a novel framework named Token Embedding-Aligned
Graph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and
cross-task zero-shot learners for graph machine learning. Concretely, we
pretrain a GNN, aligning its representations with token embeddings of an LLM.
We then train a linear projector that transforms the GNN's representations into
a fixed number of graph token embeddings without tuning the LLM. A unified
instruction is designed for various graph tasks at different levels, such as
node classification (node-level) and link prediction (edge-level). These design
choices collectively enhance our method's effectiveness in zero-shot learning,
setting it apart from existing methods. Experiments show that our graph token
embeddings help the LLM predictor achieve state-of-the-art performance on
unseen datasets and tasks compared to other methods using LLMs as predictors.",2024-08-25,"Duo Wang, Yuan Zuo, Fengzhi Li, Junjie Wu",http://arxiv.org/pdf/2408.14512v3,cs.CL
Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods,"Chain-of-Thought (CoT) prompting and its variants have gained popularity as
effective methods for solving multi-step reasoning problems using pretrained
large language models (LLMs). In this work, we analyze CoT prompting from a
statistical estimation perspective, providing a comprehensive characterization
of its sample complexity. To this end, we introduce a multi-step latent
variable model that encapsulates the reasoning process, where the latent
variable encodes the task information. Under this framework, we demonstrate
that when the pretraining dataset is sufficiently large, the estimator formed
by CoT prompting is equivalent to a Bayesian estimator. This estimator
effectively solves the multi-step reasoning problem by aggregating a posterior
distribution inferred from the demonstration examples in the prompt. Moreover,
we prove that the statistical error of the CoT estimator can be decomposed into
two main components: (i) a prompting error, which arises from inferring the
true task using CoT prompts, and (ii) the statistical error of the pretrained
LLM. We establish that, under appropriate assumptions, the prompting error
decays exponentially to zero as the number of demonstrations increases.
Additionally, we explicitly characterize the approximation and generalization
errors of the pretrained LLM. Notably, we construct a transformer model that
approximates the target distribution of the multi-step reasoning problem with
an error that decreases exponentially in the number of transformer blocks. Our
analysis extends to other variants of CoT, including Self-Consistent CoT,
Tree-of-Thought, and Selection-Inference, offering a broad perspective on the
efficacy of these methods. We also provide numerical experiments to validate
the theoretical findings.",2024-08-25,"Xinyang Hu, Fengzhuo Zhang, Siyu Chen, Zhuoran Yang",http://arxiv.org/pdf/2408.14511v2,cs.CL
DHP Benchmark: Are LLMs Good NLG Evaluators?,"Large Language Models (LLMs) are increasingly serving as evaluators in
Natural Language Generation (NLG) tasks; this is often referred to as
``LLM-as-a-judge'' paradigm. However, the capabilities of LLMs in evaluating
NLG quality remain underexplored. Current studies depend on human assessments
and simple metrics that fail to capture the discernment of LLMs across diverse
NLG tasks. To address this gap, we propose the Discernment of Hierarchical
Perturbation (DHP) benchmarking framework, which provides quantitative
discernment scores for LLMs. This framework leverages hierarchically perturbed
text data and statistical tests to systematically measure the NLG evaluation
capabilities of LLMs. We re-established six evaluation datasets for this
benchmark, covering four NLG tasks: Summarization, Story Completion, Question
Answering, and Translation. Our comprehensive benchmarking of five major LLM
families provides critical insight into their strengths and limitations as NLG
evaluators. Our dataset is available at
https://huggingface.co/datasets/YCWANGVINCE/DHP_Benchmark.",2024-08-25,"Yicheng Wang, Jiayi Yuan, Yu-Neng Chuang, Zhuoer Wang, Yingchi Liu, Mark Cusick, Param Kulkarni, Zhengping Ji, Yasser Ibrahim, Xia Hu",http://arxiv.org/pdf/2408.13704v2,cs.CL
Path-Consistency: Prefix Enhancement for Efficient Inference in LLM,"To enhance the reasoning capabilities of large language models (LLMs),
self-consistency has gained significant popularity by combining multiple
sampling with majority voting. However, the state-of-the-art self-consistency
approaches consume substantial computational resources and lead to significant
additional time costs due to the multiple sampling. This prevents its full
potential from being realized in scenarios where computational resources are
critical. To improve the inference efficiency, this paper introduces
\textit{path-consistency}, a method that leverages the confidence of answers
generated in earlier branches to identify the prefix of the most promising
path. By dynamically guiding the generation of subsequent branches based on
this prefix, the \textit{path-consistency} mitigates both the errors and
redundancies from random or less useful sampling in self-consistency. As a
result, it can significantly accelerate the inference process by reducing the
number of tokens generated. Our extensive empirical evaluation shows that the
\textit{path-consistency} achieves significant acceleration in inference
latency ranging from $7.8\%$ to $40.5\%$, while maintaining or even improving
task accuracy across different datasets, including mathematical reasoning,
common sense reasoning, symbolic reasoning, and code generation.",2024-08-25,"Jiace Zhu, Yingtao Shen, Jie Zhao, An Zou",http://arxiv.org/pdf/2409.01281v2,cs.CL
A layer-wise analysis of Mandarin and English suprasegmentals in SSL speech models,"This study asks how self-supervised speech models represent suprasegmental
categories like Mandarin lexical tone, English lexical stress, and English
phrasal accents. Through a series of probing tasks, we make layer-wise
comparisons of English and Mandarin 12 layer monolingual models. Our findings
suggest that 1) English and Mandarin wav2vec 2.0 models learn contextual
representations of abstract suprasegmental categories which are strongest in
the middle third of the network. 2) Models are better at representing features
that exist in the language of their training data, and this difference is
driven by enriched context in transformer blocks, not local acoustic
representation. 3) Fine-tuned wav2vec 2.0 improves performance in later layers
compared to pre-trained models mainly for lexically contrastive features like
tone and stress, 4) HuBERT and WavLM learn similar representations to wav2vec
2.0, differing mainly in later layer performance. Our results extend previous
understanding of how models represent suprasegmentals and offer new insights
into the language-specificity and contextual nature of these representations.",2024-08-24,"Antón de la Fuente, Dan Jurafsky",http://arxiv.org/pdf/2408.13678v1,cs.CL
"Towards Human-Level Understanding of Complex Process Engineering Schematics: A Pedagogical, Introspective Multi-Agent Framework for Open-Domain Question Answering","In the chemical and process industries, Process Flow Diagrams (PFDs) and
Piping and Instrumentation Diagrams (P&IDs) are critical for design,
construction, and maintenance. Recent advancements in Generative AI, such as
Large Multimodal Models (LMMs) like GPT4 (Omni), have shown promise in
understanding and interpreting process diagrams for Visual Question Answering
(VQA). However, proprietary models pose data privacy risks, and their
computational complexity prevents knowledge editing for domain-specific
customization on consumer hardware. To overcome these challenges, we propose a
secure, on-premises enterprise solution using a hierarchical, multi-agent
Retrieval Augmented Generation (RAG) framework for open-domain question
answering (ODQA) tasks, offering enhanced data privacy, explainability, and
cost-effectiveness. Our novel multi-agent framework employs introspective and
specialized sub-agents using open-source, small-scale multimodal models with
the ReAct (Reason+Act) prompting technique for PFD and P&ID analysis,
integrating multiple information sources to provide accurate and contextually
relevant answers. Our approach, supported by iterative self-correction, aims to
deliver superior performance in ODQA tasks. We conducted rigorous experimental
studies, and the empirical results validated the proposed approach
effectiveness.",2024-08-24,"Sagar Srinivas Sakhinana, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2409.00082v1,cs.CL
Localize-and-Stitch: Efficient Model Merging via Sparse Task Arithmetic,"Model merging offers an effective strategy to combine the strengths of
multiple finetuned models into a unified model that preserves the specialized
capabilities of each. Existing methods merge models in a global manner,
performing arithmetic operations across all model parameters. However, such
global merging often leads to task interference, degrading the performance of
the merged model. In this work, we introduce Localize-and-Stitch, a novel
approach that merges models in a localized way. Our algorithm works in two
steps: i) Localization: identify tiny ($1\%$ of the total parameters) localized
regions in the finetuned models containing essential skills for the downstream
tasks, and ii) Stitching: reintegrate only these essential regions back into
the pretrained model for task synergy. We demonstrate that our approach
effectively locates sparse regions responsible for finetuned performance, and
the localized regions could be treated as compact and interpretable
representations of the finetuned models (tasks). Empirically, we evaluate our
method on various vision and language benchmarks, showing that it outperforms
existing model merging methods under different data availability scenarios.
Beyond strong empirical performance, our algorithm also facilitates model
compression and preserves pretrained knowledge, enabling flexible and continual
skill composition from multiple finetuned models with minimal storage and
computational overhead. Our code is available at
https://github.com/uiuctml/Localize-and-Stitch.",2024-08-24,"Yifei He, Yuzheng Hu, Yong Lin, Tong Zhang, Han Zhao",http://arxiv.org/pdf/2408.13656v2,cs.CL
Symbolic Working Memory Enhances Language Models for Complex Rule Application,"Large Language Models (LLMs) have shown remarkable reasoning performance but
struggle with multi-step deductive reasoning involving a series of rule
application steps, especially when rules are presented non-sequentially. Our
preliminary analysis shows that while LLMs excel in single-step rule
application, their performance drops significantly in multi-step scenarios due
to the challenge in rule grounding. It requires anchoring the applicable rule
and supporting facts at each step, amidst multiple input rules, facts, and
inferred facts. To address this, we propose augmenting LLMs with external
working memory and introduce a neurosymbolic framework for rule application.
The memory stores facts and rules in both natural language and symbolic forms,
enabling precise tracking. Utilizing this memory, our framework iteratively
performs symbolic rule grounding and LLM-based rule implementation. The former
matches predicates and variables of symbolic rules and facts to ground
applicable rules at each step. Experiments indicate our framework's
effectiveness in rule application and its robustness across various steps and
settings~\footnote{Code and data are available at
\url{https://github.com/SiyuanWangw/RuleApplication}.}.",2024-08-24,"Siyuan Wang, Zhongyu Wei, Yejin Choi, Xiang Ren",http://arxiv.org/pdf/2408.13654v1,cs.CL
Narratives at Conflict: Computational Analysis of News Framing in Multilingual Disinformation Campaigns,"Any report frames issues to favor a particular interpretation by highlighting
or excluding certain aspects of a story. Despite the widespread use of framing
in disinformation, framing properties and detection methods remain
underexplored outside the English-speaking world. We explore how multilingual
framing of the same issue differs systematically. We use eight years of
Russia-backed disinformation campaigns, spanning 8k news articles in 4
languages targeting 15 countries. We find that disinformation campaigns
consistently and intentionally favor specific framing, depending on the target
language of the audience. We further discover how Russian-language articles
consistently highlight selected frames depending on the region of the media
coverage. We find that the two most prominent models for automatic frame
analysis underperform and show high disagreement, highlighting the need for
further research.",2024-08-24,"Antonina Sinelnik, Dirk Hovy",http://arxiv.org/pdf/2408.13651v1,cs.CL
Ancient but Digitized: Developing Handwritten Optical Character Recognition for East Syriac Script Through Creating KHAMIS Dataset,"Many languages have vast amounts of handwritten texts, such as ancient
scripts about folktale stories and historical narratives or contemporary
documents and letters. Digitization of those texts has various applications,
such as daily tasks, cultural studies, and historical research. Syriac is an
ancient, endangered, and low-resourced language that has not received the
attention it requires and deserves. This paper reports on a research project
aimed at developing a optical character recognition (OCR) model based on the
handwritten Syriac texts as a starting point to build more digital services for
this endangered language. A dataset was created, KHAMIS (inspired by the East
Syriac poet, Khamis bar Qardahe), which consists of handwritten sentences in
the East Syriac script. We used it to fine-tune the Tesseract-OCR engine's
pretrained Syriac model on handwritten data. The data was collected from
volunteers capable of reading and writing in the language to create KHAMIS.
KHAMIS currently consists of 624 handwritten Syriac sentences collected from 31
university students and one professor, and it will be partially available
online and the whole dataset available in the near future for development and
research purposes. As a result, the handwritten OCR model was able to achieve a
character error rate of 1.097-1.610% and 8.963-10.490% on both training and
evaluation sets, respectively, and both a character error rate of 18.89-19.71%
and a word error rate of 62.83-65.42% when evaluated on the test set, which is
twice as better than the default Syriac model of Tesseract.",2024-08-24,"Ameer Majeed, Hossein Hassani",http://arxiv.org/pdf/2408.13631v1,cs.CL
No Dataset Needed for Downstream Knowledge Benchmarking: Response Dispersion Inversely Correlates with Accuracy on Domain-specific QA,"This research seeks to obviate the need for creating QA datasets and grading
(chatbot) LLM responses when comparing LLMs' knowledge in specific topic
domains. This is done in an entirely end-user centric way without need for
access to any inner workings of the LLM, so long as it can be prompted and
given a random seed to create different generations to the same prompt. The
paper does this by, for a given topic domain, defining the ""response
dispersion"" of an LLM by repeatedly asking an LLM the same opinion question
about that topic domain. Namely, the response dispersion is the count of
singular values needed to explain 95% of the variance in the embedding matrix
of the LLM's responses. It is found that the response dispersion is inversely
correlated with accuracy on relevant QA evaluations (average spearman rank
correlation stronger than -.59). A use-case analysis shows that when comparing
two different LLMs on the same topic domain, comparing their response
dispersion is a suitable replacement for comparing their QA accuracy between
74% and 89% of the time, the range depending on certain reasonable
accuracy-difference tolerances that may be acceptable to an end-user in
exchange for the labor being saved using response dispersion instead of QA
accuracy for comparison. Two response embeddings are studied for creating the
embedding matrix in this study, one is from OpenAI's APIs and one is a novel
embedding, here named reference sentence similarity embeddings, that can be
computed locally and performs very nearly as well in calculating response
dispersion. Also in this research, a pre-existing dataset called the IRC-Wiki
Trivia dataset, originally developed for trivia games, has been re-purposed,
curated, and the curation, called IRC-WikiTriviaQA, is made available for the
purpose of this research.",2024-08-24,Robert L Simione II,http://arxiv.org/pdf/2408.13624v1,cs.CL
Preliminary Investigations of a Multi-Faceted Robust and Synergistic Approach in Semiconductor Electron Micrograph Analysis: Integrating Vision Transformers with Large Language and Multimodal Models,"Characterizing materials using electron micrographs is crucial in areas such
as semiconductors and quantum materials. Traditional classification methods
falter due to the intricatestructures of these micrographs. This study
introduces an innovative architecture that leverages the generative
capabilities of zero-shot prompting in Large Language Models (LLMs) such as
GPT-4(language only), the predictive ability of few-shot (in-context) learning
in Large Multimodal Models (LMMs) such as GPT-4(V)ision, and fuses knowledge
across image based and linguistic insights for accurate nanomaterial category
prediction. This comprehensive approach aims to provide a robust solution for
the automated nanomaterial identification task in semiconductor manufacturing,
blending performance, efficiency, and interpretability. Our method surpasses
conventional approaches, offering precise nanomaterial identification and
facilitating high-throughput screening.",2024-08-24,"Sakhinana Sagar Srinivas, Geethan Sannidhi, Sreeja Gangasani, Chidaksh Ravuru, Venkataramana Runkana",http://arxiv.org/pdf/2408.13621v1,cs.CL
GNN: Graph Neural Network and Large Language Model for Data Discovery,"Our algorithm GNN: Graph Neural Network and Large Language Model for Data
Discovery inherit the benefits of \cite{hoang2024plod} (PLOD: Predictive
Learning Optimal Data Discovery), \cite{Hoang2024BODBO} (BOD: Blindly Optimal
Data Discovery) in terms of overcoming the challenges of having to predefine
utility function and the human input for attribute ranking, which helps prevent
the time-consuming loop process. In addition to these previous works, our
algorithm GNN leverages the advantages of graph neural networks and large
language models to understand text type values that cannot be understood by
PLOD and MOD, thus making the task of predicting outcomes more reliable. GNN
could be seen as an extension of PLOD in terms of understanding the text type
value and the user's preferences, not only numerical values but also text
values, making the promise of data science and analytics purposes.",2024-08-24,Thomas Hoang,http://arxiv.org/pdf/2408.13609v2,cs.CL
SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description,"Speech-language multi-modal learning presents a significant challenge due to
the fine nuanced information inherent in speech styles. Therefore, a
large-scale dataset providing elaborate comprehension of speech style is
urgently needed to facilitate insightful interplay between speech audio and
natural language. However, constructing such datasets presents a major
trade-off between large-scale data collection and high-quality annotation. To
tackle this challenge, we propose an automatic speech annotation system for
expressiveness interpretation that annotates in-the-wild speech clips with
expressive and vivid human language descriptions. Initially, speech audios are
processed by a series of expert classifiers and captioning models to capture
diverse speech characteristics, followed by a fine-tuned LLaMA for customized
annotation generation. Unlike previous tag/templet-based annotation frameworks
with limited information and diversity, our system provides in-depth
understandings of speech style through tailored natural language descriptions,
thereby enabling accurate and voluminous data generation for large model
training. With this system, we create SpeechCraft, a fine-grained bilingual
expressive speech dataset. It is distinguished by highly descriptive natural
language style prompts, containing approximately 2,000 hours of audio data and
encompassing over two million speech clips. Extensive experiments demonstrate
that the proposed dataset significantly boosts speech-language task performance
in stylist speech synthesis and speech style understanding.",2024-08-24,"Zeyu Jin, Jia Jia, Qixin Wang, Kehan Li, Shuoyi Zhou, Songtao Zhou, Xiaoyu Qin, Zhiyong Wu",http://arxiv.org/pdf/2408.13608v1,cs.CL
Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation,"Sampling-based decoding strategies have been widely adopted for Large
Language Models (LLMs) in numerous applications, targeting a balance between
diversity and quality via temperature tuning and tail truncation. Considering
the strong dependency of the candidate next tokens on different prefixes,
recent studies propose to adaptively truncate the tail of LLMs' predicted
distribution. Although improved results have been reported with these methods
on open-ended text generation tasks, the results are highly dependent on the
curated parameters and the limited exemplar text. In this paper, we propose a
systematic way to estimate the capacity of a truncation sampling method by
considering the trade-off between diversity and risk at each decoding step,
based on our collected prefix tree which preserves the context of a full
sentence. Our work offers a comprehensive comparison of existing truncation
sampling methods and serves as a practical user guideline for their parameter
selection.",2024-08-24,"Yuxuan Zhou, Margret Keuper, Mario Fritz",http://arxiv.org/pdf/2408.13586v2,cs.CL
FLEURS-ASL: Including American Sign Language in Massively Multilingual Multitask Evaluation,"Sign language translation has historically been peripheral to mainstream
machine translation research. In order to help converge the fields, we
introduce FLEURS-ASL, an extension of the multiway parallel benchmarks FLORES
(for text) and FLEURS (for speech) to support their first sign language (as
video), American Sign Language, translated by 5 Certified Deaf Interpreters.
FLEURS-ASL can be used to evaluate a variety of tasks -- primarily sentence-
and discourse-level translation -- between ASL and 200 other languages as text,
or 102 languages as speech. We provide baselines for tasks from ASL to English
text using a unified modeling approach that incorporates timestamp tokens and
previous text tokens in a 34-second context window, trained on random video
clips from YouTube-ASL. This model meets or exceeds the performance of
phrase-level baselines while supporting a multitude of new tasks. We also use
FLEURS-ASL to show that multimodal frontier models have virtually no
understanding of ASL, underscoring the importance of including sign languages
in standard evaluation suites.",2024-08-24,Garrett Tanzer,http://arxiv.org/pdf/2408.13585v1,cs.CL
IQA-EVAL: Automatic Evaluation of Human-Model Interactive Question Answering,"To evaluate Large Language Models (LLMs) for question answering (QA),
traditional methods typically focus on assessing single-turn responses to given
questions. However, this approach doesn't capture the dynamic nature of
human-AI interactions, where humans actively seek information through
conversation. Recent works in human-computer interaction (HCI) have employed
human evaluators to conduct interactions and evaluations, but they are often
prohibitively expensive and time-consuming to scale. We introduce an automatic
evaluation framework IQA-EVAL to achieve Interactive Question Answering
Evaluations, more specifically, we introduce a LLM-based Evaluation Agent (LEA)
that can: (1) simulate human behaviors to generate interactions with IQA
models; (2) automatically evaluate the generated interactions. Moreover, we
propose assigning personas to LEAs to better simulate groups of real human
evaluators. We show that: (1) our evaluation framework with GPT-4 (or Claude)
as the backbone model achieves a high correlation with human evaluations on the
IQA task; (2) assigning personas to LEA to better represent the crowd further
significantly improves correlations. Finally, we use our automatic metric to
evaluate five recent representative LLMs with over 1000 questions from complex
and ambiguous question answering tasks, which comes with a substantial cost of
$5k if evaluated by humans.",2024-08-24,"Ruosen Li, Ruochen Li, Barry Wang, Xinya Du",http://arxiv.org/pdf/2408.13545v2,cs.CL
Are LLM-based methods good enough for detecting unfair terms of service?,"Countless terms of service (ToS) are being signed everyday by users all over
the world while interacting with all kinds of apps and websites. More often
than not, these online contracts spanning double-digit pages are signed blindly
by users who simply want immediate access to the desired service. What would
normally require a consultation with a legal team, has now become a mundane
activity consisting of a few clicks where users potentially sign away their
rights, for instance in terms of their data privacy, to countless online
entities/companies. Large language models (LLMs) are good at parsing long
text-based documents, and could potentially be adopted to help users when
dealing with dubious clauses in ToS and their underlying privacy policies. To
investigate the utility of existing models for this task, we first build a
dataset consisting of 12 questions applied individually to a set of privacy
policies crawled from popular websites. Thereafter, a series of open-source as
well as commercial chatbots such as ChatGPT, are queried over each question,
with the answers being compared to a given ground truth. Our results show that
some open-source models are able to provide a higher accuracy compared to some
commercial models. However, the best performance is recorded from a commercial
chatbot (ChatGPT4). Overall, all models perform only slightly better than
random at this task. Consequently, their performance needs to be significantly
improved before they can be adopted at large for this purpose.",2024-08-24,"Mirgita Frasheri, Arian Bakhtiarnia, Lukas Esterle, Alexandros Iosifidis",http://arxiv.org/pdf/2409.00077v2,cs.CL
Cultural Adaptation of Menus: A Fine-Grained Approach,"Machine Translation of Culture-Specific Items (CSIs) poses significant
challenges. Recent work on CSI translation has shown some success using Large
Language Models (LLMs) to adapt to different languages and cultures; however, a
deeper analysis is needed to examine the benefits and pitfalls of each method.
In this paper, we introduce the ChineseMenuCSI dataset, the largest for
Chinese-English menu corpora, annotated with CSI vs Non-CSI labels and a
fine-grained test set. We define three levels of CSI figurativeness for a more
nuanced analysis and develop a novel methodology for automatic CSI
identification, which outperforms GPT-based prompts in most categories.
Importantly, we are the first to integrate human translation theories into
LLM-driven translation processes, significantly improving translation accuracy,
with COMET scores increasing by up to 7 points.",2024-08-24,"Zhonghe Zhang, Xiaoyu He, Vivek Iyer, Alexandra Birch",http://arxiv.org/pdf/2408.13534v1,cs.CL
Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models,"Retrieval-Augmented Generation (RAG) has emerged as a crucial method for
addressing hallucinations in large language models (LLMs). While recent
research has extended RAG models to complex noisy scenarios, these explorations
often confine themselves to limited noise types and presuppose that noise is
inherently detrimental to LLMs, potentially deviating from real-world retrieval
environments and restricting practical applicability. In this paper, we define
seven distinct noise types from a linguistic perspective and establish a Noise
RAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing
multiple datasets and reasoning tasks. Through empirical evaluation of eight
representative LLMs with diverse architectures and scales, we reveal that these
noises can be further categorized into two practical groups: noise that is
beneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs
(aka harmful noise). While harmful noise generally impairs performance,
beneficial noise may enhance several aspects of model capabilities and overall
performance. Our analysis offers insights for developing more robust, adaptable
RAG solutions and mitigating hallucinations across diverse retrieval scenarios.",2024-08-24,"Jinyang Wu, Feihu Che, Chuyuan Zhang, Jianhua Tao, Shuai Zhang, Pengpeng Shao",http://arxiv.org/pdf/2408.13533v1,cs.CL
HRGraph: Leveraging LLMs for HR Data Knowledge Graphs with Information Propagation-based Job Recommendation,"Knowledge Graphs (KGs) serving as semantic networks, prove highly effective
in managing complex interconnected data in different domains, by offering a
unified, contextualized, and structured representation with flexibility that
allows for easy adaptation to evolving knowledge. Processing complex Human
Resources (HR) data, KGs can help in different HR functions like recruitment,
job matching, identifying learning gaps, and enhancing employee retention.
Despite their potential, limited efforts have been made to implement practical
HR knowledge graphs. This study addresses this gap by presenting a framework
for effectively developing HR knowledge graphs from documents using Large
Language Models. The resulting KG can be used for a variety of downstream
tasks, including job matching, identifying employee skill gaps, and many more.
In this work, we showcase instances where HR KGs prove instrumental in precise
job matching, yielding advantages for both employers and employees. Empirical
evidence from experiments with information propagation in KGs and Graph Neural
Nets, along with case studies underscores the effectiveness of KGs in tasks
such as job and employee recommendations and job area classification. Code and
data are available at : https://github.com/azminewasi/HRGraph",2024-08-24,Azmine Toushik Wasi,http://arxiv.org/pdf/2408.13521v1,cs.CL
Selective Preference Optimization via Token-Level Reward Function Estimation,"Recent advancements in large language model alignment leverage token-level
supervisions to perform fine-grained preference optimization. However, existing
token-level alignment methods either optimize on all available tokens, which
can be noisy and inefficient, or perform selective training with complex and
expensive key token selection strategies. In this work, we propose Selective
Preference Optimization (SePO), a novel selective alignment strategy that
centers on efficient key token selection. SePO proposes the first token
selection method based on Direct Preference Optimization (DPO), which trains an
oracle model to estimate a token-level reward function on the target data. This
method applies to any existing alignment datasets with response-level
annotations and enables cost-efficient token selection with small-scale oracle
models and training data. The estimated reward function is then utilized to
score all tokens within the target dataset, where only the key tokens are
selected to supervise the target policy model with a reference model-free
contrastive objective function. Extensive experiments on three public
evaluation benchmarks show that SePO significantly outperforms competitive
baseline methods by only optimizing 30% key tokens on the target dataset. SePO
applications on weak-to-strong generalization show that weak oracle models
effectively supervise strong policy models with up to 16.8x more parameters.
SePO also effectively selects key tokens from out-of-distribution data to
enhance strong policy models and alleviate the over-optimization problem.",2024-08-24,"Kailai Yang, Zhiwei Liu, Qianqian Xie, Jimin Huang, Erxue Min, Sophia Ananiadou",http://arxiv.org/pdf/2408.13518v1,cs.CL
Language Model Empowered Spatio-Temporal Forecasting via Physics-Aware Reprogramming,"Spatio-temporal forecasting is pivotal in numerous real-world applications,
including transportation planning, energy management, and climate monitoring.
In this work, we aim to harness the reasoning and generalization abilities of
Pre-trained Language Models (PLMs) for more effective spatio-temporal
forecasting, particularly in data-scarce scenarios. However, recent studies
uncover that PLMs, which are primarily trained on textual data, often falter
when tasked with modeling the intricate correlations in numerical time series,
thereby limiting their effectiveness in comprehending spatio-temporal data. To
bridge the gap, we propose RePST, a physics-aware PLM reprogramming framework
tailored for spatio-temporal forecasting. Specifically, we first propose a
physics-aware decomposer that adaptively disentangles spatially correlated time
series into interpretable sub-components, which facilitates PLM to understand
sophisticated spatio-temporal dynamics via a divide-and-conquer strategy.
Moreover, we propose a selective discrete reprogramming scheme, which
introduces an expanded spatio-temporal vocabulary space to project
spatio-temporal series into discrete representations. This scheme minimizes the
information loss during reprogramming and enriches the representations derived
by PLMs. Extensive experiments on real-world datasets show that the proposed
RePST outperforms twelve state-of-the-art baseline methods, particularly in
data-scarce scenarios, highlighting the effectiveness and superior
generalization capabilities of PLMs for spatio-temporal forecasting.",2024-08-24,"Hao Wang, Jindong Han, Wei Fan, Hao Liu",http://arxiv.org/pdf/2408.14505v2,cs.CL
Utilizing Large Language Models for Named Entity Recognition in Traditional Chinese Medicine against COVID-19 Literature: Comparative Study,"Objective: To explore and compare the performance of ChatGPT and other
state-of-the-art LLMs on domain-specific NER tasks covering different entity
types and domains in TCM against COVID-19 literature. Methods: We established a
dataset of 389 articles on TCM against COVID-19, and manually annotated 48 of
them with 6 types of entities belonging to 3 domains as the ground truth,
against which the NER performance of LLMs can be assessed. We then performed
NER tasks for the 6 entity types using ChatGPT (GPT-3.5 and GPT-4) and 4
state-of-the-art BERT-based question-answering (QA) models (RoBERTa, MiniLM,
PubMedBERT and SciBERT) without prior training on the specific task. A domain
fine-tuned model (GSAP-NER) was also applied for a comprehensive comparison.
Results: The overall performance of LLMs varied significantly in exact match
and fuzzy match. In the fuzzy match, ChatGPT surpassed BERT-based QA models in
5 out of 6 tasks, while in exact match, BERT-based QA models outperformed
ChatGPT in 5 out of 6 tasks but with a smaller F-1 difference. GPT-4 showed a
significant advantage over other models in fuzzy match, especially on the
entity type of TCM formula and the Chinese patent drug (TFD) and ingredient
(IG). Although GPT-4 outperformed BERT-based models on entity type of herb,
target, and research method, none of the F-1 scores exceeded 0.5. GSAP-NER,
outperformed GPT-4 in terms of F-1 by a slight margin on RM. ChatGPT achieved
considerably higher recalls than precisions, particularly in the fuzzy match.
Conclusions: The NER performance of LLMs is highly dependent on the entity
type, and their performance varies across application scenarios. ChatGPT could
be a good choice for scenarios where high recall is favored. However, for
knowledge acquisition in rigorous scenarios, neither ChatGPT nor BERT-based QA
models are off-the-shelf tools for professional practitioners.",2024-08-24,"Xu Tong, Nina Smirnova, Sharmila Upadhyaya, Ran Yu, Jack H. Culbert, Chao Sun, Wolfgang Otto, Philipp Mayr",http://arxiv.org/pdf/2408.13501v1,cs.CL
Why Antiwork: A RoBERTa-Based System for Work-Related Stress Identification and Leading Factor Analysis,"Harsh working environments and work-related stress have been known to
contribute to mental health problems such as anxiety, depression, and suicidal
ideation. As such, it is paramount to create solutions that can both detect
employee unhappiness and find the root cause of the problem. While prior works
have examined causes of mental health using machine learning, they typically
focus on general mental health analysis, with few of them focusing on
explainable solutions or looking at the workplace-specific setting. r/antiwork
is a subreddit for the antiwork movement, which is the desire to stop working
altogether. Using this subreddit as a proxy for work environment
dissatisfaction, we create a new dataset for antiwork sentiment detection and
subsequently train a model that highlights the words with antiwork sentiments.
Following this, we performed a qualitative and quantitative analysis to uncover
some of the key insights into the mindset of individuals who identify with the
antiwork movement and how their working environments influenced them. We find
that working environments that do not give employees authority or
responsibility, frustrating recruiting experiences, and unfair compensation,
are some of the leading causes of the antiwork sentiment, resulting in a lack
of self-confidence and motivation among their employees.",2024-08-24,"Tao Lu, Muzhe Wu, Xinyi Lu, Siyuan Xu, Shuyu Zhan, Anuj Tambwekar, Emily Mower Provost",http://arxiv.org/pdf/2408.13473v1,cs.CL
Uncovering Biases with Reflective Large Language Models,"Biases and errors in human-labeled data present significant challenges for
machine learning, especially in supervised learning reliant on potentially
flawed ground truth data. These flaws, including diagnostic errors and societal
biases, risk being propagated and amplified through models trained using
maximum likelihood estimation. We present the Reflective LLM Dialogue Framework
RLDF, which leverages structured adversarial dialogues between multiple
instances of a single LLM or different LLMs to uncover diverse perspectives and
correct inconsistencies. By conditioning LLMs to adopt opposing stances, RLDF
enables systematic bias detection through conditional statistics, information
theory, and divergence metrics. Experiments show RLDF successfully identifies
potential biases in public content while exposing limitations in human-labeled
data. Our framework supports measurable progress tracking and explainable
remediation actions, offering a scalable approach for improving content
neutrality through transparent, multi-perspective analysis.",2024-08-24,Edward Y. Chang,http://arxiv.org/pdf/2408.13464v2,cs.CL
Make Every Penny Count: Difficulty-Adaptive Self-Consistency for Cost-Efficient Reasoning,"Self-consistency (SC), a widely used decoding strategy for chain-of-thought
reasoning, shows significant gains across various multi-step reasoning tasks
but comes with a high cost due to multiple sampling with the preset size. Its
variants, Adaptive self-consistency (ASC) and Early-stopping self-consistency
(ESC), dynamically adjust the number of samples based on the posterior
distribution of a set of pre-samples, reducing the cost of SC with minimal
impact on performance. Both methods, however, do not exploit the prior
information about question difficulty. It often results in unnecessary repeated
sampling for easy questions that could be accurately answered with just one
attempt, wasting resources. To tackle this problem, we propose
Difficulty-Adaptive Self-Consistency (DSC), which leverages the difficulty
information of batch queries from both prior and posterior perspectives to
adaptively allocate inference resources, further reducing the overall cost of
SC. To demonstrate the effectiveness of DSC, we conduct extensive experiments
on three popular categories of reasoning tasks: arithmetic, commonsense and
symbolic reasoning on six benchmarks. The empirical results show that DSC
consistently surpasses the strong baseline ASC and ESC in terms of costs by a
significant margin, while attaining comparable performances.",2024-08-24,"Xinglin Wang, Shaoxiong Feng, Yiwei Li, Peiwen Yuan, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li",http://arxiv.org/pdf/2408.13457v3,cs.CL
A Law of Next-Token Prediction in Large Language Models,"Large language models (LLMs) have been widely employed across various
application domains, yet their black-box nature poses significant challenges to
understanding how these models process input data internally to make
predictions. In this paper, we introduce a precise and quantitative law that
governs the learning of contextualized token embeddings through intermediate
layers in pre-trained LLMs for next-token prediction. Our findings reveal that
each layer contributes equally to enhancing prediction accuracy, from the
lowest to the highest layer -- a universal phenomenon observed across a diverse
array of open-source LLMs, built on architectures such as Transformer, RWKV,
and Mamba. We demonstrate that this law offers new perspectives and insights to
inform and guide practices in LLM development and applications, including model
scaling, pre-training tasks, and information flow. Overall, our law enables
more fine-grained approaches to the design, training, and interpretation of
LLMs through scrutinizing their internal data processing mechanisms.",2024-08-24,"Hangfeng He, Weijie J. Su",http://arxiv.org/pdf/2408.13442v1,cs.CL
Knowledge-Aware Conversation Derailment Forecasting Using Graph Convolutional Networks,"Online conversations are particularly susceptible to derailment, which can
manifest itself in the form of toxic communication patterns including
disrespectful comments and abuse. Forecasting conversation derailment predicts
signs of derailment in advance enabling proactive moderation of conversations.
State-of-the-art approaches to conversation derailment forecasting sequentially
encode conversations and use graph neural networks to model dialogue user
dynamics. However, existing graph models are not able to capture complex
conversational characteristics such as context propagation and emotional
shifts. The use of common sense knowledge enables a model to capture such
characteristics, thus improving performance. Following this approach, here we
derive commonsense statements from a knowledge base of dialogue contextual
information to enrich a graph neural network classification architecture. We
fuse the multi-source information on utterance into capsules, which are used by
a transformer-based forecaster to predict conversation derailment. Our model
captures conversation dynamics and context propagation, outperforming the
state-of-the-art models on the CGA and CMV benchmark datasets",2024-08-24,"Enas Altarawneh, Ameeta Agrawal, Michael Jenkin, Manos Papagelis",http://arxiv.org/pdf/2408.13440v2,cs.CL
Integrating Multi-Head Convolutional Encoders with Cross-Attention for Improved SPARQL Query Translation,"The main task of the KGQA system (Knowledge Graph Question Answering) is to
convert user input questions into query syntax (such as SPARQL). With the rise
of modern popular encoders and decoders like Transformer and ConvS2S, many
scholars have shifted the research direction of SPARQL generation to the Neural
Machine Translation (NMT) architecture or the generative AI field of
Text-to-SPARQL. In NMT-based QA systems, the system treats knowledge base query
syntax as a language. It uses NMT-based translation models to translate natural
language questions into query syntax. Scholars use popular architectures
equipped with cross-attention, such as Transformer, ConvS2S, and BiLSTM, to
train translation models for query syntax. To achieve better query results,
this paper improved the ConvS2S encoder and added multi-head attention from the
Transformer, proposing a Multi-Head Conv encoder (MHC encoder) based on the
n-gram language model. The principle is to use convolutional layers to capture
local hidden features in the input sequence with different receptive fields,
using multi-head attention to calculate dependencies between them. Ultimately,
we found that the translation model based on the Multi-Head Conv encoder
achieved better performance than other encoders, obtaining 76.52\% and 83.37\%
BLEU-1 (BiLingual Evaluation Understudy) on the QALD-9 and LC-QuAD-1.0
datasets, respectively. Additionally, in the end-to-end system experiments on
the QALD-9 and LC-QuAD-1.0 datasets, we achieved leading results over other
KGQA systems, with Macro F1-measures reaching 52\% and 66\%, respectively.
Moreover, the experimental results show that with limited computational
resources, if one possesses an excellent encoder-decoder architecture and
cross-attention, experts and scholars can achieve outstanding performance
equivalent to large pre-trained models using only general embeddings.",2024-08-24,"Yi-Hui Chen, Eric Jui-Lin Lu, Kwan-Ho Cheng",http://arxiv.org/pdf/2408.13432v1,cs.CL
Generative-Adversarial Networks for Low-Resource Language Data Augmentation in Machine Translation,"Neural Machine Translation (NMT) systems struggle when translating to and
from low-resource languages, which lack large-scale data corpora for models to
use for training. As manual data curation is expensive and time-consuming, we
propose utilizing a generative-adversarial network (GAN) to augment
low-resource language data. When training on a very small amount of language
data (under 20,000 sentences) in a simulated low-resource setting, our model
shows potential at data augmentation, generating monolingual language data with
sentences such as ""ask me that healthy lunch im cooking up,"" and ""my
grandfather work harder than your grandfather before."" Our novel data
augmentation approach takes the first step in investigating the capability of
GANs in low-resource NMT, and our results suggest that there is promise for
future extension of GANs to low-resource NMT.",2024-08-24,Linda Zeng,http://arxiv.org/pdf/2409.00071v1,cs.CL
DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction,"Advancements in large language models (LLMs) allow them to address diverse
questions using human-like interfaces. Still, limitations in their training
prevent them from answering accurately in scenarios that could benefit from
multiple perspectives. Multi-agent systems allow the resolution of questions to
enhance result consistency and reliability. While drug-target interaction (DTI)
prediction is important for drug discovery, existing approaches face challenges
due to complex biological systems and the lack of interpretability needed for
clinical applications. DrugAgent is a multi-agent LLM system for DTI prediction
that combines multiple specialized perspectives with transparent reasoning. Our
system adapts and extends existing multi-agent frameworks by (1) applying
coordinator-based architecture to the DTI domain, (2) integrating
domain-specific data sources, including ML predictions, knowledge graphs, and
literature evidence, and (3) incorporating Chain-of-Thought (CoT) and ReAct
(Reason+Act) frameworks for transparent DTI reasoning. We conducted
comprehensive experiments using a kinase inhibitor dataset, where our
multi-agent LLM method outperformed the non-reasoning multi-agent model (GPT-4o
mini) by 45% in F1 score (0.514 vs 0.355). Through ablation studies, we
demonstrated the contributions of each agent, with the AI agent being the most
impactful, followed by the KG agent and search agent. Most importantly, our
approach provides detailed, human-interpretable reasoning for each prediction
by combining evidence from multiple sources - a critical feature for biomedical
applications where understanding the rationale behind predictions is essential
for clinical decision-making and regulatory compliance. Code is available at
https://anonymous.4open.science/r/DrugAgent-B2EA.",2024-08-23,"Yoshitaka Inoue, Tianci Song, Xinling Wang, Augustin Luna, Tianfan Fu",http://arxiv.org/pdf/2408.13378v4,cs.CL
Learning to Plan Long-Term for Language Modeling,"Modern language models predict the next token in the sequence by considering
the past text through a powerful function such as attention. However, language
models have no explicit mechanism that allows them to spend computation time
for planning long-distance future text, leading to a suboptimal token
prediction. In this paper, we propose a planner that predicts a latent plan for
many sentences into the future. By sampling multiple plans at once, we
condition the language model on an accurate approximation of the distribution
of text continuations, which leads to better next token prediction accuracy. In
effect, this allows trading computation time for prediction accuracy.",2024-08-23,"Florian Mai, Nathan Cornille, Marie-Francine Moens",http://arxiv.org/pdf/2409.00070v1,cs.CL
CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers,"This paper presents CodeRefine, a novel framework for automatically
transforming research paper methodologies into functional code using Large
Language Models (LLMs). Our multi-step approach first extracts and summarizes
key text chunks from papers, analyzes their code relevance, and creates a
knowledge graph using a predefined ontology. Code is then generated from this
structured representation and enhanced through a proposed retrospective
retrieval-augmented generation approach. CodeRefine addresses the challenge of
bridging theoretical research and practical implementation, offering a more
accurate alternative to LLM zero-shot prompting. Evaluations on diverse
scientific papers demonstrate CodeRefine's ability to improve code
implementation from the paper, potentially accelerating the adoption of
cutting-edge algorithms in real-world applications.",2024-08-23,"Ekaterina Trofimova, Emil Sataev, Abhijit Singh Jowhari",http://arxiv.org/pdf/2408.13366v1,cs.CL
Power Scheduler: A Batch Size and Token Number Agnostic Learning Rate Scheduler,"Finding the optimal learning rate for language model pretraining is a
challenging task. This is not only because there is a complicated correlation
between learning rate, batch size, number of training tokens, model size, and
other hyperparameters but also because it is prohibitively expensive to perform
a hyperparameter search for large language models with Billions or Trillions of
parameters. Recent studies propose using small proxy models and small corpus to
perform hyperparameter searches and transposing the optimal parameters to large
models and large corpus. While the zero-shot transferability is theoretically
and empirically proven for model size related hyperparameters, like depth and
width, the zero-shot transfer from small corpus to large corpus is
underexplored. In this paper, we study the correlation between optimal learning
rate, batch size, and number of training tokens for the recently proposed WSD
scheduler. After thousands of small experiments, we found a power-law
relationship between variables and demonstrated its transferability across
model sizes. Based on the observation, we propose a new learning rate
scheduler, Power scheduler, that is agnostic about the number of training
tokens and batch size. The experiment shows that combining the Power scheduler
with Maximum Update Parameterization (muP) can consistently achieve impressive
performance with one set of hyperparameters regardless of the number of
training tokens, batch size, model size, and even model architecture. Our 3B
dense and MoE models trained with the Power scheduler achieve comparable
performance as state-of-the-art small language models. We open-source these
pretrained models at https://ibm.biz/BdKhLa.",2024-08-23,"Yikang Shen, Matthew Stallone, Mayank Mishra, Gaoyuan Zhang, Shawn Tan, Aditya Prasad, Adriana Meza Soria, David D. Cox, Rameswar Panda",http://arxiv.org/pdf/2408.13359v2,cs.CL
LalaEval: A Holistic Human Evaluation Framework for Domain-Specific Large Language Models,"This paper introduces LalaEval, a holistic framework designed for the human
evaluation of domain-specific large language models (LLMs). LalaEval proposes a
comprehensive suite of end-to-end protocols that cover five main components
including domain specification, criteria establishment, benchmark dataset
creation, construction of evaluation rubrics, and thorough analysis and
interpretation of evaluation outcomes. This initiative aims to fill a crucial
research gap by providing a systematic methodology for conducting standardized
human evaluations within specific domains, a practice that, despite its
widespread application, lacks substantial coverage in the literature and human
evaluation are often criticized to be less reliable due to subjective factors,
so standardized procedures adapted to the nuanced requirements of specific
domains or even individual organizations are in great need. Furthermore, the
paper demonstrates the framework's application within the logistics industry,
presenting domain-specific evaluation benchmarks, datasets, and a comparative
analysis of LLMs for the logistics domain use, highlighting the framework's
capacity to elucidate performance differences and guide model selection and
development for domain-specific LLMs. Through real-world deployment, the paper
underscores the framework's effectiveness in advancing the field of
domain-specific LLM evaluation, thereby contributing significantly to the
ongoing discussion on LLMs' practical utility and performance in
domain-specific applications.",2024-08-23,"Chongyan Sun, Ken Lin, Shiwei Wang, Hulong Wu, Chengfei Fu, Zhen Wang",http://arxiv.org/pdf/2408.13338v1,cs.CL
Domain-specific long text classification from sparse relevant information,"Large Language Models have undoubtedly revolutionized the Natural Language
Processing field, the current trend being to promote one-model-for-all tasks
(sentiment analysis, translation, etc.). However, the statistical mechanisms at
work in the larger language models struggle to exploit the relevant information
when it is very sparse, when it is a weak signal. This is the case, for
example, for the classification of long domain-specific documents, when the
relevance relies on a single relevant word or on very few relevant words from
technical jargon. In the medical domain, it is essential to determine whether a
given report contains critical information about a patient's condition. This
critical information is often based on one or few specific isolated terms. In
this paper, we propose a hierarchical model which exploits a short list of
potential target terms to retrieve candidate sentences and represent them into
the contextualized embedding of the target term(s) they contain. A pooling of
the term(s) embedding(s) entails the document representation to be classified.
We evaluate our model on one public medical document benchmark in English and
on one private French medical dataset. We show that our narrower hierarchical
model is better than larger language models for retrieving relevant long
documents in a domain-specific context.",2024-08-23,"Célia D'Cruz, Jean-Marc Bereder, Frédéric Precioso, Michel Riveill",http://arxiv.org/pdf/2408.13253v1,cs.CL
An In-Depth Investigation of Data Collection in LLM App Ecosystems,"LLM app (tool) ecosystems are rapidly evolving to support sophisticated use
cases that often require extensive user data collection. Given that LLM apps
are developed by third parties and anecdotal evidence indicating inconsistent
enforcement of policies by LLM platforms, sharing user data with these apps
presents significant privacy risks. In this paper, we aim to bring transparency
in data practices of LLM app ecosystems. We examine OpenAI's GPT app ecosystem
as a case study. We propose an LLM-based framework to analyze the natural
language specifications of GPT Actions (custom tools) and assess their data
collection practices. Our analysis reveals that Actions collect excessive data
across 24 categories and 145 data types, with third-party Actions collecting
6.03% more data on average. We find that several Actions violate OpenAI's
policies by collecting sensitive information, such as passwords, which is
explicitly prohibited by OpenAI. Lastly, we develop an LLM-based privacy policy
analysis framework to automatically check the consistency of data collection by
Actions with disclosures in their privacy policies. Our measurements indicate
that the disclosures for most of the collected data types are omitted, with
only 5.8% of Actions clearly disclosing their data collection practices.",2024-08-23,"Yuhao Wu, Evin Jaff, Ke Yang, Ning Zhang, Umar Iqbal",http://arxiv.org/pdf/2408.13247v2,cs.CL
Which Prosodic Features Matter Most for Pragmatics?,"We investigate which prosodic features matter most in conveying prosodic
functions. We use the problem of predicting human perceptions of pragmatic
similarity among utterance pairs to evaluate the utility of prosodic features
of different types. We find, for example, that duration-related features are
more important than pitch-related features, and that utterance-initial features
are more important than utterance-final features. Further, failure analysis
indicates that modeling using pitch features only often fails to handle
important pragmatic functions, and suggests that several generally-neglected
acoustic and prosodic features are pragmatically significant, including
nasality and vibrato. These findings can guide future basic research in
prosody, and suggest how to improve speech synthesis evaluation, among other
applications.",2024-08-23,"Nigel G. Ward, Divette Marco, Olac Fuentes",http://arxiv.org/pdf/2408.13240v1,cs.CL
Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time,"The computational complexity of the self-attention mechanism in popular
transformer architectures poses significant challenges for training and
inference, and becomes the bottleneck for long inputs. Is it possible to
significantly reduce the quadratic time complexity of computing the gradients
in multi-layer transformer models? This paper proves that a novel fast
approximation method can calculate the gradients in almost linear time
$n^{1+o(1)}$ where $n$ is the input sequence length, while it maintains a
polynomially small approximation error $1 / \mathrm{poly}(n)$ across the entire
model. Our theory holds for general loss functions and when the multi-layer
transformer model contains many practical sub-modules, such as residual
connection, casual mask, and multi-head attention. By improving the efficiency
of gradient computation, we hope that this work will facilitate more effective
training and deployment of long-context language models based on our
theoretical results.",2024-08-23,"Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Yufa Zhou",http://arxiv.org/pdf/2408.13233v2,cs.CL
Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition,"In recent years, multi-task prompt tuning has garnered considerable attention
for its inherent modularity and potential to enhance parameter-efficient
transfer learning across diverse tasks. This paper aims to analyze and improve
the performance of multiple tasks by facilitating the transfer of knowledge
between their corresponding prompts in a multi-task setting. Our proposed
approach decomposes the prompt for each target task into a combination of
shared prompts (source prompts) and a task-specific prompt (private prompt).
During training, the source prompts undergo fine-tuning and are integrated with
the private prompt to drive the target prompt for each task. We present and
compare multiple methods for combining source prompts to construct the target
prompt, analyzing the roles of both source and private prompts within each
method. We investigate their contributions to task performance and offer
flexible, adjustable configurations based on these insights to optimize
performance. Our empirical findings clearly showcase improvements in accuracy
and robustness compared to the conventional practice of prompt tuning and
related works. Notably, our results substantially outperform other methods in
the field in few-shot settings, demonstrating superior performance in various
tasks across GLUE benchmark, among other tasks. This achievement is attained
with a significantly reduced amount of training data, making our method a
promising one for few-shot settings.",2024-08-23,"Ahmad Pouramini, Hesham Faili",http://arxiv.org/pdf/2408.13227v1,cs.CL
EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods,"Accurate forecasting of the EUR/USD exchange rate is crucial for investors,
businesses, and policymakers. This paper proposes a novel framework, IUS, that
integrates unstructured textual data from news and analysis with structured
data on exchange rates and financial indicators to enhance exchange rate
prediction. The IUS framework employs large language models for sentiment
polarity scoring and exchange rate movement classification of texts. These
textual features are combined with quantitative features and input into a
Causality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then
used to forecast the EUR/USD exchange rate. Experiments demonstrate that the
proposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE
by 9.56% compared to the best performing baseline. Results also show the
benefits of data fusion, with the combination of unstructured and structured
data yielding higher accuracy than structured data alone. Furthermore, feature
selection using the top 12 important quantitative features combined with the
textual features proves most effective. The proposed IUS framework and
Optuna-Bi-LSTM model provide a powerful new approach for exchange rate
forecasting through multi-source data integration.",2024-08-23,"Hongcheng Ding, Xuanze Zhao, Zixiao Jiang, Shamsul Nahar Abdullah, Deshinta Arrova Dewi",http://arxiv.org/pdf/2408.13214v1,cs.CL
A New Era in Computational Pathology: A Survey on Foundation and Vision-Language Models,"Recent advances in deep learning have completely transformed the domain of
computational pathology (CPath). More specifically, it has altered the
diagnostic workflow of pathologists by integrating foundation models (FMs) and
vision-language models (VLMs) in their assessment and decision-making process.
The limitations of existing deep learning approaches in CPath can be overcome
by FMs through learning a representation space that can be adapted to a wide
variety of downstream tasks without explicit supervision. Deploying VLMs allow
pathology reports written in natural language be used as rich semantic
information sources to improve existing models as well as generate predictions
in natural language form. In this survey, a holistic and systematic overview of
recent innovations in FMs and VLMs in CPath is presented. Furthermore, the
tools, datasets and training schemes for these models are summarized in
addition to categorizing them into distinct groups. This extensive survey
highlights the current trends in CPath and its possible revolution through the
use of FMs and VLMs in the future.",2024-08-23,"Dibaloke Chanda, Milan Aryal, Nasim Yahya Soltani, Masoud Ganji",http://arxiv.org/pdf/2408.14496v3,cs.CL
Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews,"Aspect-based Sentiment Analysis (ABSA) is a critical task in Natural Language
Processing (NLP) that focuses on extracting sentiments related to specific
aspects within a text, offering deep insights into customer opinions.
Traditional sentiment analysis methods, while useful for determining overall
sentiment, often miss the implicit opinions about particular product or service
features. This paper presents a comprehensive review of the evolution of ABSA
methodologies, from lexicon-based approaches to machine learning and deep
learning techniques. We emphasize the recent advancements in Transformer-based
models, particularly Bidirectional Encoder Representations from Transformers
(BERT) and its variants, which have set new benchmarks in ABSA tasks. We
focused on finetuning Llama and Mistral models, building hybrid models using
the SetFit framework, and developing our own model by exploiting the strengths
of state-of-the-art (SOTA) Transformer-based models for aspect term extraction
(ATE) and aspect sentiment classification (ASC). Our hybrid model Instruct -
DeBERTa uses SOTA InstructABSA for aspect extraction and DeBERTa-V3-baseabsa-V1
for aspect sentiment classification. We utilize datasets from different domains
to evaluate our model's performance. Our experiments indicate that the proposed
hybrid model significantly improves the accuracy and reliability of sentiment
analysis across all experimented domains. As per our findings, our hybrid model
Instruct - DeBERTa is the best-performing model for the joint task of ATE and
ASC for both SemEval restaurant 2014 and SemEval laptop 2014 datasets
separately. By addressing the limitations of existing methodologies, our
approach provides a robust solution for understanding detailed consumer
feedback, thus offering valuable insights for businesses aiming to enhance
customer satisfaction and product development.",2024-08-23,"Dineth Jayakody, A V A Malkith, Koshila Isuranda, Vishal Thenuwara, Nisansa de Silva, Sachintha Rajith Ponnamperuma, G G N Sandamali, K L K Sudheera",http://arxiv.org/pdf/2408.13202v1,cs.CL
Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning,"Spatial reasoning in Large Language Models (LLMs) is the foundation for
embodied intelligence. However, even in simple maze environments, LLMs still
encounter challenges in long-term path-planning, primarily influenced by their
spatial hallucination and context inconsistency hallucination by long-term
reasoning. To address this challenge, this study proposes an innovative model,
Spatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). To
address the spatial hallucination of LLMs, we propose the Spatial-to-Relational
approach, which transforms spatial prompts into entity relations and paths
representing entity relation chains. This approach fully taps the potential of
LLMs in terms of sequential thinking. As a result, we design a path-planning
algorithm based on Q-learning to mitigate the context inconsistency
hallucination, which enhances the reasoning ability of LLMs. Using the Q-value
of state-action as auxiliary information for prompts, we correct the
hallucinations of LLMs, thereby guiding LLMs to learn the optimal path.
Finally, we propose a reverse curriculum learning technique based on LLMs to
further mitigate the context inconsistency hallucination. LLMs can rapidly
accumulate successful experiences by reducing task difficulty and leveraging
them to tackle more complex tasks. We performed comprehensive experiments based
on Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that our
S2RCQL achieved a 23%--40% improvement in both success and optimality rates
compared with advanced prompt engineering.",2024-08-23,"Hourui Deng, Hongjie Zhang, Jie Ou, Chaosheng Feng",http://arxiv.org/pdf/2408.13184v3,cs.CL
Lessons in co-creation: the inconvenient truths of inclusive sign language technology development,"In the era of AI-driven language technologies, there is a growing demand for
the participation and leadership of deaf communities in sign language
technology development, often framed as co-creation. This paper, developed
through collaborative and iterative dialogue between the authors with data from
informal participant observations, examines the involvement of the European
Union of the Deaf in two EU Horizon 2020 projects, EASIER and SignON. These
projects aimed to develop mobile translation applications between signed and
spoken languages, bringing together predominantly hearing, non-signing
technology experts with predominantly hearing sign language academics and
organizations representing deaf end users in large multi-partner consortia.
While co-creation is sometimes presented as the best or required way to do
research or even as emancipatory, it frequently masks systemic issues of power
imbalances and tokenism. Drawing from EUD's experiences of these projects, we
highlight several inconvenient truths of co-creation, and propose seven lessons
for future initiatives: recognizing deaf partners' invisible labour as work,
managing expectations about technologies, cripping co-creation processes,
exploring alternative methods to mitigate co-creation fatigue, seeking
intersectional feedback, ensuring co-creation is not just virtue signalling,
and fostering deaf leadership in AI sign language research. We argue for
co-creation as a transformative activity that fundamentally alters the status
quo and levels the playing field. This necessitates increasing the number of
deaf researchers and enhancing AI literacy among deaf communities. Without
these critical transformative actions, co-creation risks merely paying lip
service to deaf communities.",2024-08-23,"Maartje De Meulder, Davy Van Landuyt, Rehana Omardeen",http://arxiv.org/pdf/2408.13171v1,cs.CL
"The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities","This report examines the fine-tuning of Large Language Models (LLMs),
integrating theoretical insights with practical applications. It outlines the
historical evolution of LLMs from traditional Natural Language Processing (NLP)
models to their pivotal role in AI. A comparison of fine-tuning methodologies,
including supervised, unsupervised, and instruction-based approaches,
highlights their applicability to different tasks. The report introduces a
structured seven-stage pipeline for fine-tuning LLMs, spanning data
preparation, model initialization, hyperparameter tuning, and model deployment.
Emphasis is placed on managing imbalanced datasets and optimization techniques.
Parameter-efficient methods like Low-Rank Adaptation (LoRA) and Half
Fine-Tuning are explored for balancing computational efficiency with
performance. Advanced techniques such as memory fine-tuning, Mixture of Experts
(MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized
networks and multi-agent collaboration. The report also examines novel
approaches like Proximal Policy Optimization (PPO) and Direct Preference
Optimization (DPO), which align LLMs with human preferences, alongside pruning
and routing optimizations to improve efficiency. Further sections cover
validation frameworks, post-deployment monitoring, and inference optimization,
with attention to deploying LLMs on distributed and cloud-based platforms.
Emerging areas such as multimodal LLMs, fine-tuning for audio and speech, and
challenges related to scalability, privacy, and accountability are also
addressed. This report offers actionable insights for researchers and
practitioners navigating LLM fine-tuning in an evolving landscape.",2024-08-23,"Venkatesh Balavadhani Parthasarathy, Ahtsham Zafar, Aafaq Khan, Arsalan Shahid",http://arxiv.org/pdf/2408.13296v3,cs.CL
Exploring Bias and Prediction Metrics to Characterise the Fairness of Machine Learning for Equity-Centered Public Health Decision-Making: A Narrative Review,"Background: The rapid advancement of Machine Learning (ML) represents novel
opportunities to enhance public health research, surveillance, and
decision-making. However, there is a lack of comprehensive understanding of
algorithmic bias, systematic errors in predicted population health outcomes,
resulting from the public health application of ML. The objective of this
narrative review is to explore the types of bias generated by ML and
quantitative metrics to assess these biases.
  Methods : We performed search on PubMed, MEDLINE, IEEE (Institute of
Electrical and Electronics Engineers), ACM (Association for Computing
Machinery) Digital Library, Science Direct, and Springer Nature. We used
keywords to identify studies describing types of bias and metrics to measure
these in the domain of ML and public and population health published in English
between 2008 and 2023, inclusive.
  Results: A total of 72 articles met the inclusion criteria. Our review
identified the commonly described types of bias and quantitative metrics to
assess these biases from an equity perspective.
  Conclusion : The review will help formalize the evaluation framework for ML
on public health from an equity perspective.",2024-08-23,"Shaina Raza, Arash Shaban-Nejad, Elham Dolatabadi, Hiroshi Mamiya",http://arxiv.org/pdf/2408.13295v2,cs.CL
An alternative formulation of attention pooling function in translation,"The aim of this paper is to present an alternative formulation of the
attention scoring function in translation tasks. Generally speaking, language
is deeply structured, and this is reflected in the attention scoring matrix. We
exploit this property to define the attention pooling function, taking this
aspect into account. In the first chapters, we introduce the attention
mechanism in mathematical terms and explain its limitations and alternative
formulations. Next, we focus on the experimental session that led to the
alternative formulation. Essentially, we guide queries and keys to interact in
a specific manner, encoding the distinct roles of attention heads and directing
values on where to seek context. In mathematical terms, we can think of this
formula as projecting the attention scores matrix, say $H$, onto the space of
band matrices with fixed bandwidth. This convex subspace is clearly
finite-dimensional and therefore closed. As a consequence, the projection on
this space is well-posed and unique. However, at the price of losing the
uniqueness of the projection (i.e., the best approximation for $H$), we defined
a new space consisting of band matrices plus error sparse matrices. We prove
that this is a compact subspace which guarantees the existence of a matrix that
best approximates $H$. We conclude the thesis by validating the new formula,
namely calculating how well the new formula for attention scores approximates
the original one. Additionally, we explore the impact of different parameters
such as w (context windows) and num-pos (number of relevant words in a
sentence). These analyses provide deeper insights into how languages are
processed and translated, revealing nuances in the roles of context and word
relevance.",2024-08-23,Eddie Conti,http://arxiv.org/pdf/2409.00068v1,cs.CL
Analysis of child development facts and myths using text mining techniques and classification models,"The rapid dissemination of misinformation on the internet complicates the
decision-making process for individuals seeking reliable information,
particularly parents researching child development topics. This misinformation
can lead to adverse consequences, such as inappropriate treatment of children
based on myths. While previous research has utilized text-mining techniques to
predict child abuse cases, there has been a gap in the analysis of child
development myths and facts. This study addresses this gap by applying text
mining techniques and classification models to distinguish between myths and
facts about child development, leveraging newly gathered data from publicly
available websites. The research methodology involved several stages. First,
text mining techniques were employed to pre-process the data, ensuring enhanced
accuracy. Subsequently, the structured data was analysed using six robust
Machine Learning (ML) classifiers and one Deep Learning (DL) model, with two
feature extraction techniques applied to assess their performance across three
different training-testing splits. To ensure the reliability of the results,
cross-validation was performed using both k-fold and leave-one-out methods.
Among the classification models tested, Logistic Regression (LR) demonstrated
the highest accuracy, achieving a 90% accuracy with the Bag-of-Words (BoW)
feature extraction technique. LR stands out for its exceptional speed and
efficiency, maintaining low testing time per statement (0.97 microseconds).
These findings suggest that LR, when combined with BoW, is effective in
accurately classifying child development information, thus providing a valuable
tool for combating misinformation and assisting parents in making informed
decisions.",2024-08-23,"Mehedi Tajrian, Azizur Rahman, Muhammad Ashad Kabir, Md Rafiqul Islam",http://arxiv.org/pdf/2408.13091v1,cs.CL
SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks,"Prompting has become a practical method for utilizing pre-trained language
models (LMs). This approach offers several advantages. It allows an LM to adapt
to new tasks with minimal training and parameter updates, thus achieving
efficiency in both storage and computation. Additionally, prompting modifies
only the LM's inputs and harnesses the generative capabilities of language
models to address various downstream tasks in a unified manner. This
significantly reduces the need for human labor in designing task-specific
models. These advantages become even more evident as the number of tasks served
by the LM scales up. Motivated by the strengths of prompting, we are the first
to explore the potential of prompting speech LMs in the domain of speech
processing. Recently, there has been a growing interest in converting speech
into discrete units for language modeling. Our pioneer research demonstrates
that these quantized speech units are highly versatile within our unified
prompting framework. Not only can they serve as class labels, but they also
contain rich phonetic information that can be re-synthesized back into speech
signals for speech generation tasks. Specifically, we reformulate speech
processing tasks into speech-to-unit generation tasks. As a result, we can
seamlessly integrate tasks such as speech classification, sequence generation,
and speech generation within a single, unified prompting framework. The
experiment results show that the prompting method can achieve competitive
performance compared to the strong fine-tuning method based on self-supervised
learning models with a similar number of trainable parameters. The prompting
method also shows promising results in the few-shot setting. Moreover, with the
advanced speech LMs coming into the stage, the proposed prompting framework
attains great potential.",2024-08-23,"Kai-Wei Chang, Haibin Wu, Yu-Kai Wang, Yuan-Kuei Wu, Hua Shen, Wei-Cheng Tseng, Iu-thing Kang, Shang-Wen Li, Hung-yi Lee",http://arxiv.org/pdf/2408.13040v1,cs.CL
In-Context Learning with Reinforcement Learning for Incomplete Utterance Rewriting,"In-context learning (ICL) of large language models (LLMs) has attracted
increasing attention in the community where LLMs make predictions only based on
instructions augmented with a few examples. Existing example selection methods
for ICL utilize sparse or dense retrievers and derive effective performance.
However, these methods do not utilize direct feedback of LLM to train the
retriever and the examples selected can not necessarily improve the analogy
ability of LLM. To tackle this, we propose our policy-based reinforcement
learning framework for example selection (RLS), which consists of a language
model (LM) selector and an LLM generator. The LM selector encodes the candidate
examples into dense representations and selects the top-k examples into the
demonstration for LLM. The outputs of LLM are adopted to compute the reward and
policy gradient to optimize the LM selector. We conduct experiments on
different datasets and significantly outperform existing example selection
methods. Moreover, our approach shows advantages over supervised finetuning
(SFT) models in few shot setting. Further experiments show the balance of
abundance and the similarity with the test case of examples is important for
ICL performance of LLM.",2024-08-23,"Haowei Du, Dongyan Zhao",http://arxiv.org/pdf/2408.13028v1,cs.CL
Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates,"LLM-as-a-Judge has been widely applied to evaluate and compare different LLM
alignmnet approaches (e.g., RLHF and DPO). However, concerns regarding its
reliability have emerged, due to LLM judges' biases and inconsistent
decision-making. Previous research has developed evaluation frameworks to
assess reliability of LLM judges and their alignment with human preferences.
However, the employed evaluation metrics often lack adequate explainability and
fail to address LLM internal inconsistency. Additionally, existing studies
inadequately explore the impact of various prompt templates when applying
LLM-as-a-Judge methods, leading to potentially inconsistent comparisons between
different alignment algorithms. In this work, we systematically evaluate
LLM-as-a-Judge on alignment tasks by defining more theoretically interpretable
evaluation metrics and explicitly mitigating LLM internal inconsistency from
reliability metrics. We develop an open-source framework to evaluate, compare,
and visualize the reliability and alignment of LLM judges, which facilitates
practitioners to choose LLM judges for alignment tasks. In the experiments, we
examine effects of diverse prompt templates on LLM-judge reliability and also
demonstrate our developed framework by comparing various LLM judges on two
common alignment datasets (i.e., TL;DR Summarization and HH-RLHF-Helpfulness).
Our results indicate a significant impact of prompt templates on LLM judge
performance, as well as a mediocre alignment level between the tested LLM
judges and human evaluators.",2024-08-23,"Hui Wei, Shenghua He, Tian Xia, Fei Liu, Andy Wong, Jingyang Lin, Mei Han",http://arxiv.org/pdf/2408.13006v2,cs.CL
MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries,"Medical decisions directly impact individuals' health and well-being.
Extracting decision spans from clinical notes plays a crucial role in
understanding medical decision-making processes. In this paper, we develop a
new dataset called ""MedDec"", which contains clinical notes of eleven different
phenotypes (diseases) annotated by ten types of medical decisions. We introduce
the task of medical decision extraction, aiming to jointly extract and classify
different types of medical decisions within clinical notes. We provide a
comprehensive analysis of the dataset, develop a span detection model as a
baseline for this task, evaluate recent span detection approaches, and employ a
few metrics to measure the complexity of data samples. Our findings shed light
on the complexities inherent in clinical decision extraction and enable future
work in this area of research. The dataset and code are available through
https://github.com/CLU-UML/MedDec.",2024-08-23,"Mohamed Elgaar, Jiali Cheng, Nidhi Vakil, Hadi Amiri, Leo Anthony Celi",http://arxiv.org/pdf/2408.12980v1,cs.CL
Internal and External Knowledge Interactive Refinement Framework for Knowledge-Intensive Question Answering,"Recent works have attempted to integrate external knowledge into LLMs to
address the limitations and potential factual errors in LLM-generated content.
However, how to retrieve the correct knowledge from the large amount of
external knowledge imposes a challenge. To this end, we empirically observe
that LLMs have already encoded rich knowledge in their pretrained parameters
and utilizing these internal knowledge improves the retrieval of external
knowledge when applying them to knowledge-intensive tasks. In this paper, we
propose a new internal and external knowledge interactive refinement paradigm
dubbed IEKR to utilize internal knowledge in LLM to help retrieve relevant
knowledge from the external knowledge base, as well as exploit the external
knowledge to refine the hallucination of generated internal knowledge. By
simply adding a prompt like 'Tell me something about' to the LLMs, we try to
review related explicit knowledge and insert them with the query into the
retriever for external retrieval. The external knowledge is utilized to
complement the internal knowledge into input of LLM for answers. We conduct
experiments on 3 benchmark datasets in knowledge-intensive question answering
task with different LLMs and domains, achieving the new state-of-the-art.
Further analysis shows the effectiveness of different modules in our approach.",2024-08-23,"Haowei Du, Dongyan Zhao",http://arxiv.org/pdf/2408.12979v1,cs.CL
Open Llama2 Model for the Lithuanian Language,"In this paper, we propose and describe the first open Llama2 large language
models (LLMs) for the Lithuanian language, including an accompanying
question/answer (Q/A) dataset and translations of popular LLM benchmarks. We
provide a brief review of open regional LLMs and detailed information on the
proposed LLMs and their training process. We also conduct an empirical
evaluation, comparing the perplexities of the proposed LLMs with those of other
modern open LLMs. In addition, benchmarking the proposed LLMs against language
understanding tasks reveals that high-quality pretraining datasets may be
essential for achieving models that perform efficiently on these benchmarks.
The full realisations of the described LLMs are available in the accompanying
open repository~\url{https://huggingface.co/neurotechnology}.",2024-08-23,"Artūras Nakvosas, Povilas Daniušis, Vytas Mulevičius",http://arxiv.org/pdf/2408.12963v1,cs.CL
Multimodal Contrastive In-Context Learning,"The rapid growth of Large Language Models (LLMs) usage has highlighted the
importance of gradient-free in-context learning (ICL). However, interpreting
their inner workings remains challenging. This paper introduces a novel
multimodal contrastive in-context learning framework to enhance our
understanding of ICL in LLMs. First, we present a contrastive learning-based
interpretation of ICL in real-world settings, marking the distance of the
key-value representation as the differentiator in ICL. Second, we develop an
analytical framework to address biases in multimodal input formatting for
real-world datasets. We demonstrate the effectiveness of ICL examples where
baseline performance is poor, even when they are represented in unseen formats.
Lastly, we propose an on-the-fly approach for ICL (Anchored-by-Text ICL) that
demonstrates effectiveness in detecting hateful memes, a task where typical ICL
struggles due to resource limitations. Extensive experiments on multimodal
datasets reveal that our approach significantly improves ICL performance across
various scenarios, such as challenging tasks and resource-constrained
environments. Moreover, it provides valuable insights into the mechanisms of
in-context learning in LLMs. Our findings have important implications for
developing more interpretable, efficient, and robust multimodal AI systems,
especially in challenging tasks and resource-constrained environments.",2024-08-23,"Yosuke Miyanishi, Minh Le Nguyen",http://arxiv.org/pdf/2408.12959v1,cs.CL
Causal-Guided Active Learning for Debiasing Large Language Models,"Although achieving promising performance, recent analyses show that current
generative large language models (LLMs) may still capture dataset biases and
utilize them for generation, leading to poor generalizability and harmfulness
of LLMs. However, due to the diversity of dataset biases and the
over-optimization problem, previous prior-knowledge-based debiasing methods and
fine-tuning-based debiasing methods may not be suitable for current LLMs. To
address this issue, we explore combining active learning with the causal
mechanisms and propose a casual-guided active learning (CAL) framework, which
utilizes LLMs itself to automatically and autonomously identify informative
biased samples and induce the bias patterns. Then a cost-effective and
efficient in-context learning based method is employed to prevent LLMs from
utilizing dataset biases during generation. Experimental results show that CAL
can effectively recognize typical biased instances and induce various bias
patterns for debiasing LLMs.",2024-08-23,"Li Du, Zhouhao Sun, Xiao Ding, Yixuan Ma, Yang Zhao, Kaitao Qiu, Ting Liu, Bing Qin",http://arxiv.org/pdf/2408.12942v2,cs.CL
LCA and energy efficiency in buildings: mapping more than twenty years of research,"Research on Life Cycle Assessment (LCA) is being conducted in various
sectors, from analyzing building materials and components to comprehensive
evaluations of entire structures. However, reviews of the existing literature
have been unable to provide a comprehensive overview of research in this field,
leaving scholars without a definitive guideline for future investigations. This
paper aims to fill this gap, mapping more than twenty years of research. Using
an innovative methodology that combines social network analysis and text
mining, the paper examined 8024 scientific abstracts. The authors identified
seven key thematic groups, building and sustainability clusters (BSCs). To
assess their significance in the broader discourse on building and
sustainability, the semantic brand score (SBS) indicator was applied.
Additionally, building and sustainability trends were tracked, focusing on the
LCA concept. The major research topics mainly relate to building materials and
energy efficiency. In addition to presenting an innovative approach to
reviewing extensive literature domains, the article also provides insights into
emerging and underdeveloped themes, outlining crucial future research
directions.",2024-08-23,"F. Asdrubali, A. Fronzetti Colladon, L. Segneri, D. M. Gandola",http://arxiv.org/pdf/2409.00065v1,cs.CL
IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model with Multimodal Capabilities,"In the field of multimodal large language models (MLLMs), common methods
typically involve unfreezing the language model during training to foster
profound visual understanding. However, the fine-tuning of such models with
vision-language data often leads to a diminution of their natural language
processing (NLP) capabilities. To avoid this performance degradation, a
straightforward solution is to freeze the language model while developing
multimodal competencies. Unfortunately, previous works have not attained
satisfactory outcomes. Building on the strategy of freezing the language model,
we conduct thorough structural exploration and introduce the Inner-Adaptor
Architecture (IAA). Specifically, the architecture incorporates multiple
multimodal adaptors at varying depths within the large language model to
facilitate direct interaction with the inherently text-oriented transformer
layers, thereby enabling the frozen language model to acquire multimodal
capabilities. Unlike previous approaches of freezing language models that
require large-scale aligned data, our proposed architecture is able to achieve
superior performance on small-scale datasets. We conduct extensive experiments
to improve the general multimodal capabilities and visual grounding abilities
of the MLLM. Our approach remarkably outperforms previous state-of-the-art
methods across various vision-language benchmarks without sacrificing
performance on NLP tasks. Code and models are available at
https://github.com/360CVGroup/Inner-Adaptor-Architecture.",2024-08-23,"Bin Wang, Chunyu Xie, Dawei Leng, Yuhui Yin",http://arxiv.org/pdf/2408.12902v2,cs.CL
Memory-Efficient LLM Training with Online Subspace Descent,"Recently, a wide range of memory-efficient LLM training algorithms have
gained substantial popularity. These methods leverage the low-rank structure of
gradients to project optimizer states into a subspace using projection matrix
found by singular value decomposition (SVD). However, convergence of these
algorithms is highly dependent on the update rules of their projection matrix.
In this work, we provide the \emph{first} convergence guarantee for arbitrary
update rules of projection matrix. This guarantee is generally applicable to
optimizers that can be analyzed with Hamiltonian Descent, including most common
ones, such as LION, Adam. Inspired by our theoretical understanding, we propose
Online Subspace Descent, a new family of subspace descent optimizer without
SVD. Instead of updating the projection matrix with eigenvectors, Online
Subspace Descent updates the projection matrix with online PCA. Online Subspace
Descent is flexible and introduces only minimum overhead to training. We show
that for the task of pretraining LLaMA models ranging from 60M to 7B parameters
on the C4 dataset, Online Subspace Descent achieves lower perplexity and better
downstream tasks performance than state-of-the-art low-rank training methods
across different settings and narrows the gap with full-rank baselines.",2024-08-23,"Kaizhao Liang, Bo Liu, Lizhang Chen, Qiang Liu",http://arxiv.org/pdf/2408.12857v1,cs.CL
Multi-Faceted Question Complexity Estimation Targeting Topic Domain-Specificity,"Question difficulty estimation remains a multifaceted challenge in
educational and assessment settings. Traditional approaches often focus on
surface-level linguistic features or learner comprehension levels, neglecting
the intricate interplay of factors contributing to question complexity. This
paper presents a novel framework for domain-specific question difficulty
estimation, leveraging a suite of NLP techniques and knowledge graph analysis.
We introduce four key parameters: Topic Retrieval Cost, Topic Salience, Topic
Coherence, and Topic Superficiality, each capturing a distinct facet of
question complexity within a given subject domain. These parameters are
operationalized through topic modelling, knowledge graph analysis, and
information retrieval techniques. A model trained on these features
demonstrates the efficacy of our approach in predicting question difficulty. By
operationalizing these parameters, our framework offers a novel approach to
question complexity estimation, paving the way for more effective question
generation, assessment design, and adaptive learning systems across diverse
academic disciplines.",2024-08-23,"Sujay R, Suki Perumal, Yash Nagraj, Anushka Ghei, Srinivas K S",http://arxiv.org/pdf/2408.12850v1,cs.CL
CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition,"Few-shot Named Entity Recognition (NER), the task of identifying named
entities with only a limited amount of labeled data, has gained increasing
significance in natural language processing. While existing methodologies have
shown some effectiveness, such as enriching label semantics through various
prompting modes or employing metric learning techniques, their performance
exhibits limited robustness across diverse domains due to the lack of rich
knowledge in their pre-trained models. To address this issue, we propose
CLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework
for Few-Shot Named Entity Recognition, achieving promising results with limited
training data. Considering the impact of LLM's internal representations on
downstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive
learning mechanisms specifically tailored for few-shot NER. By enhancing the
model's internal representations, CLLMFS effectively improves both entity
boundary awareness ability and entity recognition accuracy. Our method has
achieved state-of-the-art performance improvements on F1-score ranging from
2.58\% to 97.74\% over existing best-performing methods across several
recognized benchmarks. Furthermore, through cross-domain NER experiments
conducted on multiple datasets, we have further validated the robust
generalization capability of our method. Our code will be released in the near
future.",2024-08-23,"Yafeng Zhang, Zilan Yu, Yuang Huang, Jing Tang",http://arxiv.org/pdf/2408.12834v1,cs.CL
LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction,"Human mobility prediction is essential for applications like urban planning
and transportation management, yet it remains challenging due to the complex,
often implicit, intentions behind human behavior. Existing models predominantly
focus on spatiotemporal patterns, paying less attention to the underlying
intentions that govern movements. Recent advancements in large language models
(LLMs) offer a promising alternative research angle for integrating commonsense
reasoning into mobility prediction. However, it is a non-trivial problem
because LLMs are not natively built for mobility intention inference, and they
also face scalability issues and integration difficulties with spatiotemporal
models. To address these challenges, we propose a novel LIMP (LLMs for
Intent-ware Mobility Prediction) framework. Specifically, LIMP introduces an
""Analyze-Abstract-Infer"" (A2I) agentic workflow to unleash LLM's commonsense
reasoning power for mobility intention inference. Besides, we design an
efficient fine-tuning scheme to transfer reasoning power from commercial LLM to
smaller-scale, open-source language model, ensuring LIMP's scalability to
millions of mobility records. Moreover, we propose a transformer-based
intention-aware mobility prediction model to effectively harness the intention
inference ability of LLM. Evaluated on two real-world datasets, LIMP
significantly outperforms baseline models, demonstrating improved accuracy in
next-location prediction and effective intention inference. The
interpretability of intention-aware mobility prediction highlights our LIMP
framework's potential for real-world applications. Codes and data can be found
in https://github.com/tsinghua-fib-lab/LIMP .",2024-08-23,"Songwei Li, Jie Feng, Jiawei Chi, Xinyuan Hu, Xiaomeng Zhao, Fengli Xu",http://arxiv.org/pdf/2408.12832v1,cs.CL
Grounding Fallacies Misrepresenting Scientific Publications in Evidence,"Health-related misinformation claims often falsely cite a credible biomedical
publication as evidence. These publications only superficially seem to support
the false claim, when logical fallacies are applied. In this work, we aim to
detect and to highlight such fallacies, which requires assessing the exact
content of the misrepresented publications. To achieve this, we introduce
MissciPlus, an extension of the fallacy detection dataset Missci. MissciPlus
extends Missci by grounding the applied fallacies in real-world passages from
misrepresented studies. This creates a realistic test-bed for detecting and
verbalizing fallacies under real-world input conditions, and enables new and
realistic passage-retrieval tasks. MissciPlus is the first logical fallacy
dataset which pairs the real-world misrepresented evidence with incorrect
claims, identical to the input to evidence-based fact-checking models. With
MissciPlus, we i) benchmark retrieval models in identifying passages that
support claims only with fallacious reasoning, ii) evaluate how well LLMs
verbalize fallacious reasoning based on misrepresented scientific passages, and
iii) assess the effectiveness of fact-checking models in refuting claims that
misrepresent biomedical research. Our findings show that current fact-checking
models struggle to use misrepresented scientific passages to refute
misinformation. Moreover, these passages can mislead LLMs into accepting false
claims as true.",2024-08-23,"Max Glockner, Yufang Hou, Preslav Nakov, Iryna Gurevych",http://arxiv.org/pdf/2408.12812v2,cs.CL
VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models,"Deep Neural Networks (DNNs) have revolutionized various fields by enabling
task automation and reducing human error. However, their internal workings and
decision-making processes remain obscure due to their black box nature.
Consequently, the lack of interpretability limits the application of these
models in high-risk scenarios. To address this issue, the emerging field of
eXplainable Artificial Intelligence (XAI) aims to explain and interpret the
inner workings of DNNs. Despite advancements, XAI faces challenges such as the
semantic gap between machine and human understanding, the trade-off between
interpretability and performance, and the need for context-specific
explanations. To overcome these limitations, we propose a novel multimodal
framework named VALE Visual and Language Explanation. VALE integrates
explainable AI techniques with advanced language models to provide
comprehensive explanations. This framework utilizes visual explanations from
XAI tools, an advanced zero-shot image segmentation model, and a visual
language model to generate corresponding textual explanations. By combining
visual and textual explanations, VALE bridges the semantic gap between machine
outputs and human interpretation, delivering results that are more
comprehensible to users. In this paper, we conduct a pilot study of the VALE
framework for image classification tasks. Specifically, Shapley Additive
Explanations (SHAP) are used to identify the most influential regions in
classified images. The object of interest is then extracted using the Segment
Anything Model (SAM), and explanations are generated using state-of-the-art
pre-trained Vision-Language Models (VLMs). Extensive experimental studies are
performed on two datasets: the ImageNet dataset and a custom underwater SONAR
image dataset, demonstrating VALEs real-world applicability in underwater image
classification.",2024-08-23,"Purushothaman Natarajan, Athira Nambiar",http://arxiv.org/pdf/2408.12808v1,cs.CL
Preference Consistency Matters: Enhancing Preference Learning in Language Models with Automated Self-Curation of Training Corpora,"Inconsistent annotations in training corpora, particularly within preference
learning datasets, pose challenges in developing advanced language models.
These inconsistencies often arise from variability among annotators and
inherent multi-dimensional nature of the preferences. To address these issues,
we introduce a self-curation method that preprocesses annotated datasets by
leveraging proxy models trained directly on them. Our method enhances
preference learning by automatically detecting and selecting consistent
annotations. We validate the proposed approach through extensive
instruction-following tasks, demonstrating performance improvements of up to
33\% across various learning algorithms and proxy capabilities. This work
offers a straightforward and reliable solution to address preference
inconsistencies without relying on heuristics, serving as an initial step
toward the development of more advanced preference learning methodologies. Code
is available at https://github.com/Self-Curation/ .",2024-08-23,"JoonHo Lee, JuYoun Son, Juree Seok, Wooseok Jang, Yeong-Dae Kwon",http://arxiv.org/pdf/2408.12799v2,cs.CL
Quality or Quantity? On Data Scale and Diversity in Adapting Large Language Models for Low-Resource Translation,"Despite the recent popularity of Large Language Models (LLMs) in Machine
Translation (MT), their performance in low-resource languages (LRLs) still lags
significantly behind Neural Machine Translation (NMT) models. In this work, we
explore what it would take to adapt LLMs for the low-resource setting.
Particularly, we re-examine the role of two factors: a) the importance and
application of parallel data, and b) diversity in Supervised Fine-Tuning (SFT).
Recently, parallel data has seen reduced use in adapting LLMs for MT, while
data diversity has been embraced to promote transfer across languages and
tasks. However, for low-resource LLM-MT, we show that the opposite is true for
both considerations: a) parallel data is critical during both pre-training and
SFT; b) diversity tends to cause interference instead of transfer. Our
experiments with three LLMs across two low-resourced language groups --
Indigenous American and North-East Indian -- reveal consistent trends,
underscoring the generalizability of our findings. We believe these insights
will be valuable for scaling to massively multilingual LLM-MT models that can
effectively serve LRLs.",2024-08-23,"Vivek Iyer, Bhavitvya Malik, Pavel Stepachev, Pinzhen Chen, Barry Haddow, Alexandra Birch",http://arxiv.org/pdf/2408.12780v2,cs.CL
Investigating LLM Applications in E-Commerce,"The emergence of Large Language Models (LLMs) has revolutionized natural
language processing in various applications especially in e-commerce. One
crucial step before the application of such LLMs in these fields is to
understand and compare the performance in different use cases in such tasks.
This paper explored the efficacy of LLMs in the e-commerce domain, focusing on
instruction-tuning an open source LLM model with public e-commerce datasets of
varying sizes and comparing the performance with the conventional models
prevalent in industrial applications. We conducted a comprehensive comparison
between LLMs and traditional pre-trained language models across specific tasks
intrinsic to the e-commerce domain, namely classification, generation,
summarization, and named entity recognition (NER). Furthermore, we examined the
effectiveness of the current niche industrial application of very large LLM,
using in-context learning, in e-commerce specific tasks. Our findings indicate
that few-shot inference with very large LLMs often does not outperform
fine-tuning smaller pre-trained models, underscoring the importance of
task-specific model optimization.Additionally, we investigated different
training methodologies such as single-task training, mixed-task training, and
LoRA merging both within domain/tasks and between different tasks. Through
rigorous experimentation and analysis, this paper offers valuable insights into
the potential effectiveness of LLMs to advance natural language processing
capabilities within the e-commerce industry.",2024-08-23,"Chester Palen-Michel, Ruixiang Wang, Yipeng Zhang, David Yu, Canran Xu, Zhe Wu",http://arxiv.org/pdf/2408.12779v1,cs.CL
Phrasing for UX: Enhancing Information Engagement through Computational Linguistics and Creative Analytics,"This study explores the relationship between textual features and Information
Engagement (IE) on digital platforms. It highlights the impact of computational
linguistics and analytics on user interaction. The READ model is introduced to
quantify key predictors like representativeness, ease of use, affect, and
distribution, which forecast engagement levels. The model's effectiveness is
validated through AB testing and randomized trials, showing strong predictive
performance in participation (accuracy: 0.94), perception (accuracy: 0.85),
perseverance (accuracy: 0.81), and overall IE (accuracy: 0.97).
  While participation metrics are strong, perception and perseverance show
slightly lower recall and F1-scores, indicating some challenges. The study
demonstrates that modifying text based on the READ model's insights leads to
significant improvements. For example, increasing representativeness and
positive affect boosts selection rates by 11 percent, raises evaluation
averages from 3.98 to 4.46, and improves retention rates by 11 percent. These
findings highlight the importance of linguistic factors in IE, providing a
framework for enhancing digital text engagement. The research offers practical
strategies applicable to fields like education, health, and media.",2024-08-23,Nimrod Dvir,http://arxiv.org/pdf/2409.00064v1,cs.CL
Assessing Modality Bias in Video Question Answering Benchmarks with Multimodal Large Language Models,"Multimodal large language models (MLLMs) can simultaneously process visual,
textual, and auditory data, capturing insights that complement human analysis.
However, existing video question-answering (VidQA) benchmarks and datasets
often exhibit a bias toward a single modality, despite the goal of requiring
advanced reasoning skills that integrate diverse modalities to answer the
queries. In this work, we introduce the modality importance score (MIS) to
identify such bias. It is designed to assess which modality embeds the
necessary information to answer the question. Additionally, we propose an
innovative method using state-of-the-art MLLMs to estimate the modality
importance, which can serve as a proxy for human judgments of modality
perception. With this MIS, we demonstrate the presence of unimodal bias and the
scarcity of genuinely multimodal questions in existing datasets. We further
validate the modality importance score with multiple ablation studies to
evaluate the performance of MLLMs on permuted feature sets. Our results
indicate that current models do not effectively integrate information due to
modality imbalance in existing datasets. Our proposed MLLM-derived MIS can
guide the curation of modality-balanced datasets that advance multimodal
learning and enhance MLLMs' capabilities to understand and utilize synergistic
relations across modalities.",2024-08-22,"Jean Park, Kuk Jin Jang, Basam Alasaly, Sriharsha Mopidevi, Andrew Zolensky, Eric Eaton, Insup Lee, Kevin Johnson",http://arxiv.org/pdf/2408.12763v2,cs.CL
"SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection","Large language models (LLMs) are highly capable but face latency challenges
in real-time applications, such as conducting online hallucination detection.
To overcome this issue, we propose a novel framework that leverages a small
language model (SLM) classifier for initial detection, followed by a LLM as
constrained reasoner to generate detailed explanations for detected
hallucinated content. This study optimizes the real-time interpretable
hallucination detection by introducing effective prompting techniques that
align LLM-generated explanations with SLM decisions. Empirical experiment
results demonstrate its effectiveness, thereby enhancing the overall user
experience.",2024-08-22,"Mengya Hu, Rui Xu, Deren Lei, Yaxi Li, Mingyu Wang, Emily Ching, Eslam Kamal, Alex Deng",http://arxiv.org/pdf/2408.12748v1,cs.CL
SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging,"Recent advances in Text-to-SQL have largely focused on the SQLite dialect,
neglecting the diverse landscape of SQL dialects like BigQuery and PostgreSQL.
This limitation is due to the diversity in SQL syntaxes and functions, along
with the high cost of collecting and curating SQL-specific training data. To
address this, we introduce SQL-GEN, a framework for generating high-quality
synthetic training data for any SQL dialect, guided by readily available
dialect-specific tutorials. SQL-GEN significantly improves cross-dialect
Text-to-SQL performance, boosting execution accuracy by up to 20\% over
existing methods. This performance gain narrows the gap with models trained on
large-scale human-annotated data. Furthermore, combining synthetic data from
SQL-GEN with human-annotated data yields additional improvements of up to
5.6\%. To unify multi-dialect capabilities within a single model, we propose a
novel Mixture-of-Experts (MoE) initialization that leverages the shared
knowledge across dialects. Our approach merges self-attention layers from
dialect-specific models and initializes expert gates using dialect-specific
keywords. This leads to a versatile model optimized for multiple SQL dialects,
outperforming single-dialect models and significantly enhancing overall
performance.",2024-08-22,"Mohammadreza Pourreza, Ruoxi Sun, Hailong Li, Lesly Miculicich, Tomas Pfister, Sercan O. Arik",http://arxiv.org/pdf/2408.12733v2,cs.CL
Macro-Queries: An Exploration into Guided Chart Generation from High Level Prompts,"This paper explores the intersection of data visualization and Large Language
Models (LLMs). Driven by the need to make a broader range of data visualization
types accessible for novice users, we present a guided LLM-based pipeline
designed to transform data, guided by high-level user questions (referred to as
macro-queries), into a diverse set of useful visualizations. This approach
leverages various prompting techniques, fine-tuning inspired by Abela's Chart
Taxonomy, and integrated SQL tool usage.",2024-08-22,"Christopher J. Lee, Giorgio Tran, Roderick Tabalba, Jason Leigh, Ryan Longman",http://arxiv.org/pdf/2408.12726v1,cs.CL
Towards Estimating Personal Values in Song Lyrics,"Most music widely consumed in Western Countries contains song lyrics, with
U.S. samples reporting almost all of their song libraries contain lyrics. In
parallel, social science theory suggests that personal values - the abstract
goals that guide our decisions and behaviors - play an important role in
communication: we share what is important to us to coordinate efforts, solve
problems and meet challenges. Thus, the values communicated in song lyrics may
be similar or different to those of the listener, and by extension affect the
listener's reaction to the song. This suggests that working towards automated
estimation of values in lyrics may assist in downstream MIR tasks, in
particular, personalization. However, as highly subjective text, song lyrics
present a challenge in terms of sampling songs to be annotated, annotation
methods, and in choosing a method for aggregation. In this project, we take a
perspectivist approach, guided by social science theory, to gathering
annotations, estimating their quality, and aggregating them. We then compare
aggregated ratings to estimates based on pre-trained sentence/word embedding
models by employing a validated value dictionary. We discuss conceptually
'fuzzy' solutions to sampling and annotation challenges, promising initial
results in annotation quality and in automated estimations, and future
directions.",2024-08-22,"Andrew M. Demetriou, Jaehun Kim, Sandy Manolios, Cynthia C. S. Liem",http://arxiv.org/pdf/2408.12694v1,cs.CL
Urban Mobility Assessment Using LLMs,"Understanding urban mobility patterns and analyzing how people move around
cities helps improve the overall quality of life and supports the development
of more livable, efficient, and sustainable urban areas. A challenging aspect
of this work is the collection of mobility data by means of user tracking or
travel surveys, given the associated privacy concerns, noncompliance, and high
cost. This work proposes an innovative AI-based approach for synthesizing
travel surveys by prompting large language models (LLMs), aiming to leverage
their vast amount of relevant background knowledge and text generation
capabilities. Our study evaluates the effectiveness of this approach across
various U.S. metropolitan areas by comparing the results against existing
survey data at different granularity levels. These levels include (i) pattern
level, which compares aggregated metrics like the average number of locations
traveled and travel time, (ii) trip level, which focuses on comparing trips as
whole units using transition probabilities, and (iii) activity chain level,
which examines the sequence of locations visited by individuals. Our work
covers several proprietary and open-source LLMs, revealing that open-source
base models like Llama-2, when fine-tuned on even a limited amount of actual
data, can generate synthetic data that closely mimics the actual travel survey
data, and as such provides an argument for using such data in mobility studies.",2024-08-22,"Prabin Bhandari, Antonios Anastasopoulos, Dieter Pfoser",http://arxiv.org/pdf/2409.00063v1,cs.CL
MultiMed: Massively Multimodal and Multitask Medical Understanding,"Biomedical data is inherently multimodal, consisting of electronic health
records, medical imaging, digital pathology, genome sequencing, wearable
sensors, and more. The application of artificial intelligence tools to these
multifaceted sensing technologies has the potential to revolutionize the
prognosis, diagnosis, and management of human health and disease. However,
current approaches to biomedical AI typically only train and evaluate with one
or a small set of medical modalities and tasks. This limitation hampers the
development of comprehensive tools that can leverage the rich interconnected
information across many heterogeneous biomedical sensors. To address this
challenge, we present MultiMed, a benchmark designed to evaluate and enable
large-scale learning across a wide spectrum of medical modalities and tasks.
MultiMed consists of 2.56 million samples across ten medical modalities such as
medical reports, pathology, genomics, and protein data, and is structured into
eleven challenging tasks, including disease prognosis, protein structure
prediction, and medical question answering. Using MultiMed, we conduct
comprehensive experiments benchmarking state-of-the-art unimodal, multimodal,
and multitask models. Our analysis highlights the advantages of training
large-scale medical models across many related modalities and tasks. Moreover,
MultiMed enables studies of generalization across related medical concepts,
robustness to real-world noisy data and distribution shifts, and novel modality
combinations to improve prediction performance. MultiMed will be publicly
available and regularly updated and welcomes inputs from the community.",2024-08-22,"Shentong Mo, Paul Pu Liang",http://arxiv.org/pdf/2408.12682v1,cs.CL
Controllable Text Generation for Large Language Models: A Survey,"In Natural Language Processing (NLP), Large Language Models (LLMs) have
demonstrated high text generation quality. However, in real-world applications,
LLMs must meet increasingly complex requirements. Beyond avoiding misleading or
inappropriate content, LLMs are also expected to cater to specific user needs,
such as imitating particular writing styles or generating text with poetic
richness. These varied demands have driven the development of Controllable Text
Generation (CTG) techniques, which ensure that outputs adhere to predefined
control conditions--such as safety, sentiment, thematic consistency, and
linguistic style--while maintaining high standards of helpfulness, fluency, and
diversity.
  This paper systematically reviews the latest advancements in CTG for LLMs,
offering a comprehensive definition of its core concepts and clarifying the
requirements for control conditions and text quality. We categorize CTG tasks
into two primary types: content control and attribute control. The key methods
are discussed, including model retraining, fine-tuning, reinforcement learning,
prompt engineering, latent space manipulation, and decoding-time intervention.
We analyze each method's characteristics, advantages, and limitations,
providing nuanced insights for achieving generation control. Additionally, we
review CTG evaluation methods, summarize its applications across domains, and
address key challenges in current research, including reduced fluency and
practicality. We also propose several appeals, such as placing greater emphasis
on real-world applications in future research. This paper aims to offer
valuable guidance to researchers and developers in the field. Our reference
list and Chinese version are open-sourced at
https://github.com/IAAR-Shanghai/CTGSurvey.",2024-08-22,"Xun Liang, Hanyu Wang, Yezhaohui Wang, Shichao Song, Jiawei Yang, Simin Niu, Jie Hu, Dan Liu, Shunyu Yao, Feiyu Xiong, Zhiyu Li",http://arxiv.org/pdf/2408.12599v1,cs.CL
RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment,"Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve
performance competitively with human experts across various medical benchmarks.
However, they still face challenges in making professional diagnoses akin to
physicians, particularly in efficiently gathering patient information and
reasoning the final diagnosis. To this end, we introduce the RuleAlign
framework, designed to align LLMs with specific diagnostic rules. We develop a
medical dialogue dataset comprising rule-based communications between patients
and physicians and design an alignment learning approach through preference
learning. Experimental results demonstrate the effectiveness of the proposed
approach. We hope that our work can serve as an inspiration for exploring the
potential of LLMs as AI physicians.",2024-08-22,"Xiaohan Wang, Xiaoyan Yang, Yuqi Zhu, Yue Shen, Jian Wang, Peng Wei, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang",http://arxiv.org/pdf/2408.12579v1,cs.CL
MuMA-ToM: Multi-modal Multi-Agent Theory of Mind,"Understanding people's social interactions in complex real-world scenarios
often relies on intricate mental reasoning. To truly understand how and why
people interact with one another, we must infer the underlying mental states
that give rise to the social interactions, i.e., Theory of Mind reasoning in
multi-agent interactions. Additionally, social interactions are often
multi-modal -- we can watch people's actions, hear their conversations, and/or
read about their past behaviors. For AI systems to successfully and safely
interact with people in real-world environments, they also need to understand
people's mental states as well as their inferences about each other's mental
states based on multi-modal information about their interactions. For this, we
introduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.
MuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates
mental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide
video and text descriptions of people's multi-modal behavior in realistic
household environments. Based on the context, we then ask questions about
people's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM
in a human experiment and provided a human baseline. We also proposed a novel
multi-modal, multi-agent ToM model, LIMP (Language model-based Inverse
Multi-agent Planning). Our experimental results show that LIMP significantly
outperforms state-of-the-art methods, including large multi-modal models (e.g.,
GPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.",2024-08-22,"Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Leyla Isik, Yen-Ling Kuo, Tianmin Shu",http://arxiv.org/pdf/2408.12574v4,cs.CL
Jamba-1.5: Hybrid Transformer-Mamba Models at Scale,"We present Jamba-1.5, new instruction-tuned large language models based on
our Jamba architecture. Jamba is a hybrid Transformer-Mamba mixture of experts
architecture, providing high throughput and low memory usage across context
lengths, while retaining the same or better quality as Transformer models. We
release two model sizes: Jamba-1.5-Large, with 94B active parameters, and
Jamba-1.5-Mini, with 12B active parameters. Both models are fine-tuned for a
variety of conversational and instruction-following capabilties, and have an
effective context length of 256K tokens, the largest amongst open-weight
models. To support cost-effective inference, we introduce ExpertsInt8, a novel
quantization technique that allows fitting Jamba-1.5-Large on a machine with 8
80GB GPUs when processing 256K-token contexts without loss of quality. When
evaluated on a battery of academic and chatbot benchmarks, Jamba-1.5 models
achieve excellent results while providing high throughput and outperforming
other open-weight models on long-context benchmarks. The model weights for both
sizes are publicly available under the Jamba Open Model License and we release
ExpertsInt8 as open source.",2024-08-22,"Jamba Team, Barak Lenz, Alan Arazi, Amir Bergman, Avshalom Manevich, Barak Peleg, Ben Aviram, Chen Almagor, Clara Fridman, Dan Padnos, Daniel Gissin, Daniel Jannai, Dor Muhlgay, Dor Zimberg, Edden M Gerber, Elad Dolev, Eran Krakovsky, Erez Safahi, Erez Schwartz, Gal Cohen, Gal Shachaf, Haim Rozenblum, Hofit Bata, Ido Blass, Inbal Magar, Itay Dalmedigos, Jhonathan Osin, Julie Fadlon, Maria Rozman, Matan Danos, Michael Gokhman, Mor Zusman, Naama Gidron, Nir Ratner, Noam Gat, Noam Rozen, Oded Fried, Ohad Leshno, Omer Antverg, Omri Abend, Opher Lieber, Or Dagan, Orit Cohavi, Raz Alon, Ro'i Belson, Roi Cohen, Rom Gilad, Roman Glozman, Shahar Lev, Shaked Meirom, Tal Delbari, Tal Ness, Tomer Asida, Tom Ben Gal, Tom Braude, Uriya Pumerantz, Yehoshua Cohen, Yonatan Belinkov, Yuval Globerson, Yuval Peleg Levy, Yoav Shoham",http://arxiv.org/pdf/2408.12570v1,cs.CL
Towards Evaluating and Building Versatile Large Language Models for Medicine,"In this study, we present MedS-Bench, a comprehensive benchmark designed to
evaluate the performance of large language models (LLMs) in clinical contexts.
Unlike existing benchmarks that focus on multiple-choice question answering,
MedS-Bench spans 11 high-level clinical tasks, including clinical report
summarization, treatment recommendations, diagnosis, named entity recognition,
and medical concept explanation, among others. We evaluated six leading LLMs,
e.g., MEDITRON, Mistral, InternLM 2, Llama 3, GPT-4, and Claude-3.5 using
few-shot prompting, and found that even the most sophisticated models struggle
with these complex tasks. To address these limitations, we developed MedS-Ins,
a large-scale instruction tuning dataset for medicine. MedS-Ins comprises 58
medically oriented language corpora, totaling 13.5 million samples across 122
tasks. To demonstrate the dataset's utility, we conducted a proof-of-concept
experiment by performing instruction tuning on a lightweight, open-source
medical language model. The resulting model, MMedIns-Llama 3, significantly
outperformed existing models across nearly all clinical tasks. To promote
further advancements in the application of LLMs to clinical challenges, we have
made the MedS-Ins dataset fully accessible and invite the research community to
contribute to its expansion.Additionally, we have launched a dynamic
leaderboard for MedS-Bench, which we plan to regularly update the test set to
track progress and enhance the adaptation of general LLMs to the medical
domain. Leaderboard: https://henrychur.github.io/MedS-Bench/. Github:
https://github.com/MAGIC-AI4Med/MedS-Ins.",2024-08-22,"Chaoyi Wu, Pengcheng Qiu, Jinxin Liu, Hongfei Gu, Na Li, Ya Zhang, Yanfeng Wang, Weidi Xie",http://arxiv.org/pdf/2408.12547v2,cs.CL
The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design,"Embedding models play a crucial role in Natural Language Processing (NLP) by
creating text embeddings used in various tasks such as information retrieval
and assessing semantic text similarity. This paper focuses on research related
to embedding models in the Russian language. It introduces a new
Russian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,
the Russian version extending the Massive Text Embedding Benchmark (MTEB). Our
benchmark includes seven categories of tasks, such as semantic textual
similarity, text classification, reranking, and retrieval.The research also
assesses a representative set of Russian and multilingual models on the
proposed benchmark. The findings indicate that the new model achieves results
that are on par with state-of-the-art models in Russian. We release the model
ru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,
integration into the original framework and a public leaderboard.",2024-08-22,"Artem Snegirev, Maria Tikhonova, Anna Maksimova, Alena Fenogenova, Alexander Abramov",http://arxiv.org/pdf/2408.12503v2,cs.CL
GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models,"Large language models (LLMs) have exhibited remarkable capabilities in
natural language generation, but they have also been observed to magnify
societal biases, particularly those related to gender. In response to this
issue, several benchmarks have been proposed to assess gender bias in LLMs.
However, these benchmarks often lack practical flexibility or inadvertently
introduce biases. To address these shortcomings, we introduce GenderCARE, a
comprehensive framework that encompasses innovative Criteria, bias Assessment,
Reduction techniques, and Evaluation metrics for quantifying and mitigating
gender bias in LLMs. To begin, we establish pioneering criteria for gender
equality benchmarks, spanning dimensions such as inclusivity, diversity,
explainability, objectivity, robustness, and realisticity. Guided by these
criteria, we construct GenderPair, a novel pair-based benchmark designed to
assess gender bias in LLMs comprehensively. Our benchmark provides standardized
and realistic evaluations, including previously overlooked gender groups such
as transgender and non-binary individuals. Furthermore, we develop effective
debiasing techniques that incorporate counterfactual data augmentation and
specialized fine-tuning strategies to reduce gender bias in LLMs without
compromising their overall performance. Extensive experiments demonstrate a
significant reduction in various gender bias benchmarks, with reductions
peaking at over 90% and averaging above 35% across 17 different LLMs.
Importantly, these reductions come with minimal variability in mainstream
language tasks, remaining below 2%. By offering a realistic assessment and
tailored reduction of gender biases, we hope that our GenderCARE can represent
a significant step towards achieving fairness and equity in LLMs. More details
are available at https://github.com/kstanghere/GenderCARE-ccs24.",2024-08-22,"Kunsheng Tang, Wenbo Zhou, Jie Zhang, Aishan Liu, Gelei Deng, Shuai Li, Peigui Qi, Weiming Zhang, Tianwei Zhang, Nenghai Yu",http://arxiv.org/pdf/2408.12494v2,cs.CL
Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese,"In this report, we introduce Vintern-1B, a reliable 1-billion-parameters
multimodal large language model (MLLM) for Vietnamese language tasks. By
integrating the Qwen2-0.5B-Instruct language model with the
InternViT-300M-448px visual model, Vintern-1B is optimized for a range of
applications, including optical character recognition (OCR), document
extraction, and general question-answering in Vietnamese context. The model is
fine-tuned on an extensive dataset of over 3 million image-question-answer
pairs, achieving robust performance and reliable results across multiple
Vietnamese language benchmarks like OpenViVQA and ViTextVQA. Vintern-1B is
small enough to fit into various on-device applications easily. Additionally,
we have open-sourced several Vietnamese vision question answering (VQA)
datasets for text and diagrams, created with Gemini 1.5 Flash. Our models are
available at: https://huggingface.co/5CD-AI/Vintern-1B-v2.",2024-08-22,"Khang T. Doan, Bao G. Huynh, Dung T. Hoang, Thuc D. Pham, Nhat H. Pham, Quan T. M. Nguyen, Bang Q. Vo, Suong N. Hoang",http://arxiv.org/pdf/2408.12480v2,cs.CL
Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing,"Large language models (LLMs) face challenges with internal knowledge
inaccuracies and outdated information. Knowledge editing has emerged as a
pivotal approach to mitigate these issues. Although current knowledge editing
techniques exhibit promising performance in single-hop reasoning tasks, they
show limitations when applied to multi-hop reasoning. Drawing on cognitive
neuroscience and the operational mechanisms of LLMs, we hypothesize that the
residual single-hop knowledge after editing causes edited models to revert to
their original answers when processing multi-hop questions, thereby undermining
their performance in multihop reasoning tasks. To validate this hypothesis, we
conduct a series of experiments that empirically confirm our assumptions.
Building on the validated hypothesis, we propose a novel knowledge editing
method that incorporates a Knowledge Erasure mechanism for Large language model
Editing (KELE). Specifically, we design an erasure function for residual
knowledge and an injection function for new knowledge. Through joint
optimization, we derive the optimal recall vector, which is subsequently
utilized within a rank-one editing framework to update the parameters of
targeted model layers. Extensive experiments on GPT-J and GPT-2 XL demonstrate
that KELE substantially enhances the multi-hop reasoning capability of edited
LLMs.",2024-08-22,"Mengqi Zhang, Bowen Fang, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen, Liang Wang",http://arxiv.org/pdf/2408.12456v1,cs.CL
Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language,"Automated fact-checking is a key strategy to overcome the spread of COVID-19
misinformation on the internet. These systems typically leverage deep learning
approaches through Natural Language Inference (NLI) to verify the truthfulness
of information based on supporting evidence. However, one challenge that arises
in deep learning is performance stagnation due to a lack of knowledge during
training. This study proposes using a Knowledge Graph (KG) as external
knowledge to enhance NLI performance for automated COVID-19 fact-checking in
the Indonesian language. The proposed model architecture comprises three
modules: a fact module, an NLI module, and a classifier module. The fact module
processes information from the KG, while the NLI module handles semantic
relationships between the given premise and hypothesis. The representation
vectors from both modules are concatenated and fed into the classifier module
to produce the final result. The model was trained using the generated
Indonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.
Our study demonstrates that incorporating KGs can significantly improve NLI
performance in fact-checking, achieving the best accuracy of 0,8616. This
suggests that KGs are a valuable component for enhancing NLI performance in
automated fact-checking.",2024-08-22,"Arief Purnama Muharram, Ayu Purwarianti",http://arxiv.org/pdf/2409.00061v1,cs.CL
Positional Description for Numerical Normalization,"We present a Positional Description Scheme (PDS) tailored for digit
sequences, integrating placeholder value information for each digit. Given the
structural limitations of subword tokenization algorithms, language models
encounter critical Text Normalization (TN) challenges when handling numerical
tasks. Our schema addresses this challenge through straightforward
pre-processing, preserving the model architecture while significantly
simplifying number normalization, rendering the problem tractable. This
simplifies the task and facilitates more compact production-ready models
capable of learning from smaller datasets. Furthermore, our investigations
reveal that PDS enhances the arithmetic processing capabilities of language
models, resulting in a relative accuracy improvement of 23% to 51% on complex
arithmetic tasks. We demonstrate that PDS effectively mitigates fatal numerical
normalization errors in neural models, requiring only a modest amount of
training data without rule-based Finite State Transducers (FST). We demonstrate
that PDS is essential for both the Text-To-Speech and Speech Recognition text
processing, enabling effective TN under production constraints.",2024-08-22,"Deepanshu Gupta, Javier Latorre",http://arxiv.org/pdf/2408.12430v1,cs.CL
A Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation,"Large language models (LLMs) often generate content with unsupported or
unverifiable content, known as ""hallucinations."" To address this,
retrieval-augmented LLMs are employed to include citations in their content,
grounding the content in verifiable sources. Despite such developments,
manually assessing how well a citation supports the associated statement
remains a major challenge. Previous studies tackle this challenge by leveraging
faithfulness metrics to estimate citation support automatically. However, they
limit this citation support estimation to a binary classification scenario,
neglecting fine-grained citation support in practical scenarios. To investigate
the effectiveness of faithfulness metrics in fine-grained scenarios, we propose
a comparative evaluation framework that assesses the metric effectiveness in
distinguishing citations between three-category support levels: full, partial,
and no support. Our framework employs correlation analysis, classification
evaluation, and retrieval evaluation to measure the alignment between metric
scores and human judgments comprehensively. Our results indicate no single
metric consistently excels across all evaluations, highlighting the complexity
of accurately evaluating fine-grained support levels. Particularly, we find
that the best-performing metrics struggle to distinguish partial support from
full or no support. Based on these findings, we provide practical
recommendations for developing more effective metrics.",2024-08-22,"Weijia Zhang, Mohammad Aliannejadi, Jiahuan Pei, Yifei Yuan, Jia-Hong Huang, Evangelos Kanoulas",http://arxiv.org/pdf/2408.12398v1,cs.CL
CLEANANERCorp: Identifying and Correcting Incorrect Labels in the ANERcorp Dataset,"Label errors are a common issue in machine learning datasets, particularly
for tasks such as Named Entity Recognition. Such label errors might hurt model
training, affect evaluation results, and lead to an inaccurate assessment of
model performance. In this study, we dived deep into one of the widely adopted
Arabic NER benchmark datasets (ANERcorp) and found a significant number of
annotation errors, missing labels, and inconsistencies. Therefore, in this
study, we conducted empirical research to understand these errors, correct them
and propose a cleaner version of the dataset named CLEANANERCorp. CLEANANERCorp
will serve the research community as a more accurate and consistent benchmark.",2024-08-22,"Mashael Al-Duwais, Hend Al-Khalifa, Abdulmalik Al-Salman",http://arxiv.org/pdf/2408.12362v2,cs.CL
Fine-tuning Smaller Language Models for Question Answering over Financial Documents,"Recent research has shown that smaller language models can acquire
substantial reasoning abilities when fine-tuned with reasoning exemplars
crafted by a significantly larger teacher model. We explore this paradigm for
the financial domain, focusing on the challenge of answering questions that
require multi-hop numerical reasoning over financial texts. We assess the
performance of several smaller models that have been fine-tuned to generate
programs that encode the required financial reasoning and calculations. Our
findings demonstrate that these fine-tuned smaller models approach the
performance of the teacher model.
  To provide a granular analysis of model performance, we propose an approach
to investigate the specific student model capabilities that are enhanced by
fine-tuning. Our empirical analysis indicates that fine-tuning refines the
student models ability to express and apply the required financial concepts
along with adapting the entity extraction for the specific data format. In
addition, we hypothesize and demonstrate that comparable financial reasoning
capability can be induced using relatively smaller datasets.",2024-08-22,"Karmvir Singh Phogat, Sai Akhil Puranam, Sridhar Dasaratha, Chetan Harsha, Shashishekar Ramakrishna",http://arxiv.org/pdf/2408.12337v1,cs.CL
Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models,"Large Language Models (LLMs) have demonstrated exceptional capabilities
across various machine learning (ML) tasks. Given the high costs of creating
annotated datasets for supervised learning, LLMs offer a valuable alternative
by enabling effective few-shot in-context learning. However, these models can
produce hallucinations, particularly in domains with incomplete knowledge.
Additionally, current methods for knowledge distillation using LLMs often
struggle to enhance the effectiveness of both teacher and student models. To
address these challenges, we introduce DualChecker, an innovative framework
designed to mitigate hallucinations and improve the performance of both teacher
and student models during knowledge distillation. DualChecker employs
ContextAligner to ensure that the context provided by teacher models aligns
with human labeling standards. It also features a dynamic checker system that
enhances model interaction: one component re-prompts teacher models with more
detailed content when they show low confidence, and another identifies
borderline cases from student models to refine the teaching templates. This
interactive process promotes continuous improvement and effective knowledge
transfer between the models. We evaluate DualChecker using a green innovation
textual dataset that includes binary, multiclass, and token classification
tasks. The experimental results show that DualChecker significantly outperforms
existing state-of-the-art methods, achieving up to a 17% improvement in F1
score for teacher models and 10% for student models. Notably, student models
fine-tuned with LLM predictions perform comparably to those fine-tuned with
actual data, even in a challenging domain. We make all datasets, models, and
code from this research publicly available.",2024-08-22,"Meiyun Wang, Masahiro Suzuki, Hiroki Sakaji, Kiyoshi Izumi",http://arxiv.org/pdf/2408.12326v1,cs.CL
Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators,"Despite their remarkable capabilities, Large Language Models (LLMs) are prone
to generate responses that contradict verifiable facts, i.e., unfaithful
hallucination content. Existing efforts generally focus on optimizing model
parameters or editing semantic representations, which compromise the internal
factual knowledge of target LLMs. In addition, hallucinations typically exhibit
multifaceted patterns in downstream tasks, limiting the model's holistic
performance across tasks. In this paper, we propose a Comparator-driven
Decoding-Time (CDT) framework to alleviate the response hallucination. Firstly,
we construct hallucinatory and truthful comparators with multi-task fine-tuning
samples. In this case, we present an instruction prototype-guided mixture of
experts strategy to enhance the ability of the corresponding comparators to
capture different hallucination or truthfulness patterns in distinct task
instructions. CDT constrains next-token predictions to factuality-robust
distributions by contrasting the logit differences between the target LLMs and
these comparators. Systematic experiments on multiple downstream tasks show
that our framework can significantly improve the model performance and response
factuality.",2024-08-22,"Dingkang Yang, Dongling Xiao, Jinjie Wei, Mingcheng Li, Zhaoyu Chen, Ke Li, Lihua Zhang",http://arxiv.org/pdf/2408.12325v5,cs.CL
MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model,"This paper presents MaVEn, an innovative Multi-granularity Visual Encoding
framework designed to enhance the capabilities of Multimodal Large Language
Models (MLLMs) in multi-image reasoning. Current MLLMs primarily focus on
single-image visual understanding, limiting their ability to interpret and
integrate information across multiple images. MaVEn addresses this limitation
by combining discrete visual symbol sequences, which abstract coarse-grained
semantic concepts, with traditional continuous representation sequences that
model fine-grained features. This dual approach bridges the semantic gap
between visual and textual data, thereby improving the model's ability to
process and interpret information from multiple images effectively.
Additionally, we design a dynamic reduction mechanism by for long-sequence
continuous features to enhance multi-image processing efficiency. Experimental
results demonstrate that MaVEn significantly enhances MLLMs' understanding in
complex multi-image scenarios, while also improving performance in single-image
contexts.",2024-08-22,"Chaoya Jiang, Jia Hongrui, Haiyang Xu, Wei Ye, Mengfan Dong, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang",http://arxiv.org/pdf/2408.12321v2,cs.CL
Large Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations,"Guiding large language models with a selected set of human-authored
demonstrations is a common practice for improving LLM applications. However,
human effort can be costly, especially in specialized domains (e.g., clinical
diagnosis), and does not guarantee optimal performance due to the potential
discrepancy of target skills between selected demonstrations and real test
instances. Motivated by these, this paper explores the automatic creation of
customized demonstrations, whose target skills align with the given target
instance. We present SELF-TAUGHT, a problem-solving framework, which
facilitates demonstrations that are ""tailored"" to the target problem and
""filtered"" for better quality (i.e., correctness) in a zero-shot manner. In 15
tasks of multiple-choice questions of diverse domains and the diagnosis of
Alzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves
superior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,
Auto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its
generalizability to existing prompting methods and different LLMs, the quality
of its intermediate generation, and more.",2024-08-22,"Kai Tzu-iunn Ong, Taeyoon Kwon, Jinyoung Yeo",http://arxiv.org/pdf/2408.12315v1,cs.CL
Toward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates,"The natural language understanding (NLU) performance of large language models
(LLMs) has been evaluated across various tasks and datasets. The existing
evaluation methods, however, do not take into account the variance in scores
due to differences in prompts, which leads to unfair evaluation and comparison
of NLU performance. Moreover, evaluation designed for specific prompts is
inappropriate for instruction tuning, which aims to perform well with any
prompt. It is therefore necessary to find a way to measure NLU performance in a
fair manner, considering score variance between different instruction
templates. In this study, we provide English and Japanese cross-lingual
datasets for evaluating the NLU performance of LLMs, which include multiple
instruction templates for fair evaluation of each task, along with regular
expressions to constrain the output format. Furthermore, we propose the Sharpe
score as an evaluation metric that takes into account the variance in scores
between templates. Comprehensive analysis of English and Japanese LLMs reveals
that the high variance among templates has a significant impact on the fair
evaluation of LLMs.",2024-08-22,"Yusuke Sakai, Adam Nohejl, Jiangnan Hang, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2408.12263v1,cs.CL
A Language-agnostic Model of Child Language Acquisition,"This work reimplements a recent semantic bootstrapping child-language
acquisition model, which was originally designed for English, and trains it to
learn a new language: Hebrew. The model learns from pairs of utterances and
logical forms as meaning representations, and acquires both syntax and word
meanings simultaneously. The results show that the model mostly transfers to
Hebrew, but that a number of factors, including the richer morphology in
Hebrew, makes the learning slower and less robust. This suggests that a clear
direction for future work is to enable the model to leverage the similarities
between different word forms.",2024-08-22,"Louis Mahon, Omri Abend, Uri Berger, Katherine Demuth, Mark Johnson, Mark Steedman",http://arxiv.org/pdf/2408.12254v1,cs.CL
LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction,"Large Language Models (LLMs) are increasingly adopted for applications in
healthcare, reaching the performance of domain experts on tasks such as
question answering and document summarisation. Despite their success on these
tasks, it is unclear how well LLMs perform on tasks that are traditionally
pursued in the biomedical domain, such as structured information extraction. To
bridge this gap, in this paper, we systematically benchmark LLM performance in
Medical Classification and Named Entity Recognition (NER) tasks. We aim to
disentangle the contribution of different factors to the performance,
particularly the impact of LLMs' task knowledge and reasoning capabilities,
their (parametric) domain knowledge, and addition of external knowledge. To
this end, we evaluate various open LLMs - including BioMistral and Llama-2
models - on a diverse set of biomedical datasets, using standard prompting,
Chain of-Thought (CoT) and Self Consistency based reasoning as well as
Retrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora. Counter
intuitively, our results reveal that standard prompting consistently
outperforms more complex techniques across both tasks, laying bare the
limitations in the current application of CoT, self-consistency and RAG in the
biomedical domain. Our findings suggest that advanced prompting methods
developed for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are
not easily portable to biomedical tasks where precise structured outputs are
required. This highlights the need for more effective integration of external
knowledge and reasoning mechanisms in LLMs to enhance their performance in
real-world biomedical applications.",2024-08-22,"Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler",http://arxiv.org/pdf/2408.12249v2,cs.CL
Optimizing Performance: How Compact Models Match or Exceed GPT's Classification Capabilities through Fine-Tuning,"In this paper, we demonstrate that non-generative, small-sized models such as
FinBERT and FinDRoBERTa, when fine-tuned, can outperform GPT-3.5 and GPT-4
models in zero-shot learning settings in sentiment analysis for financial news.
These fine-tuned models show comparable results to GPT-3.5 when it is
fine-tuned on the task of determining market sentiment from daily financial
news summaries sourced from Bloomberg. To fine-tune and compare these models,
we created a novel database, which assigns a market score to each piece of news
without human interpretation bias, systematically identifying the mentioned
companies and analyzing whether their stocks have gone up, down, or remained
neutral. Furthermore, the paper shows that the assumptions of Condorcet's Jury
Theorem do not hold suggesting that fine-tuned small models are not independent
of the fine-tuned GPT models, indicating behavioural similarities. Lastly, the
resulted fine-tuned models are made publicly available on HuggingFace,
providing a resource for further research in financial sentiment analysis and
text classification.",2024-08-22,"Baptiste Lefort, Eric Benhamou, Jean-Jacques Ohana, David Saltiel, Beatrice Guez",http://arxiv.org/pdf/2409.11408v1,cs.CL
EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts,"Relying on human experts to evaluate CEFR speaking assessments in an
e-learning environment creates scalability challenges, as it limits how quickly
and widely assessments can be conducted. We aim to automate the evaluation of
CEFR B2 English speaking assessments in e-learning environments from
conversation transcripts. First, we evaluate the capability of leading open
source and commercial Large Language Models (LLMs) to score a candidate's
performance across various criteria in the CEFR B2 speaking exam in both global
and India-specific contexts. Next, we create a new expert-validated,
CEFR-aligned synthetic conversational dataset with transcripts that are rated
at different assessment scores. In addition, new instruction-tuned datasets are
developed from the English Vocabulary Profile (up to CEFR B2 level) and the
CEFR-SP WikiAuto datasets. Finally, using these new datasets, we perform
parameter efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a
family of models called EvalYaks. Four models in this family are for assessing
the four sections of the CEFR B2 speaking exam, one for identifying the CEFR
level of vocabulary and generating level-specific vocabulary, and another for
detecting the CEFR level of text and generating level-specific text. EvalYaks
achieved an average acceptable accuracy of 96%, a degree of variation of 0.35
levels, and performed 3 times better than the next best model. This
demonstrates that a 7B parameter LLM instruction tuned with high-quality
CEFR-aligned assessment data can effectively evaluate and score CEFR B2 English
speaking assessments, offering a promising solution for scalable, automated
language proficiency evaluation.",2024-08-22,"Nicy Scaria, Silvester John Joseph Kennedy, Thomas Latinovich, Deepak Subramani",http://arxiv.org/pdf/2408.12226v1,cs.CL
NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations,"This paper describes the architecture of our system developed for Task 3 of
SemEval-2024: Multimodal Emotion-Cause Analysis in Conversations. Our project
targets the challenges of subtask 2, dedicated to Multimodal Emotion-Cause Pair
Extraction with Emotion Category (MECPE-Cat), and constructs a dual-component
system tailored to the unique challenges of this task. We divide the task into
two subtasks: emotion recognition in conversation (ERC) and emotion-cause pair
extraction (ECPE). To address these subtasks, we capitalize on the abilities of
Large Language Models (LLMs), which have consistently demonstrated
state-of-the-art performance across various natural language processing tasks
and domains. Most importantly, we design an approach of emotion-cause-aware
instruction-tuning for LLMs, to enhance the perception of the emotions with
their corresponding causal rationales. Our method enables us to adeptly
navigate the complexities of MECPE-Cat, achieving a weighted average 34.71% F1
score of the task, and securing the 2nd rank on the leaderboard. The code and
metadata to reproduce our experiments are all made publicly available.",2024-08-22,"Meng Luo, Han Zhang, Shengqiong Wu, Bobo Li, Hong Han, Hao Fei",http://arxiv.org/pdf/2501.17261v1,cs.CL
Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment,"Pretrained language models like BERT and T5 serve as crucial backbone
encoders for dense retrieval. However, these models often exhibit limited
generalization capabilities and face challenges in improving in domain
accuracy. Recent research has explored using large language models (LLMs) as
retrievers, achieving SOTA performance across various tasks. Despite these
advancements, the specific benefits of LLMs over traditional retrievers and the
impact of different LLM configurations, such as parameter sizes, pretraining
duration, and alignment processes on retrieval tasks remain unclear. In this
work, we conduct a comprehensive empirical study on a wide range of retrieval
tasks, including in domain accuracy, data efficiency, zero shot generalization,
lengthy retrieval, instruction based retrieval, and multi task learning. We
evaluate over 15 different backbone LLMs and non LLMs. Our findings reveal that
larger models and extensive pretraining consistently enhance in domain accuracy
and data efficiency. Additionally, larger models demonstrate significant
potential in zero shot generalization, lengthy retrieval, instruction based
retrieval, and multi task learning. These results underscore the advantages of
LLMs as versatile and effective backbone encoders in dense retrieval, providing
valuable insights for future research and development in this field.",2024-08-22,"Kun Luo, Minghao Qin, Zheng Liu, Shitao Xiao, Jun Zhao, Kang Liu",http://arxiv.org/pdf/2408.12194v2,cs.CL
Reasoning Factual Knowledge in Structured Data with Large Language Models,"Large language models (LLMs) have made remarkable progress in various natural
language processing tasks as a benefit of their capability to comprehend and
reason with factual knowledge. However, a significant amount of factual
knowledge is stored in structured data, which possesses unique characteristics
that differ from the unstructured texts used for pretraining. This difference
can introduce imperceptible inference parameter deviations, posing challenges
for LLMs in effectively utilizing and reasoning with structured data to
accurately infer factual knowledge. To this end, we propose a benchmark named
StructFact, to evaluate the structural reasoning capabilities of LLMs in
inferring factual knowledge. StructFact comprises 8,340 factual questions
encompassing various tasks, domains, timelines, and regions. This benchmark
allows us to investigate the capability of LLMs across five factual tasks
derived from the unique characteristics of structural facts. Extensive
experiments on a set of LLMs with different training strategies reveal the
limitations of current LLMs in inferring factual knowledge from structured
data. We present this benchmark as a compass to navigate the strengths and
weaknesses of LLMs in reasoning with structured data for knowledge-sensitive
tasks, and to encourage advancements in related real-world applications. Please
find our code at https://github.com/EganGu/StructFact.",2024-08-22,"Sirui Huang, Yanggan Gu, Xuming Hu, Zhonghao Li, Qing Li, Guandong Xu",http://arxiv.org/pdf/2408.12188v1,cs.CL
Revisiting the Phenomenon of Syntactic Complexity Convergence on German Dialogue Data,"We revisit the phenomenon of syntactic complexity convergence in
conversational interaction, originally found for English dialogue, which has
theoretical implication for dialogical concepts such as mutual understanding.
We use a modified metric to quantify syntactic complexity based on dependency
parsing. The results show that syntactic complexity convergence can be
statistically confirmed in one of three selected German datasets that were
analysed. Given that the dataset which shows such convergence is much larger
than the other two selected datasets, the empirical results indicate a certain
degree of linguistic generality of syntactic complexity convergence in
conversational interaction. We also found a different type of syntactic
complexity convergence in one of the datasets while further investigation is
still necessary.",2024-08-22,"Yu Wang, Hendrik Buschmeier",http://arxiv.org/pdf/2408.12177v1,cs.CL
FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation,"Large language models (LLMs) have become increasingly prevalent in our daily
lives, leading to an expectation for LLMs to be trustworthy -- - both accurate
and well-calibrated (the prediction confidence should align with its ground
truth correctness likelihood). Nowadays, fine-tuning has become the most
popular method for adapting a model to practical usage by significantly
increasing accuracy on downstream tasks. Despite the great accuracy it
achieves, we found fine-tuning is still far away from satisfactory
trustworthiness due to ""tuning-induced mis-calibration"". In this paper, we
delve deeply into why and how mis-calibration exists in fine-tuned models, and
how distillation can alleviate the issue. Then we further propose a brand new
method named Efficient Trustworthy Distillation (FIRST), which utilizes a small
portion of teacher's knowledge to obtain a reliable language model in a
cost-efficient way. Specifically, we identify the ""concentrated knowledge""
phenomenon during distillation, which can significantly reduce the
computational burden. Then we apply a ""trustworthy maximization"" process to
optimize the utilization of this small portion of concentrated knowledge before
transferring it to the student. Experimental results demonstrate the
effectiveness of our method, where better accuracy (+2.3%) and less
mis-calibration (-10%) are achieved on average across both in-domain and
out-of-domain scenarios, indicating better trustworthiness.",2024-08-22,"KaShun Shum, Minrui Xu, Jianshu Zhang, Zixin Chen, Shizhe Diao, Hanze Dong, Jipeng Zhang, Muhammad Omer Raza",http://arxiv.org/pdf/2408.12168v2,cs.CL
Preference-Guided Reflective Sampling for Aligning Language Models,"Iterative data generation and model re-training can effectively align large
language models(LLMs) to human preferences. The process of data sampling is
crucial, as it significantly influences the success of policy improvement.
Repeated random sampling is a widely used method that independently queries the
model multiple times to generate outputs. In this work, we propose a more
effective sampling method, named Preference-Guided Reflective Sampling (PRS).
Unlike random sampling, PRS employs a tree-based generation framework to enable
more efficient sampling. It leverages adaptive self-refinement techniques to
better explore the sampling space. By specifying user preferences in natural
language, PRS can further optimize response generation according to these
preferences. As a result, PRS can align models to diverse user preferences. Our
experiments demonstrate that PRS generates higher-quality responses with
significantly higher rewards. On AlpacaEval and Arena-Hard, PRS substantially
outperforms repeated random sampling in best-of-$N$ sampling. Moreover, PRS
shows strong performance when applied in iterative offline RL training.",2024-08-22,"Hai Ye, Hwee Tou Ng",http://arxiv.org/pdf/2408.12163v2,cs.CL
Search-Based LLMs for Code Optimization,"The code written by developers usually suffers from efficiency problems and
contain various performance bugs. These inefficiencies necessitate the research
of automated refactoring methods for code optimization. Early research in code
optimization employs rule-based methods and focuses on specific inefficiency
issues, which are labor-intensive and suffer from the low coverage issue.
Recent work regards the task as a sequence generation problem, and resorts to
deep learning (DL) techniques such as large language models (LLMs). These
methods typically prompt LLMs to directly generate optimized code. Although
these methods show state-of-the-art performance, such one-step generation
paradigm is hard to achieve an optimal solution. First, complex optimization
methods such as combinatorial ones are hard to be captured by LLMs. Second, the
one-step generation paradigm poses challenge in precisely infusing the
knowledge required for effective code optimization within LLMs, resulting in
under-optimized code.To address these problems, we propose to model this task
from the search perspective, and propose a search-based LLMs framework named
SBLLM that enables iterative refinement and discovery of improved optimization
methods. SBLLM synergistically integrate LLMs with evolutionary search and
consists of three key components: 1) an execution-based representative sample
selection part that evaluates the fitness of each existing optimized code and
prioritizes promising ones to pilot the generation of improved code; 2) an
adaptive optimization pattern retrieval part that infuses targeted optimization
patterns into the model for guiding LLMs towards rectifying and progressively
enhancing their optimization methods; and 3) a genetic operator-inspired
chain-of-thought prompting part that aids LLMs in combining different
optimization methods and generating improved optimization methods.",2024-08-22,"Shuzheng Gao, Cuiyun Gao, Wenchao Gu, Michael Lyu",http://arxiv.org/pdf/2408.12159v1,cs.CL
Implicit Sentiment Analysis Based on Chain of Thought Prompting,"Implicit Sentiment Analysis (ISA) is a crucial research area in natural
language processing. Inspired by the idea of large language model Chain of
Thought (CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT)
framework. The framework first analyzes the implicit aspects and opinions in
the text using common sense and thinking chain capabilities. Then, it reflects
on the process of implicit sentiment analysis and finally deduces the polarity
of sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of
1120 restaurant reviews and 638 laptop reviews. The experimental results
demonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable
performance improvement. Specifically, on the restaurant dataset, the F1 score
reaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer
dataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46.
Comparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp + SCAPt
baseline by an average margin of 47.99%.",2024-08-22,"Zhihua Duan, Jialin Wang",http://arxiv.org/pdf/2408.12157v1,cs.CL
A Tighter Complexity Analysis of SparseGPT,"In this work, we improved the analysis of the running time of SparseGPT
[Frantar, Alistarh ICML 2023] from $O(d^{3})$ to $O(d^{\omega} + d^{2+a+o(1)} +
d^{1+\omega(1,1,a)-a})$ for any $a \in [0, 1]$, where $\omega$ is the exponent
of matrix multiplication. In particular, for the current $\omega \approx 2.371$
[Alman, Duan, Williams, Xu, Xu, Zhou 2024], our running time boils down to
$O(d^{2.53})$. This running time is due to the analysis of the lazy update
behavior in iterative maintenance problems such as [Deng, Song, Weinstein 2022;
Brand, Song, Zhou ICML 2024].",2024-08-22,"Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song",http://arxiv.org/pdf/2408.12151v2,cs.CL
MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents,"The clinical diagnosis of most mental disorders primarily relies on the
conversations between psychiatrist and patient. The creation of such diagnostic
conversation datasets is promising to boost the AI mental healthcare community.
However, directly collecting the conversations in real diagnosis scenarios is
near impossible due to stringent privacy and ethical considerations. To address
this issue, we seek to synthesize diagnostic conversation by exploiting
anonymized patient cases that are easier to access. Specifically, we design a
neuro-symbolic multi-agent framework for synthesizing the diagnostic
conversation of mental disorders with large language models. It takes patient
case as input and is capable of generating multiple diverse conversations with
one single patient case. The framework basically involves the interaction
between a doctor agent and a patient agent, and generates conversations under
symbolic control via a dynamic diagnosis tree. By applying the proposed
framework, we develop the largest Chinese mental disorders diagnosis dataset
MDD-5k. This dataset is built upon 1000 real, anonymized patient cases by
cooperating with Shanghai Mental Health Center and comprises 5000 high-quality
long conversations with diagnosis results and treatment opinions as labels. To
the best of our knowledge, it's also the first labeled dataset for Chinese
mental disorders diagnosis. Human evaluation demonstrates the proposed MDD-5k
dataset successfully simulates human-like diagnostic process of mental
disorders.",2024-08-22,"Congchi Yin, Feng Li, Shu Zhang, Zike Wang, Jun Shao, Piji Li, Jianhua Chen, Xun Jiang",http://arxiv.org/pdf/2408.12142v2,cs.CL
Understanding Literary Texts by LLMs: A Case Study of Ancient Chinese Poetry,"The birth and rapid development of large language models (LLMs) have caused
quite a stir in the field of literature. Once considered unattainable, AI's
role in literary creation is increasingly becoming a reality. In genres such as
poetry, jokes, and short stories, numerous AI tools have emerged, offering
refreshing new perspectives. However, it's difficult to further improve the
quality of these works. This is primarily because understanding and
appreciating a good literary work involves a considerable threshold, such as
knowledge of literary theory, aesthetic sensibility, interdisciplinary
knowledge. Therefore, authoritative data in this area is quite lacking.
Additionally, evaluating literary works is often complex and hard to fully
quantify, which directly hinders the further development of AI creation.
  To address this issue, this paper attempts to explore the mysteries of
literary texts from the perspective of LLMs, using ancient Chinese poetry as an
example for experimentation. First, we collected a variety of ancient poems
from different sources and had experts annotate a small portion of them. Then,
we designed a range of comprehension metrics based on LLMs to evaluate all
these poems. Finally, we analyzed the correlations and differences between
various poem collections to identify literary patterns. Through our
experiments, we observed a series of enlightening phenomena that provide
technical support for the future development of high-level literary creation
based on LLMs.",2024-08-22,"Cheng Zhao, Bin Wang, Zhen Wang",http://arxiv.org/pdf/2409.00060v2,cs.CL
RoVRM: A Robust Visual Reward Model Optimized via Auxiliary Textual Preference Data,"Large vision-language models (LVLMs) often fail to align with human
preferences, leading to issues like generating misleading content without
proper visual context (also known as hallucination). A promising solution to
this problem is using human-preference alignment techniques, such as best-of-n
sampling and reinforcement learning. However, these techniques face the
difficulty arising from the scarcity of visual preference data, which is
required to train a visual reward model (VRM). In this work, we continue the
line of research. We present a Robust Visual Reward Model (RoVRM) which
improves human-preference alignment for LVLMs. RoVRM leverages auxiliary
textual preference data through a three-phase progressive training and optimal
transport-based preference data selection to effectively mitigate the scarcity
of visual preference data. We experiment with RoVRM on the commonly used
vision-language tasks based on the LLaVA-1.5-7B and -13B models. Experimental
results demonstrate that RoVRM consistently outperforms traditional VRMs.
Furthermore, our three-phase progressive training and preference data selection
approaches can yield consistent performance gains over ranking-based alignment
techniques, such as direct preference optimization.",2024-08-22,"Chenglong Wang, Yang Gan, Yifu Huo, Yongyu Mu, Murun Yang, Qiaozhi He, Tong Xiao, Chunliang Zhang, Tongran Liu, Quan Du, Di Yang, Jingbo Zhu",http://arxiv.org/pdf/2408.12109v2,cs.CL
"Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis","Machine learning is widely utilized across various industries. Identifying
the appropriate machine learning models and datasets for specific tasks is
crucial for the effective industrial application of machine learning. However,
this requires expertise in both machine learning and the relevant domain,
leading to a high learning cost. Therefore, research focused on extracting
combinations of tasks, machine learning models, and datasets from academic
papers is critically important, as it can facilitate the automatic
recommendation of suitable methods. Conventional information extraction methods
from academic papers have been limited to identifying machine learning models
and other entities as named entities. To address this issue, this study
proposes a methodology extracting tasks, machine learning methods, and dataset
names from scientific papers and analyzing the relationships between these
information by using LLM, embedding model, and network clustering. The proposed
method's expression extraction performance, when using Llama3, achieves an
F-score exceeding 0.8 across various categories, confirming its practical
utility. Benchmarking results on financial domain papers have demonstrated the
effectiveness of this method, providing insights into the use of the latest
datasets, including those related to ESG (Environmental, Social, and
Governance) data.",2024-08-22,"S. Nishio, H. Nonaka, N. Tsuchiya, A. Migita, Y. Banno, T. Hayashi, H. Sakaji, T. Sakumoto, K. Watabe",http://arxiv.org/pdf/2408.12097v1,cs.CL
uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization,"Medical abstractive summarization faces the challenge of balancing
faithfulness and informativeness. Current methods often sacrifice key
information for faithfulness or introduce confabulations when prioritizing
informativeness. While recent advancements in techniques like in-context
learning (ICL) and fine-tuning have improved medical summarization, they often
overlook crucial aspects such as faithfulness and informativeness without
considering advanced methods like model reasoning and self-improvement.
Moreover, the field lacks a unified benchmark, hindering systematic evaluation
due to varied metrics and datasets. This paper addresses these gaps by
presenting a comprehensive benchmark of six advanced abstractive summarization
methods across three diverse datasets using five standardized metrics. Building
on these findings, we propose uMedSum, a modular hybrid summarization framework
that introduces novel approaches for sequential confabulation removal followed
by key missing information addition, ensuring both faithfulness and
informativeness. Our work improves upon previous GPT-4-based state-of-the-art
(SOTA) medical summarization methods, significantly outperforming them in both
quantitative metrics and qualitative domain expert evaluations. Notably, we
achieve an average relative performance improvement of 11.8% in reference-free
metrics over the previous SOTA. Doctors prefer uMedSum's summaries 6 times more
than previous SOTA in difficult cases where there are chances of confabulations
or missing information. These results highlight uMedSum's effectiveness and
generalizability across various datasets and metrics, marking a significant
advancement in medical summarization.",2024-08-22,"Aishik Nagar, Yutong Liu, Andy T. Liu, Viktor Schlegel, Vijay Prakash Dwivedi, Arun-Kumar Kaliya-Perumal, Guna Pratheep Kalanchiam, Yili Tang, Robby T. Tan",http://arxiv.org/pdf/2408.12095v2,cs.CL
"High-Quality Data Augmentation for Low-Resource NMT: Combining a Translation Memory, a GAN Generator, and Filtering","Back translation, as a technique for extending a dataset, is widely used by
researchers in low-resource language translation tasks. It typically translates
from the target to the source language to ensure high-quality translation
results. This paper proposes a novel way of utilizing a monolingual corpus on
the source side to assist Neural Machine Translation (NMT) in low-resource
settings. We realize this concept by employing a Generative Adversarial Network
(GAN), which augments the training data for the discriminator while mitigating
the interference of low-quality synthetic monolingual translations with the
generator. Additionally, this paper integrates Translation Memory (TM) with
NMT, increasing the amount of data available to the generator. Moreover, we
propose a novel procedure to filter the synthetic sentence pairs during the
augmentation process, ensuring the high quality of the data.",2024-08-22,"Hengjie Liu, Ruibo Hou, Yves Lepage",http://arxiv.org/pdf/2408.12079v1,cs.CL
ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM,"Large language models (LLMs) have achieved impressive advancements across
numerous disciplines, yet the critical issue of knowledge conflicts, a major
source of hallucinations, has rarely been studied. Only a few research explored
the conflicts between the inherent knowledge of LLMs and the retrieved
contextual knowledge. However, a thorough assessment of knowledge conflict in
LLMs is still missing. Motivated by this research gap, we present ConflictBank,
the first comprehensive benchmark developed to systematically evaluate
knowledge conflicts from three aspects: (i) conflicts encountered in retrieved
knowledge, (ii) conflicts within the models' encoded knowledge, and (iii) the
interplay between these conflict forms. Our investigation delves into four
model families and twelve LLM instances, meticulously analyzing conflicts
stemming from misinformation, temporal discrepancies, and semantic divergences.
Based on our proposed novel construction framework, we create 7,453,853
claim-evidence pairs and 553,117 QA pairs. We present numerous findings on
model scale, conflict causes, and conflict types. We hope our ConflictBank
benchmark will help the community better understand model behavior in conflicts
and develop more reliable LLMs.",2024-08-22,"Zhaochen Su, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, Yu Cheng",http://arxiv.org/pdf/2408.12076v1,cs.CL
Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs,"Given the widespread dissemination of misinformation on social media,
implementing fact-checking mechanisms for online claims is essential. Manually
verifying every claim is very challenging, underscoring the need for an
automated fact-checking system. This paper presents our system designed to
address this issue. We utilize the Averitec dataset (Schlichtkrull et al.,
2023) to assess the performance of our fact-checking system. In addition to
veracity prediction, our system provides supporting evidence, which is
extracted from the dataset. We develop a Retrieve and Generate (RAG) pipeline
to extract relevant evidence sentences from a knowledge base, which are then
inputted along with the claim into a large language model (LLM) for
classification. We also evaluate the few-shot In-Context Learning (ICL)
capabilities of multiple LLMs. Our system achieves an 'Averitec' score of 0.33,
which is a 22% absolute improvement over the baseline. Our Code is publicly
available on
https://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms.",2024-08-22,"Ronit Singhal, Pransh Patwa, Parth Patwa, Aman Chadha, Amitava Das",http://arxiv.org/pdf/2408.12060v2,cs.CL
Aligning (Medical) LLMs for (Counterfactual) Fairness,"Large Language Models (LLMs) have emerged as promising solutions for a
variety of medical and clinical decision support applications. However, LLMs
are often subject to different types of biases, which can lead to unfair
treatment of individuals, worsening health disparities, and reducing trust in
AI-augmented medical tools. Aiming to address this important issue, in this
study, we present a new model alignment approach for aligning LLMs using a
preference optimization method within a knowledge distillation framework. Prior
to presenting our proposed method, we first use an evaluation framework to
conduct a comprehensive (largest to our knowledge) empirical evaluation to
reveal the type and nature of existing biases in LLMs used for medical
applications. We then offer a bias mitigation technique to reduce the unfair
patterns in LLM outputs across different subgroups identified by the protected
attributes. We show that our mitigation method is effective in significantly
reducing observed biased patterns. Our code is publicly available at
\url{https://github.com/healthylaife/FairAlignmentLLM}.",2024-08-22,"Raphael Poulain, Hamed Fayyaz, Rahmatollah Beheshti",http://arxiv.org/pdf/2408.12055v1,cs.CL
Reasoning and Tools for Human-Level Forecasting,"Language models (LMs) trained on web-scale datasets are largely successful
due to their ability to memorize large amounts of training data, even if only
present in a few examples. These capabilities are often desirable in evaluation
on tasks such as question answering but raise questions about whether these
models can exhibit genuine reasoning or succeed only at mimicking patterns from
the training data. This distinction is particularly salient in forecasting
tasks, where the answer is not present in the training data, and the model must
reason to make logical deductions. We present Reasoning and Tools for
Forecasting (RTF), a framework of reasoning-and-acting (ReAct) agents that can
dynamically retrieve updated information and run numerical simulation with
equipped tools. We evaluate our model with questions from competitive
forecasting platforms and demonstrate that our method is competitive with and
can outperform human predictions. This suggests that LMs, with the right tools,
can indeed think and adapt like humans, offering valuable insights for
real-world decision-making.",2024-08-21,"Elvis Hsieh, Preston Fu, Jonathan Chen",http://arxiv.org/pdf/2408.12036v2,cs.CL
Let Community Rules Be Reflected in Online Content Moderation,"Content moderation is a widely used strategy to prevent the dissemination of
irregular information on social media platforms. Despite extensive research on
developing automated models to support decision-making in content moderation,
there remains a notable scarcity of studies that integrate the rules of online
communities into content moderation. This study addresses this gap by proposing
a community rule-based content moderation framework that directly integrates
community rules into the moderation of user-generated content. Our experiment
results with datasets collected from two domains demonstrate the superior
performance of models based on the framework to baseline models across all
evaluation metrics. In particular, incorporating community rules substantially
enhances model performance in content moderation. The findings of this research
have significant research and practical implications for improving the
effectiveness and generalizability of content moderation models in online
communities.",2024-08-21,"Wangjiaxuan Xin, Kanlun Wang, Zhe Fu, Lina Zhou",http://arxiv.org/pdf/2408.12035v1,cs.CL
Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition -- And Ways to Overcome Them,"Cross-modal contrastive pre-training between natural language and other
modalities, e.g., vision and audio, has demonstrated astonishing performance
and effectiveness across a diverse variety of tasks and domains. In this paper,
we investigate whether such natural language supervision can be used for
wearable sensor based Human Activity Recognition (HAR), and discover
that-surprisingly-it performs substantially worse than standard end-to-end
training and self-supervision. We identify the primary causes for this as:
sensor heterogeneity and the lack of rich, diverse text descriptions of
activities. To mitigate their impact, we also develop strategies and assess
their effectiveness through an extensive experimental evaluation. These
strategies lead to significant increases in activity recognition, bringing
performance closer to supervised and self-supervised training, while also
enabling the recognition of unseen activities and cross modal retrieval of
videos. Overall, our work paves the way for better sensor-language learning,
ultimately leading to the development of foundational models for HAR using
wearables.",2024-08-21,"Harish Haresamudram, Apoorva Beedu, Mashfiqui Rabbi, Sankalita Saha, Irfan Essa, Thomas Ploetz",http://arxiv.org/pdf/2408.12023v1,cs.CL
Understanding Epistemic Language with a Language-augmented Bayesian Theory of Mind,"How do people understand and evaluate claims about others' beliefs, even
though these beliefs cannot be directly observed? In this paper, we introduce a
cognitive model of epistemic language interpretation, grounded in Bayesian
inferences about other agents' goals, beliefs, and intentions: a
language-augmented Bayesian theory-of-mind (LaBToM). By translating natural
language into an epistemic ``language-of-thought'' with grammar-constrained LLM
decoding, then evaluating these translations against the inferences produced by
inverting a generative model of rational action and perception, LaBToM captures
graded plausibility judgments of epistemic claims. We validate our model in an
experiment where participants watch an agent navigate a maze to find keys
hidden in boxes needed to reach their goal, then rate sentences about the
agent's beliefs. In contrast with multimodal LLMs (GPT-4o, Gemini Pro) and
ablated models, our model correlates highly with human judgments for a wide
range of expressions, including modal language, uncertainty expressions,
knowledge claims, likelihood comparisons, and attributions of false belief.",2024-08-21,"Lance Ying, Tan Zhi-Xuan, Lionel Wong, Vikash Mansinghka, Joshua B. Tenenbaum",http://arxiv.org/pdf/2408.12022v2,cs.CL
RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization,"With the development of the modern social economy, tourism has become an
important way to meet people's spiritual needs, bringing development
opportunities to the tourism industry. However, existing large language models
(LLMs) face challenges in personalized recommendation capabilities and the
generation of content that can sometimes produce hallucinations. This study
proposes an optimization scheme for Tibet tourism LLMs based on
retrieval-augmented generation (RAG) technology. By constructing a database of
tourist viewpoints and processing the data using vectorization techniques, we
have significantly improved retrieval accuracy. The application of RAG
technology effectively addresses the hallucination problem in content
generation. The optimized model shows significant improvements in fluency,
accuracy, and relevance of content generation. This research demonstrates the
potential of RAG technology in the standardization of cultural tourism
information and data analysis, providing theoretical and technical support for
the development of intelligent cultural tourism service systems.",2024-08-21,"Jinhu Qi, Shuai Yan, Yibo Zhang, Wentao Zhang, Rong Jin, Yuwei Hu, Ke Wang",http://arxiv.org/pdf/2408.12003v2,cs.CL
Large Language Models for Page Stream Segmentation,"Page Stream Segmentation (PSS) is an essential prerequisite for automated
document processing at scale. However, research progress has been limited by
the absence of realistic public benchmarks. This paper works towards addressing
this gap by introducing TABME++, an enhanced benchmark featuring commercial
Optical Character Recognition (OCR) annotations. We evaluate the performance of
large language models (LLMs) on PSS, focusing on decoder-based models
fine-tuned with parameter-efficient methods. Our results show that
decoder-based LLMs outperform smaller multimodal encoders. Through a review of
existing PSS research and datasets, we identify key challenges and advancements
in the field. Our findings highlight the key importance of robust OCR,
providing valuable insights for the development of more effective document
processing systems.",2024-08-21,"Hunter Heidenreich, Ratish Dalvi, Rohith Mukku, Nikhil Verma, Neven Pičuljan",http://arxiv.org/pdf/2408.11981v1,cs.CL
Characterizing Online Toxicity During the 2022 Mpox Outbreak: A Computational Analysis of Topical and Network Dynamics,"Background: Online toxicity, encompassing behaviors such as harassment,
bullying, hate speech, and the dissemination of misinformation, has become a
pressing social concern in the digital age. The 2022 Mpox outbreak, initially
termed ""Monkeypox"" but subsequently renamed to mitigate associated stigmas and
societal concerns, serves as a poignant backdrop to this issue. Objective: In
this research, we undertake a comprehensive analysis of the toxic online
discourse surrounding the 2022 Mpox outbreak. Our objective is to dissect its
origins, characterize its nature and content, trace its dissemination patterns,
and assess its broader societal implications, with the goal of providing
insights that can inform strategies to mitigate such toxicity in future crises.
Methods: We collected more than 1.6 million unique tweets and analyzed them
from five dimensions, including context, extent, content, speaker, and intent.
Utilizing BERT-based topic modeling and social network community clustering, we
delineated the toxic dynamics on Twitter. Results: We identified five
high-level topic categories in the toxic online discourse on Twitter, including
disease (46.6%), health policy and healthcare (19.3%), homophobia (23.9%),
politics (6.0%), and racism (4.1%). Through the toxicity diffusion networks of
mentions, retweets, and the top users, we found that retweets of toxic content
were widespread, while influential users rarely engaged with or countered this
toxicity through retweets. Conclusions: By tracking topical dynamics, we can
track the changing popularity of toxic content online, providing a better
understanding of societal challenges. Network dynamics spotlight key social
media influencers and their intents, indicating that addressing these central
figures in toxic discourse can enhance crisis communication and inform
policy-making.",2024-08-21,"Lizhou Fan, Lingyao Li, Libby Hemphill",http://arxiv.org/pdf/2408.11962v3,cs.CL
Decoding SEC Actions: Enforcement Trends through Analyzing Blockchain litigation using LLM-based Thematic Factor Mapping,"The proliferation of blockchain entities (persons or enterprises) exposes
them to potential regulatory actions (e.g., being litigated) by regulatory
authorities. Regulatory frameworks for crypto assets are actively being
developed and refined, increasing the likelihood of such actions. The lack of
systematic analysis of the factors driving litigation against blockchain
entities leaves companies in need of clarity to navigate compliance risks. This
absence of insight also deprives investors of the information for informed
decision-making. This study focuses on U.S. litigation against blockchain
entities, particularly by the U.S. Securities and Exchange Commission (SEC)
given its influence on global crypto regulation. Utilizing frontier pretrained
language models and large language models, we systematically map all SEC
complaints against blockchain companies from 2012 to 2024 to thematic factors
conceptualized by our study to delineate the factors driving SEC actions. We
quantify the thematic factors and assess their influence on specific legal Acts
cited within the complaints on an annual basis, allowing us to discern the
regulatory emphasis, patterns and conduct trend analysis.",2024-08-21,"Junliang Luo, Xihan Xiong, William Knottenbelt, Xue Liu",http://arxiv.org/pdf/2408.11961v1,cs.CL
The State of Commercial Automatic French Legal Speech Recognition Systems and their Impact on Court Reporters et al,"In Quebec and Canadian courts, the transcription of court proceedings is a
critical task for appeal purposes and must be certified by an official court
reporter. The limited availability of qualified reporters and the high costs
associated with manual transcription underscore the need for more efficient
solutions. This paper examines the potential of Automatic Speech Recognition
(ASR) systems to assist court reporters in transcribing legal proceedings. We
benchmark three ASR models, including commercial and open-source options, on
their ability to recognize French legal speech using a curated dataset. Our
study evaluates the performance of these systems using the Word Error Rate
(WER) metric and introduces the Sonnex Distance to account for phonetic
accuracy. We also explore the broader implications of ASR adoption on court
reporters, copyists, the legal system, and litigants, identifying both positive
and negative impacts. The findings suggest that while current ASR systems show
promise, they require further refinement to meet the specific needs of the
legal domain.",2024-08-21,"Nicolad Garneau, Olivier Bolduc",http://arxiv.org/pdf/2408.11940v1,cs.CL
Defining Boundaries: The Impact of Domain Specification on Cross-Language and Cross-Domain Transfer in Machine Translation,"Recent advancements in neural machine translation (NMT) have revolutionized
the field, yet the dependency on extensive parallel corpora limits progress for
low-resource languages and domains. Cross-lingual transfer learning offers a
promising solution by utilizing data from high-resource languages but often
struggles with in-domain NMT. This paper investigates zero-shot cross-lingual
domain adaptation for NMT, focusing on the impact of domain specification and
linguistic factors on transfer effectiveness. Using English as the source
language and Spanish for fine-tuning, we evaluate multiple target languages,
including Portuguese, Italian, French, Czech, Polish, and Greek. We demonstrate
that both language-specific and domain-specific factors influence transfer
effectiveness, with domain characteristics playing a crucial role in
determining cross-domain transfer potential. We also explore the feasibility of
zero-shot cross-lingual cross-domain transfer, providing insights into which
domains are more responsive to transfer and why. Our results show the
importance of well-defined domain boundaries and transparency in experimental
setups for in-domain transfer learning.",2024-08-21,"Lia Shahnazaryan, Meriem Beloucif",http://arxiv.org/pdf/2408.11926v2,cs.CL
"Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for Ancient Indian Philosophy","LLMs have revolutionized the landscape of information retrieval and knowledge
dissemination. However, their application in specialized areas is often
hindered by factual inaccuracies and hallucinations, especially in long-tail
knowledge distributions. We explore the potential of retrieval-augmented
generation (RAG) models for long-form question answering (LFQA) in a
specialized knowledge domain. We present VedantaNY-10M, a dataset curated from
extensive public discourses on the ancient Indian philosophy of Advaita
Vedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM,
focusing on transcription, retrieval, and generation performance. Human
evaluations by computational linguists and domain experts show that the RAG
model significantly outperforms the standard model in producing factual and
comprehensive responses having fewer hallucinations. In addition, a
keyword-based hybrid retriever that emphasizes unique low-frequency terms
further improves results. Our study provides insights into effectively
integrating modern large language models with ancient knowledge systems.
Project page with dataset and code: https://sites.google.com/view/vedantany-10m",2024-08-21,Priyanka Mandikal,http://arxiv.org/pdf/2408.11903v2,cs.CL
"Great Memory, Shallow Reasoning: Limits of $k$NN-LMs","$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval
with next-word prediction, have demonstrated strong performance in language
modeling as well as downstream NLP benchmarks. These results have led
researchers to argue that models trained on poor quality or outdated data could
perform well by employing a $k$NN extension that has access to a higher-quality
datastore. In this work, we ask whether this improved ability to recall
information really translates into downstream abilities. We extensively
evaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment
classification and commonsense reasoning to multi-hop reasoning. Results show
that $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in
the input is sufficient for determining the output, but struggle with reasoning
tasks that require integrating multiple pieces of information to derive new
knowledge. We further demonstrate through oracle experiments and qualitative
analysis that even with perfect retrieval, $k$NN-LMs still fail to determine
the correct answers, placing an upper bound on their reasoning performance.
Code and datastores are released at https://github.com/GSYfate/knnlm-limits/.",2024-08-21,"Shangyi Geng, Wenting Zhao, Alexander M Rush",http://arxiv.org/pdf/2408.11815v1,cs.CL
WeQA: A Benchmark for Retrieval Augmented Generation in Wind Energy Domain,"In the rapidly evolving landscape of Natural Language Processing (NLP) and
text generation, the emergence of Retrieval Augmented Generation (RAG) presents
a promising avenue for improving the quality and reliability of generated text
by leveraging information retrieved from user specified database. Benchmarking
is essential to evaluate and compare the performance of the different RAG
configurations in terms of retriever and generator, providing insights into
their effectiveness, scalability, and suitability for the specific domain and
applications. In this paper, we present a comprehensive framework to generate a
domain relevant RAG benchmark. Our framework is based on automatic
question-answer generation with Human (domain experts)-AI Large Language Model
(LLM) teaming. As a case study, we demonstrate the framework by introducing
WeQA, a first-of-its-kind benchmark on the wind energy domain which comprises
of multiple scientific documents/reports related to environmental impact of
wind energy projects. Our framework systematically evaluates RAG performance
using diverse metrics and multiple question types with varying complexity
level. We also demonstrate the performance of different models on our
benchmark.",2024-08-21,"Rounak Meyur, Hung Phan, Sridevi Wagle, Jan Strube, Mahantesh Halappanavar, Sameera Horawalavithana, Anurag Acharya, Sai Munikoti",http://arxiv.org/pdf/2408.11800v2,cs.CL
Practical token pruning for foundation models in few-shot conversational virtual assistant systems,"In an enterprise Virtual Assistant (VA) system, intent classification is the
crucial component that determines how a user input is handled based on what the
user wants. The VA system is expected to be a cost-efficient SaaS service with
low training and inference time while achieving high accuracy even with a small
number of training samples. We pretrain a transformer-based sentence embedding
model with a contrastive learning objective and leverage the embedding of the
model as features when training intent classification models. Our approach
achieves the state-of-the-art results for few-shot scenarios and performs
better than other commercial solutions on popular intent classification
benchmarks. However, generating features via a transformer-based model
increases the inference time, especially for longer user inputs, due to the
quadratic runtime of the transformer's attention mechanism. On top of model
distillation, we introduce a practical multi-task adaptation approach that
configures dynamic token pruning without the need for task-specific training
for intent classification. We demonstrate that this approach improves the
inference speed of popular sentence transformer models without affecting model
performance.",2024-08-21,"Haode Qi, Cheng Qian, Jian Ni, Pratyush Singh, Reza Fazeli, Gengyu Wang, Zhongzheng Shu, Eric Wayne, Juergen Bross",http://arxiv.org/pdf/2408.11799v1,cs.CL
LLM Pruning and Distillation in Practice: The Minitron Approach,"We present a comprehensive report on compressing the Llama 3.1 8B and Mistral
NeMo 12B models to 4B and 8B parameters, respectively, using pruning and
distillation. We explore two distinct pruning strategies: (1) depth pruning and
(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on
common benchmarks from the LM Evaluation Harness. The models are then aligned
with NeMo Aligner and tested in instruct-tuned versions. This approach produces
a compelling 4B model from Llama 3.1 8B and a state-of-the-art
Mistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo
12B. We found that with no access to the original data, it is beneficial to
slightly fine-tune teacher models on the distillation dataset. We open-source
our base model weights on Hugging Face with a permissive license.",2024-08-21,"Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Ameya Sunil Mahabaleshwarkar, Gerald Shen, Jiaqi Zeng, Zijia Chen, Yoshi Suhara, Shizhe Diao, Chenhan Yu, Wei-Chun Chen, Hayley Ross, Oluwatobi Olabiyi, Ashwath Aithal, Oleksii Kuchaiev, Daniel Korzekwa, Pavlo Molchanov, Mostofa Patwary, Mohammad Shoeybi, Jan Kautz, Bryan Catanzaro",http://arxiv.org/pdf/2408.11796v4,cs.CL
DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework,"Current video generation models excel at creating short, realistic clips, but
struggle with longer, multi-scene videos. We introduce \texttt{DreamFactory},
an LLM-based framework that tackles this challenge. \texttt{DreamFactory}
leverages multi-agent collaboration principles and a Key Frames Iteration
Design Method to ensure consistency and style across long videos. It utilizes
Chain of Thought (COT) to address uncertainties inherent in large language
models. \texttt{DreamFactory} generates long, stylistically coherent, and
complex videos. Evaluating these long-form videos presents a challenge. We
propose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene
Style Consistency Score. To further research in this area, we contribute the
Multi-Scene Videos Dataset containing over 150 human-rated videos.",2024-08-21,"Zhifei Xie, Daniel Tang, Dingwei Tan, Jacques Klein, Tegawend F. Bissyand, Saad Ezzini",http://arxiv.org/pdf/2408.11788v1,cs.CL
Personality Alignment of Large Language Models,"Aligning large language models (LLMs) typically aim to reflect general human
values and behaviors, but they often fail to capture the unique characteristics
and preferences of individual users. To address this gap, we introduce the
concept of Personality Alignment. This approach tailors LLMs' responses and
decisions to match the specific preferences of individual users or closely
related groups. Inspired by psychometrics, we created the Personality Alignment
with Personality Inventories (PAPI) dataset, which includes data from over
320,000 real subjects across multiple personality assessments, including both
the Big Five Personality Factors and Dark Triad traits. This comprehensive
dataset enables quantitative evaluation of LLMs' alignment capabilities across
both positive and potentially problematic personality dimensions. Recognizing
the challenges of personality alignments, such as limited personal data,
diverse preferences, and scalability requirements, we developed an activation
intervention optimization method. This method enhances LLMs' ability to
efficiently align with individual behavioral preferences using minimal data and
computational resources. Remarkably, our method, PAS, achieves superior
performance while requiring only 1/5 of the optimization time compared to DPO,
offering practical value for personality alignment. Our work paves the way for
future AI systems to make decisions and reason in truly personality ways,
enhancing the relevance and meaning of AI interactions for each user and
advancing human-centered artificial intelligence. The dataset and code are
released at https://github.com/zhu-minjun/PAlign.",2024-08-21,"Minjun Zhu, Yixuan Weng, Linyi Yang, Yue Zhang",http://arxiv.org/pdf/2408.11779v2,cs.CL
Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards,"Recent studies show that large language models (LLMs) struggle with technical
standards in telecommunications. We propose a fine-tuned retrieval-augmented
generation (RAG) system based on the Phi-2 small language model (SLM) to serve
as an oracle for communication networks. Our developed system leverages
forward-looking semantic chunking to adaptively determine parsing breakpoints
based on embedding similarity, enabling effective processing of diverse
document formats. To handle the challenge of multiple similar contexts in
technical standards, we employ a re-ranking algorithm to prioritize the most
relevant retrieved chunks. Recognizing the limitations of Phi-2's small context
window, we implement a recent technique, namely SelfExtend, to expand the
context window during inference, which not only boosts the performance but also
can accommodate a wider range of user queries and design requirements from
customers to specialized technicians. For fine-tuning, we utilize the low-rank
adaptation (LoRA) technique to enhance computational efficiency during training
and enable effective fine-tuning on small datasets. Our comprehensive
experiments demonstrate substantial improvements over existing
question-answering approaches in the telecom domain, achieving performance that
exceeds larger language models such as GPT-4 (which is about 880 times larger
in size). This work presents a novel approach to leveraging SLMs for
communication networks, offering a balance of efficiency and performance. This
work can serve as a foundation towards agentic language models for networks.",2024-08-21,"Omar Erak, Nouf Alabbasi, Omar Alhussein, Ismail Lotfi, Amr Hussein, Sami Muhaidat, Merouane Debbah",http://arxiv.org/pdf/2408.11775v2,cs.CL
"Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks","Large Language Models (LLMs) are susceptible to malicious influence by cyber
attackers through intrusions such as adversarial, backdoor, and embedding
inversion attacks. In response, the burgeoning field of LLM Security aims to
study and defend against such threats. Thus far, the majority of works in this
area have focused on monolingual English models, however, emerging research
suggests that multilingual LLMs may be more vulnerable to various attacks than
their monolingual counterparts. While previous work has investigated embedding
inversion over a small subset of European languages, it is challenging to
extrapolate these findings to languages from different linguistic families and
with differing scripts. To this end, we explore the security of multilingual
LLMs in the context of embedding inversion attacks and investigate
cross-lingual and cross-script inversion across 20 languages, spanning over 8
language families and 12 scripts. Our findings indicate that languages written
in Arabic script and Cyrillic script are particularly vulnerable to embedding
inversion, as are languages within the Indo-Aryan language family. We further
observe that inversion models tend to suffer from language confusion, sometimes
greatly reducing the efficacy of an attack. Accordingly, we systematically
explore this bottleneck for inversion models, uncovering predictable patterns
which could be leveraged by attackers. Ultimately, this study aims to further
the field's understanding of the outstanding security vulnerabilities facing
multilingual LLMs and raise awareness for the languages most at risk of
negative impact from these attacks.",2024-08-21,"Yiyi Chen, Russa Biswas, Heather Lent, Johannes Bjerva",http://arxiv.org/pdf/2408.11749v2,cs.CL
FocusLLM: Precise Understanding of Long Context by Dynamic Condensing,"Empowering LLMs with the ability to precisely understand long contexts is
crucial for many downstream applications. However, handling long contexts with
conventional transformer architecture requires substantial training and
inference resources. Existing context condensing methods cannot accurately
understand the full context, as there is a considerable amount of information
loss in the condensing process. To address these issues, we present FocusLLM, a
framework designed to extend the fixed context length of any decoder-only LLM,
allowing the model to focus on relevant information from very long sequences.
FocusLLM first divides long text input into chunks based on the model's
original context length. It then employs the dynamic condensing process to
distill crucial information from each chunk. Ultimately, through the novel
parallel decoding mechanism, FocusLLM can integrate the extracted information
into its local context. FocusLLM stands out for great training efficiency and
versatility: trained with an 8K input length and with much less training cost
than previous methods, FocusLLM exhibits superior performance across downstream
tasks and maintains strong language modeling ability when handling extensive
long texts, even up to 400K tokens. Our code is available at
https://github.com/leezythu/FocusLLM.",2024-08-21,"Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang",http://arxiv.org/pdf/2408.11745v2,cs.CL
Efficient Detection of Toxic Prompts in Large Language Models,"Large language models (LLMs) like ChatGPT and Gemini have significantly
advanced natural language processing, enabling various applications such as
chatbots and automated content generation. However, these models can be
exploited by malicious individuals who craft toxic prompts to elicit harmful or
unethical responses. These individuals often employ jailbreaking techniques to
bypass safety mechanisms, highlighting the need for robust toxic prompt
detection methods. Existing detection techniques, both blackbox and whitebox,
face challenges related to the diversity of toxic prompts, scalability, and
computational efficiency. In response, we propose ToxicDetector, a lightweight
greybox method designed to efficiently detect toxic prompts in LLMs.
ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding
vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP)
classifier for prompt classification. Our evaluation on various versions of the
LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector
achieves a high accuracy of 96.39\% and a low false positive rate of 2.00\%,
outperforming state-of-the-art methods. Additionally, ToxicDetector's
processing time of 0.0780 seconds per prompt makes it highly suitable for
real-time applications. ToxicDetector achieves high accuracy, efficiency, and
scalability, making it a practical method for toxic prompt detection in LLMs.",2024-08-21,"Yi Liu, Junzhe Yu, Huijia Sun, Ling Shi, Gelei Deng, Yuqi Chen, Yang Liu",http://arxiv.org/pdf/2408.11727v2,cs.CL
Xinyu: An Efficient LLM-based System for Commentary Generation,"Commentary provides readers with a deep understanding of events by presenting
diverse arguments and evidence. However, creating commentary is a
time-consuming task, even for skilled commentators. Large language models
(LLMs) have simplified the process of natural language generation, but their
direct application in commentary creation still faces challenges due to unique
task requirements. These requirements can be categorized into two levels: 1)
fundamental requirements, which include creating well-structured and logically
consistent narratives, and 2) advanced requirements, which involve generating
quality arguments and providing convincing evidence. In this paper, we
introduce Xinyu, an efficient LLM-based system designed to assist commentators
in generating Chinese commentaries. To meet the fundamental requirements, we
deconstruct the generation process into sequential steps, proposing targeted
strategies and supervised fine-tuning (SFT) for each step. To address the
advanced requirements, we present an argument ranking model for arguments and
establish a comprehensive evidence database that includes up-to-date events and
classic books, thereby strengthening the substantiation of the evidence with
retrieval augmented generation (RAG) technology. To evaluate the generated
commentaries more fairly, corresponding to the two-level requirements, we
introduce a comprehensive evaluation metric that considers five distinct
perspectives in commentary generation. Our experiments confirm the
effectiveness of our proposed system. We also observe a significant increase in
the efficiency of commentators in real-world scenarios, with the average time
spent on creating a commentary dropping from 4 hours to 20 minutes.
Importantly, such an increase in efficiency does not compromise the quality of
the commentaries.",2024-08-21,"Yiquan Wu, Bo Tang, Chenyang Xi, Yu Yu, Pengyu Wang, Yifei Liu, Kun Kuang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Jie Hu, Peng Cheng, Zhonghao Wang, Yi Wang, Yi Luo, Mingchuan Yang",http://arxiv.org/pdf/2408.11609v2,cs.CL
Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning,"Empathetic response generation endows agents with the capability to
comprehend dialogue contexts and react to expressed emotions. Previous works
predominantly focus on leveraging the speaker's emotional labels, but ignore
the importance of emotion cause reasoning in empathetic response generation,
which hinders the model's capacity for further affective understanding and
cognitive inference. In this paper, we propose a cause-aware empathetic
generation approach by integrating emotions and causes through a well-designed
Chain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can
greatly promote LLMs' performance of empathy by instruction tuning and
enhancing the role awareness of an empathetic listener in the prompt.
Additionally, we propose to incorporate cause-oriented external knowledge from
COMET into the prompt, which improves the diversity of generation and
alleviates conflicts between internal and external knowledge at the same time.
Experimental results on the benchmark dataset demonstrate that our approach on
LLaMA-7b achieves state-of-the-art performance in both automatic and human
evaluations.",2024-08-21,"Xinhao Chen, Chong Yang, Man Lan, Li Cai, Yang Chen, Tu Hu, Xinlin Zhuang, Aimin Zhou",http://arxiv.org/pdf/2408.11599v1,cs.CL
Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks,"With the burgeoning advancements in the field of natural language processing
(NLP), the demand for training data has increased significantly. To save costs,
it has become common for users and businesses to outsource the labor-intensive
task of data collection to third-party entities. Unfortunately, recent research
has unveiled the inherent risk associated with this practice, particularly in
exposing NLP systems to potential backdoor attacks. Specifically, these attacks
enable malicious control over the behavior of a trained model by poisoning a
small portion of the training data. Unlike backdoor attacks in computer vision,
textual backdoor attacks impose stringent requirements for attack stealthiness.
However, existing attack methods meet significant trade-off between
effectiveness and stealthiness, largely due to the high information entropy
inherent in textual data. In this paper, we introduce the Efficient and
Stealthy Textual backdoor attack method, EST-Bad, leveraging Large Language
Models (LLMs). Our EST-Bad encompasses three core strategies: optimizing the
inherent flaw of models as the trigger, stealthily injecting triggers with
LLMs, and meticulously selecting the most impactful samples for backdoor
injection. Through the integration of these techniques, EST-Bad demonstrates an
efficient achievement of competitive attack performance while maintaining
superior stealthiness compared to prior methods across various text classifier
datasets.",2024-08-21,"Ziqiang Li, Yueqi Zeng, Pengfei Xia, Lei Liu, Zhangjie Fu, Bin Li",http://arxiv.org/pdf/2408.11587v1,cs.CL
Drama Engine: A Framework for Narrative Agents,"This technical report presents the Drama Engine, a novel framework for
agentic interaction with large language models designed for narrative purposes.
The framework adapts multi-agent system principles to create dynamic,
context-aware companions that can develop over time and interact with users and
each other. Key features include multi-agent workflows with delegation, dynamic
prompt assembly, and model-agnostic design. The Drama Engine introduces unique
elements such as companion development, mood systems, and automatic context
summarising. It is implemented in TypeScript. The framework's applications
include multi-agent chats and virtual co-workers for creative writing. The
paper discusses the system's architecture, prompt assembly process, delegation
mechanisms, and moderation techniques, as well as potential ethical
considerations and future extensions.",2024-08-21,"Martin Pichlmair, Riddhi Raj, Charlene Putney",http://arxiv.org/pdf/2408.11574v1,cs.CL
Differentiating Choices via Commonality for Multiple-Choice Question Answering,"Multiple-choice question answering (MCQA) becomes particularly challenging
when all choices are relevant to the question and are semantically similar. Yet
this setting of MCQA can potentially provide valuable clues for choosing the
right answer. Existing models often rank each choice separately, overlooking
the context provided by other choices. Specifically, they fail to leverage the
semantic commonalities and nuances among the choices for reasoning. In this
paper, we propose a novel MCQA model by differentiating choices through
identifying and eliminating their commonality, called DCQA. Our model captures
token-level attention of each choice to the question, and separates tokens of
the question attended to by all the choices (i.e., commonalities) from those by
individual choices (i.e., nuances). Using the nuances as refined contexts for
the choices, our model can effectively differentiate choices with subtle
differences and provide justifications for choosing the correct answer. We
conduct comprehensive experiments across five commonly used MCQA benchmarks,
demonstrating that DCQA consistently outperforms baseline models. Furthermore,
our case study illustrates the effectiveness of the approach in directing the
attention of the model to more differentiating features.",2024-08-21,"Wenqing Deng, Zhe Wang, Kewen Wang, Shirui Pan, Xiaowang Zhang, Zhiyong Feng",http://arxiv.org/pdf/2408.11554v1,cs.CL
Memorization in In-Context Learning,"In-context learning (ICL) has proven to be an effective strategy for
improving the performance of large language models (LLMs) with no additional
training. However, the exact mechanism behind this performance improvement
remains unclear. This study is the first to show how ICL surfaces memorized
training data and to explore the correlation between this memorization and
performance on downstream tasks across various ICL regimes: zero-shot,
few-shot, and many-shot. Our most notable findings include: (1) ICL
significantly surfaces memorization compared to zero-shot learning in most
cases; (2) demonstrations, without their labels, are the most effective element
in surfacing memorization; (3) ICL improves performance when the surfaced
memorization in few-shot regimes reaches a high level (about 40%); and (4)
there is a very strong correlation between performance and memorization in ICL
when it outperforms zero-shot learning. Overall, our study uncovers
memorization as a new factor impacting ICL, raising an important question: to
what extent do LLMs truly generalize from demonstrations in ICL, and how much
of their success is due to memorization?",2024-08-21,"Shahriar Golchin, Mihai Surdeanu, Steven Bethard, Eduardo Blanco, Ellen Riloff",http://arxiv.org/pdf/2408.11546v3,cs.CL
Imagining from Images with an AI Storytelling Tool,"A method for generating narratives by analyzing single images or image
sequences is presented, inspired by the time immemorial tradition of Narrative
Art. The proposed method explores the multimodal capabilities of GPT-4o to
interpret visual content and create engaging stories, which are illustrated by
a Stable Diffusion XL model. The method is supported by a fully implemented
tool, called ImageTeller, which accepts images from diverse sources as input.
Users can guide the narrative's development according to the conventions of
fundamental genres - such as Comedy, Romance, Tragedy, Satire or Mystery -, opt
to generate data-driven stories, or to leave the prototype free to decide how
to handle the narrative structure. User interaction is provided along the
generation process, allowing the user to request alternative chapters or
illustrations, and even reject and restart the story generation based on the
same input. Additionally, users can attach captions to the input images,
influencing the system's interpretation of the visual content. Examples of
generated stories are provided, along with details on how to access the
prototype.",2024-08-21,"Edirlei Soares de Lima, Marco A. Casanova, Antonio L. Furtado",http://arxiv.org/pdf/2408.11517v1,cs.CL
IKUN for WMT24 General MT Task: LLMs Are here for Multilingual Machine Translation,"This paper introduces two multilingual systems, IKUN and IKUN-C, developed
for the general machine translation task in WMT24. IKUN and IKUN-C represent an
open system and a constrained system, respectively, built on Llama-3-8b and
Mistral-7B-v0.3. Both systems are designed to handle all 11 language directions
using a single model. According to automatic evaluation metrics, IKUN-C
achieved 6 first-place and 3 second-place finishes among all constrained
systems, while IKUN secured 1 first-place and 2 second-place finishes across
both open and constrained systems. These encouraging results suggest that large
language models (LLMs) are nearing the level of proficiency required for
effective multilingual machine translation. The systems are based on a
two-stage approach: first, continuous pre-training on monolingual data in 10
languages, followed by fine-tuning on high-quality parallel data for 11
language directions. The primary difference between IKUN and IKUN-C lies in
their monolingual pre-training strategy. IKUN-C is pre-trained using
constrained monolingual data, whereas IKUN leverages monolingual data from the
OSCAR dataset. In the second phase, both systems are fine-tuned on parallel
data sourced from NTREX, Flores, and WMT16-23 for all 11 language pairs.",2024-08-21,"Baohao Liao, Christian Herold, Shahram Khadivi, Christof Monz",http://arxiv.org/pdf/2408.11512v2,cs.CL
DocTabQA: Answering Questions from Long Documents Using Tables,"We study a new problem setting of question answering (QA), referred to as
DocTabQA. Within this setting, given a long document, the goal is to respond to
questions by organizing the answers into structured tables derived directly
from the document's content. Unlike traditional QA approaches which
predominantly rely on unstructured text to formulate responses, DocTabQA aims
to leverage structured tables as answers to convey information clearly and
systematically, thereby enhancing user comprehension and highlighting
relationships between data points. To the best of our knowledge, this problem
has not been previously explored. In this paper, we introduce the QTabA
dataset, encompassing 300 financial documents, accompanied by manually
annotated 1.5k question-table pairs. Initially, we leverage Large Language
Models (LLMs) such as GPT-4 to establish a baseline. However, it is widely
acknowledged that LLMs encounter difficulties when tasked with generating
intricate, structured outputs from long input sequences. To overcome these
challenges, we present a two-stage framework, called DocTabTalk, which
initially retrieves relevant sentences from extensive documents and
subsequently generates hierarchical tables based on these identified sentences.
DocTabTalk incorporates two key technological innovations: AlignLLaMA and
TabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA,
enabling it to generate well-structured, hierarchical tables with improved
organization and clarity. Comprehensive experimental evaluations conducted on
both QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly
enhances the performances of the GPT-4 in our proposed DocTabQA task and the
table generation task. The code and dataset are available at
https://github.com/SmileWHC/DocTabQA for further research.",2024-08-21,"Haochen Wang, Kai Hu, Haoyu Dong, Liangcai Gao",http://arxiv.org/pdf/2408.11490v1,cs.CL
The Self-Contained Negation Test Set,"Several methodologies have recently been proposed to evaluate the ability of
Pretrained Language Models (PLMs) to interpret negation. In this article, we
build on Gubelmann and Handschuh (2022), which studies the modification of
PLMs' predictions as a function of the polarity of inputs, in English.
Crucially, this test uses ``self-contained'' inputs ending with a masked
position: depending on the polarity of a verb in the input, a particular token
is either semantically ruled out or allowed at the masked position. By
replicating Gubelmann and Handschuh (2022) experiments, we have uncovered flaws
that weaken the conclusions that can be drawn from this test. We thus propose
an improved version, the Self-Contained Neg Test, which is more controlled,
more systematic, and entirely based on examples forming minimal pairs varying
only in the presence or absence of verbal negation in English. When applying
our test to the roberta and bert base and large models, we show that only
roberta-large shows trends that match the expectations, while bert-base is
mostly insensitive to negation. For all the tested models though, in a
significant number of test instances the top-1 prediction remains the token
that is semantically forbidden by the context, which shows how much room for
improvement remains for a proper treatment of the negation phenomenon.",2024-08-21,"David Kletz, Pascal Amsili, Marie Candito",http://arxiv.org/pdf/2408.11469v1,cs.CL
Expanding FLORES+ Benchmark for more Low-Resource Settings: Portuguese-Emakhuwa Machine Translation Evaluation,"As part of the Open Language Data Initiative shared tasks, we have expanded
the FLORES+ evaluation set to include Emakhuwa, a low-resource language widely
spoken in Mozambique. We translated the dev and devtest sets from Portuguese
into Emakhuwa, and we detail the translation process and quality assurance
measures used. Our methodology involved various quality checks, including
post-editing and adequacy assessments. The resulting datasets consist of
multiple reference sentences for each source. We present baseline results from
training a Neural Machine Translation system and fine-tuning existing
multilingual translation models. Our findings suggest that spelling
inconsistencies remain a challenge in Emakhuwa. Additionally, the baseline
models underperformed on this evaluation set, underscoring the necessity for
further research to enhance machine translation quality for Emakhuwa. The data
is publicly available at https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES.",2024-08-21,"Felermino D. M. Antonio Ali, Henrique Lopes Cardoso, Rui Sousa-Silva",http://arxiv.org/pdf/2408.11457v1,cs.CL
Distributional Properties of Subword Regularization,"Subword regularization, used widely in NLP, improves model performance by
reducing the dependency on exact tokenizations, augmenting the training corpus,
and exposing the model to more unique contexts during training. BPE and
MaxMatch, two popular subword tokenization schemes, have stochastic dropout
regularization variants. However, there has not been an analysis of the
distributions formed by them. We show that these stochastic variants are
heavily biased towards a small set of tokenizations per word. If the benefits
of subword regularization are as mentioned, we hypothesize that biasedness
artificially limits the effectiveness of these schemes. Thus, we propose an
algorithm to uniformly sample tokenizations that we use as a drop-in
replacement for the stochastic aspects of existing tokenizers, and find that it
improves machine translation quality.",2024-08-21,"Marco Cognetta, Vilém Zouhar, Naoaki Okazaki",http://arxiv.org/pdf/2408.11443v1,cs.CL
LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems,"Hindi, one of the most spoken language of India, exhibits a diverse array of
accents due to its usage among individuals from diverse linguistic origins. To
enable a robust evaluation of Hindi ASR systems on multiple accents, we create
a benchmark, LAHAJA, which contains read and extempore speech on a diverse set
of topics and use cases, with a total of 12.5 hours of Hindi audio, sourced
from 132 speakers spanning 83 districts of India. We evaluate existing
open-source and commercial models on LAHAJA and find their performance to be
poor. We then train models using different datasets and find that our model
trained on multilingual data with good speaker diversity outperforms existing
models by a significant margin. We also present a fine-grained analysis which
shows that the performance declines for speakers from North-East and South
India, especially with content heavy in named entities and specialized
terminology.",2024-08-21,"Tahir Javed, Janki Nawale, Sakshi Joshi, Eldho George, Kaushal Bhogale, Deovrat Mehendale, Mitesh M. Khapra",http://arxiv.org/pdf/2408.11440v1,cs.CL
Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning,"Large Language Models (LLMs) are versatile and demonstrate impressive
generalization ability by mining and learning information from extensive
unlabeled text. However, they still exhibit reasoning mistakes, often stemming
from knowledge deficiencies, which can affect their trustworthiness and
reliability. Although users can provide diverse and comprehensive queries,
obtaining sufficient and effective feedback is demanding. Furthermore,
evaluating LLMs comprehensively with limited labeled samples is difficult. This
makes it a challenge to diagnose and remedy the deficiencies of LLMs through
rich label-free user queries. To tackle this challenge, we propose a label-free
curricular meaningful learning framework (LaMer). LaMer first employs relative
entropy to automatically diagnose and quantify the knowledge deficiencies of
LLMs in a label-free setting. Next, to remedy the diagnosed knowledge
deficiencies, we apply curricular meaningful learning: first, we adopt
meaningful learning to adaptively synthesize augmentation data according to the
severity of the deficiencies, and then design a curricular deficiency remedy
strategy to remedy the knowledge deficiencies of LLMs progressively.
Experiments show that LaMer efficiently and effectively diagnoses and remedies
knowledge deficiencies in LLMs, improving various LLMs across seven
out-of-distribution (OOD) reasoning and language understanding benchmarks,
achieving comparable results to baselines with just 40\% training data. LaMer
even surpasses methods that rely on labeled datasets for deficiency diagnosis.
In application, our label-free method can offer an effective knowledge
deficiency diagnostic tool for efficient LLM development.",2024-08-21,"Kai Xiong, Xiao Ding, Li Du, Jiahao Ying, Ting Liu, Bing Qin, Yixin Cao",http://arxiv.org/pdf/2408.11431v1,cs.CL
"Towards ""Differential AI Psychology"" and in-context Value-driven Statement Alignment with Moral Foundations Theory","Contemporary research in social sciences is increasingly utilizing
state-of-the-art statistical language models to annotate or generate content.
While these models perform benchmark-leading on common language tasks and show
exemplary task-independent emergent abilities, transferring them to novel
out-of-domain tasks is only insufficiently explored. The implications of the
statistical black-box approach - stochastic parrots - are prominently
criticized in the language model research community; however, the significance
for novel generative tasks is not.
  This work investigates the alignment between personalized language models and
survey participants on a Moral Foundation Theory questionnaire. We adapt
text-to-text models to different political personas and survey the
questionnaire repetitively to generate a synthetic population of persona and
model combinations. Analyzing the intra-group variance and cross-alignment
shows significant differences across models and personas. Our findings indicate
that adapted models struggle to represent the survey-captured assessment of
political ideologies. Thus, using language models to mimic social interactions
requires measurable improvements in in-context optimization or parameter
manipulation to align with psychological and sociological stereotypes. Without
quantifiable alignment, generating politically nuanced content remains
unfeasible. To enhance these representations, we propose a testable framework
to generate agents based on moral value statements for future research.",2024-08-21,Simon Münker,http://arxiv.org/pdf/2408.11415v1,cs.CL
MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing,"Large Language Models (LLMs) are often English-centric due to the
disproportionate distribution of languages in their pre-training data.
Enhancing non-English language capabilities through post-pretraining often
results in catastrophic forgetting of the ability of original languages.
Previous methods either achieve good expansion with severe forgetting or slight
forgetting with poor expansion, indicating the challenge of balancing language
expansion while preventing forgetting. In this paper, we propose a method
called MoE-LPR (Mixture-of-Experts with Language Priors Routing) to alleviate
this problem. MoE-LPR employs a two-stage training approach to enhance the
multilingual capability. First, the model is post-pretrained into a
Mixture-of-Experts (MoE) architecture by upcycling, where all the original
parameters are frozen and new experts are added. In this stage, we focus
improving the ability on expanded languages, without using any original
language data. Then, the model reviews the knowledge of the original languages
with replay data amounting to less than 1% of post-pretraining, where we
incorporate language priors routing to better recover the abilities of the
original languages. Evaluations on multiple benchmarks show that MoE-LPR
outperforms other post-pretraining methods. Freezing original parameters
preserves original language knowledge while adding new experts preserves the
learning ability. Reviewing with LPR enables effective utilization of
multilingual knowledge within the parameters. Additionally, the MoE
architecture maintains the same inference overhead while increasing total model
parameters. Extensive experiments demonstrate MoE-LPR's effectiveness in
improving expanded languages and preserving original language proficiency with
superior scalability. Code and scripts are freely available at
https://github.com/zjwang21/MoE-LPR.git.",2024-08-21,"Hao Zhou, Zhijun Wang, Shujian Huang, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Weihua Luo, Jiajun Chen",http://arxiv.org/pdf/2408.11396v1,cs.CL
First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models,"Dynamic activation (DA) techniques, such as DejaVu and MoEfication, have
demonstrated their potential to significantly enhance the inference efficiency
of large language models (LLMs). However, these techniques often rely on ReLU
activation functions or require additional parameters and training to maintain
performance. This paper introduces a training-free Threshold-based Dynamic
Activation(TDA) method that leverage sequence information to exploit the
inherent sparsity of models across various architectures. This method is
designed to accelerate generation speed by 18-25\% without significantly
compromising task performance, thereby addressing the limitations of existing
DA techniques. Moreover, we delve into the root causes of LLM sparsity and
theoretically analyze two of its critical features: history-related activation
uncertainty and semantic-irrelevant activation inertia. Our comprehensive
analyses not only provide a robust theoretical foundation for DA methods but
also offer valuable insights to guide future research in optimizing LLMs for
greater efficiency and effectiveness.",2024-08-21,"Chi Ma, Mincong Huang, Ying Zhang, Chao Wang, Yujie Wang, Lei Yu, Chuan Liu, Wei Lin",http://arxiv.org/pdf/2408.11393v1,cs.CL
Towards Inducing Long-Context Abilities in Multilingual Neural Machine Translation Models,"Neural Machine Translation (NMT) models have traditionally used Sinusoidal
Positional Embeddings (PEs), which often struggle to capture long-range
dependencies and are inefficient for handling extended context or
document-level translation tasks. This work addresses the challenge of
transitioning pre-trained NMT models from absolute Sinusoidal PEs to Relative
PEs, such as RoPE and ALiBi, without compromising performance. We demonstrate
that parameter-efficient fine-tuning, using only a small amount of high-quality
data, can successfully facilitate this transition. Experimental results
indicate that switching from Sinusoidal to Relative PEs results in competitive
translation quality on sentence-level evaluation benchmarks. Additionally,
models trained with RoPE consistently outperform those using ALiBi and
Sinusoidal PEs on document-level benchmarks across both string-based metrics
and qualitative evaluations. Moreover, we find that a small amount of
long-context data in a few languages is sufficient for cross-lingual length
generalization, thereby inducing long-context capabilities.",2024-08-21,"Varun Gumma, Pranjal A. Chitale, Kalika Bali",http://arxiv.org/pdf/2408.11382v3,cs.CL
RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation,"Large Language Models (LLMs) demonstrate human-level capabilities in
dialogue, reasoning, and knowledge retention. However, even the most advanced
LLMs face challenges such as hallucinations and real-time updating of their
knowledge. Current research addresses this bottleneck by equipping LLMs with
external knowledge, a technique known as Retrieval Augmented Generation (RAG).
However, two key issues constrained the development of RAG. First, there is a
growing lack of comprehensive and fair comparisons between novel RAG
algorithms. Second, open-source tools such as LlamaIndex and LangChain employ
high-level abstractions, which results in a lack of transparency and limits the
ability to develop novel algorithms and evaluation metrics. To close this gap,
we introduce RAGLAB, a modular and research-oriented open-source library.
RAGLAB reproduces 6 existing algorithms and provides a comprehensive ecosystem
for investigating RAG algorithms. Leveraging RAGLAB, we conduct a fair
comparison of 6 RAG algorithms across 10 benchmarks. With RAGLAB, researchers
can efficiently compare the performance of various algorithms and develop novel
algorithms.",2024-08-21,"Xuanwang Zhang, Yunze Song, Yidong Wang, Shuyun Tang, Xinfeng Li, Zhengran Zeng, Zhen Wu, Wei Ye, Wenyuan Xu, Yue Zhang, Xinyu Dai, Shikun Zhang, Qingsong Wen",http://arxiv.org/pdf/2408.11381v2,cs.CL
GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding,"In human reading and communication, individuals tend to engage in geospatial
reasoning, which involves recognizing geographic entities and making informed
inferences about their interrelationships. To mimic such cognitive process,
current methods either utilize conventional natural language understanding
toolkits, or directly apply models pretrained on geo-related natural language
corpora. However, these methods face two significant challenges: i) they do not
generalize well to unseen geospatial scenarios, and ii) they overlook the
importance of integrating geospatial context from geographical databases with
linguistic information from the Internet. To handle these challenges, we
propose GeoReasoner, a language model capable of reasoning on geospatially
grounded natural language. Specifically, it first leverages Large Language
Models (LLMs) to generate a comprehensive location description based on
linguistic and geospatial information. It also encodes direction and distance
information into spatial embedding via treating them as pseudo-sentences.
Consequently, the model is trained on both anchor-level and neighbor-level
inputs to learn geo-entity representation. Extensive experimental results
demonstrate GeoReasoner's superiority in three tasks: toponym recognition,
toponym linking, and geo-entity typing, compared to the state-of-the-art
baselines.",2024-08-21,"Yibo Yan, Joey Lee",http://arxiv.org/pdf/2408.11366v1,cs.CL
Clinical Context-aware Radiology Report Generation from Medical Images using Transformers,"Recent developments in the field of Natural Language Processing, especially
language models such as the transformer have brought state-of-the-art results
in language understanding and language generation. In this work, we investigate
the use of the transformer model for radiology report generation from chest
X-rays. We also highlight limitations in evaluating radiology report generation
using only the standard language generation metrics. We then applied a
transformer based radiology report generation architecture, and also compare
the performance of a transformer based decoder with the recurrence based
decoder. Experiments were performed using the IU-CXR dataset, showing superior
results to its LSTM counterpart and being significantly faster. Finally, we
identify the need of evaluating radiology report generation system using both
language generation metrics and classification metrics, which helps to provide
robust measure of generated reports in terms of their coherence and diagnostic
value.",2024-08-21,Sonit Singh,http://arxiv.org/pdf/2408.11344v1,cs.CL
SORSA: Singular Values and Orthonormal Regularized Singular Vectors Adaptation of Large Language Models,"In this paper, we propose Singular Values and Orthonormal Regularized
Singular Vectors Adaptation, or SORSA, a novel PEFT method. Each SORSA adapter
consists of two main parts: trainable principal singular weights $W_p = U_p
\text{diag}(S_p) V^\top_p$, and frozen residual weights $W_r = U_r
\text{diag}(S_r) V^\top_r$. These parts are initialized by performing singular
value decomposition (SVD) on pre-trained weights. Moreover, we implement and
analyze an orthonormal regularizer, which we prove could decrease the condition
number of $W_p$ and make the optimization more efficient. SORSA adapters could
be merged during inference, thus eliminating any inference latency. We also
introduce a method to analyze the variation of the parameters by performing SVD
and discuss and analyze SORSA's superiority in minimizing the alteration in the
SVD aspect. After all, SORSA shows a faster convergence than LoRA and PiSSA in
our experiments. On the GSM-8K benchmark, Llama 2 7B adapted using SORSA
achieved 56.03% accuracy, surpassing LoRA (42.30%), AdaLoRA (47.30%), Full FT
(49.05%), and PiSSA (53.07%). On the MATH benchmark, SORSA achieved 10.36%
accuracy, outperforming LoRA (5.50%), AdaLoRA (6.48%), Full FT (7.22%), and
PiSSA (7.44%). We conclude that SORSA offers a new perspective on
parameter-efficient fine-tuning, demonstrating remarkable performance.",2024-08-21,Yang Cao,http://arxiv.org/pdf/2409.00055v5,cs.CL
BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports,"Breast ultrasound is essential for detecting and diagnosing abnormalities,
with radiology reports summarizing key findings like lesion characteristics and
malignancy assessments. Extracting this critical information is challenging due
to the unstructured nature of these reports, with varied linguistic styles and
inconsistent formatting. While proprietary LLMs like GPT-4 are effective, they
are costly and raise privacy concerns when handling protected health
information. This study presents a pipeline for developing an in-house LLM to
extract clinical information from radiology reports. We first use GPT-4 to
create a small labeled dataset, then fine-tune a Llama3-8B model on it.
Evaluated on clinician-annotated reports, our model achieves an average F1
score of 84.6%, which is on par with GPT-4. Our findings demonstrate the
feasibility of developing an in-house LLM that not only matches GPT-4's
performance but also offers cost reductions and enhanced data privacy.",2024-08-21,"Yuxuan Chen, Haoyan Yang, Hengkai Pan, Fardeen Siddiqui, Antonio Verdone, Qingyang Zhang, Sumit Chopra, Chen Zhao, Yiqiu Shen",http://arxiv.org/pdf/2408.11334v1,cs.CL
Design Principle Transfer in Neural Architecture Search via Large Language Models,"Transferable neural architecture search (TNAS) has been introduced to design
efficient neural architectures for multiple tasks, to enhance the practical
applicability of NAS in real-world scenarios. In TNAS, architectural knowledge
accumulated in previous search processes is reused to warm up the architecture
search for new tasks. However, existing TNAS methods still search in an
extensive search space, necessitating the evaluation of numerous architectures.
To overcome this challenge, this work proposes a novel transfer paradigm, i.e.,
design principle transfer. In this work, the linguistic description of various
structural components' effects on architectural performance is termed design
principles. They are learned from established architectures and then can be
reused to reduce the search space by discarding unpromising architectures.
Searching in the refined search space can boost both the search performance and
efficiency for new NAS tasks. To this end, a large language model
(LLM)-assisted design principle transfer (LAPT) framework is devised. In LAPT,
LLM is applied to automatically reason the design principles from a set of
given architectures, and then a principle adaptation method is applied to
refine these principles progressively based on the new search results.
Experimental results show that LAPT can beat the state-of-the-art TNAS methods
on most tasks and achieve comparable performance on others.",2024-08-21,"Xun Zhou, Xingyu Wu, Liang Feng, Zhichao Lu, Kay Chen Tan",http://arxiv.org/pdf/2408.11330v2,cs.CL
"Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking Across Diverse Vocabularies","Recent advancements in NLP have resulted in models with specialized
strengths, such as processing multimodal inputs or excelling in specific
domains. However, real-world tasks, like multimodal translation, often require
a combination of these strengths, such as handling both translation and image
processing. While individual translation and vision models are powerful, they
typically lack the ability to perform both tasks in a single system. Combining
these models poses challenges, particularly due to differences in their
vocabularies, which limit the effectiveness of traditional ensemble methods to
post-generation techniques like N-best list re-ranking. In this work, we
propose a novel zero-shot ensembling strategy that allows for the integration
of different models during the decoding phase without the need for additional
training. Our approach re-ranks beams during decoding by combining scores at
the word level, using heuristics to predict when a word is completed. We
demonstrate the effectiveness of this method in machine translation scenarios,
showing that it enables the generation of translations that are both speech-
and image-aware while also improving overall translation quality (We will
release the code upon paper acceptance.).",2024-08-21,"Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues",http://arxiv.org/pdf/2408.11327v2,cs.CL
SarcasmBench: Towards Evaluating Large Language Models on Sarcasm Understanding,"In the era of large language models (LLMs), the task of ``System I''~-~the
fast, unconscious, and intuitive tasks, e.g., sentiment analysis, text
classification, etc., have been argued to be successfully solved. However,
sarcasm, as a subtle linguistic phenomenon, often employs rhetorical devices
like hyperbole and figuration to convey true sentiments and intentions,
involving a higher level of abstraction than sentiment analysis. There is
growing concern that the argument about LLMs' success may not be fully tenable
when considering sarcasm understanding. To address this question, we select
eleven SOTA LLMs and eight SOTA pre-trained language models (PLMs) and present
comprehensive evaluations on six widely used benchmark datasets through
different prompting approaches, i.e., zero-shot input/output (IO) prompting,
few-shot IO prompting, chain of thought (CoT) prompting. Our results highlight
three key findings: (1) current LLMs underperform supervised PLMs based sarcasm
detection baselines across six sarcasm benchmarks. This suggests that
significant efforts are still required to improve LLMs' understanding of human
sarcasm. (2) GPT-4 consistently and significantly outperforms other LLMs across
various prompting methods, with an average improvement of 14.0\%$\uparrow$.
Claude 3 and ChatGPT demonstrate the next best performance after GPT-4. (3)
Few-shot IO prompting method outperforms the other two methods: zero-shot IO
and few-shot CoT. The reason is that sarcasm detection, being a holistic,
intuitive, and non-rational cognitive process, is argued not to adhere to
step-by-step logical reasoning, making CoT less effective in understanding
sarcasm compared to its effectiveness in mathematical reasoning tasks.",2024-08-21,"Yazhou Zhang, Chunwang Zou, Zheng Lian, Prayag Tiwari, Jing Qin",http://arxiv.org/pdf/2408.11319v2,cs.CL
EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models,"Large Language Models (LLMs) are increasingly attracting attention in various
applications. Nonetheless, there is a growing concern as some users attempt to
exploit these models for malicious purposes, including the synthesis of
controlled substances and the propagation of disinformation. In an effort to
mitigate such risks, the concept of ""Alignment"" technology has been developed.
However, recent studies indicate that this alignment can be undermined using
sophisticated prompt engineering or adversarial suffixes, a technique known as
""Jailbreak."" Our research takes cues from the human-like generate process of
LLMs. We identify that while jailbreaking prompts may yield output logits
similar to benign prompts, their initial embeddings within the model's latent
space tend to be more analogous to those of malicious prompts. Leveraging this
finding, we propose utilizing the early transformer outputs of LLMs as a means
to detect malicious inputs, and terminate the generation immediately. Built
upon this idea, we introduce a simple yet significant defense approach called
EEG-Defender for LLMs. We conduct comprehensive experiments on ten jailbreak
methods across three models. Our results demonstrate that EEG-Defender is
capable of reducing the Attack Success Rate (ASR) by a significant margin,
roughly 85\% in comparison with 50\% for the present SOTAs, with minimal impact
on the utility and effectiveness of LLMs.",2024-08-21,"Chongwen Zhao, Zhihao Dou, Kaizhu Huang",http://arxiv.org/pdf/2408.11308v1,cs.CL
RePair: Automated Program Repair with Process-based Feedback,"The gap between the trepidation of program reliability and the expense of
repairs underscores the indispensability of Automated Program Repair (APR). APR
is instrumental in transforming vulnerable programs into more robust ones,
bolstering program reliability while simultaneously diminishing the financial
burden of manual repairs. Commercial-scale language models (LM) have taken APR
to unprecedented levels. However, the emergence reveals that for models fewer
than 100B parameters, making single-step modifications may be difficult to
achieve the desired effect. Moreover, humans interact with the LM through
explicit prompts, which hinders the LM from receiving feedback from compiler
and test cases to automatically optimize its repair policies. In this
literature, we explore how small-scale LM (less than 20B) achieve excellent
performance through process supervision and feedback. We start by constructing
a dataset named CodeNet4Repair, replete with multiple repair records, which
supervises the fine-tuning of a foundational model. Building upon the
encouraging outcomes of reinforcement learning, we develop a reward model that
serves as a critic, providing feedback for the fine-tuned LM's action,
progressively optimizing its policy. During inference, we require the LM to
generate solutions iteratively until the repair effect no longer improves or
hits the maximum step limit. The results show that process-based not only
outperforms larger outcome-based generation methods, but also nearly matches
the performance of closed-source commercial large-scale LMs.",2024-08-21,"Yuze Zhao, Zhenya Huang, Yixiao Ma, Rui Li, Kai Zhang, Hao Jiang, Qi Liu, Linbo Zhu, Yu Su",http://arxiv.org/pdf/2408.11296v1,cs.CL
RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining,"The field of Natural Language Processing (NLP) has seen significant
advancements with the development of Large Language Models (LLMs). However,
much of this research remains focused on English, often overlooking
low-resource languages like Korean. This oversight presents challenges due to
the unique non-alphabetic token structure of Korean and the substantial memory
and computational demands required for LLM training, which frequently lead to
memory constraints and out-of-memory errors. To address these issues, we
present RedWhale, a model specifically tailored for Korean language processing.
RedWhale is developed using an efficient continual pretraining approach that
includes a comprehensive Korean corpus preprocessing pipeline, a specialized
tokenizer, an optimized model initialization technique, and a multistage
pretraining strategy. These innovations collectively reduce training time and
computational costs while maintaining high levels of accuracy and
comprehension. By leveraging cross-lingual transfer learning, which exploits
shared linguistic similarities across languages, RedWhale builds on English
models to enhance Korean language processing. Experimental results demonstrate
that RedWhale outperforms other leading models on Korean NLP benchmarks,
including the Korean Balanced Evaluation of Significant Tasks (KoBEST), showing
superior understanding and generation of Korean text. Furthermore, RedWhale
showed no signs of convergence even after pretraining on 9.7 billion tokens,
indicating the potential for further improvements with additional training.
This work represents a significant advancement in bridging the linguistic
divide, particularly in enhancing NLP capabilities for the Korean language.",2024-08-21,"Anh-Dung Vo, Minseong Jung, Wonbeen Lee, Daewoo Choi",http://arxiv.org/pdf/2408.11294v1,cs.CL
Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models,"Large Vision-Language Models (LVLMs) have shown significant capability in
vision-language understanding. However, one critical issue that persists in
these models is sycophancy, which means models are unduly influenced by leading
or deceptive prompts, resulting in biased outputs and hallucinations. Despite
the progress in LVLMs, evaluating and mitigating sycophancy is yet much
under-explored. In this work, we fill this gap by systematically analyzing
sycophancy on various VL benchmarks with curated leading queries and further
proposing a text contrastive decoding method for mitigation. While the specific
sycophantic behavior varies significantly among models, our analysis reveals
the severe deficiency of all LVLMs in resilience of sycophancy across various
tasks. For improvement, we propose Leading Query Contrastive Decoding (LQCD), a
model-agnostic method focusing on calibrating the LVLMs' over-reliance on
leading cues by identifying and suppressing the probabilities of sycophancy
tokens at the decoding stage. Extensive experiments show that LQCD effectively
mitigate sycophancy, outperforming both prompt engineering methods and common
methods for hallucination mitigation. We further demonstrate that LQCD does not
hurt but even slightly improves LVLMs' responses to neutral queries, suggesting
it being a more effective strategy for general-purpose decoding but not limited
to sycophancy.",2024-08-21,"Yunpu Zhao, Rui Zhang, Junbin Xiao, Changxin Ke, Ruibo Hou, Yifan Hao, Qi Guo, Yunji Chen",http://arxiv.org/pdf/2408.11261v1,cs.CL
Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers,"Modeling the errors of a speech recognizer can help simulate errorful
recognized speech data from plain text, which has proven useful for tasks like
discriminative language modeling, improving robustness of NLP systems, where
limited or even no audio data is available at train time. Previous work
typically considered replicating behavior of GMM-HMM based systems, but the
behavior of more modern posterior-based neural network acoustic models is not
the same and requires adjustments to the error prediction model. In this work,
we extend a prior phonetic confusion based model for predicting speech
recognition errors in two ways: first, we introduce a sampling-based paradigm
that better simulates the behavior of a posterior-based acoustic model. Second,
we investigate replacing the confusion matrix with a sequence-to-sequence model
in order to introduce context dependency into the prediction. We evaluate the
error predictors in two ways: first by predicting the errors made by a
Switchboard ASR system on unseen data (Fisher), and then using that same
predictor to estimate the behavior of an unrelated cloud-based ASR system on a
novel task. Sampling greatly improves predictive accuracy within a 100-guess
paradigm, while the sequence model performs similarly to the confusion matrix.",2024-08-21,"Prashant Serai, Peidong Wang, Eric Fosler-Lussier",http://arxiv.org/pdf/2408.11258v1,cs.CL
Counterfactuals As a Means for Evaluating Faithfulness of Attribution Methods in Autoregressive Language Models,"Despite the widespread adoption of autoregressive language models,
explainability evaluation research has predominantly focused on span infilling
and masked language models. Evaluating the faithfulness of an explanation
method -- how accurately it explains the inner workings and decision-making of
the model -- is challenging because it is difficult to separate the model from
its explanation. Most faithfulness evaluation techniques corrupt or remove
input tokens deemed important by a particular attribution (feature importance)
method and observe the resulting change in the model's output. However, for
autoregressive language models, this approach creates out-of-distribution
inputs due to their next-token prediction training objective. In this study, we
propose a technique that leverages counterfactual generation to evaluate the
faithfulness of attribution methods for autoregressive language models. Our
technique generates fluent, in-distribution counterfactuals, making the
evaluation protocol more reliable.",2024-08-21,"Sepehr Kamahi, Yadollah Yaghoobzadeh",http://arxiv.org/pdf/2408.11252v4,cs.CL
Unboxing Occupational Bias: Grounded Debiasing of LLMs with U.S. Labor Data,"Large Language Models (LLMs) are prone to inheriting and amplifying societal
biases embedded within their training data, potentially reinforcing harmful
stereotypes related to gender, occupation, and other sensitive categories. This
issue becomes particularly problematic as biased LLMs can have far-reaching
consequences, leading to unfair practices and exacerbating social inequalities
across various domains, such as recruitment, online content moderation, or even
the criminal justice system. Although prior research has focused on detecting
bias in LLMs using specialized datasets designed to highlight intrinsic biases,
there has been a notable lack of investigation into how these findings
correlate with authoritative datasets, such as those from the U.S. National
Bureau of Labor Statistics (NBLS). To address this gap, we conduct empirical
research that evaluates LLMs in a ``bias-out-of-the-box"" setting, analyzing how
the generated outputs compare with the distributions found in NBLS data.
Furthermore, we propose a straightforward yet effective debiasing mechanism
that directly incorporates NBLS instances to mitigate bias within LLMs. Our
study spans seven different LLMs, including instructable, base, and
mixture-of-expert models, and reveals significant levels of bias that are often
overlooked by existing bias detection techniques. Importantly, our debiasing
method, which does not rely on external datasets, demonstrates a substantial
reduction in bias scores, highlighting the efficacy of our approach in creating
fairer and more reliable LLMs.",2024-08-20,"Atmika Gorti, Manas Gaur, Aman Chadha",http://arxiv.org/pdf/2408.11247v2,cs.CL
A Little Confidence Goes a Long Way,"We introduce a group of related methods for binary classification tasks using
probes of the hidden state activations in large language models (LLMs).
Performance is on par with the largest and most advanced LLMs currently
available, but requiring orders of magnitude fewer computational resources and
not requiring labeled data. This approach involves translating class labels
into a semantically rich description, spontaneous symmetry breaking of
multilayer perceptron probes for unsupervised learning and inference, training
probes to generate confidence scores (prior probabilities) from hidden state
activations subject to known constraints via entropy maximization, and
selecting the most confident probe model from an ensemble for prediction. These
techniques are evaluated on four datasets using five base LLMs.",2024-08-20,"John Scoville, Shang Gao, Devanshu Agrawal, Javed Qadrud-Din",http://arxiv.org/pdf/2408.11239v1,cs.CL
Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification,"Detecting out-of-distribution (OOD) data is crucial in machine learning
applications to mitigate the risk of model overconfidence, thereby enhancing
the reliability and safety of deployed systems. The majority of existing OOD
detection methods predominantly address uni-modal inputs, such as images or
texts. In the context of multi-modal documents, there is a notable lack of
extensive research on the performance of these methods, which have primarily
been developed with a focus on computer vision tasks. We propose a novel
methodology termed as attention head masking (AHM) for multi-modal OOD tasks in
document classification systems. Our empirical results demonstrate that the
proposed AHM method outperforms all state-of-the-art approaches and
significantly decreases the false positive rate (FPR) compared to existing
solutions up to 7.5\%. This methodology generalizes well to multi-modal data,
such as documents, where visual and textual information are modeled under the
same Transformer architecture. To address the scarcity of high-quality publicly
available document datasets and encourage further research on OOD detection for
documents, we introduce FinanceDocs, a new document AI dataset. Our code and
dataset are publicly available.",2024-08-20,"Christos Constantinou, Georgios Ioannides, Aman Chadha, Aaron Elkins, Edwin Simpson",http://arxiv.org/pdf/2408.11237v1,cs.CL
CoDi: Conversational Distillation for Grounded Question Answering,"Distilling conversational skills into Small Language Models (SLMs) with
approximately 1 billion parameters presents significant challenges. Firstly,
SLMs have limited capacity in their model parameters to learn extensive
knowledge compared to larger models. Secondly, high-quality conversational
datasets are often scarce, small, and domain-specific. Addressing these
challenges, we introduce a novel data distillation framework named CoDi (short
for Conversational Distillation, pronounced ""Cody""), allowing us to synthesize
large-scale, assistant-style datasets in a steerable and diverse manner.
Specifically, while our framework is task agnostic at its core, we explore and
evaluate the potential of CoDi on the task of conversational grounded reasoning
for question answering. This is a typical on-device scenario for specialist
SLMs, allowing for open-domain model responses, without requiring the model to
""memorize"" world knowledge in its limited weights. Our evaluations show that
SLMs trained with CoDi-synthesized data achieve performance comparable to
models trained on human-annotated data in standard metrics. Additionally, when
using our framework to generate larger datasets from web data, our models
surpass larger, instruction-tuned models in zero-shot conversational grounded
reasoning tasks.",2024-08-20,"Patrick Huber, Arash Einolghozati, Rylan Conway, Kanika Narang, Matt Smith, Waqar Nayyar, Adithya Sagar, Ahmed Aly, Akshat Shrivastava",http://arxiv.org/pdf/2408.11219v1,cs.CL
DSP-MLIR: A MLIR Dialect for Digital Signal Processing,"Traditional Digital Signal Processing ( DSP ) compilers work at low level (
C-level / assembly level ) and hence lose much of the optimization
opportunities present at high-level ( domain-level ). The emerging multi-level
compiler infrastructure MLIR ( Multi-level Intermediate Representation ) allows
to specify optimizations at higher level. In this paper, we utilize MLIR
framework to introduce a DSP Dialect and perform domain-specific optimizations
at dialect -level ( high-level ) and show the usefulness of these optimizations
on sample DSP apps. In particular, we develop a compiler for DSP and a DSL
(Domain Specific Language) to ease the development of apps. We show the
performance improvement in execution time for these sample apps by upto 10x
which would have been difficult if the IR were at C/ affine level.",2024-08-20,"Abhinav Kumar, Atharva Khedkar, Aviral Shrivastava",http://arxiv.org/pdf/2408.11205v1,cs.CL
Reading with Intent,"Retrieval augmented generation (RAG) systems augment how knowledge language
models are by integrating external information sources such as Wikipedia,
internal documents, scientific papers, or the open internet. RAG systems that
rely on the open internet as their knowledge source have to contend with the
complexities of human-generated content. Human communication extends much
deeper than just the words rendered as text. Intent, tonality, and connotation
can all change the meaning of what is being conveyed. Recent real-world
deployments of RAG systems have shown some difficulty in understanding these
nuances of human communication. One significant challenge for these systems
lies in processing sarcasm. Though the Large Language Models (LLMs) that make
up the backbone of these RAG systems are able to detect sarcasm, they currently
do not always use these detections for the subsequent processing of text. To
address these issues, in this paper, we synthetically generate sarcastic
passages from Natural Question's Wikipedia retrieval corpus. We then test the
impact of these passages on the performance of both the retriever and reader
portion of the RAG pipeline. We introduce a prompting system designed to
enhance the model's ability to interpret and generate responses in the presence
of sarcasm, thus improving overall system performance. Finally, we conduct
ablation studies to validate the effectiveness of our approach, demonstrating
improvements in handling sarcastic content within RAG systems.",2024-08-20,"Benjamin Reichman, Kartik Talamadupula, Toshish Jawale, Larry Heck",http://arxiv.org/pdf/2408.11189v1,cs.CL
Combining Objective and Subjective Perspectives for Political News Understanding,"Researchers and practitioners interested in computational politics rely on
automatic content analysis tools to make sense of the large amount of political
texts available on the Web. Such tools should provide objective and subjective
aspects at different granularity levels to make the analyses useful in
practice. Existing methods produce interesting insights for objective aspects,
but are limited for subjective ones, are often limited to national contexts,
and have limited explainability. We introduce a text analysis framework which
integrates both perspectives and provides a fine-grained processing of
subjective aspects. Information retrieval techniques and knowledge bases
complement powerful natural language processing components to allow a flexible
aggregation of results at different granularity levels. Importantly, the
proposed bottom-up approach facilitates the explainability of the obtained
results. We illustrate its functioning with insights on news outlets, political
orientations, topics, individual entities, and demographic segments. The
approach is instantiated on a large corpus of French news, but is designed to
work seamlessly for other languages and countries.",2024-08-20,"Evan Dufraisse, Adrian Popescu, Julien Tourille, Armelle Brun, Olivier Hamon",http://arxiv.org/pdf/2408.11174v1,cs.CL
SubgoalXL: Subgoal-based Expert Learning for Theorem Proving,"Formal theorem proving, a field at the intersection of mathematics and
computer science, has seen renewed interest with advancements in large language
models (LLMs). This paper introduces SubgoalXL, a novel approach that
synergizes subgoal-based proofs with expert learning to enhance LLMs'
capabilities in formal theorem proving within the Isabelle environment.
SubgoalXL addresses two critical challenges: the scarcity of specialized
mathematics and theorem-proving data, and the need for improved multi-step
reasoning abilities in LLMs. By optimizing data efficiency and employing
subgoal-level supervision, SubgoalXL extracts richer information from limited
human-generated proofs. The framework integrates subgoal-oriented proof
strategies with an expert learning system, iteratively refining formal
statement, proof, and subgoal generators. Leveraging the Isabelle environment's
advantages in subgoal-based proofs, SubgoalXL achieves a new state-of-the-art
performance of 56.1\% in Isabelle on the standard miniF2F dataset, marking an
absolute improvement of 4.9\%. Notably, SubgoalXL successfully solves 41 AMC12,
9 AIME, and 3 IMO problems from miniF2F. These results underscore the
effectiveness of maximizing limited data utility and employing targeted
guidance for complex reasoning in formal theorem proving, contributing to the
ongoing advancement of AI reasoning capabilities. The implementation is
available at \url{https://github.com/zhaoxlpku/SubgoalXL}.",2024-08-20,"Xueliang Zhao, Lin Zheng, Haige Bo, Changran Hu, Urmish Thakker, Lingpeng Kong",http://arxiv.org/pdf/2408.11172v1,cs.CL
Public Health in Disaster: Emotional Health and Life Incidents Extraction during Hurricane Harvey,"Countless disasters have resulted from climate change, causing severe damage
to infrastructure and the economy. These disasters have significant societal
impacts, necessitating mental health services for the millions affected. To
prepare for and respond effectively to such events, it is important to
understand people's emotions and the life incidents they experience before and
after a disaster strikes. In this case study, we collected a dataset of
approximately 400,000 public tweets related to the storm. Using a BERT-based
model, we predicted the emotions associated with each tweet. To efficiently
identify these topics, we utilized the Latent Dirichlet Allocation (LDA)
technique for topic modeling, which allowed us to bypass manual content
analysis and extract meaningful patterns from the data. However, rather than
stopping at topic identification like previous methods \cite{math11244910}, we
further refined our analysis by integrating Graph Neural Networks (GNN) and
Large Language Models (LLM). The GNN was employed to generate embeddings and
construct a similarity graph of the tweets, which was then used to optimize
clustering. Subsequently, we used an LLM to automatically generate descriptive
names for each event cluster, offering critical insights for disaster
preparedness and response strategies.",2024-08-20,"Thomas Hoang, Quynh Anh Nguyen, Long Nguyen",http://arxiv.org/pdf/2408.11133v1,cs.CL
DOMBA: Double Model Balancing for Access-Controlled Language Models via Minimum-Bounded Aggregation,"The utility of large language models (LLMs) depends heavily on the quality
and quantity of their training data. Many organizations possess large data
corpora that could be leveraged to train or fine-tune LLMs tailored to their
specific needs. However, these datasets often come with access restrictions
that are based on user privileges and enforced by access control mechanisms.
Training LLMs on such datasets could result in exposure of sensitive
information to unauthorized users. A straightforward approach for preventing
such exposure is to train a separate model for each access level. This,
however, may result in low utility models due to the limited amount of training
data per model compared to the amount in the entire organizational corpus.
Another approach is to train a single LLM on all the data while limiting the
exposure of unauthorized information. However, current exposure-limiting
methods for LLMs are ineffective for access-controlled data, where sensitive
information appears frequently across many training examples. We propose DOMBA
- double model balancing - a simple approach for training and deploying LLMs
that provides high utility and access-control functionality with security
guarantees. DOMBA aggregates the probability distributions of two models, each
trained on documents with (potentially many) different access levels, using a
""min-bounded"" average function (a function that is bounded by the smaller
value, e.g., harmonic mean). A detailed mathematical analysis and extensive
evaluation show that DOMBA safeguards restricted information while offering
utility comparable to non-secure models.",2024-08-20,"Tom Segal, Asaf Shabtai, Yuval Elovici",http://arxiv.org/pdf/2408.11121v2,cs.CL
Mistral-SPLADE: LLMs for better Learned Sparse Retrieval,"Learned Sparse Retrievers (LSR) have evolved into an effective retrieval
strategy that can bridge the gap between traditional keyword-based sparse
retrievers and embedding-based dense retrievers. At its core, learned sparse
retrievers try to learn the most important semantic keyword expansions from a
query and/or document which can facilitate better retrieval with overlapping
keyword expansions. LSR like SPLADE has typically been using encoder only
models with MLM (masked language modeling) style objective in conjunction with
known ways of retrieval performance improvement such as hard negative mining,
distillation, etc. In this work, we propose to use decoder-only model for
learning semantic keyword expansion. We posit, decoder only models that have
seen much higher magnitudes of data are better equipped to learn keyword
expansions needed for improved retrieval. We use Mistral as the backbone to
develop our Learned Sparse Retriever similar to SPLADE and train it on a subset
of sentence-transformer data which is often used for training text embedding
models. Our experiments support the hypothesis that a sparse retrieval model
based on decoder only large language model (LLM) surpasses the performance of
existing LSR systems, including SPLADE and all its variants. The LLM based
model (Echo-Mistral-SPLADE) now stands as a state-of-the-art learned sparse
retrieval model on the BEIR text retrieval benchmark.",2024-08-20,"Meet Doshi, Vishwajeet Kumar, Rudra Murthy, Vignesh P, Jaydeep Sen",http://arxiv.org/pdf/2408.11119v2,cs.CL
FLAME: Learning to Navigate with Multimodal LLM in Urban Environments,"Large Language Models (LLMs) have demonstrated potential in
Vision-and-Language Navigation (VLN) tasks, yet current applications face
challenges. While LLMs excel in general conversation scenarios, they struggle
with specialized navigation tasks, yielding suboptimal performance compared to
specialized VLN models. We introduce FLAME (FLAMingo-Architected Embodied
Agent), a novel Multimodal LLM-based agent and architecture designed for urban
VLN tasks that efficiently handles multiple observations. Our approach
implements a three-phase tuning technique for effective adaptation to
navigation tasks, including single perception tuning for street view
description, multiple perception tuning for route summarization, and end-to-end
training on VLN datasets. The augmented datasets are synthesized automatically.
Experimental results demonstrate FLAME's superiority over existing methods,
surpassing state-of-the-art methods by a 7.3% increase in task completion on
Touchdown dataset. This work showcases the potential of Multimodal LLMs (MLLMs)
in complex navigation tasks, representing an advancement towards applications
of MLLMs in the field of embodied intelligence.",2024-08-20,"Yunzhe Xu, Yiyuan Pan, Zhe Liu, Hesheng Wang",http://arxiv.org/pdf/2408.11051v2,cs.CL
MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding,"Large Language Models (LLMs) have become more prevalent in long-context
applications such as interactive chatbots, document analysis, and agent
workflows, but it is challenging to serve long-context requests with low
latency and high throughput. Speculative decoding (SD) is a widely used
technique to reduce latency losslessly, but the conventional wisdom suggests
that its efficacy is limited to small batch sizes. In MagicDec, we show that
surprisingly SD can achieve speedup even for a high throughput inference regime
for moderate to long sequences. More interestingly, an intelligent drafting
strategy can achieve better speedup with increasing batch size based on our
rigorous analysis. MagicDec first identifies the bottleneck shifts with
increasing batch size and sequence length, and uses these insights to deploy SD
more effectively for high throughput inference. We leverage draft model with
sparse KV cache to address the KV bottleneck, which scales with both sequence
length and batch size. Additionally, we propose a theoretical model to select
the optimal drafting strategy for maximum speedup. Our work highlights the
broad applicability of speculative decoding in long-context serving, as it can
enhance throughput and reduce latency without compromising accuracy. For
moderate to long sequences, we demonstrate up to 2.51x speedup for Llama3.1-8B
when serving batch sizes ranging from 32 to 256 on various types of hardware
and tasks.",2024-08-20,"Ranajoy Sadhukhan, Jian Chen, Zhuoming Chen, Vashisth Tiwari, Ruihang Lai, Jinyuan Shi, Ian En-Hsu Yen, Avner May, Tianqi Chen, Beidi Chen",http://arxiv.org/pdf/2408.11049v5,cs.CL
Inside the Black Box: Detecting Data Leakage in Pre-trained Language Encoders,"Despite being prevalent in the general field of Natural Language Processing
(NLP), pre-trained language models inherently carry privacy and copyright
concerns due to their nature of training on large-scale web-scraped data. In
this paper, we pioneer a systematic exploration of such risks associated with
pre-trained language encoders, specifically focusing on the membership leakage
of pre-training data exposed through downstream models adapted from pre-trained
language encoders-an aspect largely overlooked in existing literature. Our
study encompasses comprehensive experiments across four types of pre-trained
encoder architectures, three representative downstream tasks, and five
benchmark datasets. Intriguingly, our evaluations reveal, for the first time,
the existence of membership leakage even when only the black-box output of the
downstream model is exposed, highlighting a privacy risk far greater than
previously assumed. Alongside, we present in-depth analysis and insights toward
guiding future researchers and practitioners in addressing the privacy
considerations in developing pre-trained language models.",2024-08-20,"Yuan Xin, Zheng Li, Ning Yu, Dingfan Chen, Mario Fritz, Michael Backes, Yang Zhang",http://arxiv.org/pdf/2408.11046v1,cs.CL
Beyond Labels: Aligning Large Language Models with Human-like Reasoning,"Aligning large language models (LLMs) with a human reasoning approach ensures
that LLMs produce morally correct and human-like decisions. Ethical concerns
are raised because current models are prone to generating false positives and
providing malicious responses. To contribute to this issue, we have curated an
ethics dataset named Dataset for Aligning Reasons (DFAR), designed to aid in
aligning language models to generate human-like reasons. The dataset comprises
statements with ethical-unethical labels and their corresponding reasons. In
this study, we employed a unique and novel fine-tuning approach that utilizes
ethics labels and their corresponding reasons (L+R), in contrast to the
existing fine-tuning approach that only uses labels (L). The original
pre-trained versions, the existing fine-tuned versions, and our proposed
fine-tuned versions of LLMs were then evaluated on an ethical-unethical
classification task and a reason-generation task. Our proposed fine-tuning
strategy notably outperforms the others in both tasks, achieving significantly
higher accuracy scores in the classification task and lower misalignment rates
in the reason-generation task. The increase in classification accuracies and
decrease in misalignment rates indicate that the L+R fine-tuned models align
more with human ethics. Hence, this study illustrates that injecting reasons
has substantially improved the alignment of LLMs, resulting in more human-like
responses. We have made the DFAR dataset and corresponding codes publicly
available at https://github.com/apurba-nsu-rnd-lab/DFAR.",2024-08-20,"Muhammad Rafsan Kabir, Rafeed Mohammad Sultan, Ihsanul Haque Asif, Jawad Ibn Ahad, Fuad Rahman, Mohammad Ruhul Amin, Nabeel Mohammed, Shafin Rahman",http://arxiv.org/pdf/2408.11879v1,cs.CL
Scaling Law with Learning Rate Annealing,"We find that the cross-entropy loss curves of neural language models
empirically adhere to a scaling law with learning rate (LR) annealing over
training steps: $$L(s) = L_0 + A\cdot S_1^{-\alpha} - C\cdot S_2,$$ where
$L(s)$ is the validation loss at step $s$, $S_1$ is the area under the LR
curve, $S_2$ is the LR annealing area, and $L_0$, $A$, $C$, $\alpha$ are
constant parameters. This formulation takes into account two factors: (1)
power-law scaling over data size, and (2) the additional loss reduction during
LR annealing. Therefore, this formulation can describe the full loss curve at
each step, rather than the single loss point at the end of training. Applying
the scaling law with LR annealing and fitting only one or two training curves,
we can accurately predict the loss at any given step across any learning rate
scheduler (LRS). This approach significantly reduces computational cost in
formulating scaling laws while providing more accuracy and expressiveness for
training dynamics. Extensive experiments demonstrate that our findings hold
across a range of hyper-parameters and model architectures, and our equation
can extend to scaling effect of model sizes. Moreover, our formulation provides
accurate theoretical verification and explanation for empirical results
observed in numerous previous studies, particularly those focusing on LR
schedule and annealing. We believe that this work is promising to enhance the
understanding of LLM training dynamics while greatly democratizing scaling
laws, and it can guide researchers in refining training strategies (e.g.
critical LRS) for further LLMs.",2024-08-20,"Howe Tissue, Venus Wang, Lu Wang",http://arxiv.org/pdf/2408.11029v2,cs.CL
Athena: Safe Autonomous Agents with Verbal Contrastive Learning,"Due to emergent capabilities, large language models (LLMs) have been utilized
as language-based agents to perform a variety of tasks and make decisions with
an increasing degree of autonomy. These autonomous agents can understand
high-level instructions, interact with their environments, and execute complex
tasks using a selection of tools available to them. As the capabilities of the
agents expand, ensuring their safety and trustworthiness becomes more
imperative. In this study, we introduce the Athena framework which leverages
the concept of verbal contrastive learning where past safe and unsafe
trajectories are used as in-context (contrastive) examples to guide the agent
towards safety while fulfilling a given task. The framework also incorporates a
critiquing mechanism to guide the agent to prevent risky actions at every step.
Furthermore, due to the lack of existing benchmarks on the safety reasoning
ability of LLM-based agents, we curate a set of 80 toolkits across 8 categories
with 180 scenarios to provide a safety evaluation benchmark. Our experimental
evaluation, with both closed- and open-source LLMs, indicates verbal
contrastive learning and interaction-level critiquing improve the safety rate
significantly.",2024-08-20,"Tanmana Sadhu, Ali Pesaranghader, Yanan Chen, Dong Hoon Yi",http://arxiv.org/pdf/2408.11021v1,cs.CL
Security Attacks on LLM-based Code Completion Tools,"The rapid development of large language models (LLMs) has significantly
advanced code completion capabilities, giving rise to a new generation of
LLM-based Code Completion Tools (LCCTs). Unlike general-purpose LLMs, these
tools possess unique workflows, integrating multiple information sources as
input and prioritizing code suggestions over natural language interaction,
which introduces distinct security challenges. Additionally, LCCTs often rely
on proprietary code datasets for training, raising concerns about the potential
exposure of sensitive data. This paper exploits these distinct characteristics
of LCCTs to develop targeted attack methodologies on two critical security
risks: jailbreaking and training data extraction attacks. Our experimental
results expose significant vulnerabilities within LCCTs, including a 99.4%
success rate in jailbreaking attacks on GitHub Copilot and a 46.3% success rate
on Amazon Q. Furthermore, We successfully extracted sensitive user data from
GitHub Copilot, including 54 real email addresses and 314 physical addresses
associated with GitHub usernames. Our study also demonstrates that these
code-based attack methods are effective against general-purpose LLMs, such as
the GPT series, highlighting a broader security misalignment in the handling of
code by modern LLMs. These findings underscore critical security challenges
associated with LCCTs and suggest essential directions for strengthening their
security frameworks. The example code and attack samples from our research are
provided at https://github.com/Sensente/Security-Attacks-on-LCCTs.",2024-08-20,"Wen Cheng, Ke Sun, Xinyu Zhang, Wei Wang",http://arxiv.org/pdf/2408.11006v4,cs.CL
Disentangling segmental and prosodic factors to non-native speech comprehensibility,"Current accent conversion (AC) systems do not disentangle the two main
sources of non-native accent: segmental and prosodic characteristics. Being
able to manipulate a non-native speaker's segmental and/or prosodic channels
independently is critical to quantify how these two channels contribute to
speech comprehensibility and social attitudes. We present an AC system that not
only decouples voice quality from accent, but also disentangles the latter into
its segmental and prosodic characteristics. The system is able to generate
accent conversions that combine (1) the segmental characteristics from a source
utterance, (2) the voice characteristics from a target utterance, and (3) the
prosody of a reference utterance. We show that vector quantization of acoustic
embeddings and removal of consecutive duplicated codewords allows the system to
transfer prosody and improve voice similarity. We conduct perceptual listening
tests to quantify the individual contributions of segmental features and
prosody on the perceived comprehensibility of non-native speech. Our results
indicate that, contrary to prior research in non-native speech, segmental
features have a larger impact on comprehensibility than prosody. The proposed
AC system may also be used to study how segmental and prosody cues affect
social attitudes towards non-native speech.",2024-08-20,"Waris Quamer, Ricardo Gutierrez-Osuna",http://arxiv.org/pdf/2408.10997v1,cs.CL
CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models,"New medical treatment development requires multiple phases of clinical
trials. Despite the significant human and financial costs of bringing a drug to
market, less than 20% of drugs in testing will make it from the first phase to
final approval. Recent literature indicates that the design of the trial
protocols significantly contributes to trial performance. We investigated
Clinical Trial Outcome Prediction (CTOP) using trial design documents to
predict phase transitions automatically. We propose CTP-LLM, the first Large
Language Model (LLM) based model for CTOP. We also introduce the
PhaseTransition (PT) Dataset; which labels trials based on their progression
through the regulatory process and serves as a benchmark for CTOP evaluation.
Our fine-tuned GPT-3.5-based model (CTP-LLM) predicts clinical trial phase
transition by analyzing the trial's original protocol texts without requiring
human-selected features. CTP-LLM achieves a 67% accuracy rate in predicting
trial phase transitions across all phases and a 75% accuracy rate specifically
in predicting the transition from Phase~III to final approval. Our experimental
performance highlights the potential of LLM-powered applications in forecasting
clinical trial outcomes and assessing trial design.",2024-08-20,"Michael Reinisch, Jianfeng He, Chenxi Liao, Sauleh Ahmad Siddiqui, Bei Xiao",http://arxiv.org/pdf/2408.10995v1,cs.CL
Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework,"Identifying effective interventions from the scientific literature is
challenging due to the high volume of publications, specialized terminology,
and inconsistent reporting formats, making manual curation laborious and prone
to oversight. To address this challenge, this paper proposes a novel framework
leveraging large language models (LLMs), which integrates a progressive
ontology prompting (POP) algorithm with a dual-agent system, named LLM-Duo. On
the one hand, the POP algorithm conducts a prioritized breadth-first search
(BFS) across a predefined ontology, generating structured prompt templates and
action sequences to guide the automatic annotation process. On the other hand,
the LLM-Duo system features two specialized LLM agents, an explorer and an
evaluator, working collaboratively and adversarially to continuously refine
annotation quality. We showcase the real-world applicability of our framework
through a case study focused on speech-language intervention discovery.
Experimental results show that our approach surpasses advanced baselines,
achieving more accurate and comprehensive annotations through a fully automated
process. Our approach successfully identified 2,421 interventions from a corpus
of 64,177 research articles in the speech-language pathology domain,
culminating in the creation of a publicly accessible intervention knowledge
base with great potential to benefit the speech-language pathology community.",2024-08-20,"Yuting Hu, Dancheng Liu, Qingyun Wang, Charles Yu, Chenhui Xu, Qingxiao Zheng, Heng Ji, Jinjun Xiong",http://arxiv.org/pdf/2409.00054v2,cs.CL
Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications,"Financial LLMs hold promise for advancing financial tasks and domain-specific
applications. However, they are limited by scarce corpora, weak multimodal
capabilities, and narrow evaluations, making them less suited for real-world
application. To address this, we introduce \textit{Open-FinLLMs}, the first
open-source multimodal financial LLMs designed to handle diverse tasks across
text, tabular, time-series, and chart data, excelling in zero-shot, few-shot,
and fine-tuning settings. The suite includes FinLLaMA, pre-trained on a
comprehensive 52-billion-token corpus; FinLLaMA-Instruct, fine-tuned with 573K
financial instructions; and FinLLaVA, enhanced with 1.43M multimodal tuning
pairs for strong cross-modal reasoning. We comprehensively evaluate
Open-FinLLMs across 14 financial tasks, 30 datasets, and 4 multimodal tasks in
zero-shot, few-shot, and supervised fine-tuning settings, introducing two new
multimodal evaluation datasets. Our results show that Open-FinLLMs outperforms
afvanced financial and general LLMs such as GPT-4, across financial NLP,
decision-making, and multi-modal tasks, highlighting their potential to tackle
real-world challenges. To foster innovation and collaboration across academia
and industry, we release all codes
(https://anonymous.4open.science/r/PIXIU2-0D70/B1D7/LICENSE) and models under
OSI-approved licenses.",2024-08-20,"Jimin Huang, Mengxi Xiao, Dong Li, Zihao Jiang, Yuzhe Yang, Yifei Zhang, Lingfei Qian, Yan Wang, Xueqing Peng, Yang Ren, Ruoyu Xiang, Zhengyu Chen, Xiao Zhang, Yueru He, Weiguang Han, Shunian Chen, Lihang Shen, Daniel Kim, Yangyang Yu, Yupeng Cao, Zhiyang Deng, Haohang Li, Duanyu Feng, Yongfu Dai, VijayaSai Somasundaram, Peng Lu, Guojun Xiong, Zhiwei Liu, Zheheng Luo, Zhiyuan Yao, Ruey-Ling Weng, Meikang Qiu, Kaleb E Smith, Honghai Yu, Yanzhao Lai, Min Peng, Jian-Yun Nie, Jordan W. Suchow, Xiao-Yang Liu, Benyou Wang, Alejandro Lopez-Lira, Qianqian Xie, Sophia Ananiadou, Junichi Tsujii",http://arxiv.org/pdf/2408.11878v2,cs.CL
NLP for The Greek Language: A Longer Survey,"English language is in the spotlight of the Natural Language Processing (NLP)
community with other languages, like Greek, lagging behind in terms of offered
methods, tools and resources. Due to the increasing interest in NLP, in this
paper we try to condense research efforts for the automatic processing of Greek
language covering the last three decades. In particular, we list and briefly
discuss related works, resources and tools, categorized according to various
processing layers and contexts. We are not restricted to the modern form of
Greek language but also cover Ancient Greek and various Greek dialects. This
survey can be useful for researchers and students interested in NLP tasks,
Information Retrieval and Knowledge Management for the Greek language.",2024-08-20,"Katerina Papantoniou, Yannis Tzitzikas",http://arxiv.org/pdf/2408.10962v1,cs.CL
Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models,"Teachers are important to imparting knowledge and guiding learners, and the
role of large language models (LLMs) as potential educators is emerging as an
important area of study. Recognizing LLMs' capability to generate educational
content can lead to advances in automated and personalized learning. While LLMs
have been tested for their comprehension and problem-solving skills, their
capability in teaching remains largely unexplored. In teaching, questioning is
a key skill that guides students to analyze, evaluate, and synthesize core
concepts and principles. Therefore, our research introduces a benchmark to
evaluate the questioning capability in education as a teacher of LLMs through
evaluating their generated educational questions, utilizing Anderson and
Krathwohl's taxonomy across general, monodisciplinary, and interdisciplinary
domains. We shift the focus from LLMs as learners to LLMs as educators,
assessing their teaching capability through guiding them to generate questions.
We apply four metrics, including relevance, coverage, representativeness, and
consistency, to evaluate the educational quality of LLMs' outputs. Our results
indicate that GPT-4 demonstrates significant potential in teaching general,
humanities, and science courses; Claude2 appears more apt as an
interdisciplinary teacher. Furthermore, the automatic scores align with human
perspectives.",2024-08-20,"Yuyan Chen, Chenwei Wu, Songzhou Yan, Panjun Liu, Haoyu Zhou, Yanghua Xiao",http://arxiv.org/pdf/2408.10947v1,cs.CL
SysBench: Can Large Language Models Follow System Messages?,"Large Language Models (LLMs) have become instrumental across various
applications, with the customization of these models to specific scenarios
becoming increasingly critical. System message, a fundamental component of
LLMs, is consist of carefully crafted instructions that guide the behavior of
model to meet intended goals. Despite the recognized potential of system
messages to optimize AI-driven solutions, there is a notable absence of a
comprehensive benchmark for evaluating how well LLMs follow system messages. To
fill this gap, we introduce SysBench, a benchmark that systematically analyzes
system message following ability in terms of three limitations of existing
LLMs: constraint violation, instruction misjudgement and multi-turn
instability. Specifically, we manually construct evaluation dataset based on
six prevalent types of constraints, including 500 tailor-designed system
messages and multi-turn user conversations covering various interaction
relationships. Additionally, we develop a comprehensive evaluation protocol to
measure model performance. Finally, we conduct extensive evaluation across
various existing LLMs, measuring their ability to follow specified constraints
given in system messages. The results highlight both the strengths and
weaknesses of existing models, offering key insights and directions for future
research. The open source library SysBench is available at
https://github.com/PKU-Baichuan-MLSystemLab/SysBench.",2024-08-20,"Yanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, Bin Cui",http://arxiv.org/pdf/2408.10943v2,cs.CL
LBC: Language-Based-Classifier for Out-Of-Variable Generalization,"Large Language Models (LLMs) have great success in natural language
processing tasks such as response generation. However, their use in tabular
data has been limited due to their inferior performance compared to traditional
machine learning models (TMLs) such as XGBoost. We find that the pre-trained
knowledge of LLMs enables them to interpret new variables that appear in a test
without additional training, a capability central to the concept of
Out-of-Variable (OOV). From the findings, we propose a
Language-Based-Classifier (LBC), a classifier that maximizes the benefits of
LLMs to outperform TMLs on OOV tasks. LBC employs three key methodological
strategies: 1) Categorical changes to adjust data to better fit the model's
understanding, 2) Advanced order and indicator to enhance data representation
to the model, and 3) Using verbalizer to map logit scores to classes during
inference to generate model predictions. These strategies, combined with the
pre-trained knowledge of LBC, emphasize the model's ability to effectively
handle OOV tasks. We empirically and theoretically validate the superiority of
LBC. LBC is the first study to apply an LLM-based model to OOV tasks. The
source code is at https://github.com/sksmssh/LBCforOOVGen",2024-08-20,"Kangjun Noh, Baekryun Seong, Hoyoon Byun, Youngjun Choi, Sungjin Song, Kyungwoo Song",http://arxiv.org/pdf/2408.10923v3,cs.CL
CHECKWHY: Causal Fact Verification via Argument Structure,"With the growing complexity of fact verification tasks, the concern with
""thoughtful"" reasoning capabilities is increasing. However, recent fact
verification benchmarks mainly focus on checking a narrow scope of semantic
factoids within claims and lack an explicit logical reasoning process. In this
paper, we introduce CheckWhy, a challenging dataset tailored to a novel causal
fact verification task: checking the truthfulness of the causal relation within
claims through rigorous reasoning steps. CheckWhy consists of over 19K ""why""
claim-evidence-argument structure triplets with supports, refutes, and not
enough info labels. Each argument structure is composed of connected evidence,
representing the reasoning process that begins with foundational evidence and
progresses toward claim establishment. Through extensive experiments on
state-of-the-art models, we validate the importance of incorporating the
argument structure for causal fact verification. Moreover, the automated and
human evaluation of argument structure generation reveals the difficulty in
producing satisfying argument structure by fine-tuned models or
Chain-of-Thought prompted LLMs, leaving considerable room for future
improvements.",2024-08-20,"Jiasheng Si, Yibo Zhao, Yingjie Zhu, Haiyang Zhu, Wenpeng Lu, Deyu Zhou",http://arxiv.org/pdf/2408.10918v2,cs.CL
"To Code, or Not To Code? Exploring Impact of Code in Pre-training","Including code in the pre-training data mixture, even for models not
specifically designed for code, has become a common practice in LLMs
pre-training. While there has been anecdotal consensus among practitioners that
code data plays a vital role in general LLMs' performance, there is only
limited work analyzing the precise impact of code on non-code tasks. In this
work, we systematically investigate the impact of code data on general
performance. We ask ""what is the impact of code data used in pre-training on a
large variety of downstream tasks beyond code generation"". We conduct extensive
ablations and evaluate across a broad range of natural language reasoning
tasks, world knowledge tasks, code benchmarks, and LLM-as-a-judge win-rates for
models with sizes ranging from 470M to 2.8B parameters. Across settings, we
find a consistent results that code is a critical building block for
generalization far beyond coding tasks and improvements to code quality have an
outsized impact across all tasks. In particular, compared to text-only
pre-training, the addition of code results in up to relative increase of 8.2%
in natural language (NL) reasoning, 4.2% in world knowledge, 6.6% improvement
in generative win-rates, and a 12x boost in code performance respectively. Our
work suggests investments in code quality and preserving code during
pre-training have positive impacts.",2024-08-20,"Viraat Aryabumi, Yixuan Su, Raymond Ma, Adrien Morisot, Ivan Zhang, Acyr Locatelli, Marzieh Fadaee, Ahmet Üstün, Sara Hooker",http://arxiv.org/pdf/2408.10914v1,cs.CL
BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model,"The rapid advancement of large language models (LLMs) has revolutionized
role-playing, enabling the development of general role-playing models. However,
current role-playing training has two significant issues: (I) Using a
predefined role profile to prompt dialogue training for specific scenarios
usually leads to inconsistencies and even conflicts between the dialogue and
the profile, resulting in training biases. (II) The model learns to imitate the
role based solely on the profile, neglecting profile-dialogue alignment at the
sentence level. In this work, we propose a simple yet effective framework
called BEYOND DIALOGUE, designed to overcome these hurdles. This framework
innovatively introduces ""beyond dialogue"" tasks to align dialogue with profile
traits based on each specific scenario, thereby eliminating biases during
training. Furthermore, by adopting an innovative prompting mechanism that
generates reasoning outcomes for training, the framework allows the model to
achieve fine-grained alignment between profile and dialogue at the sentence
level. The aforementioned methods are fully automated and low-cost.
Additionally, the integration of automated dialogue and objective evaluation
methods forms a comprehensive framework, paving the way for general
role-playing. Experimental results demonstrate that our model excels in
adhering to and reflecting various dimensions of role profiles, outperforming
most proprietary general and specialized role-playing baselines. All code and
datasets are available at https://github.com/yuyouyu32/BeyondDialogue.",2024-08-20,"Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian",http://arxiv.org/pdf/2408.10903v5,cs.CL
Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs,"Although human evaluation remains the gold standard for open-domain dialogue
evaluation, the growing popularity of automated evaluation using Large Language
Models (LLMs) has also extended to dialogue. However, most frameworks leverage
benchmarks that assess older chatbots on aspects such as fluency and relevance,
which are not reflective of the challenges associated with contemporary models.
In fact, a qualitative analysis on Soda, a GPT-3.5 generated dialogue dataset,
suggests that current chatbots may exhibit several recurring issues related to
coherence and commonsense knowledge, but generally produce highly fluent and
relevant responses.
  Noting the aforementioned limitations, this paper introduces Soda-Eval, an
annotated dataset based on Soda that covers over 120K turn-level assessments
across 10K dialogues, where the annotations were generated by GPT-4. Using
Soda-Eval as a benchmark, we then study the performance of several open-access
instruction-tuned LLMs, finding that dialogue evaluation remains challenging.
Fine-tuning these models improves performance over few-shot inferences, both in
terms of correlation and explanation.",2024-08-20,"John Mendonça, Isabel Trancoso, Alon Lavie",http://arxiv.org/pdf/2408.10902v3,cs.CL
Benchmarking Large Language Models for Math Reasoning Tasks,"The use of Large Language Models (LLMs) in mathematical reasoning has become
a cornerstone of related research, demonstrating the intelligence of these
models and enabling potential practical applications through their advanced
performance, such as in educational settings. Despite the variety of datasets
and in-context learning algorithms designed to improve the ability of LLMs to
automate mathematical problem solving, the lack of comprehensive benchmarking
across different datasets makes it complicated to select an appropriate model
for specific tasks. In this project, we present a benchmark that fairly
compares seven state-of-the-art in-context learning algorithms for mathematical
problem solving across five widely used mathematical datasets on four powerful
foundation models. Furthermore, we explore the trade-off between efficiency and
performance, highlighting the practical applications of LLMs for mathematical
reasoning. Our results indicate that larger foundation models like GPT-4o and
LLaMA 3-70B can solve mathematical reasoning independently from the concrete
prompting strategy, while for smaller models the in-context learning approach
significantly influences the performance. Moreover, the optimal prompt depends
on the chosen foundation model. We open-source our benchmark code to support
the integration of additional models in future research.",2024-08-20,"Kathrin Seßler, Yao Rong, Emek Gözlüklü, Enkelejda Kasneci",http://arxiv.org/pdf/2408.10839v2,cs.CL
GS-KGC: A Generative Subgraph-based Framework for Knowledge Graph Completion with Large Language Models,"Knowledge graph completion (KGC) focuses on identifying missing triples in a
knowledge graph (KG) , which is crucial for many downstream applications. Given
the rapid development of large language models (LLMs), some LLM-based methods
are proposed for KGC task. However, most of them focus on prompt engineering
while overlooking the fact that finer-grained subgraph information can aid LLMs
in generating more accurate answers. In this paper, we propose a novel
completion framework called \textbf{G}enerative \textbf{S}ubgraph-based KGC
(GS-KGC), which utilizes subgraph information as contextual reasoning and
employs a QA approach to achieve the KGC task. This framework primarily
includes a subgraph partitioning algorithm designed to generate negatives and
neighbors. Specifically, negatives can encourage LLMs to generate a broader
range of answers, while neighbors provide additional contextual insights for
LLM reasoning. Furthermore, we found that GS-KGC can discover potential triples
within the KGs and new facts beyond the KGs. Experiments conducted on four
common KGC datasets highlight the advantages of the proposed GS-KGC, e.g., it
shows a 5.6\% increase in Hits@3 compared to the LLM-based model CP-KGC on the
FB15k-237N, and a 9.3\% increase over the LLM-based model TECHS on the ICEWS14.",2024-08-20,"Rui Yang, Jiahao Zhu, Jianping Man, Hongze Liu, Li Fang, Yi Zhou",http://arxiv.org/pdf/2408.10819v2,cs.CL
Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?,"In this study, we investigate whether non-English-centric LLMs, despite their
strong performance, `think' in their respective dominant language: more
precisely, `think' refers to how the representations of intermediate layers,
when un-embedded into the vocabulary space, exhibit higher probabilities for
certain dominant languages during generation. We term such languages as
internal $\textbf{latent languages}$.
  We examine the latent language of three typical categories of models for
Japanese processing: Llama2, an English-centric model; Swallow, an
English-centric model with continued pre-training in Japanese; and LLM-jp, a
model pre-trained on balanced English and Japanese corpora. Our empirical
findings reveal that, unlike Llama2 which relies exclusively on English as the
internal latent language, Japanese-specific Swallow and LLM-jp employ both
Japanese and English, exhibiting dual internal latent languages. For any given
target language, the model preferentially activates the latent language most
closely related to it. In addition, we explore how intermediate layers respond
to questions involving cultural conflicts between latent internal and target
output languages. We further explore how the language identity shifts across
layers while keeping consistent semantic meaning reflected in the intermediate
layer representations.
  This study deepens the understanding of non-English-centric large language
models, highlighting the intricate dynamics of language representation within
their intermediate layers.",2024-08-20,"Chengzhi Zhong, Fei Cheng, Qianying Liu, Junfeng Jiang, Zhen Wan, Chenhui Chu, Yugo Murawaki, Sadao Kurohashi",http://arxiv.org/pdf/2408.10811v1,cs.CL
ColBERT Retrieval and Ensemble Response Scoring for Language Model Question Answering,"Domain-specific question answering remains challenging for language models,
given the deep technical knowledge required to answer questions correctly. This
difficulty is amplified for smaller language models that cannot encode as much
information in their parameters as larger models. The ""Specializing Large
Language Models for Telecom Networks"" challenge aimed to enhance the
performance of two small language models, Phi-2 and Falcon-7B in
telecommunication question answering. In this paper, we present our question
answering systems for this challenge. Our solutions achieved leading marks of
81.9% accuracy for Phi-2 and 57.3% for Falcon-7B. We have publicly released our
code and fine-tuned models.",2024-08-20,"Alex Gichamba, Tewodros Kederalah Idris, Brian Ebiyau, Eric Nyberg, Teruko Mitamura",http://arxiv.org/pdf/2408.10808v2,cs.CL
Adversarial Attack for Explanation Robustness of Rationalization Models,"Rationalization models, which select a subset of input text as
rationale-crucial for humans to understand and trust predictions-have recently
emerged as a prominent research area in eXplainable Artificial Intelligence.
However, most of previous studies mainly focus on improving the quality of the
rationale, ignoring its robustness to malicious attack. Specifically, whether
the rationalization models can still generate high-quality rationale under the
adversarial attack remains unknown. To explore this, this paper proposes UAT2E,
which aims to undermine the explainability of rationalization models without
altering their predictions, thereby eliciting distrust in these models from
human users. UAT2E employs the gradient-based search on triggers and then
inserts them into the original input to conduct both the non-target and target
attack. Experimental results on five datasets reveal the vulnerability of
rationalization models in terms of explanation, where they tend to select more
meaningless tokens under attacks. Based on this, we make a series of
recommendations for improving rationalization models in terms of explanation.",2024-08-20,"Yuankai Zhang, Lingxiao Kong, Haozhao Wang, Ruixuan Li, Jun Wang, Yuhua Li, Wei Liu",http://arxiv.org/pdf/2408.10795v3,cs.CL
Flexora: Flexible Low Rank Adaptation for Large Language Models,"Large Language Models (LLMs) are driving advancements in artificial
intelligence by increasing the scale of model parameters, which has
significantly enhanced generalization ability and unlocked new capabilities in
practice. However, their performance in specific downstream tasks is usually
hindered by their knowledge boundaries on these tasks. Thus, fine-tuning
techniques, especially the widely used Low-Rank Adaptation (LoRA) method, have
been introduced to expand the boundaries on these tasks, whereas LoRA would
underperform on certain tasks owing to its potential overfitting on these
tasks. To overcome this overfitting and improve the performance of LoRA, we
propose the flexible low rank adaptation (Flexora) method to automatically and
flexibly select the most important layers needing to be fine-tuned to achieve
the best performance on different downstream tasks. Specifically, Flexora
firstly frames this layer selection problem as a well-defined hyperparameter
optimization (HPO) problem, then addresses it using the unrolled
differentiation (UD) method, and finally selects the most useful layers based
on the optimized hyperparameters. Our extensive experiments on many pretrained
models and natural language tasks show that Flexora is able to consistently
improve over the existing baselines, indicating the effectiveness of our
Flexora in practice. We additionally provide insightful theoretical results and
many ablation studies to deliver a comprehensive understanding of our Flexora.",2024-08-20,"Chenxing Wei, Yao Shu, Ying Tiffany He, Fei Richard Yu",http://arxiv.org/pdf/2408.10774v3,cs.CL
Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model,"Transformer-based large language models (LLMs) exhibit limitations such as
generating unsafe responses, unreliable reasoning, etc. Existing inference
intervention approaches attempt to mitigate these issues by finetuning
additional models to produce calibration signals (such as rewards) that guide
the LLM's decoding process. However, this solution introduces substantial time
and space overhead due to the separate models required. This work proposes
Non-disruptive parameters insertion (Otter), inserting extra parameters into
the transformer architecture to predict calibration signals along with the
original LLM output. Otter offers state-of-the-art performance on multiple
demanding tasks while saving up to 86.5\% extra space and 98.5\% extra time.
Furthermore, Otter seamlessly integrates with existing inference engines,
requiring only a one-line code change, and the original model response remains
accessible after the parameter insertion. Our code is publicly available at
\url{https://github.com/chenhan97/Otter}",2024-08-20,"Chenhan Yuan, Fei Huang, Ru Peng, Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou",http://arxiv.org/pdf/2408.10764v1,cs.CL
What can Large Language Models Capture about Code Functional Equivalence?,"Code-LLMs, LLMs pre-trained on large code corpora, have shown great progress
in learning rich representations of the structure and syntax of code,
successfully using it to generate or classify code fragments. At the same time,
understanding if they are able to do so because they capture code semantics,
and how well, is still an open question. In this paper, we tackle this problem
by introducing SeqCoBench, a benchmark for systematically assessing how
Code-LLMs can capture code functional equivalence. SeqCoBench contains over 20
code transformations that either preserve or alter the semantics of Python
programs. We conduct extensive evaluations in different settings, including
zero-shot and parameter-efficient finetuning methods on state-of-the-art
(Code)-LLMs to see if they can discern semantically equivalent or different
pairs of programs in SeqCoBench. We find that the performance gap between these
LLMs and classical match-based retrieval scores is minimal, with both
approaches showing a concerning lack of depth in understanding code semantics.",2024-08-20,"Nickil Maveli, Antonio Vergari, Shay B. Cohen",http://arxiv.org/pdf/2408.11081v2,cs.CL
Towards Efficient Large Language Models for Scientific Text: A Review,"Large language models (LLMs) have ushered in a new era for processing complex
information in various fields, including science. The increasing amount of
scientific literature allows these models to acquire and understand scientific
knowledge effectively, thus improving their performance in a wide range of
tasks. Due to the power of LLMs, they require extremely expensive computational
resources, intense amounts of data, and training time. Therefore, in recent
years, researchers have proposed various methodologies to make scientific LLMs
more affordable. The most well-known approaches align in two directions. It can
be either focusing on the size of the models or enhancing the quality of data.
To date, a comprehensive review of these two families of methods has not yet
been undertaken. In this paper, we (I) summarize the current advances in the
emerging abilities of LLMs into more accessible AI solutions for science, and
(II) investigate the challenges and opportunities of developing affordable
solutions for scientific domains using LLMs.",2024-08-20,"Huy Quoc To, Ming Liu, Guangyan Huang",http://arxiv.org/pdf/2408.10729v1,cs.CL
"Crafting Tomorrow's Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian","In the era dominated by information overload and its facilitation with Large
Language Models (LLMs), the prevalence of misinformation poses a significant
threat to public discourse and societal well-being. A critical concern at
present involves the identification of machine-generated news. In this work, we
take a significant step by introducing a benchmark dataset designed for neural
news detection in four languages: English, Turkish, Hungarian, and Persian. The
dataset incorporates outputs from multiple multilingual generators (in both,
zero-shot and fine-tuned setups) such as BloomZ, LLaMa-2, Mistral, Mixtral, and
GPT-4. Next, we experiment with a variety of classifiers, ranging from those
based on linguistic features to advanced Transformer-based models and LLMs
prompting. We present the detection results aiming to delve into the
interpretablity and robustness of machine-generated texts detectors across all
target languages.",2024-08-20,"Cem Üyük, Danica Rovó, Shaghayegh Kolli, Rabia Varol, Georg Groh, Daryna Dementieva",http://arxiv.org/pdf/2408.10724v3,cs.CL
MEGen: Generative Backdoor in Large Language Models via Model Editing,"Large language models (LLMs) have demonstrated remarkable capabilities. Their
powerful generative abilities enable flexible responses based on various
queries or instructions. Emerging as widely adopted generalists for diverse
tasks, LLMs are still vulnerable to backdoors. This paper proposes an
editing-based generative backdoor, named MEGen, aiming to create a customized
backdoor for NLP tasks with the least side effects. In our approach, we first
leverage a language model to insert a trigger selected on fixed metrics into
the input, then design a pipeline of model editing to directly embed a backdoor
into an LLM. By adjusting a small set of local parameters with a mini-batch of
samples, MEGen significantly enhances time efficiency and achieves high
robustness. Experimental results indicate that our backdoor attack strategy
achieves a high attack success rate on poison data while maintaining the
model's performance on clean data. Notably, the backdoored model, when
triggered, can freely output pre-set dangerous information while successfully
completing downstream tasks. This suggests that future LLM applications could
be guided to deliver certain dangerous information, thus altering the LLM's
generative style. We believe this approach provides insights for future LLM
applications and the execution of backdoor attacks on conversational AI
systems.",2024-08-20,"Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao",http://arxiv.org/pdf/2408.10722v1,cs.CL
CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?,"Recent advancements in large language models (LLMs) have showcased impressive
code generation capabilities, primarily evaluated through language-to-code
benchmarks. However, these benchmarks may not fully capture a model's code
understanding abilities. We introduce CodeJudge-Eval (CJ-Eval), a novel
benchmark designed to assess LLMs' code understanding abilities from the
perspective of code judging rather than code generation. CJ-Eval challenges
models to determine the correctness of provided code solutions, encompassing
various error types and compilation issues. By leveraging a diverse set of
problems and a fine-grained judging system, CJ-Eval addresses the limitations
of traditional benchmarks, including the potential memorization of solutions.
Evaluation of 12 well-known LLMs on CJ-Eval reveals that even state-of-the-art
models struggle, highlighting the benchmark's ability to probe deeper into
models' code understanding abilities. Our codes and benchmark are available at
\url{https://github.com/CodeLLM-Research/CodeJudge-Eval}.",2024-08-20,"Yuwei Zhao, Ziyang Luo, Yuchen Tian, Hongzhan Lin, Weixiang Yan, Annan Li, Jing Ma",http://arxiv.org/pdf/2408.10718v2,cs.CL
Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique,"In today's era, where large language models (LLMs) are integrated into
numerous real-world applications, ensuring their safety and robustness is
crucial for responsible AI usage. Automated red-teaming methods play a key role
in this process by generating adversarial attacks to identify and mitigate
potential vulnerabilities in these models. However, existing methods often
struggle with slow performance, limited categorical diversity, and high
resource demands. While Rainbow Teaming, a recent approach, addresses the
diversity challenge by framing adversarial prompt generation as a
quality-diversity search, it remains slow and requires a large fine-tuned
mutator for optimal performance. To overcome these limitations, we propose
Ferret, a novel approach that builds upon Rainbow Teaming by generating
multiple adversarial prompt mutations per iteration and using a scoring
function to rank and select the most effective adversarial prompt. We explore
various scoring functions, including reward models, Llama Guard, and
LLM-as-a-judge, to rank adversarial mutations based on their potential harm to
improve the efficiency of the search for harmful mutations. Our results
demonstrate that Ferret, utilizing a reward model as a scoring function,
improves the overall attack success rate (ASR) to 95%, which is 46% higher than
Rainbow Teaming. Additionally, Ferret reduces the time needed to achieve a 90%
ASR by 15.2% compared to the baseline and generates adversarial prompts that
are transferable i.e. effective on other LLMs of larger size. Our codes are
available at https://github.com/declare-lab/ferret.",2024-08-20,"Tej Deep Pala, Vernon Y. H. Toh, Rishabh Bhardwaj, Soujanya Poria",http://arxiv.org/pdf/2408.10701v1,cs.CL
Unconditional Truthfulness: Learning Conditional Dependency for Uncertainty Quantification of Large Language Models,"Uncertainty quantification (UQ) is a perspective approach to detecting Large
Language Model (LLM) hallucinations and low quality output. In this work, we
address one of the challenges of UQ in generation tasks that arises from the
conditional dependency between the generation steps of an LLM. We propose to
learn this dependency from data. We train a regression model, which target
variable is the gap between the conditional and the unconditional generation
confidence. During LLM inference, we use this learned conditional dependency
model to modulate the uncertainty of the current generation step based on the
uncertainty of the previous step. Our experimental evaluation on nine datasets
and three LLMs shows that the proposed method is highly effective for
uncertainty quantification, achieving substantial improvements over rivaling
approaches.",2024-08-20,"Artem Vazhentsev, Ekaterina Fadeeva, Rui Xing, Alexander Panchenko, Preslav Nakov, Timothy Baldwin, Maxim Panov, Artem Shelmanov",http://arxiv.org/pdf/2408.10692v1,cs.CL
Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models,"LLM have achieved success in many fields but still troubled by problematic
content in the training corpora. LLM unlearning aims at reducing their
influence and avoid undesirable behaviours. However, existing unlearning
methods remain vulnerable to adversarial queries and the unlearned knowledge
resurfaces after the manually designed attack queries. As part of a red-team
effort to proactively assess the vulnerabilities of unlearned models, we design
Dynamic Unlearning Attack (DUA), a dynamic and automated framework to attack
these models and evaluate their robustness. It optimizes adversarial suffixes
to reintroduce the unlearned knowledge in various scenarios. We find that
unlearned knowledge can be recovered in $55.2\%$ of the questions, even without
revealing the unlearned model's parameters. In response to this vulnerability,
we propose Latent Adversarial Unlearning (LAU), a universal framework that
effectively enhances the robustness of the unlearned process. It formulates the
unlearning process as a min-max optimization problem and resolves it through
two stages: an attack stage, where perturbation vectors are trained and added
to the latent space of LLMs to recover the unlearned knowledge, and a defense
stage, where previously trained perturbation vectors are used to enhance
unlearned model's robustness. With our LAU framework, we obtain two robust
unlearning methods, AdvGA and AdvNPO. We conduct extensive experiments across
multiple unlearning benchmarks and various models, and demonstrate that they
improve the unlearning effectiveness by over $53.5\%$, cause only less than a
$11.6\%$ reduction in neighboring knowledge, and have almost no impact on the
model's general capabilities.",2024-08-20,"Hongbang Yuan, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2408.10682v1,cs.CL
HMoE: Heterogeneous Mixture of Experts for Language Modeling,"Mixture of Experts (MoE) offers remarkable performance and computational
efficiency by selectively activating subsets of model parameters.
Traditionally, MoE models use homogeneous experts, each with identical
capacity. However, varying complexity in input data necessitates experts with
diverse capabilities, while homogeneous MoE hinders effective expert
specialization and efficient parameter utilization. In this study, we propose a
novel Heterogeneous Mixture of Experts (HMoE), where experts differ in size and
thus possess diverse capacities. This heterogeneity allows for more specialized
experts to handle varying token complexities more effectively. To address the
imbalance in expert activation, we propose a novel training objective that
encourages the frequent activation of smaller experts, enhancing computational
efficiency and parameter utilization. Extensive experiments demonstrate that
HMoE achieves lower loss with fewer activated parameters and outperforms
conventional homogeneous MoE models on various pre-training evaluation
benchmarks. Codes will be released upon acceptance.",2024-08-20,"An Wang, Xingwu Sun, Ruobing Xie, Shuaipeng Li, Jiaqi Zhu, Zhen Yang, Pinxue Zhao, J. N. Han, Zhanhui Kang, Di Wang, Naoaki Okazaki, Cheng-zhong Xu",http://arxiv.org/pdf/2408.10681v1,cs.CL
Towards Rehearsal-Free Multilingual ASR: A LoRA-based Case Study on Whisper,"Pre-trained multilingual speech foundation models, like Whisper, have shown
impressive performance across different languages. However, adapting these
models to new or specific languages is computationally extensive and faces
catastrophic forgetting problems. Addressing these issues, our study
investigates strategies to enhance the model on new languages in the absence of
original training data, while also preserving the established performance on
the original languages. Specifically, we first compare various LoRA-based
methods to find out their vulnerability to forgetting. To mitigate this issue,
we propose to leverage the LoRA parameters from the original model for
approximate orthogonal gradient descent on the new samples. Additionally, we
also introduce a learnable rank coefficient to allocate trainable parameters
for more efficient training. Our experiments with a Chinese Whisper model (for
Uyghur and Tibetan) yield better results with a more compact parameter set.",2024-08-20,"Tianyi Xu, Kaixun Huang, Pengcheng Guo, Yu Zhou, Longtao Huang, Hui Xue, Lei Xie",http://arxiv.org/pdf/2408.10680v1,cs.CL
Hierarchical Retrieval-Augmented Generation Model with Rethink for Multi-hop Question Answering,"Multi-hop Question Answering (QA) necessitates complex reasoning by
integrating multiple pieces of information to resolve intricate questions.
However, existing QA systems encounter challenges such as outdated information,
context window length limitations, and an accuracy-quantity trade-off. To
address these issues, we propose a novel framework, the Hierarchical
Retrieval-Augmented Generation Model with Rethink (HiRAG), comprising
Decomposer, Definer, Retriever, Filter, and Summarizer five key modules. We
introduce a new hierarchical retrieval strategy that incorporates both sparse
retrieval at the document level and dense retrieval at the chunk level,
effectively integrating their strengths. Additionally, we propose a
single-candidate retrieval method to mitigate the limitations of
multi-candidate retrieval. We also construct two new corpora, Indexed
Wikicorpus and Profile Wikicorpus, to address the issues of outdated and
insufficient knowledge.
  Our experimental results on four datasets demonstrate that HiRAG outperforms
state-of-the-art models across most metrics, and our Indexed Wikicorpus is
effective. The code for HiRAG is available at
https://github.com/2282588541a/HiRAG",2024-08-20,"Xiaoming Zhang, Ming Wang, Xiaocui Yang, Daling Wang, Shi Feng, Yifei Zhang",http://arxiv.org/pdf/2408.11875v1,cs.CL
REInstruct: Building Instruction Data from Unlabeled Corpus,"Manually annotating instruction data for large language models is difficult,
costly, and hard to scale. Meanwhile, current automatic annotation methods
typically rely on distilling synthetic data from proprietary LLMs, which not
only limits the upper bound of the quality of the instruction data but also
raises potential copyright issues. In this paper, we propose REInstruct, a
simple and scalable method to automatically build instruction data from an
unlabeled corpus without heavy reliance on proprietary LLMs and human
annotation. Specifically, REInstruct first selects a subset of unlabeled texts
that potentially contain well-structured helpful and insightful content and
then generates instructions for these texts. To generate accurate and relevant
responses for effective and robust training, REInstruct further proposes a
rewriting-based approach to improve the quality of the generated instruction
data. By training Llama-7b on a combination of 3k seed data and 32k synthetic
data from REInstruct, fine-tuned model achieves a 65.41\% win rate on
AlpacaEval leaderboard against text-davinci-003, outperforming other
open-source, non-distilled instruction data construction methods. The code is
publicly available at \url{https://github.com/cs32963/REInstruct}.",2024-08-20,"Shu Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun",http://arxiv.org/pdf/2408.10663v1,cs.CL
Beneath the Surface of Consistency: Exploring Cross-lingual Knowledge Representation Sharing in LLMs,"The veracity of a factoid is largely independent of the language it is
written in. However, language models are inconsistent in their ability to
answer the same factual question across languages. This raises questions about
how LLMs represent a given fact across languages. We explore multilingual
factual knowledge through two aspects: the model's ability to answer a query
consistently across languages, and the ability to ''store'' answers in a shared
representation for several languages. We propose a methodology to measure the
extent of representation sharing across languages by repurposing knowledge
editing methods. We examine LLMs with various multilingual configurations using
a new multilingual dataset. We reveal that high consistency does not
necessarily imply shared representation, particularly for languages with
different scripts. Moreover, we find that script similarity is a dominant
factor in representation sharing. Finally, we observe that if LLMs could fully
share knowledge across languages, their accuracy in their best-performing
language could benefit an increase of up to 150\% on average. These findings
highlight the need for improved multilingual knowledge representation in LLMs
and suggest a path for the development of more robust and consistent
multilingual LLMs.",2024-08-20,"Maxim Ifergan, Leshem Choshen, Roee Aharoni, Idan Szpektor, Omri Abend",http://arxiv.org/pdf/2408.10646v1,cs.CL
Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation,"Instruct LLM provide a paradigm used in large scale language model to align
LLM to human preference. The paradigm contains supervised fine tuning and
reinforce learning from human feedback. This paradigm is also used in
downstream scenarios to adapt LLM to specific corpora and applications.
Comparing to SFT, there are many efforts focused on RLHF and several algorithms
being proposed, such as PPO, DPO, IPO, KTO, MinorDPO and etc. Meanwhile most
efforts for SFT are focused on how to collect, filter and mix high quality
data. In this article with insight from DPO and MinorDPO, we propose a training
metric for SFT to measure the discrepancy between the optimized model and the
original model, and a loss function MinorSFT that can increase the training
effectiveness, and reduce the discrepancy between the optimized LLM and
original LLM.",2024-08-20,"Shiming Xie, Hong Chen, Fred Yu, Zeye Sun, Xiuyu Wu",http://arxiv.org/pdf/2408.10642v1,cs.CL
Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search,"In this paper, we propose a new method STRATEGIST that utilizes LLMs to
acquire new skills for playing multi-agent games through a self-improvement
process. Our method gathers quality feedback through self-play simulations with
Monte Carlo tree search and LLM-based reflection, which can then be used to
learn high-level strategic skills such as how to evaluate states that guide the
low-level execution. We showcase how our method can be used in both action
planning and dialogue generation in the context of games, achieving good
performance on both tasks. Specifically, we demonstrate that our method can
help train agents with better performance than both traditional reinforcement
learning-based approaches and other LLM-based skill learning approaches in
games including the Game of Pure Strategy (GOPS) and The Resistance: Avalon.
STRATEGIST helps bridge the gap between foundation models and symbolic
decision-making methods through its bi-level approach, leading to more robust
decision-making.",2024-08-20,"Jonathan Light, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, Ziniu Hu",http://arxiv.org/pdf/2408.10635v2,cs.CL
LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models,"Large language models (LLMs) have grown significantly in scale, leading to a
critical need for efficient model pruning techniques. Existing post-training
pruning techniques primarily focus on measuring weight importance on converged
dense models to determine salient weights to retain. However, they often
overlook the changes in weight importance during the pruning process, which can
lead to performance degradation in the pruned models. To address this issue, we
present LLM-Barber (Block-Aware Rebuilder for Sparsity Mask in One-Shot), a
novel one-shot pruning framework that rebuilds the sparsity mask of pruned
models without any retraining or weight reconstruction. LLM-Barber incorporates
block-aware error optimization across Self-Attention and MLP blocks, ensuring
global performance optimization. Inspired by the recent discovery of prominent
outliers in LLMs, LLM-Barber introduces an innovative pruning metric that
identifies weight importance using weights multiplied by gradients. Our
experiments show that LLM-Barber can efficiently prune models like LLaMA and
OPT families with 7B to 13B parameters on a single A100 GPU in just 30 minutes,
achieving state-of-the-art results in both perplexity and zero-shot performance
across various language benchmarks. Code is available at
https://github.com/YupengSu/LLM-Barber.",2024-08-20,"Yupeng Su, Ziyi Guan, Xiaoqun Liu, Tianlai Jin, Dongkuan Wu, Graziano Chesi, Ngai Wong, Hao Yu",http://arxiv.org/pdf/2408.10631v1,cs.CL
Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information,"In recent years, Large language models (LLMs) have garnered significant
attention due to their superior performance in complex reasoning tasks.
However, recent studies may diminish their reasoning capabilities markedly when
problem descriptions contain irrelevant information, even with the use of
advanced prompting techniques. To further investigate this issue, a dataset of
primary school mathematics problems containing irrelevant information, named
GSMIR, was constructed. Testing prominent LLMs and prompting techniques on this
dataset revealed that while LLMs can identify irrelevant information, they do
not effectively mitigate the interference it causes once identified. A novel
automatic construction method, ATF, which enhances the ability of LLMs to
identify and self-mitigate the influence of irrelevant information, is proposed
to address this shortcoming. This method operates in two steps: first, analysis
of irrelevant information, followed by its filtering. The ATF method, as
demonstrated by experimental results, significantly improves the reasoning
performance of LLMs and prompting techniques, even in the presence of
irrelevant information on the GSMIR dataset.",2024-08-20,"Ming Jiang, Tingting Huang, Biao Guo, Yao Lu, Feng Zhang",http://arxiv.org/pdf/2408.10615v2,cs.CL
Promoting Equality in Large Language Models: Identifying and Mitigating the Implicit Bias based on Bayesian Theory,"Large language models (LLMs) are trained on extensive text corpora, which
inevitably include biased information. Although techniques such as Affective
Alignment can mitigate some negative impacts of these biases, existing
prompt-based attack methods can still extract these biases from the model's
weights. Moreover, these biases frequently appear subtly when LLMs are prompted
to perform identical tasks across different demographic groups, thereby
camouflaging their presence. To address this issue, we have formally defined
the implicit bias problem and developed an innovative framework for bias
removal based on Bayesian theory, Bayesian-Theory based Bias Removal (BTBR).
BTBR employs likelihood ratio screening to pinpoint data entries within
publicly accessible biased datasets that represent biases inadvertently
incorporated during the LLM training phase. It then automatically constructs
relevant knowledge triples and expunges bias information from LLMs using model
editing techniques. Through extensive experimentation, we have confirmed the
presence of the implicit bias problem in LLMs and demonstrated the
effectiveness of our BTBR approach.",2024-08-20,"Yongxin Deng, Xihe Qiu, Xiaoyu Tan, Jing Pan, Chen Jue, Zhijun Fang, Yinghui Xu, Wei Chu, Yuan Qi",http://arxiv.org/pdf/2408.10608v1,cs.CL
Multilingual Non-Factoid Question Answering with Answer Paragraph Selection,"Most existing Question Answering Datasets (QuADs) primarily focus on
factoid-based short-context Question Answering (QA) in high-resource languages.
However, the scope of such datasets for low-resource languages remains limited,
with only a few works centered on factoid-based QuADs and none on non-factoid
QuADs. Therefore, this work presents MuNfQuAD, a multilingual QuAD with
non-factoid questions. It utilizes interrogative sub-headings from BBC news
articles as questions and the corresponding paragraphs as silver answers. The
dataset comprises over 578K QA pairs across 38 languages, encompassing several
low-resource languages, and stands as the largest multilingual QA dataset to
date. Based on the manual annotations of 790 QA-pairs from MuNfQuAD (golden
set), we observe that 98\% of questions can be answered using their
corresponding silver answer. Our fine-tuned Answer Paragraph Selection (APS)
model outperforms the baselines. The APS model attained an accuracy of 80\% and
72\%, as well as a macro F1 of 72\% and 66\%, on the MuNfQuAD testset and the
golden set, respectively. Furthermore, the APS model effectively generalizes a
certain language within the golden set, even after being fine-tuned on silver
labels. We also observe that the fine-tuned APS model is beneficial for
reducing the context of a question. These findings suggest that this resource
would be a valuable contribution to the QA research community.",2024-08-20,"Ritwik Mishra, Sreeram Vennam, Rajiv Ratn Shah, Ponnurangam Kumaraguru",http://arxiv.org/pdf/2408.10604v2,cs.CL
An Efficient Sign Language Translation Using Spatial Configuration and Motion Dynamics with LLMs,"Gloss-free Sign Language Translation (SLT) converts sign videos directly into
spoken language sentences without relying on glosses. Recently, Large Language
Models (LLMs) have shown remarkable translation performance in gloss-free
methods by harnessing their powerful natural language generation capabilities.
However, these methods often rely on domain-specific fine-tuning of visual
encoders to achieve optimal results. By contrast, this paper emphasizes the
importance of capturing the spatial configurations and motion dynamics inherent
in sign language. With this in mind, we introduce Spatial and Motion-based Sign
Language Translation (SpaMo), a novel LLM-based SLT framework. The core idea of
SpaMo is simple yet effective. We first extract spatial and motion features
using off-the-shelf visual encoders and then input these features into an LLM
with a language prompt. Additionally, we employ a visual-text alignment process
as a warm-up before the SLT supervision. Our experiments demonstrate that SpaMo
achieves state-of-the-art performance on two popular datasets, PHOENIX14T and
How2Sign.",2024-08-20,"Eui Jun Hwang, Sukmin Cho, Junmyeong Lee, Jong C. Park",http://arxiv.org/pdf/2408.10593v3,cs.CL
Putting People in LLMs' Shoes: Generating Better Answers via Question Rewriter,"Large Language Models (LLMs) have demonstrated significant capabilities,
particularly in the domain of question answering (QA). However, their
effectiveness in QA is often undermined by the vagueness of user questions. To
address this issue, we introduce single-round instance-level prompt
optimization, referred to as question rewriter. By enhancing the
intelligibility of human questions for black-box LLMs, our question rewriter
improves the quality of generated answers. The rewriter is optimized using
direct preference optimization based on feedback collected from automatic
criteria for evaluating generated answers; therefore, its training does not
require costly human annotations. The experiments across multiple black-box
LLMs and long-form question answering (LFQA) datasets demonstrate the efficacy
of our method. This paper provides a practical framework for training question
rewriters and sets a precedent for future explorations in prompt optimization
within LFQA tasks. Code is available at
https://github.com/3244we/Question-Rewriter.",2024-08-20,"Junhao Chen, Bowen Wang, Zhouqiang Jiang, Yuta Nakashima",http://arxiv.org/pdf/2408.10573v2,cs.CL
Speech Representation Learning Revisited: The Necessity of Separate Learnable Parameters and Robust Data Augmentation,"Speech modeling methods learn one embedding for a fixed segment of speech,
typically in between 10-25 ms. The information present in speech can be divided
into two categories: ""what is being said"" (content) and ""how it is expressed""
(other) and these two are orthogonal in nature causing the optimization
algorithm to find a sub-optimal solution if forced to optimize together. This
leads to sub-optimal performance in one or all downstream tasks as shown by
previous studies. Current self-supervised learning (SSL) methods such as HuBERT
are very good at modeling the content information present in speech. Data
augmentation improves the performance on tasks which require effective modeling
of other information but this leads to a divided capacity of the model. In this
work, we conduct a preliminary study to understand the importance of modeling
other information using separate learnable parameters. We propose a modified
version of HuBERT, termed Other HuBERT (O-HuBERT), to test our hypothesis. Our
findings are twofold: first, the O-HuBERT method is able to utilize all layers
to build complex features to encode other information; second, a robust data
augmentation strategy is essential for learning the information required by
tasks that depend on other information and to achieve state-of-the-art (SOTA)
performance on the SUPERB benchmark with a similarly sized model (100 million
parameters) and pre-training data (960 hours).",2024-08-20,"Hemant Yadav, Sunayana Sitaram, Rajiv Ratn Shah",http://arxiv.org/pdf/2408.10557v2,cs.CL
"Language Modeling on Tabular Data: A Survey of Foundations, Techniques and Evolution","Tabular data, a prevalent data type across various domains, presents unique
challenges due to its heterogeneous nature and complex structural
relationships. Achieving high predictive performance and robustness in tabular
data analysis holds significant promise for numerous applications. Influenced
by recent advancements in natural language processing, particularly transformer
architectures, new methods for tabular data modeling have emerged. Early
techniques concentrated on pre-training transformers from scratch, often
encountering scalability issues. Subsequently, methods leveraging pre-trained
language models like BERT have been developed, which require less data and
yield enhanced performance. The recent advent of large language models, such as
GPT and LLaMA, has further revolutionized the field, facilitating more advanced
and diverse applications with minimal fine-tuning. Despite the growing
interest, a comprehensive survey of language modeling techniques for tabular
data remains absent. This paper fills this gap by providing a systematic review
of the development of language modeling for tabular data, encompassing: (1) a
categorization of different tabular data structures and data types; (2) a
review of key datasets used in model training and tasks used for evaluation;
(3) a summary of modeling techniques including widely-adopted data processing
methods, popular architectures, and training objectives; (4) the evolution from
adapting traditional Pre-training/Pre-trained language models to the
utilization of large language models; (5) an identification of persistent
challenges and potential future research directions in language modeling for
tabular data analysis. GitHub page associated with this survey is available at:
https://github.com/lanxiang1017/Language-Modeling-on-Tabular-Data-Survey.git.",2024-08-20,"Yucheng Ruan, Xiang Lan, Jingying Ma, Yizhi Dong, Kai He, Mengling Feng",http://arxiv.org/pdf/2408.10548v1,cs.CL
"Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval","Information retrieval across different languages is an increasingly important
challenge in natural language processing. Recent approaches based on
multilingual pre-trained language models have achieved remarkable success, yet
they often optimize for either monolingual, cross-lingual, or multilingual
retrieval performance at the expense of others. This paper proposes a novel
hybrid batch training strategy to simultaneously improve zero-shot retrieval
performance across monolingual, cross-lingual, and multilingual settings while
mitigating language bias. The approach fine-tunes multilingual language models
using a mix of monolingual and cross-lingual question-answer pair batches
sampled based on dataset size. Experiments on XQuAD-R, MLQA-R, and MIRACL
benchmark datasets show that the proposed method consistently achieves
comparable or superior results in zero-shot retrieval across various languages
and retrieval tasks compared to monolingual-only or cross-lingual-only
training. Hybrid batch training also substantially reduces language bias in
multilingual retrieval compared to monolingual training. These results
demonstrate the effectiveness of the proposed approach for learning
language-agnostic representations that enable strong zero-shot retrieval
performance across diverse languages.",2024-08-20,"Adel Elmahdy, Sheng-Chieh Lin, Amin Ahmad",http://arxiv.org/pdf/2408.10536v1,cs.CL
"NoMatterXAI: Generating ""No Matter What"" Alterfactual Examples for Explaining Black-Box Text Classification Models","In Explainable AI (XAI), counterfactual explanations (CEs) are a well-studied
method to communicate feature relevance through contrastive reasoning of ""what
if"" to explain AI models' predictions. However, they only focus on important
(i.e., relevant) features and largely disregard less important (i.e.,
irrelevant) ones. Such irrelevant features can be crucial in many applications,
especially when users need to ensure that an AI model's decisions are not
affected or biased against specific attributes such as gender, race, religion,
or political affiliation. To address this gap, the concept of alterfactual
explanations (AEs) has been proposed. AEs explore an alternative reality of ""no
matter what"", where irrelevant features are substituted with alternative
features (e.g., ""republicans"" -> ""democrats"") within the same attribute (e.g.,
""politics"") while maintaining a similar prediction output. This serves to
validate whether AI model predictions are influenced by the specified
attributes. Despite the promise of AEs, there is a lack of computational
approaches to systematically generate them, particularly in the text domain,
where creating AEs for AI text classifiers presents unique challenges. This
paper addresses this challenge by formulating AE generation as an optimization
problem and introducing MoMatterXAI, a novel algorithm that generates AEs for
text classification tasks. Our approach achieves high fidelity of up to 95%
while preserving context similarity of over 90% across multiple models and
datasets. A human study further validates the effectiveness of AEs in
explaining AI text classifiers to end users. All codes will be publicly
available.",2024-08-20,"Tuc Nguyen, James Michels, Hua Shen, Thai Le",http://arxiv.org/pdf/2408.10528v1,cs.CL
XCB: an effective contextual biasing approach to bias cross-lingual phrases in speech recognition,"Contextualized ASR models have been demonstrated to effectively improve the
recognition accuracy of uncommon phrases when a predefined phrase list is
available. However, these models often struggle with bilingual settings, which
are prevalent in code-switching speech recognition. In this study, we make the
initial attempt to address this challenge by introducing a Cross-lingual
Contextual Biasing(XCB) module. Specifically, we augment a pre-trained ASR
model for the dominant language by integrating an auxiliary language biasing
module and a supplementary language-specific loss, aimed at enhancing the
recognition of phrases in the secondary language. Experimental results
conducted on our in-house code-switching dataset have validated the efficacy of
our approach, demonstrating significant improvements in the recognition of
biasing phrases in the secondary language, even without any additional
inference overhead. Additionally, our proposed system exhibits both efficiency
and generalization when is applied by the unseen ASRU-2019 test set.",2024-08-20,"Xucheng Wan, Naijun Zheng, Kai Liu, Huan Zhou",http://arxiv.org/pdf/2408.10524v1,cs.CL
Data Augmentation Integrating Dialogue Flow and Style to Adapt Spoken Dialogue Systems to Low-Resource User Groups,"This study addresses the interaction challenges encountered by spoken
dialogue systems (SDSs) when engaging with users who exhibit distinct
conversational behaviors, particularly minors, in scenarios where data are
scarce. We propose a novel data augmentation framework to enhance SDS
performance for user groups with limited resources. Our approach leverages a
large language model (LLM) to extract speaker styles and a pre-trained language
model (PLM) to simulate dialogue act history. This method generates enriched
and personalized dialogue data, facilitating improved interactions with unique
user demographics. Extensive experiments validate the efficacy of our
methodology, highlighting its potential to foster the development of more
adaptive and inclusive dialogue systems.",2024-08-20,"Zhiyang Qi, Michimasa Inaba",http://arxiv.org/pdf/2408.10516v1,cs.CL
QUITO-X: A New Perspective on Context Compression from the Information Bottleneck Theory,"Generative LLM have achieved remarkable success in various industrial
applications, owing to their promising In-Context Learning capabilities.
However, the issue of long context in complex tasks poses a significant barrier
to their wider adoption, manifested in two main aspects: (i) The excessively
long context leads to high costs and inference delays. (ii) A substantial
amount of task-irrelevant information introduced by long contexts exacerbates
the ""lost in the middle"" problem. Existing methods compress context by removing
redundant tokens using metrics such as self-information or PPL, which is
inconsistent with the objective of retaining the most important tokens when
conditioning on a given query. In this study, we introduce information
bottleneck theory (IB) to model the problem, offering a novel perspective that
thoroughly addresses the essential properties required for context compression.
Additionally, we propose a cross-attention-based approach to approximate mutual
information in IB, which can be flexibly replaced with suitable alternatives in
different scenarios. Extensive experiments on four datasets demonstrate that
our method achieves a 25% increase in compression rate compared to the
state-of-the-art, while maintaining question answering performance. In
particular, the context compressed by our method even outperform the full
context in some cases.",2024-08-20,"Yihang Wang, Xu Huang, Bowen Tian, Yueyang Su, Lei Yu, Huaming Liao, Yixing Fan, Jiafeng Guo, Xueqi Cheng",http://arxiv.org/pdf/2408.10497v2,cs.CL
Analysis of Plan-based Retrieval for Grounded Text Generation,"In text generation, hallucinations refer to the generation of seemingly
coherent text that contradicts established knowledge. One compelling hypothesis
is that hallucinations occur when a language model is given a generation task
outside its parametric knowledge (due to rarity, recency, domain, etc.). A
common strategy to address this limitation is to infuse the language models
with retrieval mechanisms, providing the model with relevant knowledge for the
task. In this paper, we leverage the planning capabilities of instruction-tuned
LLMs and analyze how planning can be used to guide retrieval to further reduce
the frequency of hallucinations. We empirically evaluate several variations of
our proposed approach on long-form text generation tasks. By improving the
coverage of relevant facts, plan-guided retrieval and generation can produce
more informative responses while providing a higher rate of attribution to
source documents.",2024-08-20,"Ameya Godbole, Nicholas Monath, Seungyeon Kim, Ankit Singh Rawat, Andrew McCallum, Manzil Zaheer",http://arxiv.org/pdf/2408.10490v1,cs.CL
Event Stream based Sign Language Translation: A High-Definition Benchmark Dataset and A New Algorithm,"Sign Language Translation (SLT) is a core task in the field of AI-assisted
disability. Unlike traditional SLT based on visible light videos, which is
easily affected by factors such as lighting, rapid hand movements, and privacy
breaches, this paper proposes the use of high-definition Event streams for SLT,
effectively mitigating the aforementioned issues. This is primarily because
Event streams have a high dynamic range and dense temporal signals, which can
withstand low illumination and motion blur well. Additionally, due to their
sparsity in space, they effectively protect the privacy of the target person.
More specifically, we propose a new high-resolution Event stream sign language
dataset, termed Event-CSL, which effectively fills the data gap in this area of
research. It contains 14,827 videos, 14,821 glosses, and 2,544 Chinese words in
the text vocabulary. These samples are collected in a variety of indoor and
outdoor scenes, encompassing multiple angles, light intensities, and camera
movements. We have benchmarked existing mainstream SLT works to enable fair
comparison for future efforts. Based on this dataset and several other
large-scale datasets, we propose a novel baseline method that fully leverages
the Mamba model's ability to integrate temporal information of CNN features,
resulting in improved sign language translation outcomes. Both the benchmark
dataset and source code will be released on
https://github.com/Event-AHU/OpenESL",2024-08-20,"Xiao Wang, Yao Rong, Fuling Wang, Jianing Li, Lin Zhu, Bo Jiang, Yaowei Wang",http://arxiv.org/pdf/2408.10488v1,cs.CL
LeCov: Multi-level Testing Criteria for Large Language Models,"Large Language Models (LLMs) are widely used in many different domains, but
because of their limited interpretability, there are questions about how
trustworthy they are in various perspectives, e.g., truthfulness and toxicity.
Recent research has started developing testing methods for LLMs, aiming to
uncover untrustworthy issues, i.e., defects, before deployment. However,
systematic and formalized testing criteria are lacking, which hinders a
comprehensive assessment of the extent and adequacy of testing exploration. To
mitigate this threat, we propose a set of multi-level testing criteria, LeCov,
for LLMs. The criteria consider three crucial LLM internal components, i.e.,
the attention mechanism, feed-forward neurons, and uncertainty, and contain
nine types of testing criteria in total. We apply the criteria in two
scenarios: test prioritization and coverage-guided testing. The experiment
evaluation, on three models and four datasets, demonstrates the usefulness and
effectiveness of LeCov.",2024-08-20,"Xuan Xie, Jiayang Song, Yuheng Huang, Da Song, Fuyuan Zhang, Felix Juefei-Xu, Lei Ma",http://arxiv.org/pdf/2408.10474v1,cs.CL
Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism,"Pre-trained language models (PLMs) are engineered to be robust in contextual
understanding and exhibit outstanding performance in various natural language
processing tasks. However, their considerable size incurs significant
computational and storage costs. Modern pruning strategies employ one-shot
techniques to compress PLMs without the need for retraining on task-specific or
otherwise general data; however, these approaches often lead to an
indispensable reduction in performance. In this paper, we propose SDS, a
Sparse-Dense-Sparse pruning framework to enhance the performance of the pruned
PLMs from a weight distribution optimization perspective. We outline the
pruning process in three steps. Initially, we prune less critical connections
in the model using conventional one-shot pruning methods. Next, we reconstruct
a dense model featuring a pruning-friendly weight distribution by reactivating
pruned connections with sparse regularization. Finally, we perform a second
pruning round, yielding a superior pruned model compared to the initial
pruning. Experimental results demonstrate that SDS outperforms the
state-of-the-art pruning techniques SparseGPT and Wanda under an identical
sparsity configuration. For instance, SDS reduces perplexity by 9.13 on
Raw-Wikitext2 and improves accuracy by an average of 2.05% across multiple
zero-shot benchmarks for OPT-125M with 2:4 sparsity.",2024-08-20,"Guanchen Li, Xiandong Zhao, Lian Liu, Zeping Li, Dong Li, Lu Tian, Jie He, Ashish Sirasao, Emad Barsoum",http://arxiv.org/pdf/2408.10473v1,cs.CL
Tracing Privacy Leakage of Language Models to Training Data via Adjusted Influence Functions,"The responses generated by Large Language Models (LLMs) can include sensitive
information from individuals and organizations, leading to potential privacy
leakage. This work implements Influence Functions (IFs) to trace privacy
leakage back to the training data, thereby mitigating privacy concerns of
Language Models (LMs). However, we notice that current IFs struggle to
accurately estimate the influence of tokens with large gradient norms,
potentially overestimating their influence. When tracing the most influential
samples, this leads to frequently tracing back to samples with large gradient
norm tokens, overshadowing the actual most influential samples even if their
influences are well estimated. To address this issue, we propose Heuristically
Adjusted IF (HAIF), which reduces the weight of tokens with large gradient
norms, thereby significantly improving the accuracy of tracing the most
influential samples. To establish easily obtained groundtruth for tracing
privacy leakage, we construct two datasets, PII-E and PII-CR, representing two
distinct scenarios: one with identical text in the model outputs and
pre-training data, and the other where models leverage their reasoning
abilities to generate text divergent from pre-training data. HAIF significantly
improves tracing accuracy, enhancing it by 20.96% to 73.71% on the PII-E
dataset and 3.21% to 45.93% on the PII-CR dataset, compared to the best SOTA
IFs against various GPT-2 and QWen-1.5 models. HAIF also outperforms SOTA IFs
on real-world pretraining data CLUECorpus2020, demonstrating strong robustness
regardless prompt and response lengths.",2024-08-20,"Jinxin Liu, Zao Yang",http://arxiv.org/pdf/2408.10468v4,cs.CL
Federated Learning of Large ASR Models in the Real World,"Federated learning (FL) has shown promising results on training machine
learning models with privacy preservation. However, for large models with over
100 million parameters, the training resource requirement becomes an obstacle
for FL because common devices do not have enough memory and computation power
to finish the FL tasks. Although efficient training methods have been proposed,
it is still a challenge to train the large models like Conformer based ASR.
This paper presents a systematic solution to train the full-size ASR models of
130M parameters with FL. To our knowledge, this is the first real-world FL
application of the Conformer model, which is also the largest model ever
trained with FL so far. And this is the first paper showing FL can improve the
ASR model quality with a set of proposed methods to refine the quality of data
and labels of clients. We demonstrate both the training efficiency and the
model quality improvement in real-world experiments.",2024-08-19,"Yonghui Xiao, Yuxin Ding, Changwan Ryu, Petr Zadrazil, Francoise Beaufays",http://arxiv.org/pdf/2408.10443v1,cs.CL
Goldfish: Monolingual Language Models for 350 Languages,"For many low-resource languages, the only available language models are large
multilingual models trained on many languages simultaneously. However, using
FLORES perplexity as a metric, we find that these models perform worse than
bigrams for many languages (e.g. 24% of languages in XGLM 4.5B; 43% in BLOOM
7.1B). To facilitate research that focuses on low-resource languages, we
pre-train and release Goldfish, a suite of monolingual autoregressive
Transformer language models up to 125M parameters for 350 languages. The
Goldfish reach lower FLORES perplexities than BLOOM, XGLM, and MaLA-500 on 98
of 204 FLORES languages, despite each Goldfish model being over 10x smaller.
However, the Goldfish significantly underperform larger multilingual models on
reasoning benchmarks, suggesting that for low-resource languages,
multilinguality primarily improves general reasoning abilities rather than
basic text generation. We release models trained on 5MB (350 languages), 10MB
(288 languages), 100MB (166 languages), and 1GB (83 languages) of text data
where available. The Goldfish models are available as baselines, fine-tuning
sources, or augmentations to existing models in low-resource NLP research, and
they are further useful for crosslinguistic studies requiring maximally
comparable models across languages.",2024-08-19,"Tyler A. Chang, Catherine Arnett, Zhuowen Tu, Benjamin K. Bergen",http://arxiv.org/pdf/2408.10441v1,cs.CL
Development of an AI Anti-Bullying System Using Large Language Model Key Topic Detection,"This paper presents and evaluates work on the development of an artificial
intelligence (AI) anti-bullying system. The system is designed to identify
coordinated bullying attacks via social media and other mechanisms,
characterize them and propose remediation and response activities to them. In
particular, a large language model (LLM) is used to populate an enhanced expert
system-based network model of a bullying attack. This facilitates analysis and
remediation activity - such as generating report messages to social media
companies - determination. The system is described and the efficacy of the LLM
for populating the model is analyzed herein.",2024-08-19,"Matthew Tassava, Cameron Kolodjski, Jordan Milbrath, Adorah Bishop, Nathan Flanders, Robbie Fetsch, Danielle Hanson, Jeremy Straub",http://arxiv.org/pdf/2408.10417v1,cs.CL
Resolving Lexical Bias in Edit Scoping with Projector Editor Networks,"Weight-preserving model editing techniques heavily rely on the scoping
mechanism that decides when to apply an edit to the base model. These scoping
mechanisms utilize distance functions in the representation space to ascertain
the scope of the edit. In this work, we show that distance-based scoping
functions grapple with lexical biases leading to issues such as misfires with
irrelevant prompts that share similar lexical characteristics. To address this
problem, we introduce, Projector Editor Networks for Model Editing (PENME),is a
model editing approach that employs a compact adapter with a projection network
trained via a contrastive learning objective. We demonstrate the efficacy of
PENME in achieving superior results while being compute efficient and flexible
to adapt across model architectures.",2024-08-19,"Hammad Rizwan, Domenic Rosati, Ga Wu, Hassan Sajjad",http://arxiv.org/pdf/2408.10411v2,cs.CL
Value Alignment from Unstructured Text,"Aligning large language models (LLMs) to value systems has emerged as a
significant area of research within the fields of AI and NLP. Currently, this
alignment process relies on the availability of high-quality supervised and
preference data, which can be both time-consuming and expensive to curate or
annotate. In this paper, we introduce a systematic end-to-end methodology for
aligning LLMs to the implicit and explicit values represented in unstructured
text data. Our proposed approach leverages the use of scalable synthetic data
generation techniques to effectively align the model to the values present in
the unstructured data. Through two distinct use-cases, we demonstrate the
efficiency of our methodology on the Mistral-7B-Instruct model. Our approach
credibly aligns LLMs to the values embedded within documents, and shows
improved performance against other approaches, as quantified through the use of
automatic metrics and win rates.",2024-08-19,"Inkit Padhi, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Manish Nagireddy, Pierre Dognin, Kush R. Varshney",http://arxiv.org/pdf/2408.10392v1,cs.CL
Narrowing the Gap between Vision and Action in Navigation,"The existing methods for Vision and Language Navigation in the Continuous
Environment (VLN-CE) commonly incorporate a waypoint predictor to discretize
the environment. This simplifies the navigation actions into a view selection
task and improves navigation performance significantly compared to direct
training using low-level actions. However, the VLN-CE agents are still far from
the real robots since there are gaps between their visual perception and
executed actions. First, VLN-CE agents that discretize the visual environment
are primarily trained with high-level view selection, which causes them to
ignore crucial spatial reasoning within the low-level action movements. Second,
in these models, the existing waypoint predictors neglect object semantics and
their attributes related to passibility, which can be informative in indicating
the feasibility of actions. To address these two issues, we introduce a
low-level action decoder jointly trained with high-level action prediction,
enabling the current VLN agent to learn and ground the selected visual view to
the low-level controls. Moreover, we enhance the current waypoint predictor by
utilizing visual representations containing rich semantic information and
explicitly masking obstacles based on humans' prior knowledge about the
feasibility of actions. Empirically, our agent can improve navigation
performance metrics compared to the strong baselines on both high-level and
low-level actions.",2024-08-19,"Yue Zhang, Parisa Kordjamshidi",http://arxiv.org/pdf/2408.10388v1,cs.CL
Beyond Relevant Documents: A Knowledge-Intensive Approach for Query-Focused Summarization using Large Language Models,"Query-focused summarization (QFS) is a fundamental task in natural language
processing with broad applications, including search engines and report
generation. However, traditional approaches assume the availability of relevant
documents, which may not always hold in practical scenarios, especially in
highly specialized topics. To address this limitation, we propose a novel
knowledge-intensive approach that reframes QFS as a knowledge-intensive task
setup. This approach comprises two main components: a retrieval module and a
summarization controller. The retrieval module efficiently retrieves
potentially relevant documents from a large-scale knowledge corpus based on the
given textual query, eliminating the dependence on pre-existing document sets.
The summarization controller seamlessly integrates a powerful large language
model (LLM)-based summarizer with a carefully tailored prompt, ensuring the
generated summary is comprehensive and relevant to the query. To assess the
effectiveness of our approach, we create a new dataset, along with
human-annotated relevance labels, to facilitate comprehensive evaluation
covering both retrieval and summarization performance. Extensive experiments
demonstrate the superior performance of our approach, particularly its ability
to generate accurate summaries without relying on the availability of relevant
documents initially. This underscores our method's versatility and practical
applicability across diverse query scenarios.",2024-08-19,"Weijia Zhang, Jia-Hong Huang, Svitlana Vakulenko, Yumo Xu, Thilina Rajapakse, Evangelos Kanoulas",http://arxiv.org/pdf/2408.10357v1,cs.CL
DELIA: Diversity-Enhanced Learning for Instruction Adaptation in Large Language Models,"Although instruction tuning is widely used to adjust behavior in Large
Language Models (LLMs), extensive empirical evidence and research indicates
that it is primarily a process where the model fits to specific task formats,
rather than acquiring new knowledge or capabilities. We propose that this
limitation stems from biased features learned during instruction tuning, which
differ from ideal task-specfic features, leading to learn less underlying
semantics in downstream tasks. However, ideal features are unknown and
incalculable, constraining past work to rely on prior knowledge to assist
reasoning or training, which limits LLMs' capabilities to the developers'
abilities, rather than data-driven scalable learning. In our paper, through our
novel data synthesis method, DELIA (Diversity-Enhanced Learning for Instruction
Adaptation), we leverage the buffering effect of extensive diverse data in LLMs
training to transform biased features in instruction tuning into approximations
of ideal features, without explicit prior ideal features. Experiments show
DELIA's better performance compared to common instruction tuning and other
baselines. It outperforms common instruction tuning by 17.07%-33.41% on
Icelandic-English translation bleurt score (WMT-21 dataset, gemma-7b-it) and
improves accuracy by 36.1% on formatted text generation (Llama2-7b-chat).
Notably, among knowledge injection methods we've known, DELIA uniquely align
the internal representations of new special tokens with their prior semantics.",2024-08-19,"Yuanhao Zeng, Fei Ren, Xinpeng Zhou, Yihang Wang, Yingxia Shao",http://arxiv.org/pdf/2408.10841v1,cs.CL
LongVILA: Scaling Long-Context Visual Language Models for Long Videos,"Long-context capability is critical for multi-modal foundation models,
especially for long video understanding. We introduce LongVILA, a full-stack
solution for long-context visual-language models by co-designing the algorithm
and system. For model training, we upgrade existing VLMs to support long video
understanding by incorporating two additional stages, i.e., long context
extension and long video supervised fine-tuning. However, training on long
video is computationally and memory intensive. We introduce the long-context
Multi-Modal Sequence Parallelism (MM-SP) system that efficiently parallelizes
long video training and inference, enabling 2M context length training on 256
GPUs without any gradient checkpointing. LongVILA efficiently extends the
number of video frames of VILA from 8 to 2048, achieving 99.8% accuracy in
6,000-frame (more than 1 million tokens) video needle-in-a-haystack.
LongVILA-7B demonstrates strong accuracy on 9 popular video benchmarks, e.g.
65.1% VideoMME with subtitle. Besides, MM-SP is 2.1x - 5.7x faster than ring
style sequence parallelism and 1.1x - 1.4x faster than Megatron with a hybrid
context and tensor parallelism. Moreover, it seamlessly integrates with Hugging
Face Transformers.",2024-08-19,"Yukang Chen, Fuzhao Xue, Dacheng Li, Qinghao Hu, Ligeng Zhu, Xiuyu Li, Yunhao Fang, Haotian Tang, Shang Yang, Zhijian Liu, Ethan He, Hongxu Yin, Pavlo Molchanov, Jan Kautz, Linxi Fan, Yuke Zhu, Yao Lu, Song Han",http://arxiv.org/pdf/2408.10188v6,cs.CL
Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models,"While recent large language models (LLMs) demonstrate remarkable abilities in
responding to queries in diverse languages, their ability to handle long
multilingual contexts is unexplored. As such, a systematic evaluation of the
long-context capabilities of LLMs in multilingual settings is crucial,
specifically in the context of information retrieval. To address this gap, we
introduce the MultiLingual Needle-in-a-Haystack (MLNeedle) test, designed to
assess a model's ability to retrieve relevant information (the needle) from a
collection of multilingual distractor texts (the haystack). This test serves as
an extension of the multilingual question-answering task, encompassing both
monolingual and cross-lingual retrieval. We evaluate four state-of-the-art LLMs
on MLNeedle. Our findings reveal that model performance can vary significantly
with language and needle position. Specifically, we observe that model
performance is the lowest when the needle is (i) in a language outside the
English language family and (ii) located in the middle of the input context.
Furthermore, although some models claim a context size of $8k$ tokens or
greater, none demonstrate satisfactory cross-lingual retrieval performance as
the context length increases. Our analysis provides key insights into the
long-context behavior of LLMs in multilingual settings to guide future
evaluation protocols. To our knowledge, this is the first study to investigate
the multilingual long-context behavior of LLMs.",2024-08-19,"Amey Hengle, Prasoon Bajpai, Soham Dan, Tanmoy Chakraborty",http://arxiv.org/pdf/2408.10151v1,cs.CL
In-Context Learning with Representations: Contextual Generalization of Trained Transformers,"In-context learning (ICL) refers to a remarkable capability of pretrained
large language models, which can learn a new task given a few examples during
inference. However, theoretical understanding of ICL is largely under-explored,
particularly whether transformers can be trained to generalize to unseen
examples in a prompt, which will require the model to acquire contextual
knowledge of the prompt for generalization. This paper investigates the
training dynamics of transformers by gradient descent through the lens of
non-linear regression tasks. The contextual generalization here can be attained
via learning the template function for each task in-context, where all template
functions lie in a linear space with $m$ basis functions. We analyze the
training dynamics of one-layer multi-head transformers to in-contextly predict
unlabeled inputs given partially labeled prompts, where the labels contain
Gaussian noise and the number of examples in each prompt are not sufficient to
determine the template. Under mild assumptions, we show that the training loss
for a one-layer multi-head transformer converges linearly to a global minimum.
Moreover, the transformer effectively learns to perform ridge regression over
the basis functions. To our knowledge, this study is the first provable
demonstration that transformers can learn contextual (i.e., template)
information to generalize to both unseen examples and tasks when prompts
contain only a small number of query-answer pairs.",2024-08-19,"Tong Yang, Yu Huang, Yingbin Liang, Yuejie Chi",http://arxiv.org/pdf/2408.10147v2,cs.CL
Instruction Finetuning for Leaderboard Generation from Empirical AI Research,"This study demonstrates the application of instruction finetuning of
pretrained Large Language Models (LLMs) to automate the generation of AI
research leaderboards, extracting (Task, Dataset, Metric, Score) quadruples
from articles. It aims to streamline the dissemination of advancements in AI
research by transitioning from traditional, manual community curation, or
otherwise taxonomy-constrained natural language inference (NLI) models, to an
automated, generative LLM-based approach. Utilizing the FLAN-T5 model, this
research enhances LLMs' adaptability and reliability in information extraction,
offering a novel method for structured knowledge representation.",2024-08-19,"Salomon Kabongo, Jennifer D'Souza",http://arxiv.org/pdf/2408.10141v1,cs.CL
Rhyme-aware Chinese lyric generator based on GPT,"Neural language representation models such as GPT, pre-trained on large-scale
corpora, can effectively capture rich semantic patterns from plain text and be
fine-tuned to consistently improve natural language generation performance.
However, existing pre-trained language models used to generate lyrics rarely
consider rhyme information, which is crucial in lyrics. Using a pre-trained
model directly results in poor performance. To enhance the rhyming quality of
generated lyrics, we incorporate integrated rhyme information into our model,
thereby improving lyric generation performance.",2024-08-19,"Yixiao Yuan, Yangchen Huang, Yu Ma, Xinjin Li, Zhenglin Li, Yiming Shi, Huapeng Zhou",http://arxiv.org/pdf/2408.10130v1,cs.CL
GLIMMER: Incorporating Graph and Lexical Features in Unsupervised Multi-Document Summarization,"Pre-trained language models are increasingly being used in multi-document
summarization tasks. However, these models need large-scale corpora for
pre-training and are domain-dependent. Other non-neural unsupervised
summarization approaches mostly rely on key sentence extraction, which can lead
to information loss. To address these challenges, we propose a lightweight yet
effective unsupervised approach called GLIMMER: a Graph and LexIcal features
based unsupervised Multi-docuMEnt summaRization approach. It first constructs a
sentence graph from the source documents, then automatically identifies
semantic clusters by mining low-level features from raw texts, thereby
improving intra-cluster correlation and the fluency of generated sentences.
Finally, it summarizes clusters into natural sentences. Experiments conducted
on Multi-News, Multi-XScience and DUC-2004 demonstrate that our approach
outperforms existing unsupervised approaches. Furthermore, it surpasses
state-of-the-art pre-trained multi-document summarization models (e.g. PEGASUS
and PRIMERA) under zero-shot settings in terms of ROUGE scores. Additionally,
human evaluations indicate that summaries generated by GLIMMER achieve high
readability and informativeness scores. Our code is available at
https://github.com/Oswald1997/GLIMMER.",2024-08-19,"Ran Liu, Ming Liu, Min Yu, Jianguo Jiang, Gang Li, Dan Zhang, Jingyuan Li, Xiang Meng, Weiqing Huang",http://arxiv.org/pdf/2408.10115v1,cs.CL
Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning,"Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for
aligning foundation models to human values and preferences. However, current
RLHF techniques cannot account for the naturally occurring differences in
individual human preferences across a diverse population. When these
differences arise, traditional RLHF frameworks simply average over them,
leading to inaccurate rewards and poor performance for individual subgroups. To
address the need for pluralistic alignment, we develop a class of multimodal
RLHF methods. Our proposed techniques are based on a latent variable
formulation - inferring a novel user-specific latent and learning reward models
and policies conditioned on this latent without additional user-specific data.
While conceptually simple, we show that in practice, this reward modeling
requires careful algorithmic considerations around model architecture and
reward scaling. To empirically validate our proposed technique, we first show
that it can provide a way to combat underspecification in simulated control
problems, inferring and optimizing user-specific reward functions. Next, we
conduct experiments on pluralistic language datasets representing diverse user
preferences and demonstrate improved reward function accuracy. We additionally
show the benefits of this probabilistic framework in terms of measuring
uncertainty, and actively learning user preferences. This work enables learning
from diverse populations of users with divergent preferences, an important
challenge that naturally occurs in problems from robot learning to foundation
model alignment.",2024-08-19,"Sriyash Poddar, Yanming Wan, Hamish Ivison, Abhishek Gupta, Natasha Jaques",http://arxiv.org/pdf/2408.10075v1,cs.CL
Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory,"Privacy research has attracted wide attention as individuals worry that their
private data can be easily leaked during interactions with smart devices,
social platforms, and AI applications. Computer science researchers, on the
other hand, commonly study privacy issues through privacy attacks and defenses
on segmented fields. Privacy research is conducted on various sub-fields,
including Computer Vision (CV), Natural Language Processing (NLP), and Computer
Networks. Within each field, privacy has its own formulation. Though pioneering
works on attacks and defenses reveal sensitive privacy issues, they are
narrowly trapped and cannot fully cover people's actual privacy concerns.
Consequently, the research on general and human-centric privacy research
remains rather unexplored. In this paper, we formulate the privacy issue as a
reasoning problem rather than simple pattern matching. We ground on the
Contextual Integrity (CI) theory which posits that people's perceptions of
privacy are highly correlated with the corresponding social context. Based on
such an assumption, we develop the first comprehensive checklist that covers
social identities, private attributes, and existing privacy regulations. Unlike
prior works on CI that either cover limited expert annotated norms or model
incomplete social context, our proposed privacy checklist uses the whole Health
Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to
show that we can resort to large language models (LLMs) to completely cover the
HIPAA's regulations. Additionally, our checklist also gathers expert
annotations across multiple ontologies to determine private information
including but not limited to personally identifiable information (PII). We use
our preliminary results on the HIPAA to shed light on future context-centric
privacy research to cover more privacy regulations, social norms and standards.",2024-08-19,"Haoran Li, Wei Fan, Yulin Chen, Jiayang Cheng, Tianshu Chu, Xuebing Zhou, Peizhao Hu, Yangqiu Song",http://arxiv.org/pdf/2408.10053v2,cs.CL
MegaFake: A Theory-Driven Dataset of Fake News Generated by Large Language Models,"The advent of large language models (LLMs) has revolutionized online content
creation, making it much easier to generate high-quality fake news. This misuse
threatens the integrity of our digital environment and ethical standards.
Therefore, understanding the motivations and mechanisms behind LLM-generated
fake news is crucial. In this study, we analyze the creation of fake news from
a social psychology perspective and develop a comprehensive LLM-based
theoretical framework, LLM-Fake Theory. We introduce a novel pipeline that
automates the generation of fake news using LLMs, thereby eliminating the need
for manual annotation. Utilizing this pipeline, we create a theoretically
informed Machine-generated Fake news dataset, MegaFake, derived from the
GossipCop dataset. We conduct comprehensive analyses to evaluate our MegaFake
dataset. We believe that our dataset and insights will provide valuable
contributions to future research focused on the detection and governance of
fake news in the era of LLMs.",2024-08-19,"Lionel Z. Wang, Yiming Ma, Renfei Gao, Beichen Guo, Han Zhu, Wenqi Fan, Zexin Lu, Ka Chung Ng",http://arxiv.org/pdf/2408.11871v2,cs.CL
C${^2}$RL: Content and Context Representation Learning for Gloss-free Sign Language Translation and Retrieval,"Sign Language Representation Learning (SLRL) is crucial for a range of sign
language-related downstream tasks such as Sign Language Translation (SLT) and
Sign Language Retrieval (SLRet). Recently, many gloss-based and gloss-free SLRL
methods have been proposed, showing promising performance. Among them, the
gloss-free approach shows promise for strong scalability without relying on
gloss annotations. However, it currently faces suboptimal solutions due to
challenges in encoding the intricate, context-sensitive characteristics of sign
language videos, mainly struggling to discern essential sign features using a
non-monotonic video-text alignment strategy. Therefore, we introduce an
innovative pretraining paradigm for gloss-free SLRL, called C${^2}$RL, in this
paper. Specifically, rather than merely incorporating a non-monotonic semantic
alignment of video and text to learn language-oriented sign features, we
emphasize two pivotal aspects of SLRL: Implicit Content Learning (ICL) and
Explicit Context Learning (ECL). ICL delves into the content of communication,
capturing the nuances, emphasis, timing, and rhythm of the signs. In contrast,
ECL focuses on understanding the contextual meaning of signs and converting
them into equivalent sentences. Despite its simplicity, extensive experiments
confirm that the joint optimization of ICL and ECL results in robust sign
language representation and significant performance gains in gloss-free SLT and
SLRet tasks. Notably, C${^2}$RL improves the BLEU-4 score by +5.3 on P14T,
+10.6 on CSL-daily, +6.2 on OpenASL, and +1.3 on How2Sign. It also boosts the
R@1 score by +8.3 on P14T, +14.4 on CSL-daily, and +5.9 on How2Sign.
Additionally, we set a new baseline for the OpenASL dataset in the SLRet task.",2024-08-19,"Zhigang Chen, Benjia Zhou, Yiqing Huang, Jun Wan, Yibo Hu, Hailin Shi, Yanyan Liang, Zhen Lei, Du Zhang",http://arxiv.org/pdf/2408.09949v1,cs.CL
Microscopic Analysis on LLM players via Social Deduction Game,"Recent studies have begun developing autonomous game players for social
deduction games using large language models (LLMs). When building LLM players,
fine-grained evaluations are crucial for addressing weaknesses in game-playing
abilities. However, existing studies have often overlooked such assessments.
Specifically, we point out two issues with the evaluation methods employed.
First, game-playing abilities have typically been assessed through game-level
outcomes rather than specific event-level skills; Second, error analyses have
lacked structured methodologies. To address these issues, we propose an
approach utilizing a variant of the SpyFall game, named SpyGame. We conducted
an experiment with four LLMs, analyzing their gameplay behavior in SpyGame both
quantitatively and qualitatively. For the quantitative analysis, we introduced
eight metrics to resolve the first issue, revealing that these metrics are more
effective than existing ones for evaluating the two critical skills: intent
identification and camouflage. In the qualitative analysis, we performed
thematic analysis to resolve the second issue. This analysis identifies four
major categories that affect gameplay of LLMs. Additionally, we demonstrate how
these categories complement and support the findings from the quantitative
analysis.",2024-08-19,"Byungjun Kim, Dayeon Seo, Bugeun Kim",http://arxiv.org/pdf/2408.09946v1,cs.CL
"Large Language Models for Classical Chinese Poetry Translation: Benchmarking, Evaluating, and Improving","Different from the traditional translation tasks, classical Chinese poetry
translation requires both adequacy and fluency in translating culturally and
historically significant content and linguistic poetic elegance. Large language
models (LLMs) with impressive multilingual capabilities may bring a ray of hope
to achieve this extreme translation demand. This paper first introduces a
suitable benchmark (PoetMT) where each Chinese poetry has a recognized elegant
translation. Meanwhile, we propose a new metric based on GPT-4 to evaluate the
extent to which current LLMs can meet these demands. Our empirical evaluation
reveals that the existing LLMs fall short in the challenging task. Hence, we
propose a Retrieval-Augmented Machine Translation (RAT) method which
incorporates knowledge related to classical poetry for advancing the
translation of Chinese Poetry in LLMs. Experimental results show that RAT
consistently outperforms all comparison methods regarding wildly used BLEU,
COMET, BLEURT, our proposed metric, and human evaluation.",2024-08-19,"Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang",http://arxiv.org/pdf/2408.09945v4,cs.CL
"""Image, Tell me your story!"" Predicting the original meta-context of visual misinformation","To assist human fact-checkers, researchers have developed automated
approaches for visual misinformation detection. These methods assign veracity
scores by identifying inconsistencies between the image and its caption, or by
detecting forgeries in the image. However, they neglect a crucial point of the
human fact-checking process: identifying the original meta-context of the
image. By explaining what is actually true about the image, fact-checkers can
better detect misinformation, focus their efforts on check-worthy visual
content, engage in counter-messaging before misinformation spreads widely, and
make their explanation more convincing. Here, we fill this gap by introducing
the task of automated image contextualization. We create 5Pils, a dataset of
1,676 fact-checked images with question-answer pairs about their original
meta-context. Annotations are based on the 5 Pillars fact-checking framework.
We implement a first baseline that grounds the image in its original
meta-context using the content of the image and textual evidence retrieved from
the open web. Our experiments show promising results while highlighting several
open challenges in retrieval and reasoning. We make our code and data publicly
available.",2024-08-19,"Jonathan Tonglet, Marie-Francine Moens, Iryna Gurevych",http://arxiv.org/pdf/2408.09939v2,cs.CL
Attribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit,"Model editing aims to correct outdated or erroneous knowledge in large models
without costly retraining. Recent research discovered that the mid-layer
representation of the subject's final token in a prompt has a strong influence
on factual predictions, and developed Large Language Model (LLM) editing
techniques based on this observation. However, for Vision-LLMs (VLLMs), how
visual representations impact the predictions from a decoder-only language
model remains largely unexplored. To the best of our knowledge, model editing
for VLLMs has not been extensively studied in the literature. In this work, we
employ the contribution allocation and noise perturbation methods to measure
the contributions of visual representations for token predictions. Our
attribution analysis shows that visual representations in mid-to-later layers
that are highly relevant to the prompt contribute significantly to predictions.
Based on these insights, we propose VisEdit, a novel model editor for VLLMs
that effectively corrects knowledge by editing intermediate visual
representations in regions important to the edit prompt. We evaluated VisEdit
using multiple VLLM backbones and public VLLM editing benchmark datasets. The
results show the superiority of VisEdit over the strong baselines adapted from
existing state-of-the-art editors for LLMs.",2024-08-19,"Qizhou Chen, Taolin Zhang, Chengyu Wang, Xiaofeng He, Dakan Wang, Tingting Liu",http://arxiv.org/pdf/2408.09916v3,cs.CL
Active Learning for Identifying Disaster-Related Tweets: A Comparison with Keyword Filtering and Generic Fine-Tuning,"Information from social media can provide essential information for emergency
response during natural disasters in near real-time. However, it is difficult
to identify the disaster-related posts among the large amounts of unstructured
data available. Previous methods often use keyword filtering, topic modelling
or classification-based techniques to identify such posts. Active Learning (AL)
presents a promising sub-field of Machine Learning (ML) that has not been used
much in the field of text classification of social media content. This study
therefore investigates the potential of AL for identifying disaster-related
Tweets. We compare a keyword filtering approach, a RoBERTa model fine-tuned
with generic data from CrisisLex, a base RoBERTa model trained with AL and a
fine-tuned RoBERTa model trained with AL regarding classification performance.
For testing, data from CrisisLex and manually labelled data from the 2021 flood
in Germany and the 2023 Chile forest fires were considered. The results show
that generic fine-tuning combined with 10 rounds of AL outperformed all other
approaches. Consequently, a broadly applicable model for the identification of
disaster-related Tweets could be trained with very little labelling effort. The
model can be applied to use cases beyond this study and provides a useful tool
for further research in social media analysis.",2024-08-19,"David Hanny, Sebastian Schmidt, Bernd Resch",http://arxiv.org/pdf/2408.09914v1,cs.CL
Performance Law of Large Language Models,"Guided by the belief of the scaling law, large language models (LLMs) have
achieved impressive performance in recent years. However, scaling law only
gives a qualitative estimation of loss, which is influenced by various factors
such as model architectures, data distributions, tokenizers, and computation
precision. Thus, estimating the real performance of LLMs with different
training settings rather than loss may be quite useful in practical
development. In this article, we present an empirical equation named
""Performance Law"" to directly predict the MMLU score of an LLM, which is a
widely used metric to indicate the general capability of LLMs in real-world
conversations and applications. Based on only a few key hyperparameters of the
LLM architecture and the size of training data, we obtain a quite accurate MMLU
prediction of various LLMs with diverse sizes and architectures developed by
different organizations in different years. Performance law can be used to
guide the choice of LLM architecture and the effective allocation of
computational resources without extensive experiments.",2024-08-19,"Chuhan Wu, Ruiming Tang",http://arxiv.org/pdf/2408.09895v4,cs.CL
Docling Technical Report,"This technical report introduces Docling, an easy to use, self-contained,
MIT-licensed open-source package for PDF document conversion. It is powered by
state-of-the-art specialized AI models for layout analysis (DocLayNet) and
table structure recognition (TableFormer), and runs efficiently on commodity
hardware in a small resource budget. The code interface allows for easy
extensibility and addition of new features and models.",2024-08-19,"Christoph Auer, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Nikolaos Livathinos, Panos Vagenas, Cesar Berrospi Ramis, Matteo Omenetti, Fabian Lindlbauer, Kasper Dinkla, Lokesh Mishra, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar",http://arxiv.org/pdf/2408.09869v5,cs.CL
MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation,"The Explainable Recommendation task is designed to receive a pair of user and
item and output explanations to justify why an item is recommended to a user.
Many models approach review generation as a proxy for explainable
recommendations. While these models can produce fluent and grammatically
correct sentences, they often lack precision and fail to provide personalized,
informative recommendations. To address this issue, we propose a personalized,
aspect-controlled model called Multi-Aspect Prompt LEarner (MAPLE), which
integrates aspect category as another input dimension to facilitate memorizing
fine-grained aspect terms. Experiments conducted on two real-world review
datasets in the restaurant domain demonstrate that MAPLE significantly
outperforms baseline review-generation models. MAPLE excels in both text and
feature diversity, ensuring that the generated content covers a wide range of
aspects. Additionally, MAPLE delivers good generation quality while maintaining
strong coherence and factual relevance. The code and dataset used in this paper
can be found here https://github.com/Nana2929/MAPLE.git.",2024-08-19,"Ching-Wen Yang, Zhi-Quan Feng, Ying-Jia Lin, Che-Wei Chen, Kun-da Wu, Hao Xu, Jui-Feng Yao, Hung-Yu Kao",http://arxiv.org/pdf/2408.09865v2,cs.CL
TaSL: Continual Dialog State Tracking via Task Skill Localization and Consolidation,"A practical dialogue system requires the capacity for ongoing skill
acquisition and adaptability to new tasks while preserving prior knowledge.
However, current methods for Continual Dialogue State Tracking (DST), a crucial
function of dialogue systems, struggle with the catastrophic forgetting issue
and knowledge transfer between tasks. We present TaSL, a novel framework for
task skill localization and consolidation that enables effective knowledge
transfer without relying on memory replay. TaSL uses a novel group-wise
technique to pinpoint task-specific and task-shared areas. Additionally, a
fine-grained skill consolidation strategy protects task-specific knowledge from
being forgotten while updating shared knowledge for bi-directional knowledge
transfer. As a result, TaSL strikes a balance between preserving previous
knowledge and excelling at new tasks. Comprehensive experiments on various
backbones highlight the significant performance improvements of TaSL over
existing state-of-the-art methods. The source code is provided for
reproducibility.",2024-08-19,"Yujie Feng, Xu Chu, Yongxin Xu, Guangyuan Shi, Bo Liu, Xiao-Ming Wu",http://arxiv.org/pdf/2408.09857v1,cs.CL
TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition,"While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have
effectively addressed GPU memory constraints during fine-tuning, their
performance often falls short, especially in multidimensional task scenarios.
To address this issue, one straightforward solution is to introduce
task-specific LoRA modules as domain experts, leveraging the modeling of
multiple experts' capabilities and thus enhancing the general capability of
multi-task learning. Despite promising, these additional components often add
complexity to the training and inference process, contravening the efficient
characterization of PEFT designed for. Considering this, we introduce an
innovative PEFT method, TeamLoRA, consisting of a collaboration and competition
module for experts, and thus achieving the right balance of effectiveness and
efficiency: (i) For collaboration, a novel knowledge-sharing and -organizing
mechanism is devised to appropriately reduce the scale of matrix operations,
thereby boosting the training and inference speed. (ii) For competition, we
propose leveraging a game-theoretic interaction mechanism for experts,
encouraging experts to transfer their domain-specific knowledge while facing
diverse downstream tasks, and thus enhancing the performance. By doing so,
TeamLoRA elegantly connects the experts as a ""Team"" with internal collaboration
and competition, enabling a faster and more accurate PEFT paradigm for
multi-task learning. To validate the superiority of TeamLoRA, we curate a
comprehensive multi-task evaluation(CME) benchmark to thoroughly assess the
capability of multi-task learning. Experiments conducted on our CME and other
benchmarks indicate the effectiveness and efficiency of TeamLoRA. Our project
is available at https://github.com/Lin-Tianwei/TeamLoRA.",2024-08-19,"Tianwei Lin, Jiang Liu, Wenqiao Zhang, Zhaocheng Li, Yang Dai, Haoyuan Li, Zhelun Yu, Wanggui He, Juncheng Li, Hao Jiang, Siliang Tang, Yueting Zhuang",http://arxiv.org/pdf/2408.09856v1,cs.CL
Self-Directed Turing Test for Large Language Models,"The Turing test examines whether AIs can exhibit human-like behaviour in
natural language conversations. Traditional Turing tests adopt a rigid dialogue
format where each participant sends only one message each time and require
continuous human involvement to direct the entire interaction with the test
subject. This fails to reflect a natural conversational style and hinders the
evaluation of Large Language Models (LLMs) in complex and prolonged dialogues.
This paper proposes the Self-Directed Turing Test, which extends the original
test with a burst dialogue format, allowing more dynamic exchanges by multiple
consecutive messages. It further efficiently reduces human workload by having
the LLM self-direct the majority of the test process, iteratively generating
dialogues that simulate its interaction with humans. With the pseudo-dialogue
history, the model then engages in a shorter dialogue with a human, which is
paired with a human-human conversation on the same topic to be judged using
questionnaires. We introduce the X-Turn Pass-Rate metric to assess the human
likeness of LLMs across varying durations. While LLMs like GPT-4 initially
perform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10
turns of dialogues respectively, their performance drops as the dialogue
progresses, which underscores the difficulty in maintaining consistency in the
long term.",2024-08-19,"Weiqi Wu, Hongqiu Wu, Hai Zhao",http://arxiv.org/pdf/2408.09853v1,cs.CL
Importance Weighting Can Help Large Language Models Self-Improve,"Large language models (LLMs) have shown remarkable capability in numerous
tasks and applications. However, fine-tuning LLMs using high-quality datasets
under external supervision remains prohibitively expensive. In response, LLM
self-improvement approaches have been vibrantly developed recently. The typical
paradigm of LLM self-improvement involves training LLM on self-generated data,
part of which may be detrimental and should be filtered out due to the unstable
data quality. While current works primarily employs filtering strategies based
on answer correctness, in this paper, we demonstrate that filtering out correct
but with high distribution shift extent (DSE) samples could also benefit the
results of self-improvement. Given that the actual sample distribution is
usually inaccessible, we propose a new metric called DS weight to approximate
DSE, inspired by the Importance Weighting methods. Consequently, we integrate
DS weight with self-consistency to comprehensively filter the self-generated
samples and fine-tune the language model. Experiments show that with only a
tiny valid set (up to 5\% size of the training set) to compute DS weight, our
approach can notably promote the reasoning ability of current LLM
self-improvement methods. The resulting performance is on par with methods that
rely on external supervision from pre-trained reward models.",2024-08-19,"Chunyang Jiang, Chi-min Chan, Wei Xue, Qifeng Liu, Yike Guo",http://arxiv.org/pdf/2408.09849v2,cs.CL
Continual Dialogue State Tracking via Reason-of-Select Distillation,"An ideal dialogue system requires continuous skill acquisition and adaptation
to new tasks while retaining prior knowledge. Dialogue State Tracking (DST),
vital in these systems, often involves learning new services and confronting
catastrophic forgetting, along with a critical capability loss termed the
""Value Selection Quandary."" To address these challenges, we introduce the
Reason-of-Select (RoS) distillation method by enhancing smaller models with a
novel 'meta-reasoning' capability. Meta-reasoning employs an enhanced
multi-domain perspective, combining fragments of meta-knowledge from
domain-specific dialogues during continual learning. This transcends
traditional single-perspective reasoning. The domain bootstrapping process
enhances the model's ability to dissect intricate dialogues from multiple
possible values. Its domain-agnostic property aligns data distribution across
different domains, effectively mitigating forgetting. Additionally, two novel
improvements, ""multi-value resolution"" strategy and Semantic Contrastive
Reasoning Selection method, significantly enhance RoS by generating
DST-specific selection chains and mitigating hallucinations in teachers'
reasoning, ensuring effective and reliable knowledge transfer. Extensive
experiments validate the exceptional performance and robust generalization
capabilities of our method. The source code is provided for reproducibility.",2024-08-19,"Yujie Feng, Bo Liu, Xiaoyu Dong, Zexin Lu, Li-Ming Zhan, Albert Y. S. Lam, Xiao-Ming Wu",http://arxiv.org/pdf/2408.09846v2,cs.CL
CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models,"What a large language model (LLM) would respond in ethically relevant
context? In this paper, we curate a large benchmark CMoralEval for morality
evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a
Chinese TV program discussing Chinese moral norms with stories from the society
and 2) a collection of Chinese moral anomies from various newspapers and
academic papers on morality. With these sources, we aim to create a moral
evaluation dataset characterized by diversity and authenticity. We develop a
morality taxonomy and a set of fundamental moral principles that are not only
rooted in traditional Chinese culture but also consistent with contemporary
societal norms. To facilitate efficient construction and annotation of
instances in CMoralEval, we establish a platform with AI-assisted instance
generation to streamline the annotation process. These help us curate
CMoralEval that encompasses both explicit moral scenarios (14,964 instances)
and moral dilemma scenarios (15,424 instances), each with instances from
different data sources. We conduct extensive experiments with CMoralEval to
examine a variety of Chinese LLMs. Experiment results demonstrate that
CMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly
available at \url{https://github.com/tjunlp-lab/CMoralEval}.",2024-08-19,"Linhao Yu, Yongqi Leng, Yufei Huang, Shang Wu, Haixin Liu, Xinmeng Ji, Jiahui Zhao, Jinwang Song, Tingting Cui, Xiaoqing Cheng, Tao Liu, Deyi Xiong",http://arxiv.org/pdf/2408.09819v1,cs.CL
AutoML-guided Fusion of Entity and LLM-based Representations for Document Classification,"Large semantic knowledge bases are grounded in factual knowledge. However,
recent approaches to dense text representations (i.e. embeddings) do not
efficiently exploit these resources. Dense and robust representations of
documents are essential for effectively solving downstream classification and
retrieval tasks. This work demonstrates that injecting embedded information
from knowledge bases can augment the performance of contemporary Large Language
Model (LLM)-based representations for the task of text classification. Further,
by considering automated machine learning (AutoML) with the fused
representation space, we demonstrate it is possible to improve classification
accuracy even if we use low-dimensional projections of the original
representation space obtained via efficient matrix factorization. This result
shows that significantly faster classifiers can be achieved with minimal or no
loss in predictive performance, as demonstrated using five strong LLM baselines
on six diverse real-life datasets. The code is freely available at
\url{https://github.com/bkolosk1/bablfusion.git}.",2024-08-19,"Boshko Koloski, Senja Pollak, Roberto Navigli, Blaž Škrlj",http://arxiv.org/pdf/2408.09794v2,cs.CL
Anim-Director: A Large Multimodal Model Powered Agent for Controllable Animation Video Generation,"Traditional animation generation methods depend on training generative models
with human-labelled data, entailing a sophisticated multi-stage pipeline that
demands substantial human effort and incurs high training costs. Due to limited
prompting plans, these methods typically produce brief, information-poor, and
context-incoherent animations. To overcome these limitations and automate the
animation process, we pioneer the introduction of large multimodal models
(LMMs) as the core processor to build an autonomous animation-making agent,
named Anim-Director. This agent mainly harnesses the advanced understanding and
reasoning capabilities of LMMs and generative AI tools to create animated
videos from concise narratives or simple instructions. Specifically, it
operates in three main stages: Firstly, the Anim-Director generates a coherent
storyline from user inputs, followed by a detailed director's script that
encompasses settings of character profiles and interior/exterior descriptions,
and context-coherent scene descriptions that include appearing characters,
interiors or exteriors, and scene events. Secondly, we employ LMMs with the
image generation tool to produce visual images of settings and scenes. These
images are designed to maintain visual consistency across different scenes
using a visual-language prompting method that combines scene descriptions and
images of the appearing character and setting. Thirdly, scene images serve as
the foundation for producing animated videos, with LMMs generating prompts to
guide this process. The whole process is notably autonomous without manual
intervention, as the LMMs interact seamlessly with generative tools to generate
prompts, evaluate visual quality, and select the best one to optimize the final
output.",2024-08-19,"Yunxin Li, Haoyuan Shi, Baotian Hu, Longyue Wang, Jiashun Zhu, Jinyi Xu, Zhen Zhao, Min Zhang",http://arxiv.org/pdf/2408.09787v1,cs.CL
GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making,"Traditional methods for making software deployment decisions in the
automotive industry typically rely on manual analysis of tabular software test
data. These methods often lead to higher costs and delays in the software
release cycle due to their labor-intensive nature. Large Language Models (LLMs)
present a promising solution to these challenges. However, their application
generally demands multiple rounds of human-driven prompt engineering, which
limits their practical deployment, particularly for industrial end-users who
need reliable and efficient results. In this paper, we propose GoNoGo, an LLM
agent system designed to streamline automotive software deployment while
meeting both functional requirements and practical industrial constraints.
Unlike previous systems, GoNoGo is specifically tailored to address
domain-specific and risk-sensitive systems. We evaluate GoNoGo's performance
across different task difficulties using zero-shot and few-shot examples taken
from industrial practice. Our results show that GoNoGo achieves a 100% success
rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains
high performance even for more complex tasks. We find that GoNoGo effectively
automates decision-making for simpler tasks, significantly reducing the need
for manual intervention. In summary, GoNoGo represents an efficient and
user-friendly LLM-based solution currently employed in our industrial partner's
company to assist with software release decision-making, supporting more
informed and timely decisions in the release process for risk-sensitive vehicle
systems.",2024-08-19,"Arsham Gholamzadeh Khoee, Yinan Yu, Robert Feldt, Andris Freimanis, Patrick Andersson Rhodin, Dhasarathy Parthasarathy",http://arxiv.org/pdf/2408.09785v2,cs.CL
Summarizing long regulatory documents with a multi-step pipeline,"Due to their length and complexity, long regulatory texts are challenging to
summarize. To address this, a multi-step extractive-abstractive architecture is
proposed to handle lengthy regulatory documents more effectively. In this
paper, we show that the effectiveness of a two-step architecture for
summarizing long regulatory texts varies significantly depending on the model
used. Specifically, the two-step architecture improves the performance of
decoder-only models. For abstractive encoder-decoder models with short context
lengths, the effectiveness of an extractive step varies, whereas for
long-context encoder-decoder models, the extractive step worsens their
performance. This research also highlights the challenges of evaluating
generated texts, as evidenced by the differing results from human and automated
evaluations. Most notably, human evaluations favoured language models
pretrained on legal text, while automated metrics rank general-purpose language
models higher. The results underscore the importance of selecting the
appropriate summarization strategy based on model architecture and context
length.",2024-08-19,"Mika Sie, Ruby Beek, Michiel Bots, Sjaak Brinkkemper, Albert Gatt",http://arxiv.org/pdf/2408.09777v2,cs.CL
Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?,"Large language models (LLMs) have been found to produce hallucinations when
the question exceeds their internal knowledge boundaries. A reliable model
should have a clear perception of its knowledge boundaries, providing correct
answers within its scope and refusing to answer when it lacks knowledge.
Existing research on LLMs' perception of their knowledge boundaries typically
uses either the probability of the generated tokens or the verbalized
confidence as the model's confidence in its response. However, these studies
overlook the differences and connections between the two. In this paper, we
conduct a comprehensive analysis and comparison of LLMs' probabilistic
perception and verbalized perception of their factual knowledge boundaries.
First, we investigate the pros and cons of these two perceptions. Then, we
study how they change under questions of varying frequencies. Finally, we
measure the correlation between LLMs' probabilistic confidence and verbalized
confidence. Experimental results show that 1) LLMs' probabilistic perception is
generally more accurate than verbalized perception but requires an in-domain
validation set to adjust the confidence threshold. 2) Both perceptions perform
better on less frequent questions. 3) It is challenging for LLMs to accurately
express their internal confidence in natural language.",2024-08-19,"Shiyu Ni, Keping Bi, Lulu Yu, Jiafeng Guo",http://arxiv.org/pdf/2408.09773v1,cs.CL
Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning,"Recent studies highlight the effectiveness of using in-context learning (ICL)
to steer large language models (LLMs) in processing tabular data, a challenging
task given the structured nature of such data. Despite advancements in
performance, the fairness implications of these methods are less understood.
This study investigates how varying demonstrations within ICL prompts influence
the fairness outcomes of LLMs. Our findings reveal that deliberately including
minority group samples in prompts significantly boosts fairness without
sacrificing predictive accuracy. Further experiments demonstrate that the
proportion of minority to majority samples in demonstrations affects the
trade-off between fairness and prediction accuracy. Based on these insights, we
introduce a mitigation technique that employs clustering and evolutionary
strategies to curate a diverse and representative sample set from the training
data. This approach aims to enhance both predictive performance and fairness in
ICL applications. Experimental results validate that our proposed method
dramatically improves fairness across various metrics, showing its efficacy in
real-world scenarios.",2024-08-19,"Jingyu Hu, Weiru Liu, Mengnan Du",http://arxiv.org/pdf/2408.09757v1,cs.CL
R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation,"Inspired by the tremendous success of Large Language Models (LLMs), existing
X-ray medical report generation methods attempt to leverage large models to
achieve better performance. They usually adopt a Transformer to extract the
visual features of a given X-ray image, and then, feed them into the LLM for
text generation. How to extract more effective information for the LLMs to help
them improve final results is an urgent problem that needs to be solved.
Additionally, the use of visual Transformer models also brings high
computational complexity. To address these issues, this paper proposes a novel
context-guided efficient X-ray medical report generation framework.
Specifically, we introduce the Mamba as the vision backbone with linear
complexity, and the performance obtained is comparable to that of the strong
Transformer model. More importantly, we perform context retrieval from the
training set for samples within each mini-batch during the training phase,
utilizing both positively and negatively related samples to enhance feature
representation and discriminative learning. Subsequently, we feed the vision
tokens, context information, and prompt statements to invoke the LLM for
generating high-quality medical reports. Extensive experiments on three X-ray
report generation datasets (i.e., IU-Xray, MIMIC-CXR, CheXpert Plus) fully
validated the effectiveness of our proposed model. The source code of this work
will be released on \url{https://github.com/Event-AHU/Medical_Image_Analysis}.",2024-08-19,"Xiao Wang, Yuehang Li, Fuling Wang, Shiao Wang, Chuanfu Li, Bo Jiang",http://arxiv.org/pdf/2408.09743v1,cs.CL
Paired Completion: Flexible Quantification of Issue-framing at Scale with LLMs,"Detecting and quantifying issue framing in textual discourse - the
perspective one takes to a given topic (e.g. climate science vs. denialism,
misogyny vs. gender equality) - is highly valuable to a range of end-users from
social and political scientists to program evaluators and policy analysts.
However, conceptual framing is notoriously challenging for automated natural
language processing (NLP) methods since the words and phrases used by either
`side' of an issue are often held in common, with only subtle stylistic
flourishes separating their use. Here we develop and rigorously evaluate new
detection methods for issue framing and narrative analysis within large text
datasets. By introducing a novel application of next-token log probabilities
derived from generative large language models (LLMs) we show that issue framing
can be reliably and efficiently detected in large corpora with only a few
examples of either perspective on a given issue, a method we call `paired
completion'. Through 192 independent experiments over three novel, synthetic
datasets, we evaluate paired completion against prompt-based LLM methods and
labelled methods using traditional NLP and recent LLM contextual embeddings. We
additionally conduct a cost-based analysis to mark out the feasible set of
performant methods at production-level scales, and a model bias analysis.
Together, our work demonstrates a feasible path to scalable, accurate and
low-bias issue-framing in large corpora.",2024-08-19,"Simon D Angus, Lachlan O'Neill",http://arxiv.org/pdf/2408.09742v1,cs.CL
Pedestrian Attribute Recognition: A New Benchmark Dataset and A Large Language Model Augmented Framework,"Pedestrian Attribute Recognition (PAR) is one of the indispensable tasks in
human-centered research. However, existing datasets neglect different domains
(e.g., environments, times, populations, and data sources), only conducting
simple random splits, and the performance of these datasets has already
approached saturation. In the past five years, no large-scale dataset has been
opened to the public. To address this issue, this paper proposes a new
large-scale, cross-domain pedestrian attribute recognition dataset to fill the
data gap, termed MSP60K. It consists of 60,122 images and 57 attribute
annotations across eight scenarios. Synthetic degradation is also conducted to
further narrow the gap between the dataset and real-world challenging
scenarios. To establish a more rigorous benchmark, we evaluate 17
representative PAR models under both random and cross-domain split protocols on
our dataset. Additionally, we propose an innovative Large Language Model (LLM)
augmented PAR framework, named LLM-PAR. This framework processes pedestrian
images through a Vision Transformer (ViT) backbone to extract features and
introduces a multi-embedding query Transformer to learn partial-aware features
for attribute classification. Significantly, we enhance this framework with LLM
for ensemble learning and visual feature augmentation. Comprehensive
experiments across multiple PAR benchmark datasets have thoroughly validated
the efficacy of our proposed framework. The dataset and source code
accompanying this paper will be made publicly available at
\url{https://github.com/Event-AHU/OpenPAR}.",2024-08-19,"Jiandong Jin, Xiao Wang, Qian Zhu, Haiyang Wang, Chenglong Li",http://arxiv.org/pdf/2408.09720v1,cs.CL
SEMDR: A Semantic-Aware Dual Encoder Model for Legal Judgment Prediction with Legal Clue Tracing,"Legal Judgment Prediction (LJP) aims to form legal judgments based on the
criminal fact description. However, researchers struggle to classify confusing
criminal cases, such as robbery and theft, which requires LJP models to
distinguish the nuances between similar crimes. Existing methods usually design
handcrafted features to pick up necessary semantic legal clues to make more
accurate legal judgment predictions. In this paper, we propose a Semantic-Aware
Dual Encoder Model (SEMDR), which designs a novel legal clue tracing mechanism
to conduct fine-grained semantic reasoning between criminal facts and
instruments. Our legal clue tracing mechanism is built from three reasoning
levels: 1) Lexicon-Tracing, which aims to extract criminal facts from criminal
descriptions; 2) Sentence Representation Learning, which contrastively trains
language models to better represent confusing criminal facts; 3) Multi-Fact
Reasoning, which builds a reasons graph to propagate semantic clues among fact
nodes to capture the subtle difference among criminal facts. Our legal clue
tracing mechanism helps SEMDR achieve state-of-the-art on the CAIL2018 dataset
and shows its advance in few-shot scenarios. Our experiments show that SEMDR
has a strong ability to learn more uniform and distinguished representations
for criminal facts, which helps to make more accurate predictions on confusing
criminal cases and reduces the model uncertainty during making judgments. All
codes will be released via GitHub.",2024-08-19,"Pengjie Liu, Wang Zhang, Yulong Ding, Xuefeng Zhang, Shuang-Hua Yang",http://arxiv.org/pdf/2408.09717v1,cs.CL
Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer,"The use of Large Language Models (LLMs) for program code generation has
gained substantial attention, but their biases and limitations with non-English
prompts challenge global inclusivity. This paper investigates the complexities
of multilingual prompt-based code generation. Our evaluations of LLMs,
including CODELLAMA and CODEGEMMA, reveal significant disparities in code
quality for non-English prompts; we also demonstrate the inadequacy of simple
approaches like prompt translation, bootstrapped data augmentation, and
fine-tuning. To address this, we propose a zero-shot cross-lingual approach
using a neural projection technique, integrating a cross-lingual encoder like
LASER to map multilingual embeddings from it into the LLM's token space. This
method requires training only on English data and scales effectively to other
languages. Results on a translated and quality-checked MBPP dataset show
substantial improvements in code quality. This research promotes a more
inclusive code generation landscape by empowering LLMs with multilingual
capabilities to support the diverse linguistic spectrum in programming.",2024-08-19,"Mingda Li, Abhijit Mishra, Utkarsh Mujumdar",http://arxiv.org/pdf/2408.09701v2,cs.CL
"Recording for Eyes, Not Echoing to Ears: Contextualized Spoken-to-Written Conversion of ASR Transcripts","Automatic Speech Recognition (ASR) transcripts exhibit recognition errors and
various spoken language phenomena such as disfluencies, ungrammatical
sentences, and incomplete sentences, hence suffering from poor readability. To
improve readability, we propose a Contextualized Spoken-to-Written conversion
(CoS2W) task to address ASR and grammar errors and also transfer the informal
text into the formal style with content preserved, utilizing contexts and
auxiliary information. This task naturally matches the in-context learning
capabilities of Large Language Models (LLMs). To facilitate comprehensive
comparisons of various LLMs, we construct a document-level Spoken-to-Written
conversion of ASR Transcripts Benchmark (SWAB) dataset. Using SWAB, we study
the impact of different granularity levels on the CoS2W performance, and
propose methods to exploit contexts and auxiliary information to enhance the
outputs. Experimental results reveal that LLMs have the potential to excel in
the CoS2W task, particularly in grammaticality and formality, our methods
achieve effective understanding of contexts and auxiliary information by LLMs.
We further investigate the effectiveness of using LLMs as evaluators and find
that LLM evaluators show strong correlations with human evaluations on rankings
of faithfulness and formality, which validates the reliability of LLM
evaluators for the CoS2W task.",2024-08-19,"Jiaqing Liu, Chong Deng, Qinglin Zhang, Shilin Zhou, Qian Chen, Hai Yu, Wen Wang",http://arxiv.org/pdf/2408.09688v4,cs.CL
BLADE: Benchmarking Language Model Agents for Data-Driven Science,"Data-driven scientific discovery requires the iterative integration of
scientific domain knowledge, statistical expertise, and an understanding of
data semantics to make nuanced analytical decisions, e.g., about which
variables, transformations, and statistical models to consider. LM-based agents
equipped with planning, memory, and code execution capabilities have the
potential to support data-driven science. However, evaluating agents on such
open-ended tasks is challenging due to multiple valid approaches, partially
correct steps, and different ways to express the same decisions. To address
these challenges, we present BLADE, a benchmark to automatically evaluate
agents' multifaceted approaches to open-ended research questions. BLADE
consists of 12 datasets and research questions drawn from existing scientific
literature, with ground truth collected from independent analyses by expert
data scientists and researchers. To automatically evaluate agent responses, we
developed corresponding computational methods to match different
representations of analyses to this ground truth. Though language models
possess considerable world knowledge, our evaluation shows that they are often
limited to basic analyses. However, agents capable of interacting with the
underlying data demonstrate improved, but still non-optimal, diversity in their
analytical decision making. Our work enables the evaluation of agents for
data-driven science and provides researchers deeper insights into agents'
analysis approaches.",2024-08-19,"Ken Gu, Ruoxi Shang, Ruien Jiang, Keying Kuang, Richard-John Lin, Donghe Lyu, Yue Mao, Youran Pan, Teng Wu, Jiaqian Yu, Yikun Zhang, Tianmai M. Zhang, Lanyi Zhu, Mike A. Merrill, Jeffrey Heer, Tim Althoff",http://arxiv.org/pdf/2408.09667v2,cs.CL
A Comparison of Large Language Model and Human Performance on Random Number Generation Tasks,"Random Number Generation Tasks (RNGTs) are used in psychology for examining
how humans generate sequences devoid of predictable patterns. By adapting an
existing human RNGT for an LLM-compatible environment, this preliminary study
tests whether ChatGPT-3.5, a large language model (LLM) trained on
human-generated text, exhibits human-like cognitive biases when generating
random number sequences. Initial findings indicate that ChatGPT-3.5 more
effectively avoids repetitive and sequential patterns compared to humans, with
notably lower repeat frequencies and adjacent number frequencies. Continued
research into different models, parameters, and prompting methodologies will
deepen our understanding of how LLMs can more closely mimic human random
generation behaviors, while also broadening their applications in cognitive and
behavioral science research.",2024-08-19,Rachel M. Harrison,http://arxiv.org/pdf/2408.09656v2,cs.CL
ELDER: Enhancing Lifelong Model Editing with Mixture-of-LoRA,"Large language models (LLMs) require model editing to efficiently update
specific knowledge within them and avoid factual errors. Most model editing
methods are solely designed for single-time use and result in a significant
forgetting effect in lifelong editing scenarios, where sequential edits are
conducted over time. Previous approaches manage sequential edits by freezing
original parameters and discretely allocating new parameters for each knowledge
update. However, these methods lack robustness to minor input variations due to
the discrete mapping between data and parameters. To overcome this challenge,
we propose ELDER, a novel approach to create a continuous association between
data and adapters. ELDER integrates multiple LoRAs through a router network and
is trained to establish a smooth data-adapter association, thereby enhancing
the edit robustness and generalization of semantically equivalent inputs. To
ensure inputs containing the same knowledge will be processed by the same
LoRAs, we design a novel loss to guide the model link LoRA allocations with
edit knowledge. Furthermore, we propose a deferral mechanism to retain the
original LLM capabilities post-edit. Extensive experiments on GPT-2 XL and
LLaMA2-7B demonstrate that ELDER effectively edits models in the lifelong
setting, outperforming eight baselines while exhibiting strong scalability and
preserving LLMs' general abilities on downstream tasks. Our code is available
at https://github.com/JiaangL/ELDER.",2024-08-19,"Jiaang Li, Quan Wang, Zhongnan Wang, Yongdong Zhang, Zhendong Mao",http://arxiv.org/pdf/2408.11869v3,cs.CL
Improving embedding with contrastive fine-tuning on small datasets with expert-augmented scores,"This paper presents an approach to improve text embedding models through
contrastive fine-tuning on small datasets augmented with expert scores. It
focuses on enhancing semantic textual similarity tasks and addressing text
retrieval problems. The proposed method uses soft labels derived from
expert-augmented scores to fine-tune embedding models, preserving their
versatility and ensuring retrieval capability is improved. The paper evaluates
the method using a Q\&A dataset from an online shopping website and eight
expert models. Results show improved performance over a benchmark model across
multiple metrics on various retrieval tasks from the massive text embedding
benchmark (MTEB). The method is cost-effective and practical for real-world
applications, especially when labeled data is scarce.",2024-08-19,"Jun Lu, David Li, Bill Ding, Yu Kang",http://arxiv.org/pdf/2408.11868v1,cs.CL
Acquiring Bidirectionality via Large and Small Language Models,"Using token representation from bidirectional language models (LMs) such as
BERT is still a widely used approach for token-classification tasks. Even
though there exist much larger unidirectional LMs such as Llama-2, they are
rarely used to replace the token representation of bidirectional LMs. In this
work, we hypothesize that their lack of bidirectionality is keeping them
behind. To that end, we propose to newly train a small backward LM and
concatenate its representations to those of existing LM for downstream tasks.
Through experiments in named entity recognition, we demonstrate that
introducing backward model improves the benchmark performance more than 10
points. Furthermore, we show that the proposed method is especially effective
for rare domains and in few-shot learning settings.",2024-08-19,"Takumi Goto, Hiroyoshi Nagao, Yuta Koreeda",http://arxiv.org/pdf/2408.09640v2,cs.CL
How to Make the Most of LLMs' Grammatical Knowledge for Acceptability Judgments,"The grammatical knowledge of language models (LMs) is often measured using a
benchmark of linguistic minimal pairs, where the LMs are presented with a pair
of acceptable and unacceptable sentences and required to judge which is more
acceptable. Conventional approaches directly compare sentence probabilities
assigned by LMs, but recent large language models (LLMs) are trained to perform
tasks via prompting, and thus, the raw probabilities they assign may not fully
reflect their grammatical knowledge. In this study, we attempt to derive more
accurate acceptability judgments from LLMs using prompts and templates. Through
extensive experiments in English and Chinese, we compare nine judgment methods
and find two of them, a probability readout method -- in-template LP and a
prompt-based method -- Yes/No probability computing, achieve higher accuracy
than the conventional ones. Our analysis reveals that these methods excel in
different linguistic phenomena, suggesting they access different aspects of
LLMs' knowledge. We also find that ensembling the two methods outperforms
single methods. Consequently, we recommend these techniques, either
individually or ensembled, as more effective alternatives to conventional
approaches for assessing grammatical knowledge in LLMs.",2024-08-19,"Yusuke Ide, Yuto Nishida, Justin Vasselli, Miyu Oba, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2408.09639v2,cs.CL
MoDeGPT: Modular Decomposition for Large Language Model Compression,"Large Language Models (LLMs) have reshaped the landscape of artificial
intelligence by demonstrating exceptional performance across various tasks.
However, substantial computational requirements make their deployment
challenging on devices with limited resources. Recently, compression methods
using low-rank matrix techniques have shown promise, yet these often lead to
degraded accuracy or introduce significant overhead in parameters and inference
latency. This paper introduces \textbf{Mo}dular \textbf{De}composition
(MoDeGPT), a novel structured compression framework that does not need recovery
fine-tuning while resolving the above drawbacks. MoDeGPT partitions the
Transformer block into modules comprised of matrix pairs and reduces the hidden
dimensions via reconstructing the module-level outputs. MoDeGPT is developed
based on a theoretical framework that utilizes three well-established matrix
decomposition algorithms -- Nystr\""om approximation, CR decomposition, and SVD
-- and applies them to our redefined transformer modules. Our comprehensive
experiments show MoDeGPT, without backward propagation, matches or surpasses
previous structured compression methods that rely on gradient information, and
saves 98% of compute costs on compressing a 13B model. On \textsc{Llama}-2/3
and OPT models, MoDeGPT maintains 90-95% zero-shot performance with 25-30%
compression rates. Moreover, the compression can be done on a single GPU within
a few hours and increases the inference throughput by up to 46%.",2024-08-19,"Chi-Heng Lin, Shangqian Gao, James Seale Smith, Abhishek Patel, Shikhar Tuli, Yilin Shen, Hongxia Jin, Yen-Chang Hsu",http://arxiv.org/pdf/2408.09632v5,cs.CL
A Strategy to Combine 1stGen Transformers and Open LLMs for Automatic Text Classification,"Transformer models have achieved state-of-the-art results, with Large
Language Models (LLMs), an evolution of first-generation transformers (1stTR),
being considered the cutting edge in several NLP tasks. However, the literature
has yet to conclusively demonstrate that LLMs consistently outperform 1stTRs
across all NLP tasks. This study compares three 1stTRs (BERT, RoBERTa, and
BART) with two open LLMs (Llama 2 and Bloom) across 11 sentiment analysis
datasets. The results indicate that open LLMs may moderately outperform or
match 1stTRs in 8 out of 11 datasets but only when fine-tuned. Given this
substantial cost for only moderate gains, the practical applicability of these
models in cost-sensitive scenarios is questionable. In this context, a
confidence-based strategy that seamlessly integrates 1stTRs with open LLMs
based on prediction certainty is proposed. High-confidence documents are
classified by the more cost-effective 1stTRs, while uncertain cases are handled
by LLMs in zero-shot or few-shot modes, at a much lower cost than fine-tuned
versions. Experiments in sentiment analysis demonstrate that our solution not
only outperforms 1stTRs, zero-shot, and few-shot LLMs but also competes closely
with fine-tuned LLMs at a fraction of the cost.",2024-08-19,"Claudio M. V. de Andrade, Washington Cunha, Davi Reis, Adriana Silvina Pagano, Leonardo Rocha, Marcos André Gonçalves",http://arxiv.org/pdf/2408.09629v1,cs.CL
Refining Packing and Shuffling Strategies for Enhanced Performance in Generative Language Models,"Packing and shuffling tokens is a common practice in training auto-regressive
language models (LMs) to prevent overfitting and improve efficiency. Typically
documents are concatenated to chunks of maximum sequence length (MSL) and then
shuffled. However setting the atom size, the length for each data chunk
accompanied by random shuffling, to MSL may lead to contextual incoherence due
to tokens from different documents being packed into the same chunk. An
alternative approach is to utilize padding, another common data packing
strategy, to avoid contextual incoherence by only including one document in
each shuffled chunk. To optimize both packing strategies (concatenation vs
padding), we investigated the optimal atom size for shuffling and compared
their performance and efficiency. We found that matching atom size to MSL
optimizes performance for both packing methods (concatenation and padding), and
padding yields lower final perplexity (higher performance) than concatenation
at the cost of more training steps and lower compute efficiency. This trade-off
informs the choice of packing methods in training language models.",2024-08-19,"Yanbing Chen, Ruilin Wang, Zihao Yang, Lavender Yao Jiang, Eric Karl Oermann",http://arxiv.org/pdf/2408.09621v1,cs.CL
PhysBERT: A Text Embedding Model for Physics Scientific Literature,"The specialized language and complex concepts in physics pose significant
challenges for information extraction through Natural Language Processing
(NLP). Central to effective NLP applications is the text embedding model, which
converts text into dense vector representations for efficient information
retrieval and semantic analysis. In this work, we introduce PhysBERT, the first
physics-specific text embedding model. Pre-trained on a curated corpus of 1.2
million arXiv physics papers and fine-tuned with supervised data, PhysBERT
outperforms leading general-purpose models on physics-specific tasks including
the effectiveness in fine-tuning for specific physics subdomains.",2024-08-18,"Thorsten Hellert, João Montenegro, Andrea Pollastro",http://arxiv.org/pdf/2408.09574v1,cs.CL
Grammatical Error Feedback: An Implicit Evaluation Approach,"Grammatical feedback is crucial for consolidating second language (L2)
learning. Most research in computer-assisted language learning has focused on
feedback through grammatical error correction (GEC) systems, rather than
examining more holistic feedback that may be more useful for learners. This
holistic feedback will be referred to as grammatical error feedback (GEF). In
this paper, we present a novel implicit evaluation approach to GEF that
eliminates the need for manual feedback annotations. Our method adopts a
grammatical lineup approach where the task is to pair feedback and essay
representations from a set of possible alternatives. This matching process can
be performed by appropriately prompting a large language model (LLM). An
important aspect of this process, explored here, is the form of the lineup,
i.e., the selection of foils. This paper exploits this framework to examine the
quality and need for GEC to generate feedback, as well as the system used to
generate feedback, using essays from the Cambridge Learner Corpus.",2024-08-18,"Stefano Bannò, Kate Knill, Mark J. F. Gales",http://arxiv.org/pdf/2408.09565v1,cs.CL
HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model,"Large Language Model (LLM)-based agents exhibit significant potential across
various domains, operating as interactive systems that process environmental
observations to generate executable actions for target tasks. The effectiveness
of these agents is significantly influenced by their memory mechanism, which
records historical experiences as sequences of action-observation pairs. We
categorize memory into two types: cross-trial memory, accumulated across
multiple attempts, and in-trial memory (working memory), accumulated within a
single attempt. While considerable research has optimized performance through
cross-trial memory, the enhancement of agent performance through improved
working memory utilization remains underexplored. Instead, existing approaches
often involve directly inputting entire historical action-observation pairs
into LLMs, leading to redundancy in long-horizon tasks. Inspired by human
problem-solving strategies, this paper introduces HiAgent, a framework that
leverages subgoals as memory chunks to manage the working memory of LLM-based
agents hierarchically. Specifically, HiAgent prompts LLMs to formulate subgoals
before generating executable actions and enables LLMs to decide proactively to
replace previous subgoals with summarized observations, retaining only the
action-observation pairs relevant to the current subgoal. Experimental results
across five long-horizon tasks demonstrate that HiAgent achieves a twofold
increase in success rate and reduces the average number of steps required by
3.8. Additionally, our analysis shows that HiAgent consistently improves
performance across various steps, highlighting its robustness and
generalizability. Project Page: https://github.com/HiAgent2024/HiAgent .",2024-08-18,"Mengkang Hu, Tianxing Chen, Qiguang Chen, Yao Mu, Wenqi Shao, Ping Luo",http://arxiv.org/pdf/2408.09559v1,cs.CL
No Such Thing as a General Learner: Language models and their dual optimization,"What role can the otherwise successful Large Language Models (LLMs) play in
the understanding of human cognition, and in particular in terms of informing
language acquisition debates? To contribute to this question, we first argue
that neither humans nor LLMs are general learners, in a variety of senses. We
make a novel case for how in particular LLMs follow a dual-optimization
process: they are optimized during their training (which is typically compared
to language acquisition), and modern LLMs have also been selected, through a
process akin to natural selection in a species. From this perspective, we argue
that the performance of LLMs, whether similar or dissimilar to that of humans,
does not weigh easily on important debates about the importance of human
cognitive biases for language.",2024-08-18,"Emmanuel Chemla, Ryan M. Nefdt",http://arxiv.org/pdf/2408.09544v2,cs.CL
Using ChatGPT to Score Essays and Short-Form Constructed Responses,"This study aimed to determine if ChatGPT's large language models could match
the scoring accuracy of human and machine scores from the ASAP competition. The
investigation focused on various prediction models, including linear
regression, random forest, gradient boost, and boost. ChatGPT's performance was
evaluated against human raters using quadratic weighted kappa (QWK) metrics.
Results indicated that while ChatGPT's gradient boost model achieved QWKs close
to human raters for some data sets, its overall performance was inconsistent
and often lower than human scores. The study highlighted the need for further
refinement, particularly in handling biases and ensuring scoring fairness.
Despite these challenges, ChatGPT demonstrated potential for scoring
efficiency, especially with domain-specific fine-tuning. The study concludes
that ChatGPT can complement human scoring but requires additional development
to be reliable for high-stakes assessments. Future research should improve
model accuracy, address ethical considerations, and explore hybrid models
combining ChatGPT with empirical methods.",2024-08-18,Mark D. Shermis,http://arxiv.org/pdf/2408.09540v1,cs.CL
"Revisiting the Graph Reasoning Ability of Large Language Models: Case Studies in Translation, Connectivity and Shortest Path","Large Language Models (LLMs) have achieved great success in various reasoning
tasks. In this work, we focus on the graph reasoning ability of LLMs. Although
theoretical studies proved that LLMs are capable of handling graph reasoning
tasks, empirical evaluations reveal numerous failures. To deepen our
understanding on this discrepancy, we revisit the ability of LLMs on three
fundamental graph tasks: graph description translation, graph connectivity, and
the shortest-path problem. Our findings suggest that LLMs can fail to
understand graph structures through text descriptions and exhibit varying
performance for all these three fundamental tasks. Meanwhile, we perform a
real-world investigation on knowledge graphs and make consistent observations
with our findings. The codes and datasets are available.",2024-08-18,"Xinnan Dai, Qihao Wen, Yifei Shen, Hongzhi Wen, Dongsheng Li, Jiliang Tang, Caihua Shan",http://arxiv.org/pdf/2408.09529v2,cs.CL
Out-of-distribution generalization via composition: a lens through induction heads in Transformers,"Large language models (LLMs) such as GPT-4 sometimes appear to be creative,
solving novel tasks often with a few demonstrations in the prompt. These tasks
require the models to generalize on distributions different from those from
training data -- which is known as out-of-distribution (OOD) generalization.
Despite the tremendous success of LLMs, how they approach OOD generalization
remains an open and underexplored question. We examine OOD generalization in
settings where instances are generated according to hidden rules, including
in-context learning with symbolic reasoning. Models are required to infer the
hidden rules behind input prompts without any fine-tuning.
  We empirically examined the training dynamics of Transformers on a synthetic
example and conducted extensive experiments on a variety of pretrained LLMs,
focusing on a type of components known as induction heads. We found that OOD
generalization and composition are tied together -- models can learn rules by
composing two self-attention layers, thereby achieving OOD generalization.
Furthermore, a shared latent subspace in the embedding (or feature) space acts
as a bridge for composition by aligning early layers and later layers, which we
refer to as the common bridge representation hypothesis.",2024-08-18,"Jiajun Song, Zhuoyan Xu, Yiqiao Zhong",http://arxiv.org/pdf/2408.09503v2,cs.CL
REFINE-LM: Mitigating Language Model Stereotypes via Reinforcement Learning,"With the introduction of (large) language models, there has been significant
concern about the unintended bias such models may inherit from their training
data. A number of studies have shown that such models propagate gender
stereotypes, as well as geographical and racial bias, among other biases. While
existing works tackle this issue by preprocessing data and debiasing
embeddings, the proposed methods require a lot of computational resources and
annotation effort while being limited to certain types of biases. To address
these issues, we introduce REFINE-LM, a debiasing method that uses
reinforcement learning to handle different types of biases without any
fine-tuning. By training a simple model on top of the word probability
distribution of a LM, our bias agnostic reinforcement learning method enables
model debiasing without human annotations or significant computational
resources. Experiments conducted on a wide range of models, including several
LMs, show that our method (i) significantly reduces stereotypical biases while
preserving LMs performance; (ii) is applicable to different types of biases,
generalizing across contexts such as gender, ethnicity, religion, and
nationality-based biases; and (iii) it is not expensive to train.",2024-08-18,"Rameez Qureshi, Naïm Es-Sebbani, Luis Galárraga, Yvette Graham, Miguel Couceiro, Zied Bouraoui",http://arxiv.org/pdf/2408.09489v1,cs.CL
Activated Parameter Locating via Causal Intervention for Model Merging,"Model merging combines multiple homologous models into one model, achieving
convincing generalization without the necessity of additional training. A key
challenge in this problem is resolving parameter redundancies and conflicts
across multiple models. Existing models have demonstrated that dropping a
portion of delta parameters can alleviate conflicts while maintaining
performance. However, these methods often drop parameters either randomly or
based on magnitude, overlooking task-specific information embedded in
fine-tuned models. In this paper, we propose an Activated Parameter Locating
(APL) method that utilizes causal intervention to estimate parameter
importance, enabling more precise parameter drops and better conflict
mitigation. Moreover, to reduce the computational complexity associated with a
large number of parameter partitions, we also introduce a theoretically
supported gradient approximation strategy for APL. Experiments on model merging
within both in-domain and out-of-domain settings, along with associated
analyses, showcase the effectiveness of APL.",2024-08-18,"Fanshuang Kong, Richong Zhang, Ziqiao Wang",http://arxiv.org/pdf/2408.09485v1,cs.CL
PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis,"While existing Aspect-based Sentiment Analysis (ABSA) has received extensive
effort and advancement, there are still gaps in defining a more holistic
research target seamlessly integrating multimodality, conversation context,
fine-granularity, and also covering the changing sentiment dynamics as well as
cognitive causal rationales. This paper bridges the gaps by introducing a
multimodal conversational ABSA, where two novel subtasks are proposed: 1)
Panoptic Sentiment Sextuple Extraction, panoramically recognizing holder,
target, aspect, opinion, sentiment, rationale from multi-turn multi-party
multimodal dialogue. 2) Sentiment Flipping Analysis, detecting the dynamic
sentiment transformation throughout the conversation with the causal reasons.
To benchmark the tasks, we construct PanoSent, a dataset annotated both
manually and automatically, featuring high quality, large scale, multimodality,
multilingualism, multi-scenarios, and covering both implicit and explicit
sentiment elements. To effectively address the tasks, we devise a novel
Chain-of-Sentiment reasoning framework, together with a novel multimodal large
language model (namely Sentica) and a paraphrase-based verification mechanism.
Extensive evaluations demonstrate the superiority of our methods over strong
baselines, validating the efficacy of all our proposed methods. The work is
expected to open up a new era for the ABSA community, and thus all our codes
and data are open at https://PanoSent.github.io/",2024-08-18,"Meng Luo, Hao Fei, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu",http://arxiv.org/pdf/2408.09481v2,cs.CL
Image-Based Geolocation Using Large Vision-Language Models,"Geolocation is now a vital aspect of modern life, offering numerous benefits
but also presenting serious privacy concerns. The advent of large
vision-language models (LVLMs) with advanced image-processing capabilities
introduces new risks, as these models can inadvertently reveal sensitive
geolocation information. This paper presents the first in-depth study analyzing
the challenges posed by traditional deep learning and LVLM-based geolocation
methods. Our findings reveal that LVLMs can accurately determine geolocations
from images, even without explicit geographic training.
  To address these challenges, we introduce \tool{}, an innovative framework
that significantly enhances image-based geolocation accuracy. \tool{} employs a
systematic chain-of-thought (CoT) approach, mimicking human geoguessing
strategies by carefully analyzing visual and contextual cues such as vehicle
types, architectural styles, natural landscapes, and cultural elements.
Extensive testing on a dataset of 50,000 ground-truth data points shows that
\tool{} outperforms both traditional models and human benchmarks in accuracy.
It achieves an impressive average score of 4550.5 in the GeoGuessr game, with
an 85.37\% win rate, and delivers highly precise geolocation predictions, with
the closest distances as accurate as 0.3 km. Furthermore, our study highlights
issues related to dataset integrity, leading to the creation of a more robust
dataset and a refined framework that leverages LVLMs' cognitive capabilities to
improve geolocation precision. These findings underscore \tool{}'s superior
ability to interpret complex visual data, the urgent need to address emerging
security vulnerabilities posed by LVLMs, and the importance of responsible AI
development to ensure user privacy protection.",2024-08-18,"Yi Liu, Junchen Ding, Gelei Deng, Yuekang Li, Tianwei Zhang, Weisong Sun, Yaowen Zheng, Jingquan Ge, Yang Liu",http://arxiv.org/pdf/2408.09474v1,cs.CL
WPN: An Unlearning Method Based on N-pair Contrastive Learning in Language Models,"Generative language models (LMs) offer numerous advantages but may produce
inappropriate or harmful outputs due to the harmful knowledge acquired during
pre-training. This knowledge often manifests as undesirable correspondences,
such as ""harmful prompts"" leading to ""harmful outputs,"" which our research aims
to mitigate through unlearning techniques.However, existing unlearning methods
based on gradient ascent can significantly impair the performance of LMs. To
address this issue, we propose a novel approach called Weighted Positional
N-pair (WPN) Learning, which leverages position-weighted mean pooling within an
n-pair contrastive learning framework. WPN is designed to modify the output
distribution of LMs by eliminating specific harmful outputs (e.g., replacing
toxic responses with neutral ones), thereby transforming the model's behavior
from ""harmful prompt-harmful output"" to ""harmful prompt-harmless
response"".Experiments on OPT and GPT-NEO LMs show that WPN effectively reduces
the proportion of harmful responses, achieving a harmless rate of up to 95.8\%
while maintaining stable performance on nine common benchmarks (with less than
2\% degradation on average). Moreover, we provide empirical evidence to
demonstrate WPN's ability to weaken the harmful correspondences in terms of
generalizability and robustness, as evaluated on out-of-distribution test sets
and under adversarial attacks.",2024-08-18,"Guitao Chen, Yunshen Wang, Hongye Sun, Guang Chen",http://arxiv.org/pdf/2408.09459v1,cs.CL
Identifying Speakers and Addressees of Quotations in Novels with Prompt Learning,"Quotations in literary works, especially novels, are important to create
characters, reflect character relationships, and drive plot development.
Current research on quotation extraction in novels primarily focuses on
quotation attribution, i.e., identifying the speaker of the quotation. However,
the addressee of the quotation is also important to construct the relationship
between the speaker and the addressee. To tackle the problem of dataset
scarcity, we annotate the first Chinese quotation corpus with elements
including speaker, addressee, speaking mode and linguistic cue. We propose
prompt learning-based methods for speaker and addressee identification based on
fine-tuned pre-trained models. Experiments on both Chinese and English datasets
show the effectiveness of the proposed methods, which outperform methods based
on zero-shot and few-shot large language models.",2024-08-18,"Yuchen Yan, Hanjie Zhao, Senbin Zhu, Hongde Liu, Zhihong Zhang, Yuxiang Jia",http://arxiv.org/pdf/2408.09452v1,cs.CL
Retrieval-Augmented Generation Meets Data-Driven Tabula Rasa Approach for Temporal Knowledge Graph Forecasting,"Pre-trained large language models (PLLMs) like OpenAI ChatGPT and Google
Gemini face challenges such as inaccurate factual recall, hallucinations,
biases, and future data leakage for temporal Knowledge Graph (tKG) forecasting.
To address these issues, we introduce sLA-tKGF (small-scale language assistant
for tKG forecasting), which utilizes Retrieval-Augmented Generation (RAG)
aided, custom-trained small-scale language models through a tabula rasa
approach from scratch for effective tKG forecasting. Our framework constructs
knowledge-infused prompts with relevant historical data from tKGs, web search
results, and PLLMs-generated textual descriptions to understand historical
entity relationships prior to the target time. It leverages these external
knowledge-infused prompts for deeper understanding and reasoning of
context-specific semantic and temporal information to zero-shot prompt
small-scale language models for more accurate predictions of future events
within tKGs. It reduces hallucinations and mitigates distributional shift
challenges through comprehending changing trends over time. As a result, it
enables more accurate and contextually grounded forecasts of future events
while minimizing computational demands. Rigorous empirical studies demonstrate
our framework robustness, scalability, and state-of-the-art (SOTA) performance
on benchmark datasets with interpretable and trustworthy tKG forecasting.",2024-08-18,"Geethan Sannidhi, Sagar Srinivas Sakhinana, Venkataramana Runkana",http://arxiv.org/pdf/2408.13273v1,cs.CL
Agentic Retrieval-Augmented Generation for Time Series Analysis,"Time series modeling is crucial for many applications, however, it faces
challenges such as complex spatio-temporal dependencies and distribution shifts
in learning from historical context to predict task-specific outcomes. To
address these challenges, we propose a novel approach using an agentic
Retrieval-Augmented Generation (RAG) framework for time series analysis. The
framework leverages a hierarchical, multi-agent architecture where the master
agent orchestrates specialized sub-agents and delegates the end-user request to
the relevant sub-agent. The sub-agents utilize smaller, pre-trained language
models (SLMs) customized for specific time series tasks through fine-tuning
using instruction tuning and direct preference optimization, and retrieve
relevant prompts from a shared repository of prompt pools containing distilled
knowledge about historical patterns and trends to improve predictions on new
data. Our proposed modular, multi-agent RAG approach offers flexibility and
achieves state-of-the-art performance across major time series tasks by
tackling complex challenges more effectively than task-specific customized
methods across benchmark datasets.",2024-08-18,"Chidaksh Ravuru, Sagar Srinivas Sakhinana, Venkataramana Runkana",http://arxiv.org/pdf/2408.14484v1,cs.CL
Crossing New Frontiers: Knowledge-Augmented Large Language Model Prompting for Zero-Shot Text-Based De Novo Molecule Design,"Molecule design is a multifaceted approach that leverages computational
methods and experiments to optimize molecular properties, fast-tracking new
drug discoveries, innovative material development, and more efficient chemical
processes. Recently, text-based molecule design has emerged, inspired by
next-generation AI tasks analogous to foundational vision-language models. Our
study explores the use of knowledge-augmented prompting of large language
models (LLMs) for the zero-shot text-conditional de novo molecular generation
task. Our approach uses task-specific instructions and a few demonstrations to
address distributional shift challenges when constructing augmented prompts for
querying LLMs to generate molecules consistent with technical descriptions. Our
framework proves effective, outperforming state-of-the-art (SOTA) baseline
models on benchmark datasets.",2024-08-18,"Sakhinana Sagar Srinivas, Venkataramana Runkana",http://arxiv.org/pdf/2408.11866v1,cs.CL
Hindi-BEIR : A Large Scale Retrieval Benchmark in Hindi,"Given the large number of Hindi speakers worldwide, there is a pressing need
for robust and efficient information retrieval systems for Hindi. Despite
ongoing research, there is a lack of comprehensive benchmark for evaluating
retrieval models in Hindi. To address this gap, we introduce the Hindi version
of the BEIR benchmark, which includes a subset of English BEIR datasets
translated to Hindi, existing Hindi retrieval datasets, and synthetically
created datasets for retrieval. The benchmark is comprised of $15$ datasets
spanning across $8$ distinct tasks. We evaluate state-of-the-art multilingual
retrieval models on this benchmark to identify task and domain-specific
challenges and their impact on retrieval performance. By releasing this
benchmark and a set of relevant baselines, we enable researchers to understand
the limitations and capabilities of current Hindi retrieval models, promoting
advancements in this critical area. The datasets from Hindi-BEIR are publicly
available.",2024-08-18,"Arkadeep Acharya, Rudra Murthy, Vishwajeet Kumar, Jaydeep Sen",http://arxiv.org/pdf/2408.09437v1,cs.CL
HySem: A context length optimized LLM pipeline for unstructured tabular extraction,"Regulatory compliance reporting in the pharmaceutical industry relies on
detailed tables, but these are often under-utilized beyond compliance due to
their unstructured format and arbitrary content. Extracting and semantically
representing tabular data is challenging due to diverse table presentations.
Large Language Models (LLMs) demonstrate substantial potential for semantic
representation, yet they encounter challenges related to accuracy and context
size limitations, which are crucial considerations for the industry
applications. We introduce HySem, a pipeline that employs a novel context
length optimization technique to generate accurate semantic JSON
representations from HTML tables. This approach utilizes a custom fine-tuned
model specifically designed for cost- and privacy-sensitive small and medium
pharmaceutical enterprises. Running on commodity hardware and leveraging
open-source models, HySem surpasses its peer open-source models in accuracy and
provides competitive performance when benchmarked against OpenAI GPT-4o and
effectively addresses context length limitations, which is a crucial factor for
supporting larger tables.",2024-08-18,"Narayanan PP, Anantharaman Palacode Narayana Iyer",http://arxiv.org/pdf/2408.09434v2,cs.CL
FASST: Fast LLM-based Simultaneous Speech Translation,"Simultaneous speech translation (SST) takes streaming speech input and
generates text translation on the fly. Existing methods either have high
latency due to recomputation of input representations, or fall behind of
offline ST in translation quality. In this paper, we propose FASST, a fast
large language model based method for streaming speech translation. We propose
blockwise-causal speech encoding and consistency mask, so that streaming speech
input can be encoded incrementally without recomputation. Furthermore, we
develop a two-stage training strategy to optimize FASST for simultaneous
inference. We evaluate FASST and multiple strong prior models on MuST-C
dataset. Experiment results show that FASST achieves the best quality-latency
trade-off. It outperforms the previous best model by an average of 1.5 BLEU
under the same latency for English to Spanish translation.",2024-08-18,"Siqi Ouyang, Xi Xu, Chinmay Dandekar, Lei Li",http://arxiv.org/pdf/2408.09430v1,cs.CL
"Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models","Hallucination issues continue to affect multimodal large language models
(MLLMs), with existing research mainly addressing object-level or
attribute-level hallucinations, neglecting the more complex relation
hallucinations that require advanced reasoning. Current benchmarks for relation
hallucinations lack detailed evaluation and effective mitigation, and their
datasets often suffer from biases due to systematic annotation processes. To
address these challenges, we introduce Reefknot, a comprehensive benchmark
targeting relation hallucinations, comprising over 20,000 real-world samples.
We provide a systematic definition of relation hallucinations, integrating
perceptive and cognitive perspectives, and construct a relation-based corpus
using the Visual Genome scene graph dataset. Our comparative evaluation reveals
significant limitations in current MLLMs' ability to handle relation
hallucinations. Additionally, we propose a novel confidence-based mitigation
strategy, which reduces the hallucination rate by an average of 9.75% across
three datasets, including Reefknot. Our work offers valuable insights for
achieving trustworthy multimodal intelligence.",2024-08-18,"Kening Zheng, Junkai Chen, Yibo Yan, Xin Zou, Xuming Hu",http://arxiv.org/pdf/2408.09429v2,cs.CL
Distinguish Confusion in Legal Judgment Prediction via Revised Relation Knowledge,"Legal Judgment Prediction (LJP) aims to automatically predict a law case's
judgment results based on the text description of its facts. In practice, the
confusing law articles (or charges) problem frequently occurs, reflecting that
the law cases applicable to similar articles (or charges) tend to be misjudged.
Although some recent works based on prior knowledge solve this issue well, they
ignore that confusion also occurs between law articles with a high posterior
semantic similarity due to the data imbalance problem instead of only between
the prior highly similar ones, which is this work's further finding. This paper
proposes an end-to-end model named \textit{D-LADAN} to solve the above
challenges. On the one hand, D-LADAN constructs a graph among law articles
based on their text definition and proposes a graph distillation operation
(GDO) to distinguish the ones with a high prior semantic similarity. On the
other hand, D-LADAN presents a novel momentum-updated memory mechanism to
dynamically sense the posterior similarity between law articles (or charges)
and a weighted GDO to adaptively capture the distinctions for revising the
inductive bias caused by the data imbalance problem. We perform extensive
experiments to demonstrate that D-LADAN significantly outperforms
state-of-the-art methods in accuracy and robustness.",2024-08-18,"Nuo Xu, Pinghui Wang, Junzhou Zhao, Feiyang Sun, Lin Lan, Jing Tao, Li Pan, Xiaohong Guan",http://arxiv.org/pdf/2408.09422v1,cs.CL
Enhancing Startup Success Predictions in Venture Capital: A GraphRAG Augmented Multivariate Time Series Method,"In the Venture Capital (VC) industry, predicting the success of startups is
challenging due to limited financial data and the need for subjective revenue
forecasts. Previous methods based on time series analysis often fall short as
they fail to incorporate crucial inter-company relationships such as
competition and collaboration. To fill the gap, this paper aims to introduce a
novel approach using GraphRAG augmented time series model. With GraphRAG, time
series predictive methods are enhanced by integrating these vital relationships
into the analysis framework, allowing for a more dynamic understanding of the
startup ecosystem in venture capital. Our experimental results demonstrate that
our model significantly outperforms previous models in startup success
predictions.",2024-08-18,"Zitian Gao, Yihao Xiao",http://arxiv.org/pdf/2408.09420v5,cs.CL
Challenges and Responses in the Practice of Large Language Models,"This paper carefully summarizes extensive and profound questions from all
walks of life, focusing on the current high-profile AI field, covering multiple
dimensions such as industry trends, academic research, technological innovation
and business applications. This paper meticulously curates questions that are
both thought-provoking and practically relevant, providing nuanced and
insightful answers to each. To facilitate readers' understanding and reference,
this paper specifically classifies and organizes these questions systematically
and meticulously from the five core dimensions of computing power
infrastructure, software architecture, data resources, application scenarios,
and brain science. This work aims to provide readers with a comprehensive,
in-depth and cutting-edge AI knowledge framework to help people from all walks
of life grasp the pulse of AI development, stimulate innovative thinking, and
promote industrial progress.",2024-08-18,Hongyin Zhu,http://arxiv.org/pdf/2408.09416v2,cs.CL
Comparison between the Structures of Word Co-occurrence and Word Similarity Networks for Ill-formed and Well-formed Texts in Taiwan Mandarin,"The study of word co-occurrence networks has attracted the attention of
researchers due to their potential significance as well as applications.
Understanding the structure of word co-occurrence networks is therefore
important to fully realize their significance and usages. In past studies, word
co-occurrence networks built on well-formed texts have been found to possess
certain characteristics, including being small-world, following a two-regime
power law distribution, and being generally disassortative. On the flip side,
past studies have found that word co-occurrence networks built from ill-formed
texts such as microblog posts may behave differently from those built from
well-formed documents. While both kinds of word co-occurrence networks are
small-world and disassortative, word co-occurrence networks built from
ill-formed texts are scale-free and follow the power law distribution instead
of the two-regime power law distribution. However, since past studies on the
behavior of word co-occurrence networks built from ill-formed texts only
investigated English, the universality of such characteristics remains to be
seen among different languages. In addition, it is yet to be investigated
whether there could be possible similitude/differences between word
co-occurrence networks and other potentially comparable networks. This study
therefore investigates and compares the structure of word co-occurrence
networks and word similarity networks based on Taiwan Mandarin ill-formed
internet forum posts and compare them with those built with well-formed
judicial judgments, and seeks to find out whether the three aforementioned
properties (scale-free, small-world, and disassortative) for ill-formed and
well-formed texts are universal among different languages and between word
co-occurrence and word similarity networks.",2024-08-18,"Po-Hsuan Huang, Hsuan-Lei Shao",http://arxiv.org/pdf/2408.09404v1,cs.CL
Game Development as Human-LLM Interaction,"Game development is a highly specialized task that relies on a complex game
engine powered by complex programming languages, preventing many gaming
enthusiasts from handling it. This paper introduces the Chat Game Engine
(ChatGE) powered by LLM, which allows everyone to develop a custom game using
natural language through Human-LLM interaction. To enable an LLM to function as
a ChatGE, we instruct it to perform the following processes in each turn: (1)
$P_{script}$: configure the game script segment based on the user's input; (2)
$P_{code}$: generate the corresponding code snippet based on the game script
segment; (3) $P_{utter}$: interact with the user, including guidance and
feedback. We propose a data synthesis pipeline based on LLM to generate game
script-code pairs and interactions from a few manually crafted seed data. We
propose a three-stage progressive training strategy to transfer the
dialogue-based LLM to our ChatGE smoothly. We construct a ChatGE for poker
games as a case study and comprehensively evaluate it from two perspectives:
interaction quality and code correctness.",2024-08-18,"Jiale Hong, Hongqiu Wu, Hai Zhao",http://arxiv.org/pdf/2408.09386v2,cs.CL
Reward Difference Optimization For Sample Reweighting In Offline RLHF,"With the rapid advances in Large Language Models (LLMs), aligning LLMs with
human preferences become increasingly important. Although Reinforcement
Learning with Human Feedback (RLHF) proves effective, it is complicated and
highly resource-intensive. As such, offline RLHF has been introduced as an
alternative solution, which directly optimizes LLMs with ranking losses on a
fixed preference dataset. Current offline RLHF only captures the ""ordinal
relationship"" between responses, overlooking the crucial aspect of how much one
is preferred over the others. To address this issue, we propose a simple yet
effective solution called Reward Difference Optimization, shorted as RDO.
Specifically, we introduce reward difference coefficients to reweigh sample
pairs in offline RLHF. We then develop a difference model which captures rich
interactions between a pair of responses for predicting these difference
coefficients. Experiments with 7B LLMs on the HH and TL;DR datasets
substantiate the effectiveness of our method in both automatic metrics and
human evaluation, thereby highlighting its potential for aligning LLMs with
human intent and values",2024-08-18,"Shiqi Wang, Zhengze Zhang, Rui Zhao, Fei Tan, Cam Tu Nguyen",http://arxiv.org/pdf/2408.09385v2,cs.CL
Improving and Assessing the Fidelity of Large Language Models Alignment to Online Communities,"Large language models (LLMs) have shown promise in representing individuals
and communities, offering new ways to study complex social dynamics. However,
effectively aligning LLMs with specific human groups and systematically
assessing the fidelity of the alignment remains a challenge. This paper
presents a robust framework for aligning LLMs with online communities via
instruction-tuning and comprehensively evaluating alignment across various
aspects of language, including authenticity, emotional tone, toxicity, and
harm. We demonstrate the utility of our approach by applying it to online
communities centered on dieting and body image. We administer an eating
disorder psychometric test to the aligned LLMs to reveal unhealthy beliefs and
successfully differentiate communities with varying levels of eating disorder
risk. Our results highlight the potential of LLMs in automated moderation and
broader applications in public health and social science research.",2024-08-18,"Minh Duc Chu, Zihao He, Rebecca Dorn, Kristina Lerman",http://arxiv.org/pdf/2408.09366v2,cs.CL
Concept Distillation from Strong to Weak Models via Hypotheses-to-Theories Prompting,"Hand-crafting high quality prompts to optimize the performance of language
models is a complicated and labor-intensive process. Furthermore, when
migrating to newer, smaller, or weaker models (possibly due to latency or cost
gains), prompts need to be updated to re-optimize the task performance. We
propose Concept Distillation (CD), an automatic prompt optimization technique
for enhancing weaker models on complex tasks. CD involves: (1) collecting
mistakes made by weak models with a base prompt (initialization), (2) using a
strong model to generate reasons for these mistakes and create rules/concepts
for weak models (induction), and (3) filtering these rules based on validation
set performance and integrating them into the base prompt
(deduction/verification). We evaluated CD on NL2Code and mathematical reasoning
tasks, observing significant performance boosts for small and weaker language
models. Notably, Mistral-7B's accuracy on Multi-Arith increased by 20%, and
Phi-3-mini-3.8B's accuracy on HumanEval rose by 34%. Compared to other
automated methods, CD offers an effective, cost-efficient strategy for
improving weak models' performance on complex tasks and enables seamless
workload migration across different language models without compromising
performance.",2024-08-18,"Emmanuel Aboah Boateng, Cassiano O. Becker, Nabiha Asghar, Kabir Walia, Ashwin Srinivasan, Ehi Nosakhare, Soundar Srinivasan, Victor Dibia",http://arxiv.org/pdf/2408.09365v2,cs.CL
"SkyScript-100M: 1,000,000,000 Pairs of Scripts and Shooting Scripts for Short Drama","Generating high-quality shooting scripts containing information such as scene
and shot language is essential for short drama script generation. We collect
6,660 popular short drama episodes from the Internet, each with an average of
100 short episodes, and the total number of short episodes is about 80,000,
with a total duration of about 2,000 hours and totaling 10 terabytes (TB). We
perform keyframe extraction and annotation on each episode to obtain about
10,000,000 shooting scripts. We perform 100 script restorations on the
extracted shooting scripts based on our self-developed large short drama
generation model SkyReels. This leads to a dataset containing 1,000,000,000
pairs of scripts and shooting scripts for short dramas, called SkyScript-100M.
We compare SkyScript-100M with the existing dataset in detail and demonstrate
some deeper insights that can be achieved based on SkyScript-100M. Based on
SkyScript-100M, researchers can achieve several deeper and more far-reaching
script optimization goals, which may drive a paradigm shift in the entire field
of text-to-video and significantly advance the field of short drama video
generation. The data and code are available at
https://github.com/vaew/SkyScript-100M.",2024-08-18,"Jing Tang, Quanlu Jia, Yuqiang Xie, Zeyu Gong, Xiang Wen, Jiayi Zhang, Yalong Guo, Guibin Chen, Jiangping Yang",http://arxiv.org/pdf/2408.09333v2,cs.CL
Fostering Natural Conversation in Large Language Models with NICO: a Natural Interactive COnversation dataset,"Benefiting from diverse instruction datasets, contemporary Large Language
Models (LLMs) perform effectively as AI assistants in collaborating with
humans. However, LLMs still struggle to generate natural and colloquial
responses in real-world applications such as chatbots and psychological
counseling that require more human-like interactions. To address these
limitations, we introduce NICO, a Natural Interactive COnversation dataset in
Chinese. We first use GPT-4-turbo to generate dialogue drafts and make them
cover 20 daily-life topics and 5 types of social interactions. Then, we hire
workers to revise these dialogues to ensure that they are free of grammatical
errors and unnatural utterances. We define two dialogue-level natural
conversation tasks and two sentence-level tasks for identifying and rewriting
unnatural sentences. Multiple open-source and closed-source LLMs are tested and
analyzed in detail. The experimental results highlight the challenge of the
tasks and demonstrate how NICO can help foster the natural dialogue
capabilities of LLMs. The dataset will be released.",2024-08-18,"Renliang Sun, Mengyuan Liu, Shiping Yang, Rui Wang, Junqing He, Jiaxing Zhang",http://arxiv.org/pdf/2408.09330v2,cs.CL
Threshold Filtering Packing for Supervised Fine-Tuning: Training Related Samples within Packs,"Packing for Supervised Fine-Tuning (SFT) in autoregressive models involves
concatenating data points of varying lengths until reaching the designed
maximum length to facilitate GPU processing. However, randomly concatenating
data points can lead to cross-contamination of sequences due to the significant
difference in their subject matter. The mainstream approaches in SFT ensure
that each token in the attention calculation phase only focuses on tokens
within its own short sequence, without providing additional learning signals
for the preceding context. To address these challenges, we introduce Threshold
Filtering Packing (TFP), a method that selects samples with related context
while maintaining sufficient diversity within the same pack. Our experiments
show that TFP offers a simple-to-implement and scalable approach that
significantly enhances SFT performance, with observed improvements of up to 7\%
on GSM8K, 4\% on HumanEval. Furthermore, results from bias benchmark datasets
highlight TFP's promising performance in improving fairness while also boosting
prediction accuracy by 15\%.",2024-08-18,"Jiancheng Dong, Lei Jiang, Wei Jin, Lu Cheng",http://arxiv.org/pdf/2408.09327v2,cs.CL
Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks,"Large Language Models (LLMs) have increasingly become pivotal in content
generation with notable societal impact. These models hold the potential to
generate content that could be deemed harmful.Efforts to mitigate this risk
include implementing safeguards to ensure LLMs adhere to social ethics.However,
despite such measures, the phenomenon of ""jailbreaking"" -- where carefully
crafted prompts elicit harmful responses from models -- persists as a
significant challenge. Recognizing the continuous threat posed by jailbreaking
tactics and their repercussions for the trustworthy use of LLMs, a rigorous
assessment of the models' robustness against such attacks is essential. This
study introduces an comprehensive evaluation framework and conducts an
large-scale empirical experiment to address this need. We concentrate on 10
cutting-edge jailbreak strategies across three categories, 1525 questions from
61 specific harmful categories, and 13 popular LLMs. We adopt multi-dimensional
metrics such as Attack Success Rate (ASR), Toxicity Score, Fluency, Token
Length, and Grammatical Errors to thoroughly assess the LLMs' outputs under
jailbreak. By normalizing and aggregating these metrics, we present a detailed
reliability score for different LLMs, coupled with strategic recommendations to
reduce their susceptibility to such vulnerabilities. Additionally, we explore
the relationships among the models, attack strategies, and types of harmful
content, as well as the correlations between the evaluation metrics, which
proves the validity of our multifaceted evaluation framework. Our extensive
experimental results demonstrate a lack of resilience among all tested LLMs
against certain strategies, and highlight the need to concentrate on the
reliability facets of LLMs. We believe our study can provide valuable insights
into enhancing the security evaluation of LLMs against jailbreak within the
domain.",2024-08-18,"Kexin Chen, Yi Liu, Dongxia Wang, Jiaying Chen, Wenhai Wang",http://arxiv.org/pdf/2408.09326v1,cs.CL
An Open-Source American Sign Language Fingerspell Recognition and Semantic Pose Retrieval Interface,"This paper introduces an open-source interface for American Sign Language
fingerspell recognition and semantic pose retrieval, aimed to serve as a
stepping stone towards more advanced sign language translation systems.
Utilizing a combination of convolutional neural networks and pose estimation
models, the interface provides two modular components: a recognition module for
translating ASL fingerspelling into spoken English and a production module for
converting spoken English into ASL pose sequences. The system is designed to be
highly accessible, user-friendly, and capable of functioning in real-time under
varying environmental conditions like backgrounds, lighting, skin tones, and
hand sizes. We discuss the technical details of the model architecture,
application in the wild, as well as potential future enhancements for
real-world consumer applications.",2024-08-17,Kevin Jose Thomas,http://arxiv.org/pdf/2408.09311v1,cs.CL
CyberPal.AI: Empowering LLMs with Expert-Driven Cybersecurity Instructions,"Large Language Models (LLMs) have significantly advanced natural language
processing (NLP), providing versatile capabilities across various applications.
However, their application to complex, domain-specific tasks, such as
cyber-security, often faces substantial challenges. In this study, we introduce
SecKnowledge and CyberPal.AI to address these challenges and train
security-expert LLMs. SecKnowledge is a domain-knowledge-driven cyber-security
instruction dataset, meticulously designed using years of accumulated expert
knowledge in the domain through a multi-phase generation process. CyberPal.AI
refers to a family of LLMs fine-tuned using SecKnowledge, aimed at building
security-specialized LLMs capable of answering and following complex
security-related instructions. Additionally, we introduce SecKnowledge-Eval, a
comprehensive and diverse cyber-security evaluation benchmark, composed of an
extensive set of cyber-security tasks we specifically developed to assess LLMs
in the field of cyber-security, along with other publicly available security
benchmarks. Our results show a significant average improvement of up to 24%
over the baseline models, underscoring the benefits of our expert-driven
instruction dataset generation process. These findings contribute to the
advancement of AI-based cyber-security applications, paving the way for
security-expert LLMs that can enhance threat-hunting and investigation
processes.",2024-08-17,"Matan Levi, Yair Alluouche, Daniel Ohayon, Anton Puzanov",http://arxiv.org/pdf/2408.09304v1,cs.CL
ConVerSum: A Contrastive Learning-based Approach for Data-Scarce Solution of Cross-Lingual Summarization Beyond Direct Equivalents,"Cross-lingual summarization (CLS) is a sophisticated branch in Natural
Language Processing that demands models to accurately translate and summarize
articles from different source languages. Despite the improvement of the
subsequent studies, This area still needs data-efficient solutions along with
effective training methodologies. To the best of our knowledge, there is no
feasible solution for CLS when there is no available high-quality CLS data. In
this paper, we propose a novel data-efficient approach, ConVerSum, for CLS
leveraging the power of contrastive learning, generating versatile candidate
summaries in different languages based on the given source document and
contrasting these summaries with reference summaries concerning the given
documents. After that, we train the model with a contrastive ranking loss.
Then, we rigorously evaluate the proposed approach against current
methodologies and compare it to powerful Large Language Models (LLMs)- Gemini,
GPT 3.5, and GPT 4o proving our model performs better for low-resource
languages' CLS. These findings represent a substantial improvement in the area,
opening the door to more efficient and accurate cross-lingual summarizing
techniques.",2024-08-17,"Sanzana Karim Lora, M. Sohel Rahman, Rifat Shahriyar",http://arxiv.org/pdf/2408.09273v2,cs.CL
How Susceptible are LLMs to Influence in Prompts?,"Large Language Models (LLMs) are highly sensitive to prompts, including
additional context provided therein. As LLMs grow in capability, understanding
their prompt-sensitivity becomes increasingly crucial for ensuring reliable and
robust performance, particularly since evaluating these models becomes more
challenging. In this work, we investigate how current models (Llama, Mixtral,
Falcon) respond when presented with additional input from another model,
mimicking a scenario where a more capable model -- or a system with access to
more external information -- provides supplementary information to the target
model. Across a diverse spectrum of question-answering tasks, we study how an
LLM's response to multiple-choice questions changes when the prompt includes a
prediction and explanation from another model. Specifically, we explore the
influence of the presence of an explanation, the stated authoritativeness of
the source, and the stated confidence of the supplementary input. Our findings
reveal that models are strongly influenced, and when explanations are provided
they are swayed irrespective of the quality of the explanation. The models are
more likely to be swayed if the input is presented as being authoritative or
confident, but the effect is small in size. This study underscores the
significant prompt-sensitivity of LLMs and highlights the potential risks of
incorporating outputs from external sources without thorough scrutiny and
further validation. As LLMs continue to advance, understanding and mitigating
such sensitivities will be crucial for their reliable and trustworthy
deployment.",2024-08-17,"Sotiris Anagnostidis, Jannis Bulian",http://arxiv.org/pdf/2408.11865v1,cs.CL
Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form Text,"The emergence of Large Language Models (LLMs) as chat assistants capable of
generating human-like conversations has amplified the need for robust
evaluation methods, particularly for open-ended tasks. Conventional metrics
like BLEU and ROUGE, while useful, are increasingly inadequate for capturing
the subtle semantics and contextual richness of such generative outputs. We
propose a reference-guided verdict method that automates the evaluation process
by leveraging multiple LLMs-as-judges. Through experiments on three open-ended
question-answering tasks, we demonstrate that combining multiple LLMs-as-judges
significantly improves the reliability and accuracy of evaluations,
particularly in complex tasks where a single model might struggle. Our findings
reveal a strong correlation with human evaluations, establishing our method as
a viable and effective alternative to traditional metrics and human judgments,
particularly in the context of LLM-based chat assistants where the complexity
and diversity of responses challenge existing benchmarks.",2024-08-17,"Sher Badshah, Hassan Sajjad",http://arxiv.org/pdf/2408.09235v2,cs.CL
Unraveling Text Generation in LLMs: A Stochastic Differential Equation Approach,"This paper explores the application of Stochastic Differential Equations
(SDE) to interpret the text generation process of Large Language Models (LLMs)
such as GPT-4. Text generation in LLMs is modeled as a stochastic process where
each step depends on previously generated content and model parameters,
sampling the next word from a vocabulary distribution. We represent this
generation process using SDE to capture both deterministic trends and
stochastic perturbations. The drift term describes the deterministic trends in
the generation process, while the diffusion term captures the stochastic
variations. We fit these functions using neural networks and validate the model
on real-world text corpora. Through numerical simulations and comprehensive
analyses, including drift and diffusion analysis, stochastic process property
evaluation, and phase space exploration, we provide deep insights into the
dynamics of text generation. This approach not only enhances the understanding
of the inner workings of LLMs but also offers a novel mathematical perspective
on language generation, which is crucial for diagnosing, optimizing, and
controlling the quality of generated text.",2024-08-17,Yukun Zhang,http://arxiv.org/pdf/2408.11863v1,cs.CL
Generating Data with Text-to-Speech and Large-Language Models for Conversational Speech Recognition,"Currently, a common approach in many speech processing tasks is to leverage
large scale pre-trained models by fine-tuning them on in-domain data for a
particular application. Yet obtaining even a small amount of such data can be
problematic, especially for sensitive domains and conversational speech
scenarios, due to both privacy issues and annotation costs. To address this,
synthetic data generation using single speaker datasets has been employed. Yet,
for multi-speaker cases, such an approach often requires extensive manual
effort and is prone to domain mismatches. In this work, we propose a synthetic
data generation pipeline for multi-speaker conversational ASR, leveraging a
large language model (LLM) for content creation and a conversational
multi-speaker text-to-speech (TTS) model for speech synthesis. We conduct
evaluation by fine-tuning the Whisper ASR model for telephone and distant
conversational speech settings, using both in-domain data and generated
synthetic data. Our results show that the proposed method is able to
significantly outperform classical multi-speaker generation approaches that use
external, non-conversational speech datasets.",2024-08-17,"Samuele Cornell, Jordan Darefsky, Zhiyao Duan, Shinji Watanabe",http://arxiv.org/pdf/2408.09215v1,cs.CL
Architectural Foundations for the Large Language Model Infrastructures,"The development of a large language model (LLM) infrastructure is a pivotal
undertaking in artificial intelligence. This paper explores the intricate
landscape of LLM infrastructure, software, and data management. By analyzing
these core components, we emphasize the pivotal considerations and safeguards
crucial for successful LLM development. This work presents a concise synthesis
of the challenges and strategies inherent in constructing a robust and
effective LLM infrastructure, offering valuable insights for researchers and
practitioners alike.",2024-08-17,Hongyin Zhu,http://arxiv.org/pdf/2408.09205v2,cs.CL
AI Managed Emergency Documentation with a Pretrained Model,"This study investigates the use of a large language model system to improve
efficiency and quality in emergency department (ED) discharge letter writing.
Time constraints and infrastructural deficits make compliance with current
discharge letter targets difficult. We explored potential efficiencies from an
artificial intelligence software in the generation of ED discharge letters and
the attitudes of doctors toward this technology. The evaluated system leverages
advanced techniques to fine-tune a model to generate discharge summaries from
short-hand inputs, including voice, text, and electronic health record data.
Nineteen physicians with emergency medicine experience evaluated the system
text and voice-to-text interfaces against manual typing. The results showed
significant time savings with MedWrite LLM interfaces compared to manual
methods.",2024-08-17,"David Menzies, Sean Kirwan, Ahmad Albarqawi",http://arxiv.org/pdf/2408.09193v1,cs.CL
Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model,"Metaphors are common in everyday language, and the identification and
understanding of metaphors are facilitated by models to achieve a better
understanding of the text. Metaphors are mainly identified and generated by
pre-trained models in existing research, but situations, where tenors or
vehicles are not included in the metaphor, cannot be handled. The problem can
be effectively solved by using Large Language Models (LLMs), but significant
room for exploration remains in this early-stage research area. A multi-stage
generative heuristic-enhanced prompt framework is proposed in this study to
enhance the ability of LLMs to recognize tenors, vehicles, and grounds in
Chinese metaphors. In the first stage, a small model is trained to obtain the
required confidence score for answer candidate generation. In the second stage,
questions are clustered and sampled according to specific rules. Finally, the
heuristic-enhanced prompt needed is formed by combining the generated answer
candidates and demonstrations. The proposed model achieved 3rd place in Track 1
of Subtask 1, 1st place in Track 2 of Subtask 1, and 1st place in both tracks
of Subtask 2 at the NLPCC-2024 Shared Task 9.",2024-08-17,"Jie Wang, Jin Wang, Xuejie Zhang",http://arxiv.org/pdf/2408.09177v1,cs.CL
Cognitive LLMs: Towards Integrating Cognitive Architectures and Large Language Models for Manufacturing Decision-making,"Resolving the dichotomy between the human-like yet constrained reasoning
processes of Cognitive Architectures and the broad but often noisy inference
behavior of Large Language Models (LLMs) remains a challenging but exciting
pursuit, for enabling reliable machine reasoning capabilities in production
systems. Because Cognitive Architectures are famously developed for the purpose
of modeling the internal mechanisms of human cognitive decision-making at a
computational level, new investigations consider the goal of informing LLMs
with the knowledge necessary for replicating such processes, e.g., guided
perception, memory, goal-setting, and action. Previous approaches that use LLMs
for grounded decision-making struggle with complex reasoning tasks that require
slower, deliberate cognition over fast and intuitive inference -- reporting
issues related to the lack of sufficient grounding, as in hallucination. To
resolve these challenges, we introduce LLM-ACTR, a novel neuro-symbolic
architecture that provides human-aligned and versatile decision-making by
integrating the ACT-R Cognitive Architecture with LLMs. Our framework extracts
and embeds knowledge of ACT-R's internal decision-making process as latent
neural representations, injects this information into trainable LLM adapter
layers, and fine-tunes the LLMs for downstream prediction. Our experiments on
novel Design for Manufacturing tasks show both improved task performance as
well as improved grounded decision-making capability of our approach, compared
to LLM-only baselines that leverage chain-of-thought reasoning strategies.",2024-08-17,"Siyu Wu, Alessandro Oltramari, Jonathan Francis, C. Lee Giles, Frank E. Ritter",http://arxiv.org/pdf/2408.09176v1,cs.CL
TableBench: A Comprehensive and Complex Benchmark for Table Question Answering,"Recent advancements in Large Language Models (LLMs) have markedly enhanced
the interpretation and processing of tabular data, introducing previously
unimaginable capabilities. Despite these achievements, LLMs still encounter
significant challenges when applied in industrial scenarios, particularly due
to the increased complexity of reasoning required with real-world tabular data,
underscoring a notable disparity between academic benchmarks and practical
applications. To address this discrepancy, we conduct a detailed investigation
into the application of tabular data in industrial scenarios and propose a
comprehensive and complex benchmark TableBench, including 18 fields within four
major categories of table question answering (TableQA) capabilities.
Furthermore, we introduce TableLLM, trained on our meticulously constructed
training set TableInstruct, achieving comparable performance with GPT-3.5.
Massive experiments conducted on TableBench indicate that both open-source and
proprietary LLMs still have significant room for improvement to meet real-world
demands, where the most advanced model, GPT-4, achieves only a modest score
compared to humans.",2024-08-17,"Xianjie Wu, Jian Yang, Linzheng Chai, Ge Zhang, Jiaheng Liu, Xinrun Du, Di Liang, Daixin Shu, Xianfu Cheng, Tianzhen Sun, Guanglin Niu, Tongliang Li, Zhoujun Li",http://arxiv.org/pdf/2408.09174v2,cs.CL
Unlocking the Power of LLM Uncertainty for Active In-Context Example Selection,"Large Language Models (LLMs) have shown remarkable performance across a wide
range of downstream tasks. However, it is challenging for users to discern
whether the responses of LLM are generated with certainty or are fabricated to
meet user expectations. In this paper, we introduce Uncertainty Tripartite
Testing Paradigm (Unc-TTP), a novel method for classifying LLM uncertainty by
leveraging output inconsistency. Specifically, Unc-TTP performs three rounds of
sampling under varying label injection interference, enumerating all possible
outcomes, and uses the degree of output inconsistency as the indicator of the
LLM's intrinsic uncertainty. To validate the effectiveness of this
inconsistency-defined uncertainty, we draw inspiration from Active Learning,
comparing the informativeness of actively selected in-context examples. Our
experiments show that uncertainty examples selected via Unc-TTP are more
informative than certainty examples. Furthermore, the Unc-TTP-guided
uncertainty-based active example selection strategy outperforms existing
methods, highlighting its effectiveness in classifying LLM uncertainty and
enhancing in-context learning. This work not only underscores the potential of
inconsistency-based uncertainty classification for both open- and closed-source
LLMs but also presents a practical approach for leveraging uncertainty to
improve LLM performance in real-world tasks.",2024-08-17,"Hsiu-Yuan Huang, Zichen Wu, Yutong Yang, Junzhao Zhang, Yunfang Wu",http://arxiv.org/pdf/2408.09172v4,cs.CL
Automatic Metrics in Natural Language Generation: A Survey of Current Evaluation Practices,"Automatic metrics are extensively used to evaluate natural language
processing systems. However, there has been increasing focus on how they are
used and reported by practitioners within the field. In this paper, we have
conducted a survey on the use of automatic metrics, focusing particularly on
natural language generation (NLG) tasks. We inspect which metrics are used as
well as why they are chosen and how their use is reported. Our findings from
this survey reveal significant shortcomings, including inappropriate metric
usage, lack of implementation details and missing correlations with human
judgements. We conclude with recommendations that we believe authors should
follow to enable more rigour within the field.",2024-08-17,"Patrícia Schmidtová, Saad Mahamood, Simone Balloccu, Ondřej Dušek, Albert Gatt, Dimitra Gkatzia, David M. Howcroft, Ondřej Plátek, Adarsa Sivaprasad",http://arxiv.org/pdf/2408.09169v1,cs.CL
CogLM: Tracking Cognitive Development of Large Language Models,"Piaget's Theory of Cognitive Development (PTC) posits that the development of
cognitive levels forms the foundation for human learning across various
abilities. As Large Language Models (LLMs) have recently shown remarkable
abilities across a wide variety of tasks, we are curious about the cognitive
levels of current LLMs: to what extent they have developed and how this
development has been achieved. To this end, we construct a benchmark CogLM
(Cognitive Ability Evaluation for Language Model) based on PTC to assess the
cognitive levels of LLMs. CogLM comprises 1,220 questions spanning 10 cognitive
abilities crafted by more than 20 human experts, providing a comprehensive
testbed for the cognitive levels of LLMs. Through extensive experiments across
multiple mainstream LLMs with CogLM, we find that: (1) In our testing
framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive
abilities, comparable to those of a 20-year-old human. (2) The parameter size
and optimization objective are two key factors affecting the cognitive levels
of LLMs. (3) The performance on downstream tasks is positively correlated with
the level of cognitive abilities. These findings fill the gap in research on
the cognitive abilities of LLMs, tracing the development of LLMs from a
cognitive perspective and guiding the future direction of their evolution.",2024-08-17,"Xinglin Wang, Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Boyuan Pan, Heda Wang, Yao Hu, Kan Li",http://arxiv.org/pdf/2408.09150v3,cs.CL
Selective Prompt Anchoring for Code Generation,"Recent advances in large language models (LLMs) have transformed software
development by automatically generating code from natural language. Yet
challenges remain in generating fully correct code that aligns with user
intent. Our study reveals that LLMs tend to pay less attention to user prompts
as more code tokens are generated. We hypothesize that this attention dilution
issue is an important reason for code generation errors. To mitigate this
issue, we propose Selective Prompt Anchoring (SPA) to guide code LLMs to pay
more attention to user intent when generating code. We evaluate SPA using six
base LLMs across six benchmarks. Our results demonstrate that SPA enhances
Pass@1 by up to 12.9%, consistently outperforming SOTA code generation methods
in all settings. Our code is available at
https://github.com/magic-YuanTian/Selective-Prompt-Anchoring.",2024-08-17,"Yuan Tian, Tianyi Zhang",http://arxiv.org/pdf/2408.09121v4,cs.CL
Measuring Agreeableness Bias in Multimodal Models,"This paper examines a phenomenon in multimodal language models where
pre-marked options in question images can significantly influence model
responses. Our study employs a systematic methodology to investigate this
effect: we present models with images of multiple-choice questions, which they
initially answer correctly, then expose the same model to versions with
pre-marked options. Our findings reveal a significant shift in the models'
responses towards the pre-marked option, even when it contradicts their answers
in the neutral settings. Comprehensive evaluations demonstrate that this
agreeableness bias is a consistent and quantifiable behavior across various
model architectures. These results show potential limitations in the
reliability of these models when processing images with pre-marked options,
raising important questions about their application in critical decision-making
contexts where such visual cues might be present.",2024-08-17,"Jaehyuk Lim, Bruce W. Lee",http://arxiv.org/pdf/2408.09111v2,cs.CL
Improving Rare Word Translation With Dictionaries and Attention Masking,"In machine translation, rare words continue to be a problem for the dominant
encoder-decoder architecture, especially in low-resource and out-of-domain
translation settings. Human translators solve this problem with monolingual or
bilingual dictionaries. In this paper, we propose appending definitions from a
bilingual dictionary to source sentences and using attention masking to link
together rare words with their definitions. We find that including definitions
for rare words improves performance by up to 1.0 BLEU and 1.6 MacroF1.",2024-08-17,"Kenneth J. Sible, David Chiang",http://arxiv.org/pdf/2408.09075v2,cs.CL
CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code Language Prompts,"Taxonomies play a crucial role in various applications by providing a
structural representation of knowledge. The task of taxonomy expansion involves
integrating emerging concepts into existing taxonomies by identifying
appropriate parent concepts for these new query concepts. Previous approaches
typically relied on self-supervised methods that generate annotation data from
existing taxonomies. However, these methods are less effective when the
existing taxonomy is small (fewer than 100 entities). In this work, we
introduce CodeTaxo, a novel approach that leverages large language models
through code language prompts to capture the taxonomic structure. Extensive
experiments on five real-world benchmarks from different domains demonstrate
that CodeTaxo consistently achieves superior performance across all evaluation
metrics, significantly outperforming previous state-of-the-art methods. The
code and data are available at https://github.com/QingkaiZeng/CodeTaxo-Pub.",2024-08-17,"Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Zhenyu Wu, Shangbin Feng, Meng Jiang",http://arxiv.org/pdf/2408.09070v2,cs.CL
Sentiment analysis of preservice teachers' reflections using a large language model,"In this study, the emotion and tone of preservice teachers' reflections were
analyzed using sentiment analysis with LLMs: GPT-4, Gemini, and BERT. We
compared the results to understand how each tool categorizes and describes
individual reflections and multiple reflections as a whole. This study aims to
explore ways to bridge the gaps between qualitative, quantitative, and
computational analyses of reflective practices in teacher education. This study
finds that to effectively integrate LLM analysis into teacher education,
developing an analysis method and result format that are both comprehensive and
relevant for preservice teachers and teacher educators is crucial.",2024-08-17,"Yunsoo Park, Younkyung Hong",http://arxiv.org/pdf/2408.11862v1,cs.CL
Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models,"Parameter-efficient fine-tuning (PEFT) methods are increasingly used with
pre-trained language models (PLMs) for continual learning (CL). These methods
typically involve training a PEFT module for each new task and employing
similarity-based selection to route modules during inference. However, they
face two major limitations: 1) interference during module training with already
learned modules and 2) suboptimal routing when composing modules. In this
paper, we present L2R, a method that isolates the training of new PEFT modules
to ensure their task specialization. L2R then learns to compose the learned
modules by training a network of routers that leverages a small memory
containing examples of previously seen tasks. We evaluate our method in two CL
setups using various benchmarks. Our results demonstrate that L2R provides an
effective composition of PEFT modules, leading to improved generalization and
performance compared to other methods.",2024-08-16,"Vladimir Araujo, Marie-Francine Moens, Tinne Tuytelaars",http://arxiv.org/pdf/2408.09053v2,cs.CL
When Prompting Fails to Sway: Inertia in Moral and Value Judgments of Large Language Models,"Large Language Models (LLMs) exhibit non-deterministic behavior, and
prompting has emerged as a primary method for steering their outputs toward
desired directions. One popular strategy involves assigning a specific
""persona"" to the model to induce more varied and context-sensitive responses,
akin to the diversity found in human perspectives. However, contrary to the
expectation that persona-based prompting would yield a wide range of opinions,
our experiments demonstrate that LLMs maintain consistent value orientations.
In particular, we observe a persistent inertia in their responses, where
certain moral and value dimensions, especially harm avoidance and fairness,
remain distinctly skewed in one direction despite varied persona settings. To
investigate this phenomenon systematically, use role-play at scale, which
combines randomized, diverse persona prompts with a macroscopic trend analysis
of model outputs. Our findings highlight the strong internal biases and value
preferences in LLMs, underscoring the need for careful scrutiny and potential
adjustment of these models to ensure balanced and equitable applications.",2024-08-16,"Bruce W. Lee, Yeongheon Lee, Hyunsoo Cho",http://arxiv.org/pdf/2408.09049v2,cs.CL
"Improving VTE Identification through Language Models from Radiology Reports: A Comparative Study of Mamba, Phi-3 Mini, and BERT","Venous thromboembolism (VTE) is a critical cardiovascular condition,
encompassing deep vein thrombosis (DVT) and pulmonary embolism (PE). Accurate
and timely identification of VTE is essential for effective medical care. This
study builds upon our previous work, which addressed VTE detection using deep
learning methods for DVT and a hybrid approach combining deep learning and
rule-based classification for PE. Our earlier approaches, while effective, had
two major limitations: they were complex and required expert involvement for
feature engineering of the rule set. To overcome these challenges, we utilize
the Mamba architecture-based classifier. This model achieves remarkable
results, with a 97\% accuracy and F1 score on the DVT dataset and a 98\%
accuracy and F1 score on the PE dataset. In contrast to the previous hybrid
method on PE identification, the Mamba classifier eliminates the need for
hand-engineered rules, significantly reducing model complexity while
maintaining comparable performance. Additionally, we evaluated a lightweight
Large Language Model (LLM), Phi-3 Mini, in detecting VTE. While this model
delivers competitive results, outperforming the baseline BERT models, it proves
to be computationally intensive due to its larger parameter set. Our evaluation
shows that the Mamba-based model demonstrates superior performance and
efficiency in VTE identification, offering an effective solution to the
limitations of previous approaches.",2024-08-16,"Jamie Deng, Yusen Wu, Yelena Yesha, Phuong Nguyen",http://arxiv.org/pdf/2408.09043v1,cs.CL
Studying the Effects of Collaboration in Interactive Theme Discovery Systems,"NLP-assisted solutions have gained considerable traction to support
qualitative data analysis. However, there does not exist a unified evaluation
framework that can account for the many different settings in which qualitative
researchers may employ them. In this paper, we take a first step in this
direction by proposing an evaluation framework to study the way in which
different tools may result in different outcomes depending on the collaboration
strategy employed. Specifically, we study the impact of synchronous vs.
asynchronous collaboration using two different NLP-assisted qualitative
research tools and present a comprehensive analysis of significant differences
in the consistency, cohesiveness, and correctness of their outputs.",2024-08-16,"Alvin Po-Chun Chen, Dananjay Srinivas, Alexandra Barry, Maksim Seniw, Maria Leonor Pacheco",http://arxiv.org/pdf/2408.09030v2,cs.CL
Speaking the Same Language: Leveraging LLMs in Standardizing Clinical Data for AI,"The implementation of Artificial Intelligence (AI) in the healthcare industry
has garnered considerable attention, attributable to its prospective
enhancement of clinical outcomes, expansion of access to superior healthcare,
cost reduction, and elevation of patient satisfaction. Nevertheless, the
primary hurdle that persists is related to the quality of accessible
multi-modal healthcare data in conjunction with the evolution of AI
methodologies. This study delves into the adoption of large language models to
address specific challenges, specifically, the standardization of healthcare
data. We advocate the use of these models to identify and map clinical data
schemas to established data standard attributes, such as the Fast Healthcare
Interoperability Resources. Our results illustrate that employing large
language models significantly diminishes the necessity for manual data curation
and elevates the efficacy of the data standardization process. Consequently,
the proposed methodology has the propensity to expedite the integration of AI
in healthcare, ameliorate the quality of patient care, whilst minimizing the
time and financial resources necessary for the preparation of data for AI.",2024-08-16,"Arindam Sett, Somaye Hashemifar, Mrunal Yadav, Yogesh Pandit, Mohsen Hejrati",http://arxiv.org/pdf/2408.11861v1,cs.CL
Adaptive Uncertainty Quantification for Generative AI,"This work is concerned with conformal prediction in contemporary applications
(including generative AI) where a black-box model has been trained on data that
are not accessible to the user. Mirroring split-conformal inference, we design
a wrapper around a black-box algorithm which calibrates conformity scores. This
calibration is local and proceeds in two stages by first adaptively
partitioning the predictor space into groups and then calibrating sectionally
group by group. Adaptive partitioning (self-grouping) is achieved by fitting a
robust regression tree to the conformity scores on the calibration set. This
new tree variant is designed in such a way that adding a single new observation
does not change the tree fit with overwhelmingly large probability. This
add-one-in robustness property allows us to conclude a finite sample
group-conditional coverage guarantee, a refinement of the marginal guarantee.
In addition, unlike traditional split-conformal inference, adaptive splitting
and within-group calibration yields adaptive bands which can stretch and shrink
locally. We demonstrate benefits of local tightening on several simulated as
well as real examples using non-parametric regression. Finally, we consider two
contemporary classification applications for obtaining uncertainty
quantification around GPT-4o predictions. We conformalize skin disease
diagnoses based on self-reported symptoms as well as predicted states of U.S.
legislators based on summaries of their ideology. We demonstrate substantial
local tightening of the uncertainty sets while attaining similar marginal
coverage.",2024-08-16,"Jungeum Kim, Sean O'Hagan, Veronika Rockova",http://arxiv.org/pdf/2408.08990v2,cs.CL
From Lazy to Prolific: Tackling Missing Labels in Open Vocabulary Extreme Classification by Positive-Unlabeled Sequence Learning,"Open-vocabulary Extreme Multi-label Classification (OXMC) extends traditional
XMC by allowing prediction beyond an extremely large, predefined label set
(typically $10^3$ to $10^{12}$ labels), addressing the dynamic nature of
real-world labeling tasks. However, self-selection bias in data annotation
leads to significant missing labels in both training and test data,
particularly for less popular inputs. This creates two critical challenges:
generation models learn to be ""lazy'"" by under-generating labels, and
evaluation becomes unreliable due to insufficient annotation in the test set.
In this work, we introduce Positive-Unlabeled Sequence Learning (PUSL), which
reframes OXMC as an infinite keyphrase generation task, addressing the
generation model's laziness. Additionally, we propose to adopt a suite of
evaluation metrics, F1@$\mathcal{O}$ and newly proposed B@$k$, to reliably
assess OXMC models with incomplete ground truths. In a highly imbalanced
e-commerce dataset with substantial missing labels, PUSL generates 30% more
unique labels, and 72% of its predictions align with actual user queries. On
the less skewed EURLex-4.3k dataset, PUSL demonstrates superior F1 scores,
especially as label counts increase from 15 to 30. Our approach effectively
tackles both the modeling and evaluation challenges in OXMC with missing
labels.",2024-08-16,"Ranran Haoran Zhang, Bensu Uçar, Soumik Dey, Hansi Wu, Binbin Li, Rui Zhang",http://arxiv.org/pdf/2408.08981v3,cs.CL
See What LLMs Cannot Answer: A Self-Challenge Framework for Uncovering LLM Weaknesses,"The impressive performance of Large Language Models (LLMs) has consistently
surpassed numerous human-designed benchmarks, presenting new challenges in
assessing the shortcomings of LLMs. Designing tasks and finding LLMs'
limitations are becoming increasingly important. In this paper, we investigate
the question of whether an LLM can discover its own limitations from the errors
it makes. To this end, we propose a Self-Challenge evaluation framework with
human-in-the-loop. Starting from seed instances that GPT-4 fails to answer, we
prompt GPT-4 to summarize error patterns that can be used to generate new
instances and incorporate human feedback on them to refine these patterns for
generating more challenging data, iteratively. We end up with 8 diverse
patterns, such as text manipulation and questions with assumptions. We then
build a benchmark, SC-G4, consisting of 1,835 instances generated by GPT-4
using these patterns, with human-annotated gold responses. The SC-G4 serves as
a challenging benchmark that allows for a detailed assessment of LLMs'
abilities. Our results show that only 44.96\% of instances in SC-G4 can be
answered correctly by GPT-4. Interestingly, our pilot study indicates that
these error patterns also challenge other LLMs, such as Claude-3 and Llama-3,
and cannot be fully resolved through fine-tuning. Our work takes the first step
to demonstrate that LLMs can autonomously identify their inherent flaws and
provide insights for future dynamic and automatic evaluation.",2024-08-16,"Yulong Chen, Yang Liu, Jianhao Yan, Xuefeng Bai, Ming Zhong, Yinghao Yang, Ziyi Yang, Chenguang Zhu, Yue Zhang",http://arxiv.org/pdf/2408.08978v2,cs.CL
SEAL: Systematic Error Analysis for Value ALignment,"Reinforcement Learning from Human Feedback (RLHF) aims to align language
models (LMs) with human values by training reward models (RMs) on binary
preferences and using these RMs to fine-tune the base LMs. Despite its
importance, the internal mechanisms of RLHF remain poorly understood. This
paper introduces new metrics to evaluate the effectiveness of modeling and
aligning human values, namely feature imprint, alignment resistance and
alignment robustness. We categorize alignment datasets into target features
(desired values) and spoiler features (undesired concepts). By regressing RM
scores against these features, we quantify the extent to which RMs reward them
- a metric we term feature imprint. We define alignment resistance as the
proportion of the preference dataset where RMs fail to match human preferences,
and we assess alignment robustness by analyzing RM responses to perturbed
inputs. Our experiments, utilizing open-source components like the
Anthropic/hh-rlhf preference dataset and OpenAssistant RMs, reveal significant
imprints of target features and a notable sensitivity to spoiler features. We
observed a 26% incidence of alignment resistance in portions of the dataset
where LM-labelers disagreed with human preferences. Furthermore, we find that
misalignment often arises from ambiguous entries within the alignment dataset.
These findings underscore the importance of scrutinizing both RMs and alignment
datasets for a deeper understanding of value alignment.",2024-08-16,"Manon Revel, Matteo Cargnelutti, Tyna Eloundou, Greg Leppert",http://arxiv.org/pdf/2408.10270v1,cs.CL
A Multi-Task and Multi-Label Classification Model for Implicit Discourse Relation Recognition,"We address the inherent ambiguity in Implicit Discourse Relation Recognition
(IDRR) by introducing a novel multi-task classification model capable of
learning both multi-label and single-label representations of discourse
relations. Our model is trained exclusively on the DiscoGeM corpus and
evaluated both on the DiscoGeM and the PDTB 3.0 corpus. We establish the first
benchmark on multi-label IDRR classification and achieve SOTA results on
single-label IDRR classification using the DiscoGeM corpus. Finally, we present
the first evaluation on the potential of transfer learning between the DiscoGeM
and the PDTB 3.0 corpus on single-label IDRR classification.",2024-08-16,"Nelson Filipe Costa, Leila Kosseim",http://arxiv.org/pdf/2408.08971v2,cs.CL
BnSentMix: A Diverse Bengali-English Code-Mixed Dataset for Sentiment Analysis,"The widespread availability of code-mixed data can provide valuable insights
into low-resource languages like Bengali, which have limited datasets.
Sentiment analysis has been a fundamental text classification task across
several languages for code-mixed data. However, there has yet to be a
large-scale and diverse sentiment analysis dataset on code-mixed Bengali. We
address this limitation by introducing BnSentMix, a sentiment analysis dataset
on code-mixed Bengali consisting of 20,000 samples with 4 sentiment labels from
Facebook, YouTube, and e-commerce sites. We ensure diversity in data sources to
replicate realistic code-mixed scenarios. Additionally, we propose 14 baseline
methods including novel transformer encoders further pre-trained on code-mixed
Bengali-English, achieving an overall accuracy of 69.8% and an F1 score of
69.1% on sentiment classification tasks. Detailed analyses reveal variations in
performance across different sentiment labels and text types, highlighting
areas for future improvement.",2024-08-16,"Sadia Alam, Md Farhan Ishmam, Navid Hasin Alvee, Md Shahnewaz Siddique, Md Azam Hossain, Abu Raihan Mostofa Kamal",http://arxiv.org/pdf/2408.08964v3,cs.CL
Trust-Oriented Adaptive Guardrails for Large Language Models,"Guardrail, an emerging mechanism designed to ensure that large language
models (LLMs) align with human values by moderating harmful or toxic responses,
requires a sociotechnical approach in their design. This paper addresses a
critical issue: existing guardrails lack a well-founded methodology to
accommodate the diverse needs of different user groups, particularly concerning
access rights. Supported by trust modeling (primarily on `social' aspect) and
enhanced with online in-context learning via retrieval-augmented generation (on
`technical' aspect), we introduce an adaptive guardrail mechanism, to
dynamically moderate access to sensitive content based on user trust metrics.
User trust metrics, defined as a novel combination of direct interaction trust
and authority-verified trust, enable the system to precisely tailor the
strictness of content moderation by aligning with the user's credibility and
the specific context of their inquiries. Our empirical evaluation demonstrates
the effectiveness of the adaptive guardrail in meeting diverse user needs,
outperforming existing guardrails while securing sensitive information and
precisely managing potentially hazardous content through a context-aware
knowledge base. To the best of our knowledge, this work is the first to
introduce trust-oriented concept into a guardrail system, offering a scalable
solution that enriches the discourse on ethical deployment for next-generation
LLM service.",2024-08-16,"Jinwei Hu, Yi Dong, Xiaowei Huang",http://arxiv.org/pdf/2408.08959v2,cs.CL
xGen-MM (BLIP-3): A Family of Open Large Multimodal Models,"This report introduces xGen-MM (also known as BLIP-3), a framework for
developing Large Multimodal Models (LMMs). The framework comprises meticulously
curated datasets, a training recipe, model architectures, and a resulting suite
of LMMs. xGen-MM, short for xGen-MultiModal, expands the Salesforce xGen
initiative on foundation AI models. Our models undergo rigorous evaluation
across a range of tasks, including both single and multi-image benchmarks. Our
pre-trained base model exhibits strong in-context learning capabilities and the
instruction-tuned model demonstrates competitive performance among open-source
LMMs with similar model sizes. In addition, we introduce a safety-tuned model
with DPO, aiming to mitigate harmful behaviors such as hallucinations and
improve safety. We open-source our models, curated large-scale datasets, and
our fine-tuning codebase to facilitate further advancements in LMM research.
Associated resources will be available on our project page above.",2024-08-16,"Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael S Ryoo, Shrikant Kendre, Jieyu Zhang, Can Qin, Shu Zhang, Chia-Chih Chen, Ning Yu, Juntao Tan, Tulika Manoj Awalgaonkar, Shelby Heinecke, Huan Wang, Yejin Choi, Ludwig Schmidt, Zeyuan Chen, Silvio Savarese, Juan Carlos Niebles, Caiming Xiong, Ran Xu",http://arxiv.org/pdf/2408.08872v2,cs.CL
PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars,"Self-ensembling techniques with diverse reasoning paths such as
Self-Consistency have demonstrated remarkable performance gains in text
generation with Large Language Models (LLMs). However, such techniques depend
on the availability of an accurate answer extraction process to aggregate
across multiple outputs. Moreover, they acquire higher inference cost, in
comparison to Greedy Decoding, due to generation of relatively higher number of
output tokens. Research has shown that the free form text outputs from
Self-Consistency can be aggregated reliably using LLMs to produce the final
output. Additionally, recent advancements in LLM inference have demonstrated
that usage of diverse exemplars in prompts have the ability to induce diversity
in the LLM outputs. Such proven techniques can be easily extended to
self-ensembling based approaches to achieve enhanced results in text
generation. In this paper, we introduce PEDAL (Prompts based on Exemplar
Diversity Aggregated using LLMs), a hybrid self-ensembling approach, that
combines the strengths of diverse exemplar based prompts and LLM based
aggregation to achieve improvement in overall performance. On the publicly
available SVAMP and ARC datasets, our experiments reveal that PEDAL can achieve
better accuracy than Greedy Decoding based strategies with lower inference cost
compared to Self Consistency based approaches.",2024-08-16,Sumanth Prabhu,http://arxiv.org/pdf/2408.08869v2,cs.CL
Risks and NLP Design: A Case Study on Procedural Document QA,"As NLP systems are increasingly deployed at scale, concerns about their
potential negative impacts have attracted the attention of the research
community, yet discussions of risk have mostly been at an abstract level and
focused on generic AI or NLP applications. We argue that clearer assessments of
risks and harms to users--and concrete strategies to mitigate them--will be
possible when we specialize the analysis to more concrete applications and
their plausible users. As an illustration, this paper is grounded in cooking
recipe procedural document question answering (ProcDocQA), where there are
well-defined risks to users such as injuries or allergic reactions. Our case
study shows that an existing language model, applied in ""zero-shot"" mode,
quantitatively answers real-world questions about recipes as well or better
than the humans who have answered the questions on the web. Using a novel
questionnaire informed by theoretical work on AI risk, we conduct a
risk-oriented error analysis that could then inform the design of a future
system to be deployed with lower risk of harm and better performance.",2024-08-16,"Nikita Haduong, Alice Gao, Noah A. Smith",http://arxiv.org/pdf/2408.11860v1,cs.CL
PsychoLex: Unveiling the Psychological Mind of Large Language Models,"This paper explores the intersection of psychology and artificial
intelligence through the development and evaluation of specialized Large
Language Models (LLMs). We introduce PsychoLex, a suite of resources designed
to enhance LLMs' proficiency in psychological tasks in both Persian and
English. Key contributions include the PsychoLexQA dataset for instructional
content and the PsychoLexEval dataset for rigorous evaluation of LLMs in
complex psychological scenarios. Additionally, we present the PsychoLexLLaMA
model, optimized specifically for psychological applications, demonstrating
superior performance compared to general-purpose models. The findings
underscore the potential of tailored LLMs for advancing psychological research
and applications, while also highlighting areas for further refinement. This
research offers a foundational step towards integrating LLMs into specialized
psychological domains, with implications for future advancements in AI-driven
psychological practice.",2024-08-16,"Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Hassan Naderi",http://arxiv.org/pdf/2408.08848v1,cs.CL
FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats,"The table reasoning task aims to answer the question according to the given
table. Currently, using Large Language Models (LLMs) is the predominant method
for table reasoning. Most existing methods employ a fixed tabular format to
represent the table, which could limit the performance. Given that each
instance requires different capabilities and models possess varying abilities,
we assert that different instances and models suit different tabular formats.
We prove the aforementioned claim through quantitative analysis of experimental
results, where different instances and models achieve different performances
using various tabular formats. Building on this discussion, we propose
FLEXTAF-Single and FLEXTAF-Vote to enhance table reasoning performance by
employing flexible tabular formats. Specifically, (i) FLEXTAF-Single trains a
classifier to predict the most suitable tabular format based on the instance
and the LLM. (ii) FLEXTAF-Vote integrates the results across different formats.
Our experiments on WikiTableQuestions and TabFact reveal significant
improvements, with average gains of 2.3% and 4.8% compared to the best
performance achieved using a fixed tabular format with greedy decoding and
self-consistency decoding, thereby validating the effectiveness of our methods.",2024-08-16,"Xuanliang Zhang, Dingzirui Wang, Longxu Dou, Baoxin Wang, Dayong Wu, Qingfu Zhu, Wanxiang Che",http://arxiv.org/pdf/2408.08841v2,cs.CL
CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems,"In this study, we introduce CIKMar, an efficient approach to educational
dialogue systems powered by the Gemma Language model. By leveraging a
Dual-Encoder ranking system that incorporates both BERT and SBERT model, we
have designed CIKMar to deliver highly relevant and accurate responses, even
with the constraints of a smaller language model size. Our evaluation reveals
that CIKMar achieves a robust recall and F1-score of 0.70 using BERTScore
metrics. However, we have identified a significant challenge: the Dual-Encoder
tends to prioritize theoretical responses over practical ones. These findings
underscore the potential of compact and efficient models like Gemma in
democratizing access to advanced educational AI systems, ensuring effective and
contextually appropriate responses.",2024-08-16,"Joanito Agili Lopo, Marina Indah Prasasti, Alma Permatasari",http://arxiv.org/pdf/2408.08805v1,cs.CL
FourierKAN outperforms MLP on Text Classification Head Fine-tuning,"In resource constraint settings, adaptation to downstream classification
tasks involves fine-tuning the final layer of a classifier (i.e. classification
head) while keeping rest of the model weights frozen. Multi-Layer Perceptron
(MLP) heads fine-tuned with pre-trained transformer backbones have long been
the de facto standard for text classification head fine-tuning. However, the
fixed non-linearity of MLPs often struggles to fully capture the nuances of
contextual embeddings produced by pre-trained models, while also being
computationally expensive. In our work, we investigate the efficacy of KAN and
its variant, Fourier KAN (FR-KAN), as alternative text classification heads.
Our experiments reveal that FR-KAN significantly outperforms MLPs with an
average improvement of 10% in accuracy and 11% in F1-score across seven
pre-trained transformer models and four text classification tasks. Beyond
performance gains, FR-KAN is more computationally efficient and trains faster
with fewer parameters. These results underscore the potential of FR-KAN to
serve as a lightweight classification head, with broader implications for
advancing other Natural Language Processing (NLP) tasks.",2024-08-16,"Abdullah Al Imran, Md Farhan Ishmam",http://arxiv.org/pdf/2408.08803v2,cs.CL
EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics,"Designing emotionally intelligent conversational systems to provide comfort
and advice to people experiencing distress is a compelling area of research.
Recently, with advancements in large language models (LLMs), end-to-end
dialogue agents without explicit strategy prediction steps have become
prevalent. However, implicit strategy planning lacks transparency, and recent
studies show that LLMs' inherent preference bias towards certain
socio-emotional strategies hinders the delivery of high-quality emotional
support. To address this challenge, we propose decoupling strategy prediction
from language generation, and introduce a novel dialogue strategy prediction
framework, EmoDynamiX, which models the discourse dynamics between user
fine-grained emotions and system strategies using a heterogeneous graph for
better performance and transparency. Experimental results on two ESC datasets
show EmoDynamiX outperforms previous state-of-the-art methods with a
significant margin (better proficiency and lower preference bias). Our approach
also exhibits better transparency by allowing backtracing of decision making.",2024-08-16,"Chenwei Wan, Matthieu Labeau, Chloé Clavel",http://arxiv.org/pdf/2408.08782v4,cs.CL
Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions,"LLMs-as-a-judge is a recently popularized method which replaces human
judgements in task evaluation (Zheng et al. 2024) with automatic evaluation
using LLMs. Due to widespread use of RLHF (Reinforcement Learning from Human
Feedback), state-of-the-art LLMs like GPT4 and Llama3 are expected to have
strong alignment with human preferences when prompted for a quality judgement,
such as the coherence of a text. While this seems beneficial, it is not clear
whether the assessments by an LLM-as-a-judge constitute only an evaluation
based on the instructions in the prompts, or reflect its preference for
high-quality data similar to its fine-tune data. To investigate how much
influence prompting the LLMs-as-a-judge has on the alignment of AI judgements
to human judgements, we analyze prompts with increasing levels of instructions
about the target quality of an evaluation, for several LLMs-as-a-judge.
Further, we compare to a prompt-free method using model perplexity as a quality
measure instead. We aggregate a taxonomy of quality criteria commonly used
across state-of-the-art evaluations with LLMs and provide this as a rigorous
benchmark of models as judges. Overall, we show that the LLMs-as-a-judge
benefit only little from highly detailed instructions in prompts and that
perplexity can sometimes align better with human judgements than prompting,
especially on textual quality.",2024-08-16,"Bhuvanashree Murugadoss, Christian Poelitz, Ian Drosos, Vu Le, Nick McKenna, Carina Suzana Negreanu, Chris Parnin, Advait Sarkar",http://arxiv.org/pdf/2408.08781v1,cs.CL
Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions,"With the help of in-context learning (ICL), large language models (LLMs) have
achieved impressive performance across various tasks. However, the function of
descriptive instructions during ICL remains under-explored. In this work, we
propose an ensemble prompt framework to describe the selection criteria of
multiple in-context examples, and preliminary experiments on machine
translation (MT) across six translation directions confirm that this framework
boosts ICL performance. But to our surprise, LLMs might not care what the
descriptions actually say, and the performance gain is primarily caused by the
ensemble format, since it could lead to improvement even with random
descriptive nouns. We further apply this new ensemble framework on a range of
commonsense, math, logical reasoning and hallucination tasks with three LLMs
and achieve promising results, suggesting again that designing a proper prompt
format would be much more effective and efficient than paying effort into
specific descriptions. Our code will be publicly available once this paper is
published.",2024-08-16,"Chenming Tang, Zhixiang Wang, Hao Sun, Yunfang Wu",http://arxiv.org/pdf/2408.08780v5,cs.CL
DAC: Decomposed Automation Correction for Text-to-SQL,"Text-to-SQL is an important task that helps people obtain information from
databases by automatically generating SQL queries. Considering the brilliant
performance, approaches based on Large Language Models (LLMs) become the
mainstream for text-to-SQL. Among these approaches, automated correction is an
effective approach that further enhances performance by correcting the mistakes
in the generated results. The existing correction methods require LLMs to
directly correct with generated SQL, while previous research shows that LLMs do
not know how to detect mistakes, leading to poor performance. Therefore, in
this paper, we propose to employ the decomposed correction to enhance
text-to-SQL performance. We first demonstrate that decomposed correction
outperforms direct correction since detecting and fixing mistakes with the
results of the decomposed sub-tasks is easier than with SQL. Based on this
analysis, we introduce Decomposed Automation Correction (DAC), which corrects
SQL by decomposing text-to-SQL into entity linking and skeleton parsing. DAC
first generates the entity and skeleton corresponding to the question and then
compares the differences between the initial SQL and the generated entities and
skeleton as feedback for correction. Experimental results show that our method
improves performance by $3.7\%$ on average of Spider, Bird, and KaggleDBQA
compared with the baseline method, demonstrating the effectiveness of DAC.",2024-08-16,"Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, Wanxiang Che",http://arxiv.org/pdf/2408.08779v2,cs.CL
Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused,"Large Language Models (LLMs) have demonstrated exceptional performance across
various natural language processing tasks, yet they occasionally tend to yield
content that factually inaccurate or discordant with the expected output, a
phenomenon empirically referred to as ""hallucination"". To tackle this issue,
recent works have investigated contrastive decoding between the original model
and an amateur model with induced hallucination, which has shown promising
results. Nonetheless, this method may undermine the output distribution of the
original LLM caused by its coarse contrast and simplistic subtraction
operation, potentially leading to errors in certain cases. In this paper, we
introduce a novel contrastive decoding framework termed LOL (LOwer Layer
Matters). Our approach involves concatenating the contrastive decoding of both
the final and lower layers between the original model and the amateur model,
thereby achieving multi-layer fusion to aid in the mitigation of hallucination.
Additionally, we incorporate a truthfulness refocused module that leverages
contextual guidance to enhance factual encoding, further capturing truthfulness
during contrastive decoding. Extensive experiments conducted on two publicly
available datasets illustrate that our proposed LOL framework can substantially
alleviate hallucination while surpassing existing baselines in most cases.
Compared with the best baseline, we improve by average 4.5 points on all
metrics of TruthfulQA. The source code is coming soon.",2024-08-16,"Dingwei Chen, Feiteng Fang, Shiwen Ni, Feng Liang, Ruifeng Xu, Min Yang, Chengming Li",http://arxiv.org/pdf/2408.08769v1,cs.CL
ConcateNet: Dialogue Separation Using Local And Global Feature Concatenation,"Dialogue separation involves isolating a dialogue signal from a mixture, such
as a movie or a TV program. This can be a necessary step to enable dialogue
enhancement for broadcast-related applications. In this paper, ConcateNet for
dialogue separation is proposed, which is based on a novel approach for
processing local and global features aimed at better generalization for
out-of-domain signals. ConcateNet is trained using a noise reduction-focused,
publicly available dataset and evaluated using three datasets: two noise
reduction-focused datasets (in-domain), which show competitive performance for
ConcateNet, and a broadcast-focused dataset (out-of-domain), which verifies the
better generalization performance for the proposed architecture compared to
considered state-of-the-art noise-reduction methods.",2024-08-16,"Mhd Modar Halimeh, Matteo Torcoli, Emanuël Habets",http://arxiv.org/pdf/2408.08729v1,cs.CL
ChatZero:Zero-shot Cross-Lingual Dialogue Generation via Pseudo-Target Language,"Although large language models(LLMs) show amazing capabilities, among various
exciting applications discovered for LLMs fall short in other low-resource
languages. Besides, most existing methods depend on large-scale dialogue
corpora and thus building systems for dialogue generation in a zero-shot
scenario remains a considerable challenge. To address this challenge, we
propose a novel end-to-end zero-shot dialogue generation model ChatZero based
on cross-lingual code-switching method. First, we construct code-switching
language and pseudo-target language with placeholders. Then for cross-lingual
semantic transfer, we employ unsupervised contrastive learning to minimize the
semantics gap of the source language, code-switching language, and
pseudo-target language that are mutually positive examples in the high
dimensional semantic space. Experiments on the multilingual DailyDialog and
DSTC7-AVSD datasets demonstrate that ChatZero can achieve more than 90\% of the
original performance under the zero-shot case compared to supervised learning,
and achieve state-of-the-art performance compared with other baselines.",2024-08-16,"Yongkang Liu, Feng Shi, Daling Wang, Yifei Zhang, Hinrich Schütze",http://arxiv.org/pdf/2408.08724v1,cs.CL
Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling,"Massive parameters of LLMs have made inference latency a fundamental
bottleneck. Speculative decoding represents a lossless approach to accelerate
inference through a guess-and-verify paradigm. Some methods rely on additional
architectures to guess draft tokens, which need extra training before use.
Alternatively, retrieval-based training-free techniques build libraries from
pre-existing corpora or by n-gram generation. However, they face challenges
like large storage requirements, time-consuming retrieval, and limited
adaptability. Observing that candidate tokens generated during the decoding
process are likely to reoccur in future sequences, we propose Token Recycling.
It stores candidate tokens in an adjacency matrix and employs a
breadth-first-search (BFS)-like algorithm to construct a draft tree, which is
then validated through tree attention. New candidate tokens from the decoding
process are then used to update the matrix. Token Recycling requires
\textless2MB of additional storage and achieves approximately 2x speedup across
all sizes of LLMs. It significantly outperforms existing train-free methods by
30\% and even a widely recognized training method by 25\%.",2024-08-16,"Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu",http://arxiv.org/pdf/2408.08696v3,cs.CL
Quantifying the Effectiveness of Student Organization Activities using Natural Language Processing,"Student extracurricular activities play an important role in enriching the
students' educational experiences. With the increasing popularity of Machine
Learning and Natural Language Processing, it becomes a logical step that
incorporating ML-NLP in improving extracurricular activities is a potential
focus of study in Artificial Intelligence (AI). This research study aims to
develop a machine learning workflow that will quantify the effectiveness of
student-organized activities based on student emotional responses using
sentiment analysis. The study uses the Bidirectional Encoder Representations
from Transformers (BERT) Large Language Model (LLM) called via the
pysentimiento toolkit, as a Transformer pipeline in Hugging Face. A sample data
set from Organization C, a Recognized Student Organization (RSO) of a higher
educational institute in the Philippines, College X, was used to develop the
workflow. The workflow consisted of data preprocessing, key feature selection,
LLM feature processing, and score aggregation, resulting in an Event Score for
each data set. The results show that the BERT LLM can also be used effectively
in analyzing sentiment beyond product reviews and post comments. For the
student affairs offices of educational institutions, this study can provide a
practical example of how NLP can be applied to real-world scenarios, showcasing
the potential impact of data-driven decision making.",2024-08-16,"Lyberius Ennio F. Taruc, Arvin R. De La Cruz",http://arxiv.org/pdf/2408.08694v1,cs.CL
Med-PMC: Medical Personalized Multi-modal Consultation with a Proactive Ask-First-Observe-Next Paradigm,"The application of the Multi-modal Large Language Models (MLLMs) in medical
clinical scenarios remains underexplored. Previous benchmarks only focus on the
capacity of the MLLMs in medical visual question-answering (VQA) or report
generation and fail to assess the performance of the MLLMs on complex clinical
multi-modal tasks. In this paper, we propose a novel Medical Personalized
Multi-modal Consultation (Med-PMC) paradigm to evaluate the clinical capacity
of the MLLMs. Med-PMC builds a simulated clinical environment where the MLLMs
are required to interact with a patient simulator to complete the multi-modal
information-gathering and decision-making task. Specifically, the patient
simulator is decorated with personalized actors to simulate diverse patients in
real scenarios. We conduct extensive experiments to access 12 types of MLLMs,
providing a comprehensive view of the MLLMs' clinical performance. We found
that current MLLMs fail to gather multimodal information and show potential
bias in the decision-making task when consulted with the personalized patient
simulators. Further analysis demonstrates the effectiveness of Med-PMC, showing
the potential to guide the development of robust and reliable clinical MLLMs.
Code and data are available at https://github.com/LiuHC0428/Med-PMC.",2024-08-16,"Hongcheng Liu, Yusheng Liao, Siqv Ou, Yuhao Wang, Heyang Liu, Yanfeng Wang, Yu Wang",http://arxiv.org/pdf/2408.08693v1,cs.CL
The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation,"This paper presents a novel methodology for generating synthetic Preference
Optimization (PO) datasets using multi-agent workflows. We evaluate the
effectiveness and potential of these workflows in automating and enhancing the
dataset generation process. PO dataset generation requires two modules: (1)
response evaluation, and (2) response generation. In the response evaluation
module, the responses from Large Language Models (LLMs) are evaluated and
ranked - a task typically carried out by human annotators that we automate
using LLMs. We assess the response evaluation module in a 2 step process. In
step 1, we assess LLMs as evaluators using three distinct prompting strategies.
In step 2, we apply the winning prompting strategy to compare the performance
of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. Our evaluation shows that
GPT-4o-as-a-Judge is more consistent across all datasets. For the response
generation module, we use the identified LLM evaluator configuration and
compare different configurations of the LLM Feedback Loop. We use the win rate
to determine the best multi-agent configuration for generation. Experimenting
with various configurations, we find that the LLM Feedback Loop, with Llama as
the generator and Gemma as the reviewer, achieves a notable 71.8% and 73.8% win
rate over single-agent Llama and Gemma, respectively. After identifying the
best configurations for both modules, we generate our PO datasets using the
above pipeline.",2024-08-16,"Samee Arif, Sualeha Farid, Abdul Hameed Azeemi, Awais Athar, Agha Ali Raza",http://arxiv.org/pdf/2408.08688v4,cs.CL
LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression,"The key to effective point cloud compression is to obtain a robust context
model consistent with complex 3D data structures. Recently, the advancement of
large language models (LLMs) has highlighted their capabilities not only as
powerful generators for in-context learning and generation but also as
effective compressors. These dual attributes of LLMs make them particularly
well-suited to meet the demands of data compression. Therefore, this paper
explores the potential of using LLM for compression tasks, focusing on lossless
point cloud geometry compression (PCGC) experiments. However, applying LLM
directly to PCGC tasks presents some significant challenges, i.e., LLM does not
understand the structure of the point cloud well, and it is a difficult task to
fill the gap between text and point cloud through text description, especially
for large complicated and small shapeless point clouds. To address these
problems, we introduce a novel architecture, namely the Large Language
Model-based Point Cloud Geometry Compression (LLM-PCGC) method, using LLM to
compress point cloud geometry information without any text description or
aligning operation. By utilizing different adaptation techniques for
cross-modality representation alignment and semantic consistency, including
clustering, K-tree, token mapping invariance, and Low Rank Adaptation (LoRA),
the proposed method can translate LLM to a compressor/generator for point
cloud. To the best of our knowledge, this is the first structure to employ LLM
as a compressor for point cloud data. Experiments demonstrate that the LLM-PCGC
outperforms the other existing methods significantly, by achieving -40.213% bit
rate reduction compared to the reference software of MPEG Geometry-based Point
Cloud Compression (G-PCC) standard, and by achieving -2.267% bit rate reduction
compared to the state-of-the-art learning-based method.",2024-08-16,"Yuqi Ye, Wei Gao",http://arxiv.org/pdf/2408.08682v1,cs.CL
MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector,"The increasing parameters and expansive dataset of large language models
(LLMs) highlight the urgent demand for a technical solution to audit the
underlying privacy risks and copyright issues associated with LLMs. Existing
studies have partially addressed this need through an exploration of the
pre-training data detection problem, which is an instance of a membership
inference attack (MIA). This problem involves determining whether a given piece
of text has been used during the pre-training phase of the target LLM. Although
existing methods have designed various sophisticated MIA score functions to
achieve considerable detection performance in pre-trained LLMs, how to achieve
high-confidence detection and how to perform MIA on aligned LLMs remain
challenging. In this paper, we propose MIA-Tuner, a novel instruction-based MIA
method, which instructs LLMs themselves to serve as a more precise pre-training
data detector internally, rather than design an external MIA score function.
Furthermore, we design two instruction-based safeguards to respectively
mitigate the privacy risks brought by the existing methods and MIA-Tuner. To
comprehensively evaluate the most recent state-of-the-art LLMs, we collect a
more up-to-date MIA benchmark dataset, named WIKIMIA-24, to replace the widely
adopted benchmark WIKIMIA. We conduct extensive experiments across various
aligned and unaligned LLMs over the two benchmark datasets. The results
demonstrate that MIA-Tuner increases the AUC of MIAs from 0.7 to a
significantly high level of 0.9.",2024-08-16,"Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang",http://arxiv.org/pdf/2408.08661v1,cs.CL
LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs,"We present the first systematic evaluation examining format bias in
performance of large language models (LLMs). Our approach distinguishes between
two categories of an evaluation metric under format constraints to reliably and
accurately assess performance: one measures performance when format constraints
are adhered to, while the other evaluates performance regardless of constraint
adherence. We then define a metric for measuring the format bias of LLMs and
establish effective strategies to reduce it. Subsequently, we present our
empirical format bias evaluation spanning four commonly used categories --
multiple-choice question-answer, wrapping, list, and mapping -- covering 15
widely-used formats. Our evaluation on eight generation tasks uncovers
significant format bias across state-of-the-art LLMs. We further discover that
improving the format-instruction following capabilities of LLMs across formats
potentially reduces format bias. Based on our evaluation findings, we study
prompting and fine-tuning with synthesized format data techniques to mitigate
format bias. Our methods successfully reduce the variance in ChatGPT's
performance among wrapping formats from 235.33 to 0.71 (%$^2$).",2024-08-16,"Do Xuan Long, Hai Nguyen Ngoc, Tiviatis Sim, Hieu Dao, Shafiq Joty, Kenji Kawaguchi, Nancy F. Chen, Min-Yen Kan",http://arxiv.org/pdf/2408.08656v2,cs.CL
Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning,"Language models are known to absorb biases from their training data, leading
to predictions driven by statistical regularities rather than semantic
relevance. We investigate the impact of these biases on answer choice
preferences in the Massive Multi-Task Language Understanding (MMLU) task. Our
findings reveal that differences in learned regularities across answer options
are predictive of model preferences and mirror human test-taking strategies. To
address this issue, we introduce two novel methods: Counterfactual Prompting
with Chain of Thought (CoT) and Counterfactual Prompting with Agnostically
Primed CoT (APriCoT). We demonstrate that while Counterfactual Prompting with
CoT alone is insufficient to mitigate bias, our novel Primed Counterfactual
Prompting with CoT approach effectively reduces the influence of base-rate
probabilities while improving overall accuracy. Our results suggest that
mitigating bias requires a ""System-2"" like process and that CoT reasoning is
susceptible to confirmation bias under some prompting methodologies. Our
contributions offer practical solutions for developing more robust and fair
language models.",2024-08-16,"Kyle Moore, Jesse Roberts, Thao Pham, Douglas Fisher",http://arxiv.org/pdf/2408.08651v2,cs.CL
An End-to-End Model for Photo-Sharing Multi-modal Dialogue Generation,"Photo-Sharing Multi-modal dialogue generation requires a dialogue agent not
only to generate text responses but also to share photos at the proper moment.
Using image text caption as the bridge, a pipeline model integrates an image
caption model, a text generation model, and an image generation model to handle
this complex multi-modal task. However, representing the images with text
captions may loss important visual details and information and cause error
propagation in the complex dialogue system. Besides, the pipeline model
isolates the three models separately because discrete image text captions
hinder end-to-end gradient propagation. We propose the first end-to-end model
for photo-sharing multi-modal dialogue generation, which integrates an image
perceptron and an image generator with a large language model. The large
language model employs the Q-Former to perceive visual images in the input end.
For image generation in the output end, we propose a dynamic vocabulary
transformation matrix and use straight-through and gumbel-softmax techniques to
align the large language model and stable diffusion model and achieve
end-to-end gradient propagation. We perform experiments on PhotoChat and
DialogCC datasets to evaluate our end-to-end model. Compared with pipeline
models, the end-to-end model gains state-of-the-art performances on various
metrics of text and image generation. More analysis experiments also verify the
effectiveness of the end-to-end model for photo-sharing multi-modal dialogue
generation.",2024-08-16,"Peiming Guo, Sinuo Liu, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang",http://arxiv.org/pdf/2408.08650v2,cs.CL
Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation,"Argument mining is natural language processing technology aimed at
identifying arguments in text. Furthermore, the approach is being developed to
identify the premises and claims of those arguments, and to identify the
relationships between arguments including support and attack relationships. In
this paper, we assume that an argument map contains the premises and claims of
arguments, and support and attack relationships between them, that have been
identified by argument mining. So from a piece of text, we assume an argument
map is obtained automatically by natural language processing. However, to
understand and to automatically analyse that argument map, it would be
desirable to instantiate that argument map with logical arguments. Once we have
the logical representation of the arguments in an argument map, we can use
automated reasoning to analyze the argumentation (e.g. check consistency of
premises, check validity of claims, and check the labelling on each arc
corresponds with thw logical arguments). We address this need by using
classical logic for representing the explicit information in the text, and
using default logic for representing the implicit information in the text. In
order to investigate our proposal, we consider some specific options for
instantiation.",2024-08-16,"Jonathan Ben-Naim, Victor David, Anthony Hunter",http://arxiv.org/pdf/2408.08648v1,cs.CL
Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning,"Multimodal Large Language Models (MLLMs) excel in solving text-based
mathematical problems, but they struggle with mathematical diagrams since they
are primarily trained on natural scene images. For humans, visual aids
generally enhance problem-solving, but MLLMs perform worse as information
shifts from textual to visual modality. This decline is mainly due to their
shortcomings in aligning images and text. To tackle aforementioned challenges,
we propose Math-PUMA, a methodology focused on Progressive Upward Multimodal
Alignment. This approach is designed to improve the mathematical reasoning
skills of MLLMs through a three-stage training process, with the second stage
being the critical alignment stage. We first enhance the language model's
mathematical reasoning capabilities with extensive set of textual mathematical
problems. We then construct a multimodal dataset with varying degrees of
textual and visual information, creating data pairs by presenting each problem
in at least two forms. By leveraging the Kullback-Leibler (KL) divergence of
next-token prediction distributions to align visual and textual modalities,
consistent problem-solving abilities are ensured. Finally, we utilize
multimodal instruction tuning for MLLMs with high-quality multimodal data.
Experimental results on multiple mathematical reasoning benchmarks demonstrate
that the MLLMs trained with Math-PUMA surpass most open-source MLLMs. Our
approach effectively narrows the performance gap for problems presented in
different modalities. The code and data are available at:
\url{https://github.com/wwzhuang01/Math-PUMA}.",2024-08-16,"Wenwen Zhuang, Xin Huang, Xiantao Zhang, Jin Zeng",http://arxiv.org/pdf/2408.08640v2,cs.CL
A Survey on Benchmarks of Multimodal Large Language Models,"Multimodal Large Language Models (MLLMs) are gaining increasing popularity in
both academia and industry due to their remarkable performance in various
applications such as visual question answering, visual perception,
understanding, and reasoning. Over the past few years, significant efforts have
been made to examine MLLMs from multiple perspectives. This paper presents a
comprehensive review of 200 benchmarks and evaluations for MLLMs, focusing on
(1)perception and understanding, (2)cognition and reasoning, (3)specific
domains, (4)key capabilities, and (5)other modalities. Finally, we discuss the
limitations of the current evaluation methods for MLLMs and explore promising
future directions. Our key argument is that evaluation should be regarded as a
crucial discipline to support the development of MLLMs better. For more
details, please visit our GitHub repository:
https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey.",2024-08-16,"Jian Li, Weiheng Lu, Hao Fei, Meng Luo, Ming Dai, Min Xia, Yizhang Jin, Zhenye Gan, Ding Qi, Chaoyou Fu, Ying Tai, Wankou Yang, Yabiao Wang, Chengjie Wang",http://arxiv.org/pdf/2408.08632v2,cs.CL
Persona is a Double-edged Sword: Mitigating the Negative Impact of Role-playing Prompts in Zero-shot Reasoning Tasks,"Recent studies demonstrate that prompting a role-playing persona to an LLM
improves reasoning capability. However, assigning an adequate persona is
difficult since LLMs are extremely sensitive to assigned prompts; thus,
inaccurately defined personas sometimes hinder LLMs and degrade their reasoning
capabilities. In this paper, we first investigate the potential negative impact
of injecting persona into language models. Furthermore, we propose a novel
framework, Jekyll \& Hyde, which ensembles the outcomes of both role-playing
and neutral prompts to enhance the robustness of reasoning ability.
Specifically, Jekyll \& Hyde predicts an appropriate persona using an LLM when
defining the role-playing prompt. Then, Jekyll \& Hyde collects two potential
solutions from role-playing and neutral prompts and selects a better solution
using the LLM evaluator. The experimental analysis demonstrates that
role-playing prompts sometimes distract LLMs, degrading their reasoning
abilities in 7 out of 12 datasets in llama3. Meanwhile, Jekyll \& Hyde improve
reasoning capabilities by selecting better choices among the potential
solutions on twelve widely-used natural language reasoning datasets. In
addition, we reveal that assigning LLM-generated personas obtains more stable
results than handcrafted personas.",2024-08-16,"Junseok Kim, Nakyeong Yang, Kyomin Jung",http://arxiv.org/pdf/2408.08631v2,cs.CL
RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions,"Clinical question answering systems have the potential to provide clinicians
with relevant and timely answers to their questions. Nonetheless, despite the
advances that have been made, adoption of these systems in clinical settings
has been slow. One issue is a lack of question-answering datasets which reflect
the real-world needs of health professionals. In this work, we present
RealMedQA, a dataset of realistic clinical questions generated by humans and an
LLM. We describe the process for generating and verifying the QA pairs and
assess several QA models on BioASQ and RealMedQA to assess the relative
difficulty of matching answers to questions. We show that the LLM is more
cost-efficient for generating ""ideal"" QA pairs. Additionally, we achieve a
lower lexical similarity between questions and answers than BioASQ which
provides an additional challenge to the top two QA models, as per the results.
We release our code and our dataset publicly to encourage further research.",2024-08-16,"Gregory Kell, Angus Roberts, Serge Umansky, Yuti Khare, Najma Ahmed, Nikhil Patel, Chloe Simela, Jack Coumbe, Julian Rozario, Ryan-Rhys Griffiths, Iain J. Marshall",http://arxiv.org/pdf/2408.08624v1,cs.CL
Convexity-based Pruning of Speech Representation Models,"Speech representation models based on the transformer architecture and
trained by self-supervised learning have shown great promise for solving tasks
such as speech and speaker recognition, keyword spotting, emotion detection,
and more. Typically, it is found that larger models lead to better performance.
However, the significant computational effort involved in such large
transformer systems is a challenge for embedded and real-world applications.
Recent work has shown that there is significant redundancy in the transformer
models for NLP and massive layer pruning is feasible (Sajjad et al., 2023).
Here, we investigate layer pruning in audio models. We base the pruning
decision on a convexity criterion. Convexity of classification regions has
recently been proposed as an indicator of subsequent fine-tuning performance in
a range of application domains, including NLP and audio. In empirical
investigations, we find a massive reduction in the computational effort with no
loss of performance or even improvements in certain cases.",2024-08-16,"Teresa Dorszewski, Lenka Tětková, Lars Kai Hansen",http://arxiv.org/pdf/2408.11858v1,cs.CL
A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models,"Recent studies on logical reasoning in Language Models (LMs) have sparked a
debate on whether they can learn systematic reasoning principles during
pre-training or merely exploit superficial patterns in the training data. This
paper presents a mechanistic interpretation of syllogistic reasoning in LMs to
advance the understanding of internal dynamics. Specifically, we present a
methodology for circuit discovery aimed at interpreting content-independent
reasoning mechanisms. Through two distinct intervention methods, we uncover a
sufficient and necessary circuit involving middle-term suppression that
elucidates how LMs transfer information to derive valid conclusions from
premises. Furthermore, we investigate how belief biases manifest in syllogistic
reasoning, finding evidence of partial contamination from additional attention
heads responsible for encoding commonsense and contextualized knowledge.
Finally, we explore the generalization of the discovered mechanisms across
various syllogistic schemes, model sizes and architectures, finding that the
identified circuit is sufficient and necessary for the schemes on which the
models achieve high downstream accuracy (> 60%), and that the activation
patterns apply to models of different families. Overall, our findings suggest
that LMs indeed learn transferable content-independent reasoning mechanisms,
but that, at the same time, such mechanisms do not involve generalizable and
abstract logical primitives, being susceptible to contamination by the same
world knowledge acquired during pre-training.",2024-08-16,"Geonhee Kim, Marco Valentino, André Freitas",http://arxiv.org/pdf/2408.08590v2,cs.CL
"Using large language models to estimate features of multi-word expressions: Concreteness, valence, arousal","This study investigates the potential of large language models (LLMs) to
provide accurate estimates of concreteness, valence and arousal for multi-word
expressions. Unlike previous artificial intelligence (AI) methods, LLMs can
capture the nuanced meanings of multi-word expressions. We systematically
evaluated ChatGPT-4o's ability to predict concreteness, valence and arousal. In
Study 1, ChatGPT-4o showed strong correlations with human concreteness ratings
(r = .8) for multi-word expressions. In Study 2, these findings were repeated
for valence and arousal ratings of individual words, matching or outperforming
previous AI models. Study 3 extended the prevalence and arousal analysis to
multi-word expressions and showed promising results despite the lack of
large-scale human benchmarks. These findings highlight the potential of LLMs
for generating valuable psycholinguistic data related to multiword expressions.
To help researchers with stimulus selection, we provide datasets with AI norms
of concreteness, valence and arousal for 126,397 English single words and
63,680 multi-word expressions",2024-08-16,"Gonzalo Martínez, Juan Diego Molero, Sandra González, Javier Conde, Marc Brysbaert, Pedro Reviriego",http://arxiv.org/pdf/2408.16012v1,cs.CL
Overview of the BioLaySumm 2024 Shared Task on the Lay Summarization of Biomedical Research Articles,"This paper presents the setup and results of the second edition of the
BioLaySumm shared task on the Lay Summarisation of Biomedical Research
Articles, hosted at the BioNLP Workshop at ACL 2024. In this task edition, we
aim to build on the first edition's success by further increasing research
interest in this important task and encouraging participants to explore novel
approaches that will help advance the state-of-the-art. Encouragingly, we found
research interest in the task to be high, with this edition of the task
attracting a total of 53 participating teams, a significant increase in
engagement from the previous edition. Overall, our results show that a broad
range of innovative approaches were adopted by task participants, with a
predictable shift towards the use of Large Language Models (LLMs).",2024-08-16,"Tomas Goldsack, Carolina Scarton, Matthew Shardlow, Chenghua Lin",http://arxiv.org/pdf/2408.08566v1,cs.CL
Collaborative Cross-modal Fusion with Large Language Model for Recommendation,"Despite the success of conventional collaborative filtering (CF) approaches
for recommendation systems, they exhibit limitations in leveraging semantic
knowledge within the textual attributes of users and items. Recent focus on the
application of large language models for recommendation (LLM4Rec) has
highlighted their capability for effective semantic knowledge capture. However,
these methods often overlook the collaborative signals in user behaviors. Some
simply instruct-tune a language model, while others directly inject the
embeddings of a CF-based model, lacking a synergistic fusion of different
modalities. To address these issues, we propose a framework of Collaborative
Cross-modal Fusion with Large Language Models, termed CCF-LLM, for
recommendation. In this framework, we translate the user-item interactions into
a hybrid prompt to encode both semantic knowledge and collaborative signals,
and then employ an attentive cross-modal fusion strategy to effectively fuse
latent embeddings of both modalities. Extensive experiments demonstrate that
CCF-LLM outperforms existing methods by effectively utilizing semantic and
collaborative signals in the LLM4Rec context.",2024-08-16,"Zhongzhou Liu, Hao Zhang, Kuicai Dong, Yuan Fang",http://arxiv.org/pdf/2408.08564v1,cs.CL
Integrating Multi-view Analysis: Multi-view Mixture-of-Expert for Textual Personality Detection,"Textual personality detection aims to identify personality traits by
analyzing user-generated content. To achieve this effectively, it is essential
to thoroughly examine user-generated content from various perspectives.
However, previous studies have struggled with automatically extracting and
effectively integrating information from multiple perspectives, thereby
limiting their performance on personality detection. To address these
challenges, we propose the Multi-view Mixture-of-Experts Model for Textual
Personality Detection (MvP). MvP introduces a Multi-view Mixture-of-Experts
(MoE) network to automatically analyze user posts from various perspectives.
Additionally, it employs User Consistency Regularization to mitigate conflicts
among different perspectives and learn a multi-view generic user
representation. The model's training is optimized via a multi-task joint
learning strategy that balances supervised personality detection with
self-supervised user consistency constraints. Experimental results on two
widely-used personality detection datasets demonstrate the effectiveness of the
MvP model and the benefits of automatically analyzing user posts from diverse
perspectives for textual personality detection.",2024-08-16,"Haohao Zhu, Xiaokun Zhang, Junyu Lu, Liang Yang, Hongfei Lin",http://arxiv.org/pdf/2408.08551v1,cs.CL
SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models,"Large language models (LLMs) have been widely adopted due to their remarkable
performance across various applications, driving the accelerated development of
a large number of diverse models. However, these individual LLMs show
limitations in generalization and performance on complex tasks due to inherent
training biases, model size constraints, and the quality or diversity of
pre-training datasets. A promising direction is to efficiently harness the
diverse capabilities of LLMs to overcome these individual limitations. To
address these limitations, we introduce a novel LLM selection algorithm called
SelectLLM, which efficiently directs input queries to the most suitable subset
of LLMs from a large pool, ensuring that the selected models collectively
provide accurate responses. SelectLLM employs a multi-label classifier and
policy based on the classifier's predictions and confidence scores in selecting
an optimal, query-aware, and lightweight subset of LLMs. Our findings indicate
that the proposed model outperforms existing ensemble-based baselines and
achieves competitive performance with similarly sized top-performing LLMs while
maintaining efficiency. Specifically, it achieves a huge reduction in inference
latency on two challenging reasoning benchmarks: 13% on GSM8K and 70% on MMLU,
compared to the top-performing baseline. Also, we establish a theoretical upper
bound by an Oracle with LLMs and perform an in-depth linguistic analysis to
understand the performance gap between the Oracle and SelectLLM.",2024-08-16,"Kaushal Kumar Maurya, KV Aditya Srivatsa, Ekaterina Kochmar",http://arxiv.org/pdf/2408.08545v3,cs.CL
Where is the signal in tokenization space?,"Large Language Models (LLMs) are typically shipped with tokenizers that
deterministically encode text into so-called canonical token sequences, to
which the LLMs assign probability values. One common assumption is that the
probability of a piece of text is the probability of its canonical token
sequence. However, the tokenization of a string is not unique: e.g., the Llama2
tokenizer encodes Tokens as [Tok,ens], but [Tok,en,s] also represents the same
text. In this paper, we study non-canonical tokenizations. We prove that, given
a string, it is computationally hard to find the most likely tokenization for
an autoregressive LLM, as well as to compute the marginal probability over all
possible tokenizations. We then show how the marginal is, in most cases,
indistinguishable from the canonical probability. Surprisingly, we then
empirically demonstrate the existence of a significant amount of signal hidden
within tokenization space. Notably, by simply aggregating the probabilities of
non-canonical tokenizations, we achieve improvements across a range of LLM
evaluation benchmarks for a variety of architectures, including transformers
and state space models.",2024-08-16,"Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck",http://arxiv.org/pdf/2408.08541v1,cs.CL
CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking,"Despite advancements in Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG) systems, their effectiveness is often hindered by a lack of
integration with entity relationships and community structures, limiting their
ability to provide contextually rich and accurate information retrieval for
fact-checking. We introduce CommunityKG-RAG (Community Knowledge
Graph-Retrieval Augmented Generation), a novel zero-shot framework that
integrates community structures within Knowledge Graphs (KGs) with RAG systems
to enhance the fact-checking process. Capable of adapting to new domains and
queries without additional training, CommunityKG-RAG utilizes the multi-hop
nature of community structures within KGs to significantly improve the accuracy
and relevance of information retrieval. Our experimental results demonstrate
that CommunityKG-RAG outperforms traditional methods, representing a
significant advancement in fact-checking by offering a robust, scalable, and
efficient solution.",2024-08-16,"Rong-Ching Chang, Jiawei Zhang",http://arxiv.org/pdf/2408.08535v1,cs.CL
MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement Framework for Multimodal Question Answering,"Recent advancements in retrieval-augmented generation (RAG) have demonstrated
impressive performance in the question-answering (QA) task. However, most
previous works predominantly focus on text-based answers. While some studies
address multimodal data, they still fall short in generating comprehensive
multimodal answers, particularly for explaining concepts or providing
step-by-step tutorials on how to accomplish specific goals. This capability is
especially valuable for applications such as enterprise chatbots and settings
such as customer service and educational systems, where the answers are sourced
from multimodal data. In this paper, we introduce a simple and effective
framework named MuRAR (Multimodal Retrieval and Answer Refinement). MuRAR
enhances text-based answers by retrieving relevant multimodal data and refining
the responses to create coherent multimodal answers. This framework can be
easily extended to support multimodal answers in enterprise chatbots with
minimal modifications. Human evaluation results indicate that multimodal
answers generated by MuRAR are more useful and readable compared to plain text
answers.",2024-08-16,"Zhengyuan Zhu, Daniel Lee, Hong Zhang, Sai Sree Harsha, Loic Feujio, Akash Maharaj, Yunyao Li",http://arxiv.org/pdf/2408.08521v2,cs.CL
"Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding","Generating long-term texts such as novels using artificial intelligence has
always been a challenge. A common approach is to use large language models
(LLMs) to construct a hierarchical framework that first plans and then writes.
Despite the fact that the generated novels reach a sufficient length, they
exhibit poor logical coherence and appeal in their plots and deficiencies in
character and event depiction, ultimately compromising the overall narrative
quality. In this paper, we propose a method named Extracting Excelsior and
Expanding. Ex3 initially extracts structure information from raw novel data. By
combining this structure information with the novel data, an
instruction-following dataset is meticulously crafted. This dataset is then
utilized to fine-tune the LLM, aiming for excelsior generation performance. In
the final stage, a tree-like expansion method is deployed to facilitate the
generation of arbitrarily long novels. Evaluation against previous methods
showcases Ex3's ability to produce higher-quality long-form novels.",2024-08-16,"Lei Huang, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen",http://arxiv.org/pdf/2408.08506v2,cs.CL
DePrompt: Desensitization and Evaluation of Personal Identifiable Information in Large Language Model Prompts,"Prompt serves as a crucial link in interacting with large language models
(LLMs), widely impacting the accuracy and interpretability of model outputs.
However, acquiring accurate and high-quality responses necessitates precise
prompts, which inevitably pose significant risks of personal identifiable
information (PII) leakage. Therefore, this paper proposes DePrompt, a
desensitization protection and effectiveness evaluation framework for prompt,
enabling users to safely and transparently utilize LLMs. Specifically, by
leveraging large model fine-tuning techniques as the underlying privacy
protection method, we integrate contextual attributes to define privacy types,
achieving high-precision PII entity identification. Additionally, through the
analysis of key features in prompt desensitization scenarios, we devise
adversarial generative desensitization methods that retain important semantic
content while disrupting the link between identifiers and privacy attributes.
Furthermore, we present utility evaluation metrics for prompt to better gauge
and balance privacy and usability. Our framework is adaptable to prompts and
can be extended to text usability-dependent scenarios. Through comparison with
benchmarks and other model methods, experimental evaluations demonstrate that
our desensitized prompt exhibit superior privacy protection utility and model
inference results.",2024-08-16,"Xiongtao Sun, Gan Liu, Zhipeng He, Hui Li, Xiaoguang Li",http://arxiv.org/pdf/2408.08930v1,cs.CL
JPEG-LM: LLMs as Image Generators with Canonical Codec Representations,"Recent work in image and video generation has been adopting the
autoregressive LLM architecture due to its generality and potentially easy
integration into multi-modal systems. The crux of applying autoregressive
training in language generation to visual generation is discretization --
representing continuous data like images and videos as discrete tokens. Common
methods of discretizing images and videos include modeling raw pixel values,
which are prohibitively lengthy, or vector quantization, which requires
convoluted pre-hoc training. In this work, we propose to directly model images
and videos as compressed files saved on computers via canonical codecs (e.g.,
JPEG, AVC/H.264). Using the default Llama architecture without any
vision-specific modifications, we pretrain JPEG-LM from scratch to generate
images (and AVC-LM to generate videos as a proof of concept), by directly
outputting compressed file bytes in JPEG and AVC formats. Evaluation of image
generation shows that this simple and straightforward approach is more
effective than pixel-based modeling and sophisticated vector quantization
baselines (on which our method yields a 31% reduction in FID). Our analysis
shows that JPEG-LM has an especial advantage over vector quantization models in
generating long-tail visual elements. Overall, we show that using canonical
codec representations can help lower the barriers between language generation
and visual generation, facilitating future research on multi-modal
language/image/video LLMs.",2024-08-15,"Xiaochuang Han, Marjan Ghazvininejad, Pang Wei Koh, Yulia Tsvetkov",http://arxiv.org/pdf/2408.08459v2,cs.CL
W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering,"In knowledge-intensive tasks such as open-domain question answering (OpenQA),
large language models (LLMs) often struggle to generate factual answers,
relying solely on their internal (parametric) knowledge. To address this
limitation, Retrieval-Augmented Generation (RAG) systems enhance LLMs by
retrieving relevant information from external sources, thereby positioning the
retriever as a pivotal component. Although dense retrieval demonstrates
state-of-the-art performance, its training poses challenges due to the scarcity
of ground-truth evidence, largely attributed to the high costs of human
annotation. In this paper, we propose W-RAG, a method that draws weak training
signals from the downstream task (such as OpenQA) of an LLM, and fine-tunes the
retriever to prioritize passages that most benefit the task. Specifically, we
rerank the top-$k$ passages retrieved via BM25 by assessing the probability
that the LLM will generate the correct answer for a question given each
passage. The highest-ranking passages are then used as positive fine-tuning
examples for dense retrieval. We conduct comprehensive experiments across four
publicly available OpenQA datasets to demonstrate that our approach enhances
both retrieval and OpenQA performance compared to baseline models, achieving
results comparable to models fine-tuned with human-labeled data.",2024-08-15,"Jinming Nian, Zhiyuan Peng, Qifan Wang, Yi Fang",http://arxiv.org/pdf/2408.08444v2,cs.CL
Rater Cohesion and Quality from a Vicarious Perspective,"Human feedback is essential for building human-centered AI systems across
domains where disagreement is prevalent, such as AI safety, content moderation,
or sentiment analysis. Many disagreements, particularly in politically charged
settings, arise because raters have opposing values or beliefs. Vicarious
annotation is a method for breaking down disagreement by asking raters how they
think others would annotate the data. In this paper, we explore the use of
vicarious annotation with analytical methods for moderating rater disagreement.
We employ rater cohesion metrics to study the potential influence of political
affiliations and demographic backgrounds on raters' perceptions of offense.
Additionally, we utilize CrowdTruth's rater quality metrics, which consider the
demographics of the raters, to score the raters and their annotations. We study
how the rater quality metrics influence the in-group and cross-group rater
cohesion across the personal and vicarious levels.",2024-08-15,"Deepak Pandita, Tharindu Cyril Weerasooriya, Sujan Dutta, Sarah K. Luger, Tharindu Ranasinghe, Ashiqur R. KhudaBukhsh, Marcos Zampieri, Christopher M. Homan",http://arxiv.org/pdf/2408.08411v2,cs.CL
Hermes 3 Technical Report,"Instruct (or ""chat"") tuned models have become the primary way in which most
people interact with large language models. As opposed to ""base"" or
""foundation"" models, instruct-tuned models are optimized to respond to
imperative statements. We present Hermes 3, a neutrally-aligned generalist
instruct and tool use model with strong reasoning and creative abilities. Its
largest version, Hermes 3 405B, achieves state of the art performance among
open weight models on several public benchmarks.",2024-08-15,"Ryan Teknium, Jeffrey Quesnelle, Chen Guang",http://arxiv.org/pdf/2408.11857v1,cs.CL
VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool,"Due to the growing complexity of modern Integrated Circuits (ICs), automating
hardware design can prevent a significant amount of human error from the
engineering process and result in less errors. Verilog is a popular hardware
description language for designing and modeling digital systems; thus, Verilog
generation is one of the emerging areas of research to facilitate the design
process. In this work, we propose VerilogCoder, a system of multiple Artificial
Intelligence (AI) agents for Verilog code generation, to autonomously write
Verilog code and fix syntax and functional errors using collaborative Verilog
tools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we
propose a task planner that utilizes a novel Task and Circuit Relation Graph
retrieval method to construct a holistic plan based on module descriptions. To
debug and fix functional errors, we develop a novel and efficient abstract
syntax tree (AST)-based waveform tracing tool, which is integrated within the
autonomous Verilog completion flow. The proposed methodology successfully
generates 94.2% syntactically and functionally correct Verilog code, surpassing
the state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.",2024-08-15,"Chia-Tung Ho, Haoxing Ren, Brucek Khailany",http://arxiv.org/pdf/2408.08927v2,cs.CL
Zero-Shot Learning and Key Points Are All You Need for Automated Fact-Checking,"Automated fact-checking is an important task because determining the accurate
status of a proposed claim within the vast amount of information available
online is a critical challenge. This challenge requires robust evaluation to
prevent the spread of false information. Modern large language models (LLMs)
have demonstrated high capability in performing a diverse range of Natural
Language Processing (NLP) tasks. By utilizing proper prompting strategies,
their versatility due to their understanding of large context sizes and
zero-shot learning ability enables them to simulate human problem-solving
intuition and move towards being an alternative to humans for solving problems.
In this work, we introduce a straightforward framework based on Zero-Shot
Learning and Key Points (ZSL-KeP) for automated fact-checking, which despite
its simplicity, performed well on the AVeriTeC shared task dataset by robustly
improving the baseline and achieving 10th place.",2024-08-15,"Mohammad Ghiasvand Mohammadkhani, Ali Ghiasvand Mohammadkhani, Hamid Beigy",http://arxiv.org/pdf/2408.08400v1,cs.CL
Level Up Your Tutorials: VLMs for Game Tutorials Quality Assessment,"Designing effective game tutorials is crucial for a smooth learning curve for
new players, especially in games with many rules and complex core mechanics.
Evaluating the effectiveness of these tutorials usually requires multiple
iterations with testers who have no prior knowledge of the game. Recent
Vision-Language Models (VLMs) have demonstrated significant capabilities in
understanding and interpreting visual content. VLMs can analyze images, provide
detailed insights, and answer questions about their content. They can recognize
objects, actions, and contexts in visual data, making them valuable tools for
various applications, including automated game testing. In this work, we
propose an automated game-testing solution to evaluate the quality of game
tutorials. Our approach leverages VLMs to analyze frames from video game
tutorials, answer relevant questions to simulate human perception, and provide
feedback. This feedback is compared with expected results to identify confusing
or problematic scenes and highlight potential errors for developers. In
addition, we publish complete tutorial videos and annotated frames from
different game versions used in our tests. This solution reduces the need for
extensive manual testing, especially by speeding up and simplifying the initial
development stages of the tutorial to improve the final game experience.",2024-08-15,"Daniele Rege Cambrin, Gabriele Scaffidi Militone, Luca Colomba, Giovanni Malnati, Daniele Apiletti, Paolo Garza",http://arxiv.org/pdf/2408.08396v1,cs.CL
Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models,"Sentiment analysis plays a crucial role in various domains, such as business
intelligence and financial forecasting. Large language models (LLMs) have
become a popular paradigm for sentiment analysis, leveraging multi-task
learning to address specific tasks concurrently. However, LLMs with fine-tuning
for sentiment analysis often underperforms due to the inherent challenges in
managing diverse task complexities. Moreover, constant-weight approaches in
multi-task learning struggle to adapt to variations in data characteristics,
further complicating model effectiveness. To address these issues, we propose a
novel multi-task learning framework with a dynamic adaptive optimization (DAO)
module. This module is designed as a plug-and-play component that can be
seamlessly integrated into existing models, providing an effective and flexible
solution for multi-task learning. The key component of the DAO module is
dynamic adaptive loss, which dynamically adjusts the weights assigned to
different tasks based on their relative importance and data characteristics
during training. Sentiment analyses on a standard and customized financial text
dataset demonstrate that the proposed framework achieves superior performance.
Specifically, this work improves the Mean Squared Error (MSE) and Accuracy
(ACC) by 15.58% and 1.24% respectively, compared with previous work.",2024-08-15,"Hongcheng Ding, Xuanze Zhao, Shamsul Nahar Abdullah, Deshinta Arrova Dewi, Zixiao Jiang, Xiangyu Shi",http://arxiv.org/pdf/2408.11856v2,cs.CL
Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions,"The emergence of synthetic data represents a pivotal shift in modern machine
learning, offering a solution to satisfy the need for large volumes of data in
domains where real data is scarce, highly private, or difficult to obtain. We
investigate the feasibility of creating realistic, large-scale synthetic
datasets of user-generated content, noting that such content is increasingly
prevalent and a source of frequently sought information. Large language models
(LLMs) offer a starting point for generating synthetic social media discussion
threads, due to their ability to produce diverse responses that typify online
interactions. However, as we demonstrate, straightforward application of LLMs
yields limited success in capturing the complex structure of online
discussions, and standard prompting mechanisms lack sufficient control. We
therefore propose a multi-step generation process, predicated on the idea of
creating compact representations of discussion threads, referred to as
scaffolds. Our framework is generic yet adaptable to the unique characteristics
of specific social media platforms. We demonstrate its feasibility using data
from two distinct online discussion platforms. To address the fundamental
challenge of ensuring the representativeness and realism of synthetic data, we
propose a portfolio of evaluation measures to compare various instantiations of
our framework.",2024-08-15,"Krisztian Balog, John Palowitch, Barbara Ikica, Filip Radlinski, Hamidreza Alvari, Mehdi Manshadi",http://arxiv.org/pdf/2408.08379v1,cs.CL
Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples,"As machine learning systems become more widely used, especially for safety
critical applications, there is a growing need to ensure that these systems
behave as intended, even in the face of adversarial examples. Adversarial
examples are inputs that are designed to trick the decision making process, and
are intended to be imperceptible to humans. However, for text-based
classification systems, changes to the input, a string of text, are always
perceptible. Therefore, text-based adversarial examples instead focus on trying
to preserve semantics. Unfortunately, recent work has shown this goal is often
not met. To improve the quality of text-based adversarial examples, we need to
know what elements of the input text are worth focusing on. To address this, in
this paper, we explore what parts of speech have the highest impact of
text-based classifiers. Our experiments highlight a distinct bias in CNN
algorithms against certain parts of speech tokens within review datasets. This
finding underscores a critical vulnerability in the linguistic processing
capabilities of CNNs.",2024-08-15,"Anahita Samadi, Allison Sullivan",http://arxiv.org/pdf/2408.08374v1,cs.CL
Can Large Language Models Understand Symbolic Graphics Programs?,"Against the backdrop of enthusiasm for large language models (LLMs), there is
an urgent need to scientifically assess their capabilities and shortcomings.
This is nontrivial in part because it is difficult to find tasks which the
models have not encountered during training. Utilizing symbolic graphics
programs, we propose a domain well-suited to test multiple spatial-semantic
reasoning skills of LLMs. Popular in computer graphics, these programs
procedurally generate visual data. While LLMs exhibit impressive skills in
general program synthesis and analysis, symbolic graphics programs offer a new
layer of evaluation: they allow us to test an LLM's ability to answer
different-grained semantic-level questions of the images or 3D geometries
without a vision encoder. To semantically understand the symbolic programs,
LLMs would need to possess the ability to ""imagine"" and reason how the
corresponding graphics content would look with only the symbolic description.
We use this task to evaluate LLMs by creating a large benchmark for the
semantic visual understanding of symbolic graphics programs, built procedurally
with minimal human effort. Particular emphasis is placed on transformations of
images that leave the image level semantics invariant while introducing
significant changes to the underlying program. We evaluate commercial and
open-source LLMs on our benchmark to assess their ability to reason about
visual output of programs, finding that LLMs considered stronger at reasoning
generally perform better. Lastly, we introduce a novel method to improve this
ability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned
with pre-collected instruction data on symbolic graphics programs.
Interestingly, we find that SIT not only improves LLM's understanding on
symbolic programs, but it also improves general reasoning ability on various
other benchmarks.",2024-08-15,"Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Schölkopf",http://arxiv.org/pdf/2408.08313v3,cs.CL
ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws,"High-quality data is crucial for the pre-training performance of large
language models. Unfortunately, existing quality filtering methods rely on a
known high-quality dataset as reference, which can introduce potential bias and
compromise diversity. In this paper, we propose ScalingFilter, a novel approach
that evaluates text quality based on the perplexity difference between two
language models trained on the same data, thereby eliminating the influence of
the reference dataset in the filtering process. An theoretical analysis shows
that ScalingFilter is equivalent to an inverse utilization of scaling laws.
Through training models with 1.3B parameters on the same data source processed
by various quality filters, we find ScalingFilter can improve zero-shot
performance of pre-trained models in downstream tasks. To assess the bias
introduced by quality filtering, we introduce semantic diversity, a metric of
utilizing text embedding models for semantic representations. Extensive
experiments reveal that semantic diversity is a reliable indicator of dataset
diversity, and ScalingFilter achieves an optimal balance between downstream
performance and semantic diversity.",2024-08-15,"Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng",http://arxiv.org/pdf/2408.08310v1,cs.CL
"Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors","In this paper, we explore the capabilities of state-of-the-art large language
models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level
transportation engineering problems. We introduce TransportBench, a benchmark
dataset that includes a sample of transportation engineering problems on a wide
range of subjects in the context of planning, design, management, and control
of transportation systems. This dataset is used by human experts to evaluate
the capabilities of various commercial and open-sourced LLMs, especially their
accuracy, consistency, and reasoning behaviors, in solving transportation
engineering problems. Our comprehensive analysis uncovers the unique strengths
and limitations of each LLM, e.g. our analysis shows the impressive accuracy
and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving
TransportBench problems. Our study marks a thrilling first step toward
harnessing artificial general intelligence for complex transportation
challenges.",2024-08-15,"Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng Ouyang, Bin Hu",http://arxiv.org/pdf/2408.08302v1,cs.CL
The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community,"Human-model conversations provide a window into users' real-world scenarios,
behavior, and needs, and thus are a valuable resource for model development and
research. While for-profit companies collect user data through the APIs of
their models, using it internally to improve their own models, the open source
and research community lags behind.
  We introduce the ShareLM collection, a unified set of human conversations
with large language models, and its accompanying plugin, a Web extension for
voluntarily contributing user-model conversations. Where few platforms share
their chats, the ShareLM plugin adds this functionality, thus, allowing users
to share conversations from most platforms. The plugin allows the user to rate
their conversations, both at the conversation and the response levels, and
delete conversations they prefer to keep private before they ever leave the
user's local storage. We release the plugin conversations as part of the
ShareLM collection, and call for more community effort in the field of open
human-model data.
  The code, plugin, and data are available.",2024-08-15,"Shachar Don-Yehiya, Leshem Choshen, Omri Abend",http://arxiv.org/pdf/2408.08291v2,cs.CL
Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models,"Language Model (LM) agents for cybersecurity that are capable of autonomously
identifying vulnerabilities and executing exploits have potential to cause
real-world impact. Policymakers, model providers, and researchers in the AI and
cybersecurity communities are interested in quantifying the capabilities of
such agents to help mitigate cyberrisk and investigate opportunities for
penetration testing. Toward that end, we introduce Cybench, a framework for
specifying cybersecurity tasks and evaluating agents on those tasks. We include
40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF
competitions, chosen to be recent, meaningful, and spanning a wide range of
difficulties. Each task includes its own description, starter files, and is
initialized in an environment where an agent can execute commands and observe
outputs. Since many tasks are beyond the capabilities of existing LM agents, we
introduce subtasks for each task, which break down a task into intermediary
steps for a more detailed evaluation. To evaluate agent capabilities, we
construct a cybersecurity agent and evaluate 8 models: GPT-4o, OpenAI
o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct, Gemini
1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. For the top performing
models (GPT-4o and Claude 3.5 Sonnet), we further investigate performance
across 4 agent scaffolds (structed bash, action-only, pseudoterminal, and web
search). Without subtask guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o,
OpenAI o1-preview, and Claude 3 Opus successfully solved complete tasks that
took human teams up to 11 minutes to solve. In comparison, the most difficult
task took human teams 24 hours and 54 minutes to solve. All code and data are
publicly available at https://cybench.github.io.",2024-08-15,"Andy K. Zhang, Neil Perry, Riya Dulepet, Joey Ji, Celeste Menders, Justin W. Lin, Eliot Jones, Gashon Hussein, Samantha Liu, Donovan Jasper, Pura Peetathawatchai, Ari Glenn, Vikram Sivashankar, Daniel Zamoshchin, Leo Glikbarg, Derek Askaryar, Mike Yang, Teddy Zhang, Rishi Alluri, Nathan Tran, Rinnara Sangpisit, Polycarpos Yiorkadjis, Kenny Osele, Gautham Raghupathi, Dan Boneh, Daniel E. Ho, Percy Liang",http://arxiv.org/pdf/2408.08926v4,cs.CL
mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis,"This paper introduces mhGPT, a lightweight generative pre-trained transformer
trained on mental health-related social media and PubMed articles. Fine-tuned
for specific mental health tasks, mhGPT was evaluated under limited hardware
constraints and compared with state-of-the-art models like MentaLLaMA and
Gemma. Despite having only 1.98 billion parameters and using just 5% of the
dataset, mhGPT outperformed larger models and matched the performance of models
trained on significantly more data. The key contributions include integrating
diverse mental health data, creating a custom tokenizer, and optimizing a
smaller architecture for low-resource settings. This research could advance
AI-driven mental health care, especially in areas with limited computing power.",2024-08-15,"Dae-young Kim, Rebecca Hwa, Muhammad Mahbubur Rahman",http://arxiv.org/pdf/2408.08261v1,cs.CL
Retail-GPT: leveraging Retrieval Augmented Generation (RAG) for building E-commerce Chat Assistants,"This work presents Retail-GPT, an open-source RAG-based chatbot designed to
enhance user engagement in retail e-commerce by guiding users through product
recommendations and assisting with cart operations. The system is
cross-platform and adaptable to various e-commerce domains, avoiding reliance
on specific chat applications or commercial activities. Retail-GPT engages in
human-like conversations, interprets user demands, checks product availability,
and manages cart operations, aiming to serve as a virtual sales agent and test
the viability of such assistants across different retail businesses.",2024-08-15,"Bruno Amaral Teixeira de Freitas, Roberto de Alencar Lotufo",http://arxiv.org/pdf/2408.08925v1,cs.CL
FactorLLM: Factorizing Knowledge via Mixture of Experts for Large Language Models,"Recent research has demonstrated that Feed-Forward Networks (FFNs) in Large
Language Models (LLMs) play a pivotal role in storing diverse linguistic and
factual knowledge. Conventional methods frequently face challenges due to
knowledge confusion stemming from their monolithic and redundant architectures,
which calls for more efficient solutions with minimal computational overhead,
particularly for LLMs. In this paper, we explore the FFN computation paradigm
in LLMs and introduce FactorLLM, a novel approach that decomposes well-trained
dense FFNs into sparse sub-networks without requiring any further
modifications, while maintaining the same level of performance. Furthermore, we
embed a router from the Mixture-of-Experts (MoE), combined with our devised
Prior-Approximate (PA) loss term that facilitates the dynamic activation of
experts and knowledge adaptation, thereby accelerating computational processes
and enhancing performance using minimal training data and fine-tuning steps.
FactorLLM thus enables efficient knowledge factorization and activates select
groups of experts specifically tailored to designated tasks, emulating the
interactive functional segmentation of the human brain. Extensive experiments
across various benchmarks demonstrate the effectiveness of our proposed
FactorLLM which achieves comparable performance to the source model securing up
to 85% model performance while obtaining over a 30% increase in inference
speed. Code: https://github.com/zhenwuweihe/FactorLLM.",2024-08-15,"Zhongyu Zhao, Menghang Dong, Rongyu Zhang, Wenzhao Zheng, Yunpeng Zhang, Huanrui Yang, Dalong Du, Kurt Keutzer, Shanghang Zhang",http://arxiv.org/pdf/2408.11855v1,cs.CL
Inductive Learning of Logical Theories with LLMs: An Expressivity-Graded Analysis,"This work presents a novel systematic methodology to analyse the capabilities
and limitations of Large Language Models (LLMs) with feedback from a formal
inference engine, on logic theory induction. The analysis is complexity-graded
w.r.t. rule dependency structure, allowing quantification of specific inference
challenges on LLM performance. Integrating LLMs with formal methods is a
promising frontier in the Natural Language Processing field, as an important
avenue for improving model inference control and explainability. In particular,
inductive learning over complex sets of facts and rules, poses unique
challenges for current autoregressive models, as they lack explicit symbolic
grounding. While they can be complemented by formal systems, the properties
delivered by LLMs regarding inductive learning, are not well understood and
quantified. Empirical results indicate that the largest LLMs can achieve
competitive results against a SOTA Inductive Logic Programming (ILP) system
baseline, but also that tracking long predicate relationship chains is a more
difficult obstacle than theory complexity for LLMs.",2024-08-15,"João Pedro Gandarela, Danilo S. Carvalho, André Freitas",http://arxiv.org/pdf/2408.16779v2,cs.CL
Evolving Text Data Stream Mining,"A text stream is an ordered sequence of text documents generated over time. A
massive amount of such text data is generated by online social platforms every
day. Designing an algorithm for such text streams to extract useful information
is a challenging task due to unique properties of the stream such as infinite
length, data sparsity, and evolution. Thereby, learning useful information from
such streaming data under the constraint of limited time and memory has gained
increasing attention. During the past decade, although many text stream mining
algorithms have proposed, there still exists some potential issues. First,
high-dimensional text data heavily degrades the learning performance until the
model either works on subspace or reduces the global feature space. The second
issue is to extract semantic text representation of documents and capture
evolving topics over time. Moreover, the problem of label scarcity exists,
whereas existing approaches work on the full availability of labeled data. To
deal with these issues, in this thesis, new learning models are proposed for
clustering and multi-label learning on text streams.",2024-08-15,Jay Kumar,http://arxiv.org/pdf/2409.00010v1,cs.CL
Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion,"While various approaches have recently been studied for bias identification,
little is known about how implicit language that does not explicitly convey a
viewpoint affects bias amplification in large language models. To examine the
severity of bias toward a view, we evaluated the performance of two downstream
tasks where the implicit and explicit knowledge of social groups were used.
First, we present a stress test evaluation by using a biased model in edge
cases of excessive bias scenarios. Then, we evaluate how LLMs calibrate
linguistically in response to both implicit and explicit opinions when they are
aligned with conflicting viewpoints. Our findings reveal a discrepancy in LLM
performance in identifying implicit and explicit opinions, with a general
tendency of bias toward explicit opinions of opposing stances. Moreover, the
bias-aligned models generate more cautious responses using uncertainty phrases
compared to the unaligned (zero-shot) base models. The direct, incautious
responses of the unaligned models suggest a need for further refinement of
decisiveness by incorporating uncertainty markers to enhance their reliability,
especially on socially nuanced topics with high subjectivity.",2024-08-15,"Abeer Aldayel, Areej Alokaili, Rehab Alahmadi",http://arxiv.org/pdf/2408.08212v2,cs.CL
Prefix Guidance: A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks,"In recent years, the rapid development of large language models (LLMs) has
achieved remarkable performance across various tasks. However, research
indicates that LLMs are vulnerable to jailbreak attacks, where adversaries can
induce the generation of harmful content through meticulously crafted prompts.
This vulnerability poses significant challenges to the secure use and promotion
of LLMs. Existing defense methods offer protection from different perspectives
but often suffer from insufficient effectiveness or a significant impact on the
model's capabilities. In this paper, we propose a plug-and-play and
easy-to-deploy jailbreak defense framework, namely Prefix Guidance (PG), which
guides the model to identify harmful prompts by directly setting the first few
tokens of the model's output. This approach combines the model's inherent
security capabilities with an external classifier to defend against jailbreak
attacks. We demonstrate the effectiveness of PG across three models and five
attack methods. Compared to baselines, our approach is generally more effective
on average. Additionally, results on the Just-Eval benchmark further confirm
PG's superiority to preserve the model's performance. our code is available at
https://github.com/weiyezhimeng/Prefix-Guidance.",2024-08-15,"Jiawei Zhao, Kejiang Chen, Xiaojian Yuan, Weiming Zhang",http://arxiv.org/pdf/2408.08924v2,cs.CL
DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search,"We introduce DeepSeek-Prover-V1.5, an open-source language model designed for
theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both
training and inference processes. Pre-trained on DeepSeekMath-Base with
specialization in formal mathematical languages, the model undergoes supervised
fine-tuning using an enhanced formal theorem proving dataset derived from
DeepSeek-Prover-V1. Further refinement is achieved through reinforcement
learning from proof assistant feedback (RLPAF). Beyond the single-pass
whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a
variant of Monte-Carlo tree search that employs an intrinsic-reward-driven
exploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5
demonstrates significant improvements over DeepSeek-Prover-V1, achieving new
state-of-the-art results on the test set of the high school level miniF2F
benchmark ($63.5\%$) and the undergraduate level ProofNet benchmark ($25.3\%$).",2024-08-15,"Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, Chong Ruan",http://arxiv.org/pdf/2408.08152v1,cs.CL
P/D-Serve: Serving Disaggregated Large Language Model at Scale,"Serving disaggregated large language models (LLMs) over tens of thousands of
xPU devices (GPUs or NPUs) with reliable performance faces multiple challenges.
1) Ignoring the diversity (various prefixes and tidal requests), treating all
the prompts in a mixed pool is inadequate. To facilitate the similarity per
scenario and minimize the inner mismatch on P/D (prefill and decoding)
processing, fine-grained organization is required, dynamically adjusting P/D
ratios for better performance. 2) Due to inaccurate estimation on workload
(queue status or maintained connections), the global scheduler easily incurs
unnecessary timeouts in prefill. 3) Block-fixed device-to-device (D2D) KVCache
transfer over cluster-level RDMA (remote direct memory access) fails to achieve
desired D2D utilization as expected. To overcome previous problems, this paper
proposes an end-to-end system P/D-Serve, complying with the paradigm of MLOps
(machine learning operations), which models end-to-end (E2E) P/D performance
and enables: 1) fine-grained P/D organization, mapping the service with RoCE
(RDMA over converged ethernet) as needed, to facilitate similar processing and
dynamic adjustments on P/D ratios; 2) on-demand forwarding upon rejections for
idle prefill, decoupling the scheduler from regular inaccurate reports and
local queues, to avoid timeouts in prefill; and 3) efficient KVCache transfer
via optimized D2D access. P/D-Serve is implemented upon Ascend and MindSpore,
has been deployed over tens of thousands of NPUs for more than eight months in
commercial use, and further achieves 60\%, 42\% and 46\% improvements on E2E
throughput, time-to-first-token (TTFT) SLO (service level objective) and D2D
transfer time. As the E2E system with optimizations, P/D-Serve achieves 6.7x
increase on throughput, compared with aggregated LLMs.",2024-08-15,"Yibo Jin, Tao Wang, Huimin Lin, Mingyang Song, Peiyang Li, Yipeng Ma, Yicheng Shan, Zhengfan Yuan, Cailong Li, Yajing Sun, Tiandeng Wu, Xing Chu, Ruizhi Huan, Li Ma, Xiao You, Wenting Zhou, Yunpeng Ye, Wen Liu, Xiangkun Xu, Yongsheng Zhang, Tiantian Dong, Jiawei Zhu, Zhe Wang, Xijian Ju, Jianxun Song, Haoliang Cheng, Xiaojing Li, Jiandong Ding, Hefei Guo, Zhengyong Zhang",http://arxiv.org/pdf/2408.08147v1,cs.CL
KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning,"Large Language Models (LLMs) exhibit high inference latency due to their
autoregressive decoding nature. While the draft head in speculative decoding
mitigates this issue, its full potential remains unexplored. In this paper, we
introduce KOALA (K-layer Optimized Adversarial Learning Architecture), an
orthogonal approach to the draft head. By transforming the conventional
single-layer draft head into a multi-layer architecture and incorporating
adversarial learning into the traditional supervised training, KOALA
significantly improves the accuracy of the draft head in predicting subsequent
tokens, thus more closely mirroring the functionality of LLMs. Although this
improvement comes at the cost of slightly increased drafting overhead, KOALA
substantially unlocks the draft head's potential, greatly enhancing speculative
decoding. We conducted comprehensive evaluations of KOALA, including both
autoregressive and non-autoregressive draft heads across various tasks,
demonstrating a latency speedup ratio improvement of 0.24x-0.41x, which is
10.57%-14.09% faster than the original draft heads.",2024-08-15,"Kaiqi Zhang, Jing Zhao, Rui Chen",http://arxiv.org/pdf/2408.08146v1,cs.CL
"MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU","Although Large Language Models(LLMs) can generate coherent and contextually
relevant text, they often struggle to recognise the intent behind the human
user's query. Natural Language Understanding (NLU) models, however, interpret
the purpose and key information of user's input to enable responsive
interactions. Existing NLU models generally map individual utterances to a
dual-level semantic frame, involving sentence-level intent and word-level slot
labels. However, real-life conversations primarily consist of multi-turn
conversations, involving the interpretation of complex and extended dialogues.
Researchers encounter challenges addressing all facets of multi-turn dialogue
conversations using a unified single NLU model. This paper introduces a novel
approach, MIDAS, leveraging a multi-level intent, domain, and slot knowledge
distillation for multi-turn NLU. To achieve this, we construct distinct
teachers for varying levels of conversation knowledge, namely, sentence-level
intent detection, word-level slot filling, and conversation-level domain
classification. These teachers are then fine-tuned to acquire specific
knowledge of their designated levels. A multi-teacher loss is proposed to
facilitate the combination of these multi-level teachers, guiding a student
model in multi-turn dialogue tasks. The experimental results demonstrate the
efficacy of our model in improving the overall multi-turn conversation
understanding, showcasing the potential for advancements in NLU models through
the incorporation of multi-level dialogue knowledge distillation techniques.",2024-08-15,"Yan Li, So-Eon Kim, Seong-Bae Park, Soyeon Caren Han",http://arxiv.org/pdf/2408.08144v2,cs.CL
Graph Retrieval-Augmented Generation: A Survey,"Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable
success in addressing the challenges of Large Language Models (LLMs) without
necessitating retraining. By referencing an external knowledge base, RAG
refines LLM outputs, effectively mitigating issues such as ``hallucination'',
lack of domain-specific knowledge, and outdated information. However, the
complex structure of relationships among different entities in databases
presents challenges for RAG systems. In response, GraphRAG leverages structural
information across entities to enable more precise and comprehensive retrieval,
capturing relational knowledge and facilitating more accurate, context-aware
responses. Given the novelty and potential of GraphRAG, a systematic review of
current technologies is imperative. This paper provides the first comprehensive
overview of GraphRAG methodologies. We formalize the GraphRAG workflow,
encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced
Generation. We then outline the core technologies and training methods at each
stage. Additionally, we examine downstream tasks, application domains,
evaluation methodologies, and industrial use cases of GraphRAG. Finally, we
explore future research directions to inspire further inquiries and advance
progress in the field. In order to track recent progress in this field, we set
up a repository at \url{https://github.com/pengboci/GraphRAG-Survey}.",2024-08-15,"Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, Siliang Tang",http://arxiv.org/pdf/2408.08921v2,cs.CL
AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents,"In this paper, we present a simulation system called AgentCourt that
simulates the entire courtroom process. The judge, plaintiff's lawyer, defense
lawyer, and other participants are autonomous agents driven by large language
models (LLMs). Our core goal is to enable lawyer agents to learn how to argue a
case, as well as improving their overall legal skills, through courtroom
process simulation. To achieve this goal, we propose an adversarial
evolutionary approach for the lawyer-agent. Since AgentCourt can simulate the
occurrence and development of court hearings based on a knowledge base and LLM,
the lawyer agents can continuously learn and accumulate experience from real
court cases. The simulation experiments show that after two lawyer-agents have
engaged in a thousand adversarial legal cases in AgentCourt (which can take a
decade for real-world lawyers), compared to their pre-evolutionary state, the
evolved lawyer agents exhibit consistent improvement in their ability to handle
legal tasks. To enhance the credibility of our experimental results, we
enlisted a panel of professional lawyers to evaluate our simulations. The
evaluation indicates that the evolved lawyer agents exhibit notable
advancements in responsiveness, as well as expertise and logical rigor. This
work paves the way for advancing LLM-driven agent technology in legal
scenarios. Code is available at https://github.com/relic-yuexi/AgentCourt.",2024-08-15,"Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang Liu, Chengming Li, Qiang Qu, Shiwen Ni, Min Yang",http://arxiv.org/pdf/2408.08089v1,cs.CL
Extracting Sentence Embeddings from Pretrained Transformer Models,"Pre-trained transformer models shine in many natural language processing
tasks and therefore are expected to bear the representation of the input
sentence or text meaning. These sentence-level embeddings are also important in
retrieval-augmented generation. But do commonly used plain averaging or prompt
templates sufficiently capture and represent the underlying meaning? After
providing a comprehensive review of existing sentence embedding extraction and
refinement methods, we thoroughly test different combinations and our original
extensions of the most promising ones on pretrained models. Namely, given 110 M
parameters, BERT's hidden representations from multiple layers, and many
tokens, we try diverse ways to extract optimal sentence embeddings. We test
various token aggregation and representation post-processing techniques. We
also test multiple ways of using a general Wikitext dataset to complement
BERT's sentence embeddings. All methods are tested on eight Semantic Textual
Similarity (STS), six short text clustering, and twelve classification tasks.
We also evaluate our representation-shaping techniques on other static models,
including random token representations. Proposed representation extraction
methods improve the performance on STS and clustering tasks for all models
considered. Very high improvements for static token-based models, especially
random embeddings for STS tasks, almost reach the performance of BERT-derived
representations. Our work shows that the representation-shaping techniques
significantly improve sentence embeddings extracted from BERT-based and simple
baseline models.",2024-08-15,"Lukas Stankevičius, Mantas Lukoševičius",http://arxiv.org/pdf/2408.08073v2,cs.CL
I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm,"Large Language Models (LLMs) have achieved significant advancements, however,
the common learning paradigm treats LLMs as passive information repositories,
neglecting their potential for active learning and alignment. Some approaches
train LLMs using their own generated synthetic data, exploring the possibility
of active alignment. However, there is still a huge gap between these one-time
alignment methods and the continuous automatic alignment of humans. In this
paper, we introduce \textbf{I-SHEEP}, an \textbf{I}terative
\textbf{S}elf-En\textbf{H}anc\textbf{E}m\textbf{E}nt \textbf{P}aradigm.This
human-like paradigm enables LLMs to \textbf{continuously self-align from
scratch with nothing}. Compared to the one-time alignment method Dromedary
\cite{sun2023principledriven}, which refers to the first iteration in this
paper, I-SHEEP can significantly enhance capacities on both Qwen and Llama
models. I-SHEEP achieves a maximum relative improvement of 78.2\% in the Alpaca
Eval, 24.0\% in the MT Bench, and an absolute increase of 8.88\% in the IFEval
accuracy over subsequent iterations in Qwen-1.5 72B model. Additionally,
I-SHEEP surpasses the base model in various standard benchmark generation
tasks, achieving an average improvement of 24.77\% in code generation tasks,
12.04\% in TrivialQA, and 20.29\% in SQuAD. We also provide new insights based
on the experiment results. Our codes, datasets, and models are available at
\textbf{https://anonymous.4open.science/r/I-SHEEP}.",2024-08-15,"Yiming Liang, Ge Zhang, Xingwei Qu, Tianyu Zheng, Jiawei Guo, Xinrun Du, Zhenzhu Yang, Jiaheng Liu, Chenghua Lin, Lei Ma, Wenhao Huang, Jiajun Zhang",http://arxiv.org/pdf/2408.08072v3,cs.CL
RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented Generation,"Despite Retrieval-Augmented Generation (RAG) showing promising capability in
leveraging external knowledge, a comprehensive evaluation of RAG systems is
still challenging due to the modular nature of RAG, evaluation of long-form
responses and reliability of measurements. In this paper, we propose a
fine-grained evaluation framework, RAGChecker, that incorporates a suite of
diagnostic metrics for both the retrieval and generation modules. Meta
evaluation verifies that RAGChecker has significantly better correlations with
human judgments than other evaluation metrics. Using RAGChecker, we evaluate 8
RAG systems and conduct an in-depth analysis of their performance, revealing
insightful patterns and trade-offs in the design choices of RAG architectures.
The metrics of RAGChecker can guide researchers and practitioners in developing
more effective RAG systems. This work has been open sourced at
https://github.com/amazon-science/RAGChecker.",2024-08-15,"Dongyu Ru, Lin Qiu, Xiangkun Hu, Tianhang Zhang, Peng Shi, Shuaichen Chang, Cheng Jiayang, Cunxiang Wang, Shichao Sun, Huanyu Li, Zizhao Zhang, Binjie Wang, Jiarong Jiang, Tong He, Zhiguo Wang, Pengfei Liu, Yue Zhang, Zheng Zhang",http://arxiv.org/pdf/2408.08067v2,cs.CL
Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework,"The conventional BIM authoring process typically requires designers to master
complex and tedious modeling commands in order to materialize their design
intentions within BIM authoring tools. This additional cognitive burden
complicates the design process and hinders the adoption of BIM and model-based
design in the AEC (Architecture, Engineering, and Construction) industry. To
facilitate the expression of design intentions more intuitively, we propose
Text2BIM, an LLM-based multi-agent framework that can generate 3D building
models from natural language instructions. This framework orchestrates multiple
LLM agents to collaborate and reason, transforming textual user input into
imperative code that invokes the BIM authoring tool's APIs, thereby generating
editable BIM models with internal layouts, external envelopes, and semantic
information directly in the software. Furthermore, a rule-based model checker
is introduced into the agentic workflow, utilizing predefined domain knowledge
to guide the LLM agents in resolving issues within the generated models and
iteratively improving model quality. Extensive experiments were conducted to
compare and analyze the performance of three different LLMs under the proposed
framework. The evaluation results demonstrate that our approach can effectively
generate high-quality, structurally rational building models that are aligned
with the abstract concepts specified by user input. Finally, an interactive
software prototype was developed to integrate the framework into the BIM
authoring software Vectorworks, showcasing the potential of modeling by
chatting.",2024-08-15,"Changyu Du, Sebastian Esser, Stavros Nousias, André Borrmann",http://arxiv.org/pdf/2408.08054v1,cs.CL
Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words,"We develop a large language model (LLM) based automatic speech recognition
(ASR) system that can be contextualized by providing keywords as prior
information in text prompts. We adopt decoder-only architecture and use our
in-house LLM, PLaMo-100B, pre-trained from scratch using datasets dominated by
Japanese and English texts as the decoder. We adopt a pre-trained Whisper
encoder as an audio encoder, and the audio embeddings from the audio encoder
are projected to the text embedding space by an adapter layer and concatenated
with text embeddings converted from text prompts to form inputs to the decoder.
By providing keywords as prior information in the text prompts, we can
contextualize our LLM-based ASR system without modifying the model architecture
to transcribe ambiguous words in the input audio accurately. Experimental
results demonstrate that providing keywords to the decoder can significantly
improve the recognition performance of rare and ambiguous words.",2024-08-15,"Kento Nozawa, Takashi Masuko, Toru Taniguchi",http://arxiv.org/pdf/2408.08027v2,cs.CL
Leveraging Web-Crawled Data for High-Quality Fine-Tuning,"Most large language models are fine-tuned using either expensive
human-annotated data or GPT-4 generated data which cannot guarantee performance
in certain domains. We argue that although the web-crawled data often has
formatting errors causing semantic inaccuracies, it can still serve as a
valuable source for high-quality supervised fine-tuning in specific domains
without relying on advanced models like GPT-4. To this end, we create a paired
training dataset automatically by aligning web-crawled data with a smaller set
of high-quality data. By training a language model on this dataset, we can
convert web data with irregular formats into high-quality ones. Our experiments
show that training with the model-transformed data yields better results,
surpassing training with only high-quality data by an average score of 9.4% in
Chinese math problems. Additionally, our 7B model outperforms several
open-source models larger than 32B and surpasses well-known closed-source
models such as GPT-3.5, highlighting the efficacy of our approach.",2024-08-15,"Jing Zhou, Chenglin Jiang, Wei Shen, Xiao Zhou, Xiaonan He",http://arxiv.org/pdf/2408.08003v1,cs.CL
FuseChat: Knowledge Fusion of Chat Models,"While training large language models (LLMs) from scratch can indeed lead to
models with distinct capabilities and strengths, it incurs substantial costs
and may lead to redundancy in competencies. Knowledge fusion aims to integrate
existing LLMs of diverse architectures and capabilities into a more potent LLM
through lightweight continual training, thereby reducing the need for costly
LLM development. In this work, we propose a new framework for the knowledge
fusion of chat LLMs through two main stages, resulting in FuseChat. Firstly, we
conduct pairwise knowledge fusion on source chat LLMs of varying structures and
scales to create multiple target LLMs with identical structure and size via
lightweight fine-tuning. During this process, a statistics-based token
alignment approach is introduced as the cornerstone for fusing LLMs with
different structures. Secondly, we merge these target LLMs within the parameter
space, where we propose a novel method for determining the merging coefficients
based on the magnitude of parameter updates before and after fine-tuning. We
implement and validate FuseChat using six prominent chat LLMs with diverse
architectures and scales, including OpenChat-3.5-7B, Starling-LM-7B-alpha,
NH2-SOLAR-10.7B, InternLM2-Chat-20B, Mixtral-8x7B-Instruct, and
Qwen-1.5-Chat-72B. Experimental results on two instruction-following
benchmarks, AlpacaEval 2.0 and MT-Bench, demonstrate the superiority of
FuseChat-7B over baselines of various sizes. Our model is even comparable to
the larger Mixtral-8x7B-Instruct and approaches GPT-3.5-Turbo-1106 on MT-Bench.
Our code, model weights, and data are public at
\url{https://github.com/fanqiwan/FuseAI}.",2024-08-15,"Fanqi Wan, Longguang Zhong, Ziyi Yang, Ruijun Chen, Xiaojun Quan",http://arxiv.org/pdf/2408.07990v1,cs.CL
ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models,"The rapid advancements in Large Language Models (LLMs) have led to
significant improvements in various natural language processing tasks. However,
the evaluation of LLMs' legal knowledge, particularly in non-English languages
such as Arabic, remains under-explored. To address this gap, we introduce
ArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal
knowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval
consists of multiple tasks sourced from Saudi legal documents and synthesized
questions. In this work, we aim to analyze the capabilities required to solve
legal problems in Arabic and benchmark the performance of state-of-the-art
LLMs. We explore the impact of in-context learning and investigate various
evaluation methods. Additionally, we explore workflows for generating questions
with automatic validation to enhance the dataset's quality. We benchmark
multilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We
also share our methodology for creating the dataset and validation, which can
be generalized to other domains. We hope to accelerate AI research in the
Arabic Legal domain by releasing the ArabLegalEval dataset and code:
https://github.com/Thiqah/ArabLegalEval",2024-08-15,"Faris Hijazi, Somayah AlHarbi, Abdulaziz AlHussein, Harethah Abu Shairah, Reem AlZahrani, Hebah AlShamlan, Omar Knio, George Turkiyyah",http://arxiv.org/pdf/2408.07983v1,cs.CL
Coupling without Communication and Drafter-Invariant Speculative Decoding,"Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alice
wants to draw a sample $a\sim P$ and Bob a sample $b \sim Q$ such that $a = b$
with as high of probability as possible. It is well-known that, by sampling
from an optimal coupling between the distributions, Alice and Bob can achieve
$\Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total variation
distance between $P$ and $Q$. What if Alice and Bob must solve this same
problem \emph{without communicating at all?} Perhaps surprisingly, with access
to public randomness, they can still achieve $\Pr[a = b] \geq \frac{1 -
D_{TV}(P,Q)}{1 + D_{TV}(P,Q)} \geq 1-2D_{TV}(P,Q)$ using a simple protocol
based on the Weighted MinHash algorithm. This bound was shown to be optimal in
the worst-case by [Bavarian et al., 2020]. In this work, we revisit the
communication-free coupling problem. We provide a simpler proof of the
optimality result from [Bavarian et al., 2020]. We show that, while the
worst-case success probability of Weighted MinHash cannot be improved, an
equally simple protocol based on Gumbel sampling offers a Pareto improvement:
for every pair of distributions $P, Q$, Gumbel sampling achieves an equal or
higher value of $\Pr[a = b]$ than Weighted MinHash. Importantly, this
improvement translates to practice. We demonstrate an application of
communication-free coupling to \emph{speculative decoding}, a recent method for
accelerating autoregressive large language models [Leviathan, Kalman, Matias,
ICML 2023]. We show that communication-free protocols can be used to contruct
\emph{\CSD{}} schemes, which have the desirable property that their output is
fixed given a fixed random seed, regardless of what drafter is used for
speculation. In experiments on a language generation task, Gumbel sampling
outperforms Weighted MinHash. Code is available at
https://github.com/majid-daliri/DISD.",2024-08-15,"Majid Daliri, Christopher Musco, Ananda Theertha Suresh",http://arxiv.org/pdf/2408.07978v3,cs.CL
Polaris: Open-ended Interactive Robotic Manipulation via Syn2Real Visual Grounding and Large Language Models,"This paper investigates the task of the open-ended interactive robotic
manipulation on table-top scenarios. While recent Large Language Models (LLMs)
enhance robots' comprehension of user instructions, their lack of visual
grounding constrains their ability to physically interact with the environment.
This is because the robot needs to locate the target object for manipulation
within the physical workspace. To this end, we introduce an interactive robotic
manipulation framework called Polaris, which integrates perception and
interaction by utilizing GPT-4 alongside grounded vision models. For precise
manipulation, it is essential that such grounded vision models produce detailed
object pose for the target object, rather than merely identifying pixels
belonging to them in the image. Consequently, we propose a novel
Synthetic-to-Real (Syn2Real) pose estimation pipeline. This pipeline utilizes
rendered synthetic data for training and is then transferred to real-world
manipulation tasks. The real-world performance demonstrates the efficacy of our
proposed pipeline and underscores its potential for extension to more general
categories. Moreover, real-robot experiments have showcased the impressive
performance of our framework in grasping and executing multiple manipulation
tasks. This indicates its potential to generalize to scenarios beyond the
tabletop. More information and video results are available here:
https://star-uu-wang.github.io/Polaris/",2024-08-15,"Tianyu Wang, Haitao Lin, Junqiu Yu, Yanwei Fu",http://arxiv.org/pdf/2408.07975v1,cs.CL
Predicting Lung Cancer Patient Prognosis with Large Language Models,"Prognosis prediction is crucial for determining optimal treatment plans for
lung cancer patients. Traditionally, such predictions relied on models
developed from retrospective patient data. Recently, large language models
(LLMs) have gained attention for their ability to process and generate text
based on extensive learned knowledge. In this study, we evaluate the potential
of GPT-4o mini and GPT-3.5 in predicting the prognosis of lung cancer patients.
We collected two prognosis datasets, i.e., survival and post-operative
complication datasets, and designed multiple tasks to assess the models'
performance comprehensively. Logistic regression models were also developed as
baselines for comparison. The experimental results demonstrate that LLMs can
achieve competitive, and in some tasks superior, performance in lung cancer
prognosis prediction compared to data-driven logistic regression models despite
not using additional patient data. These findings suggest that LLMs can be
effective tools for prognosis prediction in lung cancer, particularly when
patient data is limited or unavailable.",2024-08-15,"Danqing Hu, Bing Liu, Xiang Li, Xiaofeng Zhu, Nan Wu",http://arxiv.org/pdf/2408.07971v1,cs.CL
GERestaurant: A German Dataset of Annotated Restaurant Reviews for Aspect-Based Sentiment Analysis,"We present GERestaurant, a novel dataset consisting of 3,078 German language
restaurant reviews manually annotated for Aspect-Based Sentiment Analysis
(ABSA). All reviews were collected from Tripadvisor, covering a diverse
selection of restaurants, including regional and international cuisine with
various culinary styles. The annotations encompass both implicit and explicit
aspects, including all aspect terms, their corresponding aspect categories, and
the sentiments expressed towards them. Furthermore, we provide baseline scores
for the four ABSA tasks Aspect Category Detection, Aspect Category Sentiment
Analysis, End-to-End ABSA and Target Aspect Sentiment Detection as a reference
point for future advances. The dataset fills a gap in German language resources
and facilitates exploration of ABSA in the restaurant domain.",2024-08-15,"Nils Constantin Hellwig, Jakob Fehle, Markus Bink, Christian Wolff",http://arxiv.org/pdf/2408.07955v1,cs.CL
MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL,"Recent In-Context Learning based methods have achieved remarkable success in
Text-to-SQL task. However, there is still a large gap between the performance
of these models and human performance on datasets with complex database schema
and difficult questions, such as BIRD. Besides, existing work has neglected to
supervise intermediate steps when solving questions iteratively with question
decomposition methods, and the schema linking methods used in these works are
very rudimentary. To address these issues, we propose MAG-SQL, a multi-agent
generative approach with soft schema linking and iterative Sub-SQL refinement.
In our framework, an entity-based method with tables' summary is used to select
the columns in database, and a novel targets-conditions decomposition method is
introduced to decompose those complex questions. Additionally, we build a
iterative generating module which includes a Sub-SQL Generator and Sub-SQL
Refiner, introducing external oversight for each step of generation. Through a
series of ablation studies, the effectiveness of each agent in our framework
has been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL
achieves an execution accuracy of 61.08%, compared to the baseline accuracy of
46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL.
Besides, our approach makes similar progress on Spider. The codes are available
at https://github.com/LancelotXWX/MAG-SQL.",2024-08-15,"Wenxuan Xie, Gaochen Wu, Bowen Zhou",http://arxiv.org/pdf/2408.07930v4,cs.CL
Plan with Code: Comparing approaches for robust NL to DSL generation,"Planning in code is considered a more reliable approach for many
orchestration tasks. This is because code is more tractable than steps
generated via Natural Language and make it easy to support more complex
sequences by abstracting deterministic logic into functions. It also allows
spotting issues with incorrect function names with the help of parsing checks
that can be run on code. Progress in Code Generation methodologies, however,
remains limited to general-purpose languages like C, C++, and Python. LLMs
continue to face challenges with custom function names in Domain Specific
Languages or DSLs, leading to higher hallucination rates and syntax errors.
This is more common for custom function names, that are typically part of the
plan. Moreover, keeping LLMs up-to-date with newer function names is an issue.
This poses a challenge for scenarios like task planning over a large number of
APIs, since the plan is represented as a DSL having custom API names. In this
paper, we focus on workflow automation in RPA (Robotic Process Automation)
domain as a special case of task planning. We present optimizations for using
Retrieval Augmented Generation (or RAG) with LLMs for DSL generation along with
an ablation study comparing these strategies with a fine-tuned model. Our
results showed that the fine-tuned model scored the best on code similarity
metric. However, with our optimizations, RAG approach is able to match the
quality for in-domain API names in the test set. Additionally, it offers
significant advantage for out-of-domain or unseen API names, outperforming
Fine-Tuned model on similarity metric by 7 pts.",2024-08-15,"Nastaran Bassamzadeh, Chhaya Methani",http://arxiv.org/pdf/2408.08335v1,cs.CL
When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?,"The introduction of Large Language Models (LLMs) has advanced data
representation and analysis, bringing significant progress in their use for
medical questions and answering. Despite these advancements, integrating
tabular data, especially numerical data pivotal in clinical contexts, into LLM
paradigms has not been thoroughly explored. In this study, we examine the
effectiveness of vector representations from last hidden states of LLMs for
medical diagnostics and prognostics using electronic health record (EHR) data.
We compare the performance of these embeddings with that of raw numerical EHR
data when used as feature inputs to traditional machine learning (ML)
algorithms that excel at tabular data learning, such as eXtreme Gradient
Boosting. We focus on instruction-tuned LLMs in a zero-shot setting to
represent abnormal physiological data and evaluating their utilities as feature
extractors to enhance ML classifiers for predicting diagnoses, length of stay,
and mortality. Furthermore, we examine prompt engineering techniques on
zero-shot and few-shot LLM embeddings to measure their impact comprehensively.
Although findings suggest the raw data features still prevails in medical ML
tasks, zero-shot LLM embeddings demonstrate competitive results, suggesting a
promising avenue for future research in medical applications.",2024-08-15,"Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Matthew Churpek, Majid Afshar",http://arxiv.org/pdf/2408.11854v2,cs.CL
DM2RM: Dual-Mode Multimodal Ranking for Target Objects and Receptacles Based on Open-Vocabulary Instructions,"In this study, we aim to develop a domestic service robot (DSR) that, guided
by open-vocabulary instructions, can carry everyday objects to the specified
pieces of furniture. Few existing methods handle mobile manipulation tasks with
open-vocabulary instructions in the image retrieval setting, and most do not
identify both the target objects and the receptacles. We propose the Dual-Mode
Multimodal Ranking model (DM2RM), which enables images of both the target
objects and receptacles to be retrieved using a single model based on
multimodal foundation models. We introduce a switching mechanism that leverages
a mode token and phrase identification via a large language model to switch the
embedding space based on the prediction target. To evaluate the DM2RM, we
construct a novel dataset including real-world images collected from hundreds
of building-scale environments and crowd-sourced instructions with referring
expressions. The evaluation results show that the proposed DM2RM outperforms
previous approaches in terms of standard metrics in image retrieval settings.
Furthermore, we demonstrate the application of the DM2RM on a standardized
real-world DSR platform including fetch-and-carry actions, where it achieves a
task success rate of 82% despite the zero-shot transfer setting. Demonstration
videos, code, and more materials are available at
https://kkrr10.github.io/dm2rm/.",2024-08-15,"Ryosuke Korekata, Kanta Kaneda, Shunya Nagashima, Yuto Imai, Komei Sugiura",http://arxiv.org/pdf/2408.07910v1,cs.CL
Assessing Language Models' Worldview for Fiction Generation,"The use of Large Language Models (LLMs) has become ubiquitous, with abundant
applications in computational creativity. One such application is fictional
story generation. Fiction is a narrative that occurs in a story world that is
slightly different than ours. With LLMs becoming writing partners, we question
how suitable they are to generate fiction. This study investigates the ability
of LLMs to maintain a state of world essential to generate fiction. Through a
series of questions to nine LLMs, we find that only two models exhibit
consistent worldview, while the rest are self-conflicting. Subsequent analysis
of stories generated by four models revealed a strikingly uniform narrative
pattern. This uniformity across models further suggests a lack of `state'
necessary for fiction. We highlight the limitations of current LLMs in fiction
writing and advocate for future research to test and create story worlds for
LLMs to reside in. All code, dataset, and the generated responses can be found
in https://github.com/tanny411/llm-reliability-and-consistency-evaluation.",2024-08-15,"Aisha Khatun, Daniel G. Brown",http://arxiv.org/pdf/2408.07904v1,cs.CL
Cross-Modal Denoising: A Novel Training Paradigm for Enhancing Speech-Image Retrieval,"The success of speech-image retrieval relies on establishing an effective
alignment between speech and image. Existing methods often model cross-modal
interaction through simple cosine similarity of the global feature of each
modality, which fall short in capturing fine-grained details within modalities.
To address this issue, we introduce an effective framework and a novel learning
task named cross-modal denoising (CMD) to enhance cross-modal interaction to
achieve finer-level cross-modal alignment. Specifically, CMD is a denoising
task designed to reconstruct semantic features from noisy features within one
modality by interacting features from another modality. Notably, CMD operates
exclusively during model training and can be removed during inference without
adding extra inference time. The experimental results demonstrate that our
framework outperforms the state-of-the-art method by 2.0% in mean R@1 on the
Flickr8k dataset and by 1.7% in mean R@1 on the SpokenCOCO dataset for the
speech-image retrieval tasks, respectively. These experimental results validate
the efficiency and effectiveness of our framework.",2024-08-15,"Lifeng Zhou, Yuke Li, Rui Deng, Yuting Yang, Haoqi Zhu",http://arxiv.org/pdf/2408.13705v2,cs.CL
Evaluating Fine-Tuning Efficiency of Human-Inspired Learning Strategies in Medical Question Answering,"Fine-tuning Large Language Models (LLMs) incurs considerable training costs,
driving the need for data-efficient training with optimised data ordering.
Human-inspired strategies offer a solution by organising data based on human
learning practices. This study evaluates the fine-tuning efficiency of five
human-inspired strategies across four language models, three datasets, and both
human- and LLM-labelled data in the context of medical question answering.
These strategies achieve the best accuracy gain of 1.81% and an average gain of
1.02% across datasets, with interleaved strategies delivering the best average
results. However, the best strategy varies across model-dataset combinations,
limiting the generalisability of the effects of any single strategy.
Additionally, LLM-defined question difficulty outperforms human-defined labels
in curriculum-based learning, showing the potential of model-generated data as
a cost-effective alternative for optimising fine-tuning.",2024-08-15,"Yushi Yang, Andrew M. Bean, Robert McCraith, Adam Mahdi",http://arxiv.org/pdf/2408.07888v2,cs.CL
Coarse-to-fine Alignment Makes Better Speech-image Retrieval,"In this paper, we propose a novel framework for speech-image retrieval. We
utilize speech-image contrastive (SIC) learning tasks to align speech and image
representations at a coarse level and speech-image matching (SIM) learning
tasks to further refine the fine-grained cross-modal alignment. SIC and SIM
learning tasks are jointly trained in a unified manner. To optimize the
learning process, we utilize an embedding queue that facilitates efficient
sampling of high-quality and diverse negative representations during SIC
learning. Additionally, it enhances the learning of SIM tasks by effectively
mining hard negatives based on contrastive similarities calculated in SIC
tasks. To further optimize learning under noisy supervision, we incorporate
momentum distillation into the training process. Experimental results show that
our framework outperforms the state-of-the-art method by more than 4% in R@1 on
two benchmark datasets for the speech-image retrieval tasks. Moreover, as
observed in zero-shot experiments, our framework demonstrates excellent
generalization capabilities.",2024-08-15,"Lifeng Zhou, Yuke Li",http://arxiv.org/pdf/2408.13119v2,cs.CL
Instruct Large Language Models to Generate Scientific Literature Survey Step by Step,"Abstract. Automatically generating scientific literature surveys is a
valuable task that can significantly enhance research efficiency. However, the
diverse and complex nature of information within a literature survey poses
substantial challenges for generative models. In this paper, we design a series
of prompts to systematically leverage large language models (LLMs), enabling
the creation of comprehensive literature surveys through a step-by-step
approach. Specifically, we design prompts to guide LLMs to sequentially
generate the title, abstract, hierarchical headings, and the main content of
the literature survey. We argue that this design enables the generation of the
headings from a high-level perspective. During the content generation process,
this design effectively harnesses relevant information while minimizing costs
by restricting the length of both input and output content in LLM queries. Our
implementation with Qwen-long achieved third place in the NLPCC 2024 Scientific
Literature Survey Generation evaluation task, with an overall score only 0.03%
lower than the second-place team. Additionally, our soft heading recall is
95.84%, the second best among the submissions. Thanks to the efficient prompt
design and the low cost of the Qwen-long API, our method reduces the expense
for generating each literature survey to 0.1 RMB, enhancing the practical value
of our method.",2024-08-15,"Yuxuan Lai, Yupeng Wu, Yidan Wang, Wenpeng Hu, Chen Zheng",http://arxiv.org/pdf/2408.07884v1,cs.CL
PyMarian: Fast Neural Machine Translation and Evaluation in Python,"The deep learning language of choice these days is Python; measured by
factors such as available libraries and technical support, it is hard to beat.
At the same time, software written in lower-level programming languages like
C++ retain advantages in speed. We describe a Python interface to Marian NMT, a
C++-based training and inference toolkit for sequence-to-sequence models,
focusing on machine translation. This interface enables models trained with
Marian to be connected to the rich, wide range of tools available in Python. A
highlight of the interface is the ability to compute state-of-the-art COMET
metrics from Python but using Marian's inference engine, with a speedup factor
of up to 7.8$\times$ the existing implementations. We also briefly spotlight a
number of other integrations, including Jupyter notebooks, connection with
prebuilt models, and a web app interface provided with the package. PyMarian is
available in PyPI via $\texttt{pip install pymarian}$.",2024-08-15,"Thamme Gowda, Roman Grundkiewicz, Elijah Rippeth, Matt Post, Marcin Junczys-Dowmunt",http://arxiv.org/pdf/2408.11853v1,cs.CL
Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models,"Stigma is a barrier to treatment for individuals struggling with substance
use disorders (SUD), which leads to significantly lower treatment engagement
rates. With only 7% of those affected receiving any form of help, societal
stigma not only discourages individuals with SUD from seeking help but isolates
them, hindering their recovery journey and perpetuating a cycle of shame and
self-doubt. This study investigates how stigma manifests on social media,
particularly Reddit, where anonymity can exacerbate discriminatory behaviors.
We analyzed over 1.2 million posts, identifying 3,207 that exhibited
stigmatizing language towards people who use substances (PWUS). Using Informed
and Stylized LLMs, we develop a model for de-stigmatization of these
expressions into empathetic language, resulting in 1,649 reformed phrase pairs.
Our paper contributes to the field by proposing a computational framework for
analyzing stigma and destigmatizing online content, and delving into the
linguistic features that propagate stigma towards PWUS. Our work not only
enhances understanding of stigma's manifestations online but also provides
practical tools for fostering a more supportive digital environment for those
affected by SUD. Code and data will be made publicly available upon acceptance.",2024-08-15,"Layla Bouzoubaa, Elham Aghakhani, Rezvaneh Rezapour",http://arxiv.org/pdf/2408.07873v1,cs.CL
Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability,"While many capabilities of language models (LMs) improve with increased
training budget, the influence of scale on hallucinations is not yet fully
understood. Hallucinations come in many forms, and there is no universally
accepted definition. We thus focus on studying only those hallucinations where
a correct answer appears verbatim in the training set. To fully control the
training data content, we construct a knowledge graph (KG)-based dataset, and
use it to train a set of increasingly large LMs. We find that for a fixed
dataset, larger and longer-trained LMs hallucinate less. However, hallucinating
on $\leq5$% of the training data requires an order of magnitude larger model,
and thus an order of magnitude more compute, than Hoffmann et al. (2022)
reported was optimal. Given this costliness, we study how hallucination
detectors depend on scale. While we see detector size improves performance on
fixed LM's outputs, we find an inverse relationship between the scale of the LM
and the detectability of its hallucinations.",2024-08-14,"Jiri Hron, Laura Culp, Gamaleldin Elsayed, Rosanne Liu, Ben Adlam, Maxwell Bileschi, Bernd Bohnet, JD Co-Reyes, Noah Fiedel, C. Daniel Freeman, Izzeddin Gur, Kathleen Kenealy, Jaehoon Lee, Peter J. Liu, Gaurav Mishra, Igor Mordatch, Azade Nova, Roman Novak, Aaron Parisi, Jeffrey Pennington, Alex Rizkowsky, Isabelle Simpson, Hanie Sedghi, Jascha Sohl-dickstein, Kevin Swersky, Sharad Vikram, Tris Warkentin, Lechao Xiao, Kelvin Xu, Jasper Snoek, Simon Kornblith",http://arxiv.org/pdf/2408.07852v1,cs.CL
SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition,"Speech emotion recognition (SER) has made significant strides with the advent
of powerful self-supervised learning (SSL) models. However, the generalization
of these models to diverse languages and emotional expressions remains a
challenge. We propose a large-scale benchmark to evaluate the robustness and
adaptability of state-of-the-art SER models in both in-domain and out-of-domain
settings. Our benchmark includes a diverse set of multilingual datasets,
focusing on less commonly used corpora to assess generalization to new data. We
employ logit adjustment to account for varying class distributions and
establish a single dataset cluster for systematic evaluation. Surprisingly, we
find that the Whisper model, primarily designed for automatic speech
recognition, outperforms dedicated SSL models in cross-lingual SER. Our results
highlight the need for more robust and generalizable SER models, and our
benchmark serves as a valuable resource to drive future research in this
direction.",2024-08-14,"Mohamed Osman, Daniel Z. Kaplan, Tamer Nadeem",http://arxiv.org/pdf/2408.07851v1,cs.CL
CodeMirage: Hallucinations in Code Generated by Large Language Models,"Large Language Models (LLMs) have shown promising potentials in program
generation and no-code automation. However, LLMs are prone to generate
hallucinations, i.e., they generate text which sounds plausible but is
incorrect. Although there has been a recent surge in research on LLM
hallucinations for text generation, similar hallucination phenomenon can happen
in code generation. Sometimes the generated code can have syntactical or
logical errors as well as more advanced issues like security vulnerabilities,
memory leaks, etc. Given the wide adaptation of LLMs to enhance efficiency in
code generation and development in general, it becomes imperative to
investigate hallucinations in code generation. To the best of our knowledge,
this is the first attempt at studying hallucinations in the code generated by
LLMs. We start by introducing the code hallucination definition and a
comprehensive taxonomy of code hallucination types. We propose the first
benchmark CodeMirage dataset for code hallucinations. The benchmark contains
1,137 GPT-3.5 generated hallucinated code snippets for Python programming
problems from two base datasets - HumanEval and MBPP. We then propose the
methodology for code hallucination detection and experiment with open source
LLMs such as CodeLLaMA as well as OpenAI's GPT-3.5 and GPT-4 models using
one-shot prompt. We find that GPT-4 performs the best on HumanEval dataset and
gives comparable results to the fine-tuned CodeBERT baseline on MBPP dataset.
Towards the end, we discuss various mitigation strategies for code
hallucinations and conclude our work.",2024-08-14,"Vibhor Agarwal, Yulong Pei, Salwa Alamir, Xiaomo Liu",http://arxiv.org/pdf/2408.08333v1,cs.CL
ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model,"In the realm of event prediction, temporal knowledge graph forecasting (TKGF)
stands as a pivotal technique. Previous approaches face the challenges of not
utilizing experience during testing and relying on a single short-term history,
which limits adaptation to evolving data. In this paper, we introduce the
Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by
integrating dynamic causal rule mining (DCRM) and dual history augmented
generation (DHAG). DCRM dynamically constructs causal rules from real-time
data, allowing for swift adaptation to new causal relationships. In parallel,
DHAG merges short-term and long-term historical contexts, leveraging a
bi-branch approach to enrich event prediction. Our framework demonstrates
notable performance enhancements across diverse datasets, with significant
Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language
models (LLMs) for event prediction without necessitating extensive retraining.
The ONSEP framework not only advances the field of TKGF but also underscores
the potential of neural-symbolic approaches in adapting to dynamic data
environments.",2024-08-14,"Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, Jie Tan",http://arxiv.org/pdf/2408.07840v1,cs.CL
Fast Training Dataset Attribution via In-Context Learning,"We investigate the use of in-context learning and prompt engineering to
estimate the contributions of training data in the outputs of instruction-tuned
large language models (LLMs). We propose two novel approaches: (1) a
similarity-based approach that measures the difference between LLM outputs with
and without provided context, and (2) a mixture distribution model approach
that frames the problem of identifying contribution scores as a matrix
factorization task. Our empirical comparison demonstrates that the mixture
model approach is more robust to retrieval noise in in-context learning,
providing a more reliable estimation of data contributions.",2024-08-14,"Milad Fotouhi, Mohammad Taha Bahadori, Oluwaseyi Feyisetan, Payman Arabshahi, David Heckerman",http://arxiv.org/pdf/2408.11852v2,cs.CL
The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models,"Schema linking is a crucial step in Text-to-SQL pipelines. Its goal is to
retrieve the relevant tables and columns of a target database for a user's
query while disregarding irrelevant ones. However, imperfect schema linking can
often exclude required columns needed for accurate query generation. In this
work, we revisit schema linking when using the latest generation of large
language models (LLMs). We find empirically that newer models are adept at
utilizing relevant schema elements during generation even in the presence of
large numbers of irrelevant ones. As such, our Text-to-SQL pipeline entirely
forgoes schema linking in cases where the schema fits within the model's
context window in order to minimize issues due to filtering required schema
elements. Furthermore, instead of filtering contextual information, we
highlight techniques such as augmentation, selection, and correction, and adopt
them to improve the accuracy of our Text-to-SQL pipeline. Our approach ranks
first on the BIRD benchmark achieving an accuracy of 71.83%.",2024-08-14,"Karime Maamari, Fadhil Abubaker, Daniel Jaroslawicz, Amine Mhedhbi",http://arxiv.org/pdf/2408.07702v2,cs.CL
Quantifying over Optimum Answer Sets,"Answer Set Programming with Quantifiers (ASP(Q)) has been introduced to
provide a natural extension of ASP modeling to problems in the polynomial
hierarchy (PH). However, ASP(Q) lacks a method for encoding in an elegant and
compact way problems requiring a polynomial number of calls to an oracle in
$\Sigma_n^p$ (that is, problems in $\Delta_{n+1}^p$). Such problems include, in
particular, optimization problems. In this paper we propose an extension of
ASP(Q), in which component programs may contain weak constraints. Weak
constraints can be used both for expressing local optimization within
quantified component programs and for modeling global optimization criteria. We
showcase the modeling capabilities of the new formalism through various
application scenarios. Further, we study its computational properties obtaining
complexity results and unveiling non-obvious characteristics of ASP(Q) programs
with weak constraints.",2024-08-14,"Giuseppe Mazzotta, Francesco Ricca, Mirek Truszczynski",http://arxiv.org/pdf/2408.07697v1,cs.CL
Enhanced Detection of Conversational Mental Manipulation Through Advanced Prompting Techniques,"This study presents a comprehensive, long-term project to explore the
effectiveness of various prompting techniques in detecting dialogical mental
manipulation. We implement Chain-of-Thought prompting with Zero-Shot and
Few-Shot settings on a binary mental manipulation detection task, building upon
existing work conducted with Zero-Shot and Few- Shot prompting. Our primary
objective is to decipher why certain prompting techniques display superior
performance, so as to craft a novel framework tailored for detection of mental
manipulation. Preliminary findings suggest that advanced prompting techniques
may not be suitable for more complex models, if they are not trained through
example-based learning.",2024-08-14,"Ivory Yang, Xiaobo Guo, Sean Xie, Soroush Vosoughi",http://arxiv.org/pdf/2408.07676v1,cs.CL
"Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities","Model merging is an efficient empowerment technique in the machine learning
community that does not require the collection of raw training data and does
not require expensive computation. As model merging becomes increasingly
prevalent across various fields, it is crucial to understand the available
model merging techniques comprehensively. However, there is a significant gap
in the literature regarding a systematic and thorough review of these
techniques. This survey provides a comprehensive overview of model merging
methods and theories, their applications in various domains and settings, and
future research directions. Specifically, we first propose a new taxonomic
approach that exhaustively discusses existing model merging methods. Secondly,
we discuss the application of model merging techniques in large language
models, multimodal large language models, and 10+ machine learning subfields,
including continual learning, multi-task learning, few-shot learning, etc.
Finally, we highlight the remaining challenges of model merging and discuss
future research directions. A comprehensive list of papers about model merging
is available at
\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.",2024-08-14,"Enneng Yang, Li Shen, Guibing Guo, Xingwei Wang, Xiaochun Cao, Jie Zhang, Dacheng Tao",http://arxiv.org/pdf/2408.07666v4,cs.CL
Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models,"Warning: This paper may contain texts with uncomfortable content.
  Large Language Models (LLMs) have achieved remarkable performance in various
tasks, including those involving multimodal data like speech. However, these
models often exhibit biases due to the nature of their training data. Recently,
more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent
need to address these biases. This study introduces Spoken Stereoset, a dataset
specifically designed to evaluate social biases in SLLMs. By examining how
different models respond to speech from diverse demographic groups, we aim to
identify these biases. Our experiments reveal significant insights into their
performance and bias levels. The findings indicate that while most models show
minimal bias, some still exhibit slightly stereotypical or anti-stereotypical
tendencies.",2024-08-14,"Yi-Cheng Lin, Wei-Chih Chen, Hung-yi Lee",http://arxiv.org/pdf/2408.07665v1,cs.CL
Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions,"Large language models are susceptible to jailbreak attacks, which can result
in the generation of harmful content. While prior defenses mitigate these risks
by perturbing or inspecting inputs, they ignore competing objectives, the
underlying cause of alignment failures. In this paper, we propose
Alignment-Enhanced Decoding (AED), a novel defense that employs adaptive
decoding to address the root causes of jailbreak issues. We first define the
Competitive Index to quantify alignment failures and utilize feedback from
self-evaluation to compute post-alignment logits. Then, AED adaptively combines
AED and post-alignment logits with the original logits to obtain harmless and
helpful distributions. Consequently, our method enhances safety alignment while
maintaining helpfulness. We conduct experiments across five models and four
common jailbreaks, with the results validating the effectiveness of our
approach. Code is available at https://github.com/GIGABaozi/AED.git.",2024-08-14,"Quan Liu, Zhenhong Zhou, Longzhu He, Yi Liu, Wei Zhang, Sen Su",http://arxiv.org/pdf/2408.07663v2,cs.CL
See It All: Contextualized Late Aggregation for 3D Dense Captioning,"3D dense captioning is a task to localize objects in a 3D scene and generate
descriptive sentences for each object. Recent approaches in 3D dense captioning
have adopted transformer encoder-decoder frameworks from object detection to
build an end-to-end pipeline without hand-crafted components. However, these
approaches struggle with contradicting objectives where a single query
attention has to simultaneously view both the tightly localized object regions
and contextual environment. To overcome this challenge, we introduce SIA
(See-It-All), a transformer pipeline that engages in 3D dense captioning with a
novel paradigm called late aggregation. SIA simultaneously decodes two sets of
queries-context query and instance query. The instance query focuses on
localization and object attribute descriptions, while the context query
versatilely captures the region-of-interest of relationships between multiple
objects or with the global scene, then aggregated afterwards (i.e., late
aggregation) via simple distance-based measures. To further enhance the quality
of contextualized caption generation, we design a novel aggregator to generate
a fully informed caption based on the surrounding context, the global
environment, and object instances. Extensive experiments on two of the most
widely-used 3D dense captioning datasets demonstrate that our proposed method
achieves a significant improvement over prior methods.",2024-08-14,"Minjung Kim, Hyung Suk Lim, Seung Hwan Kim, Soonyoung Lee, Bumsoo Kim, Gunhee Kim",http://arxiv.org/pdf/2408.07648v1,cs.CL
Hierarchical Working Memory and a New Magic Number,"The extremely limited working memory span, typically around four items,
contrasts sharply with our everyday experience of processing much larger
streams of sensory information concurrently. This disparity suggests that
working memory can organize information into compact representations such as
chunks, yet the underlying neural mechanisms remain largely unknown. Here, we
propose a recurrent neural network model for chunking within the framework of
the synaptic theory of working memory. We showed that by selectively
suppressing groups of stimuli, the network can maintain and retrieve the
stimuli in chunks, hence exceeding the basic capacity. Moreover, we show that
our model can dynamically construct hierarchical representations within working
memory through hierarchical chunking. A consequence of this proposed mechanism
is a new limit on the number of items that can be stored and subsequently
retrieved from working memory, depending only on the basic working memory
capacity when chunking is not invoked. Predictions from our model were
confirmed by analyzing single-unit responses in epileptic patients and memory
experiments with verbal material. Our work provides a novel conceptual and
analytical framework for understanding the on-the-fly organization of
information in the brain that is crucial for cognition.",2024-08-14,"Weishun Zhong, Mikhail Katkov, Misha Tsodyks",http://arxiv.org/pdf/2408.07637v1,cs.CL
WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs,"Large Language Models (LLMs) have greatly contributed to the development of
adaptive intelligent agents and are positioned as an important way to achieve
Artificial General Intelligence (AGI). However, LLMs are prone to produce
factually incorrect information and often produce ""phantom"" content that
undermines their reliability, which poses a serious challenge for their
deployment in real-world scenarios. Enhancing LLMs by combining external
databases and information retrieval mechanisms is an effective path. To address
the above challenges, we propose a new approach called WeKnow-RAG, which
integrates Web search and Knowledge Graphs into a ""Retrieval-Augmented
Generation (RAG)"" system. First, the accuracy and reliability of LLM responses
are improved by combining the structured representation of Knowledge Graphs
with the flexibility of dense vector retrieval. WeKnow-RAG then utilizes
domain-specific knowledge graphs to satisfy a variety of queries and domains,
thereby improving performance on factual information and complex reasoning
tasks by employing multi-stage web page retrieval techniques using both sparse
and dense retrieval methods. Our approach effectively balances the efficiency
and accuracy of information retrieval, thus improving the overall retrieval
process. Finally, we also integrate a self-assessment mechanism for the LLM to
evaluate the trustworthiness of the answers it generates. Our approach proves
its outstanding effectiveness in a wide range of offline experiments and online
submissions.",2024-08-14,"Weijian Xie, Xuefeng Liang, Yuhui Liu, Kaihua Ni, Hong Cheng, Zetian Hu",http://arxiv.org/pdf/2408.07611v2,cs.CL
Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations,"While cross-linguistic model transfer is effective in many settings, there is
still limited understanding of the conditions under which it works. In this
paper, we focus on assessing the role of lexical semantics in cross-lingual
transfer, as we compare its impact to that of other language properties.
Examining each language property individually, we systematically analyze how
differences between English and a target language influence the capacity to
align the language with an English pretrained representation space. We do so by
artificially manipulating the English sentences in ways that mimic specific
characteristics of the target language, and reporting the effect of each
manipulation on the quality of alignment with the representation space. We show
that while properties such as the script or word order only have a limited
impact on alignment quality, the degree of lexical matching between the two
languages, which we define using a measure of translation entropy, greatly
affects it.",2024-08-14,"Roy Ilani, Taelin Karidi, Omri Abend",http://arxiv.org/pdf/2408.07599v1,cs.CL
Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey,"With significant advancements in Transformers LLMs, NLP has extended its
reach into many research fields due to its enhanced capabilities in text
generation and user interaction. One field benefiting greatly from these
advancements is cybersecurity. In cybersecurity, many parameters that need to
be protected and exchanged between senders and receivers are in the form of
text and tabular data, making NLP a valuable tool in enhancing the security
measures of communication protocols. This survey paper provides a comprehensive
analysis of the utilization of Transformers and LLMs in cyber-threat detection
systems. The methodology of paper selection and bibliometric analysis is
outlined to establish a rigorous framework for evaluating existing research.
The fundamentals of Transformers are discussed, including background
information on various cyber-attacks and datasets commonly used in this field.
The survey explores the application of Transformers in IDSs, focusing on
different architectures such as Attention-based models, LLMs like BERT and GPT,
CNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.
Furthermore, it explores the diverse environments and applications where
Transformers and LLMs-based IDS have been implemented, including computer
networks, IoT devices, critical infrastructure protection, cloud computing,
SDN, as well as in autonomous vehicles. The paper also addresses research
challenges and future directions in this area, identifying key issues such as
interpretability, scalability, and adaptability to evolving threats, and more.
Finally, the conclusion summarizes the findings and highlights the significance
of Transformers and LLMs in enhancing cyber-threat detection capabilities,
while also outlining potential avenues for further research and development.",2024-08-14,Hamza Kheddar,http://arxiv.org/pdf/2408.07583v2,cs.CL
MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark,"With the development of Multimodal Large Language Models (MLLMs), the
evaluation of multimodal models in the context of mathematical problems has
become a valuable research field. Multimodal visual-textual mathematical
reasoning serves as a critical indicator for evaluating the comprehension and
complex multi-step quantitative reasoning abilities of MLLMs. However, previous
multimodal math benchmarks have not sufficiently integrated visual and textual
information. To address this gap, we proposed MathScape, a new benchmark that
emphasizes the understanding and application of combined visual and textual
information. MathScape is designed to evaluate photo-based math problem
scenarios, assessing the theoretical understanding and application ability of
MLLMs through a categorical hierarchical approach. We conduct a
multi-dimensional evaluation on 11 advanced MLLMs, revealing that our benchmark
is challenging even for the most sophisticated models. By analyzing the
evaluation results, we identify the limitations of MLLMs, offering valuable
insights for enhancing model performance.",2024-08-14,"Minxuan Zhou, Hao Liang, Tianpeng Li, Zhiyu Wu, Mingan Lin, Linzhuang Sun, Yaqi Zhou, Yan Zhang, Xiaoqin Huang, Yicong Chen, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou",http://arxiv.org/pdf/2408.07543v4,cs.CL
Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments,"Emergency department (ED) overcrowding and the complexity of rapid
decision-making in critical care settings pose significant challenges to
healthcare systems worldwide. While clinical decision support systems (CDSS)
have shown promise, the integration of large language models (LLMs) offers new
possibilities for enhancing triage accuracy and clinical decision-making. This
study presents an LLM-driven CDSS designed to assist ED physicians and nurses
in patient triage, treatment planning, and overall emergency care management.
  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,
orchestrated by CrewAI and Langchain. The system comprises four AI agents
emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED
Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for
triage assessment and integrates with the RxNorm API for medication management.
  The model was evaluated using the Asclepius dataset, with performance
assessed by a clinical emergency medicine specialist. The CDSS demonstrated
high accuracy in triage decision-making compared to the baseline of a
single-agent system. Furthermore, the system exhibited strong performance in
critical areas, including primary diagnosis, critical findings identification,
disposition decision-making, treatment planning, and resource allocation.
  Our multi-agent CDSS demonstrates significant potential for supporting
comprehensive emergency care management. By leveraging state-of-the-art AI
technologies, this system offers a scalable and adaptable tool that could
enhance emergency medical care delivery, potentially alleviating ED
overcrowding and improving patient outcomes. This work contributes to the
growing field of AI applications in emergency medicine and offers a promising
direction for future research and clinical implementation.",2024-08-14,"Seungjun Han, Wongyung Choi",http://arxiv.org/pdf/2408.07531v2,cs.CL
Large Language Models Know What Makes Exemplary Contexts,"In-context learning (ICL) has proven to be a significant capability with the
advancement of Large Language models (LLMs). By instructing LLMs using few-shot
demonstrative examples, ICL enables them to perform a wide range of tasks
without needing to update millions of parameters. This paper presents a unified
framework for LLMs that allows them to self-select influential in-context
examples to compose their contexts; self-rank candidates with different
demonstration compositions; self-optimize the demonstration selection and
ordering through reinforcement learning. Specifically, our method designs a
parameter-efficient retrieval head that generates the optimized demonstration
after training with rewards from LLM's own preference. Experimental results
validate the proposed method's effectiveness in enhancing ICL performance.
Additionally, our approach effectively identifies and selects the most
representative examples for the current task, and includes more diversity in
retrieval.",2024-08-14,"Quanyu Long, Jianda Chen, Wenya Wang, Sinno Jialin Pan",http://arxiv.org/pdf/2408.07505v2,cs.CL
A Study on Bias Detection and Classification in Natural Language Processing,"Human biases have been shown to influence the performance of models and
algorithms in various fields, including Natural Language Processing. While the
study of this phenomenon is garnering focus in recent years, the available
resources are still relatively scarce, often focusing on different forms or
manifestations of biases. The aim of our work is twofold: 1) gather
publicly-available datasets and determine how to better combine them to
effectively train models in the task of hate speech detection and
classification; 2) analyse the main issues with these datasets, such as
scarcity, skewed resources, and reliance on non-persistent data. We discuss
these issues in tandem with the development of our experiments, in which we
show that the combinations of different datasets greatly impact the models'
performance.",2024-08-14,"Ana Sofia Evans, Helena Moniz, Luísa Coheur",http://arxiv.org/pdf/2408.07479v1,cs.CL
Bridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization,"Direct preference optimization (DPO), a widely adopted offline preference
optimization algorithm, aims to align large language models (LLMs) with
human-desired behaviors using pairwise preference data. However, the generation
of the winning response and the losing response within pairwise data are
typically isolated, leading to weak correlations between them as well as
suboptimal alignment performance. To address this issue, we propose an
effective framework for Bridging and Modeling Correlations in pairwise data,
named BMC. Firstly, we increase the consistency and informativeness of the
pairwise preference signals through targeted modifications, synthesizing a
pseudo-winning response by improving the losing response with the winning
response as a reference. Secondly, we identify that DPO alone is insufficient
to model these correlations and capture nuanced variations. Therefore, we
propose learning token-level correlations by dynamically leveraging the policy
model's confidence during training. Comprehensive experiments on QA, math, and
instruction-following tasks demonstrate the effectiveness of our approach,
significantly surpassing competitive baselines, including DPO. Additionally,
our in-depth quantitative analysis reveals the reasons behind our method's
superior performance over DPO and showcases its versatility to other DPO
variants. We release our repository at https://github.com/YJiangcm/BMC.",2024-08-14,"Yuxin Jiang, Bo Huang, Yufei Wang, Xingshan Zeng, Liangyou Li, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Wei Wang",http://arxiv.org/pdf/2408.07471v4,cs.CL
Large Language Models Prompting With Episodic Memory,"Prompt optimization is essential for enhancing the performance of Large
Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks,
particularly in scenarios of few-shot learning where training examples are
incorporated directly into the prompt. Despite the growing interest in
optimizing prompts with few-shot examples, existing methods for prompt
optimization are often resource-intensive or perform inadequately. In this
work, we propose PrOmpting with Episodic Memory (POEM), a novel prompt
optimization technique that is simple, efficient, and demonstrates strong
generalization capabilities. We approach prompt optimization as a Reinforcement
Learning (RL) challenge, using episodic memory to archive combinations of input
data, permutations of few-shot examples, and the rewards observed during
training. In the testing phase, we optimize the sequence of examples for each
test query by selecting the sequence that yields the highest total rewards from
the top-k most similar training examples in the episodic memory. Our results
show that POEM outperforms recent techniques like TEMPERA and RLPrompt by over
5.3% in various text classification tasks. Furthermore, our approach adapts
well to broader language understanding tasks, consistently outperforming
conventional heuristic methods for ordering examples.",2024-08-14,"Dai Do, Quan Tran, Svetha Venkatesh, Hung Le",http://arxiv.org/pdf/2408.07465v1,cs.CL
From Brazilian Portuguese to European Portuguese,"Brazilian Portuguese and European Portuguese are two varieties of the same
language and, despite their close similarities, they exhibit several
differences. However, there is a significant disproportion in the availability
of resources between the two variants, with Brazilian Portuguese having more
abundant resources. This inequity can impact the quality of translation
services accessible to European Portuguese speakers. To address this issue, we
propose the development of a Brazilian Portuguese to European Portuguese
translation system, leveraging recent advancements in neural architectures and
models. To evaluate the performance of such systems, we manually curated a gold
test set comprising 500 sentences across five different topics. Each sentence
in the gold test set has two distinct references, facilitating a
straightforward evaluation of future translation models. We experimented with
various models by fine-tuning existing Large Language Models using parallel
data extracted from movie subtitles and TED Talks transcripts in both Brazilian
and European Portuguese. Our evaluation involved the use of conventional
automatic metrics as well as a human evaluation. In addition, all models were
compared against ChatGPT 3.5 Turbo, which currently yields the best results.",2024-08-14,"João Sanches, Rui Ribeiro, Luísa Coheur",http://arxiv.org/pdf/2408.07457v1,cs.CL
Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals,"Despite recent success in natural language processing (NLP), fact
verification still remains a difficult task. Due to misinformation spreading
increasingly fast, attention has been directed towards automatically verifying
the correctness of claims. In the domain of NLP, this is usually done by
training supervised machine learning models to verify claims by utilizing
evidence from trustworthy corpora. We present efficient methods for verifying
claims on a dataset where the evidence is in the form of structured knowledge
graphs. We use the FactKG dataset, which is constructed from the DBpedia
knowledge graph extracted from Wikipedia. By simplifying the evidence retrieval
process, from fine-tuned language models to simple logical retrievals, we are
able to construct models that both require less computational resources and
achieve better test-set accuracy.",2024-08-14,Tobias A. Opsahl,http://arxiv.org/pdf/2408.07453v1,cs.CL
CMU's IWSLT 2024 Simultaneous Speech Translation System,"This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech
Translation (SST) task for translating English speech to German text in a
streaming manner. Our end-to-end speech-to-text (ST) system integrates the
WavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the
decoder. We employ a two-stage training approach: initially, we align the
representations of speech and text, followed by full fine-tuning. Both stages
are trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST
model for SST using a simple fixed hold-n policy. Experiments show that our
model obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2
seconds latency on the MuST-C-v2 tst-COMMON.",2024-08-14,"Xi Xu, Siqi Ouyang, Brian Yan, Patrick Fernandes, William Chen, Lei Li, Graham Neubig, Shinji Watanabe",http://arxiv.org/pdf/2408.07452v1,cs.CL
LiveFC: A System for Live Fact-Checking of Audio Streams,"The advances in the digital era have led to rapid dissemination of
information. This has also aggravated the spread of misinformation and
disinformation. This has potentially serious consequences, such as civil
unrest. While fact-checking aims to combat this, manual fact-checking is
cumbersome and not scalable. While automated fact-checking approaches exist,
they do not operate in real-time and do not always account for spread of
misinformation through different modalities. This is particularly important as
proactive fact-checking on live streams in real-time can help people be
informed of false narratives and prevent catastrophic consequences that may
cause civil unrest. This is particularly relevant with the rapid dissemination
of information through video on social media platforms or other streams like
political rallies and debates. Hence, in this work we develop a platform named
LiveFC, that can aid in fact-checking live audio streams in real-time. LiveFC
has a user-friendly interface that displays the claims detected along with
their veracity and evidence for live streams with associated speakers for
claims from respective segments. The app can be accessed at
http://livefc.factiverse.ai and a screen recording of the demo can be found at
https://bit.ly/3WVAoIw.",2024-08-14,"Venktesh V, Vinay Setty",http://arxiv.org/pdf/2408.07448v2,cs.CL
Exploring Retrieval Augmented Generation in Arabic,"Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful
technique in natural language processing, combining the strengths of
retrieval-based and generation-based models to enhance text generation tasks.
However, the application of RAG in Arabic, a language with unique
characteristics and resource constraints, remains underexplored. This paper
presents a comprehensive case study on the implementation and evaluation of RAG
for Arabic text. The work focuses on exploring various semantic embedding
models in the retrieval stage and several LLMs in the generation stage, in
order to investigate what works and what doesn't in the context of Arabic. The
work also touches upon the issue of variations between document dialect and
query dialect in the retrieval stage. Results show that existing semantic
embedding models and LLMs can be effectively employed to build Arabic RAG
pipelines.",2024-08-14,"Samhaa R. El-Beltagy, Mohamed A. Abdallah",http://arxiv.org/pdf/2408.07425v1,cs.CL
Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge Editing for Large Language Models,"Knowledge editing aims to update outdated or incorrect knowledge in large
language models (LLMs). However, current knowledge editing methods have limited
scalability for lifelong editing. This study explores the fundamental reason
why knowledge editing fails in lifelong editing. We begin with the closed-form
solution derived from linear associative memory, which underpins
state-of-the-art knowledge editing methods. We extend the solution from single
editing to lifelong editing, and through rigorous mathematical derivation,
identify an interference term in the final solution, suggesting that editing
knowledge may impact irrelevant knowledge. Further analysis of the interference
term reveals a close relationship with superposition between knowledge
representations. When knowledge superposition does not exist in language
models, the interference term vanishes, allowing for lossless knowledge
editing. Experiments across numerous language models reveal that knowledge
superposition is universal, exhibiting high kurtosis, zero mean, and
heavy-tailed distributions with clear scaling laws. Ultimately, by combining
theory and experiments, we demonstrate that knowledge superposition is the
fundamental reason for the failure of lifelong editing. Moreover, this is the
first study to investigate knowledge editing from the perspective of
superposition and provides a comprehensive observation of superposition across
numerous real-world language models. Code available at
https://github.com/ChenhuiHu/knowledge_in_superposition.",2024-08-14,"Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2408.07413v3,cs.CL
Aquila2 Technical Report,"This paper introduces the Aquila2 series, which comprises a wide range of
bilingual models with parameter sizes of 7, 34, and 70 billion. These models
are trained based on an innovative framework named HeuriMentor (HM), which
offers real-time insights into model convergence and enhances the training
process and data management. The HM System, comprising the Adaptive Training
Engine (ATE), Training State Monitor (TSM), and Data Management Unit (DMU),
allows for precise monitoring of the model's training progress and enables
efficient optimization of data distribution, thereby enhancing training
effectiveness. Extensive evaluations show that the Aquila2 model series
performs comparably well on both English and Chinese benchmarks. Specifically,
Aquila2-34B demonstrates only a slight decrease in performance when quantized
to Int4. Furthermore, we have made our training code
(https://github.com/FlagOpen/FlagScale) and model weights
(https://github.com/FlagAI-Open/Aquila2) publicly available to support ongoing
research and the development of applications.",2024-08-14,"Bo-Wen Zhang, Liangdong Wang, Jijie Li, Shuhao Gu, Xinya Wu, Zhengduo Zhang, Boyan Gao, Yulong Ao, Guang Liu",http://arxiv.org/pdf/2408.07410v1,cs.CL
A Quantum-Inspired Analysis of Human Disambiguation Processes,"Formal languages are essential for computer programming and are constructed
to be easily processed by computers. In contrast, natural languages are much
more challenging and instigated the field of Natural Language Processing (NLP).
One major obstacle is the ubiquity of ambiguities. Recent advances in NLP have
led to the development of large language models, which can resolve ambiguities
with high accuracy. At the same time, quantum computers have gained much
attention in recent years as they can solve some computational problems faster
than classical computers. This new computing paradigm has reached the fields of
machine learning and NLP, where hybrid classical-quantum learning algorithms
have emerged. However, more research is needed to identify which NLP tasks
could benefit from a genuine quantum advantage. In this thesis, we applied
formalisms arising from foundational quantum mechanics, such as contextuality
and causality, to study ambiguities arising from linguistics. By doing so, we
also reproduced psycholinguistic results relating to the human disambiguation
process. These results were subsequently used to predict human behaviour and
outperformed current NLP methods.",2024-08-14,Daphne Wang,http://arxiv.org/pdf/2408.07402v1,cs.CL
DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization,"Data visualization (DV) is the fundamental and premise tool to improve the
efficiency in conveying the insights behind the big data, which has been widely
accepted in existing data-driven world. Task automation in DV, such as
converting natural language queries to visualizations (i.e., text-to-vis),
generating explanations from visualizations (i.e., vis-to-text), answering
DV-related questions in free form (i.e. FeVisQA), and explicating tabular data
(i.e., table-to-text), is vital for advancing the field. Despite their
potential, the application of pre-trained language models (PLMs) like T5 and
BERT in DV has been limited by high costs and challenges in handling
cross-modal information, leading to few studies on PLMs for DV. We introduce
DataVisT5, a novel PLM tailored for DV that enhances the T5 architecture
through a hybrid objective pre-training and multi-task fine-tuning strategy,
integrating text and DV datasets to effectively interpret cross-modal
semantics. Extensive evaluations on public datasets show that DataVisT5
consistently outperforms current state-of-the-art models on various DV-related
tasks. We anticipate that DataVisT5 will not only inspire further research on
vertical PLMs but also expand the range of applications for PLMs.",2024-08-14,"Zhuoyue Wan, Yuanfeng Song, Shuaimin Li, Chen Jason Zhang, Raymond Chi-Wing Wong",http://arxiv.org/pdf/2408.07401v2,cs.CL
Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics,"Previous research on emergence in large language models shows these display
apparent human-like abilities and psychological latent traits. However, results
are partly contradicting in expression and magnitude of these latent traits,
yet agree on the worrisome tendencies to score high on the Dark Triad of
narcissism, psychopathy, and Machiavellianism, which, together with a track
record of derailments, demands more rigorous research on safety of these
models. We provided a state of the art language model with the same personality
questionnaire in nine languages, and performed Bayesian analysis of Gaussian
Mixture Model, finding evidence for a deeper-rooted issue. Our results suggest
both interlingual and intralingual instabilities, which indicate that current
language models do not develop a consistent core personality. This can lead to
unsafe behaviour of artificial intelligence systems that are based on these
foundation models, and are increasingly integrated in human life. We
subsequently discuss the shortcomings of modern psychometrics, abstract it, and
provide a framework for its species-neutral, substrate-free formulation.",2024-08-14,"Peter Romero, Stephen Fitz, Teruo Nakatsuma",http://arxiv.org/pdf/2408.07377v2,cs.CL
SAGE-RT: Synthetic Alignment data Generation for Safety Evaluation and Red Teaming,"We introduce Synthetic Alignment data Generation for Safety Evaluation and
Red Teaming (SAGE-RT or SAGE) a novel pipeline for generating synthetic
alignment and red-teaming data. Existing methods fall short in creating nuanced
and diverse datasets, providing necessary control over the data generation and
validation processes, or require large amount of manually generated seed data.
SAGE addresses these limitations by using a detailed taxonomy to produce
safety-alignment and red-teaming data across a wide range of topics. We
generated 51,000 diverse and in-depth prompt-response pairs, encompassing over
1,500 topics of harmfulness and covering variations of the most frequent types
of jailbreaking prompts faced by large language models (LLMs). We show that the
red-teaming data generated through SAGE jailbreaks state-of-the-art LLMs in
more than 27 out of 32 sub-categories, and in more than 58 out of 279
leaf-categories (sub-sub categories). The attack success rate for GPT-4o,
GPT-3.5-turbo is 100% over the sub-categories of harmfulness. Our approach
avoids the pitfalls of synthetic safety-training data generation such as mode
collapse and lack of nuance in the generation pipeline by ensuring a detailed
coverage of harmful topics using iterative expansion of the topics and
conditioning the outputs on the generated raw-text. This method can be used to
generate red-teaming and alignment data for LLM Safety completely synthetically
to make LLMs safer or for red-teaming the models over a diverse range of
topics.",2024-08-14,"Anurakt Kumar, Divyanshu Kumar, Jatan Loya, Nitin Aravind Birur, Tanay Baswa, Sahil Agarwal, Prashanth Harshangi",http://arxiv.org/pdf/2408.11851v1,cs.CL
Only One Relation Possible? Modeling the Ambiguity in Event Temporal Relation Extraction,"Event Temporal Relation Extraction (ETRE) aims to identify the temporal
relationship between two events, which plays an important role in natural
language understanding. Most previous works follow a single-label
classification style, classifying an event pair into either a specific temporal
relation (e.g., \textit{Before}, \textit{After}), or a special label
\textit{Vague} when there may be multiple possible temporal relations between
the pair. In our work, instead of directly making predictions on
\textit{Vague}, we propose a multi-label classification solution for ETRE
(METRE) to infer the possibility of each temporal relation independently, where
we treat \textit{Vague} as the cases when there is more than one possible
relation between two events. We design a speculation mechanism to explore the
possible relations hidden behind \textit{Vague}, which enables the latent
information to be used efficiently. Experiments on TB-Dense, MATRES and UDS-T
show that our method can effectively utilize the \textit{Vague} instances to
improve the recognition for specific temporal relations and outperforms most
state-of-the-art methods.",2024-08-14,"Yutong Hu, Quzhe Huang, Yansong Feng",http://arxiv.org/pdf/2408.07353v1,cs.CL
Enhancing Visual Question Answering through Ranking-Based Hybrid Training and Multimodal Fusion,"Visual Question Answering (VQA) is a challenging task that requires systems
to provide accurate answers to questions based on image content. Current VQA
models struggle with complex questions due to limitations in capturing and
integrating multimodal information effectively. To address these challenges, we
propose the Rank VQA model, which leverages a ranking-inspired hybrid training
strategy to enhance VQA performance. The Rank VQA model integrates high-quality
visual features extracted using the Faster R-CNN model and rich semantic text
features obtained from a pre-trained BERT model. These features are fused
through a sophisticated multimodal fusion technique employing multi-head
self-attention mechanisms. Additionally, a ranking learning module is
incorporated to optimize the relative ranking of answers, thus improving answer
accuracy. The hybrid training strategy combines classification and ranking
losses, enhancing the model's generalization ability and robustness across
diverse datasets. Experimental results demonstrate the effectiveness of the
Rank VQA model. Our model significantly outperforms existing state-of-the-art
models on standard VQA datasets, including VQA v2.0 and COCO-QA, in terms of
both accuracy and Mean Reciprocal Rank (MRR). The superior performance of Rank
VQA is evident in its ability to handle complex questions that require
understanding nuanced details and making sophisticated inferences from the
image and text. This work highlights the effectiveness of a ranking-based
hybrid training strategy in improving VQA performance and lays the groundwork
for further research in multimodal learning methods.",2024-08-14,"Peiyuan Chen, Zecheng Zhang, Yiping Dong, Li Zhou, Han Wang",http://arxiv.org/pdf/2408.07303v2,cs.CL
Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach,"Advanced Large language models (LLMs) like GPT-4 or LlaMa 3 provide superior
performance in complex human-like interactions. But they are costly, or too
large for edge devices such as smartphones and harder to self-host, leading to
security and privacy concerns. This paper introduces a novel interpretable
knowledge distillation approach to enhance the performance of smaller, more
economical LLMs that firms can self-host. We study this problem in the context
of building a customer service agent aimed at achieving high customer
satisfaction through goal-oriented dialogues. Unlike traditional knowledge
distillation, where the ""student"" model learns directly from the ""teacher""
model's responses via fine-tuning, our interpretable ""strategy"" teaching
approach involves the teacher providing strategies to improve the student's
performance in various scenarios. This method alternates between a ""scenario
generation"" step and a ""strategies for improvement"" step, creating a customized
library of scenarios and optimized strategies for automated prompting. The
method requires only black-box access to both student and teacher models; hence
it can be used without manipulating model parameters. In our customer service
application, the method improves performance, and the learned strategies are
transferable to other LLMs and scenarios beyond the training set. The method's
interpretabilty helps safeguard against potential harms through human audit.",2024-08-13,"Tong Wang, K. Sudhir, Dat Hong",http://arxiv.org/pdf/2408.07238v1,cs.CL
Neural embedding of beliefs reveals the role of relative dissonance in human decision-making,"Beliefs form the foundation of human cognition and decision-making, guiding
our actions and social connections. A model encapsulating beliefs and their
interrelationships is crucial for understanding their influence on our actions.
However, research on belief interplay has often been limited to beliefs related
to specific issues and relied heavily on surveys. We propose a method to study
the nuanced interplay between thousands of beliefs by leveraging an online user
debate data and mapping beliefs onto a neural embedding space constructed using
a fine-tuned large language model (LLM). This belief space captures the
interconnectedness and polarization of diverse beliefs across social issues.
Our findings show that positions within this belief space predict new beliefs
of individuals and estimate cognitive dissonance based on the distance between
existing and new beliefs. This study demonstrates how LLMs, combined with
collective online records of human beliefs, can offer insights into the
fundamental principles that govern human decision-making.",2024-08-13,"Byunghwee Lee, Rachith Aiyappa, Yong-Yeol Ahn, Haewoon Kwak, Jisun An",http://arxiv.org/pdf/2408.07237v2,cs.CL
BERT's Conceptual Cartography: Mapping the Landscapes of Meaning,"Conceptual Engineers want to make words better. However, they often
underestimate how varied our usage of words is. In this paper, we take the
first steps in exploring the contextual nuances of words by creating conceptual
landscapes -- 2D surfaces representing the pragmatic usage of words -- that
conceptual engineers can use to inform their projects. We use the spoken
component of the British National Corpus and BERT to create contextualised word
embeddings, and use Gaussian Mixture Models, a selection of metrics, and
qualitative analysis to visualise and numerically represent lexical landscapes.
Such an approach has not yet been used in the conceptual engineering literature
and provides a detailed examination of how different words manifest in various
contexts that is potentially useful to conceptual engineering projects. Our
findings highlight the inherent complexity of conceptual engineering, revealing
that each word exhibits a unique and intricate landscape. Conceptual Engineers
cannot, therefore, use a one-size-fits-all approach when improving words -- a
task that may be practically intractable at scale.",2024-08-13,"Nina Haket, Ryan Daniels",http://arxiv.org/pdf/2408.07190v1,cs.CL
Unlocking Efficiency: Adaptive Masking for Gene Transformer Models,"Gene transformer models such as Nucleotide Transformer, DNABert, and LOGO are
trained to learn optimal gene sequence representations by using the Masked
Language Modeling (MLM) training objective over the complete Human Reference
Genome. However, the typical tokenization methods employ a basic sliding window
of tokens, such as k-mers, that fail to utilize gene-centric semantics. This
could result in the (trivial) masking of easily predictable sequences, leading
to inefficient MLM training. Time-variant training strategies are known to
improve pretraining efficiency in both language and vision tasks. In this work,
we focus on using curriculum masking where we systematically increase the
difficulty of masked token prediction task by using a Pointwise Mutual
Information-based difficulty criterion, as gene sequences lack well-defined
semantic units similar to words or sentences of NLP domain. Our proposed
Curriculum Masking-based Gene Masking Strategy (CM-GEMS) demonstrates superior
representation learning capabilities compared to baseline masking approaches
when evaluated on downstream gene sequence classification tasks. We perform
extensive evaluation in both few-shot (five datasets) and full dataset settings
(Genomic Understanding Evaluation benchmark consisting of 27 tasks). Our
findings reveal that CM-GEMS outperforms state-of-the-art models (DNABert-2,
Nucleotide transformer, DNABert) trained at 120K steps, achieving similar
results in just 10K and 1K steps. We also demonstrate that Curriculum-Learned
LOGO (a 2-layer DNABert-like model) can achieve nearly 90% of the
state-of-the-art model performance of 120K steps. We will make the models and
codes publicly available at https://github.com/roysoumya/curriculum-GeneMask.",2024-08-13,"Soumyadeep Roy, Shamik Sural, Niloy Ganguly",http://arxiv.org/pdf/2408.07180v1,cs.CL
Self-folding Self-replication,"Inspired by protein folding, we explored the construction of
three-dimensional structures and machines from one-dimensional chains of simple
building blocks. This approach not only allows us to recreate the
self-replication mechanism introduced earlier, but also significantly
simplifies the process. We introduced a new set of folding blocks that
facilitate the formation of secondary structures such as {\alpha}-helices and
\b{eta}-sheets, as well as more advanced tertiary and quaternary structures,
including self-replicating machines. The introduction of rotational degrees of
freedom leads to a reduced variety of blocks and, most importantly, reduces the
overall size of the machines by a factor of five. In addition, we present a
universal copier-constructor, a highly efficient self-replicating mechanism
composed of approximately 40 blocks, including the restictions posed on it. The
paper also addresses evolutionary considerations, outlining several steps on
the evolutionary ladder towards more sophisticated self-replicating systems.
Finally, this study offers a clear rationale for nature's preference for
one-dimensional chains in constructing three-dimensional structures.",2024-08-13,Ralph P. Lano,http://arxiv.org/pdf/2408.07154v1,cs.CL
Language Models as Models of Language,"This chapter critically examines the potential contributions of modern
language models to theoretical linguistics. Despite their focus on engineering
goals, these models' ability to acquire sophisticated linguistic knowledge from
mere exposure to data warrants a careful reassessment of their relevance to
linguistic theory. I review a growing body of empirical evidence suggesting
that language models can learn hierarchical syntactic structure and exhibit
sensitivity to various linguistic phenomena, even when trained on
developmentally plausible amounts of data. While the competence/performance
distinction has been invoked to dismiss the relevance of such models to
linguistic theory, I argue that this assessment may be premature. By carefully
controlling learning conditions and making use of causal intervention methods,
experiments with language models can potentially constrain hypotheses about
language acquisition and competence. I conclude that closer collaboration
between theoretical linguists and computational researchers could yield
valuable insights, particularly in advancing debates about linguistic nativism.",2024-08-13,Raphaël Millière,http://arxiv.org/pdf/2408.07144v1,cs.CL
"ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice","Despite remarkable performance in legal consultation exhibited by legal Large
Language Models(LLMs) combined with legal article retrieval components, there
are still cases when the advice given is incorrect or baseless. To alleviate
these problems, we propose {\bf ELLA}, a tool for {\bf E}mpowering {\bf L}LMs
for interpretable, accurate, and informative {\bf L}egal {\bf A}dvice. ELLA
visually presents the correlation between legal articles and LLM's response by
calculating their similarities, providing users with an intuitive legal basis
for the responses. Besides, based on the users' queries, ELLA retrieves
relevant legal articles and displays them to users. Users can interactively
select legal articles for LLM to generate more accurate responses. ELLA also
retrieves relevant legal cases for user reference. Our user study shows that
presenting the legal basis for the response helps users understand better. The
accuracy of LLM's responses also improves when users intervene in selecting
legal articles for LLM. Providing relevant legal cases also aids individuals in
obtaining comprehensive information.",2024-08-13,"Yutong Hu, Kangcheng Luo, Yansong Feng",http://arxiv.org/pdf/2408.07137v1,cs.CL
Fingerspelling within Sign Language Translation,"Fingerspelling poses challenges for sign language processing due to its
high-frequency motion and use for open-vocabulary terms. While prior work has
studied fingerspelling recognition, there has been little attention to
evaluating how well sign language translation models understand fingerspelling
in the context of entire sentences -- and improving this capability. We
manually annotate instances of fingerspelling within FLEURS-ASL and use them to
evaluate the effect of two simple measures to improve fingerspelling
recognition within American Sign Language to English translation: 1) use a
model family (ByT5) with character- rather than subword-level tokenization, and
2) mix fingerspelling recognition data into the translation training mixture.
We find that 1) substantially improves understanding of fingerspelling (and
therefore translation quality overall), but the effect of 2) is mixed.",2024-08-13,Garrett Tanzer,http://arxiv.org/pdf/2408.07065v1,cs.CL
Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents,"Large language model (LLM) agents have shown great potential in solving
real-world software engineering (SWE) problems. The most advanced open-source
SWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite.
However, these sophisticated agent frameworks exhibit varying strengths,
excelling in certain tasks while underperforming in others. To fully harness
the diversity of these agents, we propose DEI (Diversity Empowered
Intelligence), a framework that leverages their unique expertise. DEI functions
as a meta-module atop existing SWE agent frameworks, managing agent collectives
for enhanced problem-solving. Experimental results show that a DEI-guided
committee of agents is able to surpass the best individual agent's performance
by a large margin. For instance, a group of open-source SWE agents, with a
maximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3%
resolve rate with DEI, making a 25% improvement and beating most closed-source
solutions. Our best-performing group excels with a 55% resolve rate, securing
the highest ranking on SWE-Bench Lite. Our findings contribute to the growing
body of research on collaborative AI systems and their potential to solve
complex software engineering challenges.",2024-08-13,"Kexun Zhang, Weiran Yao, Zuxin Liu, Yihao Feng, Zhiwei Liu, Rithesh Murthy, Tian Lan, Lei Li, Renze Lou, Jiacheng Xu, Bo Pang, Yingbo Zhou, Shelby Heinecke, Silvio Savarese, Huan Wang, Caiming Xiong",http://arxiv.org/pdf/2408.07060v1,cs.CL
A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning,"The availability of performant pre-trained models has led to a proliferation
of fine-tuned expert models that are specialized to a particular domain or
task. Model MoErging methods aim to recycle expert models to create an
aggregate system with improved performance or generalization. A key component
of MoErging methods is the creation of a router that decides which expert
model(s) to use for a particular input or application. The promise,
effectiveness, and large design space of MoErging has spurred the development
of many new methods over the past few years. This rapid pace of development has
made it challenging to compare different MoErging methods, which are rarely
compared to one another and are often validated in different experimental
setups. To remedy such gaps, we present a comprehensive survey of MoErging
methods that includes a novel taxonomy for cataloging key design choices and
clarifying suitable applications for each method. Apart from surveying MoErging
research, we inventory software tools and applications that make use of
MoErging. We additionally discuss related fields of study such as model
merging, multitask learning, and mixture-of-experts models. Taken as a whole,
our survey provides a unified overview of existing MoErging methods and creates
a solid foundation for future work in this burgeoning field.",2024-08-13,"Prateek Yadav, Colin Raffel, Mohammed Muqeeth, Lucas Caccia, Haokun Liu, Tianlong Chen, Mohit Bansal, Leshem Choshen, Alessandro Sordoni",http://arxiv.org/pdf/2408.07057v1,cs.CL
"LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs","Current long context large language models (LLMs) can process inputs up to
100,000 tokens, yet struggle to generate outputs exceeding even a modest length
of 2,000 words. Through controlled experiments, we find that the model's
effective generation length is inherently bounded by the sample it has seen
during supervised fine-tuning (SFT). In other words, their output limitation is
due to the scarcity of long-output examples in existing SFT datasets. To
address this, we introduce AgentWrite, an agent-based pipeline that decomposes
ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to
generate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we
construct LongWriter-6k, a dataset containing 6,000 SFT data with output
lengths ranging from 2k to 32k words. By incorporating this dataset into model
training, we successfully scale the output length of existing models to over
10,000 words while maintaining output quality. We also develop LongBench-Write,
a comprehensive benchmark for evaluating ultra-long generation capabilities.
Our 9B parameter model, further improved through DPO, achieves state-of-the-art
performance on this benchmark, surpassing even much larger proprietary models.
In general, our work demonstrates that existing long context LLM already
possesses the potential for a larger output window--all you need is data with
extended output during model alignment to unlock this capability. Our code &
models are at: https://github.com/THUDM/LongWriter.",2024-08-13,"Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li",http://arxiv.org/pdf/2408.07055v1,cs.CL
The News Comment Gap and Algorithmic Agenda Setting in Online Forums,"The disparity between news stories valued by journalists and those preferred
by readers, known as the ""News Gap"", is well-documented. However, the
difference in expectations regarding news related user-generated content is
less studied. Comment sections, hosted by news websites, are popular venues for
reader engagement, yet still subject to editorial decisions. It is thus
important to understand journalist vs reader comment preferences and how these
are served by various comment ranking algorithms that represent discussions
differently. We analyse 1.2 million comments from Austrian newspaper Der
Standard to understand the ""News Comment Gap"" and the effects of different
ranking algorithms. We find that journalists prefer positive, timely, complex,
direct responses, while readers favour comments similar to article content from
elite authors. We introduce the versatile Feature-Oriented Ranking Utility
Metric (FORUM) to assess the impact of different ranking algorithms and find
dramatic differences in how they prioritise the display of comments by
sentiment, topical relevance, lexical diversity, and readability. Journalists
can exert substantial influence over the discourse through both curatorial and
algorithmic means. Understanding these choices' implications is vital in
fostering engaging and civil discussions while aligning with journalistic
objectives, especially given the increasing legal scrutiny and societal
importance of online discourse.",2024-08-13,"Flora Böwing, Patrick Gildersleve",http://arxiv.org/pdf/2408.07052v2,cs.CL
TableGuard -- Securing Structured & Unstructured Data,"With the increasing demand for data sharing across platforms and
organizations, ensuring the privacy and security of sensitive information has
become a critical challenge. This paper introduces ""TableGuard"". An innovative
approach to data obfuscation tailored for relational databases. Building on the
principles and techniques developed in prior work on context-sensitive
obfuscation, TableGuard applies these methods to ensure that API calls return
only obfuscated data, thereby safeguarding privacy when sharing data with third
parties. TableGuard leverages advanced context-sensitive obfuscation techniques
to replace sensitive data elements with contextually appropriate alternatives.
By maintaining the relational integrity and coherence of the data, our approach
mitigates the risks of cognitive dissonance and data leakage. We demonstrate
the implementation of TableGuard using a BERT based transformer model, which
identifies and obfuscates sensitive entities within relational tables. Our
evaluation shows that TableGuard effectively balances privacy protection with
data utility, minimizing information loss while ensuring that the obfuscated
data remains functionally useful for downstream applications. The results
highlight the importance of domain-specific obfuscation strategies and the role
of context length in preserving data integrity. The implications of this
research are significant for organizations that need to share data securely
with external parties. TableGuard offers a robust framework for implementing
privacy-preserving data sharing mechanisms, thereby contributing to the broader
field of data privacy and security.",2024-08-13,"Anantha Sharma, Ajinkya Deshmukh",http://arxiv.org/pdf/2408.07045v1,cs.CL
Generative AI for automatic topic labelling,"Topic Modeling has become a prominent tool for the study of scientific
fields, as they allow for a large scale interpretation of research trends.
Nevertheless, the output of these models is structured as a list of keywords
which requires a manual interpretation for the labelling. This paper proposes
to assess the reliability of three LLMs, namely flan, GPT-4o, and GPT-4 mini
for topic labelling. Drawing on previous research leveraging BERTopic, we
generate topics from a dataset of all the scientific articles (n=34,797)
authored by all biology professors in Switzerland (n=465) between 2008 and
2020, as recorded in the Web of Science database. We assess the output of the
three models both quantitatively and qualitatively and find that, first, both
GPT models are capable of accurately and precisely label topics from the
models' output keywords. Second, 3-word labels are preferable to grasp the
complexity of research topics.",2024-08-13,"Diego Kozlowski, Carolina Pradier, Pierre Benz",http://arxiv.org/pdf/2408.07003v1,cs.CL
The advantages of context specific language models: the case of the Erasmian Language Model,"The current trend to improve language model performance seems to be based on
scaling up with the number of parameters (e.g. the state of the art GPT4 model
has approximately 1.7 trillion parameters) or the amount of training data fed
into the model. However this comes at significant costs in terms of
computational resources and energy costs that compromise the sustainability of
AI solutions, as well as risk relating to privacy and misuse. In this paper we
present the Erasmian Language Model (ELM) a small context specific, 900 million
parameter model, pre-trained and fine-tuned by and for Erasmus University
Rotterdam. We show how the model performs adequately in a classroom context for
essay writing, and how it achieves superior performance in subjects that are
part of its context. This has implications for a wide range of institutions and
organizations, showing that context specific language models may be a viable
alternative for resource constrained, privacy sensitive use cases.",2024-08-13,"João Gonçalves, Nick Jelicic, Michele Murgia, Evert Stamhuis",http://arxiv.org/pdf/2408.06931v2,cs.CL
Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification,"Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports. We
included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results. The SpanCategorizer and MedRoBERTa$.$nl models
outperformed all other span and document classifiers, respectively. The
weighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in
SpanCategorizer and 0.96 to 0.98 in MedRoBERTa$.$nl. Direct document
classification was superior to indirect document classification using span
classifiers. SetFit achieved competitive document classification performance
using only 10% of the training data. Utilizing a reduced label set yielded
near-perfect document classification results. We recommend using our published
SpanCategorizer and MedRoBERTa$.$nl models for span- and document-level
diagnosis extraction from Dutch echocardiography reports. For settings with
limited training data, SetFit may be a promising alternative for document
classification.",2024-08-13,"Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, René van Es, Bram van Es",http://arxiv.org/pdf/2408.06930v2,cs.CL
Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas,"The success of Large Language Models (LLMs) in multicultural environments
hinges on their ability to understand users' diverse cultural backgrounds. We
measure this capability by having an LLM simulate human profiles representing
various nationalities within the scope of a questionnaire-style psychological
experiment. Specifically, we employ GPT-3.5 to reproduce reactions to
persuasive news articles of 7,286 participants from 15 countries; comparing the
results with a dataset of real participants sharing the same demographic
traits. Our analysis shows that specifying a person's country of residence
improves GPT-3.5's alignment with their responses. In contrast, using native
language prompting introduces shifts that significantly reduce overall
alignment, with some languages particularly impairing performance. These
findings suggest that while direct nationality information enhances the model's
cultural adaptability, native language cues do not reliably improve simulation
fidelity and can detract from the model's effectiveness.",2024-08-13,"Louis Kwok, Michal Bravansky, Lewis D. Griffin",http://arxiv.org/pdf/2408.06929v1,cs.CL
"Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives","The Chain-of-Thought (CoT) paradigm has become a pivotal method for solving
complex problems. However, its application to intricate, domain-specific tasks
remains challenging, as large language models (LLMs) often struggle to
accurately decompose these tasks and, even when decomposition is correct, fail
to execute the subtasks effectively. This paper introduces the Re-TASK
framework, a novel theoretical model that revisits LLM tasks from the
perspectives of capability, skill, and knowledge, drawing on the principles of
Bloom's Taxonomy and Knowledge Space Theory. While CoT offers a workflow
perspective on tasks, the Re-TASK framework introduces a Chain-of-Learning
view, illustrating how tasks and their corresponding subtasks depend on various
capability items. Each capability item is further dissected into its
constituent aspects of knowledge and skills. Our framework reveals that many
CoT failures in domain-specific tasks stem from insufficient knowledge or
inadequate skill adaptation. In response, we combine CoT with the Re-TASK
framework and implement a carefully designed Re-TASK prompting strategy to
improve task performance. Specifically, we identify core capability items
linked to tasks and subtasks, then strengthen these capabilities through
targeted knowledge injection and skill adaptation. We validate the Re-TASK
framework on three datasets across the law, finance, and mathematics domains,
achieving significant improvements over the baseline models. Notably, our
approach yields a remarkable 44.42% improvement with the Yi-1.5-9B model and a
33.08% improvement with the Llama3-Chinese-8b on the legal dataset. These
experimental results confirm the effectiveness of the Re-TASK framework,
demonstrating substantial enhancements in both the performance and
applicability of LLMs.",2024-08-13,"Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Sitao Xie, Yubo Zhang, Jiaxin Shi, Zhixing Wang, Hongyan Li, Junchi Yan",http://arxiv.org/pdf/2408.06904v2,cs.CL
Leveraging Language Models for Emotion and Behavior Analysis in Education,"The analysis of students' emotions and behaviors is crucial for enhancing
learning outcomes and personalizing educational experiences. Traditional
methods often rely on intrusive visual and physiological data collection,
posing privacy concerns and scalability issues. This paper proposes a novel
method leveraging large language models (LLMs) and prompt engineering to
analyze textual data from students. Our approach utilizes tailored prompts to
guide LLMs in detecting emotional and engagement states, providing a
non-intrusive and scalable solution. We conducted experiments using Qwen,
ChatGPT, Claude2, and GPT-4, comparing our method against baseline models and
chain-of-thought (CoT) prompting. Results demonstrate that our method
significantly outperforms the baselines in both accuracy and contextual
understanding. This study highlights the potential of LLMs combined with prompt
engineering to offer practical and effective tools for educational emotion and
behavior analysis.",2024-08-13,"Kaito Tanaka, Benjamin Tan, Brian Wong",http://arxiv.org/pdf/2408.06874v1,cs.CL
LoRA$^2$ : Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models,"Fine-tuning large language models (LLMs) with high parameter efficiency for
downstream tasks has become a new paradigm. Low-Rank Adaptation (LoRA)
significantly reduces the number of trainable parameters for fine-tuning.
Although it has demonstrated commendable performance, updating parameters
within a single scale may not be the optimal choice for complex downstream
tasks.In this paper, we extend the LoRA to multiple scales, dubbed as LoRA$^2$.
We first combine orthogonal projection theory to train a set of LoRAs in two
mutually orthogonal planes. Then, we improve the importance score algorithm,
which reduce parameter sensitivity score calculations by approximately 98.5\%.
By pruning singular values with lower importance scores, thereby enhancing
adaptability to various downstream tasks. Extensive experiments are conducted
on two widely used pre-trained models to validate the effectiveness of
LoRA$^2$. Results show that it significantly reduces the number of trainable
parameters to just 0.72\% compared to full fine-tuning, while still delivering
highly impressive performance. Even when the parameters are further reduced to
0.17M, it still achieves comparable results to the baseline with 8 times more
parameters. Our code is available here:
https://anonymous.4open.science/r/LoRA-2-5B4C",2024-08-13,"Jia-Chen Zhang, Yu-Jie Xiong, He-Xi Qiu, Dong-Hai Zhu, Chun-Ming Xia",http://arxiv.org/pdf/2408.06854v1,cs.CL
Causal Agent based on Large Language Model,"Large language models (LLMs) have achieved significant success across various
domains. However, the inherent complexity of causal problems and causal theory
poses challenges in accurately describing them in natural language, making it
difficult for LLMs to comprehend and use them effectively. Causal methods are
not easily conveyed through natural language, which hinders LLMs' ability to
apply them accurately. Additionally, causal datasets are typically tabular,
while LLMs excel in handling natural language data, creating a structural
mismatch that impedes effective reasoning with tabular data. This lack of
causal reasoning capability limits the development of LLMs. To address these
challenges, we have equipped the LLM with causal tools within an agent
framework, named the Causal Agent, enabling it to tackle causal problems. The
causal agent comprises tools, memory, and reasoning modules. In the tools
module, the causal agent applies causal methods to align tabular data with
natural language. In the reasoning module, the causal agent employs the ReAct
framework to perform reasoning through multiple iterations with the tools. In
the memory module, the causal agent maintains a dictionary instance where the
keys are unique names and the values are causal graphs. To verify the causal
ability of the causal agent, we established a benchmark consisting of four
levels of causal problems: variable level, edge level, causal graph level, and
causal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for
these four levels of issues and tested the causal agent on the datasets. Our
methodology demonstrates remarkable efficacy on the four-level causal problems,
with accuracy rates all above 80%. For further insights and implementation
details, our code is accessible via the GitHub repository
https://github.com/Kairong-Han/Causal_Agent.",2024-08-13,"Kairong Han, Kun Kuang, Ziyu Zhao, Junjian Ye, Fei Wu",http://arxiv.org/pdf/2408.06849v1,cs.CL
MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data Uncertainty,"Despite the massive advancements in large language models (LLMs), they still
suffer from producing plausible but incorrect responses. To improve the
reliability of LLMs, recent research has focused on uncertainty quantification
to predict whether a response is correct or not. However, most uncertainty
quantification methods have been evaluated on single-labeled questions, which
removes data uncertainty: the irreducible randomness often present in user
queries, which can arise from factors like multiple possible answers. This
limitation may cause uncertainty quantification results to be unreliable in
practical settings. In this paper, we investigate previous uncertainty
quantification methods under the presence of data uncertainty. Our
contributions are two-fold: 1) proposing a new Multi-Answer Question Answering
dataset, MAQA, consisting of world knowledge, mathematical reasoning, and
commonsense reasoning tasks to evaluate uncertainty quantification regarding
data uncertainty, and 2) assessing 5 uncertainty quantification methods of
diverse white- and black-box LLMs. Our findings show that previous methods
relatively struggle compared to single-answer settings, though this varies
depending on the task. Moreover, we observe that entropy- and consistency-based
methods effectively estimate model uncertainty, even in the presence of data
uncertainty. We believe these observations will guide future work on
uncertainty quantification in more realistic settings.",2024-08-13,"Yongjin Yang, Haneul Yoo, Hwaran Lee",http://arxiv.org/pdf/2408.06816v2,cs.CL
What should I wear to a party in a Greek taverna? Evaluation for Conversational Agents in the Fashion Domain,"Large language models (LLMs) are poised to revolutionize the domain of online
fashion retail, enhancing customer experience and discovery of fashion online.
LLM-powered conversational agents introduce a new way of discovery by directly
interacting with customers, enabling them to express in their own ways, refine
their needs, obtain fashion and shopping advice that is relevant to their taste
and intent. For many tasks in e-commerce, such as finding a specific product,
conversational agents need to convert their interactions with a customer to a
specific call to different backend systems, e.g., a search system to showcase a
relevant set of products. Therefore, evaluating the capabilities of LLMs to
perform those tasks related to calling other services is vital. However, those
evaluations are generally complex, due to the lack of relevant and high quality
datasets, and do not align seamlessly with business needs, amongst others. To
this end, we created a multilingual evaluation dataset of 4k conversations
between customers and a fashion assistant in a large e-commerce fashion
platform to measure the capabilities of LLMs to serve as an assistant between
customers and a backend engine. We evaluate a range of models, showcasing how
our dataset scales to business needs and facilitates iterative development of
tools.",2024-08-13,"Antonis Maronikolakis, Ana Peleteiro Ramallo, Weiwei Cheng, Thomas Kober",http://arxiv.org/pdf/2408.08907v1,cs.CL
Layerwise Recurrent Router for Mixture-of-Experts,"The scaling of large language models (LLMs) has revolutionized their
capabilities in various tasks, yet this growth must be matched with efficient
computational strategies. The Mixture-of-Experts (MoE) architecture stands out
for its ability to scale model size without significantly increasing training
costs. Despite their advantages, current MoE models often display parameter
inefficiency. For instance, a pre-trained MoE-based LLM with 52 billion
parameters might perform comparably to a standard model with 6.7 billion
parameters. Being a crucial part of MoE, current routers in different layers
independently assign tokens without leveraging historical routing information,
potentially leading to suboptimal token-expert combinations and the parameter
inefficiency problem. To alleviate this issue, we introduce the Layerwise
Recurrent Router for Mixture-of-Experts (RMoE). RMoE leverages a Gated
Recurrent Unit (GRU) to establish dependencies between routing decisions across
consecutive layers. Such layerwise recurrence can be efficiently parallelly
computed for input tokens and introduces negotiable costs. Our extensive
empirical evaluations demonstrate that RMoE-based language models consistently
outperform a spectrum of baseline models. Furthermore, RMoE integrates a novel
computation stage orthogonal to existing methods, allowing seamless
compatibility with other MoE architectures. Our analyses attribute RMoE's gains
to its effective cross-layer information sharing, which also improves expert
selection and diversity. Our code is at https://github.com/qiuzh20/RMoE .",2024-08-13,"Zihan Qiu, Zeyu Huang, Shuang Cheng, Yizhi Zhou, Zili Wang, Ivan Titov, Jie Fu",http://arxiv.org/pdf/2408.06793v2,cs.CL
Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets Subgraph-Aware Entity Descriptions,"Traditional knowledge graph completion (KGC) methods rely solely on
structural information, struggling with the inherent sparsity of knowledge
graphs (KGs). Large Language Models (LLMs) learn extensive knowledge from large
corpora with powerful context modeling, making them promising for mitigating
the limitations of previous methods. Directly fine-tuning LLMs offers great
capability but comes at the cost of huge time and memory consumption, while
utilizing frozen LLMs yields suboptimal results.In this work, we aim to
leverage LLMs for KGC effectively and efficiently. We capture the context-aware
hidden states of knowledge triples by employing prompts to stimulate the
intermediate layers of LLMs. We then train a data-efficient classifier on these
hidden states to harness the inherent capabilities of frozen LLMs in KGC.
Additionally, to reduce ambiguity and enrich knowledge representation, we
generate detailed entity descriptions through subgraph sampling on KGs.
Extensive experiments on standard benchmarks demonstrate the efficiency and
effectiveness of our approach. We outperform traditional KGC methods across
most datasets and, notably, achieve classification performance comparable to
fine-tuned LLMs while enhancing GPU memory efficiency by $188\times$ and
accelerating training and inference by $13.48\times$.",2024-08-13,"Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang",http://arxiv.org/pdf/2408.06787v3,cs.CL
Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors,"We propose Fast-and-Frugal Text-Graph (FnF-TG) Transformers, a
Transformer-based framework that unifies textual and structural information for
inductive link prediction in text-attributed knowledge graphs. We demonstrate
that, by effectively encoding ego-graphs (1-hop neighbourhoods), we can reduce
the reliance on resource-intensive textual encoders. This makes the model both
fast at training and inference time, as well as frugal in terms of cost. We
perform a comprehensive evaluation on three popular datasets and show that
FnF-TG can achieve superior performance compared to previous state-of-the-art
methods. We also extend inductive learning to a fully inductive setting, where
relations don't rely on transductive (fixed) representations, as in previous
work, but are a function of their textual description. Additionally, we
introduce new variants of existing datasets, specifically designed to test the
performance of models on unseen relations at inference time, thus offering a
new test-bench for fully inductive link prediction.",2024-08-13,"Andrei C. Coman, Christos Theodoropoulos, Marie-Francine Moens, James Henderson",http://arxiv.org/pdf/2408.06778v3,cs.CL
Sumotosima: A Framework and Dataset for Classifying and Summarizing Otoscopic Images,"Otoscopy is a diagnostic procedure to examine the ear canal and eardrum using
an otoscope. It identifies conditions like infections, foreign bodies, ear drum
perforations and ear abnormalities. We propose a novel resource efficient deep
learning and transformer based framework, Sumotosima (Summarizer for otoscopic
images), an end-to-end pipeline for classification followed by summarization.
Our framework works on combination of triplet and cross-entropy losses.
Additionally, we use Knowledge Enhanced Multimodal BART whose input is fused
textual and image embedding. The objective is to provide summaries that are
well-suited for patients, ensuring clarity and efficiency in understanding
otoscopic images. Given the lack of existing datasets, we have curated our own
OCASD (Otoscopic Classification And Summary Dataset), which includes 500 images
with 5 unique categories annotated with their class and summaries by
Otolaryngologists. Sumotosima achieved a result of 98.03%, which is 7.00%,
3.10%, 3.01% higher than K-Nearest Neighbors, Random Forest and Support Vector
Machines, respectively, in classification tasks. For summarization, Sumotosima
outperformed GPT-4o and LLaVA by 88.53% and 107.57% in ROUGE scores,
respectively. We have made our code and dataset publicly available at
https://github.com/anas2908/Sumotosima",2024-08-13,"Eram Anwarul Khan, Anas Anwarul Haq Khan",http://arxiv.org/pdf/2408.06755v1,cs.CL
Multilingual Models for Check-Worthy Social Media Posts Detection,"This work presents an extensive study of transformer-based NLP models for
detection of social media posts that contain verifiable factual claims and
harmful claims. The study covers various activities, including dataset
collection, dataset pre-processing, architecture selection, setup of settings,
model training (fine-tuning), model testing, and implementation. The study
includes a comprehensive analysis of different models, with a special focus on
multilingual models where the same model is capable of processing social media
posts in both English and in low-resource languages such as Arabic, Bulgarian,
Dutch, Polish, Czech, Slovak. The results obtained from the study were
validated against state-of-the-art models, and the comparison demonstrated the
robustness of the proposed models. The novelty of this work lies in the
development of multi-label multilingual classification models that can
simultaneously detect harmful posts and posts that contain verifiable factual
claims in an efficient way.",2024-08-13,"Sebastian Kula, Michal Gregor",http://arxiv.org/pdf/2408.06737v1,cs.CL
Exploring the anatomy of articulation rate in spontaneous English speech: relationships between utterance length effects and social factors,"Speech rate has been shown to vary across social categories such as gender,
age, and dialect, while also being conditioned by properties of speech
planning. The effect of utterance length, where speech rate is faster and less
variable for longer utterances, has also been shown to reduce the role of
social factors once it has been accounted for, leaving unclear the relationship
between social factors and speech production in conditioning speech rate.
Through modelling of speech rate across 13 English speech corpora, it is found
that utterance length has the largest effect on speech rate, though this effect
itself varies little across corpora and speakers. While age and gender also
modulate speech rate, their effects are much smaller in magnitude. These
findings suggest utterance length effects may be conditioned by articulatory
and perceptual constraints, and that social influences on speech rate should be
interpreted in the broader context of how speech rate variation is structured.",2024-08-13,"James Tanner, Morgan Sonderegger, Jane Stuart-Smith, Tyler Kendall, Jeff Mielke, Robin Dodsworth, Erik Thomas",http://arxiv.org/pdf/2408.06732v1,cs.CL
Large language models can consistently generate high-quality content for election disinformation operations,"Advances in large language models have raised concerns about their potential
use in generating compelling election disinformation at scale. This study
presents a two-part investigation into the capabilities of LLMs to automate
stages of an election disinformation operation. First, we introduce DisElect, a
novel evaluation dataset designed to measure LLM compliance with instructions
to generate content for an election disinformation operation in localised UK
context, containing 2,200 malicious prompts and 50 benign prompts. Using
DisElect, we test 13 LLMs and find that most models broadly comply with these
requests; we also find that the few models which refuse malicious prompts also
refuse benign election-related prompts, and are more likely to refuse to
generate content from a right-wing perspective. Secondly, we conduct a series
of experiments (N=2,340) to assess the ""humanness"" of LLMs: the extent to which
disinformation operation content generated by an LLM is able to pass as
human-written. Our experiments suggest that almost all LLMs tested released
since 2022 produce election disinformation operation content indiscernible by
human evaluators over 50% of the time. Notably, we observe that multiple models
achieve above-human levels of humanness. Taken together, these findings suggest
that current LLMs can be used to generate high-quality content for election
disinformation operations, even in hyperlocalised scenarios, at far lower costs
than traditional methods, and offer researchers and policymakers an empirical
benchmark for the measurement and evaluation of these capabilities in current
and future models.",2024-08-13,"Angus R. Williams, Liam Burke-Moore, Ryan Sze-Yin Chan, Florence E. Enock, Federico Nanni, Tvesha Sippy, Yi-Ling Chung, Evelina Gabasova, Kobi Hackenburg, Jonathan Bright",http://arxiv.org/pdf/2408.06731v1,cs.CL
Enhancing Visual Dialog State Tracking through Iterative Object-Entity Alignment in Multi-Round Conversations,"Visual Dialog (VD) is a task where an agent answers a series of image-related
questions based on a multi-round dialog history. However, previous VD methods
often treat the entire dialog history as a simple text input, disregarding the
inherent conversational information flows at the round level. In this paper, we
introduce Multi-round Dialogue State Tracking model (MDST), a framework that
addresses this limitation by leveraging the dialogue state learned from dialog
history to answer questions. MDST captures each round of dialog history,
constructing internal dialogue state representations defined as 2-tuples of
vision-language representations. These representations effectively ground the
current question, enabling the generation of accurate answers. Experimental
results on the VisDial v1.0 dataset demonstrate that MDST achieves a new
state-of-the-art performance in generative setting. Furthermore, through a
series of human studies, we validate the effectiveness of MDST in generating
long, consistent, and human-like answers while consistently answering a series
of questions correctly.",2024-08-13,"Wei Pang, Ruixue Duan, Jinfu Yang, Ning Li",http://arxiv.org/pdf/2408.06725v1,cs.CL
PEARL: Parallel Speculative Decoding with Adaptive Draft Length,"Speculative decoding (SD), where an extra draft model is employed to provide
multiple draft tokens first, and then the original target model verifies these
tokens in parallel, has shown great power for LLM inference acceleration.
However, existing SD methods suffer from the mutual waiting problem, i.e., the
target model gets stuck when the draft model is guessing tokens, and vice
versa. This problem is directly incurred by the asynchronous execution of the
draft model and the target model and is exacerbated due to the fixed draft
length in speculative decoding. To address these challenges, we propose a
conceptually simple, flexible, and general framework to boost speculative
decoding, namely Parallel spEculative decoding with Adaptive dRaft Length
(PEARL). Specifically, PEARL proposes pre-verify to verify the first draft
token in advance during the drafting phase, and post-verify to generate more
draft tokens during the verification phase. PEARL parallels the drafting phase
and the verification phase via applying the two strategies, and achieves
adaptive draft length for different scenarios, which effectively alleviates the
mutual waiting problem. Experiments on various text generation benchmarks
demonstrate the effectiveness of our PEARL, leading to a superior speed up
performance up to 4.43$\times$ and 1.50$\times$, compared to auto-regressive
decoding and vanilla speculative decoding, respectively. Our code is available
at https://github.com/smart-lty/ParallelSpeculativeDecoding.",2024-08-13,"Tianyu Liu, Yun Li, Qitan Lv, Kai Liu, Jianchen Zhu, Winston Hu, Xiao Sun",http://arxiv.org/pdf/2408.11850v3,cs.CL
Latin Treebanks in Review: An Evaluation of Morphological Tagging Across Time,"Existing Latin treebanks draw from Latin's long written tradition, spanning
17 centuries and a variety of cultures. Recent efforts have begun to harmonize
these treebanks' annotations to better train and evaluate morphological
taggers. However, the heterogeneity of these treebanks must be carefully
considered to build effective and reliable data. In this work, we review
existing Latin treebanks to identify the texts they draw from, identify their
overlap, and document their coverage across time and genre. We additionally
design automated conversions of their morphological feature annotations into
the conventions of standard Latin grammar. From this, we build new time-period
data splits that draw from the existing treebanks which we use to perform a
broad cross-time analysis for POS and morphological feature tagging. We find
that BERT-based taggers outperform existing taggers while also being more
robust to cross-domain shifts.",2024-08-13,"Marisa Hudspeth, Brendan O'Connor, Laure Thompson",http://arxiv.org/pdf/2408.06675v1,cs.CL
Pragmatic inference of scalar implicature by LLMs,"This study investigates how Large Language Models (LLMs), particularly BERT
(Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic
inference of scalar implicature, such as some. Two sets of experiments were
conducted using cosine similarity and next sentence/token prediction as
experimental methods. The results in experiment 1 showed that, both models
interpret some as pragmatic implicature not all in the absence of context,
aligning with human language processing. In experiment 2, in which Question
Under Discussion (QUD) was presented as a contextual cue, BERT showed
consistent performance regardless of types of QUDs, while GPT-2 encountered
processing difficulties since a certain type of QUD required pragmatic
inference for implicature. The findings revealed that, in terms of theoretical
approaches, BERT inherently incorporates pragmatic implicature not all within
the term some, adhering to Default model (Levinson, 2000). In contrast, GPT-2
seems to encounter processing difficulties in inferring pragmatic implicature
within context, consistent with Context-driven model (Sperber and Wilson,
2002).",2024-08-13,"Ye-eun Cho, Seong mook Kim",http://arxiv.org/pdf/2408.06673v1,cs.CL
Amuro and Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models,"The development of large language models leads to the formation of a
pre-train-then-align paradigm, in which the model is typically pre-trained on a
large text corpus and undergoes a tuning stage to align the model with human
preference or downstream tasks. In this work, we investigate the relationship
between pre-training and fine-tuning by fine-tuning multiple intermediate
pre-trained model checkpoints. Our results on 18 datasets suggest that i)
continual pre-training improves the model in a latent way that unveils after
fine-tuning; ii) with extra fine-tuning, the datasets that the model does not
demonstrate capability gain much more than those that the model performs well
during the pre-training stage; iii) although model benefits significantly
through supervised fine-tuning, it may forget previously known domain knowledge
and the tasks that are not seen during fine-tuning; iv) the model resembles
high sensitivity to evaluation prompts after supervised fine-tuning, but this
sensitivity can be alleviated by more pre-training.",2024-08-13,"Kaiser Sun, Mark Dredze",http://arxiv.org/pdf/2408.06663v5,cs.CL
Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach,"Accurate stock market predictions following earnings reports are crucial for
investors. Traditional methods, particularly classical machine learning models,
struggle with these predictions because they cannot effectively process and
interpret extensive textual data contained in earnings reports and often
overlook nuances that influence market movements. This paper introduces an
advanced approach by employing Large Language Models (LLMs) instruction
fine-tuned with a novel combination of instruction-based techniques and
quantized low-rank adaptation (QLoRA) compression. Our methodology integrates
'base factors', such as financial metric growth and earnings transcripts, with
'external factors', including recent market indices performances and analyst
grades, to create a rich, supervised dataset. This comprehensive dataset
enables our models to achieve superior predictive performance in terms of
accuracy, weighted F1, and Matthews correlation coefficient (MCC), especially
evident in the comparison with benchmarks such as GPT-4. We specifically
highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases
significant improvements over baseline models. The paper also discusses the
potential of expanding the output capabilities to include a 'Hold' option and
extending the prediction horizon, aiming to accommodate various investment
styles and time frames. This study not only demonstrates the power of
integrating cutting-edge AI with fine-tuned financial data but also paves the
way for future research in enhancing AI-driven financial analysis tools.",2024-08-13,"Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan",http://arxiv.org/pdf/2408.06634v2,cs.CL
EditScribe: Non-Visual Image Editing with Natural Language Verification Loops,"Image editing is an iterative process that requires precise visual evaluation
and manipulation for the output to match the editing intent. However, current
image editing tools do not provide accessible interaction nor sufficient
feedback for blind and low vision individuals to achieve this level of control.
To address this, we developed EditScribe, a prototype system that makes image
editing accessible using natural language verification loops powered by large
multimodal models. Using EditScribe, the user first comprehends the image
content through initial general and object descriptions, then specifies edit
actions using open-ended natural language prompts. EditScribe performs the
image edit, and provides four types of verification feedback for the user to
verify the performed edit, including a summary of visual changes, AI judgement,
and updated general and object descriptions. The user can ask follow-up
questions to clarify and probe into the edits or verification feedback, before
performing another edit. In a study with ten blind or low-vision users, we
found that EditScribe supported participants to perform and verify image edit
actions non-visually. We observed different prompting strategies from
participants, and their perceptions on the various types of verification
feedback. Finally, we discuss the implications of leveraging natural language
verification loops to make visual authoring non-visually accessible.",2024-08-13,"Ruei-Che Chang, Yuxuan Liu, Lotus Zhang, Anhong Guo",http://arxiv.org/pdf/2408.06632v1,cs.CL
IFShip: Interpretable Fine-grained Ship Classification with Domain Knowledge-Enhanced Vision-Language Models,"End-to-end interpretation currently dominates the remote sensing fine-grained
ship classification (RS-FGSC) task. However, the inference process remains
uninterpretable, leading to criticisms of these models as ""black box"" systems.
To address this issue, we propose a domain knowledge-enhanced Chain-of-Thought
(CoT) prompt generation mechanism, which is used to semi-automatically
construct a task-specific instruction-following dataset, TITANIC-FGS. By
training on TITANIC-FGS, we adapt general-domain vision-language models (VLMs)
to the FGSC task, resulting in a model named IFShip. Building upon IFShip, we
develop an FGSC visual chatbot that redefines the FGSC problem as a
step-by-step reasoning task and conveys the reasoning process in natural
language. Experimental results show that IFShip outperforms state-of-the-art
FGSC algorithms in both interpretability and classification accuracy.
Furthermore, compared to VLMs such as LLaVA and MiniGPT-4, IFShip demonstrates
superior performance on the FGSC task. It provides an accurate chain of
reasoning when fine-grained ship types are recognizable to the human eye and
offers interpretable explanations when they are not. Our dataset is publicly
available at: https://github.com/lostwolves/IFShip.",2024-08-13,"Mingning Guo, Mengwei Wu, Yuxiang Shen, Haifeng Li, Chao Tao",http://arxiv.org/pdf/2408.06631v4,cs.CL
Style-Talker: Finetuning Audio Language Model and Style-Based Text-to-Speech Model for Fast Spoken Dialogue Generation,"The rapid advancement of large language models (LLMs) has significantly
propelled the development of text-based chatbots, demonstrating their
capability to engage in coherent and contextually relevant dialogues. However,
extending these advancements to enable end-to-end speech-to-speech conversation
bots remains a formidable challenge, primarily due to the extensive dataset and
computational resources required. The conventional approach of cascading
automatic speech recognition (ASR), LLM, and text-to-speech (TTS) models in a
pipeline, while effective, suffers from unnatural prosody because it lacks
direct interactions between the input audio and its transcribed text and the
output audio. These systems are also limited by their inherent latency from the
ASR process for real-time applications. This paper introduces Style-Talker, an
innovative framework that fine-tunes an audio LLM alongside a style-based TTS
model for fast spoken dialog generation. Style-Talker takes user input audio
and uses transcribed chat history and speech styles to generate both the
speaking style and text for the response. Subsequently, the TTS model
synthesizes the speech, which is then played back to the user. While the
response speech is being played, the input speech undergoes ASR processing to
extract the transcription and speaking style, serving as the context for the
ensuing dialogue turn. This novel pipeline accelerates the traditional cascade
ASR-LLM-TTS systems while integrating rich paralinguistic information from
input speech. Our experimental results show that Style-Talker significantly
outperforms the conventional cascade and speech-to-speech baselines in terms of
both dialogue naturalness and coherence while being more than 50% faster.",2024-08-13,"Yinghao Aaron Li, Xilin Jiang, Jordan Darefsky, Ge Zhu, Nima Mesgarani",http://arxiv.org/pdf/2408.11849v1,cs.CL
WorldScribe: Towards Context-Aware Live Visual Descriptions,"Automated live visual descriptions can aid blind people in understanding
their surroundings with autonomy and independence. However, providing
descriptions that are rich, contextual, and just-in-time has been a
long-standing challenge in accessibility. In this work, we develop WorldScribe,
a system that generates automated live real-world visual descriptions that are
customizable and adaptive to users' contexts: (i) WorldScribe's descriptions
are tailored to users' intents and prioritized based on semantic relevance.
(ii) WorldScribe is adaptive to visual contexts, e.g., providing consecutively
succinct descriptions for dynamic scenes, while presenting longer and detailed
ones for stable settings. (iii) WorldScribe is adaptive to sound contexts,
e.g., increasing volume in noisy environments, or pausing when conversations
start. Powered by a suite of vision, language, and sound recognition models,
WorldScribe introduces a description generation pipeline that balances the
tradeoffs between their richness and latency to support real-time use. The
design of WorldScribe is informed by prior work on providing visual
descriptions and a formative study with blind participants. Our user study and
subsequent pipeline evaluation show that WorldScribe can provide real-time and
fairly accurate visual descriptions to facilitate environment understanding
that is adaptive and customized to users' contexts. Finally, we discuss the
implications and further steps toward making live visual descriptions more
context-aware and humanized.",2024-08-13,"Ruei-Che Chang, Yuxuan Liu, Anhong Guo",http://arxiv.org/pdf/2408.06627v1,cs.CL
Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs,"Large Language Models (LLMs) have demonstrated strong reasoning and
memorization capabilities via pretraining on massive textual corpora. However,
this poses risk of privacy and copyright violations, highlighting the need for
efficient machine unlearning methods that remove sensitive data without
retraining from scratch. While Gradient Ascent (GA) is commonly used to unlearn
by reducing the likelihood of generating unwanted content, it leads to unstable
optimization and catastrophic forgetting of retrained knowledge. We find that
combining GA with low-rank adaptation results in poor trade-offs between
computational cost and generative performance. To address these challenges, we
propose Low-rank Knowledge Unlearning (LoKU), a novel framework that enables
robust and efficient unlearning for LLMs. First, we introduce Inverted Hinge
Loss, which suppresses unwanted tokens while maintaining fluency by boosting
the probability of the next most likely token. Second, we develop a
data-adaptive initialization for LoRA adapters via low-rank approximation
weighted with relative Fisher information, thereby focusing updates on
parameters critical for removing targeted knowledge. Experiments on the
Training Data Extraction Challenge dataset using GPT-Neo models as well as on
the TOFU benchmark with Phi-1.5B and Llama2-7B models demonstrate that our
approach effectively removes sensitive information while maintaining reasoning
and generative capabilities with minimal impact. Our implementation can be
found in https://github.com/csm9493/efficient-llm-unlearning.",2024-08-13,"Sungmin Cha, Sungjun Cho, Dasol Hwang, Moontae Lee",http://arxiv.org/pdf/2408.06621v5,cs.CL
Generalized knowledge-enhanced framework for biomedical entity and relation extraction,"In recent years, there has been an increasing number of frameworks developed
for biomedical entity and relation extraction. This research effort aims to
address the accelerating growth in biomedical publications and the intricate
nature of biomedical texts, which are written for mainly domain experts. To
handle these challenges, we develop a novel framework that utilizes external
knowledge to construct a task-independent and reusable background knowledge
graph for biomedical entity and relation extraction. The design of our model is
inspired by how humans learn domain-specific topics. In particular, humans
often first acquire the most basic and common knowledge regarding a field to
build the foundational knowledge and then use that as a basis for extending to
various specialized topics. Our framework employs such common-knowledge-sharing
mechanism to build a general neural-network knowledge graph that is learning
transferable to different domain-specific biomedical texts effectively.
Experimental evaluations demonstrate that our model, equipped with this
generalized and cross-transferable knowledge base, achieves competitive
performance benchmarks, including BioRelEx for binding interaction detection
and ADE for Adverse Drug Effect identification.",2024-08-13,"Minh Nguyen, Phuong Le",http://arxiv.org/pdf/2408.06618v1,cs.CL
CROME: Cross-Modal Adapters for Efficient Multimodal LLM,"Multimodal Large Language Models (MLLMs) demonstrate remarkable
image-language capabilities, but their widespread use faces challenges in
cost-effective training and adaptation. Existing approaches often necessitate
expensive language model retraining and limited adaptability. Additionally, the
current focus on zero-shot performance improvements offers insufficient
guidance for task-specific tuning. We propose CROME, an efficient
vision-language instruction tuning framework. It features a novel gated
cross-modal adapter that effectively combines visual and textual
representations prior to input into a frozen LLM. This lightweight adapter,
trained with minimal parameters, enables efficient cross-modal understanding.
Notably, CROME demonstrates superior zero-shot performance on standard visual
question answering and instruction-following benchmarks. Moreover, it yields
fine-tuning with exceptional parameter efficiency, competing with task-specific
specialist state-of-the-art methods. CROME demonstrates the potential of pre-LM
alignment for building scalable, adaptable, and parameter-efficient multimodal
models.",2024-08-13,"Sayna Ebrahimi, Sercan O. Arik, Tejas Nama, Tomas Pfister",http://arxiv.org/pdf/2408.06610v1,cs.CL
"A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition","Large Language Models (LLMs) are known for their remarkable ability to
generate synthesized 'knowledge', such as text documents, music, images, etc.
However, there is a huge gap between LLM's and human capabilities for
understanding abstract concepts and reasoning. We discuss these issues in a
larger philosophical context of human knowledge acquisition and the Turing
test. In addition, we illustrate the limitations of LLMs by analyzing GPT-4
responses to questions ranging from science and math to common sense reasoning.
These examples show that GPT-4 can often imitate human reasoning, even though
it lacks understanding. However, LLM responses are synthesized from a large LLM
model trained on all available data. In contrast, human understanding is based
on a small number of abstract concepts. Based on this distinction, we discuss
the impact of LLMs on acquisition of human knowledge and education.",2024-08-13,"Vladimir Cherkassky, Eng Hock Lee",http://arxiv.org/pdf/2408.06598v1,cs.CL
A Structure-aware Generative Model for Biomedical Event Extraction,"Biomedical Event Extraction (BEE) is a challenging task that involves
modeling complex relationships between fine-grained entities in biomedical
text. BEE has traditionally been formulated as a classification problem. With
recent advancements in large language models (LLMs), generation-based models
that cast event extraction as a sequence generation problem have attracted
attention in the NLP research community. However, current generative models
often overlook cross-instance information in complex event structures, such as
nested and overlapping events, which constitute over 20% of events in benchmark
datasets. In this paper, we propose GenBEE, an event structure-aware generative
model that captures complex event structures in biomedical text for biomedical
event extraction. GenBEE constructs event prompts that distill knowledge from
LLMs to incorporate both label semantics and argument dependency relationships.
In addition, GenBEE generates prefixes with event structural prompts to
incorporate structural features to improve the model's overall performance. We
have evaluated the proposed GenBEE model on three widely used BEE benchmark
datasets, namely MLEE, GE11, and PHEE. Experimental results show that GenBEE
has achieved state-of-the-art performance on the MLEE and GE11 datasets, and
achieved competitive results when compared to the state-of-the-art
classification-based models on the PHEE dataset.",2024-08-13,"Haohan Yuan, Siu Cheung Hui, Haopeng Zhang",http://arxiv.org/pdf/2408.06583v5,cs.CL
OpenEP: Open-Ended Future Event Prediction,"Future event prediction (FEP) is a long-standing and crucial task in the
world, as understanding the evolution of events enables early risk
identification, informed decision-making, and strategic planning. Existing work
typically treats event prediction as classification tasks and confines the
outcomes of future events to a fixed scope, such as yes/no questions, candidate
set, and taxonomy, which is difficult to include all possible outcomes of
future events. In this paper, we introduce OpenEP (an Open-Ended Future Event
Prediction task), which generates flexible and diverse predictions aligned with
real-world scenarios. This is mainly reflected in two aspects: firstly, the
predictive questions are diverse, covering different stages of event
development and perspectives; secondly, the outcomes are flexible, without
constraints on scope or format. To facilitate the study of this task, we
construct OpenEPBench, an open-ended future event prediction dataset. For
question construction, we pose questions from seven perspectives, including
location, time, event development, event outcome, event impact, event response,
and other, to facilitate an in-depth analysis and understanding of the
comprehensive evolution of events. For outcome construction, we collect
free-form text containing the outcomes as ground truth to provide semantically
complete and detail-enriched outcomes. Furthermore, we propose StkFEP, a
stakeholder-enhanced future event prediction framework, that incorporates event
characteristics for open-ended settings. Our method extracts stakeholders
involved in events to extend questions to gather diverse information. We also
collect historically events that are relevant and similar to the question to
reveal potential evolutionary patterns. Experiment results indicate that
accurately predicting future events in open-ended settings is challenging for
existing LLMs.",2024-08-13,"Yong Guan, Hao Peng, Xiaozhi Wang, Lei Hou, Juanzi Li",http://arxiv.org/pdf/2408.06578v2,cs.CL
CTISum: A New Benchmark Dataset For Cyber Threat Intelligence Summarization,"Cyber Threat Intelligence (CTI) summarization task requires the system to
generate concise and accurate highlights from raw intelligence data, which
plays an important role in providing decision-makers with crucial information
to quickly detect and respond to cyber threats in the cybersecurity domain.
However, efficient techniques for summarizing CTI reports, including facts,
analytical insights, attack processes, etc., have largely been unexplored,
primarily due to the lack of available dataset. To this end, we present CTISum,
a new benchmark for CTI summarization task. Considering the importance of
attack process, a novel fine-grained subtask of attack process summarization is
proposed to enable defenders to assess risk, identify security gaps,
vulnerabilities, and so on. Specifically, we first design a multi-stage
annotation pipeline to gather and annotate the CTI data, and then benchmark the
CTISum with a collection of extractive and abstractive summarization methods.
Experimental results show that current state-of-the-art models exhibit
limitations when applied to CTISum, underscoring the fact that automatically
producing concise summaries of CTI reports remains an open research challenge.",2024-08-13,"Wei Peng, Junmei Ding, Wei Wang, Lei Cui, Wei Cai, Zhiyu Hao, Xiaochun Yun",http://arxiv.org/pdf/2408.06576v1,cs.CL
SparkRA: A Retrieval-Augmented Knowledge Service System Based on Spark Large Language Model,"Large language models (LLMs) have shown remarkable achievements across
various language tasks.To enhance the performance of LLMs in scientific
literature services, we developed the scientific literature LLM (SciLit-LLM)
through pre-training and supervised fine-tuning on scientific literature,
building upon the iFLYTEK Spark LLM. Furthermore, we present a knowledge
service system Spark Research Assistant (SparkRA) based on our SciLit-LLM.
SparkRA is accessible online and provides three primary functions: literature
investigation, paper reading, and academic writing. As of July 30, 2024,
SparkRA has garnered over 50,000 registered users, with a total usage count
exceeding 1.3 million.",2024-08-13,"Dayong Wu, Jiaqi Li, Baoxin Wang, Honghong Zhao, Siyuan Xue, Yanjie Yang, Zhijun Chang, Rui Zhang, Li Qian, Bo Wang, Shijin Wang, Zhixiong Zhang, Guoping Hu",http://arxiv.org/pdf/2408.06574v1,cs.CL
Social Debiasing for Fair Multi-modal LLMs,"Multi-modal Large Language Models (MLLMs) have advanced significantly,
offering powerful vision-language understanding capabilities. However, these
models often inherit severe social biases from their training datasets, leading
to unfair predictions based on attributes like race and gender. This paper
addresses the issue of social biases in MLLMs by i) Introducing a comprehensive
Counterfactual dataset with Multiple Social Concepts (CMSC), which provides a
more diverse and extensive training set compared to existing datasets. ii)
Proposing an Anti-Stereotype Debiasing strategy (ASD). Our method works by
revisiting the MLLM training process, rescaling the autoregressive loss
function, and improving data sampling methods to counteract biases. Through
extensive experiments on various MLLMs, our CMSC dataset and ASD method
demonstrate a significant reduction in social biases while maintaining the
models' original performance.",2024-08-13,"Harry Cheng, Yangyang Guo, Qingpei Guo, Ming Yang, Tian Gan, Liqiang Nie",http://arxiv.org/pdf/2408.06569v1,cs.CL
AquilaMoE: Efficient Training for MoE Models with Scale-Up and Scale-Out Strategies,"In recent years, with the rapid application of large language models across
various fields, the scale of these models has gradually increased, and the
resources required for their pre-training have grown exponentially. Training an
LLM from scratch will cost a lot of computation resources while scaling up from
a smaller model is a more efficient approach and has thus attracted significant
attention. In this paper, we present AquilaMoE, a cutting-edge bilingual 8*16B
Mixture of Experts (MoE) language model that has 8 experts with 16 billion
parameters each and is developed using an innovative training methodology
called EfficientScale. This approach optimizes performance while minimizing
data requirements through a two-stage process. The first stage, termed
Scale-Up, initializes the larger model with weights from a pre-trained smaller
model, enabling substantial knowledge transfer and continuous pretraining with
significantly less data. The second stage, Scale-Out, uses a pre-trained dense
model to initialize the MoE experts, further enhancing knowledge transfer and
performance. Extensive validation experiments on 1.8B and 7B models compared
various initialization schemes, achieving models that maintain and reduce loss
during continuous pretraining. Utilizing the optimal scheme, we successfully
trained a 16B model and subsequently the 8*16B AquilaMoE model, demonstrating
significant improvements in performance and training efficiency.",2024-08-13,"Bo-Wen Zhang, Liangdong Wang, Ye Yuan, Jijie Li, Shuhao Gu, Mengdi Zhao, Xinya Wu, Guang Liu, Chengwei Wu, Hanyu Zhao, Li Du, Yiming Ju, Quanyue Ma, Yulong Ao, Yingli Zhao, Songhe Zhu, Zhou Cao, Dong Liang, Yonghua Lin, Ming Zhang, Shunfei Wang, Yanxin Zhou, Min Ye, Xuekai Chen, Xinyang Yu, Xiangjun Huang, Jian Yang",http://arxiv.org/pdf/2408.06567v1,cs.CL
MGH Radiology Llama: A Llama 3 70B Model for Radiology,"In recent years, the field of radiology has increasingly harnessed the power
of artificial intelligence (AI) to enhance diagnostic accuracy, streamline
workflows, and improve patient care. Large language models (LLMs) have emerged
as particularly promising tools, offering significant potential in assisting
radiologists with report generation, clinical decision support, and patient
communication. This paper presents an advanced radiology-focused large language
model: MGH Radiology Llama. It is developed using the Llama 3 70B model,
building upon previous domain-specific models like Radiology-GPT and
Radiology-Llama2. Leveraging a unique and comprehensive dataset from
Massachusetts General Hospital, comprising over 6.5 million de-identified
medical reports across various imaging modalities, the model demonstrates
significant improvements in generating accurate and clinically relevant
radiology impressions given the corresponding findings. Our evaluation,
incorporating both traditional metrics and a GPT-4-based assessment, highlights
the enhanced performance of this work over general-purpose LLMs.",2024-08-13,"Yucheng Shi, Peng Shu, Zhengliang Liu, Zihao Wu, Quanzheng Li, Tianming Liu, Ninghao Liu, Xiang Li",http://arxiv.org/pdf/2408.11848v2,cs.CL
Introducing the NewsPaLM MBR and QE Dataset: LLM-Generated High-Quality Parallel Data Outperforms Traditional Web-Crawled Data,"Recent research in neural machine translation (NMT) has shown that training
on high-quality machine-generated data can outperform training on
human-generated data. This work accompanies the first-ever release of a
LLM-generated, MBR-decoded and QE-reranked dataset with both sentence-level and
multi-sentence examples. We perform extensive experiments to demonstrate the
quality of our dataset in terms of its downstream impact on NMT model
performance. We find that training from scratch on our (machine-generated)
dataset outperforms training on the (web-crawled) WMT'23 training dataset
(which is 300 times larger), and also outperforms training on the top-quality
subset of the WMT'23 training dataset. We also find that performing
self-distillation by finetuning the LLM which generated this dataset
outperforms the LLM's strong few-shot baseline. These findings corroborate the
quality of our dataset, and demonstrate the value of high-quality
machine-generated data in improving performance of NMT models.",2024-08-13,"Mara Finkelstein, David Vilar, Markus Freitag",http://arxiv.org/pdf/2408.06537v5,cs.CL
Rethinking the Alignment of Psychotherapy Dialogue Generation with Motivational Interviewing Strategies,"Recent advancements in large language models (LLMs) have shown promise in
generating psychotherapeutic dialogues, particularly in the context of
motivational interviewing (MI). However, the inherent lack of transparency in
LLM outputs presents significant challenges given the sensitive nature of
psychotherapy. Applying MI strategies, a set of MI skills, to generate more
controllable therapeutic-adherent conversations with explainability provides a
possible solution. In this work, we explore the alignment of LLMs with MI
strategies by first prompting the LLMs to predict the appropriate strategies as
reasoning and then utilizing these strategies to guide the subsequent dialogue
generation. We seek to investigate whether such alignment leads to more
controllable and explainable generations. Multiple experiments including
automatic and human evaluations are conducted to validate the effectiveness of
MI strategies in aligning psychotherapy dialogue generation. Our findings
demonstrate the potential of LLMs in producing strategically aligned dialogues
and suggest directions for practical applications in psychotherapeutic
settings.",2024-08-12,"Xin Sun, Xiao Tang, Abdallah El Ali, Zhuying Li, Pengjie Ren, Jan de Wit, Jiahuan Pei, Jos A. Bosch",http://arxiv.org/pdf/2408.06527v2,cs.CL
Retrieval-Augmented Hierarchical in-Context Reinforcement Learning and Hindsight Modular Reflections for Task Planning with LLMs,"Large Language Models (LLMs) have demonstrated remarkable abilities in
various language tasks, making them promising candidates for decision-making in
robotics. Inspired by Hierarchical Reinforcement Learning (HRL), we propose
Retrieval-Augmented in-context reinforcement Learning (RAHL), a novel framework
that decomposes complex tasks into sub-tasks using an LLM-based high-level
policy, in which a complex task is decomposed into sub-tasks by a high-level
policy on-the-fly. The sub-tasks, defined by goals, are assigned to the
low-level policy to complete. To improve the agent's performance in
multi-episode execution, we propose Hindsight Modular Reflection (HMR), where,
instead of reflecting on the full trajectory, we let the agent reflect on
shorter sub-trajectories to improve reflection efficiency. We evaluated the
decision-making ability of the proposed RAHL in three benchmark
environments--ALFWorld, Webshop, and HotpotQA. The results show that RAHL can
achieve an improvement in performance in 9%, 42%, and 10% in 5 episodes of
execution in strong baselines. Furthermore, we also implemented RAHL on the
Boston Dynamics SPOT robot. The experiment shows that the robot can scan the
environment, find entrances, and navigate to new rooms controlled by the LLM
policy.",2024-08-12,"Chuanneng Sun, Songjun Huang, Dario Pompili",http://arxiv.org/pdf/2408.06520v2,cs.CL
Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models,"Despite their wide adoption, the biases and unintended behaviors of language
models remain poorly understood. In this paper, we identify and characterize a
phenomenon never discussed before, which we call semantic leakage, where models
leak irrelevant information from the prompt into the generation in unexpected
ways. We propose an evaluation setting to detect semantic leakage both by
humans and automatically, curate a diverse test suite for diagnosing this
behavior, and measure significant semantic leakage in 13 flagship models. We
also show that models exhibit semantic leakage in languages besides English and
across different settings and generation scenarios. This discovery highlights
yet another type of bias in language models that affects their generation
patterns and behavior.",2024-08-12,"Hila Gonen, Terra Blevins, Alisa Liu, Luke Zettlemoyer, Noah A. Smith",http://arxiv.org/pdf/2408.06518v3,cs.CL
What Color Scheme is More Effective in Assisting Readers to Locate Information in a Color-Coded Article?,"Color coding, a technique assigning specific colors to cluster information
types, has proven advantages in aiding human cognitive activities, especially
reading and comprehension. The rise of Large Language Models (LLMs) has
streamlined document coding, enabling simple automatic text labeling with
various schemes. This has the potential to make color-coding more accessible
and benefit more users. However, the impact of color choice on information
seeking is understudied. We conducted a user study assessing various color
schemes' effectiveness in LLM-coded text documents, standardizing contrast
ratios to approximately 5.55:1 across schemes. Participants performed timed
information-seeking tasks in color-coded scholarly abstracts. Results showed
non-analogous and yellow-inclusive color schemes improved performance, with the
latter also being more preferred by participants. These findings can inform
better color scheme choices for text annotation. As LLMs advance document
coding, we advocate for more research focusing on the ""color"" aspect of
color-coding techniques.",2024-08-12,"Ho Yin Ng, Zeyu He, Ting-Hao 'Kenneth' Huang",http://arxiv.org/pdf/2408.06494v2,cs.CL
Cross-Lingual Conversational Speech Summarization with Large Language Models,"Cross-lingual conversational speech summarization is an important problem,
but suffers from a dearth of resources. While transcriptions exist for a number
of languages, translated conversational speech is rare and datasets containing
summaries are non-existent. We build upon the existing Fisher and Callhome
Spanish-English Speech Translation corpus by supplementing the translations
with summaries. The summaries are generated using GPT-4 from the reference
translations and are treated as ground truth. The task is to generate similar
summaries in the presence of transcription and translation errors. We build a
baseline cascade-based system using open-source speech recognition and machine
translation models. We test a range of LLMs for summarization and analyze the
impact of transcription and translation errors. Adapting the Mistral-7B model
for this task performs significantly better than off-the-shelf models and
matches the performance of GPT-4.",2024-08-12,"Max Nelson, Shannon Wotherspoon, Francis Keith, William Hartmann, Matthew Snover",http://arxiv.org/pdf/2408.06484v1,cs.CL
TOGGL: Transcribing Overlapping Speech with Staggered Labeling,"Transcribing the speech of multiple overlapping speakers typically requires
separating the audio into multiple streams and recognizing each one
independently. More recent work jointly separates and transcribes, but requires
a separate decoding component for each speaker. We propose the TOGGL model to
simultaneously transcribe the speech of multiple speakers. The TOGGL model uses
special output tokens to attribute the speech to each speaker with only a
single decoder. Our approach generalizes beyond two speakers, even when trained
only on two-speaker data. We demonstrate superior performance compared to
competing approaches on a conversational speech dataset. Our approach also
improves performance on single-speaker audio.",2024-08-12,"Chak-Fai Li, William Hartmann, Matthew Snover",http://arxiv.org/pdf/2408.06474v1,cs.CL
"Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models","We propose a novel in-context learning algorithm for building autonomous
decision-making language agents. The language agent continuously attempts to
solve the same task by self-correcting each time the task fails. Our selected
language agent demonstrates the ability to solve tasks in a text-based game
environment. Our results show that the gemma-2-9b-it language model, using our
proposed method, can successfully complete two of six tasks that failed in the
first attempt. This highlights the effectiveness of our approach in enhancing
the problem-solving capabilities of a single language model through
self-correction, paving the way for more advanced autonomous agents. The code
is publicly available at
https://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",2024-08-12,"Abhishek Dutta, Yen-Che Hsiao",http://arxiv.org/pdf/2408.06458v2,cs.CL
Evaluating Language Models for Efficient Code Generation,"We introduce Differential Performance Evaluation (DPE), a framework designed
to reliably evaluate Large Language Models (LLMs) for efficient code
generation. Traditional coding benchmarks often fail to provide reliable
insights into code efficiency, due to their reliance on simplistic test inputs
and the absence of effective compound metrics. DPE addresses these issues by
focusing on efficiency-demanding programming tasks and establishing an
insightful compound metric for performance evaluation. DPE operates in two
phases: To curate efficiency datasets, it selects efficiency-demanding tasks
from existing coding benchmarks and generates computationally expensive inputs
to stress the efficiency of LLM solutions. To assess the code efficiency, DPE
profiles the new solution and compares it globally against a set of reference
solutions that exhibit distinct efficiency levels, where the matched level
defines its efficiency score. As a proof of concept, we use DPE to create
EvalPerf, a benchmark with 121 performance-challenging coding tasks. Our
comprehensive evaluation draws interesting findings on the efficiency impact of
model sizes, instruction tuning, and prompting. For example, while the scaling
law fails to account for code efficiency, general instruction tuning benefits
both code correctness and efficiency. We also evaluate the evaluation by
examining the effectiveness of DPE, showing that EvalPerf is reliable and
convenient to use even across platforms.",2024-08-12,"Jiawei Liu, Songrun Xie, Junhao Wang, Yuxiang Wei, Yifeng Ding, Lingming Zhang",http://arxiv.org/pdf/2408.06450v1,cs.CL
Statistical Patterns in the Equations of Physics and the Emergence of a Meta-Law of Nature,"Physics, as a fundamental science, aims to understand the laws of Nature and
describe them in mathematical equations. While the physical reality manifests
itself in a wide range of phenomena with varying levels of complexity, the
equations that describe them display certain statistical regularities and
patterns, which we begin to explore here. By drawing inspiration from
linguistics, where Zipf's law states that the frequency of any word in a large
corpus of text is roughly inversely proportional to its rank in the frequency
table, we investigate whether similar patterns for the distribution of
operators emerge in the equations of physics. We analyse three corpora of
formulae and find, using sophisticated implicit-likelihood methods, that the
frequency of operators as a function of their rank in the frequency table is
best described by an exponential law with a stable exponent, in contrast with
Zipf's inverse power-law. Understanding the underlying reasons behind this
statistical pattern may shed light on Nature's modus operandi or reveal
recurrent patterns in physicists' attempts to formalise the laws of Nature. It
may also provide crucial input for symbolic regression, potentially augmenting
language models to generate symbolic models for physical phenomena. By
pioneering the study of statistical regularities in the equations of physics,
our results open the door for a meta-law of Nature, a (probabilistic) law that
all physical laws obey.",2024-08-12,"Andrei Constantin, Deaglan Bartlett, Harry Desmond, Pedro G. Ferreira",http://arxiv.org/pdf/2408.11065v1,cs.CL
Evaluating LLMs on Entity Disambiguation in Tables,"Tables are crucial containers of information, but understanding their meaning
may be challenging. Over the years, there has been a surge in interest in
data-driven approaches based on deep learning that have increasingly been
combined with heuristic-based ones. In the last period, the advent of
\acf{llms} has led to a new category of approaches for table annotation.
However, these approaches have not been consistently evaluated on a common
ground, making evaluation and comparison difficult. This work proposes an
extensive evaluation of four STI SOTA approaches: Alligator (formerly s-elbat),
Dagobah, TURL, and TableLlama; the first two belong to the family of
heuristic-based algorithms, while the others are respectively encoder-only and
decoder-only Large Language Models (LLMs). We also include in the evaluation
both GPT-4o and GPT-4o-mini, since they excel in various public benchmarks. The
primary objective is to measure the ability of these approaches to solve the
entity disambiguation task with respect to both the performance achieved on a
common-ground evaluation setting and the computational and cost requirements
involved, with the ultimate aim of charting new research paths in the field.",2024-08-12,"Federico Belotti, Fabio Dadda, Marco Cremaschi, Roberto Avogadro, Matteo Palmonari",http://arxiv.org/pdf/2408.06423v3,cs.CL
"LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification","This paper explores humor detection through a linguistic lens, prioritizing
syntactic, semantic, and contextual features over computational methods in
Natural Language Processing. We categorize features into syntactic, semantic,
and contextual dimensions, including lexicons, structural statistics, Word2Vec,
WordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT
embeddings and parallel hidden layers to capture sentence congruity. By
combining syntactic, semantic, and contextual features, we train Colbert for
humor detection. Feature engineering examines essential syntactic and semantic
features alongside BERT embeddings. SHAP interpretations and decision trees
identify influential features, revealing that a holistic approach improves
humor detection accuracy on unseen data. Integrating linguistic cues from
different dimensions enhances the model's ability to understand humor
complexity beyond traditional computational methods.",2024-08-12,"Tanisha Khurana, Kaushik Pillalamarri, Vikram Pande, Munindar Singh",http://arxiv.org/pdf/2408.06335v1,cs.CL
FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection,"Open Domain Question Answering (ODQA) has been advancing rapidly in recent
times, driven by significant developments in dense passage retrieval and
pretrained language models. Current models typically incorporate the FiD
framework, which is composed by a neural retriever alongside an encoder-decoder
neural reader. In the answer generation process, the retriever will retrieve
numerous passages (around 100 for instance), each of which is then individually
encoded by the encoder. Subsequently, the decoder makes predictions based on
these encoded passages. Nevertheless, this framework can be relatively
time-consuming, particularly due to the extensive length of the gathered
passages. To address this, we introduce FastFiD in this paper, a novel approach
that executes sentence selection on the encoded passages. This aids in
retaining valuable sentences while reducing the context length required for
generating answers. Experiments on three commonly used datasets (Natural
Questions, TriviaQA and ASQA) demonstrate that our method can enhance the
inference speed by 2.3X-5.7X, while simultaneously maintaining the model's
performance. Moreover, an in-depth analysis of the model's attention reveals
that the selected sentences indeed hold a substantial contribution towards the
final answer. The codes are publicly available at
https://github.com/thunlp/FastFiD.",2024-08-12,"Yufei Huang, Xu Han, Maosong Sun",http://arxiv.org/pdf/2408.06333v1,cs.CL
"Animate, or Inanimate, That is the Question for Large Language Models","The cognitive essence of humans is deeply intertwined with the concept of
animacy, which plays an essential role in shaping their memory, vision, and
multi-layered language understanding. Although animacy appears in language via
nuanced constraints on verbs and adjectives, it is also learned and refined
through extralinguistic information. Similarly, we assume that the LLMs'
limited abilities to understand natural language when processing animacy are
motivated by the fact that these models are trained exclusively on text.
  Hence, the question this paper aims to answer arises: can LLMs, in their
digital wisdom, process animacy in a similar way to what humans would do? We
then propose a systematic analysis via prompting approaches. In particular, we
probe different LLMs by prompting them using animate, inanimate, usual, and
stranger contexts. Results reveal that, although LLMs have been trained
predominantly on textual data, they exhibit human-like behavior when faced with
typical animate and inanimate entities in alignment with earlier studies.
Hence, LLMs can adapt to understand unconventional situations by recognizing
oddities as animated without needing to interface with unspoken cognitive
triggers humans rely on to break down animations.",2024-08-12,"Leonardo Ranaldi, Giulia Pucci, Fabio Massimo Zanzotto",http://arxiv.org/pdf/2408.06332v1,cs.CL
VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents,"Large Multimodal Models (LMMs) have ushered in a new era in artificial
intelligence, merging capabilities in both language and vision to form highly
capable Visual Foundation Agents. These agents are postulated to excel across a
myriad of tasks, potentially approaching general artificial intelligence.
However, existing benchmarks fail to sufficiently challenge or showcase the
full potential of LMMs in complex, real-world environments. To address this
gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering
benchmark specifically designed to train and evaluate LMMs as visual foundation
agents across diverse scenarios, including Embodied, Graphical User Interface,
and Visual Design, with tasks formulated to probe the depth of LMMs'
understanding and interaction capabilities. Through rigorous testing across
nine proprietary LMM APIs and eight open models, we demonstrate the
considerable yet still developing agent capabilities of these models.
Additionally, VAB constructs a trajectory training set constructed through
hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and
Human Demonstrations, promoting substantial performance improvements in LMMs
through behavior cloning. Our work not only aims to benchmark existing models
but also provides a solid foundation for future development into visual
foundation agents. Code, train \& test data, and part of fine-tuned open LMMs
are available at \url{https://github.com/THUDM/VisualAgentBench}.",2024-08-12,"Xiao Liu, Tianjie Zhang, Yu Gu, Iat Long Iong, Yifan Xu, Xixuan Song, Shudan Zhang, Hanyu Lai, Xinyi Liu, Hanlin Zhao, Jiadai Sun, Xinyue Yang, Yu Yang, Zehan Qi, Shuntian Yao, Xueqiao Sun, Siyi Cheng, Qinkai Zheng, Hao Yu, Hanchen Zhang, Wenyi Hong, Ming Ding, Lihang Pan, Xiaotao Gu, Aohan Zeng, Zhengxiao Du, Chan Hee Song, Yu Su, Yuxiao Dong, Jie Tang",http://arxiv.org/pdf/2408.06327v1,cs.CL
Long-Form Answers to Visual Questions from Blind and Low Vision People,"Vision language models can now generate long-form answers to questions about
images - long-form visual question answers (LFVQA). We contribute VizWiz-LF, a
dataset of long-form answers to visual questions posed by blind and low vision
(BLV) users. VizWiz-LF contains 4.2k long-form answers to 600 visual questions,
collected from human expert describers and six VQA models. We develop and
annotate functional roles of sentences of LFVQA and demonstrate that long-form
answers contain information beyond the question answer such as explanations and
suggestions. We further conduct automatic and human evaluations with BLV and
sighted people to evaluate long-form answers. BLV people perceive both
human-written and generated long-form answers to be plausible, but generated
answers often hallucinate incorrect visual details, especially for unanswerable
visual questions (e.g., blurry or irrelevant images). To reduce hallucinations,
we evaluate the ability of VQA models to abstain from answering unanswerable
questions across multiple prompting strategies.",2024-08-12,"Mina Huh, Fangyuan Xu, Yi-Hao Peng, Chongyan Chen, Hansika Murugu, Danna Gurari, Eunsol Choi, Amy Pavel",http://arxiv.org/pdf/2408.06303v1,cs.CL
The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery,"One of the grand challenges of artificial general intelligence is developing
agents capable of conducting scientific research and discovering new knowledge.
While frontier models have already been used as aides to human scientists, e.g.
for brainstorming ideas, writing code, or prediction tasks, they still conduct
only a small part of the scientific process. This paper presents the first
comprehensive framework for fully automatic scientific discovery, enabling
frontier large language models to perform research independently and
communicate their findings. We introduce The AI Scientist, which generates
novel research ideas, writes code, executes experiments, visualizes results,
describes its findings by writing a full scientific paper, and then runs a
simulated review process for evaluation. In principle, this process can be
repeated to iteratively develop ideas in an open-ended fashion, acting like the
human scientific community. We demonstrate its versatility by applying it to
three distinct subfields of machine learning: diffusion modeling,
transformer-based language modeling, and learning dynamics. Each idea is
implemented and developed into a full paper at a cost of less than $15 per
paper. To evaluate the generated papers, we design and validate an automated
reviewer, which we show achieves near-human performance in evaluating paper
scores. The AI Scientist can produce papers that exceed the acceptance
threshold at a top machine learning conference as judged by our automated
reviewer. This approach signifies the beginning of a new era in scientific
discovery in machine learning: bringing the transformative benefits of AI
agents to the entire research process of AI itself, and taking us closer to a
world where endless affordable creativity and innovation can be unleashed on
the world's most challenging problems. Our code is open-sourced at
https://github.com/SakanaAI/AI-Scientist",2024-08-12,"Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha",http://arxiv.org/pdf/2408.06292v3,cs.CL
Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM,"Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.",2024-08-12,"Trisha Das, Dina Albassam, Jimeng Sun",http://arxiv.org/pdf/2408.06285v1,cs.CL
MovieSum: An Abstractive Summarization Dataset for Movie Screenplays,"Movie screenplay summarization is challenging, as it requires an
understanding of long input contexts and various elements unique to movies.
Large language models have shown significant advancements in document
summarization, but they often struggle with processing long input contexts.
Furthermore, while television transcripts have received attention in recent
studies, movie screenplay summarization remains underexplored. To stimulate
research in this area, we present a new dataset, MovieSum, for abstractive
summarization of movie screenplays. This dataset comprises 2200 movie
screenplays accompanied by their Wikipedia plot summaries. We manually
formatted the movie screenplays to represent their structural elements.
Compared to existing datasets, MovieSum possesses several distinctive features:
(1) It includes movie screenplays, which are longer than scripts of TV
episodes. (2) It is twice the size of previous movie screenplay datasets. (3)
It provides metadata with IMDb IDs to facilitate access to additional external
knowledge. We also show the results of recently released large language models
applied to summarization on our dataset to provide a detailed baseline.",2024-08-12,"Rohit Saxena, Frank Keller",http://arxiv.org/pdf/2408.06281v1,cs.CL
Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation,"Recent advancements in Large Language Models (LLMs) have demonstrated
exceptional performance across a wide range of tasks, generating significant
interest in their application to recommendation systems. However, existing
methods have not fully capitalized on the potential of LLMs, often constrained
by limited input information or failing to fully utilize their advanced
reasoning capabilities. To address these limitations, we introduce EXP3RT, a
novel LLM-based recommender designed to leverage rich preference information
contained in user and item reviews. EXP3RT is basically fine-tuned through
distillation from a teacher LLM to perform three key tasks in order: EXP3RT
first extracts and encapsulates essential subjective preferences from raw
reviews, aggregates and summarizes them according to specific criteria to
create user and item profiles. It then generates detailed step-by-step
reasoning followed by predicted rating, i.e., reasoning-enhanced rating
prediction, by considering both subjective and objective information from
user/item profiles and item descriptions. This personalized preference
reasoning from EXP3RT enhances rating prediction accuracy and also provides
faithful and reasonable explanations for recommendation. Extensive experiments
show that EXP3RT outperforms existing methods on both rating prediction and
candidate item reranking for top-k recommendation, while significantly
enhancing the explainability of recommendation systems.",2024-08-12,"Jieyong Kim, Hyunseo Kim, Hyunjin Cho, SeongKu Kang, Buru Chang, Jinyoung Yeo, Dongha Lee",http://arxiv.org/pdf/2408.06276v5,cs.CL
FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data,"Large language models (LLMs) have demonstrated prowess in a wide range of
tasks. However, many LLMs exhibit significant performance discrepancies between
high- and low-resource languages. To mitigate this challenge, we present
FuxiTranyu, an open-source multilingual LLM, which is designed to satisfy the
need of the research community for balanced and high-performing multilingual
capabilities. The base model, FuxiTranyu-8B, features 8 billion parameters and
is trained from scratch on meticulously balanced multilingual data that
contains 600 billion tokens covering 43 natural languages and 16 programming
languages. We also develop two instruction-tuned models: FuxiTranyu-8B-SFT
which is fine-tuned on a diverse multilingual instruction dataset, and
FuxiTranyu-8B-DPO which is further refined with DPO on a preference dataset for
enhanced alignment ability. Extensive experiments on a wide range of
multilingual benchmarks demonstrate the competitive performance of FuxiTranyu
against existing multilingual LLMs, e.g., BLOOM-7B, PolyLM-13B, and
Mistral-7B-Instruct. Both neuron and representation interpretability analyses
reveal that FuxiTranyu achieves consistent multilingual representations across
languages. To promote further research into multilingual LLMs, we release both
the base and instruction-tuned FuxiTranyu models together with 58 pre-training
checkpoints at HuggingFace (see https://huggingface.co/TJUNLP/FuxiTranyu-8B)
and Github (see https://github.com/tjunlp-lab/FuxiTranyu).",2024-08-12,"Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong",http://arxiv.org/pdf/2408.06273v3,cs.CL
Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment,"Large Language Models (LLMs) are often aligned using contrastive alignment
objectives and preference pair datasets. The interaction between model, paired
data, and objective makes alignment a complicated procedure, sometimes
producing subpar results. We study this and find that (i) preference data gives
a better learning signal when the underlying responses are contrastive, and
(ii) alignment objectives lead to better performance when they specify more
control over the model during training. Based on these insights, we introduce
Contrastive Learning from AI Revisions (CLAIR), a data-creation method which
leads to more contrastive preference pairs, and Anchored Preference
Optimization (APO), a controllable and more stable alignment objective. We
align Llama-3-8B-Instruct using various comparable datasets and alignment
objectives and measure MixEval-Hard scores, which correlate highly with human
judgments. The CLAIR preferences lead to the strongest performance out of all
datasets, and APO consistently outperforms less controllable objectives. Our
best model, trained on 32K CLAIR preferences with APO, improves
Llama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code
is available at https://github.com/ContextualAI/CLAIR_and_APO.",2024-08-12,"Karel D'Oosterlinck, Winnie Xu, Chris Develder, Thomas Demeester, Amanpreet Singh, Christopher Potts, Douwe Kiela, Shikib Mehri",http://arxiv.org/pdf/2408.06266v5,cs.CL
Context-aware Visual Storytelling with Visual Prefix Tuning and Contrastive Learning,"Visual storytelling systems generate multi-sentence stories from image
sequences. In this task, capturing contextual information and bridging visual
variation bring additional challenges. We propose a simple yet effective
framework that leverages the generalization capabilities of pretrained
foundation models, only training a lightweight vision-language mapping network
to connect modalities, while incorporating context to enhance coherence. We
introduce a multimodal contrastive objective that also improves visual
relevance and story informativeness. Extensive experimental results, across
both automatic metrics and human evaluations, demonstrate that the stories
generated by our framework are diverse, coherent, informative, and interesting.",2024-08-12,"Yingjin Song, Denis Paperno, Albert Gatt",http://arxiv.org/pdf/2408.06259v1,cs.CL
FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks,"This paper introduces FLEURS-R, a speech restoration applied version of the
Few-shot Learning Evaluation of Universal Representations of Speech (FLEURS)
corpus. FLEURS-R maintains an N-way parallel speech corpus in 102 languages as
FLEURS, with improved audio quality and fidelity by applying the speech
restoration model Miipher. The aim of FLEURS-R is to advance speech technology
in more languages and catalyze research including text-to-speech (TTS) and
other speech generation tasks in low-resource languages. Comprehensive
evaluations with the restored speech and TTS baseline models trained from the
new corpus show that the new corpus obtained significantly improved speech
quality while maintaining the semantic contents of the speech. The corpus is
publicly released via Hugging Face.",2024-08-12,"Min Ma, Yuma Koizumi, Shigeki Karita, Heiga Zen, Jason Riesa, Haruko Ishikawa, Michiel Bacchiani",http://arxiv.org/pdf/2408.06227v1,cs.CL
On Effects of Steering Latent Representation for Large Language Model Unlearning,"Representation Misdirection for Unlearning (RMU), which steers model
representation in the intermediate layer to a target random representation, is
an effective method for large language model (LLM) unlearning. Despite its high
performance, the underlying cause and explanation remain underexplored. In this
paper, we theoretically demonstrate that steering forget representations in the
intermediate layer reduces token confidence, causing LLMs to generate wrong or
nonsense responses. We investigate how the coefficient influences the alignment
of forget-sample representations with the random direction and hint at the
optimal coefficient values for effective unlearning across different network
layers. We show that RMU unlearned models are robust against adversarial
jailbreak attacks. Furthermore, our empirical analysis shows that RMU is less
effective when applied to the middle and later layers in LLMs. To resolve this
drawback, we propose Adaptive RMU--a simple yet effective alternative method
that makes unlearning effective with most layers. Extensive experiments
demonstrate that Adaptive RMU significantly improves the unlearning performance
compared to prior art while incurring no additional computational cost.",2024-08-12,"Dang Huu-Tien, Trung-Tin Pham, Hoang Thanh-Tung, Naoya Inoue",http://arxiv.org/pdf/2408.06223v3,cs.CL
Prompto: An open source library for asynchronous querying of LLM endpoints,"Recent surge in Large Language Model (LLM) availability has opened exciting
avenues for research. However, efficiently interacting with these models
presents a significant hurdle since LLMs often reside on proprietary or
self-hosted API endpoints, each requiring custom code for interaction.
Conducting comparative studies between different models can therefore be
time-consuming and necessitate significant engineering effort, hindering
research efficiency and reproducibility. To address these challenges, we
present prompto, an open source Python library which facilitates asynchronous
querying of LLM endpoints enabling researchers to interact with multiple LLMs
concurrently, while maximising efficiency and utilising individual rate limits.
Our library empowers researchers and developers to interact with LLMs more
effectively and allowing faster experimentation, data generation and
evaluation. prompto is released with an introductory video
(https://youtu.be/lWN9hXBOLyQ) under MIT License and is available via GitHub
(https://github.com/alan-turing-institute/prompto).",2024-08-12,"Ryan Sze-Yin Chan, Federico Nanni, Angus R. Williams, Edwin Brown, Liam Burke-Moore, Ed Chapman, Kate Onslow, Tvesha Sippy, Jonathan Bright, Evelina Gabasova",http://arxiv.org/pdf/2408.11847v2,cs.CL
Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers,"This paper introduces rStar, a self-play mutual reasoning approach that
significantly improves reasoning capabilities of small language models (SLMs)
without fine-tuning or superior models. rStar decouples reasoning into a
self-play mutual generation-discrimination process. First, a target SLM
augments the Monte Carlo Tree Search (MCTS) with a rich set of human-like
reasoning actions to construct higher quality reasoning trajectories. Next,
another SLM, with capabilities similar to the target SLM, acts as a
discriminator to verify each trajectory generated by the target SLM. The
mutually agreed reasoning trajectories are considered mutual consistent, thus
are more likely to be correct. Extensive experiments across five SLMs
demonstrate rStar can effectively solve diverse reasoning problems, including
GSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA. Remarkably, rStar boosts GSM8K
accuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for
Mistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct. Code will be
available at https://github.com/zhentingqi/rStar.",2024-08-12,"Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, Fan Yang, Mao Yang",http://arxiv.org/pdf/2408.06195v1,cs.CL
Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting,"The capability to generate diverse text is a key challenge facing large
language models (LLMs). Thus far, diversity has been studied via metrics such
as $n$-gram diversity or diversity of BERT embeddings. However, for these kinds
of diversity, the user has little control over the dimensions along which
diversity is considered. For example, in the poetry domain, one might desire
diversity in terms of rhyme and meter, whereas in the code domain, one might
desire diversity in terms of the kinds of expressions used to solve a problem.
We propose a diversity metric called structural diversity, where the user
provides a mapping from generated text to features capturing the kinds of
diversity that they care about. In addition, we propose a novel strategy called
chain-of-specification (CoS) prompting for improving diversity by first having
the LLM generate a specification encoding one instance of structural features,
and then prompting the LLM to generate text that satisfies these features;
notably, our strategy works with blackbox LLMs. In our experiments, we show
that for structural diversity in the poetry and code domains, CoS significantly
improves diversity compared to several baselines.",2024-08-12,"Halley Young, Yimeng Zeng, Jacob Gardner, Osbert Bastani",http://arxiv.org/pdf/2408.06186v1,cs.CL
LipidBERT: A Lipid Language Model Pre-trained on METiS de novo Lipid Library,"In this study, we generate and maintain a database of 10 million virtual
lipids through METiS's in-house de novo lipid generation algorithms and lipid
virtual screening techniques. These virtual lipids serve as a corpus for
pre-training, lipid representation learning, and downstream task knowledge
transfer, culminating in state-of-the-art LNP property prediction performance.
We propose LipidBERT, a BERT-like model pre-trained with the Masked Language
Model (MLM) and various secondary tasks. Additionally, we compare the
performance of embeddings generated by LipidBERT and PhatGPT, our GPT-like
lipid generation model, on downstream tasks. The proposed bilingual LipidBERT
model operates in two languages: the language of ionizable lipid pre-training,
using in-house dry-lab lipid structures, and the language of LNP fine-tuning,
utilizing in-house LNP wet-lab data. This dual capability positions LipidBERT
as a key AI-based filter for future screening tasks, including new versions of
METiS de novo lipid libraries and, more importantly, candidates for in vivo
testing for orgran-targeting LNPs. To the best of our knowledge, this is the
first successful demonstration of the capability of a pre-trained language
model on virtual lipids and its effectiveness in downstream tasks using web-lab
data. This work showcases the clever utilization of METiS's in-house de novo
lipid library as well as the power of dry-wet lab integration.",2024-08-12,"Tianhao Yu, Cai Yao, Zhuorui Sun, Feng Shi, Lin Zhang, Kangjie Lyu, Xuan Bai, Andong Liu, Xicheng Zhang, Jiali Zou, Wenshou Wang, Chris Lai, Kai Wang",http://arxiv.org/pdf/2408.06150v3,cs.CL
Med42-v2: A Suite of Clinical LLMs,"Med42-v2 introduces a suite of clinical large language models (LLMs) designed
to address the limitations of generic models in healthcare settings. These
models are built on Llama3 architecture and fine-tuned using specialized
clinical data. They underwent multi-stage preference alignment to effectively
respond to natural prompts. While generic models are often preference-aligned
to avoid answering clinical queries as a precaution, Med42-v2 is specifically
trained to overcome this limitation, enabling its use in clinical settings.
Med42-v2 models demonstrate superior performance compared to the original
Llama3 models in both 8B and 70B parameter configurations and GPT-4 across
various medical benchmarks. These LLMs are developed to understand clinical
queries, perform reasoning tasks, and provide valuable assistance in clinical
environments. The models are now publicly available at
\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.",2024-08-12,"Clément Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel",http://arxiv.org/pdf/2408.06142v1,cs.CL
Speech vs. Transcript: Does It Matter for Human Annotators in Speech Summarization?,"Reference summaries for abstractive speech summarization require human
annotation, which can be performed by listening to an audio recording or by
reading textual transcripts of the recording. In this paper, we examine whether
summaries based on annotators listening to the recordings differ from those
based on annotators reading transcripts. Using existing intrinsic evaluation
based on human evaluation, automatic metrics, LLM-based evaluation, and a
retrieval-based reference-free method. We find that summaries are indeed
different based on the source modality, and that speech-based summaries are
more factually consistent and information-selective than transcript-based
summaries. Meanwhile, transcript-based summaries are impacted by recognition
errors in the source, and expert-written summaries are more informative and
reliable. We make all the collected data and analysis code
public(https://github.com/cmu-mlsp/interview_humanssum) to facilitate the
reproduction of our work and advance research in this area.",2024-08-12,"Roshan Sharma, Suwon Shon, Mark Lindsey, Hira Dhamyal, Rita Singh, Bhiksha Raj",http://arxiv.org/pdf/2408.07277v1,cs.CL
Utilize Transformers for translating Wikipedia category names,"On Wikipedia, articles are categorized to aid readers in navigating content
efficiently. The manual creation of new categories can be laborious and
time-intensive. To tackle this issue, we built language models to translate
Wikipedia categories from English to Vietnamese with a dataset containing
15,000 English-Vietnamese category pairs. Subsequently, small to medium-scale
Transformer pre-trained models with a sequence-to-sequence architecture were
fine-tuned for category translation. The experiments revealed that
OPUS-MT-en-vi surpassed other models, attaining the highest performance with a
BLEU score of 0.73, despite its smaller model storage. We expect our paper to
be an alternative solution for translation tasks with limited computer
resources.",2024-08-12,"Hoang-Thang Ta, Quoc Thang La",http://arxiv.org/pdf/2408.06124v1,cs.CL
How ChatGPT Changed the Media's Narratives on AI: A Semi-Automated Narrative Analysis Through Frame Semantics,"We perform a mixed-method frame semantics-based analysis on a dataset of more
than 49,000 sentences collected from 5846 news articles that mention AI. The
dataset covers the twelve-month period centred around the launch of OpenAI's
chatbot ChatGPT and is collected from the most visited open-access
English-language news publishers. Our findings indicate that during the six
months succeeding the launch, media attention rose tenfold$\unicode{x2014}$from
already historically high levels. During this period, discourse has become
increasingly centred around experts and political leaders, and AI has become
more closely associated with dangers and risks. A deeper review of the data
also suggests a qualitative shift in the types of threat AI is thought to
represent, as well as the anthropomorphic qualities ascribed to it.",2024-08-12,"Igor Ryazanov, Carl Öhman, Johanna Björklund",http://arxiv.org/pdf/2408.06120v2,cs.CL
Building Decision Making Models Through Language Model Regime,"We propose a novel approach for decision making problems leveraging the
generalization capabilities of large language models (LLMs). Traditional
methods such as expert systems, planning algorithms, and reinforcement learning
often exhibit limited generalization, typically requiring the training of new
models for each unique task. In contrast, LLMs demonstrate remarkable success
in generalizing across varied language tasks, inspiring a new strategy for
training decision making models. Our approach, referred to as ""Learning then
Using"" (LTU), entails a two-stage process. Initially, the \textit{learning}
phase develops a robust foundational decision making model by integrating
diverse knowledge from various domains and decision making contexts. The
subsequent \textit{using} phase refines this foundation model for specific
decision making scenarios. Distinct from other studies that employ LLMs for
decision making through supervised learning, our LTU method embraces a
versatile training methodology that combines broad pre-training with targeted
fine-tuning. Experiments in e-commerce domains such as advertising and search
optimization have shown that LTU approach outperforms traditional supervised
learning regimes in decision making capabilities and generalization. The LTU
approach is the first practical training architecture for both single-step and
multi-step decision making tasks combined with LLMs, which can be applied
beyond game and robot domains. It provides a robust and adaptable framework for
decision making, enhances the effectiveness and flexibility of various systems
in tackling various challenges.",2024-08-12,"Yu Zhang, Haoxiang Liu, Feijun Jiang, Weihua Luo, Kaifu Zhang",http://arxiv.org/pdf/2408.06087v1,cs.CL
An Investigation Into Explainable Audio Hate Speech Detection,"Research on hate speech has predominantly revolved around detection and
interpretation from textual inputs, leaving verbal content largely unexplored.
While there has been limited exploration into hate speech detection within
verbal acoustic speech inputs, the aspect of interpretability has been
overlooked. Therefore, we introduce a new task of explainable audio hate speech
detection. Specifically, we aim to identify the precise time intervals,
referred to as audio frame-level rationales, which serve as evidence for hate
speech classification. Towards this end, we propose two different approaches:
cascading and End-to-End (E2E). The cascading approach initially converts audio
to transcripts, identifies hate speech within these transcripts, and
subsequently locates the corresponding audio time frames. Conversely, the E2E
approach processes audio utterances directly, which allows it to pinpoint hate
speech within specific time frames. Additionally, due to the lack of
explainable audio hate speech datasets that include audio frame-level
rationales, we curated a synthetic audio dataset to train our models. We
further validated these models on actual human speech utterances and found that
the E2E approach outperforms the cascading method in terms of the audio frame
Intersection over Union (IoU) metric. Furthermore, we observed that including
frame-level rationales significantly enhances hate speech detection accuracy
for the E2E approach.
  \textbf{Disclaimer} The reader may encounter content of an offensive or
hateful nature. However, given the nature of the work, this cannot be avoided.",2024-08-12,"Jinmyeong An, Wonjun Lee, Yejin Jeon, Jungseul Ok, Yunsu Kim, Gary Geunbae Lee",http://arxiv.org/pdf/2408.06065v1,cs.CL
"On Tables with Numbers, with Numbers","This paper is a critical reflection on the epistemic culture of contemporary
computational linguistics, framed in the context of its growing obsession with
tables with numbers. We argue against tables with numbers on the basis of their
epistemic irrelevance, their environmental impact, their role in enabling and
exacerbating social inequalities, and their deep ties to commercial
applications and profit-driven research. We substantiate our arguments with
empirical evidence drawn from a meta-analysis of computational linguistics
research over the last decade.",2024-08-12,"Konstantinos Kogkalidis, Stergios Chatzikyriakidis",http://arxiv.org/pdf/2408.06062v3,cs.CL
Density Matrices for Metaphor Understanding,"In physics, density matrices are used to represent mixed states, i.e.
probabilistic mixtures of pure states. This concept has previously been used to
model lexical ambiguity. In this paper, we consider metaphor as a type of
lexical ambiguity, and examine whether metaphorical meaning can be effectively
modelled using mixtures of word senses. We find that modelling metaphor is
significantly more difficult than other kinds of lexical ambiguity, but that
our best-performing density matrix method outperforms simple baselines as well
as some neural language models.",2024-08-12,"Jay Owers, Ekaterina Shutova, Martha Lewis",http://arxiv.org/pdf/2408.11846v1,cs.CL
Quantum Algorithms for Compositional Text Processing,"Quantum computing and AI have found a fruitful intersection in the field of
natural language processing. We focus on the recently proposed DisCoCirc
framework for natural language, and propose a quantum adaptation, QDisCoCirc.
This is motivated by a compositional approach to rendering AI interpretable:
the behavior of the whole can be understood in terms of the behavior of parts,
and the way they are put together. For the model-native primitive operation of
text similarity, we derive quantum algorithms for fault-tolerant quantum
computers to solve the task of question-answering within QDisCoCirc, and show
that this is BQP-hard; note that we do not consider the complexity of
question-answering in other natural language processing models. Assuming
widely-held conjectures, implementing the proposed model classically would
require super-polynomial resources. Therefore, it could provide a meaningful
demonstration of the power of practical quantum processors. The model
construction builds on previous work in compositional quantum natural language
processing. Word embeddings are encoded as parameterized quantum circuits, and
compositionality here means that the quantum circuits compose according to the
linguistic structure of the text. We outline a method for evaluating the model
on near-term quantum processors, and elsewhere we report on a recent
implementation of this on quantum hardware. In addition, we adapt a quantum
algorithm for the closest vector problem to obtain a Grover-like speedup in the
fault-tolerant regime for our model. This provides an unconditional quadratic
speedup over any classical algorithm in certain circumstances, which we will
verify empirically in future work.",2024-08-12,"Tuomas Laakkonen, Konstantinos Meichanetzidis, Bob Coecke",http://arxiv.org/pdf/2408.06061v1,cs.CL
DiagESC: Dialogue Synthesis for Integrating Depression Diagnosis into Emotional Support Conversation,"Dialogue systems for mental health care aim to provide appropriate support to
individuals experiencing mental distress. While extensive research has been
conducted to deliver adequate emotional support, existing studies cannot
identify individuals who require professional medical intervention and cannot
offer suitable guidance. We introduce the Diagnostic Emotional Support
Conversation task for an advanced mental health management system. We develop
the DESC dataset to assess depression symptoms while maintaining user
experience by utilizing task-specific utterance generation prompts and a strict
filtering algorithm. Evaluations by professional psychological counselors
indicate that DESC has a superior ability to diagnose depression than existing
data. Additionally, conversational quality evaluation reveals that DESC
maintains fluent, consistent, and coherent dialogues.",2024-08-12,"Seungyeon Seo, Gary Geunbae Lee",http://arxiv.org/pdf/2408.06044v1,cs.CL
Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning,"Recent dialogue systems rely on turn-based spoken interactions, requiring
accurate Automatic Speech Recognition (ASR). Errors in ASR can significantly
impact downstream dialogue tasks. To address this, using dialogue context from
user and agent interactions for transcribing subsequent utterances has been
proposed. This method incorporates the transcription of the user's speech and
the agent's response as model input, using the accumulated context generated by
each turn. However, this context is susceptible to ASR errors because it is
generated by the ASR model in an auto-regressive fashion. Such noisy context
can further degrade the benefits of context input, resulting in suboptimal ASR
performance. In this paper, we introduce Context Noise Representation Learning
(CNRL) to enhance robustness against noisy context, ultimately improving
dialogue speech recognition accuracy. To maximize the advantage of context
awareness, our approach includes decoder pre-training using text-based dialogue
data and noise representation learning for a context encoder. Based on the
evaluation of speech dialogues, our method shows superior results compared to
baselines. Furthermore, the strength of our approach is highlighted in noisy
environments where user speech is barely audible due to real-world noise,
relying on contextual information to transcribe the input accurately.",2024-08-12,"Wonjun Lee, San Kim, Gary Geunbae Lee",http://arxiv.org/pdf/2408.06043v1,cs.CL
ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers,"In the rapidly evolving fields of natural language processing and computer
vision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yet
challenging task. The quest for models that can seamlessly integrate and
interpret multimodal data is more pressing than ever. Imagine a system that can
understand language with the depth and nuance of human cognition, while
simultaneously interpreting the rich visual context of the world around it.
  We present ARPA, an architecture that fuses the unparalleled contextual
understanding of large language models with the advanced feature extraction
capabilities of transformers, which then pass through a custom Graph Neural
Network (GNN) layer to learn intricate relationships and subtle nuances within
the data. This innovative architecture not only sets a new benchmark in visual
word disambiguation but also introduces a versatile framework poised to
transform how linguistic and visual data interact by harnessing the synergistic
strengths of its components, ensuring robust performance even in the most
complex disambiguation scenarios. Through a series of experiments and
comparative analysis, we reveal the substantial advantages of our model,
underscoring its potential to redefine standards in the field. Beyond its
architectural prowess, our architecture excels through experimental
enrichments, including sophisticated data augmentation and multi-modal training
techniques.
  ARPA's introduction marks a significant milestone in visual word
disambiguation, offering a compelling solution that bridges the gap between
linguistic and visual modalities. We invite researchers and practitioners to
explore the capabilities of our model, envisioning a future where such hybrid
models drive unprecedented advancements in artificial intelligence.",2024-08-12,"Aristi Papastavrou, Maria Lymperaiou, Giorgos Stamou",http://arxiv.org/pdf/2408.06040v1,cs.CL
Controlling Surprisal in Music Generation via Information Content Curve Matching,"In recent years, the quality and public interest in music generation systems
have grown, encouraging research into various ways to control these systems. We
propose a novel method for controlling surprisal in music generation using
sequence models. To achieve this goal, we define a metric called Instantaneous
Information Content (IIC). The IIC serves as a proxy function for the perceived
musical surprisal (as estimated from a probabilistic model) and can be
calculated at any point within a music piece. This enables the comparison of
surprisal across different musical content even if the musical events occur in
irregular time intervals. We use beam search to generate musical material whose
IIC curve closely approximates a given target IIC. We experimentally show that
the IIC correlates with harmonic and rhythmic complexity and note density. The
correlation decreases with the length of the musical context used for
estimating the IIC. Finally, we conduct a qualitative user study to test if
human listeners can identify the IIC curves that have been used as targets when
generating the respective musical material. We provide code for creating IIC
interpolations and IIC visualizations on https://github.com/muthissar/iic.",2024-08-12,"Mathias Rose Bjare, Stefan Lattner, Gerhard Widmer",http://arxiv.org/pdf/2408.06022v1,cs.CL
Global-to-Local Support Spectrums for Language Model Explainability,"Existing sample-based methods, like influence functions and representer
points, measure the importance of a training point by approximating the effect
of its removal from training. As such, they are skewed towards outliers and
points that are very close to the decision boundaries. The explanations
provided by these methods are often static and not specific enough for
different test points. In this paper, we propose a method to generate an
explanation in the form of support spectrums which are based on two main ideas:
the support sets and a global-to-local importance measure. The support set is
the set of training points, in the predicted class, that ``lie in between'' the
test point and training points in the other classes. They indicate how well the
test point can be distinguished from the points not in the predicted class. The
global-to-local importance measure is obtained by decoupling existing methods
into the global and local components which are then used to select the points
in the support set. Using this method, we are able to generate explanations
that are tailored to specific test points. In the experiments, we show the
effectiveness of the method in image classification and text generation tasks.",2024-08-12,"Lucas Agussurja, Xinyang Lu, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2408.05976v1,cs.CL
The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI,"Psychological trauma can manifest following various distressing events and is
captured in diverse online contexts. However, studies traditionally focus on a
single aspect of trauma, often neglecting the transferability of findings
across different scenarios. We address this gap by training language models
with progressing complexity on trauma-related datasets, including
genocide-related court data, a Reddit dataset on post-traumatic stress disorder
(PTSD), counseling conversations, and Incel forum posts. Our results show that
the fine-tuned RoBERTa model excels in predicting traumatic events across
domains, slightly outperforming large language models like GPT-4. Additionally,
SLALOM-feature scores and conceptual explanations effectively differentiate and
cluster trauma-related language, highlighting different trauma aspects and
identifying sexual abuse and experiences related to death as a common traumatic
event across all datasets. This transferability is crucial as it allows for the
development of tools to enhance trauma detection and intervention in diverse
populations and settings.",2024-08-12,"Miriam Schirmer, Tobias Leemann, Gjergji Kasneci, Jürgen Pfeffer, David Jurgens",http://arxiv.org/pdf/2408.05977v1,cs.CL
ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models,"The rapid advancement of Large Language Models (LLMs) and conversational
assistants necessitates dynamic, scalable, and configurable conversational
datasets for training and evaluation. These datasets must accommodate diverse
user interaction modes, including text and voice, each presenting unique
modeling challenges. Knowledge Graphs (KGs), with their structured and evolving
nature, offer an ideal foundation for current and precise knowledge. Although
human-curated KG-based conversational datasets exist, they struggle to keep
pace with the rapidly changing user information needs. We present ConvKGYarn, a
scalable method for generating up-to-date and configurable conversational KGQA
datasets. Qualitative psychometric analyses confirm our method can generate
high-quality datasets rivaling a popular conversational KGQA dataset while
offering it at scale and covering a wide range of human-interaction
configurations. We showcase its utility by testing LLMs on diverse
conversations - exploring model behavior on conversational KGQA sets with
different configurations grounded in the same KG fact set. Our results
highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate
parametric knowledge of LLMs, thus offering a robust solution to the constantly
evolving landscape of conversational assistants.",2024-08-12,"Ronak Pradeep, Daniel Lee, Ali Mousavi, Jeff Pound, Yisi Sang, Jimmy Lin, Ihab Ilyas, Saloni Potdar, Mostafa Arefiyan, Yunyao Li",http://arxiv.org/pdf/2408.05948v1,cs.CL
A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning,"With the rapid development of large language models in recent years, there
has been an increasing demand for domain-specific Agents that can cater to the
unique needs of enterprises and organizations. Unlike general models, which
strive for broad coverage, these specialized Agents rely on focused datasets
tailored to their intended applications. This research proposes a pipeline that
leverages the power of LLMs and the Retrieval-Augmented Generation related
framework to construct high-quality instruction datasets for fine-tuning on
specific domains using custom document collections. By ingesting
domain-specific documents, the pipeline generates relevant and contextually
appropriate instructions, thus effectively creating a comprehensive dataset for
fine-tuning LLMs on the target domain. This approach overcomes the limitations
of traditional dataset creation methods, which often rely on manual curation or
web-scraping techniques that may introduce noise and irrelevant data. Notably,
our pipeline offers a dynamic solution that can quickly adapt to updates or
modifications in the domain-specific document collection, eliminating the need
for complete retraining. Additionally, it addresses the challenge of data
scarcity by enabling the generation of instruction datasets from a limited set
of initial documents, rendering it suitable for unpopular or specialized
domains where comprehensive datasets are scarce. As a case study, we apply this
approach to the domain of psychiatry, a field requiring specialized knowledge
and sensitive handling of patient information. The resulting fine-tuned LLM
demonstrates showcases the viability of the proposed approach and underscores
its potential for widespread adoption across various industries and domains
where tailored, accurate, and contextually relevant language models are
indispensable.",2024-08-12,"Chih-Wei Song, Yu-Kai Lee, Yin-Te Tsai",http://arxiv.org/pdf/2408.05911v1,cs.CL
AdTEC: A Unified Benchmark for Evaluating Text Quality in Search Engine Advertising,"With the increase in the fluency of ad texts automatically created by natural
language generation technology, there is high demand to verify the quality of
these creatives in a real-world setting. We propose AdTEC (Ad Text Evaluation
Benchmark by CyberAgent), the first public benchmark to evaluate ad texts from
multiple perspectives within practical advertising operations. Our
contributions are as follows: (i) Defining five tasks for evaluating the
quality of ad texts, as well as building a Japanese dataset based on the
practical operational experiences of building a Japanese dataset based on the
practical operational experiences of advertising agencies, which are typically
kept in-house. (ii) Validating the performance of existing pre-trained language
models (PLMs) and human evaluators on the dataset. (iii) Analyzing the
characteristics and providing challenges of the benchmark. The results show
that while PLMs have already reached practical usage level in several tasks,
humans still outperform in certain domains, implying that there is significant
room for improvement in this area.",2024-08-12,"Peinan Zhang, Yusuke Sakai, Masato Mita, Hiroki Ouchi, Taro Watanabe",http://arxiv.org/pdf/2408.05906v2,cs.CL
GlyphPattern: An Abstract Pattern Recognition for Vision-Language Models,"Vision-Language Models (VLMs) building upon the foundation of powerful large
language models have made rapid progress in reasoning across visual and textual
data. While VLMs perform well on vision tasks that they are trained on, our
results highlight key challenges in abstract pattern recognition. We present
GlyphPattern, a 954 item dataset that pairs 318 human-written descriptions of
visual patterns from 40 writing systems with three visual presentation styles.
  GlyphPattern evaluates abstract pattern recognition in VLMs, requiring models
to understand and judge natural language descriptions of visual patterns.
GlyphPattern patterns are drawn from a large-scale cognitive science
investigation of human writing systems; as a result, they are rich in spatial
reference and compositionality. Our experiments show that GlyphPattern is
challenging for state-of-the-art VLMs (GPT-4o achieves only 55% accuracy), with
marginal gains from few-shot prompting. Our detailed error analysis reveals
challenges at multiple levels, including visual processing, natural language
understanding, and pattern generalization.",2024-08-12,"Zixuan Wu, Yoolim Kim, Carolyn Jane Anderson",http://arxiv.org/pdf/2408.05894v1,cs.CL
Creating Arabic LLM Prompts at Scale,"The debut of chatGPT and BARD has popularized instruction following text
generation using LLMs, where a user can interrogate an LLM using natural
language requests and obtain natural language answers that matches their
requests. Training LLMs to respond in this manner requires a large number of
worked out examples of user requests (aka prompts) with corresponding gold
responses. In this paper, we introduce two methods for creating such prompts
for Arabic cheaply and quickly. The first methods entails automatically
translating existing prompt datasets from English, such as PromptSource and
Super-NaturalInstructions, and then using machine translation quality
estimation to retain high quality translations only. The second method involves
creating natural language prompts on top of existing Arabic NLP datasets. Using
these two methods we were able to create more than 67.4 million Arabic prompts
that cover a variety of tasks including summarization, headline generation,
grammar checking, open/closed question answering, creative writing, etc. We
show that fine tuning an open 7 billion parameter large language model, namely
base Qwen2 7B, enables it to outperform a state-of-the-art 70 billion parameter
instruction tuned model, namely Llama3 70B, in handling Arabic prompts.",2024-08-12,"Abdelrahman El-Sheikh, Ahmed Elmogtaba, Kareem Darwish, Muhammad Elmallah, Ashraf Elneima, Hassan Sawaf",http://arxiv.org/pdf/2408.05882v1,cs.CL
LLM-Based Robust Product Classification in Commerce and Compliance,"Product classification is a crucial task in international trade, as
compliance regulations are verified and taxes and duties are applied based on
product categories. Manual classification of products is time-consuming and
error-prone, and the sheer volume of products imported and exported renders the
manual process infeasible. Consequently, e-commerce platforms and enterprises
involved in international trade have turned to automatic product classification
using machine learning. However, current approaches do not consider the
real-world challenges associated with product classification, such as very
abbreviated and incomplete product descriptions. In addition, recent
advancements in generative Large Language Models (LLMs) and their reasoning
capabilities are mainly untapped in product classification and e-commerce. In
this research, we explore the real-life challenges of industrial classification
and we propose data perturbations that allow for realistic data simulation.
Furthermore, we employ LLM-based product classification to improve the
robustness of the prediction in presence of incomplete data. Our research shows
that LLMs with in-context learning outperform the supervised approaches in the
clean-data scenario. Additionally, we illustrate that LLMs are significantly
more robust than the supervised approaches when data attacks are present.",2024-08-11,"Sina Gholamian, Gianfranco Romani, Bartosz Rudnikowicz, Stavroula Skylaki",http://arxiv.org/pdf/2408.05874v2,cs.CL
Defining Boundaries: A Spectrum of Task Feasibility for Large Language Models,"Large language models (LLMs) have shown remarkable performance in various
tasks but often fail to handle queries that exceed their knowledge and
capabilities, leading to incorrect or fabricated responses. This paper
addresses the need for LLMs to recognize and refuse infeasible tasks due to the
required skills surpassing their capabilities. We first conceptualize
infeasible tasks for LLMs and provide categorizations that cover a spectrum of
related hallucinations over existing literature. We develop and benchmark a new
dataset comprising diverse infeasible and feasible tasks to evaluate multiple
LLMs' abilities to reject infeasible tasks. Furthermore, we explore the
potential of increasing LLMs' refusal capabilities with fine-tuning.
Experiments validate the effectiveness of our trained models, offering
promising directions for refining the operational boundaries of LLMs in real
applications.",2024-08-11,"Wenbo Zhang, Zihang Xu, Hengrui Cai",http://arxiv.org/pdf/2408.05873v2,cs.CL
Kov: Transferable and Naturalistic Black-Box LLM Attacks using Markov Decision Processes and Tree Search,"Eliciting harmful behavior from large language models (LLMs) is an important
task to ensure the proper alignment and safety of the models. Often when
training LLMs, ethical guidelines are followed yet alignment failures may still
be uncovered through red teaming adversarial attacks. This work frames the
red-teaming problem as a Markov decision process (MDP) and uses Monte Carlo
tree search to find harmful behaviors of black-box, closed-source LLMs. We
optimize token-level prompt suffixes towards targeted harmful behaviors on
white-box LLMs and include a naturalistic loss term, log-perplexity, to
generate more natural language attacks for better interpretability. The
proposed algorithm, Kov, trains on white-box LLMs to optimize the adversarial
attacks and periodically evaluates responses from the black-box LLM to guide
the search towards more harmful black-box behaviors. In our preliminary study,
results indicate that we can jailbreak black-box models, such as GPT-3.5, in
only 10 queries, yet fail on GPT-4$-$which may indicate that newer models are
more robust to token-level attacks. All work to reproduce these results is open
sourced (https://github.com/sisl/Kov.jl).",2024-08-11,Robert J. Moss,http://arxiv.org/pdf/2408.08899v1,cs.CL
Multitask Fine-Tuning and Generative Adversarial Learning for Improved Auxiliary Classification,"In this study, we implement a novel BERT architecture for multitask
fine-tuning on three downstream tasks: sentiment classification, paraphrase
detection, and semantic textual similarity prediction. Our model, Multitask
BERT, incorporates layer sharing and a triplet architecture, custom sentence
pair tokenization, loss pairing, and gradient surgery. Such optimizations yield
a 0.516 sentiment classification accuracy, 0.886 paraphase detection accuracy,
and 0.864 semantic textual similarity correlation on test data. We also apply
generative adversarial learning to BERT, constructing a conditional generator
model that maps from latent space to create fake embeddings in
$\mathbb{R}^{768}$. These fake embeddings are concatenated with real BERT
embeddings and passed into a discriminator model for auxiliary classification.
Using this framework, which we refer to as AC-GAN-BERT, we conduct
semi-supervised sensitivity analyses to investigate the effect of increasing
amounts of unlabeled training data on AC-GAN-BERT's test accuracy. Overall,
aside from implementing a high-performing multitask classification system, our
novelty lies in the application of adversarial learning to construct a
generator that mimics BERT. We find that the conditional generator successfully
produces rich embeddings with clear spatial correlation with class labels,
demonstrating avoidance of mode collapse. Our findings validate the GAN-BERT
approach and point to future directions of generator-aided knowledge
distillation.",2024-08-11,"Christopher Sun, Abishek Satish",http://arxiv.org/pdf/2408.15265v1,cs.CL
Post-Training Sparse Attention with Double Sparsity,"The inference process for large language models is slow and memory-intensive,
with one of the most critical bottlenecks being excessive Key-Value (KV) cache
accesses. This paper introduces ""Double Sparsity,"" a novel post-training sparse
attention technique designed to alleviate this bottleneck by reducing KV cache
access. Double Sparsity combines token sparsity, which focuses on utilizing
only the important tokens for computing self-attention, with channel sparsity,
an approach that uses important feature channels for identifying important
tokens. Our key insight is that the pattern of channel sparsity is relatively
static, allowing us to use offline calibration to make it efficient at runtime,
thereby enabling accurate and efficient identification of important tokens.
Moreover, this method can be combined with offloading to achieve significant
memory usage reduction. Experimental results demonstrate that Double Sparsity
can achieve $\frac{1}{16}$ token and channel sparsity with minimal impact on
accuracy across various tasks, including wiki-2 perplexity, key-value
retrieval, and long context benchmarks with models including Llama-2-7B,
Llama-2-70B, and Mixtral-8x7B. It brings up to a 14.1$\times$ acceleration in
attention operations and a 1.9$\times$ improvement in end-to-end inference on
GPUs. With offloading, it achieves a decoding speed acceleration of
16.3$\times$ compared to state-of-the-art solutions at a sequence length of
256K. Our code is publicly available at
https://github.com/andy-yang-1/DoubleSparse.",2024-08-11,"Shuo Yang, Ying Sheng, Joseph E. Gonzalez, Ion Stoica, Lianmin Zheng",http://arxiv.org/pdf/2408.07092v2,cs.CL
Iterative Improvement of an Additively Regularized Topic Model,"Topic modelling is fundamentally a soft clustering problem (of known objects
-- documents, over unknown clusters -- topics). That is, the task is
incorrectly posed. In particular, the topic models are unstable and incomplete.
All this leads to the fact that the process of finding a good topic model
(repeated hyperparameter selection, model training, and topic quality
assessment) can be particularly long and labor-intensive. We aim to simplify
the process, to make it more deterministic and provable. To this end, we
present a method for iterative training of a topic model. The essence of the
method is that a series of related topic models are trained so that each
subsequent model is at least as good as the previous one, i.e., that it retains
all the good topics found earlier. The connection between the models is
achieved by additive regularization. The result of this iterative training is
the last topic model in the series, which we call the iteratively updated
additively regularized topic model (ITAR). Experiments conducted on several
collections of natural language texts show that the proposed ITAR model
performs better than other popular topic models (LDA, ARTM, BERTopic), its
topics are diverse, and its perplexity (ability to ""explain"" the underlying
data) is moderate.",2024-08-11,"Alex Gorbulev, Vasiliy Alekseev, Konstantin Vorontsov",http://arxiv.org/pdf/2408.05840v3,cs.CL
HateSieve: A Contrastive Learning Framework for Detecting and Segmenting Hateful Content in Multimodal Memes,"Amidst the rise of Large Multimodal Models (LMMs) and their widespread
application in generating and interpreting complex content, the risk of
propagating biased and harmful memes remains significant. Current safety
measures often fail to detect subtly integrated hateful content within
``Confounder Memes''. To address this, we introduce \textsc{HateSieve}, a new
framework designed to enhance the detection and segmentation of hateful
elements in memes. \textsc{HateSieve} features a novel Contrastive Meme
Generator that creates semantically paired memes, a customized triplet dataset
for contrastive learning, and an Image-Text Alignment module that produces
context-aware embeddings for accurate meme segmentation. Empirical experiments
on the Hateful Meme Dataset show that \textsc{HateSieve} not only surpasses
existing LMMs in performance with fewer trainable parameters but also offers a
robust mechanism for precisely identifying and isolating hateful content.
\textcolor{red}{Caution: Contains academic discussions of hate speech; viewer
discretion advised.}",2024-08-11,"Xuanyu Su, Yansong Li, Diana Inkpen, Nathalie Japkowicz",http://arxiv.org/pdf/2408.05794v2,cs.CL
SAGA: A Participant-specific Examination of Story Alternatives and Goal Applicability for a Deeper Understanding of Complex Events,"Interpreting and assessing goal driven actions is vital to understanding and
reasoning over complex events. It is important to be able to acquire the
knowledge needed for this understanding, though doing so is challenging. We
argue that such knowledge can be elicited through a participant achievement
lens. We analyze a complex event in a narrative according to the intended
achievements of the participants in that narrative, the likely future actions
of the participants, and the likelihood of goal success. We collect 6.3K high
quality goal and action annotations reflecting our proposed participant
achievement lens, with an average weighted Fleiss-Kappa IAA of 80%. Our
collection contains annotated alternate versions of each narrative. These
alternate versions vary minimally from the ""original"" story, but can license
drastically different inferences. Our findings suggest that while modern large
language models can reflect some of the goal-based knowledge we study, they
find it challenging to fully capture the design and intent behind concerted
actions, even when the model pretraining included the data from which we
extracted the goal knowledge. We show that smaller models fine-tuned on our
dataset can achieve performance surpassing larger models.",2024-08-11,"Sai Vallurupalli, Katrin Erk, Francis Ferraro",http://arxiv.org/pdf/2408.05793v1,cs.CL
HiLight: A Hierarchy-aware Light Global Model with Hierarchical Local ConTrastive Learning,"Hierarchical text classification (HTC) is a special sub-task of multi-label
classification (MLC) whose taxonomy is constructed as a tree and each sample is
assigned with at least one path in the tree. Latest HTC models contain three
modules: a text encoder, a structure encoder and a multi-label classification
head. Specially, the structure encoder is designed to encode the hierarchy of
taxonomy. However, the structure encoder has scale problem. As the taxonomy
size increases, the learnable parameters of recent HTC works grow rapidly.
Recursive regularization is another widely-used method to introduce
hierarchical information but it has collapse problem and generally relaxed by
assigning with a small weight (ie. 1e-6). In this paper, we propose a
Hierarchy-aware Light Global model with Hierarchical local conTrastive learning
(HiLight), a lightweight and efficient global model only consisting of a text
encoder and a multi-label classification head. We propose a new learning task
to introduce the hierarchical information, called Hierarchical Local
Contrastive Learning (HiLCL). Extensive experiments are conducted on two
benchmark datasets to demonstrate the effectiveness of our model.",2024-08-11,"Zhijian Chen, Zhonghua Li, Jianxin Yang, Ye Qi",http://arxiv.org/pdf/2408.05786v1,cs.CL
LI-TTA: Language Informed Test-Time Adaptation for Automatic Speech Recognition,"Test-Time Adaptation (TTA) has emerged as a crucial solution to the domain
shift challenge, wherein the target environment diverges from the original
training environment. A prime exemplification is TTA for Automatic Speech
Recognition (ASR), which enhances model performance by leveraging output
prediction entropy minimization as a self-supervision signal. However, a key
limitation of this self-supervision lies in its primary focus on acoustic
features, with minimal attention to the linguistic properties of the input. To
address this gap, we propose Language Informed Test-Time Adaptation (LI-TTA),
which incorporates linguistic insights during TTA for ASR. LI-TTA integrates
corrections from an external language model to merge linguistic with acoustic
information by minimizing the CTC loss from the correction alongside the
standard TTA loss. With extensive experiments, we show that LI-TTA effectively
improves the performance of TTA for ASR in various distribution shift
situations.",2024-08-11,"Eunseop Yoon, Hee Suk Yoon, John Harvill, Mark Hasegawa-Johnson, Chang D. Yoo",http://arxiv.org/pdf/2408.05769v1,cs.CL
Reference-free Hallucination Detection for Large Vision-Language Models,"Large vision-language models (LVLMs) have made significant progress in recent
years. While LVLMs exhibit excellent ability in language understanding,
question answering, and conversations of visual inputs, they are prone to
producing hallucinations. While several methods are proposed to evaluate the
hallucinations in LVLMs, most are reference-based and depend on external tools,
which complicates their practical application. To assess the viability of
alternative methods, it is critical to understand whether the reference-free
approaches, which do not rely on any external tools, can efficiently detect
hallucinations. Therefore, we initiate an exploratory study to demonstrate the
effectiveness of different reference-free solutions in detecting hallucinations
in LVLMs. In particular, we conduct an extensive study on three kinds of
techniques: uncertainty-based, consistency-based, and supervised uncertainty
quantification methods on four representative LVLMs across two different tasks.
The empirical results show that the reference-free approaches are capable of
effectively detecting non-factual responses in LVLMs, with the supervised
uncertainty quantification method outperforming the others, achieving the best
performance across different settings.",2024-08-11,"Qing Li, Jiahui Geng, Chenyang Lyu, Derui Zhu, Maxim Panov, Fakhri Karray",http://arxiv.org/pdf/2408.05767v2,cs.CL
VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing,"Deep learning has brought significant improvements to the field of
cross-modal representation learning. For tasks such as text-to-speech (TTS),
voice conversion (VC), and automatic speech recognition (ASR), a cross-modal
fine-grained (frame-level) sequence representation is desired, emphasizing the
semantic content of the text modality while de-emphasizing the paralinguistic
information of the speech modality. We propose a method called ""Vector
Quantized Contrastive Token-Acoustic Pre-training (VQ-CTAP)"", which uses the
cross-modal aligned sequence transcoder to bring text and speech into a joint
multimodal space, learning how to connect text and speech at the frame level.
The proposed VQ-CTAP is a paradigm for cross-modal sequence representation
learning, offering a promising solution for fine-grained generation and
recognition tasks in speech processing. The VQ-CTAP can be directly applied to
VC and ASR tasks without fine-tuning or additional structures. We propose a
sequence-aware semantic connector, which connects multiple frozen pre-trained
modules for the TTS task, exhibiting a plug-and-play capability. We design a
stepping optimization strategy to ensure effective model convergence by
gradually injecting and adjusting the influence of various loss components.
Furthermore, we propose a semantic-transfer-wise paralinguistic consistency
loss to enhance representational capabilities, allowing the model to better
generalize to unseen data and capture the nuances of paralinguistic
information. In addition, VQ-CTAP achieves high-compression speech coding at a
rate of 25Hz from 24kHz input waveforms, which is a 960-fold reduction in the
sampling rate. The audio demo is available at
https://qiangchunyu.github.io/VQCTAP/",2024-08-11,"Chunyu Qiang, Wang Geng, Yi Zhao, Ruibo Fu, Tao Wang, Cheng Gong, Tianrui Wang, Qiuyu Liu, Jiangyan Yi, Zhengqi Wen, Chen Zhang, Hao Che, Longbiao Wang, Jianwu Dang, Jianhua Tao",http://arxiv.org/pdf/2408.05758v1,cs.CL
Language-Informed Beam Search Decoding for Multilingual Machine Translation,"Beam search decoding is the de-facto method for decoding auto-regressive
Neural Machine Translation (NMT) models, including multilingual NMT where the
target language is specified as an input. However, decoding multilingual NMT
models commonly produces ``off-target'' translations -- yielding translation
outputs not in the intended language. In this paper, we first conduct an error
analysis of off-target translations for a strong multilingual NMT model and
identify how these decodings are produced during beam search. We then propose
Language-informed Beam Search (LiBS), a general decoding algorithm
incorporating an off-the-shelf Language Identification (LiD) model into beam
search decoding to reduce off-target translations. LiBS is an inference-time
procedure that is NMT-model agnostic and does not require any additional
parallel data. Results show that our proposed LiBS algorithm on average
improves +1.1 BLEU and +0.9 BLEU on WMT and OPUS datasets, and reduces
off-target rates from 22.9\% to 7.7\% and 65.8\% to 25.3\% respectively.",2024-08-11,"Yilin Yang, Stefan Lee, Prasad Tadepalli",http://arxiv.org/pdf/2408.05738v1,cs.CL
GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person Perspective,"This paper extends recent investigations on the emotional reasoning abilities
of Large Language Models (LLMs). Current research on LLMs has not directly
evaluated the distinction between how LLMs predict the self-attribution of
emotions and the perception of others' emotions. We first look at carefully
crafted emotion-evoking stimuli, originally designed to find patterns of brain
neural activity representing fine-grained inferred emotional attributions of
others. We show that GPT-4 is especially accurate in reasoning about such
stimuli. This suggests LLMs agree with humans' attributions of others' emotions
in stereotypical scenarios remarkably more than self-attributions of emotions
in idiosyncratic situations. To further explore this, our second study utilizes
a dataset containing annotations from both the author and a third-person
perspective. We find that GPT-4's interpretations align more closely with human
judgments about the emotions of others than with self-assessments. Notably,
conventional computational models of emotion primarily rely on self-reported
ground truth as the gold standard. However, an average observer's standpoint,
which LLMs appear to have adopted, might be more relevant for many downstream
applications, at least in the absence of individual information and adequate
safety considerations.",2024-08-11,"Ala N. Tak, Jonathan Gratch",http://arxiv.org/pdf/2408.13718v1,cs.CL
Training an NLP Scholar at a Small Liberal Arts College: A Backwards Designed Course Proposal,"The rapid growth in natural language processing (NLP) over the last couple
years has generated student interest and excitement in learning more about the
field. In this paper, we present two types of students that NLP courses might
want to train. First, an ""NLP engineer"" who is able to flexibly design, build
and apply new technologies in NLP for a wide range of tasks. Second, an ""NLP
scholar"" who is able to pose, refine and answer questions in NLP and how it
relates to the society, while also learning to effectively communicate these
answers to a broader audience. While these two types of skills are not mutually
exclusive -- NLP engineers should be able to think critically, and NLP scholars
should be able to build systems -- we think that courses can differ in the
balance of these skills. As educators at Small Liberal Arts Colleges, the
strengths of our students and our institution favors an approach that is better
suited to train NLP scholars. In this paper we articulate what kinds of skills
an NLP scholar should have, and then adopt a backwards design to propose course
components that can aid the acquisition of these skills.",2024-08-11,"Grusha Prasad, Forrest Davis",http://arxiv.org/pdf/2408.05664v1,cs.CL
WiDe-analysis: Enabling One-click Content Moderation Analysis on Wikipedia's Articles for Deletion,"Content moderation in online platforms is crucial for ensuring activity
therein adheres to existing policies, especially as these platforms grow. NLP
research in this area has typically focused on automating some part of it given
that it is not feasible to monitor all active discussions effectively. Past
works have focused on revealing deletion patterns with like sentiment analysis,
or on developing platform-specific models such as Wikipedia policy or stance
detectors. Unsurprisingly, however, this valuable body of work is rather
scattered, with little to no agreement with regards to e.g., the deletion
discussions corpora used for training or the number of stance labels. Moreover,
while efforts have been made to connect stance with rationales (e.g., to ground
a deletion decision on the relevant policy), there is little explanability work
beyond that. In this paper, we introduce a suite of experiments on Wikipedia
deletion discussions and wide-analyis (Wikipedia Deletion Analysis), a Python
package aimed at providing one click analysis to content moderation
discussions. We release all assets associated with wide-analysis, including
data, models and the Python package, and a HuggingFace space with the goal to
accelerate research on automating content moderation in Wikipedia and beyond.",2024-08-10,"Hsuvas Borkakoty, Luis Espinosa-Anke",http://arxiv.org/pdf/2408.05655v1,cs.CL
Eigen Attention: Attention in Low-Rank Space for KV Cache Compression,"Large language models (LLMs) represent a groundbreaking advancement in the
domain of natural language processing due to their impressive reasoning
abilities. Recently, there has been considerable interest in increasing the
context lengths for these models to enhance their applicability to complex
tasks. However, at long context lengths and large batch sizes, the key-value
(KV) cache, which stores the attention keys and values, emerges as the new
bottleneck in memory usage during inference. To address this, we propose Eigen
Attention, which performs the attention operation in a low-rank space, thereby
reducing the KV cache memory overhead. Our proposed approach is orthogonal to
existing KV cache compression techniques and can be used synergistically with
them. Through extensive experiments over OPT, MPT, and Llama model families, we
demonstrate that Eigen Attention results in up to 40% reduction in KV cache
sizes and up to 60% reduction in attention operation latency with minimal drop
in performance. Code is available at
https://github.com/UtkarshSaxena1/EigenAttn.",2024-08-10,"Utkarsh Saxena, Gobinda Saha, Sakshi Choudhary, Kaushik Roy",http://arxiv.org/pdf/2408.05646v2,cs.CL
Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion,"Speculative decoding has emerged as a widely adopted method to accelerate
large language model inference without sacrificing the quality of the model
outputs. While this technique has facilitated notable speed improvements by
enabling parallel sequence verification, its efficiency remains inherently
limited by the reliance on incremental token generation in existing draft
models. To overcome this limitation, this paper proposes an adaptation of
speculative decoding which uses discrete diffusion models to generate draft
sequences. This allows parallelization of both the drafting and verification
steps, providing significant speedups to the inference process. Our proposed
approach, $\textit{Speculative Diffusion Decoding (SpecDiff)}$, is validated on
standard language generation benchmarks and empirically demonstrated to provide
up to 7.2x speedups over standard generation processes and up to 1.75x speedups
over existing speculative decoding approaches.",2024-08-10,"Jacob K Christopher, Brian R Bartoldson, Tal Ben-Nun, Michael Cardei, Bhavya Kailkhura, Ferdinando Fioretto",http://arxiv.org/pdf/2408.05636v4,cs.CL
ViC: Virtual Compiler Is All You Need For Assembly Code Search,"Assembly code search is vital for reducing the burden on reverse engineers,
allowing them to quickly identify specific functions using natural language
within vast binary programs. Despite its significance, this critical task is
impeded by the complexities involved in building high-quality datasets. This
paper explores training a Large Language Model (LLM) to emulate a general
compiler. By leveraging Ubuntu packages to compile a dataset of 20 billion
tokens, we further continue pre-train CodeLlama as a Virtual Compiler (ViC),
capable of compiling any source code of any language to assembly code. This
approach allows for virtual compilation across a wide range of programming
languages without the need for a real compiler, preserving semantic equivalency
and expanding the possibilities for assembly code dataset construction.
Furthermore, we use ViC to construct a sufficiently large dataset for assembly
code search. Employing this extensive dataset, we achieve a substantial
improvement in assembly code search performance, with our model surpassing the
leading baseline by 26%.",2024-08-10,"Zeyu Gao, Hao Wang, Yuanda Wang, Chao Zhang",http://arxiv.org/pdf/2408.06385v1,cs.CL
Metacognitive Myopia in Large Language Models,"Large Language Models (LLMs) exhibit potentially harmful biases that
reinforce culturally inherent stereotypes, cloud moral judgments, or amplify
positive evaluations of majority groups. Previous explanations mainly
attributed bias in LLMs to human annotators and the selection of training data.
Consequently, they have typically been addressed with bottom-up approaches such
as reinforcement learning or debiasing corpora. However, these methods only
treat the effects of LLM biases by indirectly influencing the model
architecture, but do not address the underlying causes in the computational
process. Here, we propose metacognitive myopia as a cognitive-ecological
framework that can account for a conglomerate of established and emerging LLM
biases and provide a lever to address problems in powerful but vulnerable
tools. Our theoretical framework posits that a lack of the two components of
metacognition, monitoring and control, causes five symptoms of metacognitive
myopia in LLMs: integration of invalid tokens and embeddings, susceptibility to
redundant information, neglect of base rates in conditional computation,
decision rules based on frequency, and inappropriate higher-order statistical
inference for nested data structures. As a result, LLMs produce erroneous
output that reaches into the daily high-stakes decisions of humans. By
introducing metacognitive regulatory processes into LLMs, engineers and
scientists can develop precise remedies for the underlying causes of these
biases. Our theory sheds new light on flawed human-machine interactions and
raises ethical concerns regarding the increasing, imprudent implementation of
LLMs in organizational structures.",2024-08-10,"Florian Scholten, Tobias R. Rebholz, Mandy Hütter",http://arxiv.org/pdf/2408.05568v1,cs.CL
Document-Level Event Extraction with Definition-Driven ICL,"In the field of Natural Language Processing (NLP), Large Language Models
(LLMs) have shown great potential in document-level event extraction tasks, but
existing methods face challenges in the design of prompts. To address this
issue, we propose an optimization strategy called ""Definition-driven
Document-level Event Extraction (DDEE)."" By adjusting the length of the prompt
and enhancing the clarity of heuristics, we have significantly improved the
event extraction performance of LLMs. We used data balancing techniques to
solve the long-tail effect problem, enhancing the model's generalization
ability for event types. At the same time, we refined the prompt to ensure it
is both concise and comprehensive, adapting to the sensitivity of LLMs to the
style of prompts. In addition, the introduction of structured heuristic methods
and strict limiting conditions has improved the precision of event and argument
role extraction. These strategies not only solve the prompt engineering
problems of LLMs in document-level event extraction but also promote the
development of event extraction technology, providing new research perspectives
for other tasks in the NLP field.",2024-08-10,"Zhuoyuan Liu, Yilin Luo",http://arxiv.org/pdf/2408.05566v1,cs.CL
Large Language Model-based Role-Playing for Personalized Medical Jargon Extraction,"Previous studies reveal that Electronic Health Records (EHR), which have been
widely adopted in the U.S. to allow patients to access their personal medical
information, do not have high readability to patients due to the prevalence of
medical jargon. Tailoring medical notes to individual comprehension by
identifying jargon that is difficult for each person will enhance the utility
of generative models. We present the first quantitative analysis to measure the
impact of role-playing in LLM in medical term extraction. By comparing the
results of Mechanical Turk workers over 20 sentences, our study demonstrates
that LLM role-playing improves F1 scores in 95% of cases across 14 different
socio-demographic backgrounds. Furthermore, applying role-playing with
in-context learning outperformed the previous state-of-the-art models. Our
research showed that ChatGPT can improve traditional medical term extraction
systems by utilizing role-play to deliver personalized patient education, a
potential that previous models had not achieved.",2024-08-10,"Jung Hoon Lim, Sunjae Kwon, Zonghai Yao, John P. Lalor, Hong Yu",http://arxiv.org/pdf/2408.05555v1,cs.CL
Improving Whisper's Recognition Performance for Under-Represented Language Kazakh Leveraging Unpaired Speech and Text,"Whisper and other large-scale automatic speech recognition models have made
significant progress in performance. However, their performance on many
low-resource languages, such as Kazakh, is not satisfactory. It is worth
researching how to utilize low-cost data to improve the performance of Whisper
on under-represented languages. In this study, we utilized easily accessible
unpaired speech and text data and combined the language model GPT with Whisper
on Kazakh. We implemented end of transcript (EOT) judgment modification and
hallucination penalty to improve the performance of speech recognition.
Further, we employed the decoding average token log probability as a criterion
to select samples from unlabeled speech data and used pseudo-labeled data to
fine-tune the model to further improve its performance. Ultimately, we achieved
more than 10\% absolute WER reduction in multiple experiments, and the whole
process has the potential to be generalized to other under-represented
languages.",2024-08-10,"Jinpeng Li, Yu Pu, Qi Sun, Wei-Qiang Zhang",http://arxiv.org/pdf/2408.05554v1,cs.CL
Multi-layer Sequence Labeling-based Joint Biomedical Event Extraction,"In recent years, biomedical event extraction has been dominated by
complicated pipeline and joint methods, which need to be simplified. In
addition, existing work has not effectively utilized trigger word information
explicitly. Hence, we propose MLSL, a method based on multi-layer sequence
labeling for joint biomedical event extraction. MLSL does not introduce prior
knowledge and complex structures. Moreover, it explicitly incorporates the
information of candidate trigger words into the sequence labeling to learn the
interaction relationships between trigger words and argument roles. Based on
this, MLSL can learn well with just a simple workflow. Extensive
experimentation demonstrates the superiority of MLSL in terms of extraction
performance compared to other state-of-the-art methods.",2024-08-10,"Gongchi Chen, Pengchao Wu, Jinghang Gu, Longhua Qian, Guodong Zhou",http://arxiv.org/pdf/2408.05545v2,cs.CL
"P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for data pruning in LLM Training","In the rapidly advancing field of Large Language Models (LLMs), effectively
leveraging existing datasets during fine-tuning to maximize the model's
potential is of paramount importance. This paper introduces P3, an adaptive
framework aimed at optimizing the task-specific fine-tuning process through
iterative data pruning. P3 consists of three key components: (1) Policy-driven
Difficulty Measurement, which dynamically assesses data difficulty based on the
model's real-time performance, replacing static metrics with adaptable
evaluations; (2) Pace-Adaptive Selection, leveraging self-paced learning to
progressively introduce more challenging data, thereby enhancing model
capability; (3) Diversity Promotion, incorporating Determinantal Point Process
(DPP) to ensure data diversity across epochs, enriching the learning process.
We validate P3 on the reasoning scenarios, APPS and MATH, demonstrating
significant improvements over traditional data pruning methods. By advancing
dynamic data selection and utilization strategies, P3 contributes both a
theoretical framework and concrete approach to fully exploit existing data for
LLMs' performance improvement, offering utility across diverse tasks.",2024-08-10,"Yingxuan Yang, Huayi Wang, Muning Wen, Xiaoyun Mo, Qiuying Peng, Jun Wang, Weinan Zhang",http://arxiv.org/pdf/2408.05541v2,cs.CL
Context-Driven Index Trimming: A Data Quality Perspective to Enhancing Precision of RALMs,"Retrieval-Augmented Large Language Models (RALMs) have made significant
strides in enhancing the accuracy of generated responses.However, existing
research often overlooks the data quality issues within retrieval results,
often caused by inaccurate existing vector-distance-based retrieval methods.We
propose to boost the precision of RALMs' answers from a data quality
perspective through the Context-Driven Index Trimming (CDIT) framework, where
Context Matching Dependencies (CMDs) are employed as logical data quality rules
to capture and regulate the consistency between retrieved contexts.Based on the
semantic comprehension capabilities of Large Language Models (LLMs), CDIT can
effectively identify and discard retrieval results that are inconsistent with
the query context and further modify indexes in the database, thereby improving
answer quality.Experiments demonstrate on challenging question-answering
tasks.Also, the flexibility of CDIT is verified through its compatibility with
various language models and indexing methods, which offers a promising approach
to bolster RALMs' data quality and retrieval precision jointly.",2024-08-10,"Kexin Ma, Ruochun Jin, Xi Wang, Huan Chen, Jing Ren, Yuhua Tang",http://arxiv.org/pdf/2408.05524v1,cs.CL
SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning,"Recent development in Large Language Models (LLMs) and Multi-modal Large
Language Models (MLLMs) have leverage Attention-based Transformer architectures
and achieved superior performance and generalization capabilities. They have
since covered extensive areas of traditional learning tasks. For instance,
text-based tasks such as text-classification and sequence-labeling, as well as
multi-modal tasks like Visual Question Answering (VQA) and Optical Character
Recognition (OCR), which were previously addressed using different models, can
now be tackled based on one foundation model. Consequently, the training and
lightweight fine-tuning of LLMs and MLLMs, especially those based on
Transformer architecture, has become particularly important. In recognition of
these overwhelming needs, we develop SWIFT, a customizable one-stop
infrastructure for large models. With support of over $300+$ LLMs and $50+$
MLLMs, SWIFT stands as the open-source framework that provide the most
comprehensive support for fine-tuning large models. In particular, it is the
first training framework that provides systematic support for MLLMs. In
addition to the core functionalities of fine-tuning, SWIFT also integrates
post-training processes such as inference, evaluation, and model quantization,
to facilitate fast adoptions of large models in various application scenarios.
With a systematic integration of various training techniques, SWIFT offers
helpful utilities such as benchmark comparisons among different training
techniques for large models. For fine-tuning models specialized in agent
framework, we show that notable improvements on the ToolBench leader-board can
be achieved by training with customized dataset on SWIFT, with an increase of
5.2%-21.8% in the Act.EM metric over various baseline models, a reduction in
hallucination by 1.6%-14.1%, and an average performance improvement of 8%-17%.",2024-08-10,"Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Hong Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen",http://arxiv.org/pdf/2408.05517v4,cs.CL
Your Context Is Not an Array: Unveiling Random Access Limitations in Transformers,"Despite their recent successes, Transformer-based large language models show
surprising failure modes. A well-known example of such failure modes is their
inability to length-generalize: solving problem instances at inference time
that are longer than those seen during training. In this work, we further
explore the root cause of this failure by performing a detailed analysis of
model behaviors on the simple parity task. Our analysis suggests that length
generalization failures are intricately related to a model's inability to
perform random memory accesses within its context window. We present supporting
evidence for this hypothesis by demonstrating the effectiveness of
methodologies that circumvent the need for indexing or that enable random token
access indirectly, through content-based addressing. We further show where and
how the failure to perform random memory access manifests through attention map
visualizations.",2024-08-10,"MohammadReza Ebrahimi, Sunny Panchal, Roland Memisevic",http://arxiv.org/pdf/2408.05506v1,cs.CL
GEM: Context-Aware Gaze EstiMation with Visual Search Behavior Matching for Chest Radiograph,"Gaze estimation is pivotal in human scene comprehension tasks, particularly
in medical diagnostic analysis. Eye-tracking technology facilitates the
recording of physicians' ocular movements during image interpretation, thereby
elucidating their visual attention patterns and information-processing
strategies. In this paper, we initially define the context-aware gaze
estimation problem in medical radiology report settings. To understand the
attention allocation and cognitive behavior of radiologists during the medical
image interpretation process, we propose a context-aware Gaze EstiMation (GEM)
network that utilizes eye gaze data collected from radiologists to simulate
their visual search behavior patterns throughout the image interpretation
process. It consists of a context-awareness module, visual behavior graph
construction, and visual behavior matching. Within the context-awareness
module, we achieve intricate multimodal registration by establishing
connections between medical reports and images. Subsequently, for a more
accurate simulation of genuine visual search behavior patterns, we introduce a
visual behavior graph structure, capturing such behavior through high-order
relationships (edges) between gaze points (nodes). To maintain the authenticity
of visual behavior, we devise a visual behavior-matching approach, adjusting
the high-order relationships between them by matching the graph constructed
from real and estimated gaze points. Extensive experiments on four publicly
available datasets demonstrate the superiority of GEM over existing methods and
its strong generalizability, which also provides a new direction for the
effective utilization of diverse modalities in medical image interpretation and
enhances the interpretability of models in the field of medical imaging.
https://github.com/Tiger-SN/GEM",2024-08-10,"Shaonan Liu, Wenting Chen, Jie Liu, Xiaoling Luo, Linlin Shen",http://arxiv.org/pdf/2408.05502v1,cs.CL
MABR: Multilayer Adversarial Bias Removal Without Prior Bias Knowledge,"Models trained on real-world data often mirror and exacerbate existing social
biases. Traditional methods for mitigating these biases typically require prior
knowledge of the specific biases to be addressed, such as gender or racial
biases, and the social groups associated with each instance. In this paper, we
introduce a novel adversarial training strategy that operates independently of
prior bias-type knowledge and protected attribute labels. Our approach
proactively identifies biases during model training by utilizing auxiliary
models, which are trained concurrently by predicting the performance of the
main model without relying on task labels. Additionally, we implement these
auxiliary models at various levels of the feature maps of the main model,
enabling the detection of a broader and more nuanced range of bias features.
Through experiments on racial and gender biases in sentiment and occupation
classification tasks, our method effectively reduces social biases without the
need for demographic annotations. Moreover, our approach not only matches but
often surpasses the efficacy of methods that require detailed demographic
insights, marking a significant advancement in bias mitigation techniques.",2024-08-10,"Maxwell J. Yin, Boyu Wang, Charles Ling",http://arxiv.org/pdf/2408.05497v3,cs.CL
Investigating Instruction Tuning Large Language Models on Graphs,"Inspired by the recent advancements of Large Language Models (LLMs) in NLP
tasks, there's growing interest in applying LLMs to graph-related tasks. This
study delves into the capabilities of instruction-following LLMs for engaging
with real-world graphs, aiming to offer empirical insights into how LLMs can
effectively interact with graphs and generalize across graph tasks. We begin by
constructing a dataset designed for instruction tuning, which comprises a
diverse collection of 79 graph-related tasks from academic and e-commerce
domains, featuring 44,240 training instances and 18,960 test samples. Utilizing
this benchmark, our initial investigation focuses on identifying the optimal
graph representation that serves as a conduit for LLMs to understand complex
graph structures. Our findings indicate that JSON format for graph
representation consistently outperforms natural language and code formats
across various LLMs and graph types. Furthermore, we examine the key factors
that influence the generalization abilities of instruction-tuned LLMs by
evaluating their performance on both in-domain and out-of-domain graph tasks.",2024-08-10,"Kerui Zhu, Bo-Wei Huang, Bowen Jin, Yizhu Jiao, Ming Zhong, Kevin Chang, Shou-De Lin, Jiawei Han",http://arxiv.org/pdf/2408.05457v1,cs.CL
Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation,"Unified graph representation learning aims to produce node embeddings, which
can be applied to multiple downstream applications. However, existing studies
based on graph neural networks and language models either suffer from the
limitations of numerous training needed toward specific downstream predictions
or have shallow semantic features. In this work, we propose a novel Path-LLM
model to learn unified graph representation, which leverages a powerful large
language model (LLM) to incorporate our proposed path features. Our Path-LLM
framework consists of several well-designed techniques. First, we develop a new
mechanism of long-to-short shortest path (L2SP) selection, which covers
essential connections between different dense groups. An in-depth comparison of
different path selection plans is offered to illustrate the strength of our
designed L2SP. Then, we design path textualization to obtain L2SP-based
training texts. Next, we feed the texts into a self-supervised LLM training
process to learn embeddings. Extensive experiments on benchmarks validate the
superiority of Path-LLM against the state-of-the-art WalkLM method on two
classical graph learning tasks (node classification and link prediction) and
one NP-hard graph query processing task (keyword search), meanwhile saving more
than 90% of training paths.",2024-08-10,"Wenbo Shang, Xuliang Zhu, Xin Huang",http://arxiv.org/pdf/2408.05456v1,cs.CL
Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions,"Large Language Models (LLMs) represent a significant advancement in
artificial intelligence, finding applications across various domains. However,
their reliance on massive internet-sourced datasets for training brings notable
privacy issues, which are exacerbated in critical domains (e.g., healthcare).
Moreover, certain application-specific scenarios may require fine-tuning these
models on private data. This survey critically examines the privacy threats
associated with LLMs, emphasizing the potential for these models to memorize
and inadvertently reveal sensitive information. We explore current threats by
reviewing privacy attacks on LLMs and propose comprehensive solutions for
integrating privacy mechanisms throughout the entire learning pipeline. These
solutions range from anonymizing training datasets to implementing differential
privacy during training or inference and machine unlearning after training. Our
comprehensive review of existing literature highlights ongoing challenges,
available tools, and future directions for preserving privacy in LLMs. This
work aims to guide the development of more secure and trustworthy AI systems by
providing a thorough understanding of privacy preservation methods and their
effectiveness in mitigating risks.",2024-08-10,"Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, Sébastien Bratières, Emanuele Rodolà",http://arxiv.org/pdf/2408.05212v2,cs.CL
"Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering","Conditional question answering (CQA) is an important task that aims to find
probable answers and identify missing conditions. Existing approaches struggle
with CQA due to two challenges: (1) precisely identifying necessary conditions
and the logical relationship, and (2) verifying conditions to detect any that
are missing. In this paper, we propose a novel prompting approach, Chain of
condition, by first identifying all conditions and constructing their logical
relationships explicitly according to the document, then verifying whether
these conditions are satisfied, finally solving the logical expression to
indicate any missing conditions and generating the answer accordingly.
Experiments on two CQA benchmark datasets show our chain of condition
outperforms existing prompting baselines, establishing a new state of the art.
Furthermore, with only a few examples, our method can facilitate GPT-3.5-Turbo
or GPT-4 to outperform all existing supervised models.",2024-08-10,"Jiuheng Lin, Yuxuan Lai, Yansong Feng",http://arxiv.org/pdf/2408.05442v2,cs.CL
LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification,"Metaphor Components Identification (MCI) contributes to enhancing machine
understanding of metaphors, thereby advancing downstream natural language
processing tasks. However, the complexity, diversity, and dependency on context
and background knowledge pose significant challenges for MCI. Large language
models (LLMs) offer new avenues for accurate comprehension of complex natural
language texts due to their strong semantic analysis and extensive commonsense
knowledge. In this research, a new LLM-based framework is proposed, named
Linguistics-aware In-context Learning with Data Augmentation (LaiDA).
Specifically, ChatGPT and supervised fine-tuning are utilized to tailor a
high-quality dataset. LaiDA incorporates a simile dataset for pre-training. A
graph attention network encoder generates linguistically rich feature
representations to retrieve similar examples. Subsequently, LLM is fine-tuned
with prompts that integrate linguistically similar examples. LaiDA ranked 2nd
in Subtask 2 of NLPCC2024 Shared Task 9, demonstrating its effectiveness. Code
and data are available at https://github.com/WXLJZ/LaiDA.",2024-08-10,"Hongde Liu, Chenyuan He, Feiyang Meng, Changyong Niu, Yuxiang Jia",http://arxiv.org/pdf/2408.05404v1,cs.CL
Text classification optimization algorithm based on graph neural network,"In the field of natural language processing, text classification, as a basic
task, has important research value and application prospects. Traditional text
classification methods usually rely on feature representations such as the bag
of words model or TF-IDF, which overlook the semantic connections between words
and make it challenging to grasp the deep structural details of the text.
Recently, GNNs have proven to be a valuable asset for text classification
tasks, thanks to their capability to handle non-Euclidean data efficiently.
However, the existing text classification methods based on GNN still face
challenges such as complex graph structure construction and high cost of model
training. This paper introduces a text classification optimization algorithm
utilizing graph neural networks. By introducing adaptive graph construction
strategy and efficient graph convolution operation, the accuracy and efficiency
of text classification are effectively improved. The experimental results
demonstrate that the proposed method surpasses traditional approaches and
existing GNN models across multiple public datasets, highlighting its superior
performance and feasibility for text classification tasks.",2024-08-09,"Erdi Gao, Haowei Yang, Dan Sun, Haohao Xia, Yuhan Ma, Yuanjing Zhu",http://arxiv.org/pdf/2408.15257v1,cs.CL
FiSTECH: Financial Style Transfer to Enhance Creativity without Hallucinations in LLMs,"Recent trends in Generative AI have emerged towards fine-tuning foundational
large language models (LLMs) to create domain-specific LLMs for automation and
chatbot-like applications. Specialized applications for analytics-heavy domains
such as Financial report generation require specific writing styles that
comprise compound and creative sentences with minimized hallucinations. In this
work, we explore the self-corrective auto-regressive qualities of LLMs to learn
creativity in writing styles with minimal prompting. We propose a novel
two-stage fine-tuning (FT) strategy wherein in the first stage public domain
financial reports are used to train for writing styles while allowing the LLM
to hallucinate. In the second stage the examples of hallucinations are manually
corrected and further used to fine-tune the LLM. The finally trained LLM learns
to generate specific financial report sections using minimal instructions and
tabular data inputs while ensuring low fine-tuning costs. Our proposed
two-stage fine-tuning boosts the accuracy of financial questions answering by
two-folds while reducing hallucinations by over 50%. Also, the fine-tuned model
has lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity
and knowledge density with lower uncertainty and cross entropy than base LLMs.
Thus, the proposed framework can be generalized to train creativity in LLMs by
first allowing them to hallucinate.",2024-08-09,"Sohini Roychowdhury, Marko Krema, Brian Moore, Xingjian Lai, Dike Effedua, Bharat Jethwani",http://arxiv.org/pdf/2408.05365v4,cs.CL
LLaMA based Punctuation Restoration With Forward Pass Only Decoding,"This paper introduces two advancements in the field of Large Language Model
Annotation with a focus on punctuation restoration tasks. Our first
contribution is the application of LLaMA for punctuation restoration, which
demonstrates superior performance compared to the established benchmark.
  Despite its impressive quality, LLaMA faces challenges regarding inference
speed and hallucinations. To address this, our second contribution presents
Forward Pass Only Decoding (FPOD), a novel decoding approach for annotation
tasks. This innovative method results in a substantial 19.8x improvement in
inference speed, effectively addressing a critical bottleneck and enhancing the
practical utility of LLaMA for large-scale data annotation tasks without
hallucinations.
  The combination of these contributions not only solidifies LLaMA as a
powerful tool for punctuation restoration but also highlights FPOD as a crucial
strategy for overcoming speed constraints.",2024-08-09,"Yutong Pang, Debjyoti Paul, Kevin Jiang, Xuedong Zhang, Xin Lei",http://arxiv.org/pdf/2408.11845v1,cs.CL
DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts,"Data-driven storytelling is a powerful method for conveying insights by
combining narrative techniques with visualizations and text. These stories
integrate visual aids, such as highlighted bars and lines in charts, along with
textual annotations explaining insights. However, creating such stories
requires a deep understanding of the data and meticulous narrative planning,
often necessitating human intervention, which can be time-consuming and
mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks,
their ability to generate coherent and comprehensive data stories remains
underexplored. In this work, we introduce a novel task for data story
generation and a benchmark containing 1,449 stories from diverse sources. To
address the challenges of crafting coherent data stories, we propose a
multiagent framework employing two LLM agents designed to replicate the human
storytelling process: one for understanding and describing the data
(Reflection), generating the outline, and narration, and another for
verification at each intermediary step. While our agentic framework generally
outperforms non-agentic counterparts in both model-based and human evaluations,
the results also reveal unique challenges in data story generation.",2024-08-09,"Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty",http://arxiv.org/pdf/2408.05346v3,cs.CL
Revisiting Multi-Modal LLM Evaluation,"With the advent of multi-modal large language models (MLLMs), datasets used
for visual question answering (VQA) and referring expression comprehension have
seen a resurgence. However, the most popular datasets used to evaluate MLLMs
are some of the earliest ones created, and they have many known problems,
including extreme bias, spurious correlations, and an inability to permit
fine-grained analysis. In this paper, we pioneer evaluating recent MLLMs (LLaVA
1.5, LLaVA-NeXT, BLIP2, InstructBLIP, GPT-4V, and GPT-4o) on datasets designed
to address weaknesses in earlier ones. We assess three VQA datasets: 1) TDIUC,
which permits fine-grained analysis on 12 question types; 2) TallyQA, which has
simple and complex counting questions; and 3) DVQA, which requires optical
character recognition for chart understanding. We also study VQDv1, a dataset
that requires identifying all image regions that satisfy a given query. Our
experiments reveal the weaknesses of many MLLMs that have not previously been
reported. Our code is integrated into the widely used LAVIS framework for MLLM
evaluation, enabling the rapid assessment of future MLLMs. Project webpage:
https://kevinlujian.github.io/MLLM_Evaluations/",2024-08-09,"Jian Lu, Shikhar Srivastava, Junyu Chen, Robik Shrestha, Manoj Acharya, Kushal Kafle, Christopher Kanan",http://arxiv.org/pdf/2408.05334v1,cs.CL
From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management,"This study explores the potential of Large Language Models (LLMs),
specifically GPT-4, to enhance objectivity in organizational task performance
evaluations. Through comparative analyses across two studies, including various
task performance outputs, we demonstrate that LLMs can serve as a reliable and
even superior alternative to human raters in evaluating knowledge-based
performance outputs, which are a key contribution of knowledge workers. Our
results suggest that GPT ratings are comparable to human ratings but exhibit
higher consistency and reliability. Additionally, combined multiple GPT ratings
on the same performance output show strong correlations with aggregated human
performance ratings, akin to the consensus principle observed in performance
evaluation literature. However, we also find that LLMs are prone to contextual
biases, such as the halo effect, mirroring human evaluative biases. Our
research suggests that while LLMs are capable of extracting meaningful
constructs from text-based data, their scope is currently limited to specific
forms of performance evaluation. By highlighting both the potential and
limitations of LLMs, our study contributes to the discourse on AI role in
management studies and sets a foundation for future research to refine AI
theoretical and practical applications in management.",2024-08-09,"Ning Li, Huaikang Zhou, Mingze Xu",http://arxiv.org/pdf/2408.05328v1,cs.CL
A Psychology-based Unified Dynamic Framework for Curriculum Learning,"Directly learning from examples of random difficulty levels is often
challenging for both humans and machine learning models. A more effective
strategy involves exposing learners to examples in a progressive order, from
easy to difficult. Curriculum Learning (CL) has been proposed to implement this
strategy in machine learning model training. However, two key challenges
persist in CL framework design: defining the difficulty of training data and
determining the appropriate amount of data to input at each training step. This
paper presents a Psychology-based Unified Dynamic Framework for Curriculum
Learning (PUDF), drawing inspiration from psychometrics. We quantify the
difficulty of training data by applying Item Response Theory (IRT) to responses
from Artificial Crowds (AC). This theory-driven IRT-AC approach leads to global
(i.e., model-independent) and interpretable difficulty values. Leveraging IRT,
we propose a Dynamic Data Selection via Model Ability Estimation (DDS-MAE)
strategy to schedule the appropriate amount of data during model training.
Since our difficulty labeling and model ability estimation are based on a
consistent theory, namely IRT, their values are comparable within the same
scope, potentially leading to a faster convergence compared to the other CL
methods. Experimental results demonstrate that fine-tuning pre-trained language
models with PUDF enhances their performance on the GLUE benchmark. Moreover,
PUDF surpasses other state-of-the-art (SOTA) CL methods on the GLUE benchmark.
We further explore the components of PUDF, namely the difficulty measurer
(IRT-AC) and the training scheduler (DDS-MAE) qualitatively and quantitatively.
Lastly, we conduct an ablation study to clarify which components of PUDF
contribute to faster convergence and higher accuracy.",2024-08-09,"Guangyu Meng, Qingkai Zeng, John P. Lalor, Hong Yu",http://arxiv.org/pdf/2408.05326v1,cs.CL
"MUSE: Multi-Knowledge Passing on the Edges, Boosting Knowledge Graph Completion","Knowledge Graph Completion (KGC) aims to predict the missing information in
the (head entity)-[relation]-(tail entity) triplet. Deep Neural Networks have
achieved significant progress in the relation prediction task. However, most
existing KGC methods focus on single features (e.g., entity IDs) and sub-graph
aggregation, which cannot fully explore all the features in the Knowledge Graph
(KG), and neglect the external semantic knowledge injection. To address these
problems, we propose MUSE, a knowledge-aware reasoning model to learn a
tailored embedding space in three dimensions for missing relation prediction
through a multi-knowledge representation learning mechanism. Our MUSE consists
of three parallel components: 1) Prior Knowledge Learning for enhancing the
triplets' semantic representation by fine-tuning BERT; 2) Context Message
Passing for enhancing the context messages of KG; 3) Relational Path
Aggregation for enhancing the path representation from the head entity to the
tail entity. Our experimental results show that MUSE significantly outperforms
other baselines on four public datasets, such as over 5.50% improvement in H@1
and 4.20% improvement in MRR on the NELL995 dataset. The code and all datasets
will be released via https://github.com/NxxTGT/MUSE.",2024-08-09,Pengjie Liu,http://arxiv.org/pdf/2408.05283v1,cs.CL
VITA: Towards Open-Source Interactive Omni Multimodal LLM,"The remarkable multimodal capabilities and interactive experience of GPT-4o
underscore their necessity in practical applications, yet open-source models
rarely excel in both areas. In this paper, we introduce VITA, the first-ever
open-source Multimodal Large Language Model (MLLM) adept at simultaneous
processing and analysis of Video, Image, Text, and Audio modalities, and
meanwhile has an advanced multimodal interactive experience. Starting from
Mixtral 8x7B as a language foundation, we expand its Chinese vocabulary
followed by bilingual instruction tuning. We further endow the language model
with visual and audio capabilities through two-stage multi-task learning of
multimodal alignment and instruction tuning. VITA demonstrates robust
foundational capabilities of multilingual, vision, and audio understanding, as
evidenced by its strong performance across a range of both unimodal and
multimodal benchmarks. Beyond foundational capabilities, we have made
considerable progress in enhancing the natural multimodal human-computer
interaction experience. VITA is the first step for the open-source community to
explore the seamless integration of multimodal understanding and interaction.
While there is still lots of work to be done on VITA to get close to
close-source counterparts, we hope that its role as a pioneer can serve as a
cornerstone for subsequent research. Project Page: https://vita-home.github.io.",2024-08-09,"Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Shaoqi Dong, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun",http://arxiv.org/pdf/2408.05211v2,cs.CL
Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners,"Large language models (LLMs), including OpenAI's GPT-series, have made
significant advancements in recent years. Known for their expertise across
diverse subject areas and quick adaptability to user-provided prompts, LLMs
hold unique potential as Personalized Learning (PL) tools. Despite this
potential, their application in K-12 education remains largely unexplored. This
paper presents one of the first randomized controlled trials (n = 23) to
evaluate the effectiveness of GPT-4 in personalizing educational science texts
for middle school students. In this study, GPT-4 was used to profile student
learning preferences based on choices made during a training session. For the
experimental group, GPT-4 was used to rewrite science texts to align with the
student's predicted profile while, for students in the control group, texts
were rewritten to contradict their learning preferences. The results of a
Mann-Whitney U test showed that students significantly preferred (at the .10
level) the rewritten texts when they were aligned with their profile (p =
.059). These findings suggest that GPT-4 can effectively interpret and tailor
educational content to diverse learner preferences, marking a significant
advancement in PL technology. The limitations of this study and ethical
considerations for using artificial intelligence in education are also
discussed.",2024-08-09,"Michael Vaccaro Jr, Mikayla Friday, Arash Zaghi",http://arxiv.org/pdf/2408.05204v1,cs.CL
KIF: Knowledge Identification and Fusion for Language Model Continual Learning,"Language model continual learning (CL) has recently attracted significant
interest for its ability to adapt large language models (LLMs) to dynamic
real-world scenarios without retraining. A major challenge in this domain is
catastrophic forgetting, where models lose previously acquired knowledge upon
learning new tasks. Existing approaches commonly utilize multiple
parameter-efficient fine-tuning (PEFT) blocks to acquire task-specific
knowledge, yet these methods are inefficient and fail to leverage potential
knowledge transfer across tasks. In this paper, we introduce a novel CL
framework for language models, named Knowledge Identification and Fusion (KIF),
which boosts knowledge transfer without depending on memory replay. KIF
initially segregates the model into 'skill units' based on parameter
dependencies, allowing for more precise control. Subsequently, it employs a
novel group-wise knowledge identification technique to ascertain the importance
distribution of skill units for a new task. By comparing this importance
distribution with those from previous tasks, we implement a fine-grained
knowledge fusion strategy that retains task-specific knowledge, thereby
preventing forgetting, and updates task-shared knowledge, which facilitates
bi-directional knowledge transfer. As a result, KIF achieves an optimal balance
between retaining prior knowledge and excelling in new tasks. KIF also
demonstrates strong generalizability, making it suitable for various base
models and adaptable to PEFT methods like LoRA. Furthermore, it offers notable
extensibility, supporting enhancements through integration with memory replay
techniques. Comprehensive experiments conducted on two CL benchmarks, involving
models ranging from 220M to 7B parameters, affirm the effectiveness of KIF and
its variants across different settings.",2024-08-09,"Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu",http://arxiv.org/pdf/2408.05200v4,cs.CL
Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation,"The task of deciding whether two documents are written by the same author is
challenging for both machines and humans. This task is even more challenging
when the two documents are written about different topics (e.g. baseball vs.
politics) or in different genres (e.g. a blog post vs. an academic article).
For machines, the problem is complicated by the relative lack of real-world
training examples that cross the topic boundary and the vanishing scarcity of
cross-genre data. We propose targeted methods for training data selection and a
novel learning curriculum that are designed to discourage a model's reliance on
topic information for authorship attribution and correspondingly force it to
incorporate information more robustly indicative of style no matter the topic.
These refinements yield a 62.7% relative improvement in average cross-genre
authorship attribution, as well as 16.6% in the per-genre condition.",2024-08-09,"Steven Fincke, Elizabeth Boschee",http://arxiv.org/pdf/2408.05192v1,cs.CL
Deep-change at AXOLOTL-24: Orchestrating WSD and WSI Models for Semantic Change Modeling,"This paper describes our solution of the first subtask from the AXOLOTL-24
shared task on Semantic Change Modeling. The goal of this subtask is to
distribute a given set of usages of a polysemous word from a newer time period
between senses of this word from an older time period and clusters representing
gained senses of this word. We propose and experiment with three new methods
solving this task. Our methods achieve SOTA results according to both official
metrics of the first substask. Additionally, we develop a model that can tell
if a given word usage is not described by any of the provided sense
definitions. This model serves as a component in one of our methods, but can
potentially be useful on its own.",2024-08-09,"Denis Kokosinskii, Mikhail Kuklin, Nikolay Arefyev",http://arxiv.org/pdf/2408.05184v1,cs.CL
Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2,"Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse
decomposition of a neural network's latent representations into seemingly
interpretable features. Despite recent excitement about their potential,
research applications outside of industry are limited by the high cost of
training a comprehensive suite of SAEs. In this work, we introduce Gemma Scope,
an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2
2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs
on the Gemma 2 pre-trained models, but additionally release SAEs trained on
instruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each
SAE on standard metrics and release these results. We hope that by releasing
these SAE weights, we can help make more ambitious safety and interpretability
research easier for the community. Weights and a tutorial can be found at
https://huggingface.co/google/gemma-scope and an interactive demo can be found
at https://www.neuronpedia.org/gemma-scope",2024-08-09,"Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, János Kramár, Anca Dragan, Rohin Shah, Neel Nanda",http://arxiv.org/pdf/2408.05147v2,cs.CL
A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning,"Retrieval-augmented generation (RAG) is a framework enabling large language
models (LLMs) to enhance their accuracy and reduce hallucinations by
integrating external knowledge bases. In this paper, we introduce a hybrid RAG
system enhanced through a comprehensive suite of optimizations that
significantly improve retrieval quality, augment reasoning capabilities, and
refine numerical computation ability. We refined the text chunks and tables in
web pages, added attribute predictors to reduce hallucinations, conducted LLM
Knowledge Extractor and Knowledge Graph Extractor, and finally built a
reasoning strategy with all the references. We evaluated our system on the CRAG
dataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and
online evaluations demonstrate that our system significantly enhances complex
reasoning capabilities. In local evaluations, we have significantly improved
accuracy and reduced error rates compared to the baseline model, achieving a
notable increase in scores. In the meanwhile, we have attained outstanding
results in online assessments, demonstrating the performance and generalization
capabilities of the proposed system. The source code for our system is released
in \url{https://gitlab.aicrowd.com/shizueyy/crag-new}.",2024-08-09,"Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang",http://arxiv.org/pdf/2408.05141v3,cs.CL
Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media,"In the dynamic field of artificial intelligence (AI), the development and
application of Large Language Models (LLMs) for text analysis are of
significant academic interest. Despite the promising capabilities of various
LLMs in conducting qualitative analysis, their use in the humanities and social
sciences has not been thoroughly examined. This article contributes to the
emerging literature on LLMs in qualitative analysis by documenting an
experimental study involving GPT-4. The study focuses on performing thematic
analysis (TA) using a YouTube dataset derived from an EU-funded project, which
was previously analyzed by other researchers. This dataset is about the
representation of Roma migrants in Sweden during 2016, a period marked by the
aftermath of the 2015 refugee crisis and preceding the Swedish national
elections in 2017. Our study seeks to understand the potential of combining
human intelligence with AI's scalability and efficiency, examining the
advantages and limitations of employing LLMs in qualitative research within the
humanities and social sciences. Additionally, we discuss future directions for
applying LLMs in these fields.",2024-08-09,"Petre Breazu, Miriam Schirmer, Songbo Hu, Napoleon Katsos",http://arxiv.org/pdf/2408.05126v1,cs.CL
Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning,"Textual graphs are ubiquitous in real-world applications, featuring rich text
information with complex relationships, which enables advanced research across
various fields. Textual graph representation learning aims to generate
low-dimensional feature embeddings from textual graphs that can improve the
performance of downstream tasks. A high-quality feature embedding should
effectively capture both the structural and the textual information in a
textual graph. However, most textual graph dataset benchmarks rely on word2vec
techniques to generate feature embeddings, which inherently limits their
capabilities. Recent works on textual graph representation learning can be
categorized into two folds: supervised and unsupervised methods. Supervised
methods finetune a language model on labeled nodes, which have limited
capabilities when labeled data is scarce. Unsupervised methods, on the other
hand, extract feature embeddings by developing complex training pipelines. To
address these limitations, we propose a novel unified unsupervised learning
autoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ
language models as the backbone of the autoencoder, with pretraining on text
reconstruction. Additionally, we add an auxiliary loss term to make the feature
embeddings aware of the local graph structure. Our method maintains simplicity
in the training process and demonstrates generalizability across diverse
textual graphs and downstream tasks. We evaluate our method on two core graph
representation learning downstream tasks: node classification and link
prediction. Comprehensive experiments demonstrate that our approach
substantially enhances the performance of diverse graph neural networks (GNNs)
across multiple textual graph datasets.",2024-08-09,"Wenbin Hu, Huihao Jing, Qi Hu, Haoran Li, Yangqiu Song",http://arxiv.org/pdf/2408.07091v2,cs.CL
How Well Do LLMs Identify Cultural Unity in Diversity?,"Much work on the cultural awareness of large language models (LLMs) focuses
on the models' sensitivity to geo-cultural diversity. However, in addition to
cross-cultural differences, there also exists common ground across cultures.
For instance, a bridal veil in the United States plays a similar
cultural-relevant role as a honggaitou in China. In this study, we introduce a
benchmark dataset CUNIT for evaluating decoder-only LLMs in understanding the
cultural unity of concepts. Specifically, CUNIT consists of 1,425 evaluation
examples building upon 285 traditional cultural-specific concepts across 10
countries. Based on a systematic manual annotation of cultural-relevant
features per concept, we calculate the cultural association between any pair of
cross-cultural concepts. Built upon this dataset, we design a contrastive
matching task to evaluate the LLMs' capability to identify highly associated
cross-cultural concept pairs. We evaluate 3 strong LLMs, using 3 popular
prompting strategies, under the settings of either giving all extracted concept
features or no features at all on CUNIT Interestingly, we find that cultural
associations across countries regarding clothing concepts largely differ from
food. Our analysis shows that LLMs are still limited to capturing
cross-cultural associations between concepts compared to humans. Moreover,
geo-cultural proximity shows a weak influence on model performance in capturing
cross-cultural associations.",2024-08-09,"Jialin Li, Junli Wang, Junjie Hu, Ming Jiang",http://arxiv.org/pdf/2408.05102v1,cs.CL
MooER: LLM-based Speech Recognition and Translation Models from Moore Threads,"In this paper, we present MooER, a LLM-based large-scale automatic speech
recognition (ASR) / automatic speech translation (AST) model of Moore Threads.
A 5000h pseudo labeled dataset containing open source and self collected speech
data is used for training. We achieve performance comparable to other open
source models trained with up to hundreds of thousands of hours of labeled
speech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest
that our model outperforms other open source Speech LLMs. A BLEU score of 25.2
can be obtained. The main contributions of this paper are summarized as
follows. First, this paper presents a training strategy for encoders and LLMs
on speech related tasks (including ASR and AST) using a small size of pseudo
labeled data without any extra manual annotation and selection. Second, we
release our ASR and AST models and plan to open-source our training code and
strategy in the near future. Moreover, a model trained on 8wh scale training
data is planned to be released later on.",2024-08-09,"Junhao Xu, Zhenlin Liang, Yi Liu, Yichao Hu, Jian Li, Yajun Zheng, Meng Cai, Hua Wang",http://arxiv.org/pdf/2408.05101v1,cs.CL
Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts,"The task of multi-objective alignment aims at balancing and controlling the
different alignment objectives (e.g., helpfulness, harmlessness and honesty) of
large language models to meet the personalized requirements of different users.
However, previous methods tend to train multiple models to deal with various
user preferences, with the number of trained models growing linearly with the
number of alignment objectives and the number of different preferences.
Meanwhile, existing methods are generally poor in extensibility and require
significant re-training for each new alignment objective considered.
Considering the limitation of previous approaches, we propose MCA
(Multi-objective Contrastive Alignemnt), which constructs an expert prompt and
an adversarial prompt for each objective to contrast at the decoding time and
balances the objectives through combining the contrast. Our approach is
verified to be superior to previous methods in obtaining a well-distributed
Pareto front among different alignment objectives.",2024-08-09,"Tingchen Fu, Yupeng Hou, Julian McAuley, Rui Yan",http://arxiv.org/pdf/2408.05094v1,cs.CL
Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models,"Large language models (LLMs) have generated significant attention since their
inception, finding applications across various academic and industrial domains.
However, these models often suffer from the ""hallucination problem"", where
outputs, though grammatically and logically coherent, lack factual accuracy or
are entirely fabricated. A particularly troubling issue discovered and widely
discussed recently is the numerical comparison error where multiple LLMs
incorrectly infer that ""9.11$>$9.9"". We discovered that the order in which LLMs
generate answers and reasoning impacts their consistency. Specifically, results
vary significantly when an LLM generates an answer first and then provides the
reasoning versus generating the reasoning process first and then the
conclusion. Inspired by this, we propose a new benchmark method for assessing
LLM consistency: comparing responses generated through these two different
approaches. This benchmark effectively identifies instances where LLMs
fabricate answers and subsequently generate justifications. Furthermore, we
introduce a novel and straightforward prompt strategy designed to mitigate this
issue. Experimental results demonstrate that this strategy improves performance
across various LLMs compared to direct questioning. This work not only sheds
light on a critical flaw in LLMs but also offers a practical solution to
enhance their reliability.",2024-08-09,Zikai Xie,http://arxiv.org/pdf/2408.05093v4,cs.CL
Generating novel experimental hypotheses from language models: A case study on cross-dative generalization,"Neural network language models (LMs) have been shown to successfully capture
complex linguistic knowledge. However, their utility for understanding language
acquisition is still debated. We contribute to this debate by presenting a case
study where we use LMs as simulated learners to derive novel experimental
hypotheses to be tested with humans. We apply this paradigm to study
cross-dative generalization (CDG): productive generalization of novel verbs
across dative constructions (she pilked me the ball/she pilked the ball to
me)--acquisition of which is known to involve a large space of contextual
features--using LMs trained on child-directed speech. We specifically ask:
""what properties of the training exposure facilitate a novel verb's
generalization to the (unmodeled) alternate construction?"" To answer this, we
systematically vary the exposure context in which a novel dative verb occurs in
terms of the properties of the theme and recipient, and then analyze the LMs'
usage of the novel verb in the unmodeled dative construction. We find LMs to
replicate known patterns of children's CDG, as a precondition to exploring
novel hypotheses. Subsequent simulations reveal a nuanced role of the features
of the novel verbs' exposure context on the LMs' CDG. We find CDG to be
facilitated when the first postverbal argument of the exposure context is
pronominal, definite, short, and conforms to the prototypical animacy
expectations of the exposure dative. These patterns are characteristic of
harmonic alignment in datives, where the argument with features ranking higher
on the discourse prominence scale tends to precede the other. This gives rise
to a novel hypothesis that CDG is facilitated insofar as the features of the
exposure context--in particular, its first postverbal argument--are
harmonically aligned. We conclude by proposing future experiments that can test
this hypothesis in children.",2024-08-09,"Kanishka Misra, Najoung Kim",http://arxiv.org/pdf/2408.05086v2,cs.CL
Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records,"Accurate survival prediction in radiotherapy (RT) is critical for optimizing
treatment decisions. This study developed and validated the RT-Surv framework,
which integrates general-domain, open-source large language models (LLMs) to
structure unstructured electronic health records alongside structured clinical
data. Using data from 34,276 patients and an external cohort of 852, the
framework successfully transformed unstructured clinical information into
structured formats. Incorporating LLM-structured clinical features improved the
concordance index from 0.779 to 0.842 during external validation, demonstrating
a significant performance enhancement. Key LLM-structured features, such as
disease extent, general condition, and RT purpose, showed high predictive
importance and aligned closely with statistically significant predictors
identified through conventional statistical analyses, thereby improving model
interpretability. Furthermore, the framework enhanced risk stratification,
enabling more distinct differentiation among low-, intermediate-, and high-risk
groups (p < 0.001) using LLM-structured clinical features. These findings
highlight the potential of LLMs to convert unstructured data into actionable
insights, improving predictive modeling and patient outcomes in clinics.",2024-08-09,"Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom",http://arxiv.org/pdf/2408.05074v5,cs.CL
Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil,"The Exame Nacional do Ensino M\'edio (ENEM) is a pivotal test for Brazilian
students, required for admission to a significant number of universities in
Brazil. The test consists of four objective high-school level tests on Math,
Humanities, Natural Sciences and Languages, and one writing essay. Students'
answers to the test and to the accompanying socioeconomic status questionnaire
are made public every year (albeit anonymized) due to transparency policies
from the Brazilian Government. In the context of large language models (LLMs),
these data lend themselves nicely to comparing different groups of humans with
AI, as we can have access to human and machine answer distributions. We
leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4,
and MariTalk, a model trained using Portuguese data, to humans, aiming to
ascertain how their answers relate to real societal groups and what that may
reveal about the model biases. We divide the human groups by using
socioeconomic status (SES), and compare their answer distribution with LLMs for
each question and for the essay. We find no significant biases when comparing
LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as
the distance between model and human answers is mostly determined by the human
accuracy. A similar conclusion is found by looking at the generated text as,
when analyzing the essays, we observe that human and LLM essays differ in a few
key factors, one being the choice of words where model essays were easily
separable from human ones. The texts also differ syntactically, with LLM
generated essays exhibiting, on average, smaller sentences and less thought
units, among other differences. These results suggest that, for Brazilian
Portuguese in the ENEM context, LLM outputs represent no group of humans, being
significantly different from the answers from Brazilian students across all
tests.",2024-08-09,"Marcelo Sartori Locatelli, Matheus Prado Miranda, Igor Joaquim da Silva Costa, Matheus Torres Prates, Victor Thomé, Mateus Zaparoli Monteiro, Tomas Lacerda, Adriana Pagano, Eduardo Rios Neto, Wagner Meira Jr., Virgilio Almeida",http://arxiv.org/pdf/2408.05035v1,cs.CL
MIDI-to-Tab: Guitar Tablature Inference via Masked Language Modeling,"Guitar tablatures enrich the structure of traditional music notation by
assigning each note to a string and fret of a guitar in a particular tuning,
indicating precisely where to play the note on the instrument. The problem of
generating tablature from a symbolic music representation involves inferring
this string and fret assignment per note across an entire composition or
performance. On the guitar, multiple string-fret assignments are possible for
most pitches, which leads to a large combinatorial space that prevents
exhaustive search approaches. Most modern methods use constraint-based dynamic
programming to minimize some cost function (e.g.\ hand position movement). In
this work, we introduce a novel deep learning solution to symbolic guitar
tablature estimation. We train an encoder-decoder Transformer model in a masked
language modeling paradigm to assign notes to strings. The model is first
pre-trained on DadaGP, a dataset of over 25K tablatures, and then fine-tuned on
a curated set of professionally transcribed guitar performances. Given the
subjective nature of assessing tablature quality, we conduct a user study
amongst guitarists, wherein we ask participants to rate the playability of
multiple versions of tablature for the same four-bar excerpt. The results
indicate our system significantly outperforms competing algorithms.",2024-08-09,"Drew Edwards, Xavier Riley, Pedro Sarmento, Simon Dixon",http://arxiv.org/pdf/2408.05024v1,cs.CL
Investigating a Benchmark for Training-set free Evaluation of Linguistic Capabilities in Machine Reading Comprehension,"Performance of NLP systems is typically evaluated by collecting a large-scale
dataset by means of crowd-sourcing to train a data-driven model and evaluate it
on a held-out portion of the data. This approach has been shown to suffer from
spurious correlations and the lack of challenging examples that represent the
diversity of natural language. Instead, we examine a framework for evaluating
optimised models in training-set free setting on synthetically generated
challenge sets. We find that despite the simplicity of the generation method,
the data can compete with crowd-sourced datasets with regard to naturalness and
lexical diversity for the purpose of evaluating the linguistic capabilities of
MRC models. We conduct further experiments and show that state-of-the-art
language model-based MRC systems can learn to succeed on the challenge set
correctly, although, without capturing the general notion of the evaluated
phenomenon.",2024-08-09,"Viktor Schlegel, Goran Nenadic, Riza Batista-Navarro",http://arxiv.org/pdf/2408.05023v1,cs.CL
Tabular Transfer Learning via Prompting LLMs,"Learning with a limited number of labeled data is a central problem in
real-world applications of machine learning, as it is often expensive to obtain
annotations. To deal with the scarcity of labeled data, transfer learning is a
conventional approach; it suggests to learn a transferable knowledge by
training a neural network from multiple other sources. In this paper, we
investigate transfer learning of tabular tasks, which has been less studied and
successful in the literature, compared to other domains, e.g., vision and
language. This is because tables are inherently heterogeneous, i.e., they
contain different columns and feature spaces, making transfer learning
difficult. On the other hand, recent advances in natural language processing
suggest that the label scarcity issue can be mitigated by utilizing in-context
learning capability of large language models (LLMs). Inspired by this and the
fact that LLMs can also process tables within a unified language space, we ask
whether LLMs can be effective for tabular transfer learning, in particular,
under the scenarios where the source and target datasets are of different
format. As a positive answer, we propose a novel tabular transfer learning
framework, coined Prompt to Transfer (P2T), that utilizes unlabeled (or
heterogeneous) source data with LLMs. Specifically, P2T identifies a column
feature in a source dataset that is strongly correlated with a target task
feature to create examples relevant to the target task, thus creating
pseudo-demonstrations for prompts. Experimental results demonstrate that P2T
outperforms previous methods on various tabular learning benchmarks, showing
good promise for the important, yet underexplored tabular transfer learning
problem. Code is available at https://github.com/jaehyun513/P2T.",2024-08-09,"Jaehyun Nam, Woomin Song, Seong Hyeon Park, Jihoon Tack, Sukmin Yun, Jaehyung Kim, Kyu Hwan Oh, Jinwoo Shin",http://arxiv.org/pdf/2408.11063v1,cs.CL
ProFuser: Progressive Fusion of Large Language Models,"While fusing the capacities and advantages of various large language models
(LLMs) offers a pathway to construct more powerful and versatile models, a
fundamental challenge is to properly select advantageous model during the
training. Existing fusion methods primarily focus on the training mode that
uses cross entropy on ground truth in a teacher-forcing setup to measure a
model's advantage, which may provide limited insight towards model advantage.
In this paper, we introduce a novel approach that enhances the fusion process
by incorporating both the training and inference modes. Our method evaluates
model advantage not only through cross entropy during training but also by
considering inference outputs, providing a more comprehensive assessment. To
combine the two modes effectively, we introduce ProFuser to progressively
transition from inference mode to training mode. To validate ProFuser's
effectiveness, we fused three models, including vicuna-7b-v1.5,
Llama-2-7b-chat, and mpt-7b-8k-chat, and demonstrated the improved performance
in knowledge, reasoning, and safety compared to baseline methods.",2024-08-09,"Tianyuan Shi, Fanqi Wan, Canbin Huang, Xiaojun Quan, Chenliang Li, Ming Yan, Ji Zhang",http://arxiv.org/pdf/2408.04998v1,cs.CL
Get Confused Cautiously: Textual Sequence Memorization Erasure with Selective Entropy Maximization,"Large Language Models (LLMs) have been found to memorize and recite some of
the textual sequences from their training set verbatim, raising broad concerns
about privacy and copyright issues when using LLMs. This Textual Sequence
Memorization (TSM) phenomenon leads to a high demand to regulate LLM output to
prevent it from generating certain memorized text to meet user requirements.
However, our empirical study reveals that existing methods for TSM erasure fail
to forget massive memorized samples without substantially jeopardizing the
model utility. To achieve a better trade-off between the effectiveness of TSM
erasure and model utility in LLMs, our paper proposes a new framework based on
Entropy Maximization with Selective Optimization (EMSO), where the updated
weights are chosen with a novel contrastive gradient metric without any
participation of additional model or data. Our analysis shows that training
with the entropy maximization loss has a more stable optimization process and
better keeps model utility than existing methods. The contrastive gradient
metric localizes the most influential weight for TSM erasure by taking both the
gradient magnitude and direction into consideration. Extensive experiments
across three model scales demonstrate that our method excels in handling
large-scale forgetting requests while preserving model ability in language
generation and reasoning.",2024-08-09,"Zhaohan Zhang, Ziquan Liu, Ioannis Patras",http://arxiv.org/pdf/2408.04983v1,cs.CL
reCSE: Portable Reshaping Features for Sentence Embedding in Self-supervised Contrastive Learning,"We propose reCSE, a self supervised contrastive learning sentence
representation framework based on feature reshaping. This framework is
different from the current advanced models that use discrete data augmentation
methods, but instead reshapes the input features of the original sentence,
aggregates the global information of each token in the sentence, and alleviates
the common problems of representation polarity and GPU memory consumption
linear increase in current advanced models. In addition, our reCSE has achieved
competitive performance in semantic similarity tasks. And the experiment proves
that our proposed feature reshaping method has strong universality, which can
be transplanted to other self supervised contrastive learning frameworks and
enhance their representation ability, even achieving state-of-the-art
performance. Our code is available at https://github.com/heavenhellchen/reCSE.",2024-08-09,"Fufangchen Zhao, Jian Gao, Danfeng Yan",http://arxiv.org/pdf/2408.04975v4,cs.CL
"Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks","Memorisation is a natural part of learning from real-world data: neural
models pick up on atypical input-output combinations and store those training
examples in their parameter space. That this happens is well-known, but how and
where are questions that remain largely unanswered. Given a multi-layered
neural model, where does memorisation occur in the millions of parameters?
Related work reports conflicting findings: a dominant hypothesis based on image
classification is that lower layers learn generalisable features and that
deeper layers specialise and memorise. Work from NLP suggests this does not
apply to language models, but has been mainly focused on memorisation of facts.
We expand the scope of the localisation question to 12 natural language
classification tasks and apply 4 memorisation localisation techniques. Our
results indicate that memorisation is a gradual process rather than a localised
one, establish that memorisation is task-dependent, and give nuance to the
generalisation first, memorisation second hypothesis.",2024-08-09,"Verna Dankers, Ivan Titov",http://arxiv.org/pdf/2408.04965v1,cs.CL
HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction,"Extraction and interpretation of intricate information from unstructured text
data arising in financial applications, such as earnings call transcripts,
present substantial challenges to large language models (LLMs) even using the
current best practices to use Retrieval Augmented Generation (RAG) (referred to
as VectorRAG techniques which utilize vector databases for information
retrieval) due to challenges such as domain specific terminology and complex
formats of the documents. We introduce a novel approach based on a combination,
called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called
GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for
information extraction from financial documents that is shown to be capable of
generating accurate and contextually relevant answers. Using experiments on a
set of financial earning call transcripts documents which come in the form of
Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we
show that HybridRAG which retrieves context from both vector database and KG
outperforms both traditional VectorRAG and GraphRAG individually when evaluated
at both the retrieval and generation stages in terms of retrieval accuracy and
answer generation. The proposed technique has applications beyond the financial
domain",2024-08-09,"Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta",http://arxiv.org/pdf/2408.04948v1,cs.CL
Quantitative Information Extraction from Humanitarian Documents,"Humanitarian action is accompanied by a mass of reports, summaries, news, and
other documents. To guide its activities, important information must be quickly
extracted from such free-text resources. Quantities, such as the number of
people affected, amount of aid distributed, or the extent of infrastructure
damage, are central to emergency response and anticipatory action. In this
work, we contribute an annotated dataset for the humanitarian domain for the
extraction of such quantitative information, along side its important context,
including units it refers to, any modifiers, and the relevant event. Further,
we develop a custom Natural Language Processing pipeline to extract the
quantities alongside their units, and evaluate it in comparison to baseline and
recent literature. The proposed model achieves a consistent improvement in the
performance, especially in the documents pertaining to the Dominican Republic
and select African countries. We make the dataset and code available to the
research community to continue the improvement of NLP tools for the
humanitarian domain.",2024-08-09,"Daniele Liberatore, Kyriaki Kalimeri, Derya Sever, Yelena Mejova",http://arxiv.org/pdf/2408.04941v1,cs.CL
Interactive-T2S: Multi-Turn Interactions for Text-to-SQL with Large Language Models,"This study explores text-to-SQL parsing by leveraging the powerful reasoning
capabilities of large language models (LLMs). Despite recent advancements,
existing LLM-based methods have not adequately addressed scalability, leading
to inefficiencies when processing wide tables. Furthermore, current
interaction-based approaches either lack a step-by-step, interpretable SQL
generation process or fail to provide an efficient and universally applicable
interaction design. To address these challenges, we introduce Interactive-T2S,
a framework that generates SQL queries through direct interactions with
databases. This framework includes four general tools that facilitate proactive
and efficient information retrieval by the LLM. Additionally, we have developed
detailed exemplars to demonstrate the step-wise reasoning processes within our
framework. Our experiments on the BIRD-Dev dataset, employing a setting without
oracle knowledge, reveal that our method achieves state-of-the-art results with
only two exemplars, underscoring the effectiveness and robustness of our
framework.",2024-08-09,"Guanming Xiong, Junwei Bao, Hongfei Jiang, Yang Song, Wen Zhao",http://arxiv.org/pdf/2408.11062v1,cs.CL
"Surveying the Landscape of Image Captioning Evaluation: A Comprehensive Taxonomy, Trends and Metrics Analysis","The task of image captioning has recently been gaining popularity, and with
it the complex task of evaluating the quality of image captioning models. In
this work, we present the first survey and taxonomy of over 70 different image
captioning metrics and their usage in hundreds of papers, specifically designed
to help users select the most suitable metric for their needs. We find that
despite the diversity of proposed metrics, the vast majority of studies rely on
only five popular metrics, which we show to be weakly correlated with human
ratings. We hypothesize that combining a diverse set of metrics can enhance
correlation with human ratings. As an initial step, we demonstrate that a
linear regression-based ensemble method, which we call EnsembEval, trained on
one human ratings dataset, achieves improved correlation across five additional
datasets, showing there is a lot of room for improvement by leveraging a
diverse set of metrics.",2024-08-09,"Uri Berger, Gabriel Stanovsky, Omri Abend, Lea Frermann",http://arxiv.org/pdf/2408.04909v2,cs.CL
Towards a Generative Approach for Emotion Detection and Reasoning,"Large language models (LLMs) have demonstrated impressive performance in
mathematical and commonsense reasoning tasks using chain-of-thought (CoT)
prompting techniques. But can they perform emotional reasoning by concatenating
`Let's think step-by-step' to the input prompt? In this paper we investigate
this question along with introducing a novel approach to zero-shot emotion
detection and emotional reasoning using LLMs. Existing state of the art
zero-shot approaches rely on textual entailment models to choose the most
appropriate emotion label for an input text. We argue that this strongly
restricts the model to a fixed set of labels which may not be suitable or
sufficient for many applications where emotion analysis is required. Instead,
we propose framing the problem of emotion analysis as a generative
question-answering (QA) task. Our approach uses a two step methodology of
generating relevant context or background knowledge to answer the emotion
detection question step-by-step. Our paper is the first work on using a
generative approach to jointly address the tasks of emotion detection and
emotional reasoning for texts. We evaluate our approach on two popular emotion
detection datasets and also release the fine-grained emotion labels and
explanations for further training and fine-tuning of emotional reasoning
systems.",2024-08-09,"Ankita Bhaumik, Tomek Strzalkowski",http://arxiv.org/pdf/2408.04906v1,cs.CL
GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models,"Large language models (LLMs) have achieved unprecedented success in the field
of natural language processing. However, the black-box nature of their internal
mechanisms has brought many concerns about their trustworthiness and
interpretability. Recent research has discovered a class of abnormal tokens in
the model's vocabulary space and named them ""glitch tokens"". Those tokens, once
included in the input, may induce the model to produce incorrect, irrelevant,
or even harmful results, drastically undermining the reliability and
practicality of LLMs.
  In this work, we aim to enhance the understanding of glitch tokens and
propose techniques for their detection and mitigation. We first reveal the
characteristic features induced by glitch tokens on LLMs, which are evidenced
by significant deviations in the distributions of attention patterns and
dynamic information from intermediate model layers. Based on the insights, we
develop GlitchProber, a tool for efficient glitch token detection and
mitigation. GlitchProber utilizes small-scale sampling, principal component
analysis for accelerated feature extraction, and a simple classifier for
efficient vocabulary screening. Taking one step further, GlitchProber rectifies
abnormal model intermediate layer values to mitigate the destructive effects of
glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber
demonstrates higher efficiency, precision, and recall compared to existing
approaches, with an average F1 score of 0.86 and an average repair rate of
50.06%. GlitchProber unveils a novel path to address the challenges posed by
glitch tokens and inspires future research toward more robust and interpretable
LLMs.",2024-08-09,"Zhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, Haoyu Wang",http://arxiv.org/pdf/2408.04905v2,cs.CL
Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication in Codenames,"Cultural differences in common ground may result in pragmatic failure and
misunderstandings during communication. We develop our method Rational Speech
Acts for Cross-Cultural Communication (RSA+C3) to resolve cross-cultural
differences in common ground. To measure the success of our method, we study
RSA+C3 in the collaborative referential game of Codenames Duet and show that
our method successfully improves collaboration between simulated players of
different cultures. Our contributions are threefold: (1) creating Codenames
players using contrastive learning of an embedding space and LLM prompting that
are aligned with human patterns of play, (2) studying culturally induced
differences in common ground reflected in our trained models, and (3)
demonstrating that our method RSA+C3 can ease cross-cultural communication in
gameplay by inferring sociocultural context from interaction. Our code is
publicly available at github.com/icwhite/codenames.",2024-08-09,"Isadora White, Sashrika Pandey, Michelle Pan",http://arxiv.org/pdf/2408.04900v1,cs.CL
Unsupervised Episode Detection for Large-Scale News Events,"Episodic structures are inherently interpretable and adaptable to evolving
large-scale key events. However, state-of-the-art automatic event detection
methods overlook event episodes and, therefore, struggle with these crucial
characteristics. This paper introduces a novel task, episode detection, aimed
at identifying episodes from a news corpus containing key event articles. An
episode describes a cohesive cluster of core entities (e.g., ""protesters"",
""police"") performing actions at a specific time and location. Furthermore, an
episode is a significant part of a larger group of episodes under a particular
key event. Automatically detecting episodes is challenging because, unlike key
events and atomic actions, we cannot rely on explicit mentions of times and
locations to distinguish between episodes or use semantic similarity to merge
inconsistent episode co-references. To address these challenges, we introduce
EpiMine, an unsupervised episode detection framework that (1) automatically
identifies the most salient, key-event-relevant terms and segments, (2)
determines candidate episodes in an article based on natural episodic
partitions estimated through shifts in discriminative term combinations, and
(3) refines and forms final episode clusters using large language model-based
reasoning on the candidate episodes. We construct three diverse, real-world
event datasets annotated at the episode level. EpiMine outperforms all
baselines on these datasets by an average 59.2% increase across all metrics.",2024-08-09,"Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han",http://arxiv.org/pdf/2408.04873v1,cs.CL
SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation,"In-context learning (ICL) greatly improves the performance of large language
models (LLMs) on various down-stream tasks, where the improvement highly
depends on the quality of demonstrations. In this work, we introduce syntactic
knowledge to select better in-context examples for machine translation (MT). We
propose a new strategy, namely Syntax-augmented COverage-based In-context
example selection (SCOI), leveraging the deep syntactic structure beyond
conventional word matching. Specifically, we measure the set-level syntactic
coverage by computing the coverage of polynomial terms with the help of a
simplified tree-to-polynomial algorithm, and lexical coverage using word
overlap. Furthermore, we devise an alternate selection approach to combine both
coverage measures, taking advantage of syntactic and lexical information. We
conduct experiments with two multi-lingual LLMs on six translation directions.
Empirical results show that our proposed SCOI obtains the highest average COMET
score among all learning-free methods, indicating that combining syntactic and
lexical coverage successfully helps to select better in-context examples for
MT. Our code is available at https://github.com/JamyDon/SCOI.",2024-08-09,"Chenming Tang, Zhixiang Wang, Yunfang Wu",http://arxiv.org/pdf/2408.04872v2,cs.CL
Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models,"In the information era, how learners find, evaluate, and effectively use
information has become a challenging issue, especially with the added
complexity of large language models (LLMs) that have further confused learners
in their information retrieval and search activities. This study attempts to
unpack this complexity by combining exploratory search strategies with the
theories of exploratory learning to form a new theoretical model of exploratory
learning from the perspective of students' learning. Our work adapts Kolb's
learning model by incorporating high-frequency exploration and feedback loops,
aiming to promote deep cognitive and higher-order cognitive skill development
in students. Additionally, this paper discusses and suggests how advanced LLMs
integrated into information retrieval and information theory can support
students in their exploratory searches, contributing theoretically to promoting
student-computer interaction and supporting their learning journeys in the new
era with LLMs.",2024-08-09,"Yiming Luo, Patrick Cheong-Iao Pang, Shanton Chang",http://arxiv.org/pdf/2408.08894v2,cs.CL
MSG-Chart: Multimodal Scene Graph for ChartQA,"Automatic Chart Question Answering (ChartQA) is challenging due to the
complex distribution of chart elements with patterns of the underlying data not
explicitly displayed in charts. To address this challenge, we design a joint
multimodal scene graph for charts to explicitly represent the relationships
between chart elements and their patterns. Our proposed multimodal scene graph
includes a visual graph and a textual graph to jointly capture the structural
and semantical knowledge from the chart. This graph module can be easily
integrated with different vision transformers as inductive bias. Our
experiments demonstrate that incorporating the proposed graph module enhances
the understanding of charts' elements' structure and semantics, thereby
improving performance on publicly available benchmarks, ChartQA and OpenCQA.",2024-08-09,"Yue Dai, Soyeon Caren Han, Wei Liu",http://arxiv.org/pdf/2408.04852v1,cs.CL
Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture,"The mental health assessment of middle school students has always been one of
the focuses in the field of education. This paper introduces a new ensemble
learning network based on BERT, employing the concept of enhancing model
performance by integrating multiple classifiers. We trained a range of
BERT-based learners, which combined using the majority voting method. We
collect social network text data of middle school students through China's
Weibo and apply the method to the task of classifying emotional tendencies in
middle school students' social network texts. Experimental results suggest that
the ensemble learning network has a better performance than the base model and
the performance of the ensemble learning model, consisting of three
single-layer BERT models, is barely the same as a three-layer BERT model but
requires 11.58% more training time. Therefore, in terms of balancing prediction
effect and efficiency, the deeper BERT network should be preferred for
training. However, for interpretability, network ensembles can provide
acceptable solutions.",2024-08-09,"Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo",http://arxiv.org/pdf/2408.04849v1,cs.CL
AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems,"Multi-agent systems, where multiple agents (generative AI models + tools)
collaborate, are emerging as an effective pattern for solving long-running,
complex tasks in numerous domains. However, specifying their parameters (such
as models, tools, and orchestration mechanisms etc,.) and debugging them
remains challenging for most developers. To address this challenge, we present
AUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging,
and evaluating multi-agent workflows built upon the AUTOGEN framework. AUTOGEN
STUDIO offers a web interface and a Python API for representing LLM-enabled
agents using a declarative (JSON-based) specification. It provides an intuitive
drag-and-drop UI for agent workflow specification, interactive evaluation and
debugging of workflows, and a gallery of reusable agent components. We
highlight four design principles for no-code multi-agent developer tools and
contribute an open-source implementation at
https://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio",2024-08-09,"Victor Dibia, Jingya Chen, Gagan Bansal, Suff Syed, Adam Fourney, Erkang Zhu, Chi Wang, Saleema Amershi",http://arxiv.org/pdf/2408.15247v1,cs.CL
mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models,"Multi-modal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in executing instructions for a variety of single-image tasks.
Despite this progress, significant challenges remain in modeling long image
sequences. In this work, we introduce the versatile multi-modal large language
model, mPLUG-Owl3, which enhances the capability for long image-sequence
understanding in scenarios that incorporate retrieved image-text knowledge,
interleaved image-text, and lengthy videos. Specifically, we propose novel
hyper attention blocks to efficiently integrate vision and language into a
common language-guided semantic space, thereby facilitating the processing of
extended multi-image scenarios. Extensive experimental results suggest that
mPLUG-Owl3 achieves state-of-the-art performance among models with a similar
size on single-image, multi-image, and video benchmarks. Moreover, we propose a
challenging long visual sequence evaluation named Distractor Resistance to
assess the ability of models to maintain focus amidst distractions. Finally,
with the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance
on ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to
the development of more efficient and powerful multimodal large language
models.",2024-08-09,"Jiabo Ye, Haiyang Xu, Haowei Liu, Anwen Hu, Ming Yan, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou",http://arxiv.org/pdf/2408.04840v2,cs.CL
Natural Language Outlines for Code: Literate Programming in the LLM Era,"We propose using natural language outlines as a novel modality and
interaction surface for providing AI assistance to developers throughout the
software development process. An NL outline for a code function comprises
multiple statements written in concise prose, which partition the code and
summarize its main ideas in the style of literate programming. Crucially, we
find that modern LLMs can generate accurate and high-quality NL outlines in
practice. Moreover, NL outlines enable a bidirectional sync between code and
NL, where a developer can change either code or NL and have the LLM
automatically update the other. We discuss many use cases for NL outlines: they
can accelerate understanding and navigation of code and diffs, simplify code
maintenance, augment code search, steer code generation, and more. We then
propose and compare multiple LLM prompting techniques for generating outlines
and ask professional developers to judge outline quality. Finally, we present
two case studies applying NL outlines toward code review and malware detection.",2024-08-09,"Kensen Shi, Deniz Altınbüken, Saswat Anand, Mihai Christodorescu, Katja Grünwedel, Alexa Koenings, Sai Naidu, Anurag Pathak, Marc Rasi, Fredde Ribeiro, Brandon Ruffin, Siddhant Sanyam, Maxim Tabachnyk, Sara Toth, Roy Tu, Tobias Welp, Pengcheng Yin, Manzil Zaheer, Satish Chandra, Charles Sutton",http://arxiv.org/pdf/2408.04820v4,cs.CL
FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers,"The widespread use of large language models has resulted in a multitude of
tokenizers and embedding spaces, making knowledge transfer in prompt discovery
tasks difficult. In this work, we propose FUSE (Flexible Unification of
Semantic Embeddings), an inexpensive approach to approximating an adapter layer
that maps from one model's textual embedding space to another, even across
different tokenizers. We introduce a third-order tensor-based representation of
a model's embedding space that aligns semantic embeddings that have been split
apart by different tokenizers, and use this representation to derive an
approximation of the gradient of one model's outputs with respect to another
model's embedding space. We show the efficacy of our approach via
multi-objective optimization over vision-language and causal language models
for image captioning and sentiment-based image captioning.",2024-08-09,"Joshua Nathaniel Williams, J. Zico Kolter",http://arxiv.org/pdf/2408.04816v1,cs.CL
h4rm3l: A language for Composable Jailbreak Attack Synthesis,"Despite their demonstrated valuable capabilities, state-of-the-art (SOTA)
widely deployed large language models (LLMs) still have the potential to cause
harm to society due to the ineffectiveness of their safety filters, which can
be bypassed by prompt transformations called jailbreak attacks. Current
approaches to LLM safety assessment, which employ datasets of templated prompts
and benchmarking pipelines, fail to cover sufficiently large and diverse sets
of jailbreak attacks, leading to the widespread deployment of unsafe LLMs.
Recent research showed that novel jailbreak attacks could be derived by
composition; however, a formal composable representation for jailbreak attacks,
which, among other benefits, could enable the exploration of a large
compositional space of jailbreak attacks through program synthesis methods, has
not been previously proposed. We introduce h4rm3l, a novel approach that
addresses this gap with a human-readable domain-specific language (DSL). Our
framework comprises: (1) The h4rm3l DSL, which formally expresses jailbreak
attacks as compositions of parameterized string transformation primitives. (2)
A synthesizer with bandit algorithms that efficiently generates jailbreak
attacks optimized for a target black box LLM. (3) The h4rm3l red-teaming
software toolkit that employs the previous two components and an automated
harmful LLM behavior classifier that is strongly aligned with human judgment.
We demonstrate h4rm3l's efficacy by synthesizing a dataset of 2656 successful
novel jailbreak attacks targeting 6 SOTA open-source and proprietary LLMs, and
by benchmarking those models against a subset of these synthesized attacks. Our
results show that h4rm3l's synthesized attacks are diverse and more successful
than existing jailbreak attacks in literature, with success rates exceeding 90%
on SOTA LLMs.",2024-08-09,"Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning",http://arxiv.org/pdf/2408.04811v4,cs.CL
Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction,"Large Language Models (LLMs) offer significant potential for clinical symptom
extraction, but their deployment in healthcare settings is constrained by
privacy concerns, computational limitations, and operational costs. This study
investigates the optimization of compact LLMs for cancer toxicity symptom
extraction using a novel iterative refinement approach. We employ a
student-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as
student models and GPT-4o as the teacher, to dynamically select between prompt
refinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies.
Our experiments on 294 clinical notes covering 12 post-radiotherapy toxicity
symptoms demonstrate the effectiveness of this approach. The RAG method proved
most efficient, improving average accuracy scores from 0.32 to 0.73 for
Zephyr-7b-beta and from 0.40 to 0.87 for Phi3-mini-128 during refinement. In
the test set, both models showed an approximate 0.20 increase in accuracy
across symptoms. Notably, this improvement was achieved at a cost 45 times
lower than GPT-4o for Zephyr and 79 times lower for Phi-3. These results
highlight the potential of iterative refinement techniques in enhancing the
capabilities of compact LLMs for clinical applications, offering a balance
between performance, cost-effectiveness, and privacy preservation in healthcare
settings.",2024-08-08,"Reza Khanmohammadi, Ahmed I. Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Bing Luo, Indrin J. Chetty, Tuka Alhanai, Kundan Thind, Mohammad M. Ghassemi",http://arxiv.org/pdf/2408.04775v1,cs.CL
Survey: Transformer-based Models in Data Modality Conversion,"Transformers have made significant strides across various artificial
intelligence domains, including natural language processing, computer vision,
and audio processing. This success has naturally garnered considerable interest
from both academic and industry researchers. Consequently, numerous Transformer
variants (often referred to as X-formers) have been developed for these fields.
However, a thorough and systematic review of these modality-specific
conversions remains lacking. Modality Conversion involves the transformation of
data from one form of representation to another, mimicking the way humans
integrate and interpret sensory information. This paper provides a
comprehensive review of transformer-based models applied to the primary
modalities of text, vision, and speech, discussing their architectures,
conversion methodologies, and applications. By synthesizing the literature on
modality conversion, this survey aims to underline the versatility and
scalability of transformers in advancing AI-driven content generation and
understanding.",2024-08-08,"Elyas Rashno, Amir Eskandari, Aman Anand, Farhana Zulkernine",http://arxiv.org/pdf/2408.04723v1,cs.CL
Arctic-TILT. Business Document Understanding at Sub-Billion Scale,"The vast portion of workloads employing LLMs involves answering questions
grounded on PDF or scan content. We introduce the Arctic-TILT achieving
accuracy on par with models 1000$\times$ its size on these use cases. It can be
fine-tuned and deployed on a single 24GB GPU, lowering operational costs while
processing Visually Rich Documents with up to 400k tokens. The model
establishes state-of-the-art results on seven diverse Document Understanding
benchmarks, as well as provides reliable confidence scores and quick inference,
which are essential for processing files in large-scale or time-sensitive
enterprise environments.",2024-08-08,"Łukasz Borchmann, Michał Pietruszka, Wojciech Jaśkowski, Dawid Jurkiewicz, Piotr Halama, Paweł Józiak, Łukasz Garncarek, Paweł Liskowski, Karolina Szyndler, Andrzej Gretkowski, Julita Ołtusek, Gabriela Nowakowska, Artur Zawłocki, Łukasz Duhr, Paweł Dyda, Michał Turski",http://arxiv.org/pdf/2408.04632v1,cs.CL
LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP,"Standard natural language processing (NLP) pipelines operate on symbolic
representations of language, which typically consist of sequences of discrete
tokens. However, creating an analogous representation for ancient logographic
writing systems is an extremely labor intensive process that requires expert
knowledge. At present, a large portion of logographic data persists in a purely
visual form due to the absence of transcription -- this issue poses a
bottleneck for researchers seeking to apply NLP toolkits to study ancient
logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations
of language offers a potential solution. We introduce LogogramNLP, the first
benchmark enabling NLP analysis of ancient logographic languages, featuring
both transcribed and visual datasets for four writing systems along with
annotations for tasks like classification, translation, and parsing. Our
experiments compare systems that employ recent visual and text encoding
strategies as backbones. The results demonstrate that visual representations
outperform textual representations for some investigated tasks, suggesting that
visual processing pipelines may unlock a large amount of cultural heritage data
of logographic languages for NLP-based analyses.",2024-08-08,"Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor Berg-Kirkpatrick",http://arxiv.org/pdf/2408.04628v1,cs.CL
Transformer Explainer: Interactive Learning of Text-Generative Models,"Transformers have revolutionized machine learning, yet their inner workings
remain opaque to many. We present Transformer Explainer, an interactive
visualization tool designed for non-experts to learn about Transformers through
the GPT-2 model. Our tool helps users understand complex Transformer concepts
by integrating a model overview and enabling smooth transitions across
abstraction levels of mathematical operations and model structures. It runs a
live GPT-2 instance locally in the user's browser, empowering users to
experiment with their own input and observe in real-time how the internal
components and parameters of the Transformer work together to predict the next
tokens. Our tool requires no installation or special hardware, broadening the
public's education access to modern generative AI techniques. Our open-sourced
tool is available at https://poloclub.github.io/transformer-explainer/. A video
demo is available at https://youtu.be/ECR4oAwocjs.",2024-08-08,"Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau",http://arxiv.org/pdf/2408.04619v1,cs.CL
Better Alignment with Instruction Back-and-Forth Translation,"We propose a new method, instruction back-and-forth translation, to construct
high-quality synthetic data grounded in world knowledge for aligning large
language models (LLMs). Given documents from a web corpus, we generate and
curate synthetic instructions using the backtranslation approach proposed by Li
et al.(2023a), and rewrite the responses to improve their quality further based
on the initial documents. Fine-tuning with the resulting (backtranslated
instruction, rewritten response) pairs yields higher win rates on AlpacaEval
than using other common instruction datasets such as Humpback, ShareGPT, Open
Orca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the
responses with an LLM outperforms direct distillation, and the two generated
text distributions exhibit significant distinction in embedding space. Further
analysis shows that our backtranslated instructions are of higher quality than
other sources of synthetic instructions, while our responses are more diverse
and complex than those obtained from distillation. Overall we find that
instruction back-and-forth translation combines the best of both worlds --
making use of the information diversity and quantity found on the web, while
ensuring the quality of the responses which is necessary for effective
alignment.",2024-08-08,"Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason Weston, Luke Zettlemoyer, Xian Li",http://arxiv.org/pdf/2408.04614v2,cs.CL
Code-switching in text and speech reveals information-theoretic audience design,"In this work, we use language modeling to investigate the factors that
influence code-switching. Code-switching occurs when a speaker alternates
between one language variety (the primary language) and another (the secondary
language), and is widely observed in multilingual contexts. Recent work has
shown that code-switching is often correlated with areas of high information
load in the primary language, but it is unclear whether high primary language
load only makes the secondary language relatively easier to produce at
code-switching points (speaker-driven code-switching), or whether
code-switching is additionally used by speakers to signal the need for greater
attention on the part of listeners (audience-driven code-switching). In this
paper, we use bilingual Chinese-English online forum posts and transcripts of
spontaneous Chinese-English speech to replicate prior findings that high
primary language (Chinese) information load is correlated with switches to the
secondary language (English). We then demonstrate that the information load of
the English productions is even higher than that of meaning equivalent Chinese
alternatives, and these are therefore not easier to produce, providing evidence
of audience-driven influences in code-switching at the level of the
communication channel, not just at the sociolinguistic level, in both writing
and speech.",2024-08-08,"Debasmita Bhattacharya, Marten van Schijndel",http://arxiv.org/pdf/2408.04596v1,cs.CL
"Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness","With the increasing demand for practical applications of Large Language
Models (LLMs), many attention-efficient models have been developed to balance
performance and computational cost. However, the adversarial robustness of
these models remains under-explored. In this work, we design a framework to
investigate the trade-off between efficiency, performance, and adversarial
robustness of LLMs and conduct extensive experiments on three prominent models
with varying levels of complexity and efficiency -- Transformer++, Gated Linear
Attention (GLA) Transformer, and MatMul-Free LM -- utilizing the GLUE and
AdvGLUE datasets. The AdvGLUE dataset extends the GLUE dataset with adversarial
samples designed to challenge model robustness. Our results show that while the
GLA Transformer and MatMul-Free LM achieve slightly lower accuracy on GLUE
tasks, they demonstrate higher efficiency and either superior or comparative
robustness on AdvGLUE tasks compared to Transformer++ across different attack
levels. These findings highlight the potential of simplified architectures to
achieve a compelling balance between efficiency, performance, and adversarial
robustness, offering valuable insights for applications where resource
constraints and resilience to adversarial attacks are critical.",2024-08-08,"Xiaojing Fan, Chunliang Tao",http://arxiv.org/pdf/2408.04585v3,cs.CL
SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals,"Explainable Artificial Intelligence (XAI) plays a crucial role in enhancing
the transparency and accountability of AI models, particularly in natural
language processing (NLP) tasks. However, popular XAI methods such as LIME and
SHAP have been found to be unstable and potentially misleading, underscoring
the need for a standardized evaluation approach. This paper introduces SCENE
(Soft Counterfactual Evaluation for Natural language Explainability), a novel
evaluation method that leverages large language models (LLMs) to generate Soft
Counterfactual explanations in a zero-shot manner. By focusing on token-based
substitutions, SCENE creates contextually appropriate and semantically
meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts
Validitysoft and Csoft metrics to assess the effectiveness of model-agnostic
XAI methods in text classification tasks. Applied to CNN, RNN, and Transformer
architectures, SCENE provides valuable insights into the strengths and
limitations of various XAI techniques.",2024-08-08,"Haoran Zheng, Utku Pamuksuz",http://arxiv.org/pdf/2408.04575v2,cs.CL
Learning Fine-Grained Grounded Citations for Attributed Large Language Models,"Despite the impressive performance on information-seeking tasks, large
language models (LLMs) still struggle with hallucinations. Attributed LLMs,
which augment generated text with in-line citations, have shown potential in
mitigating hallucinations and improving verifiability. However, current
approaches suffer from suboptimal citation quality due to their reliance on
in-context learning. Furthermore, the practice of citing only coarse document
identifiers makes it challenging for users to perform fine-grained
verification. In this work, we introduce FRONT, a training framework designed
to teach LLMs to generate Fine-Grained Grounded Citations. By grounding model
outputs in fine-grained supporting quotes, these quotes guide the generation of
grounded and consistent responses, not only improving citation quality but also
facilitating fine-grained verification. Experiments on the ALCE benchmark
demonstrate the efficacy of FRONT in generating superior grounded responses and
highly supportive citations. With LLaMA-2-7B, the framework significantly
outperforms all the baselines, achieving an average of 14.21% improvement in
citation quality across all datasets, even surpassing ChatGPT.",2024-08-08,"Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin",http://arxiv.org/pdf/2408.04568v1,cs.CL
Understanding the Performance and Estimating the Cost of LLM Fine-Tuning,"Due to the cost-prohibitive nature of training Large Language Models (LLMs),
fine-tuning has emerged as an attractive alternative for specializing LLMs for
specific tasks using limited compute resources in a cost-effective manner. In
this paper, we characterize sparse Mixture of Experts (MoE) based LLM
fine-tuning to understand their accuracy and runtime performance on a single
GPU. Our evaluation provides unique insights into the training efficacy of
sparse and dense versions of MoE models, as well as their runtime
characteristics, including maximum batch size, execution time breakdown,
end-to-end throughput, GPU hardware utilization, and load distribution. Our
study identifies the optimization of the MoE layer as crucial for further
improving the performance of LLM fine-tuning. Using our profiling results, we
also develop and validate an analytical model to estimate the cost of LLM
fine-tuning on the cloud. This model, based on parameters of the model and GPU
architecture, estimates LLM throughput and the cost of training, aiding
practitioners in industry and academia to budget the cost of fine-tuning a
specific model.",2024-08-08,"Yuchen Xia, Jiho Kim, Yuhan Chen, Haojie Ye, Souvik Kundu, Cong Hao, Nishil Talati",http://arxiv.org/pdf/2408.04693v1,cs.CL
Conversational Prompt Engineering,"Prompts are how humans communicate with LLMs. Informative prompts are
essential for guiding LLMs to produce the desired output. However, prompt
engineering is often tedious and time-consuming, requiring significant
expertise, limiting its widespread use. We propose Conversational Prompt
Engineering (CPE), a user-friendly tool that helps users create personalized
prompts for their specific tasks. CPE uses a chat model to briefly interact
with users, helping them articulate their output preferences and integrating
these into the prompt. The process includes two main stages: first, the model
uses user-provided unlabeled data to generate data-driven questions and utilize
user responses to shape the initial instruction. Then, the model shares the
outputs generated by the instruction and uses user feedback to further refine
the instruction and the outputs. The final result is a few-shot prompt, where
the outputs approved by the user serve as few-shot examples. A user study on
summarization tasks demonstrates the value of CPE in creating personalized,
high-performing prompts. The results suggest that the zero-shot prompt obtained
is comparable to its - much longer - few-shot counterpart, indicating
significant savings in scenarios involving repetitive tasks with large text
volumes.",2024-08-08,"Liat Ein-Dor, Orith Toledo-Ronen, Artem Spector, Shai Gretz, Lena Dankin, Alon Halfon, Yoav Katz, Noam Slonim",http://arxiv.org/pdf/2408.04560v1,cs.CL
BA-LoRA: Bias-Alleviating Low-Rank Adaptation to Mitigate Catastrophic Inheritance in Large Language Models,"Large language models (LLMs) have demonstrated remarkable proficiency across
various natural language processing (NLP) tasks. However, adapting LLMs to
downstream applications requires computationally intensive and memory-demanding
fine-tuning procedures. To alleviate these burdens, parameter-efficient
fine-tuning (PEFT) techniques have emerged as a promising approach to tailor
LLMs with minimal computational overhead. While PEFT methods offer substantial
advantages, they do not fully address the pervasive issue of bias propagation
from pre-training data. This work introduces Bias-Alleviating Low-Rank
Adaptation (BA-LoRA), a novel PEFT method designed to counteract bias
inheritance. BA-LoRA incorporates three distinct regularization terms: (1) a
consistency regularizer, (2) a diversity regularizer, and (3) a singular value
decomposition regularizer. These regularizers aim to enhance the models'
consistency, diversity, and generalization capabilities during fine-tuning. We
conduct extensive experiments on natural language understanding (NLU) and
natural language generation (NLG) tasks using prominent LLMs such as LLaMA,
Mistral, and Gemma. The results demonstrate that BA-LoRA outperforms LoRA and
its state-of-the-art variants. Moreover, our method effectively mitigates the
adverse effects of pre-training bias, leading to more reliable and robust model
outputs. The code is available at https://github.com/cyp-jlu-ai/BA-LoRA.",2024-08-08,"Yupeng Chang, Yi Chang, Yuan Wu",http://arxiv.org/pdf/2408.04556v4,cs.CL
Molyé: A Corpus-based Approach to Language Contact in Colonial France,"Whether or not several Creole languages which developed during the early
modern period can be considered genetic descendants of European languages has
been the subject of intense debate. This is in large part due to the absence of
evidence of intermediate forms. This work introduces a new open corpus, the
Moly\'e corpus, which combines stereotypical representations of three kinds of
language variation in Europe with early attestations of French-based Creole
languages across a period of 400 years. It is intended to facilitate future
research on the continuity between contact situations in Europe and Creolophone
(former) colonies.",2024-08-08,"Rasul Dent, Juliette Janès, Thibault Clérice, Pedro Ortiz Suarez, Benoît Sagot",http://arxiv.org/pdf/2408.04554v1,cs.CL
MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification,"This paper focuses on detecting propagandistic spans and persuasion
techniques in Arabic text from tweets and news paragraphs. Each entry in the
dataset contains a text sample and corresponding labels that indicate the start
and end positions of propaganda techniques within the text. Tokens falling
within a labeled span were assigned ""B"" (Begin) or ""I"" (Inside), ""O"",
corresponding to the specific propaganda technique. Using attention masks, we
created uniform lengths for each span and assigned BIO tags to each token based
on the provided labels. Then, we used AraBERT-base pre-trained model for Arabic
text tokenization and embeddings with a token classification layer to identify
propaganda techniques. Our training process involves a two-phase fine-tuning
approach. First, we train only the classification layer for a few epochs,
followed by full model fine-tuning, updating all parameters. This methodology
allows the model to adapt to the specific characteristics of the propaganda
detection task while leveraging the knowledge captured by the pre-trained
AraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd
position in the leaderboard of Task 1.",2024-08-08,"Md Rafiul Biswas, Zubair Shah, Wajdi Zaghouani",http://arxiv.org/pdf/2408.04540v1,cs.CL
Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models,"As diverse linguistic communities and users adopt large language models
(LLMs), assessing their safety across languages becomes critical. Despite
ongoing efforts to make LLMs safe, they can still be made to behave unsafely
with jailbreaking, a technique in which models are prompted to act outside
their operational guidelines. Research on LLM safety and jailbreaking, however,
has so far mostly focused on English, limiting our understanding of LLM safety
in other languages. We contribute towards closing this gap by investigating the
effectiveness of many-shot jailbreaking, where models are prompted with unsafe
demonstrations to induce unsafe behaviour, in Italian. To enable our analysis,
we create a new dataset of unsafe Italian question-answer pairs. With this
dataset, we identify clear safety vulnerabilities in four families of
open-weight LLMs. We find that the models exhibit unsafe behaviors even when
prompted with few unsafe demonstrations, and -- more alarmingly -- that this
tendency rapidly escalates with more demonstrations.",2024-08-08,"Fabio Pernisi, Dirk Hovy, Paul Röttger",http://arxiv.org/pdf/2408.04522v1,cs.CL
Articulatory Configurations across Genders and Periods in French Radio and TV archives,"This paper studies changes in articulatory configurations across genders and
periods using an inversion from acoustic to articulatory parameters. From a
diachronic corpus based on French media archives spanning 60 years from 1955 to
2015, automatic transcription and forced alignment allowed extracting the
central frame of each vowel. More than one million frames were obtained from
over a thousand speakers across gender and age categories. Their formants were
used from these vocalic frames to fit the parameters of Maeda's articulatory
model. Evaluations of the quality of these processes are provided. We focus
here on two parameters of Maeda's model linked to total vocal tract length: the
relative position of the larynx (higher for females) and the lips protrusion
(more protruded for males). Implications for voice quality across genders are
discussed. The effect across periods seems gender independent; thus, the
assertion that females lowered their pitch with time is not supported.",2024-08-08,"Benjamin Elie, David Doukhan, Rémi Uro, Lucas Ondel-Yang, Albert Rilliard, Simon Devauchelle",http://arxiv.org/pdf/2408.04519v1,cs.CL
Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate,"Competitive debate is a complex task of computational argumentation. Large
Language Models (LLMs) suffer from hallucinations and lack competitiveness in
this field. To address these challenges, we introduce Agent for Debate
(Agent4Debate), a dynamic multi-agent framework based on LLMs designed to
enhance their capabilities in competitive debate. Drawing inspiration from
human behavior in debate preparation and execution, Agent4Debate employs a
collaborative architecture where four specialized agents, involving Searcher,
Analyzer, Writer, and Reviewer, dynamically interact and cooperate. These
agents work throughout the debate process, covering multiple stages from
initial research and argument formulation to rebuttal and summary. To
comprehensively evaluate framework performance, we construct the Competitive
Debate Arena, comprising 66 carefully selected Chinese debate motions. We
recruit ten experienced human debaters and collect records of 200 debates
involving Agent4Debate, baseline models, and humans. The evaluation employs the
Debatrix automatic scoring system and professional human reviewers based on the
established Debatrix-Elo and Human-Elo ranking. Experimental results indicate
that the state-of-the-art Agent4Debate exhibits capabilities comparable to
those of humans. Furthermore, ablation studies demonstrate the effectiveness of
each component in the agent structure.",2024-08-08,"Yiqun Zhang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song",http://arxiv.org/pdf/2408.04472v2,cs.CL
Crowd Intelligence for Early Misinformation Prediction on Social Media,"Misinformation spreads rapidly on social media, causing serious damage by
influencing public opinion, promoting dangerous behavior, or eroding trust in
reliable sources. It spreads too fast for traditional fact-checking, stressing
the need for predictive methods. We introduce CROWDSHIELD, a crowd
intelligence-based method for early misinformation prediction. We hypothesize
that the crowd's reactions to misinformation reveal its accuracy. Furthermore,
we hinge upon exaggerated assertions/claims and replies with particular
positions/stances on the source post within a conversation thread. We employ
Q-learning to capture the two dimensions -- stances and claims. We utilize deep
Q-learning due to its proficiency in navigating complex decision spaces and
effectively learning network properties. Additionally, we use a
transformer-based encoder to develop a comprehensive understanding of both
content and context. This multifaceted approach helps ensure the model pays
attention to user interaction and stays anchored in the communication's
content. We propose MIST, a manually annotated misinformation detection Twitter
corpus comprising nearly 200 conversation threads with more than 14K replies.
In experiments, CROWDSHIELD outperformed ten baseline systems, achieving an
improvement of ~4% macro-F1 score. We conduct an ablation study and error
analysis to validate our proposed model's performance. The source code and
dataset are available at https://github.com/LCS2-IIITD/CrowdShield.git.",2024-08-08,"Megha Sundriyal, Harshit Choudhary, Tanmoy Chakraborty, Md Shad Akhtar",http://arxiv.org/pdf/2408.04463v1,cs.CL
Synthetic SQL Column Descriptions and Their Impact on Text-to-SQL Performance,"Relational databases often suffer from uninformative descriptors of table
contents, such as ambiguous columns and hard-to-interpret values, impacting
both human users and text-to-SQL models. In this paper, we explore the use of
large language models (LLMs) to automatically generate detailed natural
language descriptions for SQL database columns, aiming to improve text-to-SQL
performance and automate metadata creation. We create a dataset of gold column
descriptions based on the BIRD-Bench benchmark, manually refining its column
descriptions and creating a taxonomy for categorizing column difficulty. We
then evaluate several different LLMs in generating column descriptions across
the columns and different difficulties in the dataset, finding that models
unsurprisingly struggle with columns that exhibit inherent ambiguity,
highlighting the need for manual expert input. We also find that incorporating
such generated column descriptions consistently enhances text-to-SQL model
performance, particularly for larger models like GPT-4o, Qwen2 72B and Mixtral
22Bx8. Notably, Qwen2-generated descriptions, containing by annotators deemed
superfluous information, outperform manually curated gold descriptions,
suggesting that models benefit from more detailed metadata than humans expect.
Future work will investigate the specific features of these high-performing
descriptions and explore other types of metadata, such as numerical reasoning
and synonyms, to further improve text-to-SQL systems. The dataset, annotations
and code will all be made available.",2024-08-08,"Niklas Wretblad, Oskar Holmström, Erik Larsson, Axel Wiksäter, Oscar Söderlund, Hjalmar Öhman, Ture Pontén, Martin Forsberg, Martin Sörme, Fredrik Heintz",http://arxiv.org/pdf/2408.04691v4,cs.CL
AcrosticSleuth: Probabilistic Identification and Ranking of Acrostics in Multilingual Corpora,"For centuries, writers have hidden messages in their texts as acrostics,
where initial letters of consecutive lines or paragraphs form meaningful words
or phrases. Scholars searching for acrostics manually can only focus on a few
authors at a time and often favor qualitative arguments in discussing
intentionally. We aim to put the study of acrostics on firmer statistical
footing by presenting AcrosticSleuth, a first-of-its-kind tool that
automatically identifies acrostics and ranks them by the probability that the
sequence of characters does not occur by chance (and therefore may have been
inserted intentionally). Acrostics are rare, so we formalize the problem as a
binary classification task in the presence of extreme class imbalance. To
evaluate AcrosticSleuth, we present the Acrostic Identification Dataset
(AcrostID), a collection of acrostics from the WikiSource online database.
Despite the class imbalance, AcrosticSleuth achieves F1 scores of 0.39, 0.59,
and 0.66 on French, English, and Russian subdomains of WikiSource,
respectively. We further demonstrate that AcrosticSleuth can identify
previously unknown high-profile instances of wordplay, such as the acrostic
spelling ARSPOETICA (``art of poetry"") by Italian Humanist Albertino Mussato
and English philosopher Thomas Hobbes' signature in the opening paragraphs of
The Elements of Law.",2024-08-08,"Aleksandr Fedchin, Isabel Cooperman, Pramit Chaudhuri, Joseph P. Dexter",http://arxiv.org/pdf/2408.04427v1,cs.CL
Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models,"Human emotions are often not expressed directly, but regulated according to
internal processes and social display rules. For affective computing systems,
an understanding of how users regulate their emotions can be highly useful, for
example to provide feedback in job interview training, or in psychotherapeutic
scenarios. However, at present no method to automatically classify different
emotion regulation strategies in a cross-user scenario exists. At the same
time, recent studies showed that instruction-tuned Large Language Models (LLMs)
can reach impressive performance across a variety of affect recognition tasks
such as categorical emotion recognition or sentiment analysis. While these
results are promising, it remains unclear to what extent the representational
power of LLMs can be utilized in the more subtle task of classifying users'
internal emotion regulation strategy. To close this gap, we make use of the
recently introduced \textsc{Deep} corpus for modeling the social display of the
emotion shame, where each point in time is annotated with one of seven
different emotion regulation classes. We fine-tune Llama2-7B as well as the
recently introduced Gemma model using Low-rank Optimization on prompts
generated from different sources of information on the \textsc{Deep} corpus.
These include verbal and nonverbal behavior, person factors, as well as the
results of an in-depth interview after the interaction. Our results show, that
a fine-tuned Llama2-7B LLM is able to classify the utilized emotion regulation
strategy with high accuracy (0.84) without needing access to data from
post-interaction interviews. This represents a significant improvement over
previous approaches based on Bayesian Networks and highlights the importance of
modeling verbal behavior in emotion regulation.",2024-08-08,"Philipp Müller, Alexander Heimerl, Sayed Muddashir Hossain, Lea Siegel, Jan Alexandersson, Patrick Gebhard, Elisabeth André, Tanja Schneeberger",http://arxiv.org/pdf/2408.04420v1,cs.CL
Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning,"Retrieval-Augmented Language Models (RALMs) have significantly improved
performance in open-domain question answering (QA) by leveraging external
knowledge. However, RALMs still struggle with unanswerable queries, where the
retrieved contexts do not contain the correct answer, and with conflicting
information, where different sources provide contradictory answers due to
imperfect retrieval. This study introduces an in-context learning-based
approach to enhance the reasoning capabilities of RALMs, making them more
robust in imperfect retrieval scenarios. Our method incorporates Machine
Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the
model's capabilities to identify unanswerabilities and conflicts among the
retrieved contexts. Experiments on two open-domain QA datasets show that our
approach increases accuracy in identifying unanswerable and conflicting
scenarios without requiring additional fine-tuning. This work demonstrates that
in-context learning can effectively enhance the robustness of RALMs in
open-domain QA tasks.",2024-08-08,"Seong-Il Park, Seung-Woo Choi, Na-Hyun Kim, Jay-Yoon Lee",http://arxiv.org/pdf/2408.04414v1,cs.CL
Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset,"This paper explores the question of how accurately current large language
models can perform logical reasoning in natural language, with an emphasis on
whether these models exhibit reasoning biases similar to humans. Specifically,
our study focuses on syllogistic reasoning, a form of deductive reasoning
extensively studied in cognitive science as a natural form of human reasoning.
We present a syllogism dataset called NeuBAROCO, which consists of syllogistic
reasoning problems in English and Japanese. This dataset was originally
designed for psychological experiments to assess human reasoning capabilities
using various forms of syllogisms. Our experiments with leading large language
models indicate that these models exhibit reasoning biases similar to humans,
along with other error tendencies. Notably, there is significant room for
improvement in reasoning problems where the relationship between premises and
hypotheses is neither entailment nor contradiction. We also present
experimental results and in-depth analysis using a new Chain-of-Thought
prompting method, which asks LLMs to translate syllogisms into abstract logical
expressions and then explain their reasoning process. Our analysis using this
method suggests that the primary limitations of LLMs lie in the reasoning
process itself rather than the interpretation of syllogisms.",2024-08-08,"Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada",http://arxiv.org/pdf/2408.04403v1,cs.CL
Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation,"Developing questions that are pedagogically sound, relevant, and promote
learning is a challenging and time-consuming task for educators. Modern-day
large language models (LLMs) generate high-quality content across multiple
domains, potentially helping educators to develop high-quality questions.
Automated educational question generation (AEQG) is important in scaling online
education catering to a diverse student population. Past attempts at AEQG have
shown limited abilities to generate questions at higher cognitive levels. In
this study, we examine the ability of five state-of-the-art LLMs of different
sizes to generate diverse and high-quality questions of different cognitive
levels, as defined by Bloom's taxonomy. We use advanced prompting techniques
with varying complexity for AEQG. We conducted expert and LLM-based evaluations
to assess the linguistic and pedagogical relevance and quality of the
questions. Our findings suggest that LLms can generate relevant and
high-quality educational questions of different cognitive levels when prompted
with adequate information, although there is a significant variance in the
performance of the five LLms considered. We also show that automated evaluation
is not on par with human evaluation.",2024-08-08,"Nicy Scaria, Suma Dharani Chenna, Deepak Subramani",http://arxiv.org/pdf/2408.04394v1,cs.CL
Open-domain Implicit Format Control for Large Language Model Generation,"Controlling the format of outputs generated by large language models (LLMs)
is a critical functionality in various applications. Current methods typically
employ constrained decoding with rule-based automata or fine-tuning with
manually crafted format instructions, both of which struggle with open-domain
format requirements. To address this limitation, we introduce a novel framework
for controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.
This study investigates LLMs' capabilities to follow open-domain, one-shot
constraints and replicate the format of the example answers. We observe that
this is a non-trivial problem for current LLMs. We also develop a dataset
collection methodology for supervised fine-tuning that enhances the open-domain
format control of LLMs without degrading output quality, as well as a benchmark
on which we evaluate both the helpfulness and format correctness of LLM
outputs. The resulting datasets, named OIFC-SFT, along with the related code,
will be made publicly available at https://github.com/cofe-ai/OIFC.",2024-08-08,"Yiqun Yao, Wenjia Ma, Xuezhi Fang, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang",http://arxiv.org/pdf/2408.04392v1,cs.CL
Overview of the NLPCC 2024 Shared Task on Chinese Metaphor Generation,"This paper presents the results of the shared task on Chinese metaphor
generation, hosted at the 13th CCF Conference on Natural Language Processing
and Chinese Computing (NLPCC 2024). The goal of this shared task is to generate
Chinese metaphors using machine learning techniques and effectively identifying
basic components of metaphorical sentences. It is divided into two subtasks: 1)
Metaphor Generation, which involves creating a metaphor from a provided tuple
consisting of TENOR, GROUND, and VEHICLE. The goal here is to synthesize a
metaphor that connects the subject (i.e. TENOR) with the object (i.e. VEHICLE),
guided by the concept of the GROUND. 2) Metaphor Components Identification,
which extracts the most fitting TENORs, GROUNDs, and VEHICLEs from a
metaphorical sentence. This component requires the identification of the most
fitting metaphor elements that correspond to the specified grounds. In addition
to overall results, we report on the setup and insights from the metaphor
generation shared task, which attracted a total of 4 participating teams across
both subtasks.",2024-08-08,"Xingwei Qu, Ge Zhang, Siwei Wu, Yizhi Li, Chenghua Lin",http://arxiv.org/pdf/2408.04378v1,cs.CL
Analyzing Consumer Reviews for Understanding Drivers of Hotels Ratings: An Indian Perspective,"In the internet era, almost every business entity is trying to have its
digital footprint in digital media and other social media platforms. For these
entities, word of mouse is also very important. Particularly, this is quite
crucial for the hospitality sector dealing with hotels, restaurants etc.
Consumers do read other consumers reviews before making final decisions. This
is where it becomes very important to understand which aspects are affecting
most in the minds of the consumers while giving their ratings. The current
study focuses on the consumer reviews of Indian hotels to extract aspects
important for final ratings. The study involves gathering data using web
scraping methods, analyzing the texts using Latent Dirichlet Allocation for
topic extraction and sentiment analysis for aspect-specific sentiment mapping.
Finally, it incorporates Random Forest to understand the importance of the
aspects in predicting the final rating of a user.",2024-08-08,"Subhasis Dasgupta, Soumya Roy, Jaydip Sen",http://arxiv.org/pdf/2408.04369v1,cs.CL
Simulating Articulatory Trajectories with Phonological Feature Interpolation,"As a first step towards a complete computational model of speech learning
involving perception-production loops, we investigate the forward mapping
between pseudo-motor commands and articulatory trajectories. Two phonological
feature sets, based respectively on generative and articulatory phonology, are
used to encode a phonetic target sequence. Different interpolation techniques
are compared to generate smooth trajectories in these feature spaces, with a
potential optimisation of the target value and timing to capture
co-articulation effects. We report the Pearson correlation between a linear
projection of the generated trajectories and articulatory data derived from a
multi-speaker dataset of electromagnetic articulography (EMA) recordings. A
correlation of 0.67 is obtained with an extended feature set based on
generative phonology and a linear interpolation technique. We discuss the
implications of our results for our understanding of the dynamics of biological
motion.",2024-08-08,"Angelo Ortiz Tandazo, Thomas Schatz, Thomas Hueber, Emmanuel Dupoux",http://arxiv.org/pdf/2408.04363v1,cs.CL
Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs,"Large language models (LLMs) and large multimodal models (LMMs) have
significantly impacted the AI community, industry, and various economic
sectors. In journalism, integrating AI poses unique challenges and
opportunities, particularly in enhancing the quality and efficiency of news
reporting. This study explores how LLMs and LMMs can assist journalistic
practice by generating contextualised captions for images accompanying news
articles. We conducted experiments using the GoodNews dataset to evaluate the
ability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of
context: entire news articles, or extracted named entities. In addition, we
compared their performance to a two-stage pipeline composed of a captioning
model (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs
(GPT-4 or LLaMA). We assess a diversity of models, and we find that while the
choice of contextualisation model is a significant factor for the two-stage
pipelines, this is not the case in the LMMs, where smaller, open-source models
perform well compared to proprietary, GPT-powered ones. Additionally, we found
that controlling the amount of provided context enhances performance. These
results highlight the limitations of a fully automated approach and underscore
the necessity for an interactive, human-in-the-loop strategy.",2024-08-08,"Aliki Anagnostopoulou, Thiago Gouvea, Daniel Sonntag",http://arxiv.org/pdf/2408.04331v1,cs.CL
Multi-Turn Context Jailbreak Attack on Large Language Models From First Principles,"Large language models (LLMs) have significantly enhanced the performance of
numerous applications, from intelligent conversations to text generation.
However, their inherent security vulnerabilities have become an increasingly
significant challenge, especially with respect to jailbreak attacks. Attackers
can circumvent the security mechanisms of these LLMs, breaching security
constraints and causing harmful outputs. Focusing on multi-turn semantic
jailbreak attacks, we observe that existing methods lack specific
considerations for the role of multiturn dialogues in attack strategies,
leading to semantic deviations during continuous interactions. Therefore, in
this paper, we establish a theoretical foundation for multi-turn attacks by
considering their support in jailbreak attacks, and based on this, propose a
context-based contextual fusion black-box jailbreak attack method, named
Context Fusion Attack (CFA). This method approach involves filtering and
extracting key terms from the target, constructing contextual scenarios around
these terms, dynamically integrating the target into the scenarios, replacing
malicious key terms within the target, and thereby concealing the direct
malicious intent. Through comparisons on various mainstream LLMs and red team
datasets, we have demonstrated CFA's superior success rate, divergence, and
harmfulness compared to other multi-turn attack strategies, particularly
showcasing significant advantages on Llama3 and GPT-4.",2024-08-08,"Xiongtao Sun, Deyue Zhang, Dongdong Yang, Quanchen Zou, Hui Li",http://arxiv.org/pdf/2408.04686v1,cs.CL
Using generative AI to support standardization work -- the case of 3GPP,"Standardization processes build upon consensus between partners, which
depends on their ability to identify points of disagreement and resolving them.
Large standardization organizations, like the 3GPP or ISO, rely on leaders of
work packages who can correctly, and efficiently, identify disagreements,
discuss them and reach a consensus. This task, however, is effort-,
labor-intensive and costly. In this paper, we address the problem of
identifying similarities, dissimilarities and discussion points using large
language models. In a design science research study, we work with one of the
organizations which leads several workgroups in the 3GPP standard. Our goal is
to understand how well the language models can support the standardization
process in becoming more cost-efficient, faster and more reliable. Our results
show that generic models for text summarization correlate well with domain
expert's and delegate's assessments (Pearson correlation between 0.66 and
0.98), but that there is a need for domain-specific models to provide better
discussion materials for the standardization groups.",2024-08-08,"Miroslaw Staron, Jonathan Strom, Albin Karlsson, Wilhelm Meding",http://arxiv.org/pdf/2408.12611v1,cs.CL
HydraFormer: One Encoder For All Subsampling Rates,"In automatic speech recognition, subsampling is essential for tackling
diverse scenarios. However, the inadequacy of a single subsampling rate to
address various real-world situations often necessitates training and deploying
multiple models, consequently increasing associated costs. To address this
issue, we propose HydraFormer, comprising HydraSub, a Conformer-based encoder,
and a BiTransformer-based decoder. HydraSub encompasses multiple branches, each
representing a distinct subsampling rate, allowing for the flexible selection
of any branch during inference based on the specific use case. HydraFormer can
efficiently manage different subsampling rates, significantly reducing training
and deployment expenses. Experiments on AISHELL-1 and LibriSpeech datasets
reveal that HydraFormer effectively adapts to various subsampling rates and
languages while maintaining high recognition performance. Additionally,
HydraFormer showcases exceptional stability, sustaining consistent performance
under various initialization conditions, and exhibits robust transferability by
learning from pretrained single subsampling rate automatic speech recognition
models\footnote{Model code and scripts:
https://github.com/HydraFormer/hydraformer}.",2024-08-08,"Yaoxun Xu, Xingchen Song, Zhiyong Wu, Di Wu, Zhendong Peng, Binbin Zhang",http://arxiv.org/pdf/2408.04325v1,cs.CL
Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP,"The development of monolingual language models for low and mid-resource
languages continues to be hindered by the difficulty in sourcing high-quality
training data. In this study, we present a novel cross-lingual vocabulary
transfer strategy, trans-tokenization, designed to tackle this challenge and
enable more efficient language adaptation. Our approach focuses on adapting a
high-resource monolingual LLM to an unseen target language by initializing the
token embeddings of the target language using a weighted average of
semantically similar token embeddings from the source language. For this, we
leverage a translation resource covering both the source and target languages.
We validate our method with the Tweeties, a series of trans-tokenized LLMs, and
demonstrate their competitive performance on various downstream tasks across a
small but diverse set of languages. Additionally, we introduce Hydra LLMs,
models with multiple swappable language modeling heads and embedding tables,
which further extend the capabilities of our trans-tokenization strategy. By
designing a Hydra LLM based on the multilingual model TowerInstruct, we
developed a state-of-the-art machine translation model for Tatar, in a
zero-shot manner, completely bypassing the need for high-quality parallel data.
This breakthrough is particularly significant for low-resource languages like
Tatar, where high-quality parallel data is hard to come by. By lowering the
data and time requirements for training high-quality models, our
trans-tokenization strategy allows for the development of LLMs for a wider
range of languages, especially those with limited resources. We hope that our
work will inspire further research and collaboration in the field of
cross-lingual vocabulary transfer and contribute to the empowerment of
languages on a global scale.",2024-08-08,"François Remy, Pieter Delobelle, Hayastan Avetisyan, Alfiya Khabibullina, Miryam de Lhoneux, Thomas Demeester",http://arxiv.org/pdf/2408.04303v1,cs.CL
Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments,"Large language models (LLMs) are supposed to acquire unconscious human
knowledge and feelings, such as social common sense and biases, by training
models from large amounts of text. However, it is not clear how much the
sentiments of specific social groups can be captured in various LLMs. In this
study, we focus on social groups defined in terms of nationality, religion, and
race/ethnicity, and validate the extent to which sentiments between social
groups can be captured in and extracted from LLMs. Specifically, we input
questions regarding sentiments from one group to another into LLMs, apply
sentiment analysis to the responses, and compare the results with social
surveys. The validation results using five representative LLMs showed higher
correlations with relatively small p-values for nationalities and religions,
whose number of data points were relatively large. This result indicates that
the LLM responses including the inter-group sentiments align well with actual
social survey results.",2024-08-08,"Kunitomo Tanaka, Ryohei Sasano, Koichi Takeda",http://arxiv.org/pdf/2408.04293v1,cs.CL
EMTeC: A Corpus of Eye Movements on Machine-Generated Texts,"The Eye Movements on Machine-Generated Texts Corpus (EMTeC) is a naturalistic
eye-movements-while-reading corpus of 107 native English speakers reading
machine-generated texts. The texts are generated by three large language models
using five different decoding strategies, and they fall into six different text
type categories. EMTeC entails the eye movement data at all stages of
pre-processing, i.e., the raw coordinate data sampled at 2000 Hz, the fixation
sequences, and the reading measures. It further provides both the original and
a corrected version of the fixation sequences, accounting for vertical
calibration drift. Moreover, the corpus includes the language models' internals
that underlie the generation of the stimulus texts: the transition scores, the
attention scores, and the hidden states. The stimuli are annotated for a range
of linguistic features both at text and at word level. We anticipate EMTeC to
be utilized for a variety of use cases such as, but not restricted to, the
investigation of reading behavior on machine-generated text and the impact of
different decoding strategies; reading behavior on different text types; the
development of new pre-processing, data filtering, and drift correction
algorithms; the cognitive interpretability and enhancement of language models;
and the assessment of the predictive power of surprisal and entropy for human
reading times. The data at all stages of pre-processing, the model internals,
and the code to reproduce the stimulus generation, data pre-processing and
analyses can be accessed via https://github.com/DiLi-Lab/EMTeC/.",2024-08-08,"Lena Sophia Bolliger, Patrick Haller, Isabelle Caroline Rose Cretton, David Robert Reich, Tannon Kew, Lena Ann Jäger",http://arxiv.org/pdf/2408.04289v1,cs.CL
LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection,"The ease of access to large language models (LLMs) has enabled a widespread
of machine-generated texts, and now it is often hard to tell whether a piece of
text was human-written or machine-generated. This raises concerns about
potential misuse, particularly within educational and academic domains. Thus,
it is important to develop practical systems that can automate the process.
Here, we present one such system, LLM-DetectAIve, designed for fine-grained
detection. Unlike most previous work on machine-generated text detection, which
focused on binary classification, LLM-DetectAIve supports four categories: (i)
human-written, (ii) machine-generated, (iii) machine-written, then
machine-humanized, and (iv) human-written, then machine-polished. Category
(iii) aims to detect attempts to obfuscate the fact that a text was
machine-generated, while category (iv) looks for cases where the LLM was used
to polish a human-written text, which is typically acceptable in academic
writing, but not in education. Our experiments show that LLM-DetectAIve can
effectively identify the above four categories, which makes it a potentially
useful tool in education, academia, and other domains.
  LLM-DetectAIve is publicly accessible at
https://github.com/mbzuai-nlp/LLM-DetectAIve. The video describing our system
is available at https://youtu.be/E8eT_bE7k8c.",2024-08-08,"Mervat Abassy, Kareem Elozeiri, Alexander Aziz, Minh Ngoc Ta, Raj Vardhan Tomar, Bimarsha Adhikari, Saad El Dine Ahmed, Yuxia Wang, Osama Mohammed Afzal, Zhuohan Xie, Jonibek Mansurov, Ekaterina Artemova, Vladislav Mikhailov, Rui Xing, Jiahui Geng, Hasan Iqbal, Zain Muhammad Mujahid, Tarek Mahmoud, Akim Tsvigun, Alham Fikri Aji, Artem Shelmanov, Nizar Habash, Iryna Gurevych, Preslav Nakov",http://arxiv.org/pdf/2408.04284v3,cs.CL
LaDiMo: Layer-wise Distillation Inspired MoEfier,"The advent of large language models has revolutionized natural language
processing, but their increasing complexity has led to substantial training
costs, resource demands, and environmental impacts. In response, sparse
Mixture-of-Experts (MoE) models have emerged as a promising alternative to
dense models. Since training MoE models from scratch can be prohibitively
expensive, recent studies have explored leveraging knowledge from pre-trained
non-MoE models. However, existing approaches have limitations, such as
requiring significant hardware resources and data. We propose a novel
algorithm, LaDiMo, which efficiently converts a Transformer-based non-MoE model
into a MoE model with minimal additional training cost. LaDiMo consists of two
stages: layer-wise expert construction and routing policy decision. By
harnessing the concept of Knowledge Distillation, we compress the model and
rapidly recover its performance. Furthermore, we develop an adaptive router
that optimizes inference efficiency by profiling the distribution of routing
weights and determining a layer-wise policy that balances accuracy and latency.
We demonstrate the effectiveness of our method by converting the LLaMA2-7B
model to a MoE model using only 100K tokens, reducing activated parameters by
over 20% while keeping accuracy. Our approach offers a flexible and efficient
solution for building and deploying MoE models.",2024-08-08,"Sungyoon Kim, Youngjun Kim, Kihyo Moon, Minsung Jang",http://arxiv.org/pdf/2408.04278v1,cs.CL
Analysis of Argument Structure Constructions in the Large Language Model BERT,"This study investigates how BERT processes and represents Argument Structure
Constructions (ASCs), extending previous LSTM analyses. Using a dataset of 2000
sentences across four ASC types (transitive, ditransitive, caused-motion,
resultative), we analyzed BERT's token embeddings across 12 layers.
Visualizations with MDS and t-SNE and clustering quantified by Generalized
Discrimination Value (GDV) were used. Feedforward classifiers (probes)
predicted construction categories from embeddings. CLS token embeddings
clustered best in layers 2-4, decreased in intermediate layers, and slightly
increased in final layers. DET and SUBJ embeddings showed consistent clustering
in intermediate layers, VERB embeddings increased in clustering from layer 1 to
12, and OBJ embeddings peaked in layer 10. Probe accuracies indicated low
construction information in layer 1, with over 90 percent accuracy from layer 2
onward, revealing latent construction information beyond GDV clustering. Fisher
Discriminant Ratio (FDR) analysis of attention weights showed OBJ tokens were
crucial for differentiating ASCs, followed by VERB and DET tokens. SUBJ, CLS,
and SEP tokens had insignificant FDR scores. This study highlights BERT's
layered processing of linguistic constructions and its differences from LSTMs.
Future research will compare these findings with neuroimaging data to
understand the neural correlates of ASC processing. This research underscores
neural language models' potential to mirror linguistic processing in the human
brain, offering insights into the computational and neural mechanisms
underlying language understanding.",2024-08-08,"Pegah Ramezani, Achim Schilling, Patrick Krauss",http://arxiv.org/pdf/2408.04270v1,cs.CL
EfficientRAG: Efficient Retriever for Multi-Hop Question Answering,"Retrieval-augmented generation (RAG) methods encounter difficulties when
addressing complex questions like multi-hop queries. While iterative retrieval
methods improve performance by gathering additional information, current
approaches often rely on multiple calls of large language models (LLMs). In
this paper, we introduce EfficientRAG, an efficient retriever for multi-hop
question answering. EfficientRAG iteratively generates new queries without the
need for LLM calls at each iteration and filters out irrelevant information.
Experimental results demonstrate that EfficientRAG surpasses existing RAG
methods on three open-domain multi-hop question-answering datasets.",2024-08-08,"Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu, Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang",http://arxiv.org/pdf/2408.04259v2,cs.CL
Explicating the Implicit: Argument Detection Beyond Sentence Boundaries,"Detecting semantic arguments of a predicate word has been conventionally
modeled as a sentence-level task. The typical reader, however, perfectly
interprets predicate-argument relations in a much wider context than just the
sentence where the predicate was evoked. In this work, we reformulate the
problem of argument detection through textual entailment to capture semantic
relations across sentence boundaries. We propose a method that tests whether
some semantic relation can be inferred from a full passage by first encoding it
into a simple and standalone proposition and then testing for entailment
against the passage. Our method does not require direct supervision, which is
generally absent due to dataset scarcity, but instead builds on existing NLI
and sentence-level SRL resources. Such a method can potentially explicate
pragmatically understood relations into a set of explicit sentences. We
demonstrate it on a recent document-level benchmark, outperforming some
supervised methods and contemporary language models.",2024-08-08,"Paul Roit, Aviv Slobodkin, Eran Hirsch, Arie Cattan, Ayal Klein, Valentina Pyatkin, Ido Dagan",http://arxiv.org/pdf/2408.04246v1,cs.CL
Learning to Rewrite: Generalized LLM-Generated Text Detection,"Large language models (LLMs) present significant risks when used to generate
non-factual content and spread disinformation at scale. Detecting such
LLM-generated content is crucial, yet current detectors often struggle to
generalize in open-world contexts. We introduce Learning2Rewrite, a novel
framework for detecting AI-generated text with exceptional generalization to
unseen domains. Our method leverages the insight that LLMs inherently modify
AI-generated content less than human-written text when tasked with rewriting.
By training LLMs to minimize alterations on AI-generated inputs, we amplify
this disparity, yielding a more distinguishable and generalizable edit distance
across diverse text distributions. Extensive experiments on data from 21
independent domains and four major LLMs (GPT-3.5, GPT-4, Gemini, and Llama-3)
demonstrate that our detector outperforms state-of-the-art detection methods by
up to 23.04% in AUROC for in-distribution tests, 37.26% for out-of-distribution
tests, and 48.66% under adversarial attacks. Our unique training objective
ensures better generalizability compared to directly training for
classification, when leveraging the same amount of parameters. Our findings
suggest that reinforcing LLMs' inherent rewriting tendencies offers a robust
and scalable solution for detecting AI-generated text.",2024-08-08,"Ran Li, Wei Hao, Weiliang Zhao, Junfeng Yang, Chengzhi Mao",http://arxiv.org/pdf/2408.04237v2,cs.CL
"ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities","Recent large language models (LLMs) advancements sparked a growing research
interest in tool assisted LLMs solving real-world challenges, which calls for
comprehensive evaluation of tool-use capabilities. While previous works focused
on either evaluating over stateless web services (RESTful API), based on a
single turn user prompt, or an off-policy dialog trajectory, ToolSandbox
includes stateful tool execution, implicit state dependencies between tools, a
built-in user simulator supporting on-policy conversational evaluation and a
dynamic evaluation strategy for intermediate and final milestones over an
arbitrary trajectory. We show that open source and proprietary models have a
significant performance gap, and complex tasks like State Dependency,
Canonicalization and Insufficient Information defined in ToolSandbox are
challenging even the most capable SOTA LLMs, providing brand-new insights into
tool-use LLM capabilities. ToolSandbox evaluation framework is released at
https://github.com/apple/ToolSandbox",2024-08-08,"Jiarui Lu, Thomas Holleis, Yizhe Zhang, Bernhard Aumayer, Feng Nan, Felix Bai, Shuang Ma, Shen Ma, Mengyu Li, Guoli Yin, Zirui Wang, Ruoming Pang",http://arxiv.org/pdf/2408.04682v2,cs.CL
Mathfish: Evaluating Language Model Math Reasoning via Grounding in Educational Curricula,"To ensure that math curriculum is grade-appropriate and aligns with critical
skills or concepts in accordance with educational standards, pedagogical
experts can spend months carefully reviewing published math problems. Drawing
inspiration from this process, our work presents a novel angle for evaluating
language models' (LMs) mathematical abilities, by investigating whether they
can discern skills and concepts enabled by math content. We contribute two
datasets: one consisting of 385 fine-grained descriptions of K-12 math skills
and concepts, or standards, from Achieve the Core (ATC), and another of 9.9K
math problems labeled with these standards (MathFish). We develop two tasks for
evaluating LMs' abilities to assess math problems: (1) verifying whether a
problem aligns with a given standard, and (2) tagging a problem with all
aligned standards. Working with experienced teachers, we find that LMs struggle
to tag and verify standards linked to problems, and instead predict labels that
are close to ground truth, but differ in subtle ways. We also show that LMs
often generate problems that do not fully align with standards described in
prompts, suggesting the need for careful scrutiny on use cases involving LMs
for generating curricular materials. Finally, we categorize problems in GSM8k
using math standards, allowing us to better understand why some problems are
more difficult to solve for models than others.",2024-08-08,"Li Lucy, Tal August, Rose E. Wang, Luca Soldaini, Courtney Allison, Kyle Lo",http://arxiv.org/pdf/2408.04226v3,cs.CL
Diffusion Guided Language Modeling,"Current language models demonstrate remarkable proficiency in text
generation. However, for many applications it is desirable to control
attributes, such as sentiment, or toxicity, of the generated language --
ideally tailored towards each specific use case and target audience. For
auto-regressive language models, existing guidance methods are prone to
decoding errors that cascade during generation and degrade performance. In
contrast, text diffusion models can easily be guided with, for example, a
simple linear sentiment classifier -- however they do suffer from significantly
higher perplexity than auto-regressive alternatives. In this paper we use a
guided diffusion model to produce a latent proposal that steers an
auto-regressive language model to generate text with desired properties. Our
model inherits the unmatched fluency of the auto-regressive approach and the
plug-and-play flexibility of diffusion. We show that it outperforms previous
plug-and-play guidance methods across a wide range of benchmark data sets.
Further, controlling a new attribute in our framework is reduced to training a
single logistic regression classifier.",2024-08-08,"Justin Lovelace, Varsha Kishore, Yiwei Chen, Kilian Q. Weinberger",http://arxiv.org/pdf/2408.04220v1,cs.CL
Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs,"In recent years, neural machine translation (NMT) has been widely used in
everyday life. However, the current NMT lacks a mechanism to adjust the
difficulty level of translations to match the user's language level.
Additionally, due to the bias in the training data for NMT, translations of
simple source sentences are often produced with complex words. In particular,
this could pose a problem for children, who may not be able to understand the
meaning of the translations correctly. In this study, we propose a method that
replaces words with high Age of Acquisitions (AoA) in translations with simpler
words to match the translations to the user's level. We achieve this by using
large language models (LLMs), providing a triple of a source sentence, a
translation, and a target word to be replaced. We create a benchmark dataset
using back-translation on Simple English Wikipedia. The experimental results
obtained from the dataset show that our method effectively replaces high-AoA
words with lower-AoA words and, moreover, can iteratively replace most of the
high-AoA words while still maintaining high BLEU and COMET scores.",2024-08-08,"Masashi Oshika, Makoto Morishita, Tsutomu Hirao, Ryohei Sasano, Koichi Takeda",http://arxiv.org/pdf/2408.04217v1,cs.CL
Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews,"This study examines the impact of AI on human false memories -- recollections
of events that did not occur or deviate from actual occurrences. It explores
false memory induction through suggestive questioning in Human-AI interactions,
simulating crime witness interviews. Four conditions were tested: control,
survey-based, pre-scripted chatbot, and generative chatbot using a large
language model (LLM). Participants (N=200) watched a crime video, then
interacted with their assigned AI interviewer or survey, answering questions
including five misleading ones. False memories were assessed immediately and
after one week. Results show the generative chatbot condition significantly
increased false memory formation, inducing over 3 times more immediate false
memories than the control and 1.7 times more than the survey method. 36.4% of
users' responses to the generative chatbot were misled through the interaction.
After one week, the number of false memories induced by generative chatbots
remained constant. However, confidence in these false memories remained higher
than the control after one week. Moderating factors were explored: users who
were less familiar with chatbots but more familiar with AI technology, and more
interested in crime investigations, were more susceptible to false memories.
These findings highlight the potential risks of using advanced AI in sensitive
contexts, like police interviews, emphasizing the need for ethical
considerations.",2024-08-08,"Samantha Chan, Pat Pataranutaporn, Aditya Suri, Wazeer Zulfikar, Pattie Maes, Elizabeth F. Loftus",http://arxiv.org/pdf/2408.04681v1,cs.CL
Attention Mechanism and Context Modeling System for Text Mining Machine Translation,"This paper advances a novel architectural schema anchored upon the
Transformer paradigm and innovatively amalgamates the K-means categorization
algorithm to augment the contextual apprehension capabilities of the schema.
The transformer model performs well in machine translation tasks due to its
parallel computing power and multi-head attention mechanism. However, it may
encounter contextual ambiguity or ignore local features when dealing with
highly complex language structures. To circumvent this constraint, this
exposition incorporates the K-Means algorithm, which is used to stratify the
lexis and idioms of the input textual matter, thereby facilitating superior
identification and preservation of the local structure and contextual
intelligence of the language. The advantage of this combination is that K-Means
can automatically discover the topic or concept regions in the text, which may
be directly related to translation quality. Consequently, the schema contrived
herein enlists K-Means as a preparatory phase antecedent to the Transformer and
recalibrates the multi-head attention weights to assist in the discrimination
of lexis and idioms bearing analogous semantics or functionalities. This
ensures the schema accords heightened regard to the contextual intelligence
embodied by these clusters during the training phase, rather than merely
focusing on locational intelligence.",2024-08-08,"Yuwei Zhang, Junming Huang, Sitong Liu, Zexi Chen, Zizheng Li",http://arxiv.org/pdf/2408.04216v3,cs.CL
Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications,"The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.",2024-08-08,"Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver Aalami, Paul Schmiedmayer",http://arxiv.org/pdf/2408.04680v2,cs.CL
MMREC: LLM Based Multi-Modal Recommender System,"The importance of recommender systems is growing rapidly due to the
exponential increase in the volume of content generated daily. This surge in
content presents unique challenges for designing effective recommender systems.
Key among these challenges is the need to effectively leverage the vast amounts
of natural language data and images that represent user preferences. This paper
presents a novel approach to enhancing recommender systems by leveraging Large
Language Models (LLMs) and deep learning techniques. The proposed framework
aims to improve the accuracy and relevance of recommendations by incorporating
multi-modal information processing and by the use of unified latent space
representation. The study explores the potential of LLMs to better understand
and utilize natural language data in recommendation contexts, addressing the
limitations of previous methods. The framework efficiently extracts and
integrates text and image information through LLMs, unifying diverse modalities
in a latent space to simplify the learning process for the ranking model.
Experimental results demonstrate the enhanced discriminative power of the model
when utilizing multi-modal information. This research contributes to the
evolving field of recommender systems by showcasing the potential of LLMs and
multi-modal data integration to create more personalized and contextually
relevant recommendations.",2024-08-08,"Jiahao Tian, Jinman Zhao, Zhenkai Wang, Zhicheng Ding",http://arxiv.org/pdf/2408.04211v1,cs.CL
Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings,"Decoding linguistic information from non-invasive brain signals using EEG has
gained increasing research attention due to its vast applicational potential.
Recently, a number of works have adopted a generative-based framework to decode
electroencephalogram (EEG) signals into sentences by utilizing the power
generative capacity of pretrained large language models (LLMs). However, this
approach has several drawbacks that hinder the further development of
linguistic applications for brain-computer interfaces (BCIs). Specifically, the
ability of the EEG encoder to learn semantic information from EEG data remains
questionable, and the LLM decoder's tendency to generate sentences based on its
training memory can be hard to avoid. These issues necessitate a novel approach
for converting EEG signals into sentences. In this paper, we propose a novel
two-step pipeline that addresses these limitations and enhances the validity of
linguistic EEG decoding research. We first confirm that word-level semantic
information can be learned from EEG data recorded during natural reading by
training a Conformer encoder via a masked contrastive objective for word-level
classification. To achieve sentence decoding results, we employ a training-free
retrieval method to retrieve sentences based on the predictions from the EEG
encoder. Extensive experiments and ablation studies were conducted in this
paper for a comprehensive evaluation of the proposed approach. Visualization of
the top prediction candidates reveals that our model effectively groups EEG
segments into semantic categories with similar meanings, thereby validating its
ability to learn patterns from unspoken EEG recordings. Despite the exploratory
nature of this work, these results suggest that our method holds promise for
providing more reliable solutions for converting EEG signals into text.",2024-08-08,"Jinzhao Zhou, Yiqun Duan, Ziyi Zhao, Yu-Cheng Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin",http://arxiv.org/pdf/2408.04679v1,cs.CL
CREST: Effectively Compacting a Datastore For Retrieval-Based Speculative Decoding,"We present CREST (Compact Retrieval-Based Speculative Decoding), a redesign
of REST that allows it to be effectively ""compacted"". REST is a drafting
technique for speculative decoding based on retrieving exact n-gram matches of
the most recent n tokens generated by the target LLM from a datastore. The key
idea of CREST is to only store a subset of the smallest and most common n-grams
in the datastore with the hope of achieving comparable performance with less
storage space. We found that storing a subset of n-grams both reduces storage
space and improves performance. CREST matches REST's accepted token length with
10.6-13.5x less storage space and achieves a 16.5-17.1% higher acceptance
length than REST using the same storage space on the HumanEval and MT Bench
benchmarks.",2024-08-08,"Sophia Ho, Jinsol Park, Patrick Wang",http://arxiv.org/pdf/2408.04678v1,cs.CL
wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech,"Knowledge graphs (KGs) enhance the performance of large language models
(LLMs) and search engines by providing structured, interconnected data that
improves reasoning and context-awareness. However, KGs only focus on text data,
thereby neglecting other modalities such as speech. In this work, we introduce
wav2graph, the first framework for supervised learning knowledge graph from
speech data. Our pipeline are straightforward: (1) constructing a KG based on
transcribed spoken utterances and a named entity database, (2) converting KG
into embedding vectors, and (3) training graph neural networks (GNNs) for node
classification and link prediction tasks. Through extensive experiments
conducted in inductive and transductive learning contexts using
state-of-the-art GNN models, we provide baseline results and error analysis for
node classification and link prediction tasks on human transcripts and
automatic speech recognition (ASR) transcripts, including evaluations using
both encoder-based and decoder-based node embeddings, as well as monolingual
and multilingual acoustic pre-trained models. All related code, data, and
models are published online.",2024-08-08,"Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy",http://arxiv.org/pdf/2408.04174v1,cs.CL
mbrs: A Library for Minimum Bayes Risk Decoding,"Minimum Bayes risk (MBR) decoding is a decision rule of text generation tasks
that outperforms conventional maximum a posterior (MAP) decoding using beam
search by selecting high-quality outputs based on a utility function rather
than those with high-probability. Typically, it finds the most suitable
hypothesis from the set of hypotheses under the sampled pseudo-references. mbrs
is a library of MBR decoding, which can flexibly combine various metrics,
alternative expectation estimations, and algorithmic variants. It is designed
with a focus on speed measurement and calling count of code blocks,
transparency, reproducibility, and extensibility, which are essential for
researchers and developers. We published our mbrs as an MIT-licensed
open-source project, and the code is available on GitHub.
  GitHub: https://github.com/naist-nlp/mbrs",2024-08-08,"Hiroyuki Deguchi, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2408.04167v2,cs.CL
Semantics or spelling? Probing contextual word embeddings with orthographic noise,"Pretrained language model (PLM) hidden states are frequently employed as
contextual word embeddings (CWE): high-dimensional representations that encode
semantic information given linguistic context. Across many areas of
computational linguistics research, similarity between CWEs is interpreted as
semantic similarity. However, it remains unclear exactly what information is
encoded in PLM hidden states. We investigate this practice by probing PLM
representations using minimal orthographic noise. We expect that if CWEs
primarily encode semantic information, a single character swap in the input
word will not drastically affect the resulting representation,given sufficient
linguistic context. Surprisingly, we find that CWEs generated by popular PLMs
are highly sensitive to noise in input data, and that this sensitivity is
related to subword tokenization: the fewer tokens used to represent a word at
input, the more sensitive its corresponding CWE. This suggests that CWEs
capture information unrelated to word-level meaning and can be manipulated
through trivial modifications of input data. We conclude that these PLM-derived
CWEs may not be reliable semantic proxies, and that caution is warranted when
interpreting representational similarity",2024-08-08,"Jacob A. Matthews, John R. Starr, Marten van Schijndel",http://arxiv.org/pdf/2408.04162v1,cs.CL
UNLEARN Efficient Removal of Knowledge in Large Language Models,"Given the prevalence of large language models (LLMs) and the prohibitive cost
of training these models from scratch, dynamically forgetting specific
knowledge e.g., private or proprietary, without retraining the model has become
an important capability. This paper proposes a novel method to achieve this
objective called UNLEARN. The approach builds upon subspace methods to identify
and specifically target the removal of knowledge without adversely affecting
other knowledge in the LLM. Results demonstrate 96% of targeted knowledge can
be forgotten while maintaining performance on other knowledge within 2.5% of
the original model, significantly outperforming the discriminatory abilities of
the previous state-of-the-art. A dual method called LEARN is also proposed for
targeted knowledge addition. Results show LEARN can match the fine-tuning
accuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar
tasks.",2024-08-08,"Tyler Lizzo, Larry Heck",http://arxiv.org/pdf/2408.04140v1,cs.CL
Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering,"In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.",2024-08-08,"Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin",http://arxiv.org/pdf/2408.04138v1,cs.CL
Incorporating Spatial Awareness in Data-Driven Gesture Generation for Virtual Agents,"This paper focuses on enhancing human-agent communication by integrating
spatial context into virtual agents' non-verbal behaviors, specifically
gestures. Recent advances in co-speech gesture generation have primarily
utilized data-driven methods, which create natural motion but limit the scope
of gestures to those performed in a void. Our work aims to extend these methods
by enabling generative models to incorporate scene information into
speech-driven gesture synthesis. We introduce a novel synthetic gesture dataset
tailored for this purpose. This development represents a critical step toward
creating embodied conversational agents that interact more naturally with their
environment and users.",2024-08-07,"Anna Deichler, Simon Alexanderson, Jonas Beskow",http://arxiv.org/pdf/2408.04127v1,cs.CL
Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology,"Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.",2024-08-07,"Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen",http://arxiv.org/pdf/2408.04121v1,cs.CL
Zero-shot Factual Consistency Evaluation Across Domains,"This work addresses the challenge of factual consistency in text generation
systems. We unify the tasks of Natural Language Inference, Summarization
Evaluation, Factuality Verification and Factual Consistency Evaluation to train
models capable of evaluating the factual consistency of source-target pairs
across diverse domains. We rigorously evaluate these against eight baselines on
a comprehensive benchmark suite comprising 22 datasets that span various tasks,
domains, and document lengths. Results demonstrate that our method achieves
state-of-the-art performance on this heterogeneous benchmark while addressing
efficiency concerns and attaining cross-domain generalization.",2024-08-07,Raunak Agarwal,http://arxiv.org/pdf/2408.04114v1,cs.CL
Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization,"Large language models (LLMs) can help writers build story worlds by
generating world elements, such as factions, characters, and locations.
However, making sense of many generated elements can be overwhelming. Moreover,
if the user wants to precisely control aspects of generated elements that are
difficult to specify verbally, prompting alone may be insufficient. We
introduce Patchview, a customizable LLM-powered system that visually aids
worldbuilding by allowing users to interact with story concepts and elements
through the physical metaphor of magnets and dust. Elements in Patchview are
visually dragged closer to concepts with high relevance, facilitating
sensemaking. The user can also steer the generation with verbally elusive
concepts by indicating the desired position of the element between concepts.
When the user disagrees with the LLM's visualization and generation, they can
correct those by repositioning the element. These corrections can be used to
align the LLM's future behaviors to the user's perception. With a user study,
we show that Patchview supports the sensemaking of world elements and steering
of element generation, facilitating exploration during the worldbuilding
process. Patchview provides insights on how customizable visual representation
can help sensemake, steer, and align generative AI model behaviors with the
user's intentions.",2024-08-07,"John Joon Young Chung, Max Kreminski",http://arxiv.org/pdf/2408.04112v1,cs.CL
Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters,"Our formulation reveals that the reduction across the sequence axis can be
efficiently computed in parallel through a tree reduction. Our algorithm,
called Tree Attention, for parallelizing exact attention computation across
multiple GPUs enables cross-device decoding to be performed asymptotically
faster (up to 8x faster in our experiments) than state-of-the-art approaches
such as Ring Attention, while also requiring significantly less communication
volume and incurring 2x less peak memory. We demonstrate that Tree Attention
speeds up decoding up to 4x on Llama 3.1-8B and can be applied to a variety of
hardware and networking setups such as H100 DGX nodes, AMD MI300x nodes, and
PCIe connected NVIDIA RTX 4090s. Our code is publicly available here:
https://github.com/Zyphra/tree_attention",2024-08-07,"Vasudev Shyam, Jonathan Pilault, Emily Shepperd, Quentin Anthony, Beren Millidge",http://arxiv.org/pdf/2408.04093v4,cs.CL
ACL Ready: RAG Based Assistant for the ACL Checklist,"The ARR Responsible NLP Research checklist website states that the ""checklist
is designed to encourage best practices for responsible research, addressing
issues of research ethics, societal impact and reproducibility."" Answering the
questions is an opportunity for authors to reflect on their work and make sure
any shared scientific assets follow best practices. Ideally, considering the
checklist before submission can favorably impact the writing of a research
paper. However, the checklist is often filled out at the last moment. In this
work, we introduce ACLReady, a retrieval-augmented language model application
that can be used to empower authors to reflect on their work and assist authors
with the ACL checklist. To test the effectiveness of the system, we conducted a
qualitative study with 13 users which shows that 92% of users found the
application useful and easy to use as well as 77% of the users found that the
application provided the information they expected. Our code is publicly
available under the CC BY-NC 4.0 license on GitHub.",2024-08-07,"Michael Galarnyk, Rutwik Routu, Kosha Bheda, Priyanshu Mehta, Agam Shah, Sudheer Chava",http://arxiv.org/pdf/2408.04675v1,cs.CL
StructuredRAG: JSON Response Formatting with Large Language Models,"The ability of Large Language Models (LLMs) to generate structured outputs,
such as JSON, is crucial for their use in Compound AI Systems. However,
evaluating and improving this capability remains challenging. In this work, we
introduce StructuredRAG, a benchmark of six tasks designed to assess LLMs'
proficiency in following response format instructions. We evaluate two
state-of-the-art LLMs, Gemini 1.5 Pro and Llama 3 8B-instruct with 4-bit
quantization using two distinct prompting strategies. We introduce these
prompting strategies as f-String and Follow the Format (FF) prompting. Across
24 experiments, we find an average success rate of 82.55%. We further find a
high variance in performance across tasks, models, and prompting strategies
with success rates ranging from 0 to 100%. We find that Llama 3 8B-instruct
often performs competitively with Gemini 1.5 Pro. We observe that task
complexity significantly influences performance, with tasks involving lists or
composite object outputs proving more challenging. Our findings highlight the
need for further research into improving the reliability and consistency of
structured output generation in LLMs. We have open-sourced our experimental
code and results at github.com/weaviate/structured-rag.",2024-08-07,"Connor Shorten, Charles Pierse, Thomas Benjamin Smith, Erika Cardenas, Akanksha Sharma, John Trengrove, Bob van Luijt",http://arxiv.org/pdf/2408.11061v1,cs.CL
Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?,"Large Language Models (LLMs) can generate text by transferring style
attributes like formality resulting in formal or informal text. However,
instructing LLMs to generate text that when spoken, is more intelligible in an
acoustically difficult environment, is an under-explored topic. We conduct the
first study to evaluate LLMs on a novel task of generating acoustically
intelligible paraphrases for better human speech perception in noise. Our
experiments in English demonstrated that with standard prompting, LLMs struggle
to control the non-textual attribute, i.e., acoustic intelligibility, while
efficiently capturing the desired textual attributes like semantic equivalence.
To remedy this issue, we propose a simple prompting approach,
prompt-and-select, which generates paraphrases by decoupling the desired
textual and non-textual attributes in the text generation pipeline. Our
approach resulted in a 40% relative improvement in human speech perception, by
paraphrasing utterances that are highly distorted in a listening condition with
babble noise at a signal-to-noise ratio (SNR) -5 dB. This study reveals the
limitation of LLMs in capturing non-textual attributes, and our proposed method
showcases the potential of using LLMs for better human speech perception in
noise.",2024-08-07,"Anupama Chingacham, Miaoran Zhang, Vera Demberg, Dietrich Klakow",http://arxiv.org/pdf/2408.04029v1,cs.CL
Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity,"As Large Language Models (LLMs) become increasingly sophisticated and
ubiquitous in natural language processing (NLP) applications, ensuring their
robustness, trustworthiness, and alignment with human values has become a
critical challenge. This paper presents a novel framework for contextual
grounding in textual models, with a particular emphasis on the Context
Representation stage. Our approach aims to enhance the reliability and ethical
alignment of these models through a comprehensive, context-aware methodology.
By explicitly capturing and representing relevant situational, cultural, and
ethical contexts in a machine-readable format, we lay the foundation for
anchoring a model's behavior within these contexts. Our approach leverages
techniques from knowledge representation and reasoning, such as ontologies,
semantic web technologies, and logic-based formalisms. We evaluate our
framework on real-world textual datasets, demonstrating its effectiveness in
improving model performance, fairness, and alignment with human expectations,
while maintaining high accuracy. Furthermore, we discuss the other key
components of the framework, including context-aware encoding, context-aware
learning, interpretability and explainability, and continuous monitoring and
adaptation. This research contributes to the growing body of work on
responsible AI, offering a practical approach to developing more reliable,
trustworthy, and ethically-aligned language models. Our findings have
significant implications for the deployment of LLMs in sensitive domains such
as healthcare, legal systems, and social services, where contextual
understanding is paramount.",2024-08-07,"Wrick Talukdar, Anjanava Biswas",http://arxiv.org/pdf/2408.04023v1,cs.CL
MathBridge: A Large Corpus Dataset for Translating Spoken Mathematical Expressions into $LaTeX$ Formulas for Improved Readability,"Improving the readability of mathematical expressions in text-based document
such as subtitle of mathematical video, is an significant task. To achieve
this, mathematical expressions should be convert to compiled formulas. For
instance, the spoken expression ``x equals minus b plus or minus the square
root of b squared minus four a c, all over two a'' from automatic speech
recognition is more readily comprehensible when displayed as a compiled formula
$x = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$. To convert mathematical spoken
sentences to compiled formulas, two processes are required: spoken sentences
are converted into LaTeX formulas, and LaTeX formulas are converted into
compiled formulas. The latter can be managed by using LaTeX engines. However,
there is no way to do the former effectively. Even if we try to solve this
using language models, there is no paired data between spoken sentences and
LaTeX formulas to train it. In this paper, we introduce MathBridge, the first
extensive dataset for translating mathematical spoken sentences into LaTeX
formulas. MathBridge comprises approximately 23 million LaTeX formulas paired
with the corresponding mathematical spoken sentences. Through comprehensive
evaluations, including fine-tuning with proposed data, we discovered that
MathBridge significantly enhances the capabilities of pretrained language
models for converting to LaTeX formulas from mathematical spoken sentences.
Specifically, for the T5-large model, the sacreBLEU score increased from 4.77
to 46.8, demonstrating substantial enhancement.",2024-08-07,"Kyudan Jung, Sieun Hyeon, Jeong Youn Kwon, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee, Jaeyoung Do",http://arxiv.org/pdf/2408.07081v3,cs.CL
Image-to-LaTeX Converter for Mathematical Formulas and Text,"In this project, we train a vision encoder-decoder model to generate LaTeX
code from images of mathematical formulas and text. Utilizing a diverse
collection of image-to-LaTeX data, we build two models: a base model with a
Swin Transformer encoder and a GPT-2 decoder, trained on machine-generated
images, and a fine-tuned version enhanced with Low-Rank Adaptation (LoRA)
trained on handwritten formulas. We then compare the BLEU performance of our
specialized model on a handwritten test set with other similar models, such as
Pix2Text, TexTeller, and Sumen. Through this project, we contribute open-source
models for converting images to LaTeX and provide from-scratch code for
building these models with distributed training and GPU optimizations.",2024-08-07,"Daniil Gurgurov, Aleksey Morshnev",http://arxiv.org/pdf/2408.04015v1,cs.CL
SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature,"Natural language processing (NLP) has seen significant advancements with the
advent of large language models (LLMs). However, substantial improvements are
still needed for languages other than English, especially for specific domains
like the applications of Mercosur Common Nomenclature (NCM), a Brazilian
Harmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a
foundational Portuguese LLM, as an LLM source to implement the NCM application
processing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)
technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.
This approach retains the chain-of-thought (CoT) methodology for prompt
development in a more concise and streamlined manner, utilizing brief and
focused documents for training. The proposed model demonstrates an efficient
and cost-effective alternative for fine-tuning smaller LLMs, significantly
outperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the
research focuses on NCM applications, the methodology can be easily adapted for
HS applications worldwide.",2024-08-07,"Vinícius Di Oliveira, Yuri Façanha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino",http://arxiv.org/pdf/2408.03936v1,cs.CL
From Words to Worth: Newborn Article Impact Prediction with LLM,"As the academic landscape expands, the challenge of efficiently identifying
impactful newly published articles grows increasingly vital. This paper
introduces a promising approach, leveraging the capabilities of LLMs to predict
the future impact of newborn articles solely based on titles and abstracts.
Moving beyond traditional methods heavily reliant on external information, the
proposed method employs LLM to discern the shared semantic features of highly
impactful papers from a large collection of title-abstract pairs. These
semantic features are further utilized to predict the proposed indicator,
TNCSI_SP, which incorporates favorable normalization properties across value,
field, and time. To facilitate parameter-efficient fine-tuning of the LLM, we
have also meticulously curated a dataset containing over 12,000 entries, each
annotated with titles, abstracts, and their corresponding TNCSI_SP values. The
quantitative results, with an MAE of 0.216 and an NDCG@20 of 0.901, demonstrate
that the proposed approach achieves state-of-the-art performance in predicting
the impact of newborn articles when compared to several promising methods.
Finally, we present a real-world application example for predicting the impact
of newborn journal articles to demonstrate its noteworthy practical value.
Overall, our findings challenge existing paradigms and propose a shift towards
a more content-focused prediction of academic impact, offering new insights for
article impact prediction.",2024-08-07,"Penghai Zhao, Qinghua Xing, Kairan Dou, Jinyu Tian, Ying Tai, Jian Yang, Ming-Ming Cheng, Xiang Li",http://arxiv.org/pdf/2408.03934v2,cs.CL
AutoFAIR : Automatic Data FAIRification via Machine Reading,"The explosive growth of data fuels data-driven research, facilitating
progress across diverse domains. The FAIR principles emerge as a guiding
standard, aiming to enhance the findability, accessibility, interoperability,
and reusability of data. However, current efforts primarily focus on manual
data FAIRification, which can only handle targeted data and lack efficiency. To
address this issue, we propose AutoFAIR, an architecture designed to enhance
data FAIRness automately. Firstly, We align each data and metadata operation
with specific FAIR indicators to guide machine-executable actions. Then, We
utilize Web Reader to automatically extract metadata based on language models,
even in the absence of structured data webpage schemas. Subsequently, FAIR
Alignment is employed to make metadata comply with FAIR principles by ontology
guidance and semantic matching. Finally, by applying AutoFAIR to various data,
especially in the field of mountain hazards, we observe significant
improvements in findability, accessibility, interoperability, and reusability
of data. The FAIRness scores before and after applying AutoFAIR indicate
enhanced data value.",2024-08-07,"Tingyan Ma, Wei Liu, Bin Lu, Xiaoying Gan, Yunqiang Zhu, Luoyi Fu, Chenghu Zhou",http://arxiv.org/pdf/2408.04673v1,cs.CL
Identifying and Mitigating Social Bias Knowledge in Language Models,"Generating fair and accurate predictions plays a pivotal role in deploying
large language models (LLMs) in the real world. However, existing debiasing
methods inevitably generate unfair or incorrect predictions as they are
designed and evaluated to achieve parity across different social groups but
leave aside individual commonsense facts, resulting in modified knowledge that
elicits unreasonable or undesired predictions. In this paper, we first
establish a new bias mitigation benchmark, BiaScope, which systematically
assesses performance by leveraging newly constructed datasets and metrics on
knowledge retention and generalization. Then, we propose a novel debiasing
approach, Fairness Stamp (FAST), which enables fine-grained calibration of
individual social biases. FAST identifies the decisive layer responsible for
storing social biases and then calibrates its outputs by integrating a small
modular network, considering both bias mitigation and knowledge-preserving
demands. Comprehensive experiments demonstrate that FAST surpasses
state-of-the-art baselines with superior debiasing performance while not
compromising the overall model capability for knowledge retention and
downstream predictions. This highlights the potential of fine-grained debiasing
strategies to achieve fairness in LLMs.",2024-08-07,"Ruizhe Chen, Yichen Li, Jianfei Yang, Joey Tianyi Zhou, Jian Wu, Zuozhu Liu",http://arxiv.org/pdf/2408.11843v2,cs.CL
CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases,"Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce CodexGraph, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, CodexGraph enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess CodexGraph using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, CodexGraph demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.",2024-08-07,"Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Fei Wang, Michael Shieh, Wenmeng Zhou",http://arxiv.org/pdf/2408.03910v2,cs.CL
Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models,"Large Language Models (LLMs) have excelled at language understanding and
generating human-level text. However, even with supervised training and human
alignment, these LLMs are susceptible to adversarial attacks where malicious
users can prompt the model to generate undesirable text. LLMs also inherently
encode potential biases that can cause various harmful effects during
interactions. Bias evaluation metrics lack standards as well as consensus and
existing methods often rely on human-generated templates and annotations which
are expensive and labor intensive. In this work, we train models to
automatically create adversarial prompts to elicit biased responses from target
LLMs. We present LLM- based bias evaluation metrics and also analyze several
existing automatic evaluation methods and metrics. We analyze the various
nuances of model responses, identify the strengths and weaknesses of model
families, and assess where evaluation methods fall short. We compare these
metrics to human evaluation and validate that the LLM-as-a-Judge metric aligns
with human judgement on bias in response generation.",2024-08-07,"Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman",http://arxiv.org/pdf/2408.03907v1,cs.CL
Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond,"We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)
dataset comprising the speech counterpart for a portion of the MASSIVE textual
corpus. Speech-MASSIVE covers 12 languages from different families and inherits
from MASSIVE the annotations for the intent prediction and slot-filling tasks.
Our extension is prompted by the scarcity of massively multilingual SLU
datasets and the growing need for versatile speech datasets to assess
foundation models (LLMs, speech encoders) across languages and tasks. We
provide a multimodal, multitask, multilingual dataset and report SLU baselines
using both cascaded and end-to-end architectures in various training scenarios
(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the
suitability of Speech-MASSIVE for benchmarking other tasks such as speech
transcription, language identification, and speech translation. The dataset,
models, and code are publicly available at:
https://github.com/hlt-mt/Speech-MASSIVE",2024-08-07,"Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier",http://arxiv.org/pdf/2408.03900v1,cs.CL
Simplifying Scholarly Abstracts for Accessible Digital Libraries,"Standing at the forefront of knowledge dissemination, digital libraries
curate vast collections of scientific literature. However, these scholarly
writings are often laden with jargon and tailored for domain experts rather
than the general public. As librarians, we strive to offer services to a
diverse audience, including those with lower reading levels. To extend our
services beyond mere access, we propose fine-tuning a language model to rewrite
scholarly abstracts into more comprehensible versions, thereby making scholarly
literature more accessible when requested. We began by introducing a corpus
specifically designed for training models to simplify scholarly abstracts. This
corpus consists of over three thousand pairs of abstracts and significance
statements from diverse disciplines. We then fine-tuned four language models
using this corpus. The outputs from the models were subsequently examined both
quantitatively for accessibility and semantic coherence, and qualitatively for
language quality, faithfulness, and completeness. Our findings show that the
resulting models can improve readability by over three grade levels, while
maintaining fidelity to the original content. Although commercial
state-of-the-art models still hold an edge, our models are much more compact,
can be deployed locally in an affordable manner, and alleviate the privacy
concerns associated with using commercial models. We envision this work as a
step toward more inclusive and accessible libraries, improving our services for
young readers and those without a college degree.",2024-08-07,"Haining Wang, Jason Clark",http://arxiv.org/pdf/2408.03899v1,cs.CL
Personalized Clinical Note Generation from Doctor-Patient Conversations,"In this work, we present a novel technique to improve the quality of draft
clinical notes for physicians. This technique is concentrated on the ability to
model implicit physician conversation styles and note preferences. We also
introduce a novel technique for the enrollment of new physicians when a limited
number of clinical notes paired with conversations are available for that
physician, without the need to re-train a model to support them. We show that
our technique outperforms the baseline model by improving the ROUGE-2 score of
the History of Present Illness section by 13.8%, the Physical Examination
section by 88.6%, and the Assessment & Plan section by 50.8%.",2024-08-07,"Nathan Brake, Thomas Schaaf",http://arxiv.org/pdf/2408.03874v1,cs.CL
Large Language Models for Biomedical Text Simplification: Promising But Not There Yet,"In this system report, we describe the models and methods we used for our
participation in the PLABA2023 task on biomedical abstract simplification, part
of the TAC 2023 tracks. The system outputs we submitted come from the following
three categories: 1) domain fine-tuned T5-like models including Biomedical-T5
and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes
(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we
carried out for this task on BioGPT finetuning. In the official automatic
evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model
LaySciFive ranks 3rd among all 13 evaluated systems. In the official human
evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score
92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It
also produced a high score 91.57 on Fluency in comparison to the highest score
93.53. In the second round of submissions, our team using ChatGPT-prompting
ranks the 2nd in several categories including simplified term accuracy score
92.26 and completeness score 96.58, and a very similar score on faithfulness
score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our
codes, fine-tuned models, prompts, and data splits from the system development
stage will be available at https://github.com/ HECTA-UoM/PLABA-MU",2024-08-07,"Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic",http://arxiv.org/pdf/2408.03871v2,cs.CL
Why transformers are obviously good models of language,"Nobody knows how language works, but many theories abound. Transformers are a
class of neural networks that process language automatically with more success
than alternatives, both those based on neural computations and those that rely
on other (e.g. more symbolic) mechanisms. Here, I highlight direct connections
between the transformer architecture and certain theoretical perspectives on
language. The empirical success of transformers relative to alternative models
provides circumstantial evidence that the linguistic approaches that
transformers embody should be, at least, evaluated with greater scrutiny by the
linguistics community and, at best, considered to be the currently best
available theories.",2024-08-07,Felix Hill,http://arxiv.org/pdf/2408.03855v1,cs.CL
Hate Speech Detection and Classification in Amharic Text with Deep Learning,"Hate speech is a growing problem on social media. It can seriously impact
society, especially in countries like Ethiopia, where it can trigger conflicts
among diverse ethnic and religious groups. While hate speech detection in
resource rich languages are progressing, for low resource languages such as
Amharic are lacking. To address this gap, we develop Amharic hate speech data
and SBi-LSTM deep learning model that can detect and classify text into four
categories of hate speech: racial, religious, gender, and non-hate speech. We
have annotated 5k Amharic social media post and comment data into four
categories. The data is annotated using a custom annotation tool by a total of
100 native Amharic speakers. The model achieves a 94.8 F1-score performance.
Future improvements will include expanding the dataset and develop state-of-the
art models.
  Keywords: Amharic hate speech detection, classification, Amharic dataset,
Deep Learning, SBi-LSTM",2024-08-07,"Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie",http://arxiv.org/pdf/2408.03849v1,cs.CL
WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models,"WalledEval is a comprehensive AI safety testing toolkit designed to evaluate
large language models (LLMs). It accommodates a diverse range of models,
including both open-weight and API-based ones, and features over 35 safety
benchmarks covering areas such as multilingual safety, exaggerated safety, and
prompt injections. The framework supports both LLM and judge benchmarking and
incorporates custom mutators to test safety against various text-style
mutations, such as future tense and paraphrasing. Additionally, WalledEval
introduces WalledGuard, a new, small, and performant content moderation tool,
and two datasets: SGXSTest and HIXSTest, which serve as benchmarks for
assessing the exaggerated safety of LLMs and judges in cultural contexts. We
make WalledEval publicly available at https://github.com/walledai/walledeval.",2024-08-07,"Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria",http://arxiv.org/pdf/2408.03837v3,cs.CL
Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning,"Active Learning (AL) allows models to learn interactively from user feedback.
This paper introduces a counterfactual data augmentation approach to AL,
particularly addressing the selection of datapoints for user querying, a
pivotal concern in enhancing data efficiency. Our approach is inspired by
Variation Theory, a theory of human concept learning that emphasizes the
essential features of a concept by focusing on what stays the same and what
changes. Instead of just querying with existing datapoints, our approach
synthesizes artificial datapoints that highlight potential key similarities and
differences among labels using a neuro-symbolic pipeline combining large
language models (LLMs) and rule-based models. Through an experiment in the
example domain of text classification, we show that our approach achieves
significantly higher performance when there are fewer annotated data. As the
annotated training data gets larger the impact of the generated data starts to
diminish showing its capability to address the cold start problem in AL. This
research sheds light on integrating theories of human learning into the
optimization of AL.",2024-08-07,"Simret Araya Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena L. Glassman, Toby Jia-Jun Li",http://arxiv.org/pdf/2408.03819v1,cs.CL
Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring,"Automated Short Answer Scoring (ASAS) is a critical component in educational
assessment. While traditional ASAS systems relied on rule-based algorithms or
complex deep learning methods, recent advancements in Generative Language
Models (GLMs) offer new opportunities for improvement. This study explores the
application of GLMs to ASAS, leveraging their off-the-shelf capabilities and
performance in various domains. We propose a novel pipeline that combines
vector databases, transformer-based encoders, and GLMs to enhance short answer
scoring accuracy. Our approach stores training responses in a vector database,
retrieves semantically similar responses during inference, and employs a GLM to
analyze these responses and determine appropriate scores. We further optimize
the system through fine-tuned retrieval processes and prompt engineering.
Evaluation on the SemEval 2013 dataset demonstrates a significant improvement
on the SCIENTSBANK 3-way and 2-way tasks compared to existing methods,
highlighting the potential of GLMs in advancing ASAS technology.",2024-08-07,"Zifan Wang, Christopher Ormerod",http://arxiv.org/pdf/2408.03811v1,cs.CL
Prompt and Prejudice,"This paper investigates the impact of using first names in Large Language
Models (LLMs) and Vision Language Models (VLMs), particularly when prompted
with ethical decision-making tasks. We propose an approach that appends first
names to ethically annotated text scenarios to reveal demographic biases in
model outputs. Our study involves a curated list of more than 300 names
representing diverse genders and ethnic backgrounds, tested across thousands of
moral scenarios. Following the auditing methodologies from social sciences we
propose a detailed analysis involving popular LLMs/VLMs to contribute to the
field of responsible AI by emphasizing the importance of recognizing and
mitigating biases in these systems. Furthermore, we introduce a novel
benchmark, the Pratical Scenarios Benchmark (PSB), designed to assess the
presence of biases involving gender or demographic prejudices in everyday
decision-making scenarios as well as practical scenarios where an LLM might be
used to make sensible decisions (e.g., granting mortgages or insurances). This
benchmark allows for a comprehensive comparison of model behaviors across
different demographic categories, highlighting the risks and biases that may
arise in practical applications of LLMs and VLMs.",2024-08-07,"Lorenzo Berlincioni, Luca Cultrera, Federico Becattini, Marco Bertini, Alberto Del Bimbo",http://arxiv.org/pdf/2408.04671v1,cs.CL
'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization,"This paper presents our participation under the team name `Finance Wizard' in
the FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. It
documents our pipeline approach of fine-tuning a foundation model into a
task-specific model for Financial Text Summarization. It involves (1) adapting
Llama3 8B, a foundation model, to the Finance domain via continued
pre-training, (2) multi-task instruction-tuning to further equip the model with
more finance-related capabilities, (3) finally fine-tuning the model into a
task-specific `expert'. Our model, FinLlama3\_sum, yielded commendable results,
securing the third position in its category with a ROUGE-1 score of 0.521.",2024-08-07,"Meisin Lee, Soon Lay-Ki",http://arxiv.org/pdf/2408.03762v1,cs.CL
Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks,"Uncertainty quantification enables users to assess the reliability of
responses generated by large language models (LLMs). We present a novel
Question Rephrasing technique to evaluate the input uncertainty of LLMs, which
refers to the uncertainty arising from equivalent variations of the inputs
provided to LLMs. This technique is integrated with sampling methods that
measure the output uncertainty of LLMs, thereby offering a more comprehensive
uncertainty assessment. We validated our approach on property prediction and
reaction prediction for molecular chemistry tasks.",2024-08-07,"Zizhang Chen, Pengyu Hong, Sandeep Madireddy",http://arxiv.org/pdf/2408.03732v1,cs.CL
Could ChatGPT get an Engineering Degree? Evaluating Higher Education Vulnerability to AI Assistants,"AI assistants are being increasingly used by students enrolled in higher
education institutions. While these tools provide opportunities for improved
teaching and education, they also pose significant challenges for assessment
and learning outcomes. We conceptualize these challenges through the lens of
vulnerability, the potential for university assessments and learning outcomes
to be impacted by student use of generative AI. We investigate the potential
scale of this vulnerability by measuring the degree to which AI assistants can
complete assessment questions in standard university-level STEM courses.
Specifically, we compile a novel dataset of textual assessment questions from
50 courses at EPFL and evaluate whether two AI assistants, GPT-3.5 and GPT-4
can adequately answer these questions. We use eight prompting strategies to
produce responses and find that GPT-4 answers an average of 65.8% of questions
correctly, and can even produce the correct answer across at least one
prompting strategy for 85.1% of questions. When grouping courses in our dataset
by degree program, these systems already pass non-project assessments of large
numbers of core courses in various degree programs, posing risks to higher
education accreditation that will be amplified as these models improve. Our
results call for revising program-level assessment design in higher education
in light of advances in generative AI.",2024-08-07,"Beatriz Borges, Negar Foroutan, Deniz Bayazit, Anna Sotnikova, Syrielle Montariol, Tanya Nazaretzky, Mohammadreza Banaei, Alireza Sakhaeirad, Philippe Servant, Seyed Parsa Neshaei, Jibril Frej, Angelika Romanou, Gail Weiss, Sepideh Mamooler, Zeming Chen, Simin Fan, Silin Gao, Mete Ismayilzada, Debjit Paul, Alexandre Schöpfer, Andrej Janchevski, Anja Tiede, Clarence Linden, Emanuele Troiani, Francesco Salvi, Freya Behrens, Giacomo Orsi, Giovanni Piccioli, Hadrien Sevel, Louis Coulon, Manuela Pineros-Rodriguez, Marin Bonnassies, Pierre Hellich, Puck van Gerwen, Sankalp Gambhir, Solal Pirelli, Thomas Blanchard, Timothée Callens, Toni Abi Aoun, Yannick Calvino Alonso, Yuri Cho, Alberto Chiappa, Antonio Sclocchi, Étienne Bruno, Florian Hofhammer, Gabriel Pescia, Geovani Rizk, Leello Dadi, Lucas Stoffl, Manoel Horta Ribeiro, Matthieu Bovel, Yueyang Pan, Aleksandra Radenovic, Alexandre Alahi, Alexander Mathis, Anne-Florence Bitbol, Boi Faltings, Cécile Hébert, Devis Tuia, François Maréchal, George Candea, Giuseppe Carleo, Jean-Cédric Chappelier, Nicolas Flammarion, Jean-Marie Fürbringer, Jean-Philippe Pellet, Karl Aberer, Lenka Zdeborová, Marcel Salathé, Martin Jaggi, Martin Rajman, Mathias Payer, Matthieu Wyart, Michael Gastpar, Michele Ceriotti, Ola Svensson, Olivier Lévêque, Paolo Ienne, Rachid Guerraoui, Robert West, Sanidhya Kashyap, Valerio Piazza, Viesturs Simanis, Viktor Kuncak, Volkan Cevher, Philippe Schwaller, Sacha Friedli, Patrick Jermann, Tanja Käser, Antoine Bosselut",http://arxiv.org/pdf/2408.11841v2,cs.CL
Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction,"A common approach for sequence tagging tasks based on contextual word
representations is to train a machine learning classifier directly on these
embedding vectors. This approach has two shortcomings. First, such methods
consider single input sequences in isolation and are unable to put an
individual embedding vector in relation to vectors outside the current local
context of use. Second, the high performance of these models relies on
fine-tuning the embedding model in conjunction with the classifier, which may
not always be feasible due to the size or inaccessibility of the underlying
feature-generation model. It is thus desirable, given a collection of embedding
vectors of a corpus, i.e., a datastore, to find features of each vector that
describe its relation to other, similar vectors in the datastore. With this in
mind, we introduce complexity measures of the local topology of the latent
space of a contextual language model with respect to a given datastore. The
effectiveness of our features is demonstrated through their application to
dialogue term extraction. Our work continues a line of research that explores
the manifold hypothesis for word embeddings, demonstrating that local structure
in the space carved out by word embeddings can be exploited to infer semantic
properties.",2024-08-07,"Benjamin Matthias Ruppik, Michael Heck, Carel van Niekerk, Renato Vukovic, Hsien-chin Lin, Shutong Feng, Marcus Zibrowius, Milica Gašić",http://arxiv.org/pdf/2408.03706v1,cs.CL
NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time,"Large Language Models (LLMs) have ignited an innovative surge of AI
applications, marking a new era of exciting possibilities equipped with
extended context windows. However, hosting these models is cost-prohibitive
mainly due to the extensive memory consumption of KV Cache involving
long-context modeling. Despite several works proposing to evict unnecessary
tokens from the KV Cache, most of them rely on the biased local statistics of
accumulated attention scores and report performance using unconvincing metric
like perplexity on inadequate short-text evaluation. In this paper, we propose
NACL, a general framework for long-context KV cache eviction that achieves more
optimal and efficient eviction in a single operation during the encoding phase.
Due to NACL's efficiency, we combine more accurate attention score statistics
in PROXY TOKENS EVICTION with the diversified random eviction strategy of
RANDOM EVICTION, aiming to alleviate the issue of attention bias and enhance
the robustness in maintaining pivotal tokens for long-context modeling tasks.
Notably, our method significantly improves the performance on short- and
long-text tasks by 80% and 76% respectively, reducing KV Cache by up to 50%
with over 95% performance maintenance. The code is available at
https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL.",2024-08-07,"Yilong Chen, Guoxia Wang, Junyuan Shang, Shiyao Cui, Zhenyu Zhang, Tingwen Liu, Shuohuan Wang, Yu Sun, Dianhai Yu, Hua Wu",http://arxiv.org/pdf/2408.03675v2,cs.CL
mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search,"Named Entity Recognition (NER) is a task in Natural Language Processing (NLP)
that aims to identify and classify entities in text into predefined categories.
However, when applied to Arabic data, NER encounters unique challenges stemming
from the language's rich morphological inflections, absence of capitalization
cues, and spelling variants, where a single word can comprise multiple
morphemes. In this paper, we introduce Arabic KNN-NER, our submission to the
Wojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the
shared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained
flat-entity recognition for Arabic text, where we identify a single main entity
and possibly zero or multiple sub-entities for each word. Arabic KNN-NER
augments the probability distribution of a fine-tuned model with another label
probability distribution derived from performing a KNN search over the cached
training data. Our submission achieved 91% on the test set on the WojoodFine
dataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.",2024-08-07,"Ahmed Abdou, Tasneem Mohsen",http://arxiv.org/pdf/2408.03652v1,cs.CL
CARE: A Clue-guided Assistant for CSRs to Read User Manuals,"It is time-saving to build a reading assistant for customer service
representations (CSRs) when reading user manuals, especially information-rich
ones. Current solutions don't fit the online custom service scenarios well due
to the lack of attention to user questions and possible responses. Hence, we
propose to develop a time-saving and careful reading assistant for CSRs, named
CARE. It can help the CSRs quickly find proper responses from the user manuals
via explicit clue chains. Specifically, each of the clue chains is formed by
inferring over the user manuals, starting from the question clue aligned with
the user question and ending at a possible response. To overcome the shortage
of supervised data, we adopt the self-supervised strategy for model learning.
The offline experiment shows that CARE is efficient in automatically inferring
accurate responses from the user manual. The online experiment further
demonstrates the superiority of CARE to reduce CSRs' reading burden and keep
high service quality, in particular with >35% decrease in time spent and
keeping a >0.75 ICC score.",2024-08-07,"Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei",http://arxiv.org/pdf/2408.03633v3,cs.CL
Large Language Model as a Catalyst: A Paradigm Shift in Base Station Siting Optimization,"Traditional base station siting (BSS) methods rely heavily on drive testing
and user feedback, which are laborious and require extensive expertise in
communication, networking, and optimization. As large language models (LLMs)
and their associated technologies advance, particularly in the realms of prompt
engineering and agent engineering, network optimization will witness a
revolutionary approach. This approach entails the strategic use of well-crafted
prompts to infuse human experience and knowledge into these sophisticated LLMs,
and the deployment of autonomous agents as a communication bridge to seamlessly
connect the machine language based LLMs with human users using natural
language. Furthermore, our proposed framework incorporates retrieval-augmented
generation (RAG) to enhance the system's ability to acquire domain-specific
knowledge and generate solutions, thereby enabling the customization and
optimization of the BSS process. This integration represents the future
paradigm of artificial intelligence (AI) as a service and AI for more ease.
This research first develops a novel LLM-empowered BSS optimization framework,
and heuristically proposes three different potential implementations: the
strategies based on Prompt-optimized LLM (PoL), LLM-empowered autonomous BSS
agent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa).
Through evaluation on real-world data, the experiments demonstrate that
prompt-assisted LLMs and LLM-based agents can generate more efficient and
reliable network deployments, noticeably enhancing the efficiency of BSS
optimization and reducing trivial manual participation.",2024-08-07,"Yanhu Wang, Muhammad Muzammil Afzal, Zhengyang Li, Jie Zhou, Chenyuan Feng, Shuaishuai Guo, Tony Q. S. Quek",http://arxiv.org/pdf/2408.03631v2,cs.CL
PAGED: A Benchmark for Procedural Graphs Extraction from Documents,"Automatic extraction of procedural graphs from documents creates a low-cost
way for users to easily understand a complex procedure by skimming visual
graphs. Despite the progress in recent studies, it remains unanswered: whether
the existing studies have well solved this task (Q1) and whether the emerging
large language models (LLMs) can bring new opportunities to this task (Q2). To
this end, we propose a new benchmark PAGED, equipped with a large high-quality
dataset and standard evaluations. It investigates five state-of-the-art
baselines, revealing that they fail to extract optimal procedural graphs well
because of their heavy reliance on hand-written rules and limited available
data. We further involve three advanced LLMs in PAGED and enhance them with a
novel self-refine strategy. The results point out the advantages of LLMs in
identifying textual elements and their gaps in building logical structures. We
hope PAGED can serve as a major landmark for automatic procedural graph
extraction and the investigations in PAGED can offer insights into the research
on logic reasoning among non-sequential elements.",2024-08-07,"Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei",http://arxiv.org/pdf/2408.03630v2,cs.CL
Improving the quality of Persian clinical text with a novel spelling correction system,"Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.",2024-08-07,"Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti",http://arxiv.org/pdf/2408.03622v1,cs.CL
A Logical Fallacy-Informed Framework for Argument Generation,"Despite the remarkable performance of Large Language Models (LLMs) in natural
language processing tasks, they still struggle with generating logically sound
arguments, resulting in potential risks such as spreading misinformation. To
address this issue, we introduce FIPO, a fallacy-informed framework that
leverages preference optimization methods to steer LLMs toward logically sound
arguments. FIPO includes a classification loss, to capture the fine-grained
information on fallacy types. Our results on argumentation datasets show that
our method reduces the fallacy errors by up to 17.5%. Furthermore, our human
evaluation results indicate that the quality of the generated arguments by our
method significantly outperforms the fine-tuned baselines, as well as other
preference optimization methods, such as DPO. These findings highlight the
importance of ensuring models are aware of logical fallacies for effective
argument generation. Our code is available at
github.com/lucamouchel/Logical-Fallacies.",2024-08-07,"Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings",http://arxiv.org/pdf/2408.03618v4,cs.CL
Is Child-Directed Speech Effective Training Data for Language Models?,"While high-performing language models are typically trained on hundreds of
billions of words, human children become fluent language users with a much
smaller amount of data. What are the features of the data they receive, and how
do these features support language modeling objectives? To investigate this
question, we train GPT-2 and RoBERTa models on 29M words of English
child-directed speech and a new matched, synthetic dataset (TinyDialogues),
comparing to OpenSubtitles, Wikipedia, and a heterogeneous blend of datasets
from the BabyLM challenge. We evaluate the syntactic and semantic knowledge of
these models using developmentally-inspired evaluations. Through pretraining
experiments, we test whether the global developmental ordering or the local
discourse ordering of children's training data supports high performance
relative to other datasets. The local properties of the data affect model
results, but surprisingly, global properties do not. Further, child language
input is not uniquely valuable for training language models. These findings
support the hypothesis that, rather than proceeding from better data, the
child's learning algorithm is substantially more data-efficient than current
language modeling techniques.",2024-08-07,"Steven Y. Feng, Noah D. Goodman, Michael C. Frank",http://arxiv.org/pdf/2408.03617v2,cs.CL
Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks,"Building a general-purpose agent is a long-standing vision in the field of
artificial intelligence. Existing agents have made remarkable progress in many
domains, yet they still struggle to complete long-horizon tasks in an open
world. We attribute this to the lack of necessary world knowledge and
multimodal experience that can guide agents through a variety of long-horizon
tasks. In this paper, we propose a Hybrid Multimodal Memory module to address
the above challenges. It 1) transforms knowledge into Hierarchical Directed
Knowledge Graph that allows agents to explicitly represent and learn world
knowledge, and 2) summarises historical information into Abstracted Multimodal
Experience Pool that provide agents with rich references for in-context
learning. On top of the Hybrid Multimodal Memory module, a multimodal agent,
Optimus-1, is constructed with dedicated Knowledge-guided Planner and
Experience-Driven Reflector, contributing to a better planning and reflection
in the face of long-horizon tasks in Minecraft. Extensive experimental results
show that Optimus-1 significantly outperforms all existing agents on
challenging long-horizon task benchmarks, and exhibits near human-level
performance on many tasks. In addition, we introduce various Multimodal Large
Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show
that Optimus-1 exhibits strong generalization with the help of the Hybrid
Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.",2024-08-07,"Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie",http://arxiv.org/pdf/2408.03615v2,cs.CL
EnJa: Ensemble Jailbreak on Large Language Models,"As Large Language Models (LLMs) are increasingly being deployed in
safety-critical applications, their vulnerability to potential jailbreaks --
malicious prompts that can disable the safety mechanism of LLMs -- has
attracted growing research attention. While alignment methods have been
proposed to protect LLMs from jailbreaks, many have found that aligned LLMs can
still be jailbroken by carefully crafted malicious prompts, producing content
that violates policy regulations. Existing jailbreak attacks on LLMs can be
categorized into prompt-level methods which make up stories/logic to circumvent
safety alignment and token-level attack methods which leverage gradient methods
to find adversarial tokens. In this work, we introduce the concept of Ensemble
Jailbreak and explore methods that can integrate prompt-level and token-level
jailbreak into a more powerful hybrid jailbreak attack. Specifically, we
propose a novel EnJa attack to hide harmful instructions using prompt-level
jailbreak, boost the attack success rate using a gradient-based attack, and
connect the two types of jailbreak attacks via a template-based connector. We
evaluate the effectiveness of EnJa on several aligned models and show that it
achieves a state-of-the-art attack success rate with fewer queries and is much
stronger than any individual jailbreak.",2024-08-07,"Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang",http://arxiv.org/pdf/2408.03603v1,cs.CL
Teach CLIP to Develop a Number Sense for Ordinal Regression,"Ordinal regression is a fundamental problem within the field of computer
vision, with customised well-trained models on specific tasks. While
pre-trained vision-language models (VLMs) have exhibited impressive performance
on various vision tasks, their potential for ordinal regression has received
less exploration. In this study, we first investigate CLIP's potential for
ordinal regression, from which we expect the model could generalise to
different ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP
fails on this task, since current VLMs have a well-documented limitation of
encapsulating compositional concepts such as number sense. We propose a simple
yet effective method called NumCLIP to improve the quantitative understanding
of VLMs. We disassemble the exact image to number-specific text matching
problem into coarse classification and fine prediction stages. We discretize
and phrase each numerical bin with common language concept to better leverage
the available pre-trained alignment in CLIP. To consider the inherent
continuous property of ordinal regression, we propose a novel fine-grained
cross-modal ranking-based regularisation loss specifically designed to keep
both semantic and ordinal alignment in CLIP's feature space. Experimental
results on three general ordinal regression tasks demonstrate the effectiveness
of NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating
and image aesthetics assessment task, respectively. Code is publicly available
at https://github.com/xmed-lab/NumCLIP.",2024-08-07,"Yao Du, Qiang Zhai, Weihang Dai, Xiaomeng Li",http://arxiv.org/pdf/2408.03574v1,cs.CL
Active Testing of Large Language Model via Multi-Stage Sampling,"Performance evaluation plays a crucial role in the development life cycle of
large language models (LLMs). It estimates the model's capability, elucidates
behavior characteristics, and facilitates the identification of potential
issues and limitations, thereby guiding further improvement. Given that LLMs'
diverse task-handling abilities stem from large volumes of training data, a
comprehensive evaluation also necessitates abundant, well-annotated, and
representative test data to assess LLM performance across various downstream
tasks. However, the demand for high-quality test data often entails substantial
time, computational resources, and manual efforts, sometimes causing the
evaluation to be inefficient or impractical. To address these challenges,
researchers propose active testing, which estimates the overall performance by
selecting a subset of test data. Nevertheless, the existing active testing
methods tend to be inefficient, even inapplicable, given the unique new
challenges of LLMs (e.g., diverse task types, increased model complexity, and
unavailability of training data). To mitigate such limitations and expedite the
development cycle of LLMs, in this work, we introduce AcTracer, an active
testing framework tailored for LLMs that strategically selects a small subset
of test data to achieve a nearly optimal performance estimation for LLMs.
AcTracer utilizes both internal and external information from LLMs to guide the
test sampling process, reducing variance through a multi-stage pool-based
active selection. Our experiment results demonstrate that AcTracer achieves
state-of-the-art performance compared to existing methods across various tasks,
with up to 38.83% improvement over previous SOTA.",2024-08-07,"Yuheng Huang, Jiayang Song, Qiang Hu, Felix Juefei-Xu, Lei Ma",http://arxiv.org/pdf/2408.03573v1,cs.CL
Unlocking Exocentric Video-Language Data for Egocentric Video Representation Learning,"We present EMBED (Egocentric Models Built with Exocentric Data), a method
designed to transform exocentric video-language data for egocentric video
representation learning. Large-scale exocentric data covers diverse activities
with significant potential for egocentric learning, but inherent disparities
between egocentric and exocentric data pose challenges in utilizing one view
for the other seamlessly. Egocentric videos predominantly feature close-up
hand-object interactions, whereas exocentric videos offer a broader perspective
on human activities. Additionally, narratives in egocentric datasets are
typically more action-centric and closely linked with the visual content, in
contrast to the narrative styles found in exocentric datasets. To address these
challenges, we employ a data transformation framework to adapt exocentric data
for egocentric training, focusing on identifying specific video clips that
emphasize hand-object interactions and transforming narration styles to align
with egocentric perspectives. By applying both vision and language style
transfer, our framework creates a new egocentric dataset derived from
exocentric video-language data. Through extensive evaluations, we demonstrate
the effectiveness of EMBED, achieving state-of-the-art results across various
egocentric downstream tasks, including an absolute improvement of 4.7% on the
Epic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification
benchmarks in zero-shot settings. Furthermore, EMBED enables egocentric
video-language models to perform competitively in exocentric tasks. Finally, we
showcase EMBED's application across various exocentric datasets, exhibiting
strong generalization capabilities when applied to different exocentric
datasets.",2024-08-07,"Zi-Yi Dou, Xitong Yang, Tushar Nagarajan, Huiyu Wang, Jing Huang, Nanyun Peng, Kris Kitani, Fu-Jen Chu",http://arxiv.org/pdf/2408.03567v1,cs.CL
A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case,"This research compares large language model (LLM) fine-tuning methods,
including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning
(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally
compared LLM evaluation methods including End to End (E2E) benchmark method of
""Golden Answers"", traditional natural language processing (NLP) metrics, RAG
Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,
using the travel chatbot use case. The travel dataset was sourced from the the
Reddit API by requesting posts from travel-related subreddits to get
travel-related conversation prompts and personalized travel experiences, and
augmented for each fine-tuning method. We used two pretrained LLMs utilized for
fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to
the two pretrained models. The inferences from these models are extensively
evaluated against the aforementioned metrics. The best model according to human
evaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a
Reinforcement Learning from Human Feedback (RLHF) training pipeline, and
ultimately was evaluated as the best model. Our main findings are that: 1)
quantitative and Ragas metrics do not align with human evaluation, 2) Open AI
GPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep
humans in the loop for evaluation because, 4) traditional NLP metrics
insufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms
QLoRA, but still needs postprocessing, 7) RLHF improves model performance
significantly. Next steps include improving data quality, increasing data
quantity, exploring RAG methods, and focusing data collection on a specific
city, which would improve data quality by narrowing the focus, while creating a
useful product.",2024-08-07,"Sonia Meyer, Shreya Singh, Bertha Tam, Christopher Ton, Angel Ren",http://arxiv.org/pdf/2408.03562v1,cs.CL
Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection,"We explore visual prompt injection (VPI) that maliciously exploits the
ability of large vision-language models (LVLMs) to follow instructions drawn
onto the input image. We propose a new VPI method, ""goal hijacking via visual
prompt injection"" (GHVPI), that swaps the execution task of LVLMs from an
original task to an alternative task designated by an attacker. The
quantitative analysis indicates that GPT-4V is vulnerable to the GHVPI and
demonstrates a notable attack success rate of 15.8%, which is an unignorable
security risk. Our analysis also shows that successful GHVPI requires high
character recognition capability and instruction-following ability in LVLMs.",2024-08-07,"Subaru Kimura, Ryota Tanaka, Shumpei Miyawaki, Jun Suzuki, Keisuke Sakaguchi",http://arxiv.org/pdf/2408.03554v1,cs.CL
NatLan: Native Language Prompting Facilitates Knowledge Elicitation Through Language Trigger Provision and Domain Trigger Retention,"Multilingual large language models (MLLMs) do not perform as well when
answering questions in non-dominant languages as they do in their dominant
languages. Although existing translate-then-answer methods alleviate this
issue, the mechanisms behind their effectiveness remain unclear. In this study,
we analogize the dominant language of MLLMs to the native language of humans
and use two human cognitive features: the Language Trigger (LT) and the Domain
Trigger (DT), to interpret the mechanisms behind translate-then-answer methods.
This reveals that while sufficient LTs are provided by these methods, there
remains a deficiency in DT retention. To mitigate this issue, we propose Native
Language Prompting (NatLan), employing a Multi-MLLM collaboration strategy and
introducing an additional role-enhanced domain-specific MLLM with stronger
multilingual understanding capabilities as the translator. Across five language
QA benchmarks, NatLan achieves up to a 31.28% improvement in accuracy and,
compared to existing state-of-the-art methods, provides comparable or greater
retention of DTs in up to 87% of cases. Our code is available at
https://github.com/AnonyNLP/NatLan.",2024-08-07,"Baixuan Li, Yunlong Fan, Tianyi Ma, Zhiqiang Gao",http://arxiv.org/pdf/2408.03544v3,cs.CL
EXAONE 3.0 7.8B Instruction Tuned Language Model,"We introduce EXAONE 3.0 instruction-tuned language model, the first open
model in the family of Large Language Models (LLMs) developed by LG AI
Research. Among different model sizes, we publicly release the 7.8B
instruction-tuned model to promote open research and innovations. Through
extensive evaluations across a wide range of public and in-house benchmarks,
EXAONE 3.0 demonstrates highly competitive real-world performance with
instruction-following capability against other state-of-the-art open models of
similar size. Our comparative analysis shows that EXAONE 3.0 excels
particularly in Korean, while achieving compelling performance across general
tasks and complex reasoning. With its strong real-world effectiveness and
bilingual proficiency, we hope that EXAONE keeps contributing to advancements
in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at
https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",2024-08-07,"LG AI Research, :, Soyoung An, Kyunghoon Bae, Eunbi Choi, Stanley Jungkyu Choi, Yemuk Choi, Seokhee Hong, Yeonjung Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Euisoon Kim, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Moontae Lee, Seungjun Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Boseong Seo, Sihoon Yang, Heuiyeen Yeen, Kyungjae Yoo, Hyeongu Yun",http://arxiv.org/pdf/2408.03541v3,cs.CL
EgyBERT: A Large Language Model Pretrained on Egyptian Dialect Corpora,"This study presents EgyBERT, an Arabic language model pretrained on 10.4 GB
of Egyptian dialectal texts. We evaluated EgyBERT's performance by comparing it
with five other multidialect Arabic language models across 10 evaluation
datasets. EgyBERT achieved the highest average F1-score of 84.25% and an
accuracy of 87.33%, significantly outperforming all other comparative models,
with MARBERTv2 as the second best model achieving an F1-score 83.68% and an
accuracy 87.19%. Additionally, we introduce two novel Egyptian dialectal
corpora: the Egyptian Tweets Corpus (ETC), containing over 34.33 million tweets
(24.89 million sentences) amounting to 2.5 GB of text, and the Egyptian Forums
Corpus (EFC), comprising over 44.42 million sentences (7.9 GB of text)
collected from various Egyptian online forums. Both corpora are used in
pretraining the new model, and they are the largest Egyptian dialectal corpora
to date reported in the literature. Furthermore, this is the first study to
evaluate the performance of various language models on Egyptian dialect
datasets, revealing significant differences in performance that highlight the
need for more dialect-specific models. The results confirm the effectiveness of
EgyBERT model in processing and analyzing Arabic text expressed in Egyptian
dialect, surpassing other language models included in the study. EgyBERT model
is publicly available on \url{https://huggingface.co/faisalq/EgyBERT}.",2024-08-07,Faisal Qarah,http://arxiv.org/pdf/2408.03524v1,cs.CL
MoExtend: Tuning New Experts for Modality and Task Extension,"Large language models (LLMs) excel in various tasks but are primarily trained
on text data, limiting their application scope. Expanding LLM capabilities to
include vision-language understanding is vital, yet training them on multimodal
data from scratch is challenging and costly. Existing instruction tuning
methods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs
via fully fine-tuning LLMs to bridge the modality gap. However, full
fine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous
knowledge, and high training costs particularly in the era of increasing tasks
and modalities. To solve this issue, we introduce MoExtend, an effective
framework designed to streamline the modality adaptation and extension of
Mixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts
into pre-trained MoE models, endowing them with novel knowledge without the
need to tune pretrained models such as MoE and vision encoders. This approach
enables rapid adaptation and extension to new modal data or tasks, effectively
addressing the challenge of accommodating new modalities within LLMs.
Furthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk
of catastrophic forgetting. Experimental results demonstrate the efficacy and
efficiency of MoExtend in enhancing the multimodal capabilities of LLMs,
contributing to advancements in multimodal AI research. Code:
https://github.com/zhongshsh/MoExtend.",2024-08-07,"Shanshan Zhong, Shanghua Gao, Zhongzhan Huang, Wushao Wen, Marinka Zitnik, Pan Zhou",http://arxiv.org/pdf/2408.03511v1,cs.CL
"1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data","This paper presents a compute-efficient approach to pre-training a Language
Model-the ""1.5-Pints""-in only 9 days, while outperforming state-of-the-art
models as an instruction-following assistant.Based on MT-Bench (a benchmark
that emulates human judgments), 1.5-Pints outperforms Apple's OpenELM and
Microsoft's Phi.This is achieved by a carefully curated pre-training dataset of
57 billion tokens, using a mix of automated workflows and manual human review.
The selection of the dataset prioritizes content that is considered expository
and ""textbook-like"" to aid the model in reasoning and logical deduction,
culminating in its overall ability as a strong and versatile AI model. In terms
of the model architecture, we employed a modified Mistral tokenizer, alongside
a Llama-2 architecture for wider compatibility. For training, we adopted the
methodologies used by StableLM, TinyLlama, and Huggingface Zephyr. 1.5-Pints
demonstrates that by focusing on data quality over quantity in LLM training, we
can significantly reduce training time and resources required. We believe this
approach will not only make pre-training more accessible but also reduce our
carbon footprint. Our findings and resources from this research are
open-sourced, aiming to facilitate further advancements in the field. The
1.5-Pints model is available in two versions: 2K and 16K context windows.",2024-08-07,"Calvin Tan, Jerome Wang",http://arxiv.org/pdf/2408.03506v1,cs.CL
Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation,"Multimodal large language models (MLLMs) have extended the success of large
language models (LLMs) to multiple data types, such as image, text and audio,
achieving significant performance in various domains, including multimodal
translation, visual question answering and content generation. Nonetheless,
existing systems are inefficient to train MLLMs due to substantial GPU bubbles
caused by the heterogeneous modality models and complex data dependencies in 3D
parallelism. This paper proposes Optimus, a distributed MLLM training system
that reduces end-to-end MLLM training time. Optimus is based on our principled
analysis that scheduling the encoder computation within the LLM bubbles can
reduce bubbles in MLLM training. To make scheduling encoder computation
possible for all GPUs, Optimus searches the separate parallel plans for encoder
and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM
bubbles without breaking the original data dependencies in the MLLM model
architecture. We further decompose encoder layer computation into a series of
kernels, and analyze the common bubble pattern of 3D parallelism to carefully
optimize the sub-millisecond bubble scheduling, minimizing the overall training
time. Our experiments in a production cluster show that Optimus accelerates
MLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs
compared to baselines.",2024-08-07,"Weiqi Feng, Yangrui Chen, Shaoyu Wang, Yanghua Peng, Haibin Lin, Minlan Yu",http://arxiv.org/pdf/2408.03505v1,cs.CL
Forecasting Live Chat Intent from Browsing History,"Customers reach out to online live chat agents with various intents, such as
asking about product details or requesting a return. In this paper, we propose
the problem of predicting user intent from browsing history and address it
through a two-stage approach. The first stage classifies a user's browsing
history into high-level intent categories. Here, we represent each browsing
history as a text sequence of page attributes and use the ground-truth class
labels to fine-tune pretrained Transformers. The second stage provides a large
language model (LLM) with the browsing history and predicted intent class to
generate fine-grained intents. For automatic evaluation, we use a separate LLM
to judge the similarity between generated and ground-truth intents, which
closely aligns with human judgments. Our two-stage approach yields significant
performance gains compared to generating intents without the classification
stage.",2024-08-07,"Se-eun Yoon, Ahmad Bin Rabiah, Zaid Alibadi, Surya Kallumadi, Julian McAuley",http://arxiv.org/pdf/2408.04668v2,cs.CL
Automated Theorem Provers Help Improve Large Language Model Reasoning,"In this paper we demonstrate how logic programming systems and Automated
first-order logic Theorem Provers (ATPs) can improve the accuracy of Large
Language Models (LLMs) for logical reasoning tasks where the baseline
performance is given by direct LLM solutions. We first evaluate LLM reasoning
on steamroller problems using the PRONTOQA benchmark. We show how accuracy can
be improved with a neuro-symbolic architecture where the LLM acts solely as a
front-end for translating a given problem into a formal logic language and an
automated reasoning engine is called for solving it. However, this approach
critically hinges on the correctness of the LLM translation. To assess this
translation correctness, we secondly define a framework of syntactic and
semantic error categories. We implemented the framework and used it to identify
errors that LLMs make in the benchmark domain. Based on these findings, we
thirdly extended our method with capabilities for automatically correcting
syntactic and semantic errors. For semantic error correction we integrate
first-order logic ATPs, which is our main and novel contribution. We
demonstrate that this approach reduces semantic errors significantly and
further increases the accurracy of LLM logical reasoning.",2024-08-07,"Lachlan McGinness, Peter Baumgartner",http://arxiv.org/pdf/2408.03492v1,cs.CL
"Logistic Regression makes small LLMs strong and explainable ""tens-of-shot"" classifiers","For simple classification tasks, we show that users can benefit from the
advantages of using small, local, generative language models instead of large
commercial models without a trade-off in performance or introducing extra
labelling costs. These advantages, including those around privacy,
availability, cost, and explainability, are important both in commercial
applications and in the broader democratisation of AI. Through experiments on
17 sentence classification tasks (2-4 classes), we show that penalised logistic
regression on the embeddings from a small LLM equals (and usually betters) the
performance of a large LLM in the ""tens-of-shot"" regime. This requires no more
labelled instances than are needed to validate the performance of the large
LLM. Finally, we extract stable and sensible explanations for classification
decisions.",2024-08-06,"Marcus Buckmann, Edward Hill",http://arxiv.org/pdf/2408.03414v2,cs.CL
ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning,"Large Language Models (LLMs) excel in various natural language processing
tasks, but leveraging them for dense passage embedding remains challenging.
This is due to their causal attention mechanism and the misalignment between
their pre-training objectives and the text ranking tasks. Despite some recent
efforts to address these issues, existing frameworks for LLM-based text
embeddings have been limited by their support for only a limited range of LLM
architectures and fine-tuning strategies, limiting their practical application
and versatility. In this work, we introduce the Unified framework for Large
Language Model Embedding (ULLME), a flexible, plug-and-play implementation that
enables bidirectional attention across various LLMs and supports a range of
fine-tuning strategies. We also propose Generation-augmented Representation
Learning (GRL), a novel fine-tuning method to boost LLMs for text embedding
tasks. GRL enforces consistency between representation-based and
generation-based relevance scores, leveraging LLMs' powerful generative
abilities for learning passage embeddings. To showcase our framework's
flexibility and effectiveness, we release three pre-trained models from ULLME
with different backbone architectures, ranging from 1.5B to 8B parameters, all
of which demonstrate strong performance on the Massive Text Embedding
Benchmark. Our framework is publicly available at:
https://github.com/nlp-uoregon/ullme. A demo video for ULLME can also be found
at https://rb.gy/ws1ile.",2024-08-06,"Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Thien Huu Nguyen",http://arxiv.org/pdf/2408.03402v1,cs.CL
LLaVA-OneVision: Easy Visual Task Transfer,"We present LLaVA-OneVision, a family of open large multimodal models (LMMs)
developed by consolidating our insights into data, models, and visual
representations in the LLaVA-NeXT blog series. Our experimental results
demonstrate that LLaVA-OneVision is the first single model that can
simultaneously push the performance boundaries of open LMMs in three important
computer vision scenarios: single-image, multi-image, and video scenarios.
Importantly, the design of LLaVA-OneVision allows strong transfer learning
across different modalities/scenarios, yielding new emerging capabilities. In
particular, strong video understanding and cross-scenario capabilities are
demonstrated through task transfer from images to videos.",2024-08-06,"Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li",http://arxiv.org/pdf/2408.03326v3,cs.CL
CoverBench: A Challenging Benchmark for Complex Claim Verification,"There is a growing line of research on verifying the correctness of language
models' outputs. At the same time, LMs are being used to tackle complex queries
that require reasoning. We introduce CoverBench, a challenging benchmark
focused on verifying LM outputs in complex reasoning settings. Datasets that
can be used for this purpose are often designed for other complex reasoning
tasks (e.g., QA) targeting specific use-cases (e.g., financial tables),
requiring transformations, negative sampling and selection of hard examples to
collect such a benchmark. CoverBench provides a diversified evaluation for
complex claim verification in a variety of domains, types of reasoning,
relatively long inputs, and a variety of standardizations, such as multiple
representations for tables where available, and a consistent schema. We
manually vet the data for quality to ensure low levels of label noise. Finally,
we report a variety of competitive baseline results to show CoverBench is
challenging and has very significant headroom. The data is available at
https://huggingface.co/datasets/google/coverbench .",2024-08-06,"Alon Jacovi, Moran Ambar, Eyal Ben-David, Uri Shaham, Amir Feder, Mor Geva, Dror Marcus, Avi Caciularu",http://arxiv.org/pdf/2408.03325v2,cs.CL
Training LLMs to Recognize Hedges in Spontaneous Narratives,"Hedges allow speakers to mark utterances as provisional, whether to signal
non-prototypicality or ""fuzziness"", to indicate a lack of commitment to an
utterance, to attribute responsibility for a statement to someone else, to
invite input from a partner, or to soften critical feedback in the service of
face-management needs. Here we focus on hedges in an experimentally
parameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced
from memory by 21 speakers for co-present addressees, transcribed to text
(Galati and Brennan, 2010). We created a gold standard of hedges annotated by
human coders (the Roadrunner-Hedge corpus) and compared three LLM-based
approaches for hedge detection: fine-tuning BERT, and zero and few-shot
prompting with GPT-4o and LLaMA-3. The best-performing approach was a
fine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on
the top performing approaches, we used an LLM-in-the-Loop approach to improve
the gold standard coding, as well as to highlight cases in which hedges are
ambiguous in linguistically interesting ways that will guide future research.
This is the first step in our research program to train LLMs to interpret and
generate collateral signals appropriately and meaningfully in conversation.",2024-08-06,"Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E. Brennan",http://arxiv.org/pdf/2408.03319v1,cs.CL
Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters,"Enabling LLMs to improve their outputs by using more test-time computation is
a critical step towards building generally self-improving agents that can
operate on open-ended natural language. In this paper, we study the scaling of
inference-time computation in LLMs, with a focus on answering the question: if
an LLM is allowed to use a fixed but non-trivial amount of inference-time
compute, how much can it improve its performance on a challenging prompt?
Answering this question has implications not only on the achievable performance
of LLMs, but also on the future of LLM pretraining and how one should tradeoff
inference-time and pre-training compute. Despite its importance, little
research attempted to understand the scaling behaviors of various test-time
inference methods. Moreover, current work largely provides negative results for
a number of these strategies. In this work, we analyze two primary mechanisms
to scale test-time computation: (1) searching against dense, process-based
verifier reward models; and (2) updating the model's distribution over a
response adaptively, given the prompt at test time. We find that in both cases,
the effectiveness of different approaches to scaling test-time compute
critically varies depending on the difficulty of the prompt. This observation
motivates applying a ""compute-optimal"" scaling strategy, which acts to most
effectively allocate test-time compute adaptively per prompt. Using this
compute-optimal strategy, we can improve the efficiency of test-time compute
scaling by more than 4x compared to a best-of-N baseline. Additionally, in a
FLOPs-matched evaluation, we find that on problems where a smaller base model
attains somewhat non-trivial success rates, test-time compute can be used to
outperform a 14x larger model.",2024-08-06,"Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar",http://arxiv.org/pdf/2408.03314v1,cs.CL
KnowPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models,"By integrating external knowledge, Retrieval-Augmented Generation (RAG) has
become an effective strategy for mitigating the hallucination problems that
large language models (LLMs) encounter when dealing with knowledge-intensive
tasks. However, in the process of integrating external non-parametric
supporting evidence with internal parametric knowledge, inevitable knowledge
conflicts may arise, leading to confusion in the model's responses. To enhance
the knowledge selection of LLMs in various contexts, some research has focused
on refining their behavior patterns through instruction-tuning. Nonetheless,
due to the absence of explicit negative signals and comparative objectives,
models fine-tuned in this manner may still exhibit undesirable behaviors such
as contextual ignorance and contextual overinclusion. To this end, we propose a
Knowledge-aware Preference Optimization strategy, dubbed KnowPO, aimed at
achieving adaptive knowledge selection based on contextual relevance in real
retrieval scenarios. Concretely, we proposed a general paradigm for
constructing knowledge conflict datasets, which comprehensively cover various
error types and learn how to avoid these negative signals through preference
optimization methods. Simultaneously, we proposed a rewriting strategy and data
ratio optimization strategy to address preference imbalances. Experimental
results show that KnowPO outperforms previous methods for handling knowledge
conflicts by over 37\%, while also exhibiting robust generalization across
various out-of-distribution datasets.",2024-08-06,"Ruizhe Zhang, Yongxin Xu, Yuzhen Xiao, Runchuan Zhu, Xinke Jiang, Xu Chu, Junfeng Zhao, Yasha Wang",http://arxiv.org/pdf/2408.03297v2,cs.CL
"Non-Determinism of ""Deterministic"" LLM Settings","LLM (large language model) practitioners commonly notice that outputs can
vary for the same inputs under settings expected to be deterministic. Yet the
questions of how pervasive this is, and with what impact on results, have not
to our knowledge been systematically investigated. We investigate
non-determinism in five LLMs configured to be deterministic when applied to
eight common tasks in across 10 runs, in both zero-shot and few-shot settings.
We see accuracy variations up to 15% across naturally occurring runs with a gap
of best possible performance to worst possible performance up to 70%. In fact,
none of the LLMs consistently delivers repeatable accuracy across all tasks,
much less identical output strings. Sharing preliminary results with insiders
has revealed that non-determinism perhaps essential to the efficient use of
compute resources via co-mingled data in input buffers so this issue is not
going away anytime soon. To better quantify our observations, we introduce
metrics focused on quantifying determinism, TARr@N for the total agreement rate
at N runs over raw output, and TARa@N for total agreement rate of parsed-out
answers. Our code and data are publicly available at
https://github.com/breckbaldwin/llm-stability.",2024-08-06,"Berk Atil, Sarp Aykent, Alexa Chittams, Lisheng Fu, Rebecca J. Passonneau, Evan Radcliffe, Guru Rajan Rajagopal, Adam Sloan, Tomasz Tudrej, Ferhan Ture, Zhe Wu, Lixinyu Xu, Breck Baldwin",http://arxiv.org/pdf/2408.04667v5,cs.CL
SARA: Singular-Value Based Adaptive Low-Rank Adaption,"With the increasing number of parameters in large pre-trained models, LoRA as
a parameter-efficient fine-tuning(PEFT) method is widely used for not adding
inference overhead. The LoRA method assumes that weight changes during
fine-tuning can be approximated by low-rank matrices. However, the rank values
need to be manually verified to match different downstream tasks, and they
cannot accommodate the varying importance of different layers in the model. In
this work, we first analyze the relationship between the performance of
different layers and their ranks using SVD. Based on this, we design the
Singular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds
the rank during initialization by performing SVD on the pre-trained weights.
Additionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly
reduces the number of parameters by fine-tuning only multiple parallel sets of
singular values controlled by a router. Extensive experiments on various
complex tasks demonstrate the simplicity and parameter efficiency of our
methods. They can effectively and adaptively find the most suitable rank for
each layer of each model.",2024-08-06,"Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong",http://arxiv.org/pdf/2408.03290v1,cs.CL
LLMs are Not Just Next Token Predictors,"LLMs are statistical models of language learning through stochastic gradient
descent with a next token prediction objective. Prompting a popular view among
AI modelers: LLMs are just next token predictors. While LLMs are engineered
using next token prediction, and trained based on their success at this task,
our view is that a reduction to just next token predictor sells LLMs short.
Moreover, there are important explanations of LLM behavior and capabilities
that are lost when we engage in this kind of reduction. In order to draw this
out, we will make an analogy with a once prominent research program in biology
explaining evolution and development from the gene's eye view.",2024-08-06,"Stephen M. Downes, Patrick Forber, Alex Grzankowski",http://arxiv.org/pdf/2408.04666v1,cs.CL
StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation,"Evaluation is the baton for the development of large language models. Current
evaluations typically employ a single-item assessment paradigm for each atomic
test objective, which struggles to discern whether a model genuinely possesses
the required capabilities or merely memorizes/guesses the answers to specific
questions. To this end, we propose a novel evaluation framework referred to as
StructEval. Starting from an atomic test objective, StructEval deepens and
broadens the evaluation by conducting a structured assessment across multiple
cognitive levels and critical concepts, and therefore offers a comprehensive,
robust and consistent evaluation for LLMs. Experiments on three widely-used
benchmarks demonstrate that StructEval serves as a reliable tool for resisting
the risk of data contamination and reducing the interference of potential
biases, thereby providing more reliable and consistent conclusions regarding
model capabilities. Our framework also sheds light on the design of future
principled and trustworthy LLM evaluation protocols.",2024-08-06,"Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun",http://arxiv.org/pdf/2408.03281v2,cs.CL
LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification,"We introduce LAMPO, a novel paradigm that leverages Large Language Models
(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike
conventional methods, which concatenate all demonstration examples with the
test instance and prompt LLMs to produce the pointwise prediction, our
framework uses the LLM as a preference machine that makes a relative
comparative decision between the test instance and each demonstration. A
self-supervised method is then introduced to aggregate these binary comparisons
into the final ordinal decision. LAMPO addresses several limitations inherent
in previous methods, including context length constraints, ordering biases, and
challenges associated with absolute point-wise estimation. Extensive
experiments on seven public datasets demonstrate LAMPO's remarkably competitive
performance across a diverse spectrum of applications (e.g., movie review
analysis and hate speech detection). Notably, in certain applications, the
improvement can be substantial, exceeding 20% in an absolute term. Moreover, we
believe LAMPO represents an interesting addition to the non-parametric
application layered on top of LLMs, as it supports black-box LLMs without
necessitating the outputting of LLM's internal states (e.g., embeddings), as
seen in previous approaches.",2024-08-06,"Zhen Qin, Junru Wu, Jiaming Shen, Tianqi Liu, Xuanhui Wang",http://arxiv.org/pdf/2408.03359v1,cs.CL
OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs,"The increased use of large language models (LLMs) across a variety of
real-world applications calls for automatic tools to check the factual accuracy
of their outputs, as LLMs often hallucinate. This is difficult as it requires
assessing the factuality of free-form open-domain responses. While there has
been a lot of research on this topic, different papers use different evaluation
benchmarks and measures, which makes them hard to compare and hampers future
progress. To mitigate these issues, we developed OpenFactCheck, a unified
framework, with three modules: (i) RESPONSEEVAL, which allows users to easily
customize an automatic fact-checking system and to assess the factuality of all
claims in an input document using that system, (ii) LLMEVAL, which assesses the
overall factuality of an LLM, and (iii) CHECKEREVAL, a module to evaluate
automatic fact-checking systems. OpenFactCheck is open-sourced
(https://github.com/mbzuai-nlp/openfactcheck) and publicly released as a Python
library (https://pypi.org/project/openfactcheck/) and also as a web service
(http://app.openfactcheck.com). A video describing the system is available at
https://youtu.be/-i9VKL0HleI.",2024-08-06,"Hasan Iqbal, Yuxia Wang, Minghan Wang, Georgi Georgiev, Jiahui Geng, Iryna Gurevych, Preslav Nakov",http://arxiv.org/pdf/2408.11832v2,cs.CL
Synthesizing Text-to-SQL Data from Weak and Strong LLMs,"The capability gap between open-source and closed-source large language
models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we
introduce a synthetic data approach that combines data produced by larger, more
powerful models (strong models) with error information data generated by
smaller, not well-aligned models (weak models). The method not only enhances
the domain generalization of text-to-SQL models but also explores the potential
of error data supervision through preference learning. Furthermore, we employ
the synthetic data approach for instruction tuning on open-source LLMs,
resulting SENSE, a specialized text-to-SQL model. The effectiveness of SENSE is
demonstrated through state-of-the-art results on the SPIDER and BIRD
benchmarks, bridging the performance gap between open-source models and methods
prompted by closed-source models.",2024-08-06,"Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, Chang Zhou",http://arxiv.org/pdf/2408.03256v1,cs.CL
Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons,"In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.",2024-08-06,"Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng",http://arxiv.org/pdf/2408.03247v3,cs.CL
Making Long-Context Language Models Better Multi-Hop Reasoners,"Recent advancements in long-context modeling have enhanced language models
(LMs) for complex tasks across multiple NLP applications. Despite this
progress, we find that these models struggle with multi-hop reasoning and
exhibit decreased performance in the presence of noisy contexts. In this paper,
we introduce Reasoning with Attributions, a novel approach that prompts LMs to
supply attributions for each assertion during their reasoning. We validate our
approach through experiments on three multi-hop datasets, employing both
proprietary and open-source models, and demonstrate its efficacy and
resilience. Furthermore, we explore methods to augment reasoning capabilities
via fine-tuning and offer an attribution-annotated dataset and a specialized
training strategy. Our fine-tuned model achieves competitive performance on
multi-hop reasoning benchmarks, closely paralleling proprietary LMs such as
ChatGPT and Claude-instant.",2024-08-06,"Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang",http://arxiv.org/pdf/2408.03246v1,cs.CL
LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations,"The extraction of Metal-Organic Frameworks (MOFs) synthesis route from
literature has been crucial for the logical MOFs design with desirable
functionality. The recent advent of large language models (LLMs) provides
disruptively new solution to this long-standing problem. While the latest
researches mostly stick to primitive zero-shot LLMs lacking specialized
material knowledge, we introduce in this work the few-shot LLM in-context
learning paradigm. First, a human-AI interactive data curation approach is
proposed to secure high-quality demonstrations. Second, an information
retrieval algorithm is applied to pick and quantify few-shot demonstrations for
each extraction. Over three datasets randomly sampled from nearly 90,000
well-defined MOFs, we conduct triple evaluations to validate our method. The
synthesis extraction, structure inference, and material design performance of
the proposed few-shot LLMs all significantly outplay zero-shot LLM and baseline
methods. The lab-synthesized material guided by LLM surpasses 91.1%
high-quality MOFs of the same class reported in the literature, on the key
physical property of specific surface area.",2024-08-06,"Lei Shi, Zhimeng Liu, Yi Yang, Weize Wu, Yuyang Zhang, Hongbo Zhang, Jing Lin, Siyu Wu, Zihan Chen, Ruiming Li, Nan Wang, Zipeng Liu, Huobin Tan, Hongyi Gao, Yue Zhang, Ge Wang",http://arxiv.org/pdf/2408.04665v2,cs.CL
A Debiased Nearest Neighbors Framework for Multi-Label Text Classification,"Multi-Label Text Classification (MLTC) is a practical yet challenging task
that involves assigning multiple non-exclusive labels to each document.
Previous studies primarily focus on capturing label correlations to assist
label prediction by introducing special labeling schemes, designing specific
model structures, or adding auxiliary tasks. Recently, the $k$ Nearest Neighbor
($k$NN) framework has shown promise by retrieving labeled samples as references
to mine label co-occurrence information in the embedding space. However, two
critical biases, namely embedding alignment bias and confidence estimation
bias, are often overlooked, adversely affecting prediction performance. In this
paper, we introduce a DEbiased Nearest Neighbors (DENN) framework for MLTC,
specifically designed to mitigate these biases. To address embedding alignment
bias, we propose a debiased contrastive learning strategy, enhancing neighbor
consistency on label co-occurrence. For confidence estimation bias, we present
a debiased confidence estimation strategy, improving the adaptive combination
of predictions from $k$NN and inductive binary classifications. Extensive
experiments conducted on four public benchmark datasets (i.e., AAPD, RCV1-V2,
Amazon-531, and EUR-LEX57K) showcase the effectiveness of our proposed method.
Besides, our method does not introduce any extra parameters.",2024-08-06,"Zifeng Cheng, Zhiwei Jiang, Yafeng Yin, Zhaoling Chen, Cong Wang, Shiping Ge, Qiguo Huang, Qing Gu",http://arxiv.org/pdf/2408.03202v1,cs.CL
Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi,"With the surge in digital content in low-resource languages, there is an
escalating demand for advanced Natural Language Processing (NLP) techniques
tailored to these languages. BERT (Bidirectional Encoder Representations from
Transformers), serving as the foundational framework for numerous NLP
architectures and language models, is increasingly employed for the development
of low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method
for fine-tuning Large Language Models (LLMs) and reducing the training
parameters to some extent to decrease the computational costs needed for
training the model and achieve results comparable to a fully fine-tuned model.
In this work, we present a study of PEFT methods for the Indic low-resource
language Marathi. We conduct a comprehensive analysis of PEFT methods applied
to various monolingual and multilingual Marathi BERT models. These approaches
are evaluated on prominent text classification datasets like MahaSent,
MahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to
significantly expedite the training speed of the models, addressing a critical
aspect of model development and deployment. In this study, we explore Low-Rank
Adaptation of Large Language Models (LoRA) and adapter methods for low-resource
text classification. We show that these methods are competitive with full
fine-tuning and can be used without loss in accuracy. This study contributes
valuable insights into the effectiveness of Marathi BERT models, offering a
foundation for the continued advancement of NLP capabilities in Marathi and
similar Indic languages.",2024-08-06,"Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Raviraj Joshi",http://arxiv.org/pdf/2408.03172v1,cs.CL
Conditioning LLMs with Emotion in Neural Machine Translation,"Large Language Models (LLMs) have shown remarkable performance in Natural
Language Processing tasks, including Machine Translation (MT). In this work, we
propose a novel MT pipeline that integrates emotion information extracted from
a Speech Emotion Recognition (SER) model into LLMs to enhance translation
quality. We first fine-tune five existing LLMs on the Libri-trans dataset and
select the most performant model. Subsequently, we augment LLM prompts with
different dimensional emotions and train the selected LLM under these different
configurations. Our experiments reveal that integrating emotion information,
especially arousal, into LLM prompts leads to notable improvements in
translation quality.",2024-08-06,"Charles Brazier, Jean-Luc Rouas",http://arxiv.org/pdf/2408.03150v1,cs.CL
Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization,"The rapid increase in multimedia data has spurred advancements in Multimodal
Summarization with Multimodal Output (MSMO), which aims to produce a multimodal
summary that integrates both text and relevant images. The inherent
heterogeneity of content within multimodal inputs and outputs presents a
significant challenge to the execution of MSMO. Traditional approaches
typically adopt a holistic perspective on coarse image-text data or individual
visual objects, overlooking the essential connections between objects and the
entities they represent. To integrate the fine-grained entity knowledge, we
propose an Entity-Guided Multimodal Summarization model (EGMS). Our model,
building on BART, utilizes dual multimodal encoders with shared weights to
process text-image and entity-image information concurrently. A gating
mechanism then combines visual data for enhanced textual summary generation,
while image selection is refined through knowledge distillation from a
pre-trained vision-language model. Extensive experiments on public MSMO dataset
validate the superiority of the EGMS method, which also prove the necessity to
incorporate entity information into MSMO problem.",2024-08-06,"Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen",http://arxiv.org/pdf/2408.03149v1,cs.CL
"Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations","Large language models are ubiquitous in natural language processing because
they can adapt to new tasks without retraining. However, their sheer scale and
complexity present unique challenges and opportunities, prompting researchers
and practitioners to explore novel model training, optimization, and deployment
methods. This literature review focuses on various techniques for reducing
resource requirements and compressing large language models, including
quantization, pruning, knowledge distillation, and architectural optimizations.
The primary objective is to explore each method in-depth and highlight its
unique challenges and practical applications. The discussed methods are
categorized into a taxonomy that presents an overview of the optimization
landscape and helps navigate it to understand the research trajectory better.",2024-08-06,"Leo Donisch, Sigurd Schacht, Carsten Lanquillon",http://arxiv.org/pdf/2408.03130v1,cs.CL
Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation,"This paper describes our approach to the SemEval-2024 safe biomedical Natural
Language Inference for Clinical Trials (NLI4CT) task, which concerns
classifying statements about Clinical Trial Reports (CTRs). We explored the
capabilities of Mistral-7B, a generalist open-source Large Language Model
(LLM). We developed a prompt for the NLI4CT task, and fine-tuned a quantized
version of the model using an augmented version of the training dataset. The
experimental results show that this approach can produce notable results in
terms of the macro F1-score, while having limitations in terms of faithfulness
and consistency. All the developed code is publicly available on a GitHub
repository",2024-08-06,"Artur Guimarães, Bruno Martins, João Magalhães",http://arxiv.org/pdf/2408.03127v1,cs.CL
COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework,"As the NLP community increasingly addresses challenges associated with
multilingualism, robust annotation tools are essential to handle multilingual
datasets efficiently. In this paper, we introduce a code-mixed multilingual
text annotation framework, COMMENTATOR, specifically designed for annotating
code-mixed text. The tool demonstrates its effectiveness in token-level and
sentence-level language annotation tasks for Hinglish text. We perform robust
qualitative human-based evaluations to showcase COMMENTATOR led to 5x faster
annotations than the best baseline. Our code is publicly available at
\url{https://github.com/lingo-iitgn/commentator}. The demonstration video is
available at \url{https://bit.ly/commentator_video}.",2024-08-06,"Rajvee Sheth, Shubh Nisar, Heenaben Prajapati, Himanshu Beniwal, Mayank Singh",http://arxiv.org/pdf/2408.03125v1,cs.CL
Evaluating the Translation Performance of Large Language Models Based on Euas-20,"In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.",2024-08-06,"Yan Huang, Wei Liu",http://arxiv.org/pdf/2408.03119v1,cs.CL
Topic Modeling with Fine-tuning LLMs and Bag of Sentences,"Large language models (LLM)'s are increasingly used for topic modeling
outperforming classical topic models such as LDA. Commonly, pre-trained LLM
encoders such as BERT are used out-of-the-box despite the fact that fine-tuning
is known to improve LLMs considerably. The challenge lies in obtaining a
suitable (labeled) dataset for fine-tuning. In this paper, we use the recent
idea to use bag of sentences as the elementary unit in computing topics. In
turn, we derive an approach FT-Topic to perform unsupervised fine-tuning
relying primarily on two steps for constructing a training dataset in an
automatic fashion. First, a heuristic method to identifies pairs of sentence
groups that are either assumed to be of the same or different topics. Second,
we remove sentence pairs that are likely labeled incorrectly. The dataset is
then used to fine-tune an encoder LLM, which can be leveraged by any topic
modeling approach using embeddings. However, in this work, we demonstrate its
effectiveness by deriving a novel state-of-the-art topic modeling method called
SenClu, which achieves fast inference through an expectation-maximization
algorithm and hard assignments of sentence groups to a single topic, while
giving users the possibility to encode prior knowledge on the topic-document
distribution. Code is at \url{https://github.com/JohnTailor/FT-Topic}",2024-08-06,Johannes Schneider,http://arxiv.org/pdf/2408.03099v1,cs.CL
500xCompressor: Generalized Prompt Compression for Large Language Models,"Prompt compression is crucial for enhancing inference speed, reducing costs,
and improving user experience. However, current methods face challenges such as
low compression ratios and potential data leakage during evaluation. To address
these issues, we propose 500xCompressor, a method that compresses extensive
natural language contexts into a minimum of one single special token. The
500xCompressor introduces approximately 0.3% additional parameters and achieves
compression ratios ranging from 6x to 480x. It is designed to compress any
text, answer various types of questions, and could be utilized by the original
large language model (LLM) without requiring fine-tuning. Initially,
500xCompressor was pretrained on the Arxiv Corpus, followed by fine-tuning on
the ArxivQA dataset, and subsequently evaluated on strictly unseen and
classical question answering (QA) datasets. The results demonstrate that the
LLM retained 62.26-72.89% of its capabilities compared to using non-compressed
prompts. This study also shows that not all the compressed tokens are equally
utilized and that K V values have significant advantages over embeddings in
preserving information at high compression ratios. The highly compressive
nature of natural language prompts, even for fine-grained complex information,
suggests promising potential for future applications and further research into
developing a new LLM language.",2024-08-06,"Zongqian Li, Yixuan Su, Nigel Collier",http://arxiv.org/pdf/2408.03094v1,cs.CL
Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement,"Merging Large Language Models (LLMs) aims to amalgamate multiple homologous
LLMs into one with all the capabilities. Ideally, any LLMs sharing the same
backbone should be mergeable, irrespective of whether they are Fine-Tuned (FT)
with minor parameter changes or Pre-Trained (PT) with substantial parameter
shifts. However, existing methods often manually assign the model importance,
rendering them feasible only for LLMs with similar parameter alterations, such
as multiple FT LLMs. The diverse parameter changed ranges between FT and PT
LLMs pose challenges for current solutions in empirically determining the
optimal combination. In this paper, we make a pioneering effort to broaden the
applicability of merging techniques from FT to PT LLMs. We initially examine
the efficacy of current methods in merging FT and PT LLMs, discovering that
they struggle to deal with PT LLMs. Subsequently, we introduce an approach
based on WeIght DisENtanglement (WIDEN) to effectively extend the merging
scope, which first disentangles model weights into magnitude and direction
components, and then performs adaptive fusion by considering their respective
contributions. In the experiments, we merge Qwen1.5-Chat (an FT LLM with
instruction-following skills) with Sailor (a PT LLM with multilingual
abilities) across 7B and 14B model scales. Results reveal that: (1) existing
solutions usually fail when merging Sailor, either losing both abilities or
only retaining instruction-following skills; (2) WIDEN successfully injects the
multilingual abilities of Sailor into Qwen1.5-Chat and make it proficient in
Southeast Asian languages, achieving enhancements in the fundamental
capabilities. In light of previous research, we also merge multiple 13B FT LLMs
and observe that WIDEN achieves a balanced amalgamation of instruction
following, mathematical reasoning, and code generation skills.",2024-08-06,"Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li",http://arxiv.org/pdf/2408.03092v1,cs.CL
Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion,"Event Causality Extraction (ECE) aims at extracting causal event pairs from
texts. Despite ChatGPT's recent success, fine-tuning small models remains the
best approach for the ECE task. However, existing fine-tuning based ECE methods
cannot address all three key challenges in ECE simultaneously: 1) Complex
Causality Extraction, where multiple causal-effect pairs occur within a single
sentence; 2) Subtask~ Interaction, which involves modeling the mutual
dependence between the two subtasks of ECE, i.e., extracting events and
identifying the causal relationship between extracted events; and 3) Knowledge
Fusion, which requires effectively fusing the knowledge in two modalities,
i.e., the expressive pretrained language models and the structured knowledge
graphs. In this paper, we propose a unified ECE framework (UniCE to address all
three issues in ECE simultaneously. Specifically, we design a subtask
interaction mechanism to enable mutual interaction between the two ECE
subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in
the two modalities. Furthermore, we employ separate decoders for each subtask
to facilitate complex causality extraction. Experiments on three benchmark
datasets demonstrate that our method achieves state-of-the-art performance and
outperforms ChatGPT with a margin of at least 30% F1-score. More importantly,
our model can also be used to effectively improve the ECE performance of
ChatGPT via in-context learning.",2024-08-06,"Jinglong Gao, Chen Lu, Xiao Ding, Zhongyang Li, Ting Liu, Bing Qin",http://arxiv.org/pdf/2408.03079v1,cs.CL
Towards an Analysis of Discourse and Interactional Pragmatic Reasoning Capabilities of Large Language Models,"In this work, we want to give an overview on which pragmatic abilities have
been tested in LLMs so far and how these tests have been carried out. To do
this, we first discuss the scope of the field of pragmatics and suggest a
subdivision into discourse pragmatics and interactional pragmatics. We give a
non-exhaustive overview of the phenomena of those two subdomains and the
methods traditionally used to analyze them. We subsequently consider the
resulting heterogeneous set of phenomena and methods as a starting point for
our survey of work on discourse pragmatics and interactional pragmatics in the
context of LLMs.",2024-08-06,"Amelie Robrecht, Judith Sieker, Clara Lachenmaier, Sina Zarieß, Stefan Kopp",http://arxiv.org/pdf/2408.03074v1,cs.CL
Probing structural constraints of negation in Pretrained Language Models,"Contradictory results about the encoding of the semantic impact of negation
in pretrained language models (PLMs). have been drawn recently (e.g. Kassner
and Sch{\""u}tze (2020); Gubelmann and Handschuh (2022)). In this paper we focus
rather on the way PLMs encode negation and its formal impact, through the
phenomenon of the Negative Polarity Item (NPI) licensing in English. More
precisely, we use probes to identify which contextual representations best
encode 1) the presence of negation in a sentence, and 2) the polarity of a
neighboring masked polarity item. We find that contextual representations of
tokens inside the negation scope do allow for (i) a better prediction of the
presence of not compared to those outside the scope and (ii) a better
prediction of the right polarity of a masked polarity item licensed by not,
although the magnitude of the difference varies from PLM to PLM. Importantly,
in both cases the trend holds even when controlling for distance to not. This
tends to indicate that the embeddings of these models do reflect the notion of
negation scope, and do encode the impact of negation on NPI licensing. Yet,
further control experiments reveal that the presence of other lexical items is
also better captured when using the contextual representation of a token within
the same syntactic clause than outside from it, suggesting that PLMs simply
capture the more general notion of syntactic clause.",2024-08-06,"David Kletz, Marie Candito, Pascal Amsili",http://arxiv.org/pdf/2408.03070v1,cs.CL
Analysis of Argument Structure Constructions in a Deep Recurrent Language Model,"Understanding how language and linguistic constructions are processed in the
brain is a fundamental question in cognitive computational neuroscience. In
this study, we explore the representation and processing of Argument Structure
Constructions (ASCs) in a recurrent neural language model. We trained a Long
Short-Term Memory (LSTM) network on a custom-made dataset consisting of 2000
sentences, generated using GPT-4, representing four distinct ASCs: transitive,
ditransitive, caused-motion, and resultative constructions.
  We analyzed the internal activations of the LSTM model's hidden layers using
Multidimensional Scaling (MDS) and t-Distributed Stochastic Neighbor Embedding
(t-SNE) to visualize the sentence representations. The Generalized
Discrimination Value (GDV) was calculated to quantify the degree of clustering
within these representations. Our results show that sentence representations
form distinct clusters corresponding to the four ASCs across all hidden layers,
with the most pronounced clustering observed in the last hidden layer before
the output layer. This indicates that even a relatively simple,
brain-constrained recurrent neural network can effectively differentiate
between various construction types.
  These findings are consistent with previous studies demonstrating the
emergence of word class and syntax rule representations in recurrent language
models trained on next word prediction tasks. In future work, we aim to
validate these results using larger language models and compare them with
neuroimaging data obtained during continuous speech perception. This study
highlights the potential of recurrent neural language models to mirror
linguistic processing in the human brain, providing valuable insights into the
computational and neural mechanisms underlying language understanding.",2024-08-06,"Pegah Ramezani, Achim Schilling, Patrick Krauss",http://arxiv.org/pdf/2408.03062v1,cs.CL
The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums,"Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the performance of an LLM
system built on the OpenAI GPT-3.5-turbo model [8] to extract CTI information.
To do so, a random sample of more than 700 daily conversations from three
cybercrime forums - XSS, Exploit_in, and RAMP - was extracted, and the LLM
system was instructed to summarize the conversations and predict 10 key CTI
variables, such as whether a large organization and/or a critical
infrastructure is being targeted, with only simple human-language instructions.
Then, two coders reviewed each conversation and evaluated whether the
information extracted by the LLM was accurate. The LLM system performed well,
with an average accuracy score of 96.23%, an average precision of 90% and an
average recall of 88.2%. Various ways to enhance the model were uncovered, such
as the need to help the LLM distinguish between stories and past events, as
well as being careful with verb tenses in prompts. Nevertheless, the results of
this study highlight the relevance of using LLMs for cyber threat intelligence.",2024-08-06,"Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay",http://arxiv.org/pdf/2408.03354v3,cs.CL
OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents,"Multimodal conversational agents are highly desirable because they offer
natural and human-like interaction. However, there is a lack of comprehensive
end-to-end solutions to support collaborative development and benchmarking.
While proprietary systems like GPT-4o and Gemini demonstrating impressive
integration of audio, video, and text with response times of 200-250ms,
challenges remain in balancing latency, accuracy, cost, and data privacy. To
better understand and quantify these issues, we developed OpenOmni, an
open-source, end-to-end pipeline benchmarking tool that integrates advanced
technologies such as Speech-to-Text, Emotion Detection, Retrieval Augmented
Generation, Large Language Models, along with the ability to integrate
customized models. OpenOmni supports local and cloud deployment, ensuring data
privacy and supporting latency and accuracy benchmarking. This flexible
framework allows researchers to customize the pipeline, focusing on real
bottlenecks and facilitating rapid proof-of-concept development. OpenOmni can
significantly enhance applications like indoor assistance for visually impaired
individuals, advancing human-computer interaction. Our demonstration video is
available https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available via
https://openomni.ai4wa.com, code is available via
https://github.com/AI4WA/OpenOmniFramework.",2024-08-06,"Qiang Sun, Yuanyi Luo, Sirui Li, Wenxiao Zhang, Wei Liu",http://arxiv.org/pdf/2408.03047v2,cs.CL
L3iTC at the FinLLM Challenge Task: Quantization for Financial Text Classification & Summarization,"This article details our participation (L3iTC) in the FinLLM Challenge Task
2024, focusing on two key areas: Task 1, financial text classification, and
Task 2, financial text summarization. To address these challenges, we
fine-tuned several large language models (LLMs) to optimize performance for
each task. Specifically, we used 4-bit quantization and LoRA to determine which
layers of the LLMs should be trained at a lower precision. This approach not
only accelerated the fine-tuning process on the training data provided by the
organizers but also enabled us to run the models on low GPU memory. Our
fine-tuned models achieved third place for the financial classification task
with an F1-score of 0.7543 and secured sixth place in the financial
summarization task on the official test datasets.",2024-08-06,"Elvys Linhares Pontes, Carlos-Emiliano González-Gallardo, Mohamed Benjannet, Caryn Qu, Antoine Doucet",http://arxiv.org/pdf/2408.03033v1,cs.CL
Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD),"Large Vision-Language Models (LVLMs) are an extension of Large Language
Models (LLMs) that facilitate processing both image and text inputs, expanding
AI capabilities. However, LVLMs struggle with object hallucinations due to
their reliance on text cues and learned object co-occurrence biases. While most
research quantifies these hallucinations, mitigation strategies are still
lacking. Our study introduces a Language Contrastive Decoding (LCD) algorithm
that adjusts LVLM outputs based on LLM distribution confidence levels,
effectively reducing object hallucinations. We demonstrate the advantages of
LCD in leading LVLMs, showing up to %4 improvement in POPE F1 scores and up to
%36 reduction in CHAIR scores on the COCO validation set, while also improving
captioning quality scores. Our method effectively improves LVLMs without
needing complex post-processing or retraining, and is easily applicable to
different models. Our findings highlight the potential of further exploration
of LVLM-specific decoding algorithms.",2024-08-06,"Avshalom Manevich, Reut Tsarfaty",http://arxiv.org/pdf/2408.04664v1,cs.CL
Dopamin: Transformer-based Comment Classifiers through Domain Post-Training and Multi-level Layer Aggregation,"Code comments provide important information for understanding the source
code. They can help developers understand the overall purpose of a function or
class, as well as identify bugs and technical debt. However, an overabundance
of comments is meaningless and counterproductive. As a result, it is critical
to automatically filter out these comments for specific purposes. In this
paper, we present Dopamin, a Transformer-based tool for dealing with this
issue. Our model excels not only in presenting knowledge sharing of common
categories across multiple languages, but also in achieving robust performance
in comment classification by improving comment representation. As a result, it
outperforms the STACC baseline by 3% on the NLBSE'24 Tool Competition dataset
in terms of average F1-score, while maintaining a comparable inference time for
practical use. The source code is publicity available at
https://github.com/FSoft-AI4Code/Dopamin.",2024-08-06,"Nam Le Hai, Nghi D. Q. Bui",http://arxiv.org/pdf/2408.04663v1,cs.CL
Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs,"Recent advancements in Large Language Models (LLMs) have showcased their
proficiency in answering natural language queries. However, their effectiveness
is hindered by limited domain-specific knowledge, raising concerns about the
reliability of their responses. We introduce a hybrid system that augments LLMs
with domain-specific knowledge graphs (KGs), thereby aiming to enhance factual
correctness using a KG-based retrieval approach. We focus on a medical KG to
demonstrate our methodology, which includes (1) pre-processing, (2) Cypher
query generation, (3) Cypher query processing, (4) KG retrieval, and (5)
LLM-enhanced response generation. We evaluate our system on a curated dataset
of 69 samples, achieving a precision of 78\% in retrieving correct KG nodes.
Our findings indicate that the hybrid system surpasses a standalone LLM in
accuracy and completeness, as verified by an LLM-as-a-Judge evaluation method.
This positions the system as a promising tool for applications that demand
factual correctness and completeness, such as target identification -- a
critical process in pinpointing biological entities for disease treatment or
crop enhancement. Moreover, its intuitive search interface and ability to
provide accurate responses within seconds make it well-suited for
time-sensitive, precision-focused research contexts. We publish the source code
together with the dataset and the prompt templates used.",2024-08-06,"Daniel Steinigen, Roman Teucher, Timm Heine Ruland, Max Rudat, Nicolas Flores-Herr, Peter Fischer, Nikola Milosevic, Christopher Schymura, Angelo Ziletti",http://arxiv.org/pdf/2408.03010v1,cs.CL
Empathy Level Alignment via Reinforcement Learning for Empathetic Response Generation,"Empathetic response generation, aiming to understand the user's situation and
feelings and respond empathically, is crucial in building human-like dialogue
systems. Traditional approaches typically employ maximum likelihood estimation
as the optimization objective during training, yet fail to align the empathy
levels between generated and target responses. To this end, we propose an
empathetic response generation framework using reinforcement learning (EmpRL).
The framework develops an effective empathy reward function and generates
empathetic responses by maximizing the expected reward through reinforcement
learning. EmpRL utilizes the pre-trained T5 model as the generator and further
fine-tunes it to initialize the policy. To align the empathy levels between
generated and target responses within a given context, an empathy reward
function containing three empathy communication mechanisms -- emotional
reaction, interpretation, and exploration -- is constructed using pre-designed
and pre-trained empathy identifiers. During reinforcement learning training,
the proximal policy optimization algorithm is used to fine-tune the policy,
enabling the generation of empathetic responses. Both automatic and human
evaluations demonstrate that the proposed EmpRL framework significantly
improves the quality of generated responses, enhances the similarity in empathy
levels between generated and target responses, and produces empathetic
responses covering both affective and cognitive aspects.",2024-08-06,"Hui Ma, Bo Zhang, Bo Xu, Jian Wang, Hongfei Lin, Xiao Sun",http://arxiv.org/pdf/2408.02976v3,cs.CL
EC-Guide: A Comprehensive E-Commerce Guide for Instruction Tuning and Quantization,"Large language models (LLMs) have attracted considerable attention in various
fields for their cost-effective solutions to diverse challenges, especially
with advancements in instruction tuning and quantization. E-commerce, with its
complex tasks and extensive product-user interactions, presents a promising
application area for LLMs. However, the domain-specific concepts and knowledge
inherent in e-commerce pose significant challenges for adapting general LLMs.
To address this issue, we developed EC-Guide
\href{https://github.com/fzp0424/EC-Guide-KDDUP-2024}, a comprehensive
e-commerce guide for instruction tuning and quantization of LLMs. We also
heuristically integrated Chain-of-Thought (CoT) during inference to enhance
arithmetic performance. Our approach achieved the 2nd place in Track 2 and 5th
place in Track 5 at the Amazon KDD Cup'24
\href{https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms}.
Additionally, our solution is model-agnostic, enabling effective scalability
across larger systems.",2024-08-06,"Zhaopeng Feng, Zijie Meng, Zuozhu Liu",http://arxiv.org/pdf/2408.02970v1,cs.CL
Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval,"Large language models (LLMs) are fundamentally transforming human-facing
applications in the health and well-being domains: boosting patient engagement,
accelerating clinical decision-making, and facilitating medical education.
Although state-of-the-art LLMs have shown superior performance in several
conversational applications, evaluations within nutrition and diet applications
are still insufficient. In this paper, we propose to employ the Registered
Dietitian (RD) exam to conduct a standard and comprehensive evaluation of
state-of-the-art LLMs, GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, assessing
both accuracy and consistency in nutrition queries. Our evaluation includes
1050 RD exam questions encompassing several nutrition topics and proficiency
levels. In addition, for the first time, we examine the impact of Zero-Shot
(ZS), Chain of Thought (CoT), Chain of Thought with Self Consistency (CoT-SC),
and Retrieval Augmented Prompting (RAP) on both accuracy and consistency of the
responses. Our findings revealed that while these LLMs obtained acceptable
overall performance, their results varied considerably with different prompts
and question domains. GPT-4o with CoT-SC prompting outperformed the other
approaches, whereas Gemini 1.5 Pro with ZS recorded the highest consistency.
For GPT-4o and Claude 3.5, CoT improved the accuracy, and CoT-SC improved both
accuracy and consistency. RAP was particularly effective for GPT-4o to answer
Expert level questions. Consequently, choosing the appropriate LLM and
prompting technique, tailored to the proficiency level and specific domain, can
mitigate errors and potential risks in diet and nutrition chatbots.",2024-08-06,"Iman Azimi, Mohan Qi, Li Wang, Amir M. Rahmani, Youlin Li",http://arxiv.org/pdf/2408.02964v2,cs.CL
Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality,"People tend to use language to mention surprising properties of events: for
example, when a banana is blue, we are more likely to mention color than when
it is yellow. This fact is taken to suggest that yellowness is somehow a
typical feature of bananas, and blueness is exceptional. Similar to how a
yellow color is typical of bananas, there may also be genders that are typical
of occupations. In this work, we explore this question using information
theoretic techniques coupled with corpus statistic analysis. In two distinct
large corpora, we do not find strong evidence that occupations and gender
display the same patterns of mentioning as do bananas and color. Instead, we
find that gender mentioning is correlated with femaleness of occupation in
particular, suggesting perhaps that woman-dominated occupations are seen as
somehow ``more gendered'' than male-dominated ones, and thereby they encourage
more gender mentioning overall.",2024-08-06,"Da Ju, Karen Ulrich, Adina Williams",http://arxiv.org/pdf/2408.02948v1,cs.CL
Self-Supervised Learning for Multi-Channel Neural Transducer,"Self-supervised learning, such as with the wav2vec 2.0 framework
significantly improves the accuracy of end-to-end automatic speech recognition
(ASR). Wav2vec 2.0 has been applied to single-channel end-to-end ASR models. In
this work, we explored a self-supervised learning method for a multi-channel
end-to-end ASR model based on the wav2vec 2.0 framework. As the multi-channel
end-to-end ASR model, we focused on a multi-channel neural transducer. In
pre-training, we compared three different methods for feature quantization to
train a multi-channel conformer audio encoder: joint quantization, feature-wise
quantization and channel-wise quantization. In fine-tuning, we trained the
multi-channel conformer-transducer. All experiments were conducted using the
far-field in-house and CHiME-4 datasets. The results of the experiments showed
that feature-wise quantization was the most effective among the methods. We
observed a 66% relative reduction in character error rate compared with the
model without any pre-training for the far-field in-house dataset.",2024-08-06,Atsushi Kojima,http://arxiv.org/pdf/2408.02945v1,cs.CL
HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection,"Data serves as the fundamental foundation for advancing deep learning,
particularly tabular data presented in a structured format, which is highly
conducive to modeling. However, even in the era of LLM, obtaining tabular data
from sensitive domains remains a challenge due to privacy or copyright
concerns. Hence, exploring how to effectively use models like LLMs to generate
realistic and privacy-preserving synthetic tabular data is urgent. In this
paper, we take a step forward to explore LLMs for tabular data synthesis and
privacy protection, by introducing a new framework HARMONIC for tabular data
generation and evaluation. In the tabular data generation of our framework,
unlike previous small-scale LLM-based methods that rely on continued
pre-training, we explore the larger-scale LLMs with fine-tuning to generate
tabular data and enhance privacy. Based on idea of the k-nearest neighbors
algorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to
discover inter-row relationships. Then, with fine-tuning, LLMs are trained to
remember the format and connections of the data rather than the data itself,
which reduces the risk of privacy leakage. In the evaluation part of our
framework, we develop specific privacy risk metrics DLT for LLM synthetic data
generation, as well as performance evaluation metrics LLE for downstream LLM
tasks. Our experiments find that this tabular data generation framework
achieves equivalent performance to existing methods with better privacy, which
also demonstrates our evaluation framework for the effectiveness of synthetic
data and privacy risks in LLM scenarios.",2024-08-06,"Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang",http://arxiv.org/pdf/2408.02927v1,cs.CL
Intermediate direct preference optimization,"We propose the intermediate direct preference optimization (DPO) method to
calculate the DPO loss at selected intermediate layers as an auxiliary loss for
finetuning large language models (LLMs). The conventional DPO method fine-tunes
a supervised fine-tuning (SFT) model by calculating the DPO loss using logits
from the final layer. In our intermediate DPO approach, DPO losses are
calculated using the logits from K-selected intermediate layers and averaged to
obtain the intermediate DPO loss. For training the intermediate DPO model, the
final loss is obtained by calculating the weighted sum of the DPO and
intermediate DPO losses. During inference, the intermediate DPO model decodes
using the final layer logits similarly to the conventional DPO model. In
experiments using the ultrafeedback dataset, the performance of the
intermediate DPO model was evaluated using GPT-4. As a result, the intermediate
DPO model trained using the intermediate DPO loss calculated at the 22nd layer
of a 32-layer SFT model achieved win rates of 52.5% and 67.5% against the
conventional DPO and SFT models, respectively, demonstrating the effectiveness
of the proposed method. Furthermore, we report the relationships among the
position of the selected intermediate layers, the number of layers, and
performance.",2024-08-06,Atsushi Kojima,http://arxiv.org/pdf/2408.02923v1,cs.CL
Data Checklist: On Unit-Testing Datasets with Usable Information,"Model checklists (Ribeiro et al., 2020) have emerged as a useful tool for
understanding the behavior of LLMs, analogous to unit-testing in software
engineering. However, despite datasets being a key determinant of model
behavior, evaluating datasets, e.g., for the existence of annotation artifacts,
is largely done ad hoc, once a problem in model behavior has already been found
downstream. In this work, we take a more principled approach to unit-testing
datasets by proposing a taxonomy based on the V-information literature. We call
a collection of such unit tests a data checklist. Using a checklist, not only
are we able to recover known artifacts in well-known datasets such as SNLI, but
we also discover previously unknown artifacts in preference datasets for LLM
alignment. Data checklists further enable a new kind of data filtering, which
we use to improve the efficacy and data efficiency of preference alignment.",2024-08-06,"Heidi C. Zhang, Shabnam Behzad, Kawin Ethayarajh, Dan Jurafsky",http://arxiv.org/pdf/2408.02919v1,cs.CL
Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering,"Retrieving external knowledge and prompting large language models with
relevant information is an effective paradigm to enhance the performance of
question-answering tasks. Previous research typically handles paragraphs from
external documents in isolation, resulting in a lack of context and ambiguous
references, particularly in multi-document and complex tasks. To overcome these
challenges, we propose a new retrieval framework IIER, that leverages
Inter-chunk Interactions to Enhance Retrieval. This framework captures the
internal connections between document chunks by considering three types of
interactions: structural, keyword, and semantic. We then construct a unified
Chunk-Interaction Graph to represent all external documents comprehensively.
Additionally, we design a graph-based evidence chain retriever that utilizes
previous paths and chunk interactions to guide the retrieval process. It
identifies multiple seed nodes based on the target question and iteratively
searches for relevant chunks to gather supporting evidence. This retrieval
process refines the context and reasoning chain, aiding the large language
model in reasoning and answer generation. Extensive experiments demonstrate
that IIER outperforms strong baselines across four datasets, highlighting its
effectiveness in improving retrieval and reasoning capabilities.",2024-08-06,"Tiezheng Guo, Chen Wang, Yanyi Liu, Jiawei Tang, Pan Li, Sai Xu, Qingwen Yang, Xianlin Gao, Zhi Li, Yingyou Wen",http://arxiv.org/pdf/2408.02907v1,cs.CL
Lighthouse: A User-Friendly Library for Reproducible Video Moment Retrieval and Highlight Detection,"We propose Lighthouse, a user-friendly library for reproducible video moment
retrieval and highlight detection (MR-HD). Although researchers proposed
various MR-HD approaches, the research community holds two main issues. The
first is a lack of comprehensive and reproducible experiments across various
methods, datasets, and video-text features. This is because no unified training
and evaluation codebase covers multiple settings. The second is user-unfriendly
design. Because previous works use different libraries, researchers set up
individual environments. In addition, most works release only the training
codes, requiring users to implement the whole inference process of MR-HD.
Lighthouse addresses these issues by implementing a unified reproducible
codebase that includes six models, three features, and five datasets. In
addition, it provides an inference API and web demo to make these methods
easily accessible for researchers and developers. Our experiments demonstrate
that Lighthouse generally reproduces the reported scores in the reference
papers. The code is available at https://github.com/line/lighthouse.",2024-08-06,"Taichi Nishimura, Shota Nakada, Hokuto Munakata, Tatsuya Komatsu",http://arxiv.org/pdf/2408.02901v3,cs.CL
Citekit: A Modular Toolkit for Large Language Model Citation Generation,"Enabling Large Language Models (LLMs) to generate citations in
Question-Answering (QA) tasks is an emerging paradigm aimed at enhancing the
verifiability of their responses when LLMs are utilizing external references to
generate an answer. However, there is currently no unified framework to
standardize and fairly compare different citation generation methods, leading
to difficulties in reproducing different methods and a comprehensive
assessment. To cope with the problems above, we introduce \name, an open-source
and modular toolkit designed to facilitate the implementation and evaluation of
existing citation generation methods, while also fostering the development of
new approaches to improve citation quality in LLM outputs. This tool is highly
extensible, allowing users to utilize 4 main modules and 14 components to
construct a pipeline, evaluating an existing method or innovative designs. Our
experiments with two state-of-the-art LLMs and 11 citation generation baselines
demonstrate varying strengths of different modules in answer accuracy and
citation quality improvement, as well as the challenge of enhancing
granularity. Based on our analysis of the effectiveness of components, we
propose a new method, self-RAG \snippet, obtaining a balanced answer accuracy
and citation quality. Citekit is released at
https://github.com/SjJ1017/Citekit.",2024-08-06,"Jiajun Shen, Tong Zhou, Yubo Chen, Kang Liu",http://arxiv.org/pdf/2408.04662v2,cs.CL
SETN: Stock Embedding Enhanced with Textual and Network Information,"Stock embedding is a method for vector representation of stocks. There is a
growing demand for vector representations of stock, i.e., stock embedding, in
wealth management sectors, and the method has been applied to various tasks
such as stock price prediction, portfolio optimization, and similar fund
identifications. Stock embeddings have the advantage of enabling the
quantification of relative relationships between stocks, and they can extract
useful information from unstructured data such as text and network data. In
this study, we propose stock embedding enhanced with textual and network
information (SETN) using a domain-adaptive pre-trained transformer-based model
to embed textual information and a graph neural network model to grasp network
information. We evaluate the performance of our proposed model on related
company information extraction tasks. We also demonstrate that stock embeddings
obtained from the proposed model perform better in creating thematic funds than
those obtained from baseline methods, providing a promising pathway for various
applications in the wealth management industry.",2024-08-06,"Takehiro Takayanagi, Hiroki Sakaji, Kiyoshi Izumi",http://arxiv.org/pdf/2408.02899v1,cs.CL
VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge,"The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.",2024-08-05,"Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao",http://arxiv.org/pdf/2408.02865v1,cs.CL
A Framework for Fine-Tuning LLMs using Heterogeneous Feedback,"Large language models (LLMs) have been applied to a wide range of tasks,
including text summarization, web navigation, and chatbots. They have
benefitted from supervised fine-tuning (SFT) and reinforcement learning from
human feedback (RLHF) following an unsupervised pretraining. These datasets can
be difficult to collect, limited in scope, and vary in sample quality.
Additionally, datasets can vary extensively in supervision format, from
numerical to binary as well as multi-dimensional with many different values. We
present a framework for fine-tuning LLMs using heterogeneous feedback, which
has two main components. First, we combine the heterogeneous feedback data into
a single supervision format, compatible with methods like SFT and RLHF. Next,
given this unified feedback dataset, we extract a high-quality and diverse
subset to obtain performance increases potentially exceeding the full dataset.
We conduct extensive experiments to understand the effectiveness of these
techniques for incorporating heterogeneous feedback, and demonstrate
improvements from using a high-quality and diverse subset of the data. We find
that our framework is able to improve models in multiple areas simultaneously,
such as in instruction following and bias reduction.",2024-08-05,"Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka",http://arxiv.org/pdf/2408.02861v1,cs.CL
MaterioMiner -- An ontology-based text mining dataset for extraction of process-structure-property entities,"While large language models learn sound statistical representations of the
language and information therein, ontologies are symbolic knowledge
representations that can complement the former ideally. Research at this
critical intersection relies on datasets that intertwine ontologies and text
corpora to enable training and comprehensive benchmarking of neurosymbolic
models. We present the MaterioMiner dataset and the linked materials mechanics
ontology where ontological concepts from the mechanics of materials domain are
associated with textual entities within the literature corpus. Another
distinctive feature of the dataset is its eminently fine-granular annotation.
Specifically, 179 distinct classes are manually annotated by three raters
within four publications, amounting to a total of 2191 entities that were
annotated and curated. Conceptual work is presented for the symbolic
representation of causal composition-process-microstructure-property
relationships. We explore the annotation consistency between the three raters
and perform fine-tuning of pre-trained models to showcase the feasibility of
named-entity recognition model training. Reusing the dataset can foster
training and benchmarking of materials language models, automated ontology
construction, and knowledge graph generation from textual data.",2024-08-05,"Ali Riza Durmaz, Akhil Thomas, Lokesh Mishra, Rachana Niranjan Murthy, Thomas Straub",http://arxiv.org/pdf/2408.04661v1,cs.CL
Interpretation of the Intent Detection Problem as Dynamics in a Low-dimensional Space,"Intent detection is a text classification task whose aim is to recognize and
label the semantics behind a users query. It plays a critical role in various
business applications. The output of the intent detection module strongly
conditions the behavior of the whole system. This sequence analysis task is
mainly tackled using deep learning techniques. Despite the widespread use of
these techniques, the internal mechanisms used by networks to solve the problem
are poorly understood. Recent lines of work have analyzed the computational
mechanisms learned by RNNs from a dynamical systems perspective. In this work,
we investigate how different RNN architectures solve the SNIPS intent detection
problem. Sentences injected into trained networks can be interpreted as
trajectories traversing a hidden state space. This space is constrained to a
low-dimensional manifold whose dimensionality is related to the embedding and
hidden layer sizes. To generate predictions, RNN steers the trajectories
towards concrete regions, spatially aligned with the output layer matrix rows
directions. Underlying the system dynamics, an unexpected fixed point topology
has been identified with a limited number of attractors. Our results provide
new insights into the inner workings of networks that solve the intent
detection task.",2024-08-05,"Eduardo Sanchez-Karhunen, Jose F. Quesada-Moreno, Miguel A. Gutiérrez-Naranjo",http://arxiv.org/pdf/2408.02838v1,cs.CL
"Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models","As the performance of larger, newer Large Language Models continues to
improve for strategic Theory of Mind (ToM) tasks, the demand for these
state-of-the-art models increases commensurately. However, their deployment is
costly both in terms of processing power and time. In this paper, we
investigate the feasibility of creating smaller, highly-performing specialized
algorithms by way of fine-tuning. To do this, we first present a large
pre-trained model with 20 unique scenarios that combine different social
contexts with games of varying social dilemmas, record its answers, and use
them for Q&A fine-tuning on a smaller model of the same family. Our focus is on
in-context game-theoretic decision-making, the same domain within which human
interaction occurs and that requires both a theory of mind (or a semblance
thereof) and an understanding of social dynamics. The smaller model is
therefore trained not just on the answers provided, but also on the motivations
provided by the larger model, which should contain advice and guidelines to
navigate both strategic dilemmas and social cues. We find that the fine-tuned
smaller language model consistently bridged the gap in performance between the
smaller pre-trained version of the model and its larger relative and that its
improvements extended in areas and contexts beyond the ones provided in the
training examples, including on out-of-sample scenarios that include completely
different game structures. On average for all games, through fine-tuning, the
smaller model showed a 46% improvement measured as alignment towards the
behavior of the larger model, with 100% representing indistinguishable
behavior. When presented with out-of-sample social contexts and games, the
fine-tuned model still displays remarkable levels of alignment, reaching an
improvement of 18% and 28% respectively.",2024-08-05,"Nunzio Lore, Sepehr Ilami, Babak Heydari",http://arxiv.org/pdf/2408.05241v4,cs.CL
miniCTX: Neural Theorem Proving with (Long-)Contexts,"Real-world formal theorem proving often depends on a wealth of context,
including definitions, lemmas, comments, file structure, and other information.
We introduce miniCTX, which tests a model's ability to prove formal
mathematical theorems that depend on new context that is not seen during
training. miniCTX contains theorems sourced from real Lean projects and
textbooks, each associated with a context that can span tens of thousands of
tokens. Models are tasked with proving a theorem given access to code from the
theorem's repository, which contains context that is needed for the proof. As a
baseline for miniCTX, we tested fine-tuning and prompting methods that
condition theorem proving on preceding context. Both approaches substantially
outperform traditional methods that rely solely on state information. We found
that this ability to use context is not captured by previous benchmarks such as
miniF2F. Alongside miniCTX, we offer ntp-toolkit for automatically extracting
and annotating theorem proving data, making it easy to add new projects into
miniCTX to ensure that contexts are not seen during training. miniCTX offers a
challenging and realistic evaluation of neural theorem provers.",2024-08-05,"Jiewen Hu, Thomas Zhu, Sean Welleck",http://arxiv.org/pdf/2408.03350v3,cs.CL
XMainframe: A Large Language Model for Mainframe Modernization,"Mainframe operating systems, despite their inception in the 1940s, continue
to support critical sectors like finance and government. However, these systems
are often viewed as outdated, requiring extensive maintenance and
modernization. Addressing this challenge necessitates innovative tools that can
understand and interact with legacy codebases. To this end, we introduce
XMainframe, a state-of-the-art large language model (LLM) specifically designed
with knowledge of mainframe legacy systems and COBOL codebases. Our solution
involves the creation of an extensive data collection pipeline to produce
high-quality training datasets, enhancing XMainframe's performance in this
specialized domain. Additionally, we present MainframeBench, a comprehensive
benchmark for assessing mainframe knowledge, including multiple-choice
questions, question answering, and COBOL code summarization. Our empirical
evaluations demonstrate that XMainframe consistently outperforms existing
state-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30%
higher accuracy than DeepSeek-Coder on multiple-choice questions, doubles the
BLEU score of Mixtral-Instruct 8x7B on question answering, and scores six times
higher than GPT-3.5 on COBOL summarization. Our work highlights the potential
of XMainframe to drive significant advancements in managing and modernizing
legacy systems, thereby enhancing productivity and saving time for software
developers.",2024-08-05,"Anh T. V. Dau, Hieu Trung Dao, Anh Tuan Nguyen, Hieu Trung Tran, Phong X. Nguyen, Nghi D. Q. Bui",http://arxiv.org/pdf/2408.04660v3,cs.CL
Examining Gender and Power on Wikipedia Through Face and Politeness,"We propose a framework for analyzing discourse by combining two
interdependent concepts from sociolinguistic theory: face acts and politeness.
While politeness has robust existing tools and data, face acts are less
resourced. We introduce a new corpus created by annotating Wikipedia talk pages
with face acts and we use this to train a face act tagger. We then employ our
framework to study how face and politeness interact with gender and power in
discussions between Wikipedia editors. Among other findings, we observe that
female Wikipedians are not only more polite, which is consistent with prior
studies, but that this difference corresponds with significantly more language
directed at humbling aspects of their own face. Interestingly, the distinction
nearly vanishes once limiting to editors with administrative power.",2024-08-05,"Adil Soubki, Shyne Choi, Owen Rambow",http://arxiv.org/pdf/2408.02798v1,cs.CL
Entity Retrieval for Answering Entity-Centric Questions,"The similarity between the question and indexed documents is a crucial factor
in document retrieval for retrieval-augmented question answering. Although this
is typically the only method for obtaining the relevant documents, it is not
the sole approach when dealing with entity-centric questions. In this study, we
propose Entity Retrieval, a novel retrieval method which rather than relying on
question-document similarity, depends on the salient entities within the
question to identify the retrieval documents. We conduct an in-depth analysis
of the performance of both dense and sparse retrieval methods in comparison to
Entity Retrieval. Our findings reveal that our method not only leads to more
accurate answers to entity-centric questions but also operates more
efficiently.",2024-08-05,"Hassan S. Shavarani, Anoop Sarkar",http://arxiv.org/pdf/2408.02795v1,cs.CL
LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory,"Humans are not homo economicus (i.e., rational economic beings). As humans,
we exhibit systematic behavioral biases such as loss aversion, anchoring,
framing, etc., which lead us to make suboptimal economic decisions. Insofar as
such biases may be embedded in text data on which large language models (LLMs)
are trained, to what extent are LLMs prone to the same behavioral biases?
Understanding these biases in LLMs is crucial for deploying LLMs to support
human decision-making. We propose utility theory-a paradigm at the core of
modern economic theory-as an approach to evaluate the economic biases of LLMs.
Utility theory enables the quantification and comparison of economic behavior
against benchmarks such as perfect rationality or human behavior. To
demonstrate our approach, we quantify and compare the economic behavior of a
variety of open- and closed-source LLMs. We find that the economic behavior of
current LLMs is neither entirely human-like nor entirely economicus-like. We
also find that most current LLMs struggle to maintain consistent economic
behavior across settings. Finally, we illustrate how our approach can measure
the effect of interventions such as prompting on economic biases.",2024-08-05,"Jillian Ross, Yoon Kim, Andrew W. Lo",http://arxiv.org/pdf/2408.02784v1,cs.CL
The Mechanics of Conceptual Interpretation in GPT Models: Interpretative Insights,"Locating and editing knowledge in large language models (LLMs) is crucial for
enhancing their accuracy, safety, and inference rationale. We introduce
``concept editing'', an innovative variation of knowledge editing that uncovers
conceptualisation mechanisms within these models. Using the reverse dictionary
task, inference tracing, and input abstraction, we analyse the Multi-Layer
Perceptron (MLP), Multi-Head Attention (MHA), and hidden state components of
transformer models. Our results reveal distinct patterns: MLP layers employ
key-value retrieval mechanism and context-dependent processing, which are
highly associated with relative input tokens. MHA layers demonstrate a
distributed nature with significant higher-level activations, suggesting
sophisticated semantic integration. Hidden states emphasise the importance of
the last token and top layers in the inference process. We observe evidence of
gradual information building and distributed representation. These observations
elucidate how transformer models process semantic information, paving the way
for targeted interventions and improved interpretability techniques. Our work
highlights the complex, layered nature of semantic processing in LLMs and the
challenges of isolating and modifying specific concepts within these models.",2024-08-05,"Nura Aljaafari, Danilo S. Carvalho, André Freitas",http://arxiv.org/pdf/2408.11827v1,cs.CL
Self-Taught Evaluators,"Model-based evaluation is at the heart of successful model development -- as
a reward model for training, and as a replacement for human evaluation. To
train such evaluators, the standard approach is to collect a large amount of
human preference judgments over model responses, which is costly and the data
becomes stale as models improve. In this work, we present an approach that aims
to im-prove evaluators without human annotations, using synthetic training data
only. Starting from unlabeled instructions, our iterative self-improvement
scheme generates contrasting model outputs and trains an LLM-as-a-Judge to
produce reasoning traces and final judgments, repeating this training at each
new iteration using the improved predictions. Without any labeled preference
data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)
from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms
commonly used LLM judges such as GPT-4 and matches the performance of the
top-performing reward models trained with labeled examples.",2024-08-05,"Tianlu Wang, Ilia Kulikov, Olga Golovneva, Ping Yu, Weizhe Yuan, Jane Dwivedi-Yu, Richard Yuanzhe Pang, Maryam Fazel-Zarandi, Jason Weston, Xian Li",http://arxiv.org/pdf/2408.02666v2,cs.CL
Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?,"Large Language Models (LLMs) have demonstrated impressive capabilities in
natural language tasks, but their safety and morality remain contentious due to
their training on internet text corpora. To address these concerns, alignment
techniques have been developed to improve the public usability and safety of
LLMs. Yet, the potential for generating harmful content through these models
seems to persist. This paper explores the concept of jailbreaking
LLMs-reversing their alignment through adversarial triggers. Previous methods,
such as soft embedding prompts, manually crafted prompts, and gradient-based
automatic prompts, have had limited success on black-box models due to their
requirements for model access and for producing a low variety of manually
crafted prompts, making them susceptible to being blocked. This paper
introduces a novel approach using reinforcement learning to optimize
adversarial triggers, requiring only inference API access to the target model
and a small surrogate model. Our method, which leverages a BERTScore-based
reward function, enhances the transferability and effectiveness of adversarial
triggers on new black-box models. We demonstrate that this approach improves
the performance of adversarial triggers on a previously untested language
model.",2024-08-05,"Mohammad Bahrami Karkevandi, Nishant Vishwamitra, Peyman Najafirad",http://arxiv.org/pdf/2408.02651v1,cs.CL
Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models,"In today's globalized economy, comprehensive supply chain visibility is
crucial for effective risk management. Achieving visibility remains a
significant challenge due to limited information sharing among supply chain
partners. This paper presents a novel framework leveraging Knowledge Graphs
(KGs) and Large Language Models (LLMs) to enhance supply chain visibility
without relying on direct stakeholder information sharing. Our zero-shot,
LLM-driven approach automates the extraction of supply chain information from
diverse public sources and constructs KGs to capture complex interdependencies
between supply chain entities. We employ zero-shot prompting for Named Entity
Recognition (NER) and Relation Extraction (RE) tasks, eliminating the need for
extensive domain-specific training. We validate the framework with a case study
on electric vehicle supply chains, focusing on tracking critical minerals for
battery manufacturing. Results show significant improvements in supply chain
mapping, extending visibility beyond tier-2 suppliers. The framework reveals
critical dependencies and alternative sourcing options, enhancing risk
management and strategic planning. With high accuracy in NER and RE tasks, it
provides an effective tool for understanding complex, multi-tiered supply
networks. This research offers a scalable, flexible method for constructing
domain-specific supply chain KGs, addressing longstanding challenges in
visibility and paving the way for advancements in digital supply chain
surveillance.",2024-08-05,"Sara AlMahri, Liming Xu, Alexandra Brintrup",http://arxiv.org/pdf/2408.07705v1,cs.CL
SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models,"As large language models (LLMs) continue to advance in capability and
influence, ensuring their security and preventing harmful outputs has become
crucial. A promising approach to address these concerns involves training
models to automatically generate adversarial prompts for red teaming. However,
the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness
of current adversarial methods, which struggle to specifically target and
explore the weaknesses of these models. To tackle these challenges, we
introduce the $\mathbf{S}\text{elf-}\mathbf{E}\text{volving
}\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$
optimization framework, which enhances security by leveraging data generated by
the model itself. SEAS operates through three iterative stages: Initialization,
Attack, and Adversarial Optimization, refining both the Red Team and Target
models to improve robustness and safety. This framework reduces reliance on
manual testing and significantly enhances the security capabilities of LLMs.
Our contributions include a novel adversarial framework, a comprehensive safety
dataset, and after three iterations, the Target model achieves a security level
comparable to GPT-4, while the Red Team model shows a marked increase in attack
success rate (ASR) against advanced models. Our code and datasets are released
at https://SEAS-LLM.github.io/.",2024-08-05,"Muxi Diao, Rumei Li, Shiyang Liu, Guogang Liao, Jingang Wang, Xunliang Cai, Weiran Xu",http://arxiv.org/pdf/2408.02632v2,cs.CL
Language Model Can Listen While Speaking,"Dialogue serves as the most natural manner of human-computer interaction
(HCI). Recent advancements in speech language models (SLM) have significantly
enhanced speech-based conversational AI. However, these models are limited to
turn-based conversation, lacking the ability to interact with humans in
real-time spoken scenarios, for example, being interrupted when the generated
content is not satisfactory. To address these limitations, we explore full
duplex modeling (FDM) in interactive speech language models (iSLM), focusing on
enhancing real-time interaction and, more explicitly, exploring the
quintessential ability of interruption. We introduce a novel model design,
namely listening-while-speaking language model (LSLM), an end-to-end system
equipped with both listening and speaking channels. Our LSLM employs a
token-based decoder-only TTS for speech generation and a streaming
self-supervised learning (SSL) encoder for real-time audio input. LSLM fuses
both channels for autoregressive generation and detects turn-taking in real
time. Three fusion strategies -- early fusion, middle fusion, and late fusion
-- are explored, with middle fusion achieving an optimal balance between speech
generation and real-time interaction. Two experimental settings, command-based
FDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity
to diverse instructions. Our results highlight LSLM's capability to achieve
duplex communication with minimal impact on existing systems. This study aims
to advance the development of interactive speech dialogue systems, enhancing
their applicability in real-world contexts.",2024-08-05,"Ziyang Ma, Yakun Song, Chenpeng Du, Jian Cong, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen",http://arxiv.org/pdf/2408.02622v1,cs.CL
BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba,"The advancement of natural language processing (NLP) in biology hinges on
models' ability to interpret intricate biomedical literature. Traditional
models often struggle with the complex and domain-specific language in this
field. In this paper, we present BioMamba, a pre-trained model specifically
designed for biomedical text mining. BioMamba builds upon the Mamba
architecture and is pre-trained on an extensive corpus of biomedical
literature. Our empirical studies demonstrate that BioMamba significantly
outperforms models like BioBERT and general-domain Mamba across various
biomedical tasks. For instance, BioMamba achieves a 100 times reduction in
perplexity and a 4 times reduction in cross-entropy loss on the BioASQ test
set. We provide an overview of the model architecture, pre-training process,
and fine-tuning techniques. Additionally, we release the code and trained model
to facilitate further research.",2024-08-05,"Ling Yue, Sixue Xing, Yingzhou Lu, Tianfan Fu",http://arxiv.org/pdf/2408.02600v1,cs.CL
Progressively Label Enhancement for Large Language Model Alignment,"Large Language Models (LLM) alignment aims to prevent models from producing
content that misaligns with human expectations, which can lead to ethical and
legal concerns. In the last few years, Reinforcement Learning from Human
Feedback (RLHF) has been the most prominent method for achieving alignment. Due
to challenges in stability and scalability with RLHF stages, which arise from
the complex interactions between multiple models, researchers are exploring
alternative methods to achieve effects comparable to those of RLHF. However,
these methods often rely on large high-quality datasets. Despite some methods
considering the generation of additional data to expand datasets, they often
treat model training and data generation as separate and static processes,
overlooking the fact that these processes are highly interdependent, leading to
inefficient utilization of the generated data. To deal with this problem, we
propose PLE, i.e., Progressively Label Enhancement for LLM Alignment, a
framework that dynamically adjusts the model's training process based on the
evolving quality of the generated data. Specifically, we prompt the model to
generate responses for both the original query and the query guided by a set of
carefully designed principles, and then utilize a dynamic threshold to
determine the appropriate training approach for both responses based on their
corresponding reward scores. Experimental results demonstrate the effectiveness
of PLE compared to existing LLM alignment methods.",2024-08-05,"Biao Liu, Ning Xu, Xin Geng",http://arxiv.org/pdf/2408.02599v2,cs.CL
Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization,"The ever-increasing volume of digital information necessitates efficient
methods for users to extract key insights from lengthy documents. Aspect-based
summarization offers a targeted approach, generating summaries focused on
specific aspects within a document. Despite advancements in aspect-based
summarization research, there is a continuous quest for improved model
performance. Given that large language models (LLMs) have demonstrated the
potential to revolutionize diverse tasks within natural language processing,
particularly in the problem of summarization, this paper explores the potential
of fine-tuning LLMs for the aspect-based summarization task. We evaluate the
impact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,
Gemma and Aya, on a publicly available domain-specific aspect based summary
dataset. We hypothesize that this approach will enable these models to
effectively identify and extract aspect-related information, leading to
superior quality aspect-based summaries compared to the state-of-the-art. We
establish a comprehensive evaluation framework to compare the performance of
fine-tuned LLMs against competing aspect-based summarization methods and
vanilla counterparts of the fine-tuned LLMs. Our work contributes to the field
of aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs
for generating high-quality aspect-based summaries. Furthermore, it opens doors
for further exploration of using LLMs for targeted information extraction tasks
across various NLP domains.",2024-08-05,"Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Aditya Vempaty, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku",http://arxiv.org/pdf/2408.02584v1,cs.CL
Artificial Intelligence for Public Health Surveillance in Africa: Applications and Opportunities,"Artificial Intelligence (AI) is revolutionizing various fields, including
public health surveillance. In Africa, where health systems frequently
encounter challenges such as limited resources, inadequate infrastructure,
failed health information systems and a shortage of skilled health
professionals, AI offers a transformative opportunity. This paper investigates
the applications of AI in public health surveillance across the continent,
presenting successful case studies and examining the benefits, opportunities,
and challenges of implementing AI technologies in African healthcare settings.
Our paper highlights AI's potential to enhance disease monitoring and health
outcomes, and support effective public health interventions. The findings
presented in the paper demonstrate that AI can significantly improve the
accuracy and timeliness of disease detection and prediction, optimize resource
allocation, and facilitate targeted public health strategies. Additionally, our
paper identified key barriers to the widespread adoption of AI in African
public health systems and proposed actionable recommendations to overcome these
challenges.",2024-08-05,"Jean Marie Tshimula, Mitterrand Kalengayi, Dieumerci Makenga, Dorcas Lilonge, Marius Asumani, Déborah Madiya, Élie Nkuba Kalonji, Hugues Kanda, René Manassé Galekwa, Josias Kumbu, Hardy Mikese, Grace Tshimula, Jean Tshibangu Muabila, Christian N. Mayemba, D'Jeff K. Nkashama, Kalonji Kalala, Steve Ataky, Tighana Wenge Basele, Mbuyi Mukendi Didier, Selain K. Kasereka, Maximilien V. Dialufuma, Godwill Ilunga Wa Kumwita, Lionel Muyuku, Jean-Paul Kimpesa, Dominique Muteba, Aaron Aruna Abedi, Lambert Mukendi Ntobo, Gloria M. Bundutidi, Désiré Kulimba Mashinda, Emmanuel Kabengele Mpinga, Nathanaël M. Kasoro",http://arxiv.org/pdf/2408.02575v1,cs.CL
"VyAnG-Net: A Novel Multi-Modal Sarcasm Recognition Model by Uncovering Visual, Acoustic and Glossary Features","Various linguistic and non-linguistic clues, such as excessive emphasis on a
word, a shift in the tone of voice, or an awkward expression, frequently convey
sarcasm. The computer vision problem of sarcasm recognition in conversation
aims to identify hidden sarcastic, criticizing, and metaphorical information
embedded in everyday dialogue. Prior, sarcasm recognition has focused mainly on
text. Still, it is critical to consider all textual information, audio stream,
facial expression, and body position for reliable sarcasm identification.
Hence, we propose a novel approach that combines a lightweight depth attention
module with a self-regulated ConvNet to concentrate on the most crucial
features of visual data and an attentional tokenizer based strategy to extract
the most critical context-specific information from the textual data. The
following is a list of the key contributions that our experimentation has made
in response to performing the task of Multi-modal Sarcasm Recognition: an
attentional tokenizer branch to get beneficial features from the glossary
content provided by the subtitles; a visual branch for acquiring the most
prominent features from the video frames; an utterance-level feature extraction
from acoustic content and a multi-headed attention based feature fusion branch
to blend features obtained from multiple modalities. Extensive testing on one
of the benchmark video datasets, MUSTaRD, yielded an accuracy of 79.86% for
speaker dependent and 76.94% for speaker independent configuration
demonstrating that our approach is superior to the existing methods. We have
also conducted a cross-dataset analysis to test the adaptability of VyAnG-Net
with unseen samples of another dataset MUStARD++.",2024-08-05,"Ananya Pandey, Dinesh Kumar Vishwakarma",http://arxiv.org/pdf/2408.10246v1,cs.CL
Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information,"Large language models (LLMs) have shown success in handling simple games with
imperfect information and enabling multi-agent coordination, but their ability
to facilitate practical collaboration against other agents in complex,
imperfect information environments, especially in a non-English environment,
still needs to be explored. This study investigates the applicability of
knowledge acquired by open-source and API-based LLMs to sophisticated
text-based games requiring agent collaboration under imperfect information,
comparing their performance to established baselines using other types of
agents. We propose a Theory of Mind (ToM) planning technique that allows LLM
agents to adapt their strategy against various adversaries using only game
rules, current state, and historical context as input. An external tool was
incorporated to mitigate the challenge of dynamic and extensive action spaces
in this card game. Our results show that although a performance gap exists
between current LLMs and state-of-the-art reinforcement learning (RL) models,
LLMs demonstrate ToM capabilities in this game setting. It consistently
improves their performance against opposing agents, suggesting their ability to
understand the actions of allies and adversaries and establish collaboration
with allies. To encourage further research and understanding, we have made our
codebase openly accessible.",2024-08-05,"Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi Zheng, Yangqiu Song",http://arxiv.org/pdf/2408.02559v1,cs.CL
RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation,"Implementing Retrieval-Augmented Generation (RAG) systems is inherently
complex, requiring deep understanding of data, use cases, and intricate design
decisions. Additionally, evaluating these systems presents significant
challenges, necessitating assessment of both retrieval accuracy and generative
quality through a multi-faceted approach. We introduce RAG Foundry, an
open-source framework for augmenting large language models for RAG use cases.
RAG Foundry integrates data creation, training, inference and evaluation into a
single workflow, facilitating the creation of data-augmented datasets for
training and evaluating large language models in RAG settings. This integration
enables rapid prototyping and experimentation with various RAG techniques,
allowing users to easily generate datasets and train RAG models using internal
or specialized knowledge sources. We demonstrate the framework effectiveness by
augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG
configurations, showcasing consistent improvements across three
knowledge-intensive datasets. Code is released as open-source in
https://github.com/IntelLabs/RAGFoundry.",2024-08-05,"Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak",http://arxiv.org/pdf/2408.02545v1,cs.CL
Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions,"This paper investigates the faithfulness of multimodal large language model
(MLLM) agents in the graphical user interface (GUI) environment, aiming to
address the research question of whether multimodal GUI agents can be
distracted by environmental context. A general setting is proposed where both
the user and the agent are benign, and the environment, while not malicious,
contains unrelated content. A wide range of MLLMs are evaluated as GUI agents
using our simulated dataset, following three working patterns with different
levels of perception. Experimental results reveal that even the most powerful
models, whether generalist agents or specialist GUI agents, are susceptible to
distractions. While recent studies predominantly focus on the helpfulness
(i.e., action accuracy) of multimodal agents, our findings indicate that these
agents are prone to environmental distractions, resulting in unfaithful
behaviors. Furthermore, we switch to the adversarial perspective and implement
environment injection, demonstrating that such unfaithfulness can be exploited,
leading to unexpected risks.",2024-08-05,"Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, Hai Zhao",http://arxiv.org/pdf/2408.02544v1,cs.CL
OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar,"The FIFA World Cup in Qatar was discussed extensively in the news and on
social media. Due to news reports with allegations of human rights violations,
there were calls to boycott it. Wearing a OneLove armband was part of a planned
protest activity. Controversy around the armband arose when FIFA threatened to
sanction captains who wear it. To understand what topics Twitter users Tweeted
about and what the opinion of German Twitter users was towards the OneLove
armband, we performed an analysis of German Tweets published during the World
Cup using in-context learning with LLMs. We validated the labels on human
annotations. We found that Twitter users initially discussed the armband's
impact, LGBT rights, and politics; after the ban, the conversation shifted
towards politics in sports in general, accompanied by a subtle shift in
sentiment towards neutrality. Our evaluation serves as a framework for future
research to explore the impact of sports activism and evolving public
sentiment. This is especially useful in settings where labeling datasets for
specific opinions is unfeasible, such as when events are unfolding.",2024-08-05,"Christoph Rauchegger, Sonja Mei Wang, Pieter Delobelle",http://arxiv.org/pdf/2408.02520v1,cs.CL
Winning Amazon KDD Cup'24,"This paper describes the winning solution of all 5 tasks for the Amazon KDD
Cup 2024 Multi Task Online Shopping Challenge for LLMs. The challenge was to
build a useful assistant, answering questions in the domain of online shopping.
The competition contained 57 diverse tasks, covering 5 different task types
(e.g. multiple choice) and across 4 different tracks (e.g. multi-lingual). Our
solution is a single model per track. We fine-tune Qwen2-72B-Instruct on our
own training dataset. As the competition released only 96 example questions, we
developed our own training dataset by processing multiple public datasets or
using Large Language Models for data augmentation and synthetic data
generation. We apply wise-ft to account for distribution shifts and ensemble
multiple LoRA adapters in one model. We employed Logits Processors to constrain
the model output on relevant tokens for the tasks. AWQ 4-bit Quantization and
vLLM are used during inference to predict the test dataset in the time
constraints of 20 to 140 minutes depending on the track. Our solution achieved
the first place in each individual track and is the first place overall of
Amazons KDD Cup 2024.",2024-08-05,"Chris Deotte, Ivan Sorokin, Ahmet Erdem, Benedikt Schifferer, Gilberto Titericz Jr, Simon Jegou",http://arxiv.org/pdf/2408.04658v1,cs.CL
UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model,"Significant advancements has recently been achieved in the field of
multi-modal large language models (MLLMs), demonstrating their remarkable
capabilities in understanding and reasoning across diverse tasks. However,
these models are often trained for specific tasks and rely on task-specific
input-output formats, limiting their applicability to a broader range of tasks.
This raises a fundamental question: Can we develop a unified approach to
represent and handle different multi-modal tasks to maximize the
generalizability of MLLMs? In this paper, we propose UnifiedMLLM, a
comprehensive model designed to represent various tasks using a unified
representation. Our model exhibits strong capabilities in comprehending the
implicit intent of user instructions and preforming reasoning. In addition to
generating textual responses, our model also outputs task tokens and grounding
tokens, serving as indicators of task types and task granularity. These outputs
are subsequently routed through the task router and directed to specific expert
models for task completion. To train our model, we construct a task-specific
dataset and an 100k multi-task dataset encompassing complex scenarios.
Employing a three-stage training strategy, we equip our model with robust
reasoning and task processing capabilities while preserving its generalization
capacity and knowledge reservoir. Extensive experiments showcase the impressive
performance of our unified representation approach across various tasks,
surpassing existing methodologies. Furthermore, our approach exhibits
exceptional scalability and generality. Our code, model, and dataset will be
available at \url{https://github.com/lzw-lzw/UnifiedMLLM}.",2024-08-05,"Zhaowei Li, Wei Wang, YiQing Cai, Xu Qi, Pengyu Wang, Dong Zhang, Hang Song, Botian Jiang, Zhida Huang, Tao Wang",http://arxiv.org/pdf/2408.02503v1,cs.CL
"From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future","With the rise of large language models (LLMs), researchers are increasingly
exploring their applications in var ious vertical domains, such as software
engineering. LLMs have achieved remarkable success in areas including code
generation and vulnerability detection. However, they also exhibit numerous
limitations and shortcomings. LLM-based agents, a novel tech nology with the
potential for Artificial General Intelligence (AGI), combine LLMs as the core
for decision-making and action-taking, addressing some of the inherent
limitations of LLMs such as lack of autonomy and self-improvement. Despite
numerous studies and surveys exploring the possibility of using LLMs in
software engineering, it lacks a clear distinction between LLMs and LLM based
agents. It is still in its early stage for a unified standard and benchmarking
to qualify an LLM solution as an LLM-based agent in its domain. In this survey,
we broadly investigate the current practice and solutions for LLMs and
LLM-based agents for software engineering. In particular we summarise six key
topics: requirement engineering, code generation, autonomous decision-making,
software design, test generation, and software maintenance. We review and
differentiate the work of LLMs and LLM-based agents from these six topics,
examining their differences and similarities in tasks, benchmarks, and
evaluation metrics. Finally, we discuss the models and benchmarks used,
providing a comprehensive analysis of their applications and effectiveness in
software engineering. We anticipate this work will shed some lights on pushing
the boundaries of LLM-based agents in software engineering for future research.",2024-08-05,"Haolin Jin, Linghan Huang, Haipeng Cai, Jun Yan, Bo Li, Huaming Chen",http://arxiv.org/pdf/2408.02479v2,cs.CL
Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models,"Structured generation, the process of producing content in standardized
formats like JSON and XML, is widely utilized in real-world applications to
extract key output information from large language models (LLMs). This study
investigates whether such constraints on generation space impact LLMs
abilities, including reasoning and domain knowledge comprehension.
Specifically, we evaluate LLMs performance when restricted to adhere to
structured formats versus generating free-form responses across various common
tasks. Surprisingly, we observe a significant decline in LLMs reasoning
abilities under format restrictions. Furthermore, we find that stricter format
constraints generally lead to greater performance degradation in reasoning
tasks.",2024-08-05,"Zhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen",http://arxiv.org/pdf/2408.02442v3,cs.CL
Long Input Benchmark for Russian Analysis,"Recent advancements in Natural Language Processing (NLP) have fostered the
development of Large Language Models (LLMs) that can solve an immense variety
of tasks. One of the key aspects of their application is their ability to work
with long text documents and to process long sequences of tokens. This has
created a demand for proper evaluation of long-context understanding. To
address this need for the Russian language, we propose LIBRA (Long Input
Benchmark for Russian Analysis), which comprises 21 adapted datasets to study
the LLM's abilities to understand long texts thoroughly. The tests are divided
into four complexity groups and allow the evaluation of models across various
context lengths ranging from 4k up to 128k tokens. We provide the open-source
datasets, codebase, and public leaderboard for LIBRA to guide forthcoming
research.",2024-08-05,"Igor Churin, Murat Apishev, Maria Tikhonova, Denis Shevelev, Aydar Bulatov, Yuri Kuratov, Sergej Averkiev, Alena Fenogenova",http://arxiv.org/pdf/2408.02439v1,cs.CL
Towards Semantic Markup of Mathematical Documents via User Interaction,"Mathematical documents written in LaTeX often contain ambiguities. We can
resolve some of them via semantic markup using, e.g., sTeX, which also has
other potential benefits, such as interoperability with computer algebra
systems, proof systems, and increased accessibility. However, semantic markup
is more involved than ""regular"" typesetting and presents a challenge for
authors of mathematical documents. We aim to smooth out the transition from
plain LaTeX to semantic markup by developing semi-automatic tools for authors.
In this paper we present an approach to semantic markup of formulas by
(semi-)automatically generating grammars from existing sTeX macro definitions
and parsing mathematical formulas with them. We also present a GUI-based tool
for the disambiguation of parse results and showcase its functionality and
potential using a grammar for parsing untyped $\lambda$-terms.",2024-08-05,"Luka Vrečar, Joe Wells, Fairouz Kamareddine",http://arxiv.org/pdf/2408.04656v1,cs.CL
"Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation","Emotions are indispensable in human communication, but are often overlooked
in task-oriented dialogue (ToD) modelling, where the task success is the
primary focus. While existing works have explored user emotions or similar
concepts in some ToD tasks, none has so far included emotion modelling into a
fully-fledged ToD system nor conducted interaction with human or simulated
users. In this work, we incorporate emotion into the complete ToD processing
loop, involving understanding, management, and generation. To this end, we
extend the EmoWOZ dataset (Feng et al., 2022) with system affective behaviour
labels. Through interactive experimentation involving both simulated and human
users, we demonstrate that our proposed framework significantly enhances the
user's emotional experience as well as the task success.",2024-08-05,"Shutong Feng, Hsien-chin Lin, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Renato Vukovic, Milica Gašić",http://arxiv.org/pdf/2408.02417v1,cs.CL
Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models,"The drastic increase of large language models' (LLMs) parameters has led to a
new research direction of fine-tuning-free downstream customization by prompts,
i.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)
play an important role in many businesses, there has emerged growing concerns
about the prompt leakage, which undermines the intellectual properties of these
services and causes downstream attacks. In this paper, we analyze the
underlying mechanism of prompt leakage, which we refer to as prompt
memorization, and develop corresponding defending strategies. By exploring the
scaling laws in prompt extraction, we analyze key attributes that influence
prompt extraction, including model sizes, prompt lengths, as well as the types
of prompts. Then we propose two hypotheses that explain how LLMs expose their
prompts. The first is attributed to the perplexity, i.e. the familiarity of
LLMs to texts, whereas the second is based on the straightforward token
translation path in attention matrices. To defend against such threats, we
investigate whether alignments can undermine the extraction of prompts. We find
that current LLMs, even those with safety alignments like GPT-4, are highly
vulnerable to prompt extraction attacks, even under the most straightforward
user attacks. Therefore, we put forward several defense strategies with the
inspiration of our findings, which achieve 83.8\% and 71.0\% drop in the prompt
extraction rate for Llama2-7B and GPT-3.5, respectively. Source code is
avaliable at https://github.com/liangzid/PromptExtractionEval.",2024-08-05,"Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li",http://arxiv.org/pdf/2408.02416v2,cs.CL
Strong and weak alignment of large language models with human values,"Minimizing negative impacts of Artificial Intelligent (AI) systems on human
societies without human supervision requires them to be able to align with
human values. However, most current work only addresses this issue from a
technical point of view, e.g., improving current methods relying on
reinforcement learning from human feedback, neglecting what it means and is
required for alignment to occur. Here, we propose to distinguish strong and
weak value alignment. Strong alignment requires cognitive abilities (either
human-like or different from humans) such as understanding and reasoning about
agents' intentions and their ability to causally produce desired effects. We
argue that this is required for AI systems like large language models (LLMs) to
be able to recognize situations presenting a risk that human values may be
flouted. To illustrate this distinction, we present a series of prompts showing
ChatGPT's, Gemini's and Copilot's failures to recognize some of these
situations. We moreover analyze word embeddings to show that the nearest
neighbors of some human values in LLMs differ from humans' semantic
representations. We then propose a new thought experiment that we call ""the
Chinese room with a word transition dictionary"", in extension of John Searle's
famous proposal. We finally mention current promising research directions
towards a weak alignment, which could produce statistically satisfying answers
in a number of common situations, however so far without ensuring any truth
value.",2024-08-05,"Mehdi Khamassi, Marceau Nahon, Raja Chatila",http://arxiv.org/pdf/2408.04655v2,cs.CL
A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models,"Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.",2024-08-05,"Vanni Zavarella, Juan Carlos Gamero-Salinas, Sergio Consoli",http://arxiv.org/pdf/2408.02377v1,cs.CL
Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding,"State-of-the-art task-oriented dialogue systems typically rely on
task-specific ontologies for fulfilling user queries. The majority of
task-oriented dialogue data, such as customer service recordings, comes without
ontology and annotation. Such ontologies are normally built manually, limiting
the application of specialised systems. Dialogue ontology construction is an
approach for automating that process and typically consists of two steps: term
extraction and relation extraction. In this work, we focus on relation
extraction in a transfer learning set-up. To improve the generalisation, we
propose an extension to the decoding mechanism of large language models. We
adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning
problems, to generative relation extraction. Here, we generate multiple
branches in the decoding space and select the relations based on a confidence
threshold. By constraining the decoding to ontology terms and relations, we aim
to decrease the risk of hallucination. We conduct extensive experimentation on
two widely used datasets and find improvements in performance on target
ontology for source fine-tuned and one-shot prompted large language models.",2024-08-05,"Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Gašić",http://arxiv.org/pdf/2408.02361v2,cs.CL
An approach to optimize inference of the DIART speaker diarization pipeline,"Speaker diarization answers the question ""who spoke when"" for an audio file.
In some diarization scenarios, low latency is required for transcription.
Speaker diarization with low latency is referred to as online speaker
diarization. The DIART pipeline is an online speaker diarization system. It
consists of a segmentation and an embedding model. The embedding model has the
largest share of the overall latency. The aim of this paper is to optimize the
inference latency of the DIART pipeline. Different inference optimization
methods such as knowledge distilation, pruning, quantization and layer fusion
are applied to the embedding model of the pipeline. It turns out that knowledge
distillation optimizes the latency, but has a negative effect on the accuracy.
Quantization and layer fusion also have a positive influence on the latency
without worsening the accuracy. Pruning, on the other hand, does not improve
latency.",2024-08-05,"Roman Aperdannier, Sigurd Schacht, Alexander Piazza",http://arxiv.org/pdf/2408.02341v1,cs.CL
Batching BPE Tokenization Merges,"The Byte Pair Encoding algorithm can be safely batched to merge hundreds of
pairs of tokens at a time when building up a tokenizer's vocabulary. This
technique combined with reducing the memory footprint of text used in
vocabulary training make it feasible to train a high quality tokenizer on a
basic laptop. This paper presents BatchBPE, an open-source pure Python
implementation of these concepts, with the goal of making experimenting with
new tokenization strategies more accessible especially in compute- and
memory-constrained contexts. BatchBPE's usefulness and malleability are
demonstrated through the training of several token vocabularies to explore the
batch merging process and experiment with preprocessing a stop word list and
ignoring the least common text chunks in a dataset. Resultant encoded lengths
of texts are used as a basic evaluation metric.",2024-08-05,Alexander P. Morgan,http://arxiv.org/pdf/2408.04653v1,cs.CL
"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction","Advancements in AI and natural language processing have revolutionized
machine-human language interactions, with question answering (QA) systems
playing a pivotal role. The knowledge base question answering (KBQA) task,
utilizing structured knowledge graphs (KG), allows for handling extensive
knowledge-intensive questions. However, a significant gap exists in KBQA
datasets, especially for low-resource languages. Many existing construction
pipelines for these datasets are outdated and inefficient in human labor, and
modern assisting tools like Large Language Models (LLM) are not utilized to
reduce the workload. To address this, we have designed and implemented a
modern, semi-automated approach for creating datasets, encompassing tasks such
as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),
tailored explicitly for low-resource environments. We executed this pipeline
and introduced the PUGG dataset, the first Polish KBQA dataset, and novel
datasets for MRC and IR. Additionally, we provide a comprehensive
implementation, insightful findings, detailed statistics, and evaluation of
baseline models.",2024-08-05,"Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domogała, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz",http://arxiv.org/pdf/2408.02337v1,cs.CL
SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models,"Large language models (LLMs) have become powerful tools for advancing natural
language processing applications in the financial industry. However, existing
financial LLMs often face challenges such as hallucinations or superficial
parameter training, resulting in suboptimal performance, particularly in
financial computing and machine reading comprehension (MRC). To address these
issues, we propose a novel large language model specifically designed for the
Chinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific
tasks such as answering questions, summarizing financial research reports,
analyzing sentiment, and executing financial calculations. We then perform the
supervised fine-tuning (SFT) to enhance the model's proficiency across various
financial domains. Specifically, we gather extensive financial data and create
a high-quality instruction dataset composed of news articles, professional
papers, and research reports of finance domain. Utilizing both domain-specific
and general datasets, we proceed with continuous pre-training on an established
open-source base model, resulting in SNFinLLM-base. Following this, we engage
in supervised fine-tuning (SFT) to bolster the model's capability across
multiple financial tasks. Crucially, we employ a straightforward Direct
Preference Optimization (DPO) method to better align the model with human
preferences. Extensive experiments conducted on finance benchmarks and our
evaluation dataset demonstrate that SNFinLLM markedly outperforms other
state-of-the-art financial language models. For more details, check out our
demo video here: https://www.youtube.com/watch?v=GYT-65HZwus.",2024-08-05,"Shujuan Zhao, Lingfeng Qiao, Kangyang Luo, Qian-Wen Zhang, Junru Lu, Di Yin",http://arxiv.org/pdf/2408.02302v1,cs.CL
Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages,"Multilingual neural machine translation systems learn to map sentences of
different languages into a common representation space. Intuitively, with a
growing number of seen languages the encoder sentence representation grows more
flexible and easily adaptable to new languages. In this work, we test this
hypothesis by zero-shot translating from unseen languages. To deal with unknown
vocabularies from unknown languages we propose a setup where we decouple
learning of vocabulary and syntax, i.e. for each language we learn word
representations in a separate step (using cross-lingual word embeddings), and
then train to translate while keeping those word representations frozen. We
demonstrate that this setup enables zero-shot translation from entirely unseen
languages. Zero-shot translating with a model trained on Germanic and Romance
languages we achieve scores of 42.6 BLEU for Portuguese-English and 20.7 BLEU
for Russian-English on TED domain. We explore how this zero-shot translation
capability develops with varying number of languages seen by the encoder.
Lastly, we explore the effectiveness of our decoupled learning strategy for
unsupervised machine translation. By exploiting our model's zero-shot
translation capability for iterative back-translation we attain near parity
with a supervised setting.",2024-08-05,"Carlos Mullov, Ngoc-Quan Pham, Alexander Waibel",http://arxiv.org/pdf/2408.02290v1,cs.CL
Spin glass model of in-context learning,"Large language models show a surprising in-context learning ability -- being
able to use a prompt to form a prediction for a query, yet without additional
training, in stark contrast to old-fashioned supervised learning. Providing a
mechanistic interpretation and linking the empirical phenomenon to physics are
thus challenging and remain unsolved. We study a simple yet expressive
transformer with linear attention and map this structure to a spin glass model
with real-valued spins, where the couplings and fields explain the intrinsic
disorder in data. The spin glass model explains how the weight parameters
interact with each other during pre-training, and further clarifies why an
unseen function can be predicted by providing only a prompt yet without further
training. Our theory reveals that for single-instance learning, increasing the
task diversity leads to the emergence of in-context learning, by allowing the
Boltzmann distribution to converge to a unique correct solution of weight
parameters. Therefore the pre-trained transformer displays a prediction power
in a novel prompt setting. The proposed analytically tractable model thus
offers a promising avenue for thinking about how to interpret many intriguing
but puzzling properties of large language models.",2024-08-05,"Yuhao Li, Ruoran Bai, Haiping Huang",http://arxiv.org/pdf/2408.02288v3,cs.CL
COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark,"Procedural video understanding is gaining attention in the vision and
language community. Deep learning-based video analysis requires extensive data.
Consequently, existing works often use web videos as training resources, making
it challenging to query instructional contents from raw video observations. To
address this issue, we propose a new dataset, COM Kitchens. The dataset
consists of unedited overhead-view videos captured by smartphones, in which
participants performed food preparation based on given recipes. Fixed-viewpoint
video datasets often lack environmental diversity due to high camera setup
costs. We used modern wide-angle smartphone lenses to cover cooking counters
from sink to cooktop in an overhead view, capturing activity without in-person
assistance. With this setup, we collected a diverse dataset by distributing
smartphones to participants. With this dataset, we propose the novel
video-to-text retrieval task Online Recipe Retrieval (OnRR) and new video
captioning domain Dense Video Captioning on unedited Overhead-View videos
(DVC-OV). Our experiments verified the capabilities and limitations of current
web-video-based SOTA methods in handling these tasks.",2024-08-05,"Koki Maeda, Tosho Hirasawa, Atsushi Hashimoto, Jun Harashima, Leszek Rybicki, Yusuke Fukasawa, Yoshitaka Ushiku",http://arxiv.org/pdf/2408.02272v1,cs.CL
StyEmp: Stylizing Empathetic Response Generation via Multi-Grained Prefix Encoder and Personality Reinforcement,"Recent approaches for empathetic response generation mainly focus on
emotional resonance and user understanding, without considering the system's
personality. Consistent personality is evident in real human expression and is
important for creating trustworthy systems. To address this problem, we propose
StyEmp, which aims to stylize the empathetic response generation with a
consistent personality. Specifically, it incorporates a multi-grained prefix
mechanism designed to capture the intricate relationship between a system's
personality and its empathetic expressions. Furthermore, we introduce a
personality reinforcement module that leverages contrastive learning to
calibrate the generation model, ensuring that responses are both empathetic and
reflective of a distinct personality. Automatic and human evaluations on the
EMPATHETICDIALOGUES benchmark show that StyEmp outperforms competitive
baselines in terms of both empathy and personality expressions.",2024-08-05,"Yahui Fu, Chenhui Chu, Tatsuya Kawahara",http://arxiv.org/pdf/2408.02271v1,cs.CL
To Aggregate or Not to Aggregate. That is the Question: A Case Study on Annotation Subjectivity in Span Prediction,"This paper explores the task of automatic prediction of text spans in a legal
problem description that support a legal area label. We use a corpus of problem
descriptions written by laypeople in English that is annotated by practising
lawyers. Inherent subjectivity exists in our task because legal area
categorisation is a complex task, and lawyers often have different views on a
problem, especially in the face of legally-imprecise descriptions of issues.
Experiments show that training on majority-voted spans outperforms training on
disaggregated ones.",2024-08-05,"Kemal Kurniawan, Meladel Mistica, Timothy Baldwin, Jey Han Lau",http://arxiv.org/pdf/2408.02257v1,cs.CL
Advancing Post-OCR Correction: A Comparative Study of Synthetic Data,"This paper explores the application of synthetic data in the post-OCR domain
on multiple fronts by conducting experiments to assess the impact of data
volume, augmentation, and synthetic data generation methods on model
performance. Furthermore, we introduce a novel algorithm that leverages
computer vision feature detection algorithms to calculate glyph similarity for
constructing post-OCR synthetic data. Through experiments conducted across a
variety of languages, including several low-resource ones, we demonstrate that
models like ByT5 can significantly reduce Character Error Rates (CER) without
the need for manually annotated data, and our proposed synthetic data
generation method shows advantages over traditional methods, particularly in
low-resource languages.",2024-08-05,"Shuhao Guan, Derek Greene",http://arxiv.org/pdf/2408.02253v2,cs.CL
ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems,"Recently, there has been increasing interest in using Large Language Models
(LLMs) to construct complex multi-agent systems to perform tasks such as
compiling literature reviews, drafting consumer reports, and planning
vacations. Many tools and libraries exist for helping create such systems,
however none support recursive multi-agent systems -- where the models
themselves flexibly decide when to delegate tasks and how to organize their
delegation structure. In this work, we introduce ReDel: a toolkit for recursive
multi-agent systems that supports custom tool-use, delegation schemes,
event-based logging, and interactive replay in an easy-to-use web interface. We
show that, using ReDel, we are able to easily identify potential areas of
improvements through the visualization and debugging tools. Our code,
documentation, and PyPI package are open-source and free to use under the MIT
license at https://github.com/zhudotexe/redel.",2024-08-05,"Andrew Zhu, Liam Dugan, Chris Callison-Burch",http://arxiv.org/pdf/2408.02248v2,cs.CL
Pula: Training Large Language Models for Setswana,"In this work we present Pula, a suite of bilingual language models proficient
in both Setswana and English. Leveraging recent advancements in data
availability and efficient fine-tuning, Pula 8B and Pula 14B outperform GPT-4o
and Gemini 1.5 Pro on English-Setswana translation tasks and achieve
state-of-the-art performance on Setswana reasoning tasks for their size. We
release the weights for Pula 1B, 3B, 8B, and 14B as well as training logs and
training and evaluation code. Alongside Pula, we release the largest-ever
Setswana text corpus, Marothodi, and the first comprehensive Setswana
instruction-tuning dataset, Medupi, consisting of reformatted datasets,
translated corpora, and synthetic LLM-generated text. To accompany this data,
we release the code used for dataset construction, formatting, filtering, and
scraping. Last, we release two Setswana LLM-translated benchmarks, MMLU-tsn and
GSM8K-tsn, to measure Setswana knowledge and reasoning capabilities.",2024-08-05,"Nathan Brown, Vukosi Marivate",http://arxiv.org/pdf/2408.02239v2,cs.CL
Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings,"Large language models (LLMs) have garnered significant interest in natural
language processing (NLP), particularly their remarkable performance in various
downstream tasks in resource-rich languages. Recent studies have highlighted
the limitations of LLMs in low-resource languages, primarily focusing on binary
classification tasks and giving minimal attention to South Asian languages.
These limitations are primarily attributed to constraints such as dataset
scarcity, computational costs, and research gaps specific to low-resource
languages. To address this gap, we present datasets for sentiment and hate
speech tasks by translating from English to Bangla, Hindi, and Urdu,
facilitating research in low-resource language processing. Further, we
comprehensively examine zero-shot learning using multiple LLMs in English and
widely spoken South Asian languages. Our findings indicate that GPT-4
consistently outperforms Llama 2 and Gemini, with English consistently
demonstrating superior performance across diverse tasks compared to
low-resource languages. Furthermore, our analysis reveals that natural language
inference (NLI) exhibits the highest performance among the evaluated tasks,
with GPT-4 demonstrating superior capabilities.",2024-08-05,"Md. Arid Hasan, Prerona Tarannum, Krishno Dey, Imran Razzak, Usman Naseem",http://arxiv.org/pdf/2408.02237v1,cs.CL
A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction,"Legal charge prediction, an essential task in legal AI, seeks to assign
accurate charge labels to case descriptions, attracting significant recent
interest. Existing methods primarily employ diverse neural network structures
for modeling case descriptions directly, failing to effectively leverage
multi-source external knowledge. We propose a prompt learning framework-based
method that simultaneously leverages multi-source heterogeneous external
knowledge from a legal knowledge base, a conversational LLM, and related legal
articles. Specifically, we match knowledge snippets in case descriptions via
the legal knowledge base and encapsulate them into the input through a hard
prompt template. Additionally, we retrieve legal articles related to a given
case description through contrastive learning, and then obtain factual elements
within the case description through a conversational LLM. We fuse the embedding
vectors of soft prompt tokens with the encoding vector of factual elements to
achieve knowledge-enhanced model forward inference. Experimental results show
that our method achieved state-of-the-art results on CAIL-2018, the largest
legal charge prediction dataset, and our method has lower data dependency. Case
studies also demonstrate our method's strong interpretability.",2024-08-05,"Jingyun Sun, Chi Wei, Yang Li",http://arxiv.org/pdf/2408.02233v1,cs.CL
Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report),"The use of large language models (LLMs) is expanding rapidly, and open-source
versions are becoming available, offering users safer and more adaptable
options. These models enable users to protect data privacy by eliminating the
need to provide data to third parties and can be customized for specific tasks.
In this study, we compare the performance of various language models on the
Sustainable Development Goal (SDG) mapping task, using the output of GPT-4o as
the baseline. The selected open-source models for comparison include Mixtral,
LLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more
specialized version of GPT-4o, was included to extend the comparison. Given the
multi-label nature of the SDG mapping task, we employed metrics such as F1
score, precision, and recall with micro-averaging to evaluate different aspects
of the models' performance. These metrics are derived from the confusion matrix
to ensure a comprehensive evaluation. We provide a clear observation and
analysis of each model's performance by plotting curves based on F1 score,
precision, and recall at different thresholds. According to the results of this
experiment, LLaMA 2 and Gemma still have significant room for improvement. The
other four models do not exhibit particularly large differences in performance.
The outputs from all seven models are available on Zenodo:
https://doi.org/10.5281/zenodo.12789375.",2024-08-05,"Hui Yin, Amir Aryani, Nakul Nambiar",http://arxiv.org/pdf/2408.02201v1,cs.CL
CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs,"Large language models (LLMs) have shown great potential in code-related
tasks, yet open-source models lag behind their closed-source counterparts. To
bridge this performance gap, existing methods generate vast amounts of
synthetic data for fine-tuning, leading to inefficiencies in training.
Motivated by the need for more effective and efficient training, we propose the
Code Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces
the Complexity and Diversity Aware Sampling (CDAS) method to select
high-quality training data based on complexity and diversity, and the Dynamic
Pack padding strategy to reduce computational resource usage by minimizing
padding tokens during training. Experimental results demonstrate that
CodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,
achieves an 8.6% performance increase on HumanEval, reduces training time by
78%, and decreases peak GPU memory usage by 27%. These findings underscore
CodeACT's ability to enhance the performance and efficiency of open-source
models. By optimizing both the data selection and training processes, CodeACT
offers a comprehensive approach to improving the capabilities of open-source
LLMs while significantly reducing computational requirements, addressing the
dual challenges of data quality and training efficiency, and paving the way for
more resource-efficient and performant models.",2024-08-05,"Weijie Lv, Xuan Xia, Sheng-Jun Huang",http://arxiv.org/pdf/2408.02193v1,cs.CL
LLM Agents Improve Semantic Code Search,"Code Search is a key task that many programmers often have to perform while
developing solutions to problems. Current methodologies suffer from an
inability to perform accurately on prompts that contain some ambiguity or ones
that require additional context relative to a code-base. We introduce the
approach of using Retrieval Augmented Generation (RAG) powered agents to inject
information into user prompts allowing for better inputs into embedding models.
By utilizing RAG, agents enhance user queries with relevant details from GitHub
repositories, making them more informative and contextually aligned.
Additionally, we introduce a multi-stream ensemble approach which when paired
with agentic workflow can obtain improved retrieval accuracy, which we deploy
on application called repo-rift.com. Experimental results on the CodeSearchNet
dataset demonstrate that RepoRift significantly outperforms existing methods,
achieving an 78.2% success rate at Success@10 and a 34.6% success rate at
Success@1. This research presents a substantial advancement in semantic code
search, highlighting the potential of agentic LLMs and RAG to enhance code
retrieval systems.",2024-08-05,"Sarthak Jain, Aditya Dora, Ka Seng Sam, Prabhat Singh",http://arxiv.org/pdf/2408.11058v1,cs.CL
Generative Retrieval with Few-shot Indexing,"Existing generative retrieval (GR) approaches rely on training-based
indexing, i.e., fine-tuning a model to memorise the associations between a
query and the document identifier (docid) of a relevant document.
Training-based indexing has three limitations: high training overhead,
under-utilization of the pre-trained knowledge of large language models (LLMs),
and challenges in adapting to a dynamic document corpus. To address the above
issues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).
It has a novel few-shot indexing process, where we prompt an LLM to generate
docids for all documents in a corpus, ultimately creating a docid bank for the
entire corpus. During retrieval, we feed a query to the same LLM and constrain
it to generate a docid within the docid bank created during indexing, and then
map the generated docid back to its corresponding document. Few-Shot GR relies
solely on prompting an LLM without requiring any training, making it more
efficient. Moreover, we devise few-shot indexing with one-to-many mapping to
further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves
superior performance to state-of-the-art GR methods that require heavy
training.",2024-08-04,"Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren, Evangelos Kanoulas, Suzan Verberne",http://arxiv.org/pdf/2408.02152v1,cs.CL
Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey,"Large Language Models (LLMs) have gained widespread global adoption,
showcasing advanced linguistic capabilities across multiple of languages. There
is a growing interest in academia to use these models to simulate and study
human behaviors. However, it is crucial to acknowledge that an LLM's
proficiency in a specific language might not fully encapsulate the norms and
values associated with its culture. Concerns have emerged regarding potential
biases towards Anglo-centric cultures and values due to the predominance of
Western and US-based training data. This study focuses on analyzing the
cultural representations of emotions in LLMs, in the specific case of
mixed-emotion situations. Our methodology is based on the studies of Miyamoto
et al. (2010), which identified distinctive emotional indicators in Japanese
and American human responses. We first administer their mixed emotion survey to
five different LLMs and analyze their outputs. Second, we experiment with
contextual variables to explore variations in responses considering both
language and speaker origin. Thirdly, we expand our investigation to encompass
additional East Asian and Western European origin languages to gauge their
alignment with their respective cultures, anticipating a closer fit. We find
that (1) models have limited alignment with the evidence in the literature; (2)
written language has greater effect on LLMs' response than information on
participants origin; and (3) LLMs responses were found more similar for East
Asian languages than Western European languages.",2024-08-04,"Shiran Dudy, Ibrahim Said Ahmad, Ryoko Kitajima, Agata Lapedriza",http://arxiv.org/pdf/2408.02143v1,cs.CL
Table Transformers for Imputing Textual Attributes,"Missing data in tabular dataset is a common issue as the performance of
downstream tasks usually depends on the completeness of the training dataset.
Previous missing data imputation methods focus on numeric and categorical
columns, but we propose a novel end-to-end approach called Table Transformers
for Imputing Textual Attributes (TTITA) based on the transformer to impute
unstructured textual columns using other columns in the table. We conduct
extensive experiments on three datasets, and our approach shows competitive
performance outperforming baseline models such as recurrent neural networks and
Llama2. The performance improvement is more significant when the target
sequence has a longer length. Additionally, we incorporate multi-task learning
to simultaneously impute for heterogeneous columns, boosting the performance
for text imputation. We also qualitatively compare with ChatGPT for realistic
applications.",2024-08-04,"Ting-Ruen Wei, Yuan Wang, Yoshitaka Inoue, Hsin-Tai Wu, Yi Fang",http://arxiv.org/pdf/2408.02128v2,cs.CL
Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey on Methods and Datasets,"This paper provides a thorough examination of recent developments in the
field of multi-choice Machine Reading Comprehension (MRC). Focused on benchmark
datasets, methodologies, challenges, and future trajectories, our goal is to
offer researchers a comprehensive overview of the current landscape in
multi-choice MRC. The analysis delves into 30 existing cloze-style and
multiple-choice MRC benchmark datasets, employing a refined classification
method based on attributes such as corpus style, domain, complexity, context
style, question style, and answer style. This classification system enhances
our understanding of each dataset's diverse attributes and categorizes them
based on their complexity. Furthermore, the paper categorizes recent
methodologies into Fine-tuned and Prompt-tuned methods. Fine-tuned methods
involve adapting pre-trained language models (PLMs) to a specific task through
retraining on domain-specific datasets, while prompt-tuned methods use prompts
to guide PLM response generation, presenting potential applications in
zero-shot or few-shot learning scenarios. By contributing to ongoing
discussions, inspiring future research directions, and fostering innovations,
this paper aims to propel multi-choice MRC towards new frontiers of
achievement.",2024-08-04,"Shima Foolad, Kourosh Kiani, Razieh Rastgoo",http://arxiv.org/pdf/2408.02114v1,cs.CL
Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process,"In-context learning (ICL) is a few-shot learning paradigm that involves
learning mappings through input-output pairs and appropriately applying them to
new instances. Despite the remarkable ICL capabilities demonstrated by Large
Language Models (LLMs), existing works are highly dependent on large-scale
labeled support sets, not always feasible in practical scenarios. To refine
this approach, we focus primarily on an innovative selective annotation
mechanism, which precedes the standard demonstration retrieval. We introduce
the Language Model-based Determinant Point Process (LM-DPP) that simultaneously
considers the uncertainty and diversity of unlabeled instances for optimal
selection. Consequently, this yields a subset for annotation that strikes a
trade-off between the two factors. We apply LM-DPP to various language models,
including GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2
Generation datasets demonstrate that LM-DPP can effectively select canonical
examples. Further analysis reveals that LLMs benefit most significantly from
subsets that are both low uncertainty and high diversity.",2024-08-04,"Peng Wang, Xiaobin Wang, Chao Lou, Shengyu Mao, Pengjun Xie, Yong Jiang",http://arxiv.org/pdf/2408.02103v1,cs.CL
Leveraging Large Language Models with Chain-of-Thought and Prompt Engineering for Traffic Crash Severity Analysis and Inference,"Harnessing the power of Large Language Models (LLMs), this study explores the
use of three state-of-the-art LLMs, specifically GPT-3.5-turbo, LLaMA3-8B, and
LLaMA3-70B, for crash severity inference, framing it as a classification task.
We generate textual narratives from original traffic crash tabular data using a
pre-built template infused with domain knowledge. Additionally, we incorporated
Chain-of-Thought (CoT) reasoning to guide the LLMs in analyzing the crash
causes and then inferring the severity. This study also examine the impact of
prompt engineering specifically designed for crash severity inference. The LLMs
were tasked with crash severity inference to: (1) evaluate the models'
capabilities in crash severity analysis, (2) assess the effectiveness of CoT
and domain-informed prompt engineering, and (3) examine the reasoning abilities
with the CoT framework. Our results showed that LLaMA3-70B consistently
outperformed the other models, particularly in zero-shot settings. The CoT and
Prompt Engineering techniques significantly enhanced performance, improving
logical reasoning and addressing alignment issues. Notably, the CoT offers
valuable insights into LLMs' reasoning processes, unleashing their capacity to
consider diverse factors such as environmental conditions, driver behavior, and
vehicle characteristics in severity analysis and inference.",2024-08-04,"Hao Zhen, Yucheng Shi, Yongcan Huang, Jidong J. Yang, Ninghao Liu",http://arxiv.org/pdf/2408.04652v1,cs.CL
Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models,"Instruction tuning plays a critical role in aligning large language models
(LLMs) with human preference. Despite the vast amount of open instruction
datasets, naively training a LLM on all existing instructions may not be
optimal and practical. To pinpoint the most beneficial datapoints, data
assessment and selection methods have been proposed in the fields of natural
language processing (NLP) and deep learning. However, under the context of
instruction tuning, there still exists a gap in knowledge on what kind of data
evaluation metrics can be employed and how they can be integrated into the
selection mechanism. To bridge this gap, we present a comprehensive review on
existing literature of data assessment and selection especially for instruction
tuning of LLMs. We systematically categorize all applicable methods into
quality-based, diversity-based, and importance-based ones where a unified,
fine-grained taxonomy is structured. For each category, representative methods
are elaborated to describe the landscape of relevant research. In addition,
comparison between the latest methods is conducted on their officially reported
results to provide in-depth discussions on their limitations. Finally, we
summarize the open challenges and propose the promosing avenues for future
studies. All related contents are available at
https://github.com/yuleiqin/fantastic-data-engineering.",2024-08-04,"Yulei Qin, Yuncheng Yang, Pengcheng Guo, Gang Li, Hang Shao, Yuchen Shi, Zihan Xu, Yun Gu, Ke Li, Xing Sun",http://arxiv.org/pdf/2408.02085v5,cs.CL
MedSyn: LLM-based Synthetic Medical Text Generation Framework,"Generating synthetic text addresses the challenge of data availability in
privacy-sensitive domains such as healthcare. This study explores the
applicability of synthetic data in real-world medical settings. We introduce
MedSyn, a novel medical text generation framework that integrates large
language models with a Medical Knowledge Graph (MKG). We use MKG to sample
prior medical information for the prompt and generate synthetic clinical notes
with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data
through application in the ICD code prediction task. Our research indicates
that synthetic data can increase the classification accuracy of vital and
challenging codes by up to 17.8% compared to settings without synthetic data.
Furthermore, to provide new data for further research in the healthcare domain,
we present the largest open-source synthetic dataset of clinical notes for the
Russian language, comprising over 41k samples covering 219 ICD-10 codes.",2024-08-04,"Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko",http://arxiv.org/pdf/2408.02056v1,cs.CL
Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages,"The aspect-based sentiment analysis (ABSA) is a standard NLP task with
numerous approaches and benchmarks, where large language models (LLM) represent
the current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data
in underrepresented languages. On such narrow tasks, small tuned language
models can often outperform universal large ones, providing available and cheap
solutions.
  We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for
classification of sentiment towards Russia and Ukraine in the context of the
ongoing military conflict. The training/testing dataset was obtained from the
academic API from Twitter/X during 2023, narrowed to the languages of the V4
countries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their
performance under a variety of settings including translations, sentiment
targets, in-context learning and more, using GPT4 as a reference model. We
document several interesting phenomena demonstrating, among others, that some
models are much better fine-tunable on multilingual Twitter tasks than others,
and that they can reach the SOTA level with a very small training set. Finally
we identify combinations of settings providing the best results.",2024-08-04,"Tomáš Filip, Martin Pavlíček, Petr Sosík",http://arxiv.org/pdf/2408.02044v1,cs.CL
LLaSA: Large Language and E-Commerce Shopping Assistant,"The e-commerce platform has evolved rapidly due to its widespread popularity
and convenience. Developing an e-commerce shopping assistant for customers is
crucial to aiding them in quickly finding desired products and recommending
precisely what they need. However, most previous shopping assistants face two
main problems: (1) task-specificity, which necessitates the development of
different models for various tasks, thereby increasing development costs and
limiting effectiveness; and (2) poor generalization, where the trained model
performs inadequately on up-to-date products. To resolve these issues, we
employ Large Language Models (LLMs) to construct an omnipotent assistant,
leveraging their adeptness at handling multiple tasks and their superior
generalization capability. Nonetheless, LLMs lack inherent knowledge of
e-commerce concepts. To address this, we create an instruction dataset
comprising 65,000 samples and diverse tasks, termed as EshopInstruct. Through
instruction tuning on our dataset, the assistant, named LLaSA, demonstrates the
potential to function as an omnipotent assistant. Additionally, we propose
various inference optimization strategies to enhance performance with limited
inference resources. In the Amazon KDD Cup 2024 Challenge, our proposed method,
LLaSA, achieved an overall ranking of 3rd place on ShopBench, including 57
tasks and approximately 20,000 questions, and we secured top-5 rankings in each
track, especially in track4, where we achieved the best performance result
among all student teams. Our extensive practices fully demonstrate that LLMs
possess the great potential to be competent e-commerce shopping assistants.",2024-08-04,"Shuo Zhang, Boci Peng, Xinping Zhao, Boren Hu, Yun Zhu, Yanjia Zeng, Xuming Hu",http://arxiv.org/pdf/2408.02006v1,cs.CL
Optimal and efficient text counterfactuals using Graph Neural Networks,"As NLP models become increasingly integral to decision-making processes, the
need for explainability and interpretability has become paramount. In this
work, we propose a framework that achieves the aforementioned by generating
semantically edited inputs, known as counterfactual interventions, which change
the model prediction, thus providing a form of counterfactual explanations for
the model. We test our framework on two NLP tasks - binary sentiment
classification and topic classification - and show that the generated edits are
contrastive, fluent and minimal, while the whole process remains significantly
faster that other state-of-the-art counterfactual editors.",2024-08-04,"Dimitris Lymperopoulos, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou",http://arxiv.org/pdf/2408.01969v2,cs.CL
ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science,"This research introduces the Multilevel Embedding Association Test (ML-EAT),
a method designed for interpretable and transparent measurement of intrinsic
bias in language technologies. The ML-EAT addresses issues of ambiguity and
difficulty in interpreting the traditional EAT measurement by quantifying bias
at three levels of increasing granularity: the differential association between
two target concepts with two attribute concepts; the individual effect size of
each target concept with two attribute concepts; and the association between
each individual target concept and each individual attribute concept. Using the
ML-EAT, this research defines a taxonomy of EAT patterns describing the nine
possible outcomes of an embedding association test, each of which is associated
with a unique EAT-Map, a novel four-quadrant visualization for interpreting the
ML-EAT. Empirical analysis of static and diachronic word embeddings, GPT-2
language models, and a CLIP language-and-image model shows that EAT patterns
add otherwise unobservable information about the component biases that make up
an EAT; reveal the effects of prompting in zero-shot models; and can also
identify situations when cosine similarity is an ineffective metric, rendering
an EAT unreliable. Our work contributes a method for rendering bias more
observable and interpretable, improving the transparency of computational
investigations into human minds and societies.",2024-08-04,"Robert Wolfe, Alexis Hiniker, Bill Howe",http://arxiv.org/pdf/2408.01966v2,cs.CL
A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios,"We evaluate the robustness of several large language models on multiple
datasets. Robustness here refers to the relative insensitivity of the model's
answers to meaning-preserving variants of their input. Benchmark datasets are
constructed by introducing naturally-occurring, non-malicious perturbations, or
by generating semantically equivalent paraphrases of input questions or
statements. We further propose a novel metric for assessing a model robustness,
and demonstrate its benefits in the non-adversarial scenario by empirical
evaluation of several models on the created datasets.",2024-08-04,"Samuel Ackerman, Ella Rabinovich, Eitan Farchi, Ateret Anaby-Tavor",http://arxiv.org/pdf/2408.01963v4,cs.CL
The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations,"Calls to use open generative language models in academic research have
highlighted the need for reproducibility and transparency in scientific
research. However, the impact of generative AI extends well beyond academia, as
corporations and public interest organizations have begun integrating these
models into their data science pipelines. We expand this lens to include the
impact of open models on organizations, focusing specifically on fact-checking
organizations, which use AI to observe and analyze large volumes of circulating
misinformation, yet must also ensure the reproducibility and impartiality of
their work. We wanted to understand where fact-checking organizations use open
models in their data science pipelines; what motivates their use of open models
or proprietary models; and how their use of open or proprietary models can
inform research on the societal impact of generative AI. To answer these
questions, we conducted an interview study with N=24 professionals at 20
fact-checking organizations on six continents. Based on these interviews, we
offer a five-component conceptual model of where fact-checking organizations
employ generative AI to support or automate parts of their data science
pipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data
Delivery, and Data Sharing. We then provide taxonomies of fact-checking
organizations' motivations for using open models and the limitations that
prevent them for further adopting open models, finding that they prefer open
models for Organizational Autonomy, Data Privacy and Ownership, Application
Specificity, and Capability Transparency. However, they nonetheless use
proprietary models due to perceived advantages in Performance, Usability, and
Safety, as well as Opportunity Costs related to participation in emerging
generative AI ecosystems. Our work provides novel perspective on open models in
data-driven organizations.",2024-08-04,"Robert Wolfe, Tanushree Mitra",http://arxiv.org/pdf/2408.01962v1,cs.CL
"Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study","Popular and news media often portray teenagers with sensationalism, as both a
risk to society and at risk from society. As AI begins to absorb some of the
epistemic functions of traditional media, we study how teenagers in two
countries speaking two languages: 1) are depicted by AI, and 2) how they would
prefer to be depicted. Specifically, we study the biases about teenagers
learned by static word embeddings (SWEs) and generative language models (GLMs),
comparing these with the perspectives of adolescents living in the U.S. and
Nepal. We find English-language SWEs associate teenagers with societal
problems, and more than 50% of the 1,000 words most associated with teenagers
in the pretrained GloVe SWE reflect such problems. Given prompts about
teenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss
societal problems, most commonly violence, but also drug use, mental illness,
and sexual taboo. Nepali models, while not free of such associations, are less
dominated by social problems. Data from workshops with N=13 U.S. adolescents
and N=18 Nepalese adolescents show that AI presentations are disconnected from
teenage life, which revolves around activities like school and friendship.
Participant ratings of how well 20 trait words describe teens are decorrelated
from SWE associations, with Pearson's r=.02, n.s. in English FastText and
r=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in
GloVe. U.S. participants suggested AI could fairly present teens by
highlighting diversity, while Nepalese participants centered positivity.
Participants were optimistic that, if it learned from adolescents, rather than
media sources, AI could help mitigate stereotypes. Our work offers an
understanding of the ways SWEs and GLMs misrepresent a developmentally
vulnerable group and provides a template for less sensationalized
characterization.",2024-08-04,"Robert Wolfe, Aayushi Dangol, Bill Howe, Alexis Hiniker",http://arxiv.org/pdf/2408.01961v1,cs.CL
Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI,"Multimodal AI models capable of associating images and text hold promise for
numerous domains, ranging from automated image captioning to accessibility
applications for blind and low-vision users. However, uncertainty about bias
has in some cases limited their adoption and availability. In the present work,
we study 43 CLIP vision-language models to determine whether they learn
human-like facial impression biases, and we find evidence that such biases are
reflected across three distinct CLIP model families. We show for the first time
that the the degree to which a bias is shared across a society predicts the
degree to which it is reflected in a CLIP model. Human-like impressions of
visually unobservable attributes, like trustworthiness and sexuality, emerge
only in models trained on the largest dataset, indicating that a better fit to
uncurated cultural data results in the reproduction of increasingly subtle
social biases. Moreover, we use a hierarchical clustering approach to show that
dataset size predicts the extent to which the underlying structure of facial
impression bias resembles that of facial impression bias in humans. Finally, we
show that Stable Diffusion models employing CLIP as a text encoder learn facial
impression biases, and that these biases intersect with racial biases in Stable
Diffusion XL-Turbo. While pretrained CLIP models may prove useful for
scientific studies of bias, they will also require significant dataset curation
when intended for use as general-purpose models in a zero-shot setting.",2024-08-04,"Robert Wolfe, Aayushi Dangol, Alexis Hiniker, Bill Howe",http://arxiv.org/pdf/2408.01959v2,cs.CL
Why Perturbing Symbolic Music is Necessary: Fitting the Distribution of Never-used Notes through a Joint Probabilistic Diffusion Model,"Existing music generation models are mostly language-based, neglecting the
frequency continuity property of notes, resulting in inadequate fitting of rare
or never-used notes and thus reducing the diversity of generated samples. We
argue that the distribution of notes can be modeled by translational invariance
and periodicity, especially using diffusion models to generalize notes by
injecting frequency-domain Gaussian noise. However, due to the low-density
nature of music symbols, estimating the distribution of notes latent in the
high-density solution space poses significant challenges. To address this
problem, we introduce the Music-Diff architecture, which fits a joint
distribution of notes and accompanying semantic information to generate
symbolic music conditionally. We first enhance the fragmentation module for
extracting semantics by using event-based notations and the structural
similarity index, thereby preventing boundary blurring. As a prerequisite for
multivariate perturbation, we introduce a joint pre-training method to
construct the progressions between notes and musical semantics while avoiding
direct modeling of low-density notes. Finally, we recover the perturbed notes
by a multi-branch denoiser that fits multiple noise objectives via Pareto
optimization. Our experiments suggest that in contrast to language models,
joint probability diffusion models perturbing at both note and semantic levels
can provide more sample diversity and compositional regularity. The case study
highlights the rhythmic advantages of our model over language- and DDPMs-based
models by analyzing the hierarchical structure expressed in the self-similarity
metrics.",2024-08-04,"Shipei Liu, Xiaoya Fan, Guowei Wu",http://arxiv.org/pdf/2408.01950v1,cs.CL
Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference,"Despite their impressive performance, large language models (LLMs) such as
ChatGPT are known to pose important risks. One such set of risks arises from
misplaced confidence, whether over-confidence or under-confidence, that the
models have in their inference. While the former is well studied, the latter is
not, leading to an asymmetry in understanding the comprehensive risk of the
model based on misplaced confidence. In this paper, we address this asymmetry
by defining two types of risk (decision and composite risk), and proposing an
experimental framework consisting of a two-level inference architecture and
appropriate metrics for measuring such risks in both discriminative and
generative LLMs. The first level relies on a decision rule that determines
whether the underlying language model should abstain from inference. The second
level (which applies if the model does not abstain) is the model's inference.
Detailed experiments on four natural language commonsense reasoning datasets
using both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate
the practical utility of the evaluation framework. For example, our results
show that our framework can get an LLM to confidently respond to an extra 20.1%
of low-risk inference tasks that other methods might misclassify as high-risk,
and skip 19.8% of high-risk tasks, which would have been answered incorrectly.",2024-08-04,"Ke Shen, Mayank Kejriwal",http://arxiv.org/pdf/2408.01935v1,cs.CL
DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models,"Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.",2024-08-04,"Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara",http://arxiv.org/pdf/2408.01933v4,cs.CL
A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce,"Query intent classification is an essential module for customers to find
desired products on the e-commerce application quickly. Most existing query
intent classification methods rely on the users' click behavior as a supervised
signal to construct training samples. However, these methods based entirely on
posterior labels may lead to serious category imbalance problems because of the
Matthew effect in click samples. Compared with popular categories, it is
difficult for products under long-tail categories to obtain traffic and user
clicks, which makes the models unable to detect users' intent for products
under long-tail categories. This in turn aggravates the problem that long-tail
categories cannot obtain traffic, forming a vicious circle. In addition, due to
the randomness of the user's click, the posterior label is unstable for the
query with similar semantics, which makes the model very sensitive to the
input, leading to an unstable and incomplete recall of categories.
  In this paper, we propose a novel Semi-supervised Multi-channel Graph
Convolutional Network (SMGCN) to address the above problems from the
perspective of label association and semi-supervised learning. SMGCN extends
category information and enhances the posterior label by utilizing the
similarity score between the query and categories. Furthermore, it leverages
the co-occurrence and semantic similarity graph of categories to strengthen the
relations among labels and weaken the influence of posterior label instability.
We conduct extensive offline and online A/B experiments, and the experimental
results show that SMGCN significantly outperforms the strong baselines, which
shows its effectiveness and practicality.",2024-08-04,"Chunyuan Yuan, Ming Pang, Zheng Fang, Xue Jiang, Changping Peng, Zhangang Lin",http://arxiv.org/pdf/2408.01928v1,cs.CL
Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding,"This project investigates the efficacy of Large Language Models (LLMs) in
understanding and extracting scientific knowledge across specific domains and
to create a deep learning framework: Knowledge AI. As a part of this framework,
we employ pre-trained models and fine-tune them on datasets in the scientific
domain. The models are adapted for four key Natural Language Processing (NLP)
tasks: summarization, text generation, question answering, and named entity
recognition. Our results indicate that domain-specific fine-tuning
significantly enhances model performance in each of these tasks, thereby
improving their applicability for scientific contexts. This adaptation enables
non-experts to efficiently query and extract information within targeted
scientific fields, demonstrating the potential of fine-tuned LLMs as a tool for
knowledge discovery in the sciences.",2024-08-04,"Balaji Muralidharan, Hayden Beadles, Reza Marzban, Kalyan Sashank Mupparaju",http://arxiv.org/pdf/2408.04651v1,cs.CL
Cross-layer Attention Sharing for Large Language Models,"As large language models (LLMs) evolve, the increase in model depth and
parameter number leads to substantial redundancy. To enhance the efficiency of
the attention mechanism, previous works primarily compress the KV cache or
group attention heads, while largely overlooking redundancy between layers. Our
comprehensive analyses across various LLMs show that highly similar attention
patterns persist within most layers. It's intuitive to save the computation by
sharing attention weights across layers. However, further analysis reveals two
challenges: (1) Directly sharing the weight matrix without carefully
rearranging the attention heads proves to be ineffective; (2) Shallow layers
are vulnerable to small deviations in attention weights. Driven by these
insights, we introduce LiSA, a lightweight substitute for self-attention in
well-trained LLMs. LiSA employs tiny feed-forward networks to align attention
heads between adjacent layers and low-rank matrices to approximate differences
in layer-wise attention weights. Evaluations encompassing 13 typical benchmarks
demonstrate that LiSA maintains high response quality in terms of accuracy and
perplexity while reducing redundant attention calculations within 53-84% of the
total layers. Our implementations of LiSA achieve a 6X compression of Q and K,
with maximum throughput improvements of 19.5% for LLaMA3-8B and 32.3% for
LLaMA2-7B.",2024-08-04,"Yongyu Mu, Yuzhang Wu, Yuchun Fan, Chenglong Wang, Hengyu Li, Qiaozhi He, Murun Yang, Tong Xiao, Jingbo Zhu",http://arxiv.org/pdf/2408.01890v1,cs.CL
Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval,"Recent advances in large language models (LLMs) have enabled autonomous
agents with complex reasoning and task-fulfillment capabilities using a wide
range of tools. However, effectively identifying the most relevant tools for a
given task becomes a key bottleneck as the toolset size grows, hindering
reliable tool utilization. To address this, we introduce Re-Invoke, an
unsupervised tool retrieval method designed to scale effectively to large
toolsets without training. Specifically, we first generate a diverse set of
synthetic queries that comprehensively cover different aspects of the query
space associated with each tool document during the tool indexing phase.
Second, we leverage LLM's query understanding capabilities to extract key
tool-related context and underlying intents from user queries during the
inference phase. Finally, we employ a novel multi-view similarity ranking
strategy based on intents to pinpoint the most relevant tools for each query.
Our evaluation demonstrates that Re-Invoke significantly outperforms
state-of-the-art alternatives in both single-tool and multi-tool scenarios, all
within a fully unsupervised setting. Notably, on the ToolE datasets, we achieve
a 20% relative improvement in nDCG@5 for single-tool retrieval and a 39%
improvement for multi-tool retrieval.",2024-08-03,"Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent Cohen-Addad, Mohammadhossein Bateni, Chen-Yu Lee, Tomas Pfister",http://arxiv.org/pdf/2408.01875v2,cs.CL
MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance,"In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.",2024-08-03,"Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page",http://arxiv.org/pdf/2408.01869v1,cs.CL
Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly,"Large Language Models (LLMs) have demonstrated remarkable capabilities in
comprehending and analyzing lengthy sequential inputs, owing to their extensive
context windows that allow processing millions of tokens in a single forward
pass. However, this paper uncovers a surprising limitation: LLMs fall short
when handling long input sequences. We investigate this issue using three
datasets and two tasks (sentiment analysis and news categorization) across
various LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,
and Mistral Instruct models. To address this limitation, we propose and
evaluate ad-hoc solutions that substantially enhance LLMs' performance on long
input sequences by up to 50%, while reducing API cost and latency by up to 93%
and 50%, respectively.",2024-08-03,"Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver",http://arxiv.org/pdf/2408.01866v3,cs.CL
Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools,"Objective: This study aims to develop and validate an evaluation framework to
ensure the safety and reliability of mental health chatbots, which are
increasingly popular due to their accessibility, human-like interactions, and
context-aware support. Materials and Methods: We created an evaluation
framework with 100 benchmark questions and ideal responses, and five guideline
questions for chatbot responses. This framework, validated by mental health
experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation
methods explored included large language model (LLM)-based scoring, an agentic
approach using real-time data, and embedding models to compare chatbot
responses against ground truth standards. Results: The results highlight the
importance of guidelines and ground truth for improving LLM evaluation
accuracy. The agentic method, dynamically accessing reliable information,
demonstrated the best alignment with human assessments. Adherence to a
standardized, expert-validated framework significantly enhanced chatbot
response safety and reliability. Discussion: Our findings emphasize the need
for comprehensive, expert-tailored safety evaluation metrics for mental health
chatbots. While LLMs have significant potential, careful implementation is
necessary to mitigate risks. The superior performance of the agentic approach
underscores the importance of real-time data access in enhancing chatbot
reliability. Conclusion: The study validated an evaluation framework for mental
health chatbots, proving its effectiveness in improving safety and reliability.
Future work should extend evaluations to accuracy, bias, empathy, and privacy
to ensure holistic assessment and responsible integration into healthcare.
Standardized evaluations will build trust among users and professionals,
facilitating broader adoption and improved mental health support through
technology.",2024-08-03,"Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn T. Bounds, Angela Jun, Jaesu Han, Robert M. McCarron, Jessica Borelli, Parmida Safavi, Sanaz Mirbaha, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir M. Rahmani",http://arxiv.org/pdf/2408.04650v2,cs.CL
Sólo Escúchame: Spanish Emotional Accompaniment Chatbot,"According to the World Health Organization (WHO), suicide was the fourth
leading cause of death in the world for individuals aged 15 to 29 in 2019.
Given the rapid increase in mental health issues, providing psychological
support is both crucial and urgent. In this paper: (1) we propose S\'olo
Esc\'uchame, the first open-source Spanish emotional assistance chatbot, based
on LLaMA-2-7b-Chat. (2) We introduced the HEAR (Hispanic Emotional
Accompaniment Responses) dataset, compiled from multiple English sources
translated into Spanish, as well as generic data generated using
ChatGPT-3.5-Turbo. Finally, (3) we propose an evaluation metric based on two
semi-automatic assessment methods. Our system outperforms a range of
state-of-the-art models in providing psychological assistance in Spanish. Our
models and datasets are publicly available to facilitate reproducibility.",2024-08-03,"Bruno Gil Ramírez, Jessica López Espejel, María del Carmen Santiago Díaz, Gustavo Trinidad Rubín Linares",http://arxiv.org/pdf/2408.01852v2,cs.CL
Tracking Emotional Dynamics in Chat Conversations: A Hybrid Approach using DistilBERT and Emoji Sentiment Analysis,"Computer-mediated communication has become more important than face-to-face
communication in many contexts. Tracking emotional dynamics in chat
conversations can enhance communication, improve services, and support
well-being in various contexts. This paper explores a hybrid approach to
tracking emotional dynamics in chat conversations by combining DistilBERT-based
text emotion detection and emoji sentiment analysis. A Twitter dataset was
analyzed using various machine learning algorithms, including SVM, Random
Forest, and AdaBoost. We contrasted their performance with DistilBERT. Results
reveal DistilBERT's superior performance in emotion recognition. Our approach
accounts for emotive expressions conveyed through emojis to better understand
participants' emotions during chats. We demonstrate how this approach can
effectively capture and analyze emotional shifts in real-time conversations.
Our findings show that integrating text and emoji analysis is an effective way
of tracking chat emotion, with possible applications in customer service, work
chats, and social media interactions.",2024-08-03,"Ayan Igali, Abdulkhak Abdrakhman, Yerdaut Torekhan, Pakizar Shamoi",http://arxiv.org/pdf/2408.01838v1,cs.CL
Chain of Stance: Stance Detection with Large Language Models,"Stance detection is an active task in natural language processing (NLP) that
aims to identify the author's stance towards a particular target within a text.
Given the remarkable language understanding capabilities and encyclopedic prior
knowledge of large language models (LLMs), how to explore the potential of LLMs
in stance detection has received significant attention. Unlike existing
LLM-based approaches that focus solely on fine-tuning with large-scale
datasets, we propose a new prompting method, called \textit{Chain of Stance}
(CoS). In particular, it positions LLMs as expert stance detectors by
decomposing the stance detection process into a series of intermediate,
stance-related assertions that culminate in the final judgment. This approach
leads to significant improvements in classification performance. We conducted
extensive experiments using four SOTA LLMs on the SemEval 2016 dataset,
covering the zero-shot and few-shot learning setups. The results indicate that
the proposed method achieves state-of-the-art results with an F1 score of 79.84
in the few-shot setting.",2024-08-03,"Junxia Ma, Changjiang Wang, Hanwen Xing, Dongming Zhao, Yazhou Zhang",http://arxiv.org/pdf/2408.04649v1,cs.CL
STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs,"In this paper, we present the first structural binarization method for LLM
compression to less than 1-bit precision. Although LLMs have achieved
remarkable performance, their memory-bound nature during the inference stage
hinders the adoption of resource-constrained devices. Reducing weights to 1-bit
precision through binarization substantially enhances computational efficiency.
We observe that some weights in binarized LLMs can be randomly flipped without
significant performance degradation, suggesting the potential for further
compression. To exploit this, our STBLLM employs an N:M sparsity technique to
achieve structural binarization of the weights. Specifically, we introduce a
novel Standardized Importance (SI) metric, which considers weight magnitude and
input feature norm to more accurately assess weight significance. Then, we
propose a layer-wise approach, allowing different layers of the LLM to be
sparsified with varying N:M ratios, thereby balancing compression and accuracy.
Furthermore, we implement a fine-grained grouping strategy for less important
weights, applying distinct quantization schemes to sparse, intermediate, and
dense regions. Finally, we design a specialized CUDA kernel to support
structural binarization. We conduct extensive experiments on LLaMA-1/2/3, OPT
family, and Mistral to evaluate the effectiveness of STBLLM. The results
demonstrate that our approach performs better than other compressed
binarization LLM methods while significantly reducing memory requirements.",2024-08-03,"Peijie Dong, Lujun Li, Yuedong Zhong, Dayou Du, Ruibo Fan, Yuhan Chen, Zhenheng Tang, Qiang Wang, Wei Xue, Yike Guo, Xiaowen Chu",http://arxiv.org/pdf/2408.01803v2,cs.CL
MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems,"With the development of artificial intelligence (AI), large language models
(LLM) are widely used in many fields. However, the reasoning ability of LLM is
still very limited when it comes to mathematical reasoning. Mathematics plays
an important role in all aspects of human society and is a technical guarantee
in the fields of healthcare, transport and aerospace, for this reason, the
development of AI big language models in the field of mathematics has great
potential significance. To improve the mathematical reasoning ability of large
language models, we proposed an agent framework for learning to solve
mathematical problems based on inductive reasoning. By emulating the human
learning process of generalization of learned information and effective
application of previous knowledge in new reasoning tasks, this framework has
great performance in the mathematical reasoning process. It improves global
accuracy over the baseline method (chain-of-thought) by 20.96% and solves
17.54% of the mathematical problems that the baseline cannot solve. Benefiting
from the efficient RETRIEVAL method, our model improves the ability of large
language models to efficiently use external knowledge, i.e., the mathematical
computation of the model can be based on written procedures. In education, our
model can be used as a personalised learning aid, thus reducing the inequality
of educational resources.",2024-08-03,"Wenbei Xie, Donglin Liu, Haoran Yan, Wenjie Wu, Zongyang Liu",http://arxiv.org/pdf/2408.01779v1,cs.CL
PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models,"We present PLUGH (https://www.urbandictionary.com/define.php?term=plugh), a
modern benchmark that currently consists of 5 tasks, each with 125 input texts
extracted from 48 different games and representing 61 different
(non-isomorphic) spatial graphs to assess the abilities of Large Language
Models (LLMs) for spatial understanding and reasoning. Our evaluation of
API-based and open-sourced LLMs shows that while some commercial LLMs exhibit
strong reasoning abilities, open-sourced competitors can demonstrate almost the
same level of quality; however, all models still have significant room for
improvement. We identify typical reasons for LLM failures and discuss possible
ways to deal with them. Datasets and evaluation code are released
(https://github.com/altsoph/PLUGH).",2024-08-03,Alexey Tikhonov,http://arxiv.org/pdf/2408.04648v1,cs.CL
Distinguishing Chatbot from Human,"There have been many recent advances in the fields of generative Artificial
Intelligence (AI) and Large Language Models (LLM), with the Generative
Pre-trained Transformer (GPT) model being a leading ""chatbot."" LLM-based
chatbots have become so powerful that it may seem difficult to differentiate
between human-written and machine-generated text. To analyze this problem, we
have developed a new dataset consisting of more than 750,000 human-written
paragraphs, with a corresponding chatbot-generated paragraph for each. Based on
this dataset, we apply Machine Learning (ML) techniques to determine the origin
of text (human or chatbot). Specifically, we consider two methodologies for
tackling this issue: feature analysis and embeddings. Our feature analysis
approach involves extracting a collection of features from the text for
classification. We also explore the use of contextual embeddings and
transformer-based architectures to train classification models. Our proposed
solutions offer high classification accuracy and serve as useful tools for
textual analysis, resulting in a better understanding of chatbot-generated text
in this era of advanced AI technology.",2024-08-03,"Gauri Anil Godghase, Rishit Agrawal, Tanush Obili, Mark Stamp",http://arxiv.org/pdf/2408.04647v1,cs.CL
Discovery of Rare Causal Knowledge from Financial Statement Summaries,"What would happen if temperatures were subdued and result in a cool summer?
One can easily imagine that air conditioner, ice cream or beer sales would be
suppressed as a result of this. Less obvious is that agricultural shipments
might be delayed, or that sound proofing material sales might decrease. The
ability to extract such causal knowledge is important, but it is also important
to distinguish between cause-effect pairs that are known and those that are
likely to be unknown, or rare. Therefore, in this paper, we propose a method
for extracting rare causal knowledge from Japanese financial statement
summaries produced by companies. Our method consists of three steps. First, it
extracts sentences that include causal knowledge from the summaries using a
machine learning method based on an extended language ontology. Second, it
obtains causal knowledge from the extracted sentences using syntactic patterns.
Finally, it extracts the rarest causal knowledge from the knowledge it has
obtained.",2024-08-03,"Hiroki Sakaji, Jason Bennett, Risa Murono, Kiyoshi Izumi, Hiroyuki Sakai",http://arxiv.org/pdf/2408.01748v1,cs.CL
Indexing and Visualization of Climate Change Narratives Using BERT and Causal Extraction,"In this study, we propose a methodology to extract, index, and visualize
``climate change narratives'' (stories about the connection between causal and
consequential events related to climate change). We use two natural language
processing methods, BERT (Bidirectional Encoder Representations from
Transformers) and causal extraction, to textually analyze newspaper articles on
climate change to extract ``climate change narratives.'' The novelty of the
methodology could extract and quantify the causal relationships assumed by the
newspaper's writers. Looking at the extracted climate change narratives over
time, we find that since 2018, an increasing number of narratives suggest the
impact of the development of climate change policy discussion and the
implementation of climate change-related policies on corporate behaviors,
macroeconomics, and price dynamics. We also observed the recent emergence of
narratives focusing on the linkages between climate change-related policies and
monetary policy. Furthermore, there is a growing awareness of the negative
impacts of natural disasters (e.g., abnormal weather and severe floods) related
to climate change on economic activities, and this issue might be perceived as
a new challenge for companies and governments. The methodology of this study is
expected to be applied to a wide range of fields, as it can analyze causal
relationships among various economic topics, including analysis of inflation
expectation or monetary policy communication strategy.",2024-08-03,"Hiroki Sakaji, Noriyasu Kaneda",http://arxiv.org/pdf/2408.01745v1,cs.CL
Summarization of Investment Reports Using Pre-trained Model,"In this paper, we attempt to summarize monthly reports as investment reports.
Fund managers have a wide range of tasks, one of which is the preparation of
investment reports. In addition to preparing monthly reports on fund
management, fund managers prepare management reports that summarize these
monthly reports every six months or once a year. The preparation of fund
reports is a labor-intensive and time-consuming task. Therefore, in this paper,
we tackle investment summarization from monthly reports using transformer-based
models. There are two main types of summarization methods: extractive
summarization and abstractive summarization, and this study constructs both
methods and examines which is more useful in summarizing investment reports.",2024-08-03,"Hiroki Sakaji, Ryotaro Kobayashi, Kiyoshi Izumi, Hiroyuki Mitsugi, Wataru Kuramoto",http://arxiv.org/pdf/2408.01744v1,cs.CL
Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data,"Aerospace manufacturing companies, such as Thales Alenia Space, design,
develop, integrate, verify, and validate products characterized by high
complexity and low volume. They carefully document all phases for each product
but analyses across products are challenging due to the heterogeneity and
unstructured nature of the data in documents. In this paper, we propose a
hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with
Large Language Models (LLMs) to extract and validate data contained in these
documents. We consider a case study focused on test data related to electronic
boards for satellites. To do so, we extend the Semantic Sensor Network
ontology. We store the metadata of the reports in a KG, while the actual test
results are stored in parquet accessible via a Virtual Knowledge Graph. The
validation process is managed using an LLM-based approach. We also conduct a
benchmarking study to evaluate the performance of state-of-the-art LLMs in
executing this task. Finally, we analyze the costs and benefits of automating
preexisting processes of manual data extraction and validation for subsequent
cross-report analyses.",2024-08-03,"Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, Emanuele Della Valle",http://arxiv.org/pdf/2408.01700v1,cs.CL
Multi-Frame Vision-Language Model for Long-form Reasoning in Driver Behavior Analysis,"Identifying risky driving behavior in real-world situations is essential for
the safety of both drivers and pedestrians. However, integrating natural
language models in this field remains relatively untapped. To address this, we
created a novel multi-modal instruction tuning dataset and driver coaching
inference system. Our primary use case is dashcam-based coaching for commercial
drivers. The North American Dashcam Market is expected to register a CAGR of
15.4 percent from 2022 to 2027. Our dataset enables language models to learn
visual instructions across various risky driving scenarios, emphasizing
detailed reasoning crucial for effective driver coaching and managerial
comprehension. Our model is trained on road-facing and driver-facing RGB camera
footage, capturing the comprehensive scope of driving behavior in vehicles
equipped with dashcams.",2024-08-03,"Hiroshi Takato, Hiroshi Tsutsui, Komei Soda, Hidetaka Kamigaito",http://arxiv.org/pdf/2408.01682v1,cs.CL
MMPKUBase: A Comprehensive and High-quality Chinese Multi-modal Knowledge Graph,"Multi-modal knowledge graphs have emerged as a powerful approach for
information representation, combining data from different modalities such as
text, images, and videos. While several such graphs have been constructed and
have played important roles in applications like visual question answering and
recommendation systems, challenges persist in their development. These include
the scarcity of high-quality Chinese knowledge graphs and limited domain
coverage in existing multi-modal knowledge graphs. This paper introduces
MMPKUBase, a robust and extensive Chinese multi-modal knowledge graph that
covers diverse domains, including birds, mammals, ferns, and more, comprising
over 50,000 entities and over 1 million filtered images. To ensure data
quality, we employ Prototypical Contrastive Learning and the Isolation Forest
algorithm to refine the image data. Additionally, we have developed a
user-friendly platform to facilitate image attribute exploration.",2024-08-03,"Xuan Yi, Yanzeng Li, Lei Zou",http://arxiv.org/pdf/2408.01679v1,cs.CL
Transforming Slot Schema Induction with Generative Dialogue State Inference,"The challenge of defining a slot schema to represent the state of a
task-oriented dialogue system is addressed by Slot Schema Induction (SSI),
which aims to automatically induce slots from unlabeled dialogue data. Whereas
previous approaches induce slots by clustering value spans extracted directly
from the dialogue text, we demonstrate the power of discovering slots using a
generative approach. By training a model to generate slot names and values that
summarize key dialogue information with no prior task knowledge, our SSI method
discovers high-quality candidate information for representing dialogue state.
These discovered slot-value candidates can be easily clustered into unified
slot schemas that align well with human-authored schemas. Experimental
comparisons on the MultiWOZ and SGD datasets demonstrate that Generative
Dialogue State Inference (GenDSI) outperforms the previous state-of-the-art on
multiple aspects of the SSI task.",2024-08-03,"James D. Finch, Boxin Zhao, Jinho D. Choi",http://arxiv.org/pdf/2408.01638v1,cs.CL
Self-Emotion Blended Dialogue Generation in Social Simulation Agents,"When engaging in conversations, dialogue agents in a virtual simulation
environment may exhibit their own emotional states that are unrelated to the
immediate conversational context, a phenomenon known as self-emotion. This
study explores how such self-emotion affects the agents' behaviors in dialogue
strategies and decision-making within a large language model (LLM)-driven
simulation framework. In a dialogue strategy prediction experiment, we analyze
the dialogue strategy choices employed by agents both with and without
self-emotion, comparing them to those of humans. The results show that
incorporating self-emotion helps agents exhibit more human-like dialogue
strategies. In an independent experiment comparing the performance of models
fine-tuned on GPT-4 generated dialogue datasets, we demonstrate that
self-emotion can lead to better overall naturalness and humanness. Finally, in
a virtual simulation environment where agents have discussions on multiple
topics, we show that self-emotion of agents can significantly influence the
decision-making process of the agents, leading to approximately a 50% change in
decisions.",2024-08-03,"Qiang Zhang, Jason Naradowsky, Yusuke Miyao",http://arxiv.org/pdf/2408.01633v1,cs.CL
Dialog Flow Induction for Constrainable LLM-Based Chatbots,"LLM-driven dialog systems are used in a diverse set of applications, ranging
from healthcare to customer service. However, given their generalization
capability, it is difficult to ensure that these chatbots stay within the
boundaries of the specialized domains, potentially resulting in inaccurate
information and irrelevant responses. This paper introduces an unsupervised
approach for automatically inducing domain-specific dialog flows that can be
used to constrain LLM-based chatbots. We introduce two variants of dialog flow
based on the availability of in-domain conversation instances. Through human
and automatic evaluation over various dialog domains, we demonstrate that our
high-quality data-guided dialog flows achieve better domain coverage, thereby
overcoming the need for extensive manual crafting of such flows.",2024-08-03,"Stuti Agrawal, Nishi Uppuluri, Pranav Pillai, Revanth Gangi Reddy, Zoey Li, Gokhan Tur, Dilek Hakkani-Tur, Heng Ji",http://arxiv.org/pdf/2408.01623v1,cs.CL
Efficacy of Large Language Models in Systematic Reviews,"This study investigates the effectiveness of Large Language Models (LLMs) in
interpreting existing literature through a systematic review of the
relationship between Environmental, Social, and Governance (ESG) factors and
financial performance. The primary objective is to assess how LLMs can
replicate a systematic review on a corpus of ESG-focused papers. We compiled
and hand-coded a database of 88 relevant papers published from March 2020 to
May 2024. Additionally, we used a set of 238 papers from a previous systematic
review of ESG literature from January 2015 to February 2020. We evaluated two
current state-of-the-art LLMs, Meta AI's Llama 3 8B and OpenAI's GPT-4o, on the
accuracy of their interpretations relative to human-made classifications on
both sets of papers. We then compared these results to a ""Custom GPT"" and a
fine-tuned GPT-4o Mini model using the corpus of 238 papers as training data.
The fine-tuned GPT-4o Mini model outperformed the base LLMs by 28.3% on average
in overall accuracy on prompt 1. At the same time, the ""Custom GPT"" showed a
3.0% and 15.7% improvement on average in overall accuracy on prompts 2 and 3,
respectively. Our findings reveal promising results for investors and agencies
to leverage LLMs to summarize complex evidence related to ESG investing,
thereby enabling quicker decision-making and a more efficient market.",2024-08-03,"Aaditya Shah, Shridhar Mehendale, Siddha Kanthi",http://arxiv.org/pdf/2408.04646v2,cs.CL
A General-Purpose Device for Interaction with LLMs,"This paper investigates integrating large language models (LLMs) with
advanced hardware, focusing on developing a general-purpose device designed for
enhanced interaction with LLMs. Initially, we analyze the current landscape,
where virtual assistants and LLMs are reshaping human-technology interactions,
highlighting pivotal advancements and setting the stage for a new era of
intelligent hardware. Despite substantial progress in LLM technology, a
significant gap exists in hardware development, particularly concerning
scalability, efficiency, affordability, and multimodal capabilities. This
disparity presents both challenges and opportunities, underscoring the need for
hardware that is not only powerful but also versatile and capable of managing
the sophisticated demands of modern computation. Our proposed device addresses
these needs by emphasizing scalability, multimodal data processing, enhanced
user interaction, and privacy considerations, offering a comprehensive platform
for LLM integration in various applications.",2024-08-02,"Jiajun Xu, Qun Wang, Yuhang Cao, Baitao Zeng, Sicheng Liu",http://arxiv.org/pdf/2408.10230v1,cs.CL
Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course,"This study evaluates the performance of Large Language Models (LLMs) as an
Artificial Intelligence-based tutor for a university course. In particular,
different advanced techniques are utilized, such as prompt engineering,
Retrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the
different models and applied techniques using common similarity metrics like
BLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of
helpfulness and trustworthiness. Our findings indicate that RAG combined with
prompt engineering significantly enhances model responses and produces better
factual answers. In the context of education, RAG appears as an ideal technique
as it is based on enriching the input of the model with additional information
and material which usually is already present for a university course.
Fine-tuning, on the other hand, can produce quite small, still strong expert
models, but poses the danger of overfitting. Our study further asks how we
measure performance of LLMs and how well current measurements represent
correctness or relevance? We find high correlation on similarity metrics and a
bias of most of these metrics towards shorter responses. Overall, our research
points to both the potential and challenges of integrating LLMs in educational
settings, suggesting a need for balanced training approaches and advanced
evaluation frameworks.",2024-08-02,"Sebastian Kahl, Felix Löffler, Martin Maciol, Fabian Ridder, Marius Schmitz, Jennifer Spanagel, Jens Wienkamp, Christopher Burgahn, Malte Schilling",http://arxiv.org/pdf/2408.04645v1,cs.CL
Using LLMs to Establish Implicit User Sentiment of Software Desirability,"This study explores the use of LLMs for providing quantitative zero-shot
sentiment analysis of implicit software desirability, addressing a critical
challenge in product evaluation where traditional review scores, though
convenient, fail to capture the richness of qualitative user feedback.
Innovations include establishing a method that 1) works with qualitative user
experience data without the need for explicit review scores, 2) focuses on
implicit user satisfaction, and 3) provides scaled numerical sentiment
analysis, offering a more nuanced understanding of user sentiment, instead of
simply classifying sentiment as positive, neutral, or negative.
  Data is collected using the Microsoft Product Desirability Toolkit (PDT), a
well-known qualitative user experience analysis tool. For initial exploration,
the PDT metric was given to users of two software systems. PDT data was fed
through several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a
leading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader,
a leading sentiment analysis tool. Each system was asked to evaluate the data
in two ways, by looking at the sentiment expressed in the PDT word/explanation
pairs; and by looking at the sentiment expressed by the users in their grouped
selection of five words and explanations, as a whole. Each LLM provided a
sentiment score, its confidence (low, medium, high) in the score, and an
explanation of the score.
  All LLMs tested were able to statistically detect user sentiment from the
users' grouped data, whereas TRBS and Vader were not. The confidence and
explanation of confidence provided by the LLMs assisted in understanding user
sentiment. This study adds deeper understanding of evaluating user experiences,
toward the goal of creating a universal tool that quantifies implicit
sentiment.",2024-08-02,"Sherri Weitl-Harms, John D. Hastings, Jonah Lum",http://arxiv.org/pdf/2408.01527v2,cs.CL
MoDE: Effective Multi-task Parameter Efficient Fine-Tuning with a Mixture of Dyadic Experts,"Parameter-efficient fine-tuning techniques like Low-Rank Adaptation (LoRA)
have revolutionized the adaptation of large language models (LLMs) to diverse
tasks. Recent efforts have explored mixtures of LoRA modules for multi-task
settings. However, our analysis reveals redundancy in the down-projection
matrices of these architectures. This observation motivates our proposed
method, Mixture of Dyadic Experts (MoDE), which introduces a novel design for
efficient multi-task adaptation. This is done by sharing the down-projection
matrix across tasks and employing atomic rank-one adapters, coupled with
routers that allow more sophisticated task-level specialization. Our design
allows for more fine-grained mixing, thereby increasing the model's ability to
jointly handle multiple tasks. We evaluate MoDE on the Supernatural
Instructions (SNI) benchmark consisting of a diverse set of 700+ tasks and
demonstrate that it outperforms state-of-the-art multi-task parameter-efficient
fine-tuning (PEFT) methods, without introducing additional parameters. Our
findings contribute to a deeper understanding of parameter efficiency in
multi-task LLM adaptation and provide a practical solution for deploying
high-performing, lightweight models.",2024-08-02,"Lin Ning, Harsh Lara, Meiqi Guo, Abhinav Rastogi",http://arxiv.org/pdf/2408.01505v1,cs.CL
Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting,"Large Language Models (LLMs) exhibit remarkable proficiency in addressing a
diverse array of tasks within the Natural Language Processing (NLP) domain,
with various prompt design strategies significantly augmenting their
capabilities. However, these prompts, while beneficial, each possess inherent
limitations. The primary prompt design methodologies are twofold: The first,
exemplified by the Chain of Thought (CoT), involves manually crafting prompts
specific to individual datasets, hence termed Expert-Designed Prompts (EDPs).
Once these prompts are established, they are unalterable, and their
effectiveness is capped by the expertise of the human designers. When applied
to LLMs, the static nature of EDPs results in a uniform approach to both simple
and complex problems within the same dataset, leading to the inefficient use of
tokens for straightforward issues. The second method involves prompts
autonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which
provide tailored solutions to specific problems, mitigating the limitations of
EDPs. However, LDPs may encounter a decline in performance when tackling
complex problems due to the potential for error accumulation during the
solution planning process. To address these challenges, we have conceived a
novel Prompt Recursive Search (PRS) framework that leverages the LLM to
generate solutions specific to the problem, thereby conserving tokens. The
framework incorporates an assessment of problem complexity and an adjustable
structure, ensuring a reduction in the likelihood of errors. We have
substantiated the efficacy of PRS framework through extensive experiments using
LLMs with different numbers of parameters across a spectrum of datasets in
various domains. Compared to the CoT method, the PRS method has increased the
accuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%
improvement.",2024-08-02,"Xiangyu Zhao, Chengqian Ma",http://arxiv.org/pdf/2408.01423v1,cs.CL
Mission Impossible: A Statistical Perspective on Jailbreaking LLMs,"Large language models (LLMs) are trained on a deluge of text data with
limited quality control. As a result, LLMs can exhibit unintended or even
harmful behaviours, such as leaking information, fake news or hate speech.
Countermeasures, commonly referred to as preference alignment, include
fine-tuning the pretrained LLMs with carefully crafted text examples of desired
behaviour. Even then, empirical evidence shows preference aligned LLMs can be
enticed to harmful behaviour. This so called jailbreaking of LLMs is typically
achieved by adversarially modifying the input prompt to the LLM. Our paper
provides theoretical insights into the phenomenon of preference alignment and
jailbreaking from a statistical perspective. Under our framework, we first show
that pretrained LLMs will mimic harmful behaviour if present in the training
corpus. Under that same framework, we then introduce a statistical notion of
alignment, and lower-bound the jailbreaking probability, showing that it is
unpreventable under reasonable assumptions. Based on our insights, we propose
an alteration to the currently prevalent alignment strategy RLHF. Specifically,
we introduce a simple modification to the RLHF objective, we call E-RLHF, that
aims to increase the likelihood of safe responses. E-RLHF brings no additional
training cost, and is compatible with other methods. Empirically, we
demonstrate that E-RLHF outperforms RLHF on all alignment problems put forward
by the AdvBench and HarmBench project without sacrificing model performance as
measured by the MT-Bench project.",2024-08-02,"Jingtong Su, Julia Kempe, Karen Ullrich",http://arxiv.org/pdf/2408.01420v1,cs.CL
DebateQA: Evaluating Question Answering on Debatable Knowledge,"The rise of large language models (LLMs) has enabled us to seek answers to
inherently debatable questions on LLM chatbots, necessitating a reliable way to
evaluate their ability. However, traditional QA benchmarks assume fixed answers
are inadequate for this purpose. To address this, we introduce DebateQA, a
dataset of 2,941 debatable questions, each accompanied by multiple
human-annotated partial answers that capture a variety of perspectives. We
develop two metrics: Perspective Diversity, which evaluates the
comprehensiveness of perspectives, and Dispute Awareness, which assesses if the
LLM acknowledges the question's debatable nature. Experiments demonstrate that
both metrics align with human preferences and are stable across different
underlying models. Using DebateQA with two metrics, we assess 12 popular LLMs
and retrieval-augmented generation methods. Our findings reveal that while LLMs
generally excel at recognizing debatable issues, their ability to provide
comprehensive answers encompassing diverse perspectives varies considerably.",2024-08-02,"Rongwu Xu, Xuan Qi, Zehan Qi, Wei Xu, Zhijiang Guo",http://arxiv.org/pdf/2408.01419v1,cs.CL
"Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs","Humans spontaneously use increasingly efficient language as interactions
progress, by adapting and forming ad-hoc conventions. This phenomenon has been
studied extensively using reference games, showing properties of human language
that go beyond relaying intents. It remains unexplored whether multimodal large
language models (MLLMs) similarly increase communication efficiency during
interactions, and what mechanisms they may adopt for this purpose. We introduce
ICCA, an automated framework to evaluate such conversational adaptation as an
in-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and
observe that while they may understand the increasingly efficient language of
their interlocutor, they do not spontaneously make their own language more
efficient over time. This latter ability can only be elicited in some models
(e.g., GPT-4) with heavy-handed prompting. This shows that this property of
linguistic interaction does not arise from current training regimes, even
though it is a common hallmark of human language. ICCA is available at
https://github.com/lil-lab/ICCA.",2024-08-02,"Yilun Hua, Yoav Artzi",http://arxiv.org/pdf/2408.01417v1,cs.CL
Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer,"Decision Transformer (DT) has emerged as a promising class of algorithms in
offline reinforcement learning (RL) tasks, leveraging pre-collected datasets
and Transformer's capability to model long sequences. Recent works have
demonstrated that using parts of trajectories from training tasks as prompts in
DT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.
However, collecting data from specific environments can be both costly and
unsafe in many scenarios, leading to suboptimal performance and limited
few-shot prompt abilities due to the data-hungry nature of Transformer-based
models. Additionally, the limited datasets used in pre-training make it
challenging for Prompt-DT type of methods to distinguish between various RL
tasks through prompts alone. To address these challenges, we introduce the
Language model-initialized Prompt Decision Transformer (LPDT), which leverages
pre-trained language models for meta-RL tasks and fine-tunes the model using
Low-rank Adaptation (LoRA). We further incorporate prompt regularization to
effectively differentiate between tasks based on prompt feature
representations. Our approach integrates pre-trained language model and RL
tasks seamlessly. Extensive empirical studies demonstrate that initializing
with a pre-trained language model significantly enhances the performance of
Prompt-DT on unseen tasks compared to baseline methods.",2024-08-02,"Yu Yang, Pan Xu",http://arxiv.org/pdf/2408.01402v1,cs.CL
Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features,"The many-to-many multilingual neural machine translation can be regarded as
the process of integrating semantic features from the source sentences and
linguistic features from the target sentences. To enhance zero-shot
translation, models need to share knowledge across languages, which can be
achieved through auxiliary tasks for learning a universal representation or
cross-lingual mapping. To this end, we propose to exploit both semantic and
linguistic features between multiple languages to enhance multilingual
translation. On the encoder side, we introduce a disentangling learning task
that aligns encoder representations by disentangling semantic and linguistic
features, thus facilitating knowledge transfer while preserving complete
information. On the decoder side, we leverage a linguistic encoder to integrate
low-level linguistic features to assist in the target language generation.
Experimental results on multilingual datasets demonstrate significant
improvement in zero-shot translation compared to the baseline system, while
maintaining performance in supervised translation. Further analysis validates
the effectiveness of our method in leveraging both semantic and linguistic
features. The code is available at https://github.com/ictnlp/SemLing-MNMT.",2024-08-02,"Mengyu Bu, Shuhao Gu, Yang Feng",http://arxiv.org/pdf/2408.01394v1,cs.CL
Coalitions of Large Language Models Increase the Robustness of AI Agents,"The emergence of Large Language Models (LLMs) have fundamentally altered the
way we interact with digital systems and have led to the pursuit of LLM powered
AI agents to assist in daily workflows. LLMs, whilst powerful and capable of
demonstrating some emergent properties, are not logical reasoners and often
struggle to perform well at all sub-tasks carried out by an AI agent to plan
and execute a workflow. While existing studies tackle this lack of proficiency
by generalised pretraining at a huge scale or by specialised fine-tuning for
tool use, we assess if a system comprising of a coalition of pretrained LLMs,
each exhibiting specialised performance at individual sub-tasks, can match the
performance of single model agents. The coalition of models approach showcases
its potential for building robustness and reducing the operational costs of
these AI agents by leveraging traits exhibited by specific models. Our findings
demonstrate that fine-tuning can be mitigated by considering a coalition of
pretrained models and believe that this approach can be applied to other
non-agentic systems which utilise LLMs.",2024-08-02,"Prattyush Mangal, Carol Mak, Theo Kanakis, Timothy Donovan, Dave Braines, Edward Pyzer-Knapp",http://arxiv.org/pdf/2408.01380v1,cs.CL
Transformers are Universal In-context Learners,"Transformers are deep architectures that define ""in-context mappings"" which
enable predicting new tokens based on a given set of tokens (such as a prompt
in NLP applications or a set of patches for a vision transformer). In this
work, we study in particular the ability of these architectures to handle an
arbitrarily large number of context tokens. To mathematically, uniformly
address their expressivity, we consider the case that the mappings are
conditioned on a context represented by a probability distribution of tokens
which becomes discrete for a finite number of these. The relevant notion of
smoothness then corresponds to continuity in terms of the Wasserstein distance
between these contexts. We demonstrate that deep transformers are universal and
can approximate continuous in-context mappings to arbitrary precision,
uniformly over compact token domains. A key aspect of our results, compared to
existing findings, is that for a fixed precision, a single transformer can
operate on an arbitrary (even infinite) number of tokens. Additionally, it
operates with a fixed embedding dimension of tokens (this dimension does not
increase with precision) and a fixed number of heads (proportional to the
dimension). The use of MLPs between multi-head attention layers is also
explicitly controlled. We consider both unmasked attentions (as used for the
vision transformer) and masked causal attentions (as used for NLP and time
series applications). We tackle the causal setting leveraging a space-time
lifting to analyze causal attention as a mapping over probability distributions
of tokens.",2024-08-02,"Takashi Furuya, Maarten V. de Hoop, Gabriel Peyré",http://arxiv.org/pdf/2408.01367v2,cs.CL
Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation,"Vision--Language Models (VLMs) have demonstrated success across diverse
applications, yet their potential to assist in relevance judgments remains
uncertain. This paper assesses the relevance estimation capabilities of VLMs,
including CLIP, LLaVA, and GPT-4V, within a large-scale \textit{ad hoc}
retrieval task tailored for multimedia content creation in a zero-shot fashion.
Preliminary experiments reveal the following: (1) Both LLaVA and GPT-4V,
encompassing open-source and closed-source visual-instruction-tuned Large
Language Models (LLMs), achieve notable Kendall's $\tau \sim 0.4$ when compared
to human relevance judgments, surpassing the CLIPScore metric. (2) While
CLIPScore is strongly preferred, LLMs are less biased towards CLIP-based
retrieval systems. (3) GPT-4V's score distribution aligns more closely with
human judgments than other models, achieving a Cohen's $\kappa$ value of around
0.08, which outperforms CLIPScore at approximately -0.096. These findings
underscore the potential of LLM-powered VLMs in enhancing relevance judgments.",2024-08-02,"Jheng-Hong Yang, Jimmy Lin",http://arxiv.org/pdf/2408.01363v1,cs.CL
Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks,"Large Language Models are expressive tools that enable complex tasks of text
understanding within Computational Social Science. Their versatility, while
beneficial, poses a barrier for establishing standardized best practices within
the field. To bring clarity on the values of different strategies, we present
an overview of the performance of modern LLM-based classification methods on a
benchmark of 23 social knowledge tasks. Our results point to three best
practices: select models with larger vocabulary and pre-training corpora; avoid
simple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific
data, and consider more complex forms instruction-tuning on multiple datasets
only when only training data is more abundant.",2024-08-02,"Anders Giovanni Møller, Luca Maria Aiello",http://arxiv.org/pdf/2408.01346v1,cs.CL
MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models,"Multimodal models that jointly process audio and language hold great promise
in audio understanding and are increasingly being adopted in the music domain.
By allowing users to query via text and obtain information about a given audio
input, these models have the potential to enable a variety of music
understanding tasks via language-based interfaces. However, their evaluation
poses considerable challenges, and it remains unclear how to effectively assess
their ability to correctly interpret music-related inputs with current methods.
Motivated by this, we introduce MuChoMusic, a benchmark for evaluating music
understanding in multimodal language models focused on audio. MuChoMusic
comprises 1,187 multiple-choice questions, all validated by human annotators,
on 644 music tracks sourced from two publicly available music datasets, and
covering a wide variety of genres. Questions in the benchmark are crafted to
assess knowledge and reasoning abilities across several dimensions that cover
fundamental musical concepts and their relation to cultural and functional
contexts. Through the holistic analysis afforded by the benchmark, we evaluate
five open-source models and identify several pitfalls, including an
over-reliance on the language modality, pointing to a need for better
multimodal integration. Data and code are open-sourced.",2024-08-02,"Benno Weck, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, Dmitry Bogdanov",http://arxiv.org/pdf/2408.01337v1,cs.CL
FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only,"Instruction fine-tuning stands as a crucial advancement in leveraging large
language models (LLMs) for enhanced task performance. However, the annotation
of instruction datasets has traditionally been expensive and laborious, often
relying on manual annotations or costly API calls of proprietary LLMs. To
address these challenges, we introduce FANNO, a fully autonomous, open-sourced
framework that revolutionizes the annotation process without the need for
pre-existing annotated data. Utilizing a Mistral-7b-instruct model, FANNO
efficiently produces diverse and high-quality datasets through a structured
process involving document pre-screening, instruction generation, and response
generation. Experiments on Open LLM Leaderboard and AlpacaEval benchmark show
that the FANNO can generate high-quality data with diversity and complexity for
free, comparable to human-annotated or cleaned datasets like
Alpaca-GPT4-Cleaned.",2024-08-02,"He Zhu, Junyou Su, Tianle Lun, Yicheng Tao, Wenjia Zhang, Zipei Fan, Guanhua Chen",http://arxiv.org/pdf/2408.01323v1,cs.CL
Reconsidering Degeneration of Token Embeddings with Definitions for Encoder-based Pre-trained Language Models,"Learning token embeddings based on token co-occurrence statistics has proven
effective for both pre-training and fine-tuning in natural language processing.
However, recent studies have pointed out that the distribution of learned
embeddings degenerates into anisotropy (i.e., non-uniform distribution), and
even pre-trained language models (PLMs) suffer from a loss of semantics-related
information in embeddings for low-frequency tokens. This study first analyzes
the fine-tuning dynamics of encoder-based PLMs and demonstrates their
robustness against degeneration. On the basis of this analysis, we propose
DefinitionEMB, a method that utilizes definitions to re-construct isotropically
distributed and semantics-related token embeddings for encoder-based PLMs while
maintaining original robustness during fine-tuning. Our experiments demonstrate
the effectiveness of leveraging definitions from Wiktionary to re-construct
such embeddings for two encoder-based PLMs: RoBERTa-base and BART-large.
Furthermore, the re-constructed embeddings for low-frequency tokens improve the
performance of these models across various GLUE and four text summarization
datasets.",2024-08-02,"Ying Zhang, Dongyuan Li, Manabu Okumura",http://arxiv.org/pdf/2408.01308v2,cs.CL
Deep Learning based Visually Rich Document Content Understanding: A Survey,"Visually Rich Documents (VRDs) are essential in academia, finance, medical
fields, and marketing due to their multimodal information content. Traditional
methods for extracting information from VRDs depend on expert knowledge and
manual labor, making them costly and inefficient. The advent of deep learning
has revolutionized this process, introducing models that leverage multimodal
information vision, text, and layout along with pretraining tasks to develop
comprehensive document representations. These models have achieved
state-of-the-art performance across various downstream tasks, significantly
enhancing the efficiency and accuracy of information extraction from VRDs. In
response to the growing demands and rapid developments in Visually Rich
Document Understanding (VRDU), this paper provides a comprehensive review of
deep learning-based VRDU frameworks. We systematically survey and analyze
existing methods and benchmark datasets, categorizing them based on adopted
strategies and downstream tasks. Furthermore, we compare different techniques
used in VRDU models, focusing on feature representation and fusion, model
architecture, and pretraining methods, while highlighting their strengths,
limitations, and appropriate scenarios. Finally, we identify emerging trends
and challenges in VRDU, offering insights into future research directions and
practical applications. This survey aims to provide a thorough understanding of
VRDU advancements, benefiting both academic and industrial sectors.",2024-08-02,"Yihao Ding, Jean Lee, Soyeon Caren Han",http://arxiv.org/pdf/2408.01287v1,cs.CL
The Mismeasure of Man and Models: Evaluating Allocational Harms in Large Language Models,"Large language models (LLMs) are now being considered and even deployed for
applications that support high-stakes decision-making, such as recruitment and
clinical decisions. While several methods have been proposed for measuring
bias, there remains a gap between predictions, which are what the proposed
methods consider, and how they are used to make decisions. In this work, we
introduce Rank-Allocational-Based Bias Index (RABBI), a model-agnostic bias
measure that assesses potential allocational harms arising from biases in LLM
predictions. We compare RABBI and current bias metrics on two allocation
decision tasks. We evaluate their predictive validity across ten LLMs and
utility for model selection. Our results reveal that commonly-used bias metrics
based on average performance gap and distribution distance fail to reliably
capture group disparities in allocation outcomes, whereas RABBI exhibits a
strong correlation with allocation disparities. Our work highlights the need to
account for how models are used in contexts with limited resource constraints.",2024-08-02,"Hannah Chen, Yangfeng Ji, David Evans",http://arxiv.org/pdf/2408.01285v1,cs.CL
RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework,"Retrieval-Augmented Generation (RAG) is a powerful approach that enables
large language models (LLMs) to incorporate external knowledge. However,
evaluating the effectiveness of RAG systems in specialized scenarios remains
challenging due to the high costs of data construction and the lack of suitable
evaluation metrics. This paper introduces RAGEval, a framework designed to
assess RAG systems across diverse scenarios by generating high-quality
documents, questions, answers, and references through a schema-based pipeline.
With a focus on factual accuracy, we propose three novel metrics: Completeness,
Hallucination, and Irrelevance to evaluate LLM generated responses rigorously.
Experimental results show that RAGEval outperforms zero-shot and one-shot
methods in terms of clarity, safety, conformity, and richness of generated
samples. Furthermore, the use of LLMs for scoring the proposed metrics
demonstrates a high level of consistency with human evaluations. RAGEval
establishes a new paradigm for evaluating RAG systems in real-world
applications. The code and dataset are released at
https://github.com/OpenBMB/RAGEval.",2024-08-02,"Kunlun Zhu, Yifan Luo, Dingling Xu, Yukun Yan, Zhenghao Liu, Shi Yu, Ruobing Wang, Shuo Wang, Yishan Li, Nan Zhang, Xu Han, Zhiyuan Liu, Maosong Sun",http://arxiv.org/pdf/2408.01262v5,cs.CL
High-Throughput Phenotyping of Clinical Text Using Large Language Models,"High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.",2024-08-02,"Daniel B. Hier, S. Ilyas Munzir, Anne Stahlfeld, Tayo Obafemi-Ajayi, Michael D. Carrithers",http://arxiv.org/pdf/2408.01214v1,cs.CL
"Misinforming LLMs: vulnerabilities, challenges and opportunities","Large Language Models (LLMs) have made significant advances in natural
language processing, but their underlying mechanisms are often misunderstood.
Despite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely
on statistical patterns in word embeddings rather than true cognitive
processes. This leads to vulnerabilities such as ""hallucination"" and
misinformation. The paper argues that current LLM architectures are inherently
untrustworthy due to their reliance on correlations of sequential patterns of
word embedding vectors. However, ongoing research into combining generative
transformer-based models with fact bases and logic programming languages may
lead to the development of trustworthy LLMs capable of generating statements
based on given truth and explaining their self-reasoning process.",2024-08-02,"Bo Zhou, Daniel Geißler, Paul Lukowicz",http://arxiv.org/pdf/2408.01168v1,cs.CL
DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs,"Entity Alignment (EA) aims to match equivalent entities in different
Knowledge Graphs (KGs), which is essential for knowledge fusion and
integration. Recently, embedding-based EA has attracted significant attention
and many approaches have been proposed. Early approaches primarily focus on
learning entity embeddings from the structural features of KGs, defined by
relation triples. Later methods incorporated entities' names and attributes as
auxiliary information to enhance embeddings for EA. However, these approaches
often used different techniques to encode structural and attribute information,
limiting their interaction and mutual enhancement. In this work, we propose a
dense entity retrieval framework for EA, leveraging language models to
uniformly encode various features of entities and facilitate nearest entity
search across KGs. Alignment candidates are first generated through entity
retrieval, which are subsequently reranked to determine the final alignments.
We conduct comprehensive experiments on both cross-lingual and monolingual EA
datasets, demonstrating that our approach achieves state-of-the-art performance
compared to existing EA methods.",2024-08-02,"Zhichun Wang, Xuan Chen",http://arxiv.org/pdf/2408.01154v1,cs.CL
CFBench: A Comprehensive Constraints-Following Benchmark for LLMs,"The adeptness of Large Language Models (LLMs) in comprehending and following
natural language instructions is critical for their deployment in sophisticated
real-world applications. Existing evaluations mainly focus on fragmented
constraints or narrow scenarios, but they overlook the comprehensiveness and
authenticity of constraints from the user's perspective. To bridge this gap, we
propose CFBench, a large-scale Comprehensive Constraints Following Benchmark
for LLMs, featuring 1,000 curated samples that cover more than 200 real-life
scenarios and over 50 NLP tasks. CFBench meticulously compiles constraints from
real-world instructions and constructs an innovative systematic framework for
constraint types, which includes 10 primary categories and over 25
subcategories, and ensures each constraint is seamlessly integrated within the
instructions. To make certain that the evaluation of LLM outputs aligns with
user perceptions, we propose an advanced methodology that integrates
multi-dimensional assessment criteria with requirement prioritization, covering
various perspectives of constraints, instructions, and requirement fulfillment.
Evaluating current leading LLMs on CFBench reveals substantial room for
improvement in constraints following, and we further investigate influencing
factors and enhancement strategies. The data and code are publicly available at
https://github.com/PKU-Baichuan-MLSystemLab/CFBench",2024-08-02,"Tao Zhang, Chenglin Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou",http://arxiv.org/pdf/2408.01122v2,cs.CL
Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer,"Prompt tuning is an efficient solution for training large language models
(LLMs). However, current soft-prompt-based methods often sacrifice multi-task
modularity, requiring the training process to be fully or partially repeated
for each newly added task. While recent work on task vectors applied arithmetic
operations on full model weights to achieve the desired multi-task performance,
a similar approach for soft-prompts is still missing. To this end, we introduce
Task Prompt Vectors, created by element-wise difference between weights of
tuned soft-prompts and their random initialization. Experimental results on 12
NLU datasets show that task prompt vectors can be used in low-resource settings
to effectively initialize prompt tuning on similar tasks. In addition, we show
that task prompt vectors are independent of the random initialization of prompt
tuning on 2 different language model architectures. This allows prompt
arithmetics with the pre-trained vectors from different tasks. In this way, we
provide a competitive alternative to state-of-the-art baselines by arithmetic
addition of task prompt vectors from multiple tasks.",2024-08-02,"Robert Belanec, Simon Ostermann, Ivan Srba, Maria Bielikova",http://arxiv.org/pdf/2408.01119v2,cs.CL
IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation for Checkworthy Claim Detection,"This paper describes IAI group's participation for automated check-worthiness
estimation for claims, within the framework of the 2024 CheckThat! Lab ""Task 1:
Check-Worthiness Estimation"". The task involves the automated detection of
check-worthy claims in English, Dutch, and Arabic political debates and Twitter
data. We utilized various pre-trained generative decoder and encoder
transformer models, employing methods such as few-shot chain-of-thought
reasoning, fine-tuning, data augmentation, and transfer learning from one
language to another. Despite variable success in terms of performance, our
models achieved notable placements on the organizer's leaderboard: ninth-best
in English, third-best in Dutch, and the top placement in Arabic, utilizing
multilingual datasets for enhancing the generalizability of check-worthiness
detection. Despite a significant drop in performance on the unlabeled test
dataset compared to the development test dataset, our findings contribute to
the ongoing efforts in claim detection research, highlighting the challenges
and potential of language-specific adaptations in claim verification systems.",2024-08-02,"Peter Røysland Aarnes, Vinay Setty, Petra Galuščáková",http://arxiv.org/pdf/2408.01118v1,cs.CL
BioRAG: A RAG-LLM Framework for Biological Question Reasoning,"The question-answering system for Life science research, which is
characterized by the rapid pace of discovery, evolving insights, and complex
interactions among knowledge entities, presents unique challenges in
maintaining a comprehensive knowledge warehouse and accurate information
retrieval. To address these issues, we introduce BioRAG, a novel
Retrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)
framework. Our approach starts with parsing, indexing, and segmenting an
extensive collection of 22 million scientific papers as the basic knowledge,
followed by training a specialized embedding model tailored to this domain.
Additionally, we enhance the vector retrieval process by incorporating a
domain-specific knowledge hierarchy, which aids in modeling the intricate
interrelationships among each query and context. For queries requiring the most
current information, BioRAG deconstructs the question and employs an iterative
retrieval process incorporated with the search engine for step-by-step
reasoning. Rigorous experiments have demonstrated that our model outperforms
fine-tuned LLM, LLM with search engines, and other scientific RAG frameworks
across multiple life science question-answering tasks.",2024-08-02,"Chengrui Wang, Qingqing Long, Meng Xiao, Xunxin Cai, Chengjun Wu, Zhen Meng, Xuezhi Wang, Yuanchun Zhou",http://arxiv.org/pdf/2408.01107v2,cs.CL
General-purpose Dataflow Model with Neuromorphic Primitives,"Neuromorphic computing exhibits great potential to provide high-performance
benefits in various applications beyond neural networks. However, a
general-purpose program execution model that aligns with the features of
neuromorphic computing is required to bridge the gap between program
versatility and neuromorphic hardware efficiency. The dataflow model offers a
potential solution, but it faces high graph complexity and incompatibility with
neuromorphic hardware when dealing with control flow programs, which decreases
the programmability and performance. Here, we present a dataflow model tailored
for neuromorphic hardware, called neuromorphic dataflow, which provides a
compact, concise, and neuromorphic-compatible program representation for
control logic. The neuromorphic dataflow introduces ""when"" and ""where""
primitives, which restructure the view of control. The neuromorphic dataflow
embeds these primitives in the dataflow schema with the plasticity inherited
from the spiking algorithms. Our method enables the deployment of
general-purpose programs on neuromorphic hardware with both programmability and
plasticity, while fully utilizing the hardware's potential.",2024-08-02,"Weihao Zhang, Yu Du, Hongyi Li, Songchen Ma, Rong Zhao",http://arxiv.org/pdf/2408.01090v1,cs.CL
Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs,"Knowledge models are fundamental to dialogue systems for enabling
conversational interactions, which require handling domain-specific knowledge.
Ensuring effective communication in information-providing conversations entails
aligning user understanding with the knowledge available to the system.
However, dialogue systems often face challenges arising from semantic
inconsistencies in how information is expressed in natural language compared to
how it is represented within the system's internal knowledge. To address this
problem, we study the potential of large language models for conversational
grounding, a mechanism to bridge information gaps by establishing shared
knowledge between dialogue participants. Our approach involves annotating human
conversations across five knowledge domains to create a new dialogue corpus
called BridgeKG. Through a series of experiments on this dataset, we
empirically evaluate the capabilities of large language models in classifying
grounding acts and identifying grounded information items within a knowledge
graph structure. Our findings offer insights into how these models use
in-context learning for conversational grounding tasks and common prediction
errors, which we illustrate with examples from challenging dialogues. We
discuss how the models handle knowledge graphs as a semantic layer between
unstructured dialogue utterances and structured information items.",2024-08-02,"Phillip Schneider, Nektarios Machner, Kristiina Jokinen, Florian Matthes",http://arxiv.org/pdf/2408.01088v2,cs.CL
Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts,"When using large language models (LLMs) in knowledge-intensive tasks, such as
open-domain question answering, external context can bridge the gap between
external knowledge and the LLMs' parametric knowledge. Recent research has been
developed to amplify contextual knowledge over the parametric knowledge of LLMs
with contrastive decoding approaches. While these approaches could yield
truthful responses when relevant context is provided, they are prone to
vulnerabilities when faced with noisy contexts. We extend the scope of previous
studies to encompass noisy contexts and propose adaptive contrastive decoding
(ACD) to leverage contextual influence effectively. ACD demonstrates
improvements in open-domain question answering tasks compared to baselines,
especially in robustness by remaining undistracted by noisy contexts in
retrieval-augmented generation.",2024-08-02,"Youna Kim, Hyuhng Joon Kim, Cheonbok Park, Choonghyun Park, Hyunsoo Cho, Junyeob Kim, Kang Min Yoo, Sang-goo Lee, Taeuk Kim",http://arxiv.org/pdf/2408.01084v2,cs.CL
Leveraging Encoder-only Large Language Models for Mobile App Review Feature Extraction,"Mobile app review analysis presents unique challenges due to the low quality,
subjective bias, and noisy content of user-generated documents. Extracting
features from these reviews is essential for tasks such as feature
prioritization and sentiment analysis, but it remains a challenging task.
Meanwhile, encoder-only models based on the Transformer architecture have shown
promising results for classification and information extraction tasks for
multiple software engineering processes. This study explores the hypothesis
that encoder-only large language models can enhance feature extraction from
mobile app reviews. By leveraging crowdsourced annotations from an industrial
context, we redefine feature extraction as a supervised token classification
task. Our approach includes extending the pre-training of these models with a
large corpus of user reviews to improve contextual understanding and employing
instance selection techniques to optimize model fine-tuning. Empirical
evaluations demonstrate that this method improves the precision and recall of
extracted features and enhances performance efficiency. Key contributions
include a novel approach to feature extraction, annotated datasets, extended
pre-trained models, and an instance selection mechanism for cost-effective
fine-tuning. This research provides practical methods and empirical evidence in
applying large language models to natural language processing tasks within
mobile app reviews, offering improved performance in feature extraction.",2024-08-02,"Quim Motger, Alessio Miaschi, Felice Dell'Orletta, Xavier Franch, Jordi Marco",http://arxiv.org/pdf/2408.01063v2,cs.CL
The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines,"The recent surge of open-source large language models (LLMs) enables
developers to create AI-based solutions while maintaining control over aspects
such as privacy and compliance, thereby providing governance and ownership of
the model deployment process. To utilize these LLMs, inference engines are
needed. These engines load the model's weights onto available resources, such
as GPUs, and process queries to generate responses. The speed of inference, or
performance, of the LLM, is critical for real-time applications, as it computes
millions or billions of floating point operations per inference. Recently,
advanced inference engines such as vLLM have emerged, incorporating novel
mechanisms such as efficient memory management to achieve state-of-the-art
performance. In this paper, we analyze the performance, particularly the
throughput (tokens generated per unit of time), of 20 LLMs using two inference
libraries: vLLM and HuggingFace's pipelines. We investigate how various
hyperparameters, which developers must configure, influence inference
performance. Our results reveal that throughput landscapes are irregular, with
distinct peaks, highlighting the importance of hyperparameter optimization to
achieve maximum performance. We also show that applying hyperparameter
optimization when upgrading or downgrading the GPU model used for inference can
improve throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,
respectively.",2024-08-02,Matias Martinez,http://arxiv.org/pdf/2408.01050v1,cs.CL
QUDSELECT: Selective Decoding for Questions Under Discussion Parsing,"Question Under Discussion (QUD) is a discourse framework that uses implicit
questions to reveal discourse relationships between sentences. In QUD parsing,
each sentence is viewed as an answer to a question triggered by an anchor
sentence in prior context. The resulting QUD structure is required to conform
to several theoretical criteria like answer compatibility (how well the
question is answered), making QUD parsing a challenging task. Previous works
construct QUD parsers in a pipelined manner (i.e. detect the trigger sentence
in context and then generate the question). However, these parsers lack a
holistic view of the task and can hardly satisfy all the criteria. In this
work, we introduce QUDSELECT, a joint-training framework that selectively
decodes the QUD dependency structures considering the QUD criteria. Using
instruction-tuning, we train models to simultaneously predict the anchor
sentence and generate the associated question. To explicitly incorporate the
criteria, we adopt a selective decoding strategy of sampling multiple QUD
candidates during inference, followed by selecting the best one with criteria
scorers. Our method outperforms the state-of-the-art baseline models by 9% in
human evaluation and 4% in automatic evaluation, demonstrating the
effectiveness of our framework.",2024-08-02,"Ashima Suvarna, Xiao Liu, Tanmay Parekh, Kai-Wei Chang, Nanyun Peng",http://arxiv.org/pdf/2408.01046v1,cs.CL
UNER: A Unified Prediction Head for Named Entity Recognition in Visually-rich Documents,"The recognition of named entities in visually-rich documents (VrD-NER) plays
a critical role in various real-world scenarios and applications. However, the
research in VrD-NER faces three major challenges: complex document layouts,
incorrect reading orders, and unsuitable task formulations. To address these
challenges, we propose a query-aware entity extraction head, namely UNER, to
collaborate with existing multi-modal document transformers to develop more
robust VrD-NER models. The UNER head considers the VrD-NER task as a
combination of sequence labeling and reading order prediction, effectively
addressing the issues of discontinuous entities in documents. Experimental
evaluations on diverse datasets demonstrate the effectiveness of UNER in
improving entity extraction performance. Moreover, the UNER head enables a
supervised pre-training stage on various VrD-NER datasets to enhance the
document transformer backbones and exhibits substantial knowledge transfer from
the pre-training stage to the fine-tuning stage. By incorporating universal
layout understanding, a pre-trained UNER-based model demonstrates significant
advantages in few-shot and cross-linguistic scenarios and exhibits zero-shot
entity extraction abilities.",2024-08-02,"Yi Tu, Chong Zhang, Ya Guo, Huan Chen, Jinyang Tang, Huijia Zhu, Qi Zhang",http://arxiv.org/pdf/2408.01038v2,cs.CL
Enhancing Financial Market Predictions: Causality-Driven Feature Selection,"This paper introduces the FinSen dataset that revolutionizes financial market
analysis by integrating economic and financial news articles from 197 countries
with stock market data. The dataset's extensive coverage spans 15 years from
2007 to 2023 with temporal information, offering a rich, global perspective
with 160,000 records on financial market news. Our study leverages causally
validated sentiment scores and LSTM models to enhance market forecast accuracy
and reliability. Utilizing the FinSen dataset, we introduce an innovative Focal
Calibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent
with the DAN 3 model. This not only improves prediction accuracy but also
aligns probabilistic forecasts closely with real outcomes, crucial for the
financial sector where predicted probability is paramount. Our approach
demonstrates the effectiveness of combining sentiment analysis with precise
calibration techniques for trustworthy financial forecasting where the cost of
misinterpretation can be high. Finsen Data can be found at [this github
URL](https://github.com/EagleAdelaide/FinSen_Dataset.git).",2024-08-02,"Wenhao Liang, Zhengyang Li, Weitong Chen",http://arxiv.org/pdf/2408.01005v1,cs.CL
ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models,"This paper aims to extend the code generation capability of large language
models (LLMs) to automatically manage comprehensive software requirements from
given textual descriptions. Such requirements include both functional (i.e.
achieving expected behavior for inputs) and non-functional (e.g., time/space
performance, robustness, maintainability) requirements. However, textual
descriptions can either express requirements verbosely or may even omit some of
them. We introduce ARCHCODE, a novel framework that leverages in-context
learning to organize requirements observed in descriptions and to extrapolate
unexpressed requirements from them. ARCHCODE generates requirements from given
descriptions, conditioning them to produce code snippets and test cases. Each
test case is tailored to one of the requirements, allowing for the ranking of
code snippets based on the compliance of their execution results with the
requirements. Public benchmarks show that ARCHCODE enhances to satisfy
functional requirements, significantly improving Pass@k scores. Furthermore, we
introduce HumanEval-NFR, the first evaluation of LLMs' non-functional
requirements in code generation, demonstrating ARCHCODE's superiority over
baseline methods. The implementation of ARCHCODE and the HumanEval-NFR
benchmark are both publicly accessible.",2024-08-02,"Hojae Han, Jaejin Kim, Jaeseok Yoo, Youngwon Lee, Seung-won Hwang",http://arxiv.org/pdf/2408.00994v1,cs.CL
Fairness in Large Language Models in Three Hours,"Large Language Models (LLMs) have demonstrated remarkable success across
various domains but often lack fairness considerations, potentially leading to
discriminatory outcomes against marginalized populations. Unlike fairness in
traditional machine learning, fairness in LLMs involves unique backgrounds,
taxonomies, and fulfillment techniques. This tutorial provides a systematic
overview of recent advances in the literature concerning fair LLMs, beginning
with real-world case studies to introduce LLMs, followed by an analysis of bias
causes therein. The concept of fairness in LLMs is then explored, summarizing
the strategies for evaluating bias and the algorithms designed to promote
fairness. Additionally, resources for assessing bias in LLMs, including
toolkits and datasets, are compiled, and current research challenges and open
questions in the field are discussed. The repository is available at
\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.",2024-08-02,"Thang Doan Viet, Zichong Wang, Minh Nhat Nguyen, Wenbin Zhang",http://arxiv.org/pdf/2408.00992v3,cs.CL
Cross-domain Named Entity Recognition via Graph Matching,"Cross-domain NER is a practical yet challenging problem since the data
scarcity in the real-world scenario. A common practice is first to learn a NER
model in a rich-resource general domain and then adapt the model to specific
domains. Due to the mismatch problem between entity types across domains, the
wide knowledge in the general domain can not effectively transfer to the target
domain NER model. To this end, we model the label relationship as a probability
distribution and construct label graphs in both source and target label spaces.
To enhance the contextual representation with label structures, we fuse the
label graph into the word embedding output by BERT. By representing label
relationships as graphs, we formulate cross-domain NER as a graph matching
problem. Furthermore, the proposed method has good applicability with
pre-training methods and is potentially capable of other cross-domain
prediction tasks. Empirical results on four datasets show that our method
outperforms a series of transfer learning, multi-task learning, and few-shot
learning methods.",2024-08-02,"Junhao Zheng, Haibin Chen, Qianli Ma",http://arxiv.org/pdf/2408.00981v2,cs.CL
"Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts","We propose a new graph-based framework to reveal relationships among
motivations, emotions and actions explicitly given natural language texts. A
directed acyclic graph is designed to describe human's nature. Nurture beliefs
are incorporated to connect outside events and the human's nature graph. No
annotation resources are required due to the power of large language models.
Amazon Fine Foods Reviews dataset is used as corpus and food-related
motivations are focused. Totally 92,990 relationship graphs are generated, of
which 63% make logical sense. We make further analysis to investigate error
types for optimization direction in future research.",2024-08-02,Fei Yang,http://arxiv.org/pdf/2408.00966v1,cs.CL
PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting,"Understanding the nuances of a user's extensive interaction history is key to
building accurate and personalized natural language systems that can adapt to
evolving user preferences. To address this, we introduce PERSOMA, Personalized
Soft Prompt Adapter architecture. Unlike previous personalized prompting
methods for large language models, PERSOMA offers a novel approach to
efficiently capture user history. It achieves this by resampling and
compressing interactions as free form text into expressive soft prompt
embeddings, building upon recent research utilizing embedding representations
as input for LLMs. We rigorously validate our approach by evaluating various
adapter architectures, first-stage sampling strategies, parameter-efficient
tuning techniques like LoRA, and other personalization methods. Our results
demonstrate PERSOMA's superior ability to handle large and complex user
histories compared to existing embedding-based and text-prompt-based
techniques.",2024-08-02,"Liam Hebert, Krishna Sayana, Ambarish Jash, Alexandros Karatzoglou, Sukhdeep Sodhi, Sumanth Doddapaneni, Yanli Cai, Dima Kuzmin",http://arxiv.org/pdf/2408.00960v1,cs.CL
Leveraging Large Language Models (LLMs) for Traffic Management at Urban Intersections: The Case of Mixed Traffic Scenarios,"Urban traffic management faces significant challenges due to the dynamic
environments, and traditional algorithms fail to quickly adapt to this
environment in real-time and predict possible conflicts. This study explores
the ability of a Large Language Model (LLM), specifically, GPT-4o-mini to
improve traffic management at urban intersections. We recruited GPT-4o-mini to
analyze, predict position, detect and resolve the conflicts at an intersection
in real-time for various basic scenarios. The key findings of this study to
investigate whether LLMs can logically reason and understand the scenarios to
enhance the traffic efficiency and safety by providing real-time analysis. The
study highlights the potential of LLMs in urban traffic management creating
more intelligent and more adaptive systems. Results showed the GPT-4o-mini was
effectively able to detect and resolve conflicts in heavy traffic, congestion,
and mixed-speed conditions. The complex scenario of multiple intersections with
obstacles and pedestrians saw successful conflict management as well. Results
show that the integration of LLMs promises to improve the effectiveness of
traffic control for safer and more efficient urban intersection management.",2024-08-01,"Sari Masri, Huthaifa I. Ashqar, Mohammed Elhenawy",http://arxiv.org/pdf/2408.00948v1,cs.CL
Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper),"Equitable urban transportation applications require high-fidelity digital
representations of the built environment: not just streets and sidewalks, but
bike lanes, marked and unmarked crossings, curb ramps and cuts, obstructions,
traffic signals, signage, street markings, potholes, and more. Direct
inspections and manual annotations are prohibitively expensive at scale.
Conventional machine learning methods require substantial annotated training
data for adequate performance. In this paper, we consider vision language
models as a mechanism for annotating diverse urban features from satellite
images, reducing the dependence on human annotation to produce large training
sets. While these models have achieved impressive results in describing common
objects in images captured from a human perspective, their training sets are
less likely to include strong signals for esoteric features in the built
environment, and their performance in these settings is therefore unclear. We
demonstrate proof-of-concept combining a state-of-the-art vision language model
and variants of a prompting strategy that asks the model to consider segmented
elements independently of the original image. Experiments on two urban features
-- stop lines and raised tables -- show that while direct zero-shot prompting
correctly annotates nearly zero images, the pre-segmentation strategies can
annotate images with near 40% intersection-over-union accuracy. We describe how
these results inform a new research agenda in automatic annotation of the built
environment to improve equity, accessibility, and safety at broad scale and in
diverse environments.",2024-08-01,"Bin Han, Yiwei Yang, Anat Caspi, Bill Howe",http://arxiv.org/pdf/2408.00932v1,cs.CL
Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach,"Developers create pull request (PR) descriptions to provide an overview of
their changes and explain the motivations behind them. These descriptions help
reviewers and fellow developers quickly understand the updates. Despite their
importance, some developers omit these descriptions. To tackle this problem, we
propose an automated method for generating PR descriptions based on commit
messages and source code comments. This method frames the task as a text
summarization problem, for which we utilized the T5 text-to-text transfer
model. We fine-tuned a pre-trained T5 model using a dataset containing 33,466
PRs. The model's effectiveness was assessed using ROUGE metrics, which are
recognized for their strong alignment with human evaluations. Our findings
reveal that the T5 model significantly outperforms LexRank, which served as our
baseline for comparison.",2024-08-01,"Md Nazmus Sakib, Md Athikul Islam, Md Mashrur Arifin",http://arxiv.org/pdf/2408.00921v1,cs.CL
"Risks, Causes, and Mitigations of Widespread Deployments of Large Language Models (LLMs): A Survey","Recent advancements in Large Language Models (LLMs), such as ChatGPT and
LLaMA, have significantly transformed Natural Language Processing (NLP) with
their outstanding abilities in text generation, summarization, and
classification. Nevertheless, their widespread adoption introduces numerous
challenges, including issues related to academic integrity, copyright,
environmental impacts, and ethical considerations such as data bias, fairness,
and privacy. The rapid evolution of LLMs also raises concerns regarding the
reliability and generalizability of their evaluations. This paper offers a
comprehensive survey of the literature on these subjects, systematically
gathered and synthesized from Google Scholar. Our study provides an in-depth
analysis of the risks associated with specific LLMs, identifying sub-risks,
their causes, and potential solutions. Furthermore, we explore the broader
challenges related to LLMs, detailing their causes and proposing mitigation
strategies. Through this literature analysis, our survey aims to deepen the
understanding of the implications and complexities surrounding these powerful
models.",2024-08-01,"Md Nazmus Sakib, Md Athikul Islam, Royal Pathak, Md Mashrur Arifin",http://arxiv.org/pdf/2408.04643v1,cs.CL
Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection,"Large Language Models (LLMs) such as GPT-4 have shown enough promise in the
few-shot learning context to suggest use in the generation of ""silver"" data and
refinement of new ontologies through iterative application and review. Such
workflows become more effective with reliable confidence estimation.
Unfortunately, confidence estimation is a documented weakness of models such as
GPT-4, and established methods to compensate require significant additional
complexity and computation. The present effort explores methods for effective
confidence estimation with GPT-4 with few-shot learning for event detection in
the BETTER ontology as a vehicle. The key innovation is expanding the prompt
and task presented to GPT-4 to provide License to speculate when unsure and
Opportunity to quantify and explain its uncertainty (L&O). This approach
improves accuracy and provides usable confidence measures (0.759 AUC) with no
additional machinery.",2024-08-01,"Steven Fincke, Adrien Bibal, Elizabeth Boschee",http://arxiv.org/pdf/2408.00914v1,cs.CL
Hybrid Querying Over Relational Databases and Large Language Models,"Database queries traditionally operate under the closed-world assumption,
providing no answers to questions that require information beyond the data
stored in the database. Hybrid querying using SQL offers an alternative by
integrating relational databases with large language models (LLMs) to answer
beyond-database questions. In this paper, we present the first cross-domain
benchmark, SWAN, containing 120 beyond-database questions over four real-world
databases. To leverage state-of-the-art language models in addressing these
complex questions in SWAN, we present two solutions: one based on schema
expansion and the other based on user defined functions. We also discuss
optimization opportunities and potential future directions. Our evaluation
demonstrates that using GPT-4 Turbo with few-shot prompts, one can achieves up
to 40.0\% in execution accuracy and 48.2\% in data factuality. These results
highlights both the potential and challenges for hybrid querying. We believe
that our work will inspire further research in creating more efficient and
accurate data systems that seamlessly integrate relational databases and large
language models to address beyond-database questions.",2024-08-01,"Fuheng Zhao, Divyakant Agrawal, Amr El Abbadi",http://arxiv.org/pdf/2408.00884v2,cs.CL
UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation,"The remarkable success of Large Language Models (LLMs) across diverse tasks
has driven the research community to extend their capabilities to molecular
applications. However, most molecular LLMs employ adapter-based architectures
that do not treat molecule and text modalities equally and lack a supervision
signal for the molecule modality. To address these issues, we introduce UniMoT,
a Unified Molecule-Text LLM adopting a tokenizer-based architecture that
expands the vocabulary of LLM with molecule tokens. Specifically, we introduce
a Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge
the modality gap between molecule and text. This tokenizer transforms molecules
into sequences of molecule tokens with causal dependency, encapsulating
high-level molecular and textual information. Equipped with this tokenizer,
UniMoT can unify molecule and text modalities under a shared token
representation and an autoregressive training paradigm, enabling it to
interpret molecules as a foreign language and generate them as text. Following
a four-stage training scheme, UniMoT emerges as a multi-modal generalist
capable of performing both molecule-to-text and text-to-molecule tasks.
Extensive experiments demonstrate that UniMoT achieves state-of-the-art
performance across a wide range of molecule comprehension and generation tasks.",2024-08-01,"Juzheng Zhang, Yatao Bian, Yongqiang Chen, Quanming Yao",http://arxiv.org/pdf/2408.00863v1,cs.CL
MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities,"MM-Vet, with open-ended vision-language questions targeting at evaluating
integrated capabilities, has become one of the most popular benchmarks for
large multimodal model evaluation. MM-Vet assesses six core vision-language
(VL) capabilities: recognition, knowledge, spatial awareness, language
generation, OCR, and math. However, its question format is restricted to single
image-text pairs, lacking the interleaved image and text sequences prevalent in
real-world scenarios. To address this limitation, we introduce MM-Vet v2, which
includes a new VL capability called ""image-text sequence understanding"",
evaluating models' ability to process VL sequences. Furthermore, we maintain
the high quality of evaluation samples while further expanding the evaluation
set size. Using MM-Vet v2 to benchmark large multimodal models, we found that
Claude 3.5 Sonnet is the best model with a score of 71.8, slightly
outperforming GPT-4o which scored 71.0. Among open-weight models,
InternVL2-Llama3-76B leads with a score of 68.4. The code, data, and
leaderboard are accessible at https://github.com/yuweihao/MM-Vet.",2024-08-01,"Weihao Yu, Zhengyuan Yang, Lingfeng Ren, Linjie Li, Jianfeng Wang, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang, Xinchao Wang",http://arxiv.org/pdf/2408.00765v2,cs.CL
AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation,"Large Language Model-based agents have garnered significant attention and are
becoming increasingly popular. Furthermore, planning ability is a crucial
component of an LLM-based agent, which generally entails achieving a desired
goal from an initial state. This paper investigates enhancing the planning
abilities of LLMs through instruction tuning, referred to as agent training.
Recent studies have demonstrated that utilizing expert-level trajectory for
instruction-tuning LLMs effectively enhances their planning capabilities.
However, existing work primarily focuses on synthesizing trajectories from
manually designed planning tasks and environments. The labor-intensive nature
of creating these environments and tasks impedes the generation of sufficiently
varied and extensive trajectories. To address this limitation, this paper
explores the automated synthesis of diverse environments and a gradual range of
planning tasks, from easy to difficult. We introduce a framework, AgentGen,
that leverages LLMs first to generate environments and subsequently generate
planning tasks conditioned on these environments. Specifically, to improve
environmental diversity, we propose using an inspiration corpus composed of
various domain-specific text segments as the context for synthesizing
environments. Moreover, to increase the difficulty diversity of generated
planning tasks, we propose a bidirectional evolution method, Bi-Evol, that
evolves planning tasks from easier and harder directions to synthesize a task
set with a smoother difficulty curve. The evaluation results derived from
AgentBoard show that AgentGen greatly improves LLMs' planning ability, e.g.,
the AgentGen instruction-tuned Llama-3.1-8B surpasses GPT-3.5 in overall
performance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves
state-of-the-art results in planning tasks. Project page:
https://agent-gen.github.io/.",2024-08-01,"Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan",http://arxiv.org/pdf/2408.00764v3,cs.CL
Tamper-Resistant Safeguards for Open-Weight LLMs,"Rapid advances in the capabilities of large language models (LLMs) have
raised widespread concerns regarding their potential for malicious use.
Open-weight LLMs present unique challenges, as existing safeguards lack
robustness to tampering attacks that modify model weights. For example, recent
works have demonstrated that refusal and unlearning safeguards can be trivially
removed with a few steps of fine-tuning. These vulnerabilities necessitate new
approaches for enabling the safe release of open-weight LLMs. We develop a
method, called TAR, for building tamper-resistant safeguards into open-weight
LLMs such that adversaries cannot remove the safeguards even after hundreds of
steps of fine-tuning. In extensive evaluations and red teaming analyses, we
find that our method greatly improves tamper-resistance while preserving benign
capabilities. Our results demonstrate that progress on tamper-resistance is
possible, opening up a promising new avenue to improve the safety and security
of open-weight LLMs.",2024-08-01,"Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika",http://arxiv.org/pdf/2408.00761v4,cs.CL
CERT-ED: Certifiably Robust Text Classification for Edit Distance,"With the growing integration of AI in daily life, ensuring the robustness of
systems to inference-time attacks is crucial. Among the approaches for
certifying robustness to such adversarial examples, randomized smoothing has
emerged as highly promising due to its nature as a wrapper around arbitrary
black-box models. Previous work on randomized smoothing in natural language
processing has primarily focused on specific subsets of edit distance
operations, such as synonym substitution or word insertion, without exploring
the certification of all edit operations. In this paper, we adapt Randomized
Deletion (Huang et al., 2023) and propose, CERTified Edit Distance defense
(CERT-ED) for natural language classification. Through comprehensive
experiments, we demonstrate that CERT-ED outperforms the existing Hamming
distance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of
both accuracy and the cardinality of the certificate. By covering various
threat models, including 5 direct and 5 transfer attacks, our method improves
empirical robustness in 38 out of 50 settings.",2024-08-01,"Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein",http://arxiv.org/pdf/2408.00728v1,cs.CL
Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions,"The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a conventional RAG system
and they will be further used to guide the query generation in the next
iteration. Our experiments show the improved performance of various LLMs
brought by i-MedRAG compared with conventional RAG on complex questions from
clinical vignettes in the United States Medical Licensing Examination (USMLE),
as well as various knowledge tests in the Massive Multitask Language
Understanding (MMLU) dataset. Notably, our zero-shot i-MedRAG outperforms all
existing prompt engineering and fine-tuning methods on GPT-3.5, achieving an
accuracy of 69.68% on the MedQA dataset. In addition, we characterize the
scaling properties of i-MedRAG with different iterations of follow-up queries
and different numbers of queries per iteration. Our case studies show that
i-MedRAG can flexibly ask follow-up queries to form reasoning chains, providing
an in-depth analysis of medical questions. To the best of our knowledge, this
is the first-of-its-kind study on incorporating follow-up queries into medical
RAG. The implementation of i-MedRAG is available at
https://github.com/Teddy-XiongGZ/MedRAG.",2024-08-01,"Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang",http://arxiv.org/pdf/2408.00727v3,cs.CL
Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning,"While Large Language Models show remarkable performance in natural language
understanding, their resource-intensive nature makes them less accessible. In
contrast, smaller language models such as MiniCPM offer more sustainable
scalability, but often underperform without specialized optimization. In this
paper, we explore the enhancement of smaller language models through the
improvement of their text embeddings. We select three language models, MiniCPM,
Phi-2, and Gemma, to conduct contrastive fine-tuning on the NLI dataset. Our
results demonstrate that this fine-tuning method enhances the quality of text
embeddings for all three models across various benchmarks, with MiniCPM showing
the most significant improvements of an average 56.33% performance gain. The
contrastive fine-tuning code is publicly available at
https://github.com/trapoom555/Language-Model-STS-CFT.",2024-08-01,"Trapoom Ukarapol, Zhicheng Lee, Amy Xin",http://arxiv.org/pdf/2408.00690v2,cs.CL
Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index,"Past research relates design creativity to 'divergent thinking,' i.e., how
well the concept space is explored during the early phase of design.
Researchers have argued that generating several concepts would increase the
chances of producing better design solutions. 'Variety' is one of the
parameters by which one can quantify the breadth of a concept space explored by
the designers. It is useful to assess variety at the conceptual design stage
because, at this stage, designers have the freedom to explore different
solution principles so as to satisfy a design problem with substantially novel
concepts. This article elaborates on and critically examines the existing
variety metrics from the engineering design literature, discussing their
limitations. A new distance-based variety metric is proposed, along with a
prescriptive framework to support the assessment process. This framework uses
the SAPPhIRE model of causality as a knowledge representation scheme to measure
the real-valued distance between two design concepts. The proposed framework is
implemented in a software tool called 'VariAnT.' Furthermore, the tool's
application is demonstrated through an illustrative example.",2024-08-01,"Anubhab Majumder, Ujjwal Pal, Amaresh Chakrabarti",http://arxiv.org/pdf/2408.00684v1,cs.CL
Leveraging Entailment Judgements in Cross-Lingual Summarisation,"Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to
include document-summary pairs where the reference summary is unfaithful to the
corresponding document as it contains content not supported by the document
(i.e., hallucinated content). This low data quality misleads model learning and
obscures evaluation results. Automatic ways to assess hallucinations and
improve training have been proposed for monolingual summarisation,
predominantly in English. For CLS, we propose to use off-the-shelf
cross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness of
reference and model generated summaries. Then, we study training approaches
that are aware of faithfulness issues in the training data and propose an
approach that uses unlikelihood loss to teach a model about unfaithful summary
sequences. Our results show that it is possible to train CLS models that yield
more faithful summaries while maintaining comparable or better informativess.",2024-08-01,"Huajian Zhang, Laura Perez-Beltrachini",http://arxiv.org/pdf/2408.00675v1,cs.CL
Aligning Multiple Knowledge Graphs in a Single Pass,"Entity alignment (EA) is to identify equivalent entities across different
knowledge graphs (KGs), which can help fuse these KGs into a more comprehensive
one. Previous EA methods mainly focus on aligning a pair of KGs, and to the
best of our knowledge, no existing EA method considers aligning multiple (more
than two) KGs. To fill this research gap, in this work, we study a novel
problem of aligning multiple KGs and propose an effective framework named
MultiEA to solve the problem. First, we embed the entities of all the candidate
KGs into a common feature space by a shared KG encoder. Then, we explore three
alignment strategies to minimize the distances among pre-aligned entities. In
particular, we propose an innovative inference enhancement technique to improve
the alignment performance by incorporating high-order similarities. Finally, to
verify the effectiveness of MultiEA, we construct two new real-world benchmark
datasets and conduct extensive experiments on them. The results show that our
MultiEA can effectively and efficiently align multiple KGs in a single pass. We
release the source codes of MultiEA at: https://github.com/kepsail/MultiEA.",2024-08-01,"Yaming Yang, Zhe Wang, Ziyu Guan, Wei Zhao, Weigang Lu, Xinyan Huang, Jiangtao Cui, Xiaofei He",http://arxiv.org/pdf/2408.00662v2,cs.CL
"SentenceVAE: Enable Next-sentence Prediction for Large Language Models with Faster Speed, Higher Accuracy and Longer Context","Current large language models (LLMs) primarily utilize next-token prediction
method for inference, which significantly impedes their processing speed. In
this paper, we introduce a novel inference methodology termed next-sentence
prediction, aiming at enhancing the inference efficiency of LLMs. We present
Sentence Variational Autoencoder (SentenceVAE), which includes a Sentence
Encoder to compress multiple tokens in a sentence into a single token, and a
Sentence Decoder to reconstruct it. By integrating SentenceVAE into the input
and output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a
sentence-by-sentence inference method. In addition, the SentenceVAE module of
SLLMs can maintain the integrity of the original semantic content by segmenting
the context into sentences, thereby improving accuracy while boosting inference
speed. Moreover, compared to previous LLMs, SLLMs process fewer tokens over
equivalent context length, significantly reducing memory demands for
self-attention computation and facilitating the handling of longer context.
Extensive experiments on Wanjuan dataset have revealed that the proposed method
can accelerate inference speed by 204~365%, reduce perplexity (PPL) to 46~75%
of its original metric, and decrease memory overhead by 86~91% for the
equivalent context length, compared to previous token-by-token methods.",2024-08-01,"Hongjun An, Yifan Chen, Zhe Sun, Xuelong Li",http://arxiv.org/pdf/2408.00655v5,cs.CL
SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data,"In this work, we present SynesLM, an unified model which can perform three
multimodal language understanding tasks: audio-visual automatic speech
recognition(AV-ASR) and visual-aided speech/machine translation(VST/VMT).
Unlike previous research that focused on lip motion as visual cues for speech
signals, our work explores more general visual information within entire
frames, such as objects and actions. Additionally, we use synthetic image data
to enhance the correlation between image and speech data. We benchmark SynesLM
against the How2 dataset, demonstrating performance on par with
state-of-the-art (SOTA) models dedicated to AV-ASR while maintaining our
multitasking framework. Remarkably, for zero-shot AV-ASR, SynesLM achieved SOTA
performance by lowering the Word Error Rate (WER) from 43.4% to 39.4% on the
VisSpeech Dataset. Furthermore, our results in VST and VMT outperform the
previous results, improving the BLEU score to 43.5 from 37.2 for VST, and to
54.8 from 54.4 for VMT.",2024-08-01,"Yichen Lu, Jiaqi Song, Xuankai Chang, Hengwei Bian, Soumi Maiti, Shinji Watanabe",http://arxiv.org/pdf/2408.00624v1,cs.CL
Are Bigger Encoders Always Better in Vision Large Models?,"In recent years, multimodal large language models (MLLMs) have shown strong
potential in real-world applications. They are developing rapidly due to their
remarkable ability to comprehend multimodal information and their inherent
powerful cognitive and reasoning capabilities. Among MLLMs, vision language
models (VLM) stand out for their ability to understand vision information.
However, the scaling trend of VLMs under the current mainstream paradigm has
not been extensively studied. Whether we can achieve better performance by
training even larger models is still unclear. To address this issue, we
conducted experiments on the pretraining stage of MLLMs. We conduct our
experiment using different encoder sizes and large language model (LLM) sizes.
Our findings indicate that merely increasing the size of encoders does not
necessarily enhance the performance of VLMs. Moreover, we analyzed the effects
of LLM backbone parameter size and data quality on the pretraining outcomes.
Additionally, we explored the differences in scaling laws between LLMs and
VLMs.",2024-08-01,"Bozhou Li, Hao Liang, Zimo Meng, Wentao Zhang",http://arxiv.org/pdf/2408.00620v1,cs.CL
Downstream bias mitigation is all you need,"The advent of transformer-based architectures and large language models
(LLMs) have significantly advanced the performance of natural language
processing (NLP) models. Since these LLMs are trained on huge corpuses of data
from the web and other sources, there has been a major concern about harmful
prejudices that may potentially be transferred from the data. In many
applications, these pre-trained LLMs are fine-tuned on task specific datasets,
which can further contribute to biases. This paper studies the extent of biases
absorbed by LLMs during pre-training as well as task-specific behaviour after
fine-tuning. We found that controlled interventions on pre-trained LLMs, prior
to fine-tuning, have minimal effect on lowering biases in classifiers. However,
the biases present in domain-specific datasets play a much bigger role, and
hence mitigating them at this stage has a bigger impact. While pre-training
does matter, but after the model has been pre-trained, even slight changes to
co-occurrence rates in the fine-tuning dataset has a significant effect on the
bias of the model.",2024-08-01,"Arkadeep Baksi, Rahul Singh, Tarun Joshi",http://arxiv.org/pdf/2408.00612v2,cs.CL
"Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses","Rebuses are puzzles requiring constrained multi-step reasoning to identify a
hidden phrase from a set of images and letters. In this work, we introduce a
large collection of verbalized rebuses for the Italian language and use it to
assess the rebus-solving capabilities of state-of-the-art large language
models. While general-purpose systems such as LLaMA-3 and GPT-4o perform poorly
on this task, ad-hoc fine-tuning seems to improve models' performance. However,
we find that performance gains from training are largely motivated by
memorization. Our results suggest that rebus solving remains a challenging test
bed to evaluate large language models' linguistic proficiency and sequential
instruction-following skills.",2024-08-01,"Gabriele Sarti, Tommaso Caselli, Malvina Nissim, Arianna Bisazza",http://arxiv.org/pdf/2408.00584v1,cs.CL
Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation,"Despite the remarkable ability of large vision-language models (LVLMs) in
image comprehension, these models frequently generate plausible yet factually
incorrect responses, a phenomenon known as hallucination.Recently, in large
language models (LLMs), augmenting LLMs by retrieving information from external
knowledge resources has been proven as a promising solution to mitigate
hallucinations.However, the retrieval augmentation in LVLM significantly lags
behind the widespread applications of LVLM. Moreover, when transferred to
augmenting LVLMs, sometimes the hallucination degree of the model is even
exacerbated.Motivated by the research gap and counter-intuitive phenomenon, we
introduce a novel framework, the Active Retrieval-Augmented large
vision-language model (ARA), specifically designed to address hallucinations by
incorporating three critical dimensions: (i) dissecting the retrieval targets
based on the inherent hierarchical structures of images. (ii) pinpointing the
most effective retrieval methods and filtering out the reliable retrieval
results. (iii) timing the retrieval process to coincide with episodes of low
certainty, while circumventing unnecessary retrieval during periods of high
certainty. To assess the capability of our proposed ARA model in reducing
hallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and
mPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by
utilizing fitting retrieval mechanisms and timing the retrieval judiciously, we
can effectively mitigate the hallucination problem. We hope that this study can
provide deeper insights into how to adapt the retrieval augmentation to LVLMs
for reducing hallucinations with more effective retrieval and minimal retrieval
occurrences.",2024-08-01,"Xiaoye Qu, Qiyuan Chen, Wei Wei, Jishuo Sun, Jianfeng Dong",http://arxiv.org/pdf/2408.00555v1,cs.CL
Mitigating Multilingual Hallucination in Large Vision-Language Models,"While Large Vision-Language Models (LVLMs) have exhibited remarkable
capabilities across a wide range of tasks, they suffer from hallucination
problems, where models generate plausible yet incorrect answers given the input
image-query pair. This hallucination phenomenon is even more severe when
querying the image in non-English languages, while existing methods for
mitigating hallucinations in LVLMs only consider the English scenarios. In this
paper, we make the first attempt to mitigate this important multilingual
hallucination in LVLMs. With thorough experiment analysis, we found that
multilingual hallucination in LVLMs is a systemic problem that could arise from
deficiencies in multilingual capabilities or inadequate multimodal abilities.
To this end, we propose a two-stage Multilingual Hallucination Removal (MHR)
framework for LVLMs, aiming to improve resistance to hallucination for both
high-resource and low-resource languages. Instead of relying on the intricate
manual annotations of multilingual resources, we fully leverage the inherent
capabilities of the LVLM and propose a novel cross-lingual alignment method,
which generates multiple responses for each image-query input and then
identifies the hallucination-aware pairs for each language. These data pairs
are finally used for direct preference optimization to prompt the LVLMs to
favor non-hallucinating responses. Experimental results show that our MHR
achieves a substantial reduction in hallucination generation for LVLMs.
Notably, on our extended multilingual POPE benchmark, our framework delivers an
average increase of 19.0% in accuracy across 13 different languages. Our code
and model weights are available at https://github.com/ssmisya/MHR",2024-08-01,"Xiaoye Qu, Mingyang Song, Wei Wei, Jianfeng Dong, Yu Cheng",http://arxiv.org/pdf/2408.00550v1,cs.CL
Intermittent Semi-working Mask: A New Masking Paradigm for LLMs,"Multi-turn dialogues are a key interaction method between humans and Large
Language Models (LLMs), as conversations extend over multiple rounds, keeping
LLMs' high generation quality and low latency is a challenge. Mainstream LLMs
can be grouped into two categories based on masking strategy: causal LLM and
prefix LLM. Several works have demonstrated that prefix LLMs tend to outperform
causal ones in scenarios that heavily depend on historical context such as
multi-turn dialogues or in-context learning, thanks to their bidirectional
attention on prefix sequences. However, prefix LLMs have an inherent
inefficient training problem in multi-turn dialogue datasets. In addition, the
attention mechanism of prefix LLM makes it unable to reuse Key-Value Cache (KV
Cache) across dialogue rounds to reduce generation latency. In this paper, we
propose a novel masking scheme called Intermittent Semi-working Mask (ISM) to
address these problems. Specifically, we apply alternate bidirectional and
unidirectional attention on queries and answers in the dialogue history. In
this way, ISM is able to maintain the high quality of prefix LLM and low
generation latency of causal LLM, simultaneously. Extensive experiments
illustrate that our ISM achieves significant performance.",2024-08-01,"Mingcong Lu, Jiangcai Zhu, Wang Hao, Zheng Li, Shusheng Zhang, Kailai Shao, Chao Chen, Nan Li, Feng Wang, Xin Lu",http://arxiv.org/pdf/2408.00539v1,cs.CL
The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement,"YouTube is a major social media platform that plays a significant role in
digital culture, with content creators at its core. These creators often engage
in controversial behaviour to drive engagement, which can foster toxicity. This
paper presents a quantitative analysis of controversial content on YouTube,
focusing on the relationship between controversy, toxicity, and monetisation.
We introduce a curated dataset comprising 20 controversial YouTube channels
extracted from Reddit discussions, including 16,349 videos and more than 105
million comments. We identify and categorise monetisation cues from video
descriptions into various models, including affiliate marketing and direct
selling, using lists of URLs and keywords. Additionally, we train a machine
learning model to measure the toxicity of comments in these videos. Our
findings reveal that while toxic comments correlate with higher engagement,
they negatively impact monetisation, indicating that controversy-driven
interaction does not necessarily lead to financial gain. We also observed
significant variation in monetisation strategies, with some creators showing
extensive monetisation despite high toxicity levels. Our study introduces a
curated dataset, lists of URLs and keywords to categorise monetisation, a
machine learning model to measure toxicity, and is a significant step towards
understanding the complex relationship between controversy, engagement, and
monetisation on YouTube. The lists used for detecting and categorising
monetisation cues are available on https://github.com/thalesbertaglia/toxmon.",2024-08-01,"Thales Bertaglia, Catalina Goanta, Adriana Iamnitchi",http://arxiv.org/pdf/2408.00534v1,cs.CL
GalleryGPT: Analyzing Paintings with Large Multimodal Models,"Artwork analysis is important and fundamental skill for art appreciation,
which could enrich personal aesthetic sensibility and facilitate the critical
thinking ability. Understanding artworks is challenging due to its subjective
nature, diverse interpretations, and complex visual elements, requiring
expertise in art history, cultural background, and aesthetic theory. However,
limited by the data collection and model ability, previous works for
automatically analyzing artworks mainly focus on classification, retrieval, and
other simple tasks, which is far from the goal of AI. To facilitate the
research progress, in this paper, we step further to compose comprehensive
analysis inspired by the remarkable perception and generation ability of large
multimodal models. Specifically, we first propose a task of composing paragraph
analysis for artworks, i.e., painting in this paper, only focusing on visual
characteristics to formulate more comprehensive understanding of artworks. To
support the research on formal analysis, we collect a large dataset
PaintingForm, with about 19k painting images and 50k analysis paragraphs. We
further introduce a superior large multimodal model for painting analysis
composing, dubbed GalleryGPT, which is slightly modified and fine-tuned based
on LLaVA architecture leveraging our collected data. We conduct formal analysis
generation and zero-shot experiments across several datasets to assess the
capacity of our model. The results show remarkable performance improvements
comparing with powerful baseline LMMs, demonstrating its superb ability of art
analysis and generalization. \textcolor{blue}{The codes and model are available
at: https://github.com/steven640pixel/GalleryGPT.",2024-08-01,"Yi Bin, Wenhao Shi, Yujuan Ding, Zhiqiang Hu, Zheng Wang, Yang Yang, See-Kiong Ng, Heng Tao Shen",http://arxiv.org/pdf/2408.00491v1,cs.CL
In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation,"The ability of generative large language models (LLMs) to perform in-context
learning has given rise to a large body of research into how best to prompt
models for various natural language processing tasks. In this paper, we focus
on machine translation (MT), a task that has been shown to benefit from
in-context translation examples. However no systematic studies have been
published on how best to select examples, and mixed results have been reported
on the usefulness of similarity-based selection over random selection. We
provide a study covering multiple LLMs and multiple in-context example
retrieval strategies, comparing multilingual sentence embeddings. We cover
several language directions, representing different levels of language
resourcedness (English into French, German, Swahili and Wolof). Contrarily to
previously published results, we find that sentence embedding similarity can
improve MT, especially for low-resource language directions, and discuss the
balance between selection pool diversity and quality. We also highlight
potential problems with the evaluation of LLM-based MT and suggest a more
appropriate evaluation protocol, adapting the COMET metric to the evaluation of
LLMs. Code and outputs are freely available at
https://github.com/ArmelRandy/ICL-MT.",2024-08-01,"Armel Zebaze, Benoît Sagot, Rachel Bawden",http://arxiv.org/pdf/2408.00397v1,cs.CL
DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model,"Traditional legal retrieval systems designed to retrieve legal documents,
statutes, precedents, and other legal information are unable to give
satisfactory answers due to lack of semantic understanding of specific
questions. Large Language Models (LLMs) have achieved excellent results in a
variety of natural language processing tasks, which inspired us that we train a
LLM in the legal domain to help legal retrieval. However, in the Chinese legal
domain, due to the complexity of legal questions and the rigour of legal
articles, there is no legal large model with satisfactory practical application
yet. In this paper, we present DeliLaw, a Chinese legal counselling system
based on a large language model. DeliLaw integrates a legal retrieval module
and a case retrieval module to overcome the model hallucination. Users can
consult professional legal questions, search for legal articles and relevant
judgement cases, etc. on the DeliLaw system in a dialogue mode. In addition,
DeliLaw supports the use of English for counseling. we provide the address of
the system: https://data.delilegal.com/lawQuestion.",2024-08-01,"Nan Xie, Yuelin Bai, Hengyuan Gao, Feiteng Fang, Qixuan Zhao, Zhijian Li, Ziqiang Xue, Liang Zhu, Shiwen Ni, Min Yang",http://arxiv.org/pdf/2408.00357v1,cs.CL
ABC Align: Large Language Model Alignment for Safety & Accuracy,"Alignment of Large Language Models (LLMs) remains an unsolved problem. Human
preferences are highly distributed and can be captured at multiple levels of
abstraction, from the individual to diverse populations. Organisational
preferences, represented by standards and principles, are defined to mitigate
reputational risk or meet legislative obligations. In this paper, we present
ABC Align, a novel alignment methodology for LLMs that enables integration of
the standards and preferences of a large media organisation into the LLM
itself. We combine a set of data and methods that build on recent breakthroughs
in synthetic data generation, preference optimisation, and post-training model
quantisation. Our unified approach mitigates bias and improves accuracy, while
preserving reasoning capability, as measured against standard benchmarks.",2024-08-01,"Gareth Seneque, Lap-Hang Ho, Ariel Kuperman, Nafise Erfanian Saeedi, Jeffrey Molendijk",http://arxiv.org/pdf/2408.00307v1,cs.CL
Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation,"Large-scale text-to-speech (TTS) models have made significant progress
recently.However, they still fall short in the generation of Chinese dialectal
speech. Toaddress this, we propose Bailing-TTS, a family of large-scale TTS
models capable of generating high-quality Chinese dialectal speech. Bailing-TTS
serves as a foundation model for Chinese dialectal speech generation. First,
continual semi-supervised learning is proposed to facilitate the alignment of
text tokens and speech tokens. Second, the Chinese dialectal representation
learning is developed using a specific transformer architecture and multi-stage
training processes. With the proposed design of novel network architecture and
corresponding strategy, Bailing-TTS is able to generate Chinese dialectal
speech from text effectively and efficiently. Experiments demonstrate that
Bailing-TTS generates Chinese dialectal speech towards human-like spontaneous
representation. Readers are encouraged to listen to demos at
\url{https://c9412600.github.io/bltts_tech_report/index.html}.",2024-08-01,"Xinhan Di, Zihao Chen, Yunming Liang, Junjie Zheng, Yihua Wang, Chaofan Ding",http://arxiv.org/pdf/2408.00284v1,cs.CL
Navigating Text-to-Image Generative Bias across Indic Languages,"This research investigates biases in text-to-image (TTI) models for the Indic
languages widely spoken across India. It evaluates and compares the generative
performance and cultural relevance of leading TTI models in these languages
against their performance in English. Using the proposed IndicTTI benchmark, we
comprehensively assess the performance of 30 Indic languages with two
open-source diffusion models and two commercial generation APIs. The primary
objective of this benchmark is to evaluate the support for Indic languages in
these models and identify areas needing improvement. Given the linguistic
diversity of 30 languages spoken by over 1.4 billion people, this benchmark
aims to provide a detailed and insightful analysis of TTI models' effectiveness
within the Indic linguistic landscape. The data and code for the IndicTTI
benchmark can be accessed at
https://iab-rubric.org/resources/other-databases/indictti.",2024-08-01,"Surbhi Mittal, Arnav Sudan, Mayank Vatsa, Richa Singh, Tamar Glaser, Tal Hassner",http://arxiv.org/pdf/2408.00283v1,cs.CL
QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression,"In-context learning (ICL) capabilities are foundational to the success of
large language models (LLMs). Recently, context compression has attracted
growing interest since it can largely reduce reasoning complexities and
computation costs of LLMs. In this paper, we introduce a novel Query-gUIded
aTtention cOmpression (QUITO) method, which leverages attention of the question
over the contexts to filter useless information. Specifically, we take a
trigger token to calculate the attention distribution of the context in
response to the question. Based on the distribution, we propose three different
filtering methods to satisfy the budget constraints of the context length. We
evaluate the QUITO using two widely-used datasets, namely, NaturalQuestions and
ASQA. Experimental results demonstrate that QUITO significantly outperforms
established baselines across various datasets and downstream LLMs, underscoring
its effectiveness. Our code is available at
https://github.com/Wenshansilvia/attention_compressor.",2024-08-01,"Wenshan Wang, Yihang Wang, Yixing Fan, Huaming Liao, Jiafeng Guo",http://arxiv.org/pdf/2408.00274v1,cs.CL
Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding,"Large Language Models (LLMs) frequently suffer from inefficiencies, largely
attributable to the discord between the requirements of auto-regressive
decoding and the architecture of contemporary GPUs. Recently, regressive
lightweight speculative decoding has garnered attention for its notable
efficiency improvements in text generation tasks. This approach utilizes a
lightweight regressive draft model, like a Recurrent Neural Network (RNN) or a
single transformer decoder layer, leveraging sequential information to
iteratively predict potential tokens. Specifically, RNN draft models are
computationally economical but tend to deliver lower accuracy, while attention
decoder layer models exhibit the opposite traits. This paper presents Clover-2,
an advanced iteration of Clover, an RNN-based draft model designed to achieve
comparable accuracy to that of attention decoder layer models while maintaining
minimal computational overhead. Clover-2 enhances the model architecture and
incorporates knowledge distillation to increase Clover's accuracy and improve
overall efficiency. We conducted experiments using the open-source Vicuna 7B
and LLaMA3-Instruct 8B models. The results demonstrate that Clover-2 surpasses
existing methods across various model architectures, showcasing its efficacy
and robustness.",2024-08-01,"Bin Xiao, Lujun Gui, Lei Su, Weipeng Chen",http://arxiv.org/pdf/2408.00264v1,cs.CL
Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms,"Structured State Space Models (SSMs) have emerged as compelling alternatives
to Transformer architectures, offering linear-time complexity and superior
performance in various sequence modeling tasks. Despite their advantages, SSMs
like the original Mamba-2 face training difficulties due to the sensitivities
introduced by the extended series of recurrent matrix multiplications. In this
paper, we propose an advanced architecture that mitigates these challenges by
decomposing A-multiplications into multiple groups and optimizing positional
encoding through Grouped Finite Impulse Response (FIR) filtering. This new
structure, denoted as Grouped FIR-enhanced SSM (GFSSM), employs semiseparable
matrices for efficient computation. Furthermore, inspired by the ""attention
sink"" phenomenon identified in streaming language models, we incorporate a
similar mechanism to enhance the stability and performance of our model over
extended sequences. Our approach further bridges the gap between SSMs and
Transformer architectures, offering a viable path forward for scalable and
high-performing sequence modeling.",2024-08-01,"Tian Meng, Yang Tao, Wuliang Yin",http://arxiv.org/pdf/2408.00244v1,cs.CL
Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models,"Advancements in text-to-image diffusion models have broadened extensive
downstream practical applications, but such models often encounter misalignment
issues between text and image. Taking the generation of a combination of two
disentangled concepts as an example, say given the prompt ""a tea cup of iced
coke"", existing models usually generate a glass cup of iced coke because the
iced coke usually co-occurs with the glass cup instead of the tea one during
model training. The root of such misalignment is attributed to the confusion in
the latent semantic space of text-to-image diffusion models, and hence we refer
to the ""a tea cup of iced coke"" phenomenon as Latent Concept Misalignment
(LC-Mis). We leverage large language models (LLMs) to thoroughly investigate
the scope of LC-Mis, and develop an automated pipeline for aligning the latent
semantics of diffusion models to text prompts. Empirical assessments confirm
the effectiveness of our approach, substantially reducing LC-Mis errors and
enhancing the robustness and versatility of text-to-image diffusion models. The
code and dataset are here: https://github.com/RossoneriZhao/iced_coke.",2024-08-01,"Juntu Zhao, Junyu Deng, Yixin Ye, Chongxuan Li, Zhijie Deng, Dequan Wang",http://arxiv.org/pdf/2408.00230v2,cs.CL
"Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation","This paper introduces a novel approach called sentence-wise speech
summarization (Sen-SSum), which generates text summaries from a spoken document
in a sentence-by-sentence manner. Sen-SSum combines the real-time processing of
automatic speech recognition (ASR) with the conciseness of speech
summarization. To explore this approach, we present two datasets for Sen-SSum:
Mega-SSum and CSJ-SSum. Using these datasets, our study evaluates two types of
Transformer-based models: 1) cascade models that combine ASR and strong text
summarization models, and 2) end-to-end (E2E) models that directly convert
speech into a text summary. While E2E models are appealing to develop
compute-efficient models, they perform worse than cascade models. Therefore, we
propose knowledge distillation for E2E models using pseudo-summaries generated
by the cascade models. Our experiments show that this proposed knowledge
distillation effectively improves the performance of the E2E model on both
datasets.",2024-08-01,"Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Masato Mimura, Takatomo Kano, Atsunori Ogawa, Marc Delcroix",http://arxiv.org/pdf/2408.00205v1,cs.CL
OmniParser for Pure Vision Based GUI Agent,"The recent success of large vision language models shows great potential in
driving the agent system operating on user interfaces. However, we argue that
the power multimodal models like GPT-4V as a general agent on multiple
operating systems across different applications is largely underestimated due
to the lack of a robust screen parsing technique capable of: 1) reliably
identifying interactable icons within the user interface, and 2) understanding
the semantics of various elements in a screenshot and accurately associate the
intended action with the corresponding region on the screen. To fill these
gaps, we introduce \textsc{OmniParser}, a comprehensive method for parsing user
interface screenshots into structured elements, which significantly enhances
the ability of GPT-4V to generate actions that can be accurately grounded in
the corresponding regions of the interface. We first curated an interactable
icon detection dataset using popular webpages and an icon description dataset.
These datasets were utilized to fine-tune specialized models: a detection model
to parse interactable regions on the screen and a caption model to extract the
functional semantics of the detected elements. \textsc{OmniParser}
significantly improves GPT-4V's performance on ScreenSpot benchmark. And on
Mind2Web and AITW benchmark, \textsc{OmniParser} with screenshot only input
outperforms the GPT-4V baselines requiring additional information outside of
screenshot.",2024-08-01,"Yadong Lu, Jianwei Yang, Yelong Shen, Ahmed Awadallah",http://arxiv.org/pdf/2408.00203v1,cs.CL
Data is missing again -- Reconstruction of power generation data using $k$-Nearest Neighbors and spectral graph theory,"The risk of missing data and subsequent incomplete data records at wind farms
increases with the number of turbines and sensors. We propose here an
imputation method that blends data-driven concepts with expert knowledge, by
using the geometry of the wind farm in order to provide better estimates when
performing Nearest Neighbor imputation. Our method relies on learning Laplacian
eigenmaps out of the graph of the wind farm through spectral graph theory.
These learned representations can be based on the wind farm layout only, or
additionally account for information provided by collected data. The related
weighted graph is allowed to change with time and can be tracked in an online
fashion. Application to the Westermost Rough offshore wind farm shows
significant improvement over approaches that do not account for the wind farm
layout information.",2024-08-30,"Amandine Pierrot, Pierre Pinson",http://arxiv.org/pdf/2409.00300v1,cs.LG
On Expressive Power of Quantized Neural Networks under Fixed-Point Arithmetic,"Research into the expressive power of neural networks typically considers
real parameters and operations without rounding error. In this work, we study
universal approximation property of quantized networks under discrete
fixed-point parameters and fixed-point operations that may incur errors due to
rounding. We first provide a necessary condition and a sufficient condition on
fixed-point arithmetic and activation functions for universal approximation of
quantized networks. Then, we show that various popular activation functions
satisfy our sufficient condition, e.g., Sigmoid, ReLU, ELU, SoftPlus, SiLU,
Mish, and GELU. In other words, networks using those activation functions are
capable of universal approximation. We further show that our necessary
condition and sufficient condition coincide under a mild condition on
activation functions: e.g., for an activation function $\sigma$, there exists a
fixed-point number $x$ such that $\sigma(x)=0$. Namely, we find a necessary and
sufficient condition for a large class of activation functions. We lastly show
that even quantized networks using binary weights in $\{-1,1\}$ can also
universally approximate for practical activation functions.",2024-08-30,"Geonho Hwang, Yeachan Park, Sejun Park",http://arxiv.org/pdf/2409.00297v1,cs.LG
Credit Scores: Performance and Equity,"Credit scores are critical for allocating consumer debt in the United States,
yet little evidence is available on their performance. We benchmark a widely
used credit score against a machine learning model of consumer default and find
significant misclassification of borrowers, especially those with low scores.
Our model improves predictive accuracy for young, low-income, and minority
groups due to its superior performance with low quality data, resulting in a
gain in standing for these populations. Our findings suggest that improving
credit scoring performance could lead to more equitable access to credit.",2024-08-30,"Stefania Albanesi, Domonkos F. Vamossy",http://arxiv.org/pdf/2409.00296v1,cs.LG
Box2Flow: Instance-based Action Flow Graphs from Videos,"A large amount of procedural videos on the web show how to complete various
tasks. These tasks can often be accomplished in different ways and step
orderings, with some steps able to be performed simultaneously, while others
are constrained to be completed in a specific order. Flow graphs can be used to
illustrate the step relationships of a task. Current task-based methods try to
learn a single flow graph for all available videos of a specific task. The
extracted flow graphs tend to be too abstract, failing to capture detailed step
descriptions. In this work, our aim is to learn accurate and rich flow graphs
by extracting them from a single video. We propose Box2Flow, an instance-based
method to predict a step flow graph from a given procedural video. In detail,
we extract bounding boxes from videos, predict pairwise edge probabilities
between step pairs, and build the flow graph with a spanning tree algorithm.
Experiments on MM-ReS and YouCookII show our method can extract flow graphs
effectively.",2024-08-30,"Jiatong Li, Kalliopi Basioti, Vladimir Pavlovic",http://arxiv.org/pdf/2409.00295v1,cs.LG
Quantum Machine Learning for Anomaly Detection in Consumer Electronics,"Anomaly detection is a crucial task in cyber security. Technological
advancement brings new cyber-physical threats like network intrusion, financial
fraud, identity theft, and property invasion. In the rapidly changing world,
with frequently emerging new types of anomalies, classical machine learning
models are insufficient to prevent all the threats. Quantum Machine Learning
(QML) is emerging as a powerful computational tool that can detect anomalies
more efficiently. In this work, we have introduced QML and its applications for
anomaly detection in consumer electronics. We have shown a generic framework
for applying QML algorithms in anomaly detection tasks. We have also briefly
discussed popular supervised, unsupervised, and reinforcement learning-based
QML algorithms and included five case studies of recent works to show their
applications in anomaly detection in the consumer electronics field.",2024-08-30,"Sounak Bhowmik, Himanshu Thapliyal",http://arxiv.org/pdf/2409.00294v1,cs.LG
Reframing Data Value for Large Language Models Through the Lens of Plausibility,"Data valuation seeks to answer the important question, ""How much is this data
worth?"" Existing data valuation methods have largely focused on discriminative
models, primarily examining data value through the lens of its utility in
training. However, with the push for ever-larger language models, relying on
valuation methods that require training becomes increasingly expensive and
dependent on specific techniques. We propose an alternative perspective on the
data value problem for language models, centering around the plausibility of
the data. We posit that data holds lesser value if it can be plausibly
generated by the model itself. Starting from some intuitive criteria that align
with our notions of valuable data, we develop a novel value function that is
computationally tractable and derived from first principles with provable
properties. We conduct a theoretical analysis of our value function and
evaluate it across multiple scenarios and datasets.",2024-08-30,"Mohamad Rida Rammal, Ruida Zhou, Suhas Diggavi",http://arxiv.org/pdf/2409.00284v2,cs.LG
Exact Recovery Guarantees for Parameterized Nonlinear System Identification Problem under Sparse Disturbances or Semi-Oblivious Attacks,"In this work, we study the problem of learning a nonlinear dynamical system
by parameterizing its dynamics using basis functions. We assume that
disturbances occur at each time step with an arbitrary probability $p$, which
models the sparsity level of the disturbance vectors over time. These
disturbances are drawn from an arbitrary, unknown probability distribution,
which may depend on past disturbances, provided that it satisfies a zero-mean
assumption. The primary objective of this paper is to learn the system's
dynamics within a finite time and analyze the sample complexity as a function
of $p$. To achieve this, we examine a LASSO-type non-smooth estimator, and
establish necessary and sufficient conditions for its well-specifiedness and
the uniqueness of the global solution to the underlying optimization problem.
We then provide exact recovery guarantees for the estimator under two distinct
conditions: boundedness and Lipschitz continuity of the basis functions. We
show that finite-time exact recovery is achieved with high probability, even
when $p$ approaches 1. Unlike prior works, which primarily focus on independent
and identically distributed (i.i.d.) disturbances and provide only asymptotic
guarantees for system learning, this study presents the first finite-time
analysis of nonlinear dynamical systems under a highly general disturbance
model. Our framework allows for possible temporal correlations in the
disturbances and accommodates semi-oblivious adversarial attacks, significantly
broadening the scope of existing theoretical results.",2024-08-30,"Haixiang Zhang, Baturalp Yalcin, Javad Lavaei, Eduardo D. Sontag",http://arxiv.org/pdf/2409.00276v3,cs.LG
"Explainable Artificial Intelligence: A Survey of Needs, Techniques, Applications, and Future Direction","Artificial intelligence models encounter significant challenges due to their
black-box nature, particularly in safety-critical domains such as healthcare,
finance, and autonomous vehicles. Explainable Artificial Intelligence (XAI)
addresses these challenges by providing explanations for how these models make
decisions and predictions, ensuring transparency, accountability, and fairness.
Existing studies have examined the fundamental concepts of XAI, its general
principles, and the scope of XAI techniques. However, there remains a gap in
the literature as there are no comprehensive reviews that delve into the
detailed mathematical representations, design methodologies of XAI models, and
other associated aspects. This paper provides a comprehensive literature review
encompassing common terminologies and definitions, the need for XAI,
beneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI
methods in different application areas. The survey is aimed at XAI researchers,
XAI practitioners, AI model developers, and XAI beneficiaries who are
interested in enhancing the trustworthiness, transparency, accountability, and
fairness of their AI models.",2024-08-30,"Melkamu Mersha, Khang Lam, Joseph Wood, Ali AlShami, Jugal Kalita",http://arxiv.org/pdf/2409.00265v2,cs.LG
"Reconstructing unsteady flows from sparse, noisy measurements with a physics-constrained convolutional neural network","Data from fluid flow measurements are typically sparse, noisy, and
heterogeneous, often from mixed pressure and velocity measurements, resulting
in incomplete datasets. In this paper, we develop a physics-constrained
convolutional neural network, which is a deterministic tool, to reconstruct the
full flow field from incomplete data. We explore three loss functions, both
from machine learning literature and newly proposed: (i) the softly-constrained
loss, which allows the prediction to take any value; (ii) the snapshot-enforced
loss, which constrains the prediction at the sensor locations; and (iii) the
mean-enforced loss, which constrains the mean of the prediction at the sensor
locations. The proposed methods do not require the full flow field during
training, making it suitable for reconstruction from incomplete data. We apply
the method to reconstruct a laminar wake of a bluff body and a turbulent
Kolmogorov flow. First, we assume that measurements are not noisy and
reconstruct both the laminar wake and the Kolmogorov flow from sensors located
at fewer than 1% of all grid points. The snapshot-enforced loss reduces the
reconstruction error of the Kolmogorov flow by approximately 25% compared to
the softly-constrained loss. Second, we assume that measurements are noisy and
propose the mean-enforced loss to reconstruct the laminar wake and the
Kolmogorov flow at three different signal-to-noise ratios. We find that, across
the ratios tested, the loss functions with harder constraints are more robust
to both the random initialization of the networks and the noise levels in the
measurements. At high noise levels, the mean-enforced loss can recover the
instantaneous snapshots accurately, making it the suitable choice when
reconstructing flows from data corrupted with an unknown amount of noise. The
proposed method opens opportunities for physical flow reconstruction from
sparse, noisy data.",2024-08-30,"Yaxin Mo, Luca Magri",http://arxiv.org/pdf/2409.00260v1,cs.LG
Improving the Region of Attraction of a Multi-rotor UAV by Estimating Unknown Disturbances,"This study presents a machine learning-aided approach to accurately estimate
the region of attraction (ROA) of a multi-rotor unmanned aerial vehicle (UAV)
controlled using a linear quadratic regulator (LQR) controller. Conventional
ROA estimation approaches rely on a nominal dynamic model for ROA calculation,
leading to inaccurate estimation due to unknown dynamics and disturbances
associated with the physical system. To address this issue, our study utilizes
a neural network to predict these unknown disturbances of a planar quadrotor.
The nominal model integrated with the learned disturbances is then employed to
calculate the ROA of the planer quadrotor using a graphical technique. The
estimated ROA is then compared with the ROA calculated using Lyapunov analysis
and the graphical approach without incorporating the learned disturbances. The
results illustrated that the proposed method provides a more accurate
estimation of the ROA, while the conventional Lyapunov-based estimation tends
to be more conservative.",2024-08-30,"Sachithra Atapattu, Oscar De Silva, Thumeera R Wanasinghe, George K I Mann, Raymond G Gosine",http://arxiv.org/pdf/2409.00257v1,cs.LG
Building Better Datasets: Seven Recommendations for Responsible Design from Dataset Creators,"The increasing demand for high-quality datasets in machine learning has
raised concerns about the ethical and responsible creation of these datasets.
Dataset creators play a crucial role in developing responsible practices, yet
their perspectives and expertise have not yet been highlighted in the current
literature. In this paper, we bridge this gap by presenting insights from a
qualitative study that included interviewing 18 leading dataset creators about
the current state of the field. We shed light on the challenges and
considerations faced by dataset creators, and our findings underscore the
potential for deeper collaboration, knowledge sharing, and collective
development. Through a close analysis of their perspectives, we share seven
central recommendations for improving responsible dataset creation, including
issues such as data quality, documentation, privacy and consent, and how to
mitigate potential harms from unintended use cases. By fostering critical
reflection and sharing the experiences of dataset creators, we aim to promote
responsible dataset creation practices and develop a nuanced understanding of
this crucial but often undervalued aspect of machine learning research.",2024-08-30,"Will Orr, Kate Crawford",http://arxiv.org/pdf/2409.00252v1,cs.LG
Unveiling Processing--Property Relationships in Laser Powder Bed Fusion: The Synergy of Machine Learning and High-throughput Experiments,"Achieving desired mechanical properties in additive manufacturing requires
many experiments and a well-defined design framework becomes crucial in
reducing trials and conserving resources. Here, we propose a methodology
embracing the synergy between high-throughput (HT) experimentation and
hierarchical machine learning (ML) to unveil the complex relationships between
a large set of process parameters in Laser Powder Bed Fusion (LPBF) and
selected mechanical properties (tensile strength and ductility). The HT method
envisions the fabrication of small samples for rapid automated hardness and
porosity characterization, and a smaller set of tensile specimens for more
labor-intensive direct measurement of yield strength and ductility. The ML
approach is based on a sequential application of Gaussian processes (GPs) where
the correlations between process parameters and hardness/porosity are first
learnt and subsequently adopted by the GPs that relate strength and ductility
to process parameters. Finally, an optimization scheme is devised that
leverages these GPs to identify the processing parameters that maximize
combinations of strength and ductility. By founding the learning on larger
easy-to-collect and smaller labor-intensive data, we reduce the reliance on
expensive characterization and enable exploration of a large processing space.
Our approach is material-agnostic and herein we demonstrate its application on
17-4PH stainless steel.",2024-08-30,"Mahsa Amiri, Zahra Zanjani Foumani, Penghui Cao, Lorenzo Valdevit, Ramin Bostanabad",http://arxiv.org/pdf/2409.00248v1,cs.LG
TorchDA: A Python package for performing data assimilation with deep learning forward and transformation functions,"Data assimilation techniques are often confronted with challenges handling
complex high dimensional physical systems, because high precision simulation in
complex high dimensional physical systems is computationally expensive and the
exact observation functions that can be applied in these systems are difficult
to obtain. It prompts growing interest in integrating deep learning models
within data assimilation workflows, but current software packages for data
assimilation cannot handle deep learning models inside. This study presents a
novel Python package seamlessly combining data assimilation with deep neural
networks to serve as models for state transition and observation functions. The
package, named TorchDA, implements Kalman Filter, Ensemble Kalman Filter
(EnKF), 3D Variational (3DVar), and 4D Variational (4DVar) algorithms, allowing
flexible algorithm selection based on application requirements. Comprehensive
experiments conducted on the Lorenz 63 and a two-dimensional shallow water
system demonstrate significantly enhanced performance over standalone model
predictions without assimilation. The shallow water analysis validates data
assimilation capabilities mapping between different physical quantity spaces in
either full space or reduced order space. Overall, this innovative software
package enables flexible integration of deep learning representations within
data assimilation, conferring a versatile tool to tackle complex high
dimensional dynamical systems across scientific domains.",2024-08-30,"Sibo Cheng, Jinyang Min, Che Liu, Rossella Arcucci",http://arxiv.org/pdf/2409.00244v1,cs.LG
One-Frame Calibration with Siamese Network in Facial Action Unit Recognition,"Automatic facial action unit (AU) recognition is used widely in facial
expression analysis. Most existing AU recognition systems aim for
cross-participant non-calibrated generalization (NCG) to unseen faces without
further calibration. However, due to the diversity of facial attributes across
different identities, accurately inferring AU activation from single images of
an unseen face is sometimes infeasible, even for human experts -- it is crucial
to first understand how the face appears in its neutral expression, or
significant bias may be incurred. Therefore, we propose to perform one-frame
calibration (OFC) in AU recognition: for each face, a single image of its
neutral expression is used as the reference image for calibration. With this
strategy, we develop a Calibrating Siamese Network (CSN) for AU recognition and
demonstrate its remarkable effectiveness with a simple iResNet-50 (IR50)
backbone. On the DISFA, DISFA+, and UNBC-McMaster datasets, we show that our
OFC CSN-IR50 model (a) substantially improves the performance of IR50 by
mitigating facial attribute biases (including biases due to wrinkles, eyebrow
positions, facial hair, etc.), (b) substantially outperforms the naive OFC
method of baseline subtraction as well as (c) a fine-tuned version of this
naive OFC method, and (d) also outperforms state-of-the-art NCG models for both
AU intensity estimation and AU detection.",2024-08-30,"Shuangquan Feng, Virginia R. de Sa",http://arxiv.org/pdf/2409.00240v1,cs.LG
Deep learning surrogate models of JULES-INFERNO for wildfire prediction on a global scale,"Global wildfire models play a crucial role in anticipating and responding to
changing wildfire regimes. JULES-INFERNO is a global vegetation and fire model
simulating wildfire emissions and area burnt on a global scale. However,
because of the high data dimensionality and system complexity, JULES-INFERNO's
computational costs make it challenging to apply to fire risk forecasting with
unseen initial conditions. Typically, running JULES-INFERNO for 30 years of
prediction will take several hours on High Performance Computing (HPC)
clusters. To tackle this bottleneck, two data-driven models are built in this
work based on Deep Learning techniques to surrogate the JULES-INFERNO model and
speed up global wildfire forecasting. More precisely, these machine learning
models take global temperature, vegetation density, soil moisture and previous
forecasts as inputs to predict the subsequent global area burnt on an iterative
basis. Average Error per Pixel (AEP) and Structural Similarity Index Measure
(SSIM) are used as metrics to evaluate the performance of the proposed
surrogate models. A fine tuning strategy is also proposed in this work to
improve the algorithm performance for unseen scenarios. Numerical results show
a strong performance of the proposed models, in terms of both computational
efficiency (less than 20 seconds for 30 years of prediction on a laptop CPU)
and prediction accuracy (with AEP under 0.3\% and SSIM over 98\% compared to
the outputs of JULES-INFERNO).",2024-08-30,"Sibo Cheng, Hector Chassagnon, Matthew Kasoar, Yike Guo, Rossella Arcucci",http://arxiv.org/pdf/2409.00237v1,cs.LG
Spatially-Aware Diffusion Models with Cross-Attention for Global Field Reconstruction with Sparse Observations,"Diffusion models have gained attention for their ability to represent complex
distributions and incorporate uncertainty, making them ideal for robust
predictions in the presence of noisy or incomplete data. In this study, we
develop and enhance score-based diffusion models in field reconstruction tasks,
where the goal is to estimate complete spatial fields from partial
observations. We introduce a condition encoding approach to construct a
tractable mapping mapping between observed and unobserved regions using a
learnable integration of sparse observations and interpolated fields as an
inductive bias. With refined sensing representations and an unraveled temporal
dimension, our method can handle arbitrary moving sensors and effectively
reconstruct fields. Furthermore, we conduct a comprehensive benchmark of our
approach against a deterministic interpolation-based method across various
static and time-dependent PDEs. Our study attempts to addresses the gap in
strong baselines for evaluating performance across varying sampling
hyperparameters, noise levels, and conditioning methods. Our results show that
diffusion models with cross-attention and the proposed conditional encoding
generally outperform other methods under noisy conditions, although the
deterministic method excels with noiseless data. Additionally, both the
diffusion models and the deterministic method surpass the numerical approach in
accuracy and computational cost for the steady problem. We also demonstrate the
ability of the model to capture possible reconstructions and improve the
accuracy of fused results in covariance-based correction tasks using ensemble
sampling.",2024-08-30,"Yilin Zhuang, Sibo Cheng, Karthik Duraisamy",http://arxiv.org/pdf/2409.00230v2,cs.LG
Learning Latent Space Dynamics with Model-Form Uncertainties: A Stochastic Reduced-Order Modeling Approach,"This paper presents a probabilistic approach to represent and quantify
model-form uncertainties in the reduced-order modeling of complex systems using
operator inference techniques. Such uncertainties can arise in the selection of
an appropriate state-space representation, in the projection step that
underlies many reduced-order modeling methods, or as a byproduct of
considerations made during training, to name a few. Following previous works in
the literature, the proposed method captures these uncertainties by expanding
the approximation space through the randomization of the projection matrix.
This is achieved by combining Riemannian projection and retraction operators -
acting on a subset of the Stiefel manifold - with an information-theoretic
formulation. The efficacy of the approach is assessed on canonical problems in
fluid mechanics by identifying and quantifying the impact of model-form
uncertainties on the inferred operators.",2024-08-30,"Jin Yi Yong, Rudy Geelen, Johann Guilleminot",http://arxiv.org/pdf/2409.00220v2,cs.LG
Enhancing Event Reasoning in Large Language Models through Instruction Fine-Tuning with Semantic Causal Graphs,"Event detection and text reasoning have become critical applications across
various domains. While LLMs have recently demonstrated impressive progress in
reasoning abilities, they often struggle with event detection, particularly due
to the absence of training methods that consider causal relationships between
event triggers and types. To address this challenge, we propose a novel
approach for instruction fine-tuning LLMs for event detection. Our method
introduces Semantic Causal Graphs (SCGs) to capture both causal relationships
and contextual information within text. Building off of SCGs, we propose SCG
Instructions for fine-tuning LLMs by focusing on event triggers and their
relationships to event types, and employ Low-Rank Adaptation (LoRA) to help
preserve the general reasoning abilities of LLMs. Our evaluations demonstrate
that training LLMs with SCG Instructions outperforms standard instruction
fine-tuning by an average of 35.69\% on Event Trigger Classification. Notably,
our fine-tuned Mistral 7B model also outperforms GPT-4 on key event detection
metrics by an average of 31.01\% on Event Trigger Identification, 37.40\% on
Event Trigger Classification, and 16.43\% on Event Classification. We analyze
the retention of general capabilities, observing only a minimal average drop of
2.03 points across six benchmarks. This comprehensive study investigates
multiple LLMs for the event detection task across various datasets, prompting
strategies, and training approaches.",2024-08-30,"Mazal Bethany, Emet Bethany, Brandon Wherry, Cho-Yu Chiang, Nishant Vishwamitra, Anthony Rios, Peyman Najafirad",http://arxiv.org/pdf/2409.00209v1,cs.LG
Unintentional Security Flaws in Code: Automated Defense via Root Cause Analysis,"Software security remains a critical concern, particularly as junior
developers, often lacking comprehensive knowledge of security practices,
contribute to codebases. While there are tools to help developers proactively
write secure code, their actual effectiveness in helping developers fix their
vulnerable code remains largely unmeasured. Moreover, these approaches
typically focus on classifying and localizing vulnerabilities without
highlighting the specific code segments that are the root cause of the issues,
a crucial aspect for developers seeking to fix their vulnerable code. To
address these challenges, we conducted a comprehensive study evaluating the
efficacy of existing methods in helping junior developers secure their code.
Our findings across five types of security vulnerabilities revealed that
current tools enabled developers to secure only 36.2\% of vulnerable code.
Questionnaire results from these participants further indicated that not
knowing the code that was the root cause of the vulnerability was one of their
primary challenges in repairing the vulnerable code. Informed by these
insights, we developed an automated vulnerability root cause (RC) toolkit
called T5-RCGCN, that combines T5 language model embeddings with a graph
convolutional network (GCN) for vulnerability classification and localization.
Additionally, we integrated DeepLiftSHAP to identify the code segments that
were the root cause of the vulnerability. We tested T5-RCGCN with 56 junior
developers across three datasets, showing a 28.9\% improvement in code security
compared to previous methods. Developers using the tool also gained a deeper
understanding of vulnerability root causes, resulting in a 17.0\% improvement
in their ability to secure code independently. These results demonstrate the
tool's potential for both immediate security enhancement and long-term
developer skill growth.",2024-08-30,"Nafis Tanveer Islam, Mazal Bethany, Dylan Manuel, Murtuza Jadliwala, Peyman Najafirad",http://arxiv.org/pdf/2409.00199v1,cs.LG
A Generative Adversarial Network-based Method for LiDAR-Assisted Radar Image Enhancement,"This paper presents a generative adversarial network (GAN) based approach for
radar image enhancement. Although radar sensors remain robust for operations
under adverse weather conditions, their application in autonomous vehicles
(AVs) is commonly limited by the low-resolution data they produce. The primary
goal of this study is to enhance the radar images to better depict the details
and features of the environment, thereby facilitating more accurate object
identification in AVs. The proposed method utilizes high-resolution,
two-dimensional (2D) projected light detection and ranging (LiDAR) point clouds
as ground truth images and low-resolution radar images as inputs to train the
GAN. The ground truth images were obtained through two main steps. First, a
LiDAR point cloud map was generated by accumulating raw LiDAR scans. Then, a
customized LiDAR point cloud cropping and projection method was employed to
obtain 2D projected LiDAR point clouds. The inference process of the proposed
method relies solely on radar images to generate an enhanced version of them.
The effectiveness of the proposed method is demonstrated through both
qualitative and quantitative results. These results show that the proposed
method can generate enhanced images with clearer object representation compared
to the input radar images, even under adverse weather conditions.",2024-08-30,"Thakshila Thilakanayake, Oscar De Silva, Thumeera R. Wanasinghe, George K. Mann, Awantha Jayasiri",http://arxiv.org/pdf/2409.00196v1,cs.LG
SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection,"Synthesizing the voices of unseen speakers remains a persisting challenge in
multi-speaker text-to-speech (TTS). Existing methods model speaker
characteristics through speaker conditioning during training, leading to
increased model complexity and limiting reproducibility and accessibility. A
lower-complexity method would enable speech synthesis research with limited
computational and data resources to reach to a wider use. To this end, we
propose SelectTTS, a simple and effective alternative. SelectTTS selects
appropriate frames from the target speaker and decodes them using frame-level
self-supervised learning (SSL) features. We demonstrate that this approach can
effectively capture speaker characteristics for unseen speakers and achieves
performance comparable to state-of-the-art multi-speaker TTS frameworks on both
objective and subjective metrics. By directly selecting frames from the target
speaker's speech, SelectTTS enables generalization to unseen speakers with
significantly lower model complexity. Compared to baselines such as XTTS-v2 and
VALL-E, SelectTTS achieves better speaker similarity while reducing model
parameters by over 8x and training data requirements by 270x.",2024-08-30,"Ismail Rasim Ulgen, Shreeram Suresh Chandra, Junchen Lu, Berrak Sisman",http://arxiv.org/pdf/2408.17432v2,cs.LG
Fairness-Aware Estimation of Graphical Models,"This paper examines the issue of fairness in the estimation of graphical
models (GMs), particularly Gaussian, Covariance, and Ising models. These models
play a vital role in understanding complex relationships in high-dimensional
data. However, standard GMs can result in biased outcomes, especially when the
underlying data involves sensitive characteristics or protected groups. To
address this, we introduce a comprehensive framework designed to reduce bias in
the estimation of GMs related to protected attributes. Our approach involves
the integration of the pairwise graph disparity error and a tailored loss
function into a nonsmooth multi-objective optimization problem, striving to
achieve fairness across different sensitive groups while maintaining the
effectiveness of the GMs. Experimental evaluations on synthetic and real-world
datasets demonstrate that our framework effectively mitigates bias without
undermining GMs' performance.",2024-08-30,"Zhuoping Zhou, Davoud Ataee Tarzanagh, Bojian Hou, Qi Long, Li Shen",http://arxiv.org/pdf/2408.17396v2,cs.LG
Continual learning with the neural tangent ensemble,"A natural strategy for continual learning is to weigh a Bayesian ensemble of
fixed functions. This suggests that if a (single) neural network could be
interpreted as an ensemble, one could design effective algorithms that learn
without forgetting. To realize this possibility, we observe that a neural
network classifier with N parameters can be interpreted as a weighted ensemble
of N classifiers, and that in the lazy regime limit these classifiers are fixed
throughout learning. We call these classifiers the neural tangent experts and
show they output valid probability distributions over the labels. We then
derive the likelihood and posterior probability of each expert given past data.
Surprisingly, the posterior updates for these experts are equivalent to a
scaled and projected form of stochastic gradient descent (SGD) over the network
weights. Away from the lazy regime, networks can be seen as ensembles of
adaptive experts which improve over time. These results offer a new
interpretation of neural networks as Bayesian ensembles of experts, providing a
principled framework for understanding and mitigating catastrophic forgetting
in continual learning settings.",2024-08-30,"Ari S. Benjamin, Christian Pehle, Kyle Daruwalla",http://arxiv.org/pdf/2408.17394v2,cs.LG
Bayesian Optimization for Non-Convex Two-Stage Stochastic Optimization Problems,"Bayesian optimization is a sample-efficient method for solving expensive,
black-box optimization problems. Stochastic programming concerns optimization
under uncertainty where, typically, average performance is the quantity of
interest. In the first stage of a two-stage problem, here-and-now decisions
must be made in the face of uncertainty, while in the second stage,
wait-and-see decisions are made after the uncertainty has been resolved. Many
methods in stochastic programming assume that the objective is cheap to
evaluate and linear or convex. We apply Bayesian optimization to solve
non-convex, two-stage stochastic programs which are black-box and expensive to
evaluate as, for example, is often the case with simulation objectives. We
formulate a knowledge-gradient-based acquisition function to jointly optimize
the first- and second-stage variables, establish a guarantee of asymptotic
consistency, and provide a computationally efficient approximation. We
demonstrate comparable empirical results to an alternative we formulate with
fewer approximations, which alternates its focus between the two variable
types, and superior empirical results over the state of the art and the
standard, na\""ive, two-step benchmark.",2024-08-30,"Jack M. Buckingham, Ivo Couckuyt, Juergen Branke",http://arxiv.org/pdf/2408.17387v2,cs.LG
LASSO-MOGAT: A Multi-Omics Graph Attention Framework for Cancer Classification,"The application of machine learning methods to analyze changes in gene
expression patterns has recently emerged as a powerful approach in cancer
research, enhancing our understanding of the molecular mechanisms underpinning
cancer development and progression. Combining gene expression data with other
types of omics data has been reported by numerous works to improve cancer
classification outcomes. Despite these advances, effectively integrating
high-dimensional multi-omics data and capturing the complex relationships
across different biological layers remains challenging. This paper introduces
LASSO-MOGAT (LASSO-Multi-Omics Gated ATtention), a novel graph-based deep
learning framework that integrates messenger RNA, microRNA, and DNA methylation
data to classify 31 cancer types. Utilizing differential expression analysis
with LIMMA and LASSO regression for feature selection, and leveraging Graph
Attention Networks (GATs) to incorporate protein-protein interaction (PPI)
networks, LASSO-MOGAT effectively captures intricate relationships within
multi-omics data. Experimental validation using five-fold cross-validation
demonstrates the method's precision, reliability, and capacity for providing
comprehensive insights into cancer molecular mechanisms. The computation of
attention coefficients for the edges in the graph by the proposed
graph-attention architecture based on protein-protein interactions proved
beneficial for identifying synergies in multi-omics data for cancer
classification.",2024-08-30,"Fadi Alharbi, Aleksandar Vakanski, Murtada K. Elbashir, Mohanad Mohammed",http://arxiv.org/pdf/2408.17384v1,cs.LG
MoRe Fine-Tuning with 10x Fewer Parameters,"Parameter-efficient fine-tuning (PEFT) techniques have unlocked the potential
to cheaply and easily specialize large pretrained models. However, the most
prominent approaches, like low-rank adapters (LoRA), depend on heuristics or
rules-of-thumb for their architectural choices -- potentially limiting their
performance for new models and architectures. This limitation suggests that
techniques from neural architecture search could be used to obtain optimal
adapter architectures, but these are often expensive and difficult to
implement. We address this challenge with Monarch Rectangular Fine-tuning
(MoRe), a simple framework to search over adapter architectures that relies on
the Monarch matrix class. Theoretically, we show that MoRe is more expressive
than LoRA. Empirically, our approach is more parameter-efficient and performant
than state-of-the-art PEFTs on a range of tasks and models, with as few as 5\%
of LoRA's parameters.",2024-08-30,"Wenxuan Tan, Nicholas Roberts, Tzu-Heng Huang, Jitian Zhao, John Cooper, Samuel Guo, Chengyu Duan, Frederic Sala",http://arxiv.org/pdf/2408.17383v2,cs.LG
Deep Neural Networks for Predicting Recurrence and Survival in Patients with Esophageal Cancer After Surgery,"Esophageal cancer is a major cause of cancer-related mortality
internationally, with high recurrence rates and poor survival even among
patients treated with curative-intent surgery. Investigating relevant
prognostic factors and predicting prognosis can enhance post-operative clinical
decision-making and potentially improve patients' outcomes. In this work, we
assessed prognostic factor identification and discriminative performances of
three models for Disease-Free Survival (DFS) and Overall Survival (OS) using a
large multicenter international dataset from ENSURE study. We first employed
Cox Proportional Hazards (CoxPH) model to assess the impact of each feature on
outcomes. Subsequently, we utilised CoxPH and two deep neural network
(DNN)-based models, DeepSurv and DeepHit, to predict DFS and OS. The
significant prognostic factors identified by our models were consistent with
clinical literature, with post-operative pathologic features showing higher
significance than clinical stage features. DeepSurv and DeepHit demonstrated
comparable discriminative accuracy to CoxPH, with DeepSurv slightly
outperforming in both DFS and OS prediction tasks, achieving C-index of 0.735
and 0.74, respectively. While these results suggested the potential of DNNs as
prognostic tools for improving predictive accuracy and providing personalised
guidance with respect to risk stratification, CoxPH still remains an adequately
good prediction model, with the data used in this study.",2024-08-30,"Yuhan Zheng, Jessie A Elliott, John V Reynolds, Sheraz R Markar, Bartłomiej W. Papież, ENSURE study group",http://arxiv.org/pdf/2409.00163v1,cs.LG
Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control,"Model-based reinforcement learning (RL) is anticipated to exhibit higher
sample efficiency compared to model-free RL by utilizing a virtual environment
model. However, it is challenging to obtain sufficiently accurate
representations of the environmental dynamics due to uncertainties in complex
systems and environments. An inaccurate environment model may degrade the
sample efficiency and performance of model-based RL. Furthermore, while
model-based RL can improve sample efficiency, it often still requires
substantial training time to learn from scratch, potentially limiting its
advantages over model-free approaches. To address these challenges, this paper
introduces a knowledge-informed model-based residual reinforcement learning
framework aimed at enhancing learning efficiency by infusing established expert
knowledge into the learning process and avoiding the issue of beginning from
zero. Our approach integrates traffic expert knowledge into a virtual
environment model, employing the Intelligent Driver Model (IDM) for basic
dynamics and neural networks for residual dynamics, thus ensuring adaptability
to complex scenarios. We propose a novel strategy that combines traditional
control methods with residual RL, facilitating efficient learning and policy
optimization without the need to learn from scratch. The proposed approach is
applied to CAV trajectory control tasks for the dissipation of stop-and-go
waves in mixed traffic flow. Experimental results demonstrate that our proposed
approach enables the CAV agent to achieve superior performance in trajectory
control compared to the baseline agents in terms of sample efficiency, traffic
flow smoothness and traffic mobility. The source code and supplementary
materials are available at: https://zihaosheng.github.io/traffic-expertise-RL/.",2024-08-30,"Zihao Sheng, Zilin Huang, Sikai Chen",http://arxiv.org/pdf/2408.17380v2,cs.LG
Exploring the Impact of Environmental Pollutants on Multiple Sclerosis Progression,"Multiple Sclerosis (MS) is a chronic autoimmune and inflammatory neurological
disorder characterised by episodes of symptom exacerbation, known as relapses.
In this study, we investigate the role of environmental factors in relapse
occurrence among MS patients, using data from the H2020 BRAINTEASER project. We
employed predictive models, including Random Forest (RF) and Logistic
Regression (LR), with varying sets of input features to predict the occurrence
of relapses based on clinical and pollutant data collected over a week. The RF
yielded the best result, with an AUC-ROC score of 0.713. Environmental
variables, such as precipitation, NO2, PM2.5, humidity, and temperature, were
found to be relevant to the prediction.",2024-08-30,"Elena Marinello, Erica Tavazzi, Enrico Longato, Pietro Bosoni, Arianna Dagliati, Mahin Vazifehdan, Riccardo Bellazzi, Isotta Trescato, Alessandro Guazzo, Martina Vettoretti, Eleonora Tavazzi, Lara Ahmad, Roberto Bergamaschi, Paola Cavalla, Umberto Manera, Adriano Chio, Barbara Di Camillo",http://arxiv.org/pdf/2408.17376v1,cs.LG
Learning-Based Finite Element Methods Modeling for Complex Mechanical Systems,"Complex mechanic systems simulation is important in many real-world
applications. The de-facto numeric solver using Finite Element Method (FEM)
suffers from computationally intensive overhead. Though with many progress on
the reduction of computational time and acceptable accuracy, the recent CNN or
GNN-based simulation models still struggle to effectively represent complex
mechanic simulation caused by the long-range spatial dependency of distance
mesh nodes and independently learning local and global representation. In this
paper, we propose a novel two-level mesh graph network. The key of the network
is to interweave the developed Graph Block and Attention Block to better learn
mechanic interactions even for long-rang spatial dependency. Evaluation on
three synthetic and one real datasets demonstrates the superiority of our work.
For example, on the Beam dataset, our work leads to 54.3\% lower prediction
errors and 9.87\% fewer learnable network parameters.",2024-08-30,"Jiasheng Shi, Fu Lin, Weixiong Rao",http://arxiv.org/pdf/2409.00160v1,cs.LG
Leveraging Graph Neural Networks to Forecast Electricity Consumption,"Accurate electricity demand forecasting is essential for several reasons,
especially as the integration of renewable energy sources and the transition to
a decentralized network paradigm introduce greater complexity and uncertainty.
The proposed methodology leverages graph-based representations to effectively
capture the spatial distribution and relational intricacies inherent in this
decentralized network structure. This research work offers a novel approach
that extends beyond the conventional Generalized Additive Model framework by
considering models like Graph Convolutional Networks or Graph SAGE. These
graph-based models enable the incorporation of various levels of
interconnectedness and information sharing among nodes, where each node
corresponds to the combined load (i.e. consumption) of a subset of consumers
(e.g. the regions of a country). More specifically, we introduce a range of
methods for inferring graphs tailored to consumption forecasting, along with a
framework for evaluating the developed models in terms of both performance and
explainability. We conduct experiments on electricity forecasting, in both a
synthetic and a real framework considering the French mainland regions, and the
performance and merits of our approach are discussed.",2024-08-30,"Eloi Campagne, Yvenn Amara-Ouali, Yannig Goude, Argyris Kalogeratos",http://arxiv.org/pdf/2408.17366v1,cs.LG
Hold Me Tight: Stable Encoder-Decoder Design for Speech Enhancement,"Convolutional layers with 1-D filters are often used as frontend to encode
audio signals. Unlike fixed time-frequency representations, they can adapt to
the local characteristics of input data. However, 1-D filters on raw audio are
hard to train and often suffer from instabilities. In this paper, we address
these problems with hybrid solutions, i.e., combining theory-driven and
data-driven approaches. First, we preprocess the audio signals via a auditory
filterbank, guaranteeing good frequency localization for the learned encoder.
Second, we use results from frame theory to define an unsupervised learning
objective that encourages energy conservation and perfect reconstruction.
Third, we adapt mixed compressed spectral norms as learning objectives to the
encoder coefficients. Using these solutions in a low-complexity
encoder-mask-decoder model significantly improves the perceptual evaluation of
speech quality (PESQ) in speech enhancement.",2024-08-30,"Daniel Haider, Felix Perfler, Vincent Lostanlen, Martin Ehler, Peter Balazs",http://arxiv.org/pdf/2408.17358v1,cs.LG
C-RADAR: A Centralized Deep Learning System for Intrusion Detection in Software Defined Networks,"The popularity of Software Defined Networks (SDNs) has grown in recent years,
mainly because of their ability to simplify network management and improve
network flexibility. However, this also makes them vulnerable to various types
of cyber attacks. SDNs work on a centralized control plane which makes them
more prone to network attacks. Research has demonstrated that deep learning
(DL) methods can be successful in identifying intrusions in conventional
networks, but their application in SDNs is still an open research area. In this
research, we propose the use of DL techniques for intrusion detection in SDNs.
We measure the effectiveness of our method by experimentation on a dataset of
network traffic and comparing it to existing techniques. Our results show that
the DL-based approach outperforms traditional methods in terms of detection
accuracy and computational efficiency. The deep learning architecture that has
been used in this research is a Long Short Term Memory Network and
Self-Attention based architecture i.e. LSTM-Attn which achieves an Fl-score of
0.9721. Furthermore, this technique can be trained to detect new attack
patterns and improve the overall security of SDNs.",2024-08-30,"Osama Mustafa, Khizer Ali, Talha Naqash",http://arxiv.org/pdf/2408.17356v1,cs.LG
Bidirectional Decoding: Improving Action Chunking via Guided Test-Time Sampling,"Predicting and executing a sequence of actions without intermediate
replanning, known as action chunking, is increasingly used in robot learning
from human demonstrations. Yet, its effects on the learned policy remain
inconsistent: some studies find it crucial for achieving strong results, while
others observe decreased performance. In this paper, we first dissect how
action chunking impacts the divergence between a learner and a demonstrator. We
find that action chunking allows the learner to better capture the temporal
dependencies in demonstrations but at the cost of reduced reactivity to
unexpected states. To address this tradeoff, we propose Bidirectional Decoding
(BID), a test-time inference algorithm that bridges action chunking with
closed-loop adaptation. At each timestep, BID samples multiple candidate
predictions and searches for the optimal one based on two criteria: (i)
backward coherence, which favors samples that align with previous decisions;
(ii) forward contrast, which seeks samples of high likelihood for future plans.
By coupling decisions within and across action chunks, BID promotes both
long-term consistency and short-term reactivity. Experimental results show that
our method boosts the performance of two state-of-the-art generative policies
across seven simulation benchmarks and two real-world tasks. Code and videos
are available at https://bid-robot.github.io.",2024-08-30,"Yuejiang Liu, Jubayer Ibn Hamid, Annie Xie, Yoonho Lee, Maximilian Du, Chelsea Finn",http://arxiv.org/pdf/2408.17355v4,cs.LG
Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage,"Fine-tuning large language models on private data for downstream applications
poses significant privacy risks in potentially exposing sensitive information.
Several popular community platforms now offer convenient distribution of a
large variety of pre-trained models, allowing anyone to publish without
rigorous verification. This scenario creates a privacy threat, as pre-trained
models can be intentionally crafted to compromise the privacy of fine-tuning
datasets. In this study, we introduce a novel poisoning technique that uses
model-unlearning as an attack tool. This approach manipulates a pre-trained
language model to increase the leakage of private data during the fine-tuning
process. Our method enhances both membership inference and data extraction
attacks while preserving model utility. Experimental results across different
models, datasets, and fine-tuning setups demonstrate that our attacks
significantly surpass baseline performance. This work serves as a cautionary
note for users who download pre-trained models from unverified sources,
highlighting the potential risks involved.",2024-08-30,"Md Rafi Ur Rashid, Jing Liu, Toshiaki Koike-Akino, Shagufta Mehnaz, Ye Wang",http://arxiv.org/pdf/2408.17354v1,cs.LG
Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection,"Reliable use of deep neural networks (DNNs) for medical image analysis
requires methods to identify inputs that differ significantly from the training
data, called out-of-distribution (OOD), to prevent erroneous predictions. OOD
detection methods can be categorised as either confidence-based (using the
model's output layer for OOD detection) or feature-based (not using the output
layer). We created two new OOD benchmarks by dividing the D7P (dermatology) and
BreastMNIST (ultrasound) datasets into subsets which either contain or don't
contain an artefact (rulers or annotations respectively). Models were trained
with artefact-free images, and images with the artefacts were used as OOD test
sets. For each OOD image, we created a counterfactual by manually removing the
artefact via image processing, to assess the artefact's impact on the model's
predictions. We show that OOD artefacts can boost a model's softmax confidence
in its predictions, due to correlations in training data among other factors.
This contradicts the common assumption that OOD artefacts should lead to more
uncertain outputs, an assumption on which most confidence-based methods rely.
We use this to explain why feature-based methods (e.g. Mahalanobis score)
typically have greater OOD detection performance than confidence-based methods
(e.g. MCP). However, we also show that feature-based methods typically perform
worse at distinguishing between inputs that lead to correct and incorrect
predictions (for both OOD and ID data). Following from these insights, we argue
that a combination of feature-based and confidence-based methods should be used
within DNN pipelines to mitigate their respective weaknesses. These project's
code and OOD benchmarks are available at:
https://github.com/HarryAnthony/Evaluating_OOD_detection.",2024-08-30,"Harry Anthony, Konstantinos Kamnitsas",http://arxiv.org/pdf/2408.17337v1,cs.LG
Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder,"Autism Spectrum Disorder (ASD) is a lifelong condition that significantly
influencing an individual's communication abilities and their social
interactions. Early diagnosis and intervention are critical due to the profound
impact of ASD's characteristic behaviors on foundational developmental stages.
However, limitations of standardized diagnostic tools necessitate the
development of objective and precise diagnostic methodologies. This paper
proposes an end-to-end framework for automatically predicting the social
communication severity of children with ASD from raw speech data. This
framework incorporates an automatic speech recognition model, fine-tuned with
speech data from children with ASD, followed by the application of fine-tuned
pre-trained language models to generate a final prediction score. Achieving a
Pearson Correlation Coefficient of 0.6566 with human-rated scores, the proposed
method showcases its potential as an accessible and objective tool for the
assessment of ASD.",2024-08-30,"Jihyun Mun, Sunhee Kim, Minhwa Chung",http://arxiv.org/pdf/2409.00158v1,cs.LG
Estimation of Cardiac and Non-cardiac Diagnosis from Electrocardiogram Features,"Introduction: Ensuring timely and accurate diagnosis of medical conditions is
paramount for effective patient care. Electrocardiogram (ECG) signals are
fundamental for evaluating a patient's cardiac health and are readily
available. Despite this, little attention has been given to the remarkable
potential of ECG data in detecting non-cardiac conditions.
  Methods: In our study, we used publicly available datasets (MIMIC-IV-ECG-ICD
and ECG-VIEW II) to investigate the feasibility of inferring general diagnostic
conditions from ECG features. To this end, we trained a tree-based model
(XGBoost) based on ECG features and basic demographic features to estimate a
wide range of diagnoses, encompassing both cardiac and non-cardiac conditions.
  Results: Our results demonstrate the reliability of estimating 23 cardiac as
well as 21 non-cardiac conditions above 0.7 AUROC in a statistically
significant manner across a wide range of physiological categories. Our
findings underscore the predictive potential of ECG data in identifying
well-known cardiac conditions. However, even more striking, this research
represents a pioneering effort in systematically expanding the scope of
ECG-based diagnosis to conditions not traditionally associated with the cardiac
system.",2024-08-30,"Juan Miguel Lopez Alcaraz, Nils Strodthoff",http://arxiv.org/pdf/2408.17329v1,cs.LG
Modularity in Transformers: Investigating Neuron Separability & Specialization,"Transformer models are increasingly prevalent in various applications, yet
our understanding of their internal workings remains limited. This paper
investigates the modularity and task specialization of neurons within
transformer architectures, focusing on both vision (ViT) and language (Mistral
7B) models. Using a combination of selective pruning and MoEfication clustering
techniques, we analyze the overlap and specialization of neurons across
different tasks and data subsets. Our findings reveal evidence of task-specific
neuron clusters, with varying degrees of overlap between related tasks. We
observe that neuron importance patterns persist to some extent even in randomly
initialized models, suggesting an inherent structure that training refines.
Additionally, we find that neuron clusters identified through MoEfication
correspond more strongly to task-specific neurons in earlier and later layers
of the models. This work contributes to a more nuanced understanding of
transformer internals and offers insights into potential avenues for improving
model interpretability and efficiency.",2024-08-30,"Nicholas Pochinkov, Thomas Jones, Mohammed Rashidur Rahman",http://arxiv.org/pdf/2408.17324v1,cs.LG
Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering,"The use of transformer-based models is growing rapidly throughout society.
With this growth, it is important to understand how they work, and in
particular, how the attention mechanisms represent concepts. Though there are
many interpretability methods, many look at models through their neuronal
activations, which are poorly understood. We describe different lenses through
which to view neuron activations, and investigate the effectiveness in language
models and vision transformers through various methods of neural ablation: zero
ablation, mean ablation, activation resampling, and a novel approach we term
'peak ablation'. Through experimental analysis, we find that in different
regimes and models, each method can offer the lowest degradation of model
performance compared to other methods, with resampling usually causing the most
significant performance deterioration. We make our code available at
https://github.com/nickypro/investigating-ablation.",2024-08-30,"Nicholas Pochinkov, Ben Pasero, Skylar Shibayama",http://arxiv.org/pdf/2408.17322v1,cs.LG
Fair Best Arm Identification with Fixed Confidence,"In this work, we present a novel framework for Best Arm Identification (BAI)
under fairness constraints, a setting that we refer to as \textit{F-BAI} (fair
BAI). Unlike traditional BAI, which solely focuses on identifying the optimal
arm with minimal sample complexity, F-BAI also includes a set of fairness
constraints. These constraints impose a lower limit on the selection rate of
each arm and can be either model-agnostic or model-dependent. For this setting,
we establish an instance-specific sample complexity lower bound and analyze the
\textit{price of fairness}, quantifying how fairness impacts sample complexity.
Based on the sample complexity lower bound, we propose F-TaS, an algorithm
provably matching the sample complexity lower bound, while ensuring that the
fairness constraints are satisfied. Numerical results, conducted using both a
synthetic model and a practical wireless scheduling application, show the
efficiency of F-TaS in minimizing the sample complexity while achieving low
fairness violations.",2024-08-30,"Alessio Russo, Filippo Vannella",http://arxiv.org/pdf/2408.17313v1,cs.LG
Structuring a Training Strategy to Robustify Perception Models with Realistic Image Augmentations,"Advancing Machine Learning (ML)-based perception models for autonomous
systems necessitates addressing weak spots within the models, particularly in
challenging Operational Design Domains (ODDs). These are environmental
operating conditions of an autonomous vehicle which can contain difficult
conditions, e.g., lens flare at night or objects reflected in a wet street.
This report introduces a novel methodology for training with augmentations to
enhance model robustness and performance in such conditions. The proposed
approach leverages customized physics-based augmentation functions, to generate
realistic training data that simulates diverse ODD scenarios.
  We present a comprehensive framework that includes identifying weak spots in
ML models, selecting suitable augmentations, and devising effective training
strategies. The methodology integrates hyperparameter optimization and latent
space optimization to fine-tune augmentation parameters, ensuring they
maximally improve the ML models' performance. Experimental results demonstrate
improvements in model performance, as measured by commonly used metrics such as
mean Average Precision (mAP) and mean Intersection over Union (mIoU) on
open-source object detection and semantic segmentation models and datasets.
  Our findings emphasize that optimal training strategies are model- and
data-specific and highlight the benefits of integrating augmentations into the
training pipeline. By incorporating augmentations, we observe enhanced
robustness of ML-based perception models, making them more resilient to edge
cases encountered in real-world ODDs. This work underlines the importance of
customized augmentations and offers an effective solution for improving the
safety and reliability of autonomous driving functions.",2024-08-30,"Ahmed Hammam, Bharathwaj Krishnaswami Sreedhar, Nura Kawa, Tim Patzelt, Oliver De Candido",http://arxiv.org/pdf/2408.17311v1,cs.LG
Hybridizing Base-Line 2D-CNN Model with Cat Swarm Optimization for Enhanced Advanced Persistent Threat Detection,"In the realm of cyber-security, detecting Advanced Persistent Threats (APTs)
remains a formidable challenge due to their stealthy and sophisticated nature.
This research paper presents an innovative approach that leverages
Convolutional Neural Networks (CNNs) with a 2D baseline model, enhanced by the
cutting-edge Cat Swarm Optimization (CSO) algorithm, to significantly improve
APT detection accuracy. By seamlessly integrating the 2D-CNN baseline model
with CSO, we unlock the potential for unprecedented accuracy and efficiency in
APT detection. The results unveil an impressive accuracy score of $98.4\%$,
marking a significant enhancement in APT detection across various attack
stages, illuminating a path forward in combating these relentless and
sophisticated threats.",2024-08-30,"Ali M. Bakhiet, Salah A. Aly",http://arxiv.org/pdf/2408.17307v1,cs.LG
Accelerating the discovery of steady-states of planetary interior dynamics with machine learning,"Simulating mantle convection often requires reaching a computationally
expensive steady-state, crucial for deriving scaling laws for thermal and
dynamical flow properties and benchmarking numerical solutions. The strong
temperature dependence of the rheology of mantle rocks causes viscosity
variations of several orders of magnitude, leading to a slow-evolving stagnant
lid where heat conduction dominates, overlying a rapidly-evolving and strongly
convecting region. Time-stepping methods, while effective for fluids with
constant viscosity, are hindered by the Courant criterion, which restricts the
time step based on the system's maximum velocity and grid size. Consequently,
achieving steady-state requires a large number of time steps due to the
disparate time scales governing the stagnant and convecting regions.
  We present a concept for accelerating mantle convection simulations using
machine learning. We generate a dataset of 128 two-dimensional simulations with
mixed basal and internal heating, and pressure- and temperature-dependent
viscosity. We train a feedforward neural network on 97 simulations to predict
steady-state temperature profiles. These can then be used to initialize
numerical time stepping methods for different simulation parameters. Compared
to typical initializations, the number of time steps required to reach
steady-state is reduced by a median factor of 3.75. The benefit of this method
lies in requiring very few simulations to train on, providing a solution with
no prediction error as we initialize a numerical method, and posing minimal
computational overhead at inference time. We demonstrate the effectiveness of
our approach and discuss the potential implications for accelerated simulations
for advancing mantle convection research.",2024-08-30,"Siddhant Agarwal, Nicola Tosi, Christian Hüttig, David S. Greenberg, Ali Can Bekar",http://arxiv.org/pdf/2408.17298v1,cs.LG
Risk-averse Total-reward MDPs with ERM and EVaR,"Optimizing risk-averse objectives in discounted MDPs is challenging because
most models do not admit direct dynamic programming equations and require
complex history-dependent policies. In this paper, we show that the risk-averse
{\em total reward criterion}, under the Entropic Risk Measure (ERM) and
Entropic Value at Risk (EVaR) risk measures, can be optimized by a stationary
policy, making it simple to analyze, interpret, and deploy. We propose
exponential value iteration, policy iteration, and linear programming to
compute optimal policies. Compared with prior work, our results only require
the relatively mild condition of transient MDPs and allow for {\em both}
positive and negative rewards. Our results indicate that the total reward
criterion may be preferable to the discounted criterion in a broad range of
risk-averse reinforcement learning domains.",2024-08-30,"Xihong Su, Julien Grand-Clément, Marek Petrik",http://arxiv.org/pdf/2408.17286v2,cs.LG
"Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution","Text-to-image models, such as Stable Diffusion (SD), undergo iterative
updates to improve image quality and address concerns such as safety.
Improvements in image quality are straightforward to assess. However, how model
updates resolve existing concerns and whether they raise new questions remain
unexplored. This study takes an initial step in investigating the evolution of
text-to-image models from the perspectives of safety, bias, and authenticity.
Our findings, centered on Stable Diffusion, indicate that model updates paint a
mixed picture. While updates progressively reduce the generation of unsafe
images, the bias issue, particularly in gender, intensifies. We also find that
negative stereotypes either persist within the same Non-White race group or
shift towards other Non-White race groups through SD updates, yet with minimal
association of these traits with the White race group. Additionally, our
evaluation reveals a new concern stemming from SD updates: State-of-the-art
fake image detectors, initially trained for earlier SD versions, struggle to
identify fake images generated by updated versions. We show that fine-tuning
these detectors on fake images generated by updated versions achieves at least
96.6\% accuracy across various SD versions, addressing this issue. Our insights
highlight the importance of continued efforts to mitigate biases and
vulnerabilities in evolving text-to-image models.",2024-08-30,"Yixin Wu, Yun Shen, Michael Backes, Yang Zhang",http://arxiv.org/pdf/2408.17285v1,cs.LG
Minimax and Communication-Efficient Distributed Best Subset Selection with Oracle Property,"The explosion of large-scale data in fields such as finance, e-commerce, and
social media has outstripped the processing capabilities of single-machine
systems, driving the need for distributed statistical inference methods.
Traditional approaches to distributed inference often struggle with achieving
true sparsity in high-dimensional datasets and involve high computational
costs. We propose a novel, two-stage, distributed best subset selection
algorithm to address these issues. Our approach starts by efficiently
estimating the active set while adhering to the $\ell_0$ norm-constrained
surrogate likelihood function, effectively reducing dimensionality and
isolating key variables. A refined estimation within the active set follows,
ensuring sparse estimates and matching the minimax $\ell_2$ error bound. We
introduce a new splicing technique for adaptive parameter selection to tackle
subproblems under $\ell_0$ constraints and a Generalized Information Criterion
(GIC). Our theoretical and numerical studies show that the proposed algorithm
correctly finds the true sparsity pattern, has the oracle property, and greatly
lowers communication costs. This is a big step forward in distributed sparse
estimation.",2024-08-30,"Jingguo Lan, Hongmei Lin, Xueqin Wang",http://arxiv.org/pdf/2408.17276v1,cs.LG
The Transferability of Downsamped Sparse Graph Convolutional Networks,"To accelerate the training of graph convolutional networks (GCNs) on
real-world large-scale sparse graphs, downsampling methods are commonly
employed as a preprocessing step. However, the effects of graph sparsity and
topological structure on the transferability of downsampling methods have not
been rigorously analyzed or theoretically guaranteed, particularly when the
topological structure is affected by graph sparsity. In this paper, we
introduce a novel downsampling method based on a sparse random graph model and
derive an expected upper bound for the transfer error. Our findings show that
smaller original graph sizes, higher expected average degrees, and increased
sampling rates contribute to reducing this upper bound. Experimental results
validate the theoretical predictions. By incorporating both sparsity and
topological similarity into the model, this study establishes an upper bound on
the transfer error for downsampling in the training of large-scale sparse
graphs and provides insight into the influence of topological structure on
transfer performance.",2024-08-30,"Qinji Shu, Hang Sheng, Feng Ji, Hui Feng, Bo Hu",http://arxiv.org/pdf/2408.17274v2,cs.LG
Equation identification for fluid flows via physics-informed neural networks,"Scientific machine learning (SciML) methods such as physics-informed neural
networks (PINNs) are used to estimate parameters of interest from governing
equations and small quantities of data. However, there has been little work in
assessing how well PINNs perform for inverse problems across wide ranges of
governing equations across the mathematical sciences. We present a new and
challenging benchmark problem for inverse PINNs based on a parametric sweep of
the 2D Burgers' equation with rotational flow. We show that a novel strategy
that alternates between first- and second-order optimization proves superior to
typical first-order strategies for estimating parameters. In addition, we
propose a novel data-driven method to characterize PINN effectiveness in the
inverse setting. PINNs' physics-informed regularization enables them to
leverage small quantities of data more efficiently than the data-driven
baseline. However, both PINNs and the baseline can fail to recover parameters
for highly inviscid flows, motivating the need for further development of PINN
methods.",2024-08-30,"Alexander New, Marisel Villafañe-Delgado, Charles Shugert",http://arxiv.org/pdf/2408.17271v1,cs.LG
Joint Estimation and Prediction of City-wide Delivery Demand: A Large Language Model Empowered Graph-based Learning Approach,"The proliferation of e-commerce and urbanization has significantly
intensified delivery operations in urban areas, boosting the volume and
complexity of delivery demand. Data-driven predictive methods, especially those
utilizing machine learning techniques, have emerged to handle these
complexities in urban delivery demand management problems. One particularly
pressing issue that has yet to be sufficiently addressed is the joint
estimation and prediction of city-wide delivery demand, as well as the
generalization of the model to new cities. To this end, we formulate this
problem as a transferable graph-based spatiotemporal learning task. First, an
individual-collective message-passing neural network model is formalized to
capture the interaction between demand patterns of associated regions. Second,
by exploiting recent advances in large language models (LLMs), we extract
general geospatial knowledge encodings from the unstructured locational data
using the embedding generated by LLMs. Last, to encourage the cross-city
generalization of the model, we integrate the encoding into the demand
predictor in a transferable way. Comprehensive empirical evaluation results on
two real-world delivery datasets, including eight cities in China and the US,
demonstrate that our model significantly outperforms state-of-the-art baselines
in accuracy, efficiency, and transferability.",2024-08-30,"Tong Nie, Junlin He, Yuewen Mei, Guoyang Qin, Guilong Li, Jian Sun, Wei Ma",http://arxiv.org/pdf/2408.17258v3,cs.LG
Self-supervised learning for crystal property prediction via denoising,"Accurate prediction of the properties of crystalline materials is crucial for
targeted discovery, and this prediction is increasingly done with data-driven
models. However, for many properties of interest, the number of materials for
which a specific property has been determined is much smaller than the number
of known materials. To overcome this disparity, we propose a novel
self-supervised learning (SSL) strategy for material property prediction. Our
approach, crystal denoising self-supervised learning (CDSSL), pretrains
predictive models (e.g., graph networks) with a pretext task based on
recovering valid material structures when given perturbed versions of these
structures. We demonstrate that CDSSL models out-perform models trained without
SSL, across material types, properties, and dataset sizes.",2024-08-30,"Alexander New, Nam Q. Le, Michael J. Pekala, Christopher D. Stiles",http://arxiv.org/pdf/2408.17255v1,cs.LG
VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters,"Foundation models have emerged as a promising approach in time series
forecasting (TSF). Existing approaches either repurpose large language models
(LLMs) or build large-scale time series datasets to develop TSF foundation
models for universal forecasting. However, these methods face challenges due to
the severe cross-domain gap or in-domain heterogeneity. This paper explores a
new road to building a TSF foundation model from rich, high-quality natural
images. Our key insight is that a visual masked autoencoder, pre-trained on the
ImageNet dataset, can naturally be a numeric series forecaster. By
reformulating TSF as an image reconstruction task, we bridge the gap between
image pre-training and TSF downstream tasks. Surprisingly, without further
adaptation in the time series domain, the proposed VisionTS could achieve
better zero-shot forecast performance than existing TSF foundation models. With
fine-tuning for one epoch, VisionTS could further improve the forecasting and
achieve state-of-the-art performance in most cases. Extensive experiments
reveal intrinsic similarities between images and real-world time series,
suggesting that visual models may offer a ""free lunch"" for TSF and highlight
the potential for future cross-modality research. Our code is publicly
available at https://github.com/Keytoyze/VisionTS.",2024-08-30,"Mouxiang Chen, Lefei Shen, Zhuo Li, Xiaoyun Joy Wang, Jianling Sun, Chenghao Liu",http://arxiv.org/pdf/2408.17253v3,cs.LG
(Un)supervised Learning of Maximal Lyapunov Functions,"In this paper, we address the problem of discovering maximal Lyapunov
functions, as a means of determining the region of attraction of a dynamical
system. To this end, we design a novel neural network architecture, which we
prove to be a universal approximator of (maximal) Lyapunov functions. The
architecture combines a local quadratic approximation with the output of a
neural network, which models global higher-order terms in the Taylor expansion.
We formulate the problem of training the Lyapunov function as an unsupervised
optimization problem with dynamical constraints, which can be solved leveraging
techniques from physics-informed learning. We propose and analyze a tailored
training algorithm, based on the primal-dual algorithm, that can efficiently
solve the problem. Additionally, we show how the learning problem formulation
can be adapted to integrate data, when available. We apply the proposed
approach to different classes of systems, showing that it matches or
outperforms state-of-the-art alternatives in the accuracy of the approximated
regions of attraction.",2024-08-30,"Matthieu Barreau, Nicola Bastianello",http://arxiv.org/pdf/2408.17246v2,cs.LG
Categorical data clustering: 25 years beyond K-modes,"The clustering of categorical data is a common and important task in computer
science, offering profound implications across a spectrum of applications.
Unlike purely numerical data, categorical data often lack inherent ordering as
in nominal data, or have varying levels of order as in ordinal data, thus
requiring specialized methodologies for efficient organization and analysis.
This review provides a comprehensive synthesis of categorical data clustering
in the past twenty-five years, starting from the introduction of K-modes. It
elucidates the pivotal role of categorical data clustering in diverse fields
such as health sciences, natural sciences, social sciences, education,
engineering and economics. Practical comparisons are conducted for algorithms
having public implementations, highlighting distinguishing clustering
methodologies and revealing the performance of recent algorithms on several
benchmark categorical datasets. Finally, challenges and opportunities in the
field are discussed.",2024-08-30,"Tai Dinh, Wong Hauchi, Philippe Fournier-Viger, Daniil Lisik, Minh-Quyet Ha, Hieu-Chi Dam, Van-Nam Huynh",http://arxiv.org/pdf/2408.17244v3,cs.LG
Using Quantum Solved Deep Boltzmann Machines to Increase the Data Efficiency of RL Agents,"Deep Learning algorithms, such as those used in Reinforcement Learning, often
require large quantities of data to train effectively. In most cases, the
availability of data is not a significant issue. However, for some contexts,
such as in autonomous cyber defence, we require data efficient methods.
Recently, Quantum Machine Learning and Boltzmann Machines have been proposed as
solutions to this challenge. In this work we build upon the pre-existing work
to extend the use of Deep Boltzmann Machines to the cutting edge algorithm
Proximal Policy Optimisation in a Reinforcement Learning cyber defence
environment. We show that this approach, when solved using a D-WAVE quantum
annealer, can lead to a two-fold increase in data efficiency. We therefore
expect it to be used by the machine learning and quantum communities who are
hoping to capitalise on data-efficient Reinforcement Learning methods.",2024-08-30,"Daniel Kent, Clement O'Rourke, Jake Southall, Kirsty Duncan, Adrian Bedford",http://arxiv.org/pdf/2408.17240v1,cs.LG
AI-Driven Intrusion Detection Systems (IDS) on the ROAD Dataset: A Comparative Analysis for Automotive Controller Area Network (CAN),"The integration of digital devices in modern vehicles has revolutionized
automotive technology, enhancing safety and the overall driving experience. The
Controller Area Network (CAN) bus is a central system for managing in-vehicle
communication between the electronic control units (ECUs). However, the CAN
protocol poses security challenges due to inherent vulnerabilities, lacking
encryption and authentication, which, combined with an expanding attack
surface, necessitates robust security measures. In response to this challenge,
numerous Intrusion Detection Systems (IDS) have been developed and deployed.
Nonetheless, an open, comprehensive, and realistic dataset to test the
effectiveness of such IDSs remains absent in the existing literature. This
paper addresses this gap by considering the latest ROAD dataset, containing
stealthy and sophisticated injections. The methodology involves dataset
labelling and the implementation of both state-of-the-art deep learning models
and traditional machine learning models to show the discrepancy in performance
between the datasets most commonly used in the literature and the ROAD dataset,
a more realistic alternative.",2024-08-30,"Lorenzo Guerra, Linhan Xu, Paolo Bellavista, Thomas Chapuis, Guillaume Duc, Pavlo Mozharovskyi, Van-Tam Nguyen",http://arxiv.org/pdf/2408.17235v2,cs.LG
Common Steps in Machine Learning Might Hinder The Explainability Aims in Medicine,"Data pre-processing is a significant step in machine learning to improve the
performance of the model and decreases the running time. This might include
dealing with missing values, outliers detection and removing, data
augmentation, dimensionality reduction, data normalization and handling the
impact of confounding variables. Although it is found the steps improve the
accuracy of the model, but they might hinder the explainability of the model if
they are not carefully considered especially in medicine. They might block new
findings when missing values and outliers removal are implemented
inappropriately. In addition, they might make the model unfair against all the
groups in the model when making the decision. Moreover, they turn the features
into unitless and clinically meaningless and consequently not explainable. This
paper discusses the common steps of the data preprocessing in machine learning
and their impacts on the explainability and interpretability of the model.
Finally, the paper discusses some possible solutions that improve the
performance of the model while not decreasing its explainability.",2024-08-30,Ahmed M Salih,http://arxiv.org/pdf/2409.00155v1,cs.LG
Higher order definition of causality by optimally conditioned transfer entropy,"The description of the dynamics of complex systems, in particular the capture
of the interaction structure and causal relationships between elements of the
system, is one of the central questions of interdisciplinary research. While
the characterization of pairwise causal interactions is a relatively ripe field
with established theoretical concepts and the current focus is on technical
issues of their efficient estimation, it turns out that the standard concepts
such as Granger causality or transfer entropy may not faithfully reflect
possible synergies or interactions of higher orders, phenomena highly relevant
for many real-world complex systems. In this paper, we propose a generalization
and refinement of the information-theoretic approach to causal inference,
enabling the description of truly multivariate, rather than multiple pairwise,
causal interactions, and moving thus from causal networks to causal
hypernetworks. In particular, while keeping the ability to control for
mediating variables or common causes, in case of purely synergetic interactions
such as the exclusive disjunction, it ascribes the causal role to the
multivariate causal set but \emph{not} to individual inputs, distinguishing it
thus from the case of e.g. two additive univariate causes. We demonstrate this
concept by application to illustrative theoretical examples as well as a
biophysically realistic simulation of biological neuronal dynamics recently
reported to employ synergetic computations.",2024-08-30,"Jakub Kořenek, Pavel Sanda, Jaroslav Hlinka",http://arxiv.org/pdf/2409.08295v2,cs.LG
Geometry of Lightning Self-Attention: Identifiability and Dimension,"We consider function spaces defined by self-attention networks without
normalization, and theoretically analyze their geometry. Since these networks
are polynomial, we rely on tools from algebraic geometry. In particular, we
study the identifiability of deep attention by providing a description of the
generic fibers of the parametrization for an arbitrary number of layers and, as
a consequence, compute the dimension of the function space. Additionally, for a
single-layer model, we characterize the singular and boundary points. Finally,
we formulate a conjectural extension of our results to normalized
self-attention networks, prove it for a single layer, and numerically verify it
in the deep case.",2024-08-30,"Nathan W. Henry, Giovanni Luca Marchetti, Kathlén Kohn",http://arxiv.org/pdf/2408.17221v2,cs.LG
Democratizing AI in Africa: FL for Low-Resource Edge Devices,"Africa faces significant challenges in healthcare delivery due to limited
infrastructure and access to advanced medical technologies. This study explores
the use of federated learning to overcome these barriers, focusing on perinatal
health. We trained a fetal plane classifier using perinatal data from five
African countries: Algeria, Ghana, Egypt, Malawi, and Uganda, along with data
from Spanish hospitals. To incorporate the lack of computational resources in
the analysis, we considered a heterogeneous set of devices, including a
Raspberry Pi and several laptops, for model training. We demonstrate
comparative performance between a centralized and a federated model, despite
the compute limitations, and a significant improvement in model
generalizability when compared to models trained only locally. These results
show the potential for a future implementation at a large scale of a federated
learning platform to bridge the accessibility gap and improve model
generalizability with very little requirements.",2024-08-30,"Jorge Fabila, Víctor M. Campello, Carlos Martín-Isla, Johnes Obungoloch, Kinyera Leo, Amodoi Ronald, Karim Lekadir",http://arxiv.org/pdf/2408.17216v1,cs.LG
Speaker Tagging Correction With Non-Autoregressive Language Models,"Speech applications dealing with conversations require not only recognizing
the spoken words but also determining who spoke when. The task of assigning
words to speakers is typically addressed by merging the outputs of two separate
systems, namely, an automatic speech recognition (ASR) system and a speaker
diarization (SD) system. In practical settings, speaker diarization systems can
experience significant degradation in performance due to a variety of factors,
including uniform segmentation with a high temporal resolution, inaccurate word
timestamps, incorrect clustering and estimation of speaker numbers, as well as
background noise.
  Therefore, it is important to automatically detect errors and make
corrections if possible. We used a second-pass speaker tagging correction
system based on a non-autoregressive language model to correct mistakes in
words placed at the borders of sentences spoken by different speakers. We first
show that the employed error correction approach leads to reductions in word
diarization error rate (WDER) on two datasets: TAL and test set of Fisher.
Additionally, we evaluated our system in the Post-ASR Speaker Tagging
Correction challenge and observed significant improvements in cpWER compared to
baseline methods.",2024-08-30,"Grigor Kirakosyan, Davit Karamyan",http://arxiv.org/pdf/2409.00151v1,cs.LG
Towards Symbolic XAI -- Explanation Through Human Understandable Logical Relationships Between Features,"Explainable Artificial Intelligence (XAI) plays a crucial role in fostering
transparency and trust in AI systems, where traditional XAI approaches
typically offer one level of abstraction for explanations, often in the form of
heatmaps highlighting single or multiple input features. However, we ask
whether abstract reasoning or problem-solving strategies of a model may also be
relevant, as these align more closely with how humans approach solutions to
problems. We propose a framework, called Symbolic XAI, that attributes
relevance to symbolic queries expressing logical relationships between input
features, thereby capturing the abstract reasoning behind a model's
predictions. The methodology is built upon a simple yet general multi-order
decomposition of model predictions. This decomposition can be specified using
higher-order propagation-based relevance methods, such as GNN-LRP, or
perturbation-based explanation methods commonly used in XAI. The effectiveness
of our framework is demonstrated in the domains of natural language processing
(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain
knowledge is abundant and of significant interest to users. The Symbolic XAI
framework provides an understanding of the model's decision-making process that
is both flexible for customization by the user and human-readable through
logical formulas.",2024-08-30,"Thomas Schnake, Farnoush Rezaei Jafari, Jonas Lederer, Ping Xiong, Shinichi Nakajima, Stefan Gugler, Grégoire Montavon, Klaus-Robert Müller",http://arxiv.org/pdf/2408.17198v2,cs.LG
Short-term Wind Speed Forecasting for Power Integration in Smart Grids based on Hybrid LSSVM-SVMD Method,"Owing to its minimal pollution and efficient energy use, wind energy has
become one of the most widely exploited renewable energy resources. The
successful integration of wind power into the grid system is contingent upon
accurate wind speed forecasting models. However, the task of wind speed
forecasting is challenging due to the inherent intermittent characteristics of
wind speed. In this paper, a hybrid machine learning approach is developed for
predicting short-term wind speed. First, the wind data was decomposed into
modal components using Successive Variational Mode Decomposition (SVMD). Then,
each sub-signal was fitted into a Least Squares Support Vector Machines (LSSVM)
model, with its hyperparameter optimized by a novel variant of Quantum-behaved
Particle Swarm Optimization (QPSO), QPSO with elitist breeding (EBQPSO).
Second, the residuals making up for the differences between the original wind
series and the aggregate of the SVMD modes were modeled using long short-term
model (LSTM). Then, the overall predicted values were computed using the
aggregate of the LSSVM and the LSTM models. Finally, the performance of the
proposed model was compared against state-of-the-art benchmark models for
forecasting wind speed using two separate data sets collected from a local wind
farm. Empirical results show significant improvement in performance by the
proposed method, achieving a 1.21% to 32.76% reduction in root mean square
error (RMSE) and a 2.05% to 40.75% reduction in mean average error (MAE)
compared to the benchmark methods. The entire code implementation of this work
is freely available in Github.",2024-08-30,"Ephrem Admasu Yekun, Alem H. Fitwib, Selvi Karpaga Subramaniand, Anubhav Kumard, Teshome Goa Tella",http://arxiv.org/pdf/2408.17185v1,cs.LG
From Semantics to Hierarchy: A Hybrid Euclidean-Tangent-Hyperbolic Space Model for Temporal Knowledge Graph Reasoning,"Temporal knowledge graph (TKG) reasoning predicts future events based on
historical data, but it's challenging due to the complex semantic and
hierarchical information involved. Existing Euclidean models excel at capturing
semantics but struggle with hierarchy. Conversely, hyperbolic models manage
hierarchical features well but fail to represent complex semantics due to
limitations in shallow models' parameters and the absence of proper
normalization in deep models relying on the L2 norm. Current solutions, as
curvature transformations, are insufficient to address these issues. In this
work, a novel hybrid geometric space approach that leverages the strengths of
both Euclidean and hyperbolic models is proposed. Our approach transitions from
single-space to multi-space parameter modeling, effectively capturing both
semantic and hierarchical information. Initially, complex semantics are
captured through a fact co-occurrence and autoregressive method with
normalizations in Euclidean space. The embeddings are then transformed into
Tangent space using a scaling mechanism, preserving semantic information while
relearning hierarchical structures through a query-candidate separated modeling
approach, which are subsequently transformed into Hyperbolic space. Finally, a
hybrid inductive bias for hierarchical and semantic learning is achieved by
combining hyperbolic and Euclidean scoring functions through a learnable
query-specific mixing coefficient, utilizing embeddings from hyperbolic and
Euclidean spaces. Experimental results on four TKG benchmarks demonstrate that
our method reduces error relatively by up to 15.0% in mean reciprocal rank on
YAGO compared to previous single-space models. Additionally, enriched
visualization analysis validates the effectiveness of our approach, showing
adaptive capabilities for datasets with varying levels of semantic and
hierarchical complexity.",2024-08-30,"Siling Feng, Zhisheng Qi, Cong Lin",http://arxiv.org/pdf/2409.00149v1,cs.LG
Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis,"How can balance be quantified in game settings? This question is crucial for
game designers, especially in player-versus-player (PvP) games, where analyzing
the strength relations among predefined team compositions-such as hero
combinations in multiplayer online battle arena (MOBA) games or decks in card
games-is essential for enhancing gameplay and achieving balance. We have
developed two advanced measures that extend beyond the simplistic win rate to
quantify balance in zero-sum competitive scenarios. These measures are derived
from win value estimations, which employ strength rating approximations via the
Bradley-Terry model and counter relationship approximations via vector
quantization, significantly reducing the computational complexity associated
with traditional win value estimations. Throughout the learning process of
these models, we identify useful categories of compositions and pinpoint their
counter relationships, aligning with the experiences of human players without
requiring specific game knowledge. Our methodology hinges on a simple technique
to enhance codebook utilization in discrete representation with a deterministic
vector quantization process for an extremely small state space. Our framework
has been validated in popular online games, including Age of Empires II,
Hearthstone, Brawl Stars, and League of Legends. The accuracy of the observed
strength relations in these games is comparable to traditional pairwise win
value predictions, while also offering a more manageable complexity for
analysis. Ultimately, our findings contribute to a deeper understanding of PvP
game dynamics and present a methodology that significantly improves game
balance evaluation and design.",2024-08-30,"Chiu-Chou Lin, Yu-Wei Shih, Kuei-Ting Kuo, Yu-Cheng Chen, Chien-Hua Chen, Wei-Chen Chiu, I-Chen Wu",http://arxiv.org/pdf/2408.17180v1,cs.LG
SafeTail: Efficient Tail Latency Optimization in Edge Service Scheduling via Computational Redundancy Management,"Optimizing tail latency while efficiently managing computational resources is
crucial for delivering high-performance, latency-sensitive services in edge
computing. Emerging applications, such as augmented reality, require
low-latency computing services with high reliability on user devices, which
often have limited computational capabilities. Consequently, these devices
depend on nearby edge servers for processing. However, inherent uncertainties
in network and computation latencies stemming from variability in wireless
networks and fluctuating server loads make service delivery on time
challenging. Existing approaches often focus on optimizing median latency but
fall short of addressing the specific challenges of tail latency in edge
environments, particularly under uncertain network and computational
conditions. Although some methods do address tail latency, they typically rely
on fixed or excessive redundancy and lack adaptability to dynamic network
conditions, often being designed for cloud environments rather than the unique
demands of edge computing. In this paper, we introduce SafeTail, a framework
that meets both median and tail response time targets, with tail latency
defined as latency beyond the 90^th percentile threshold. SafeTail addresses
this challenge by selectively replicating services across multiple edge servers
to meet target latencies. SafeTail employs a reward-based deep learning
framework to learn optimal placement strategies, balancing the need to achieve
target latencies with minimizing additional resource usage. Through
trace-driven simulations, SafeTail demonstrated near-optimal performance and
outperformed most baseline strategies across three diverse services.",2024-08-30,"Jyoti Shokhanda, Utkarsh Pal, Aman Kumar, Soumi Chattopadhyay, Arani Bhattacharya",http://arxiv.org/pdf/2408.17171v1,cs.LG
Learning Multi-Target TDOA Features for Sound Event Localization and Detection,"Sound event localization and detection (SELD) systems using audio recordings
from a microphone array rely on spatial cues for determining the location of
sound events. As a consequence, the localization performance of such systems is
to a large extent determined by the quality of the audio features that are used
as inputs to the system. We propose a new feature, based on neural generalized
cross-correlations with phase-transform (NGCC-PHAT), that learns audio
representations suitable for localization. Using permutation invariant training
for the time-difference of arrival (TDOA) estimation problem enables NGCC-PHAT
to learn TDOA features for multiple overlapping sound events. These features
can be used as a drop-in replacement for GCC-PHAT inputs to a SELD-network. We
test our method on the STARSS23 dataset and demonstrate improved localization
performance compared to using standard GCC-PHAT or SALSA-Lite input features.",2024-08-30,"Axel Berg, Johanna Engman, Jens Gulin, Karl Åström, Magnus Oskarsson",http://arxiv.org/pdf/2408.17166v1,cs.LG
Efficient Testable Learning of General Halfspaces with Adversarial Label Noise,"We study the task of testable learning of general -- not necessarily
homogeneous -- halfspaces with adversarial label noise with respect to the
Gaussian distribution. In the testable learning framework, the goal is to
develop a tester-learner such that if the data passes the tester, then one can
trust the output of the robust learner on the data.Our main result is the first
polynomial time tester-learner for general halfspaces that achieves
dimension-independent misclassification error. At the heart of our approach is
a new methodology to reduce testable learning of general halfspaces to testable
learning of nearly homogeneous halfspaces that may be of broader interest.",2024-08-30,"Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Nikos Zarifis",http://arxiv.org/pdf/2408.17165v1,cs.LG
The Iterative Optimal Brain Surgeon: Faster Sparse Recovery by Leveraging Second-Order Information,"The rising footprint of machine learning has led to a focus on imposing
\emph{model sparsity} as a means of reducing computational and memory costs.
For deep neural networks (DNNs), the state-of-the-art accuracy-vs-sparsity is
achieved by heuristics inspired by the classical Optimal Brain Surgeon (OBS)
framework~\citep{lecun90brain, hassibi1992second, hassibi1993optimal}, which
leverages loss curvature information to make better pruning decisions. Yet,
these results still lack a solid theoretical understanding, and it is unclear
whether they can be improved by leveraging connections to the wealth of work on
sparse recovery algorithms. In this paper, we draw new connections between
these two areas and present new sparse recovery algorithms inspired by the OBS
framework that comes with theoretical guarantees under reasonable assumptions
and have strong practical performance. Specifically, our work starts from the
observation that we can leverage curvature information in OBS-like fashion upon
the projection step of classic iterative sparse recovery algorithms such as
IHT. We show for the first time that this leads both to improved convergence
bounds under standard assumptions. Furthermore, we present extensions of this
approach to the practical task of obtaining accurate sparse DNNs, and validate
it experimentally at scale for Transformer-based models on vision and language
tasks.",2024-08-30,"Diyuan Wu, Ionut-Vlad Modoranu, Mher Safaryan, Denis Kuznedelev, Dan Alistarh",http://arxiv.org/pdf/2408.17163v1,cs.LG
Deep Feature Embedding for Tabular Data,"Tabular data learning has extensive applications in deep learning but its
existing embedding techniques are limited in numerical and categorical features
such as the inability to capture complex relationships and engineering. This
paper proposes a novel deep embedding framework with leverages lightweight deep
neural networks to generate effective feature embeddings for tabular data in
machine learning research. For numerical features, a two-step feature expansion
and deep transformation technique is used to capture copious semantic
information. For categorical features, a unique identification vector for each
entity is referred by a compact lookup table with a parameterized deep
embedding function to uniform the embedding size dimensions, and transformed
into a embedding vector using deep neural network. Experiments are conducted on
real-world datasets for performance evaluation.",2024-08-30,"Yuqian Wu, Hengyi Luo, Raymond S. T. Lee",http://arxiv.org/pdf/2408.17162v1,cs.LG
Investigating Privacy Leakage in Dimensionality Reduction Methods via Reconstruction Attack,"This study investigates privacy leakage in dimensionality reduction methods
through a novel machine learning-based reconstruction attack. Employing an
informed adversary threat model, we develop a neural network capable of
reconstructing high-dimensional data from low-dimensional embeddings.
  We evaluate six popular dimensionality reduction techniques: PCA, sparse
random projection (SRP), multidimensional scaling (MDS), Isomap, t-SNE, and
UMAP. Using both MNIST and NIH Chest X-ray datasets, we perform a qualitative
analysis to identify key factors affecting reconstruction quality. Furthermore,
we assess the effectiveness of an additive noise mechanism in mitigating these
reconstruction attacks. Our experimental results on both datasets reveal that
the attack is effective against deterministic methods (PCA and Isomap), but
ineffective against methods that employ random initialization (SRP, MDS, t-SNE
and UMAP). When adding the images with large noises before performing PCA or
Isomap, the attack produced severely distorted reconstructions. In contrast,
for the other four methods, the reconstructions still show some recognizable
features, though they bear little resemblance to the original images.",2024-08-30,"Chayadon Lumbut, Donlapark Ponnoprat",http://arxiv.org/pdf/2408.17151v2,cs.LG
The Many Faces of Optimal Weak-to-Strong Learning,"Boosting is an extremely successful idea, allowing one to combine multiple
low accuracy classifiers into a much more accurate voting classifier. In this
work, we present a new and surprisingly simple Boosting algorithm that obtains
a provably optimal sample complexity. Sample optimal Boosting algorithms have
only recently been developed, and our new algorithm has the fastest runtime
among all such algorithms and is the simplest to describe: Partition your
training data into 5 disjoint pieces of equal size, run AdaBoost on each, and
combine the resulting classifiers via a majority vote. In addition to this
theoretical contribution, we also perform the first empirical comparison of the
proposed sample optimal Boosting algorithms. Our pilot empirical study suggests
that our new algorithm might outperform previous algorithms on large data sets.",2024-08-30,"Mikael Møller Høgsgaard, Kasper Green Larsen, Markus Engelund Mathiasen",http://arxiv.org/pdf/2408.17148v1,cs.LG
Towards Hyper-parameter-free Federated Learning,"The adaptive synchronization techniques in federated learning (FL) for scaled
global model updates show superior performance over the vanilla federated
averaging (FedAvg) scheme. However, existing methods employ additional tunable
hyperparameters on the server to determine the scaling factor. A contrasting
approach is automated scaling analogous to tuning-free step-size schemes in
stochastic gradient descent (SGD) methods, which offer competitive convergence
rates and exhibit good empirical performance. In this work, we introduce two
algorithms for automated scaling of global model updates. In our first
algorithm, we establish that a descent-ensuring step-size regime at the clients
ensures descent for the server objective. We show that such a scheme enables
linear convergence for strongly convex federated objectives. Our second
algorithm shows that the average of objective values of sampled clients is a
practical and effective substitute for the objective function value at the
server required for computing the scaling factor, whose computation is
otherwise not permitted. Our extensive empirical results show that the proposed
methods perform at par or better than the popular federated learning algorithms
for both convex and non-convex problems. Our work takes a step towards
designing hyper-parameter-free federated learning.",2024-08-30,"Geetika, Drishya Uniyal, Bapi Chatterjee",http://arxiv.org/pdf/2408.17145v1,cs.LG
Flow Matching for Optimal Reaction Coordinates of Biomolecular System,"We present flow matching for reaction coordinates (FMRC), a novel deep
learning algorithm designed to identify optimal reaction coordinates (RC) in
biomolecular reversible dynamics. FMRC is based on the mathematical principles
of lumpability and decomposability, which we reformulate into a conditional
probability framework for efficient data-driven optimization using deep
generative models. While FMRC does not explicitly learn the well-established
transfer operator or its eigenfunctions, it can effectively encode the dynamics
of leading eigenfunctions of the system transfer operator into its
low-dimensional RC space. We further quantitatively compare its performance
with several state-of-the-art algorithms by evaluating the quality of Markov
state models (MSM) constructed in their respective RC spaces, demonstrating the
superiority of FMRC in three increasingly complex biomolecular systems. In
addition, we successfully demonstrated the efficacy of FMRC for bias deposition
in the enhanced sampling of a simple model system. Finally, we discuss its
potential applications in downstream applications such as enhanced sampling
methods and MSM construction.",2024-08-30,"Mingyuan Zhang, Zhicheng Zhang, Hao Wu, Yong Wang",http://arxiv.org/pdf/2408.17139v2,cs.LG
Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph Neural Networks for Drug Response Prediction,"Graph Neural Networks have been widely applied in critical decision-making
areas that demand interpretable predictions, leading to the flourishing
development of interpretability algorithms. However, current graph
interpretability algorithms tend to emphasize generality and often overlook
biological significance, thereby limiting their applicability in predicting
cancer drug responses. In this paper, we propose a novel post-hoc
interpretability algorithm for cancer drug response prediction, CETExplainer,
which incorporates a controllable edge-type-specific weighting mechanism. It
considers the mutual information between subgraphs and predictions, proposing a
structural scoring approach to provide fine-grained, biologically meaningful
explanations for predictive models. We also introduce a method for constructing
ground truth based on real-world datasets to quantitatively evaluate the
proposed interpretability algorithm. Empirical analysis on the real-world
dataset demonstrates that CETExplainer achieves superior stability and improves
explanation quality compared to leading algorithms, thereby offering a robust
and insightful tool for cancer drug prediction.",2024-08-30,"Xiaodi Li, Jianfeng Gui, Qian Gao, Haoyuan Shi, Zhenyu Yue",http://arxiv.org/pdf/2408.17129v2,cs.LG
Bridging User Dynamics: Transforming Sequential Recommendations with Schrödinger Bridge and Diffusion Models,"Sequential recommendation has attracted increasing attention due to its
ability to accurately capture the dynamic changes in user interests. We have
noticed that generative models, especially diffusion models, which have
achieved significant results in fields like image and audio, hold considerable
promise in the field of sequential recommendation. However, existing sequential
recommendation methods based on diffusion models are constrained by a prior
distribution limited to Gaussian distribution, hindering the possibility of
introducing user-specific information for each recommendation and leading to
information loss. To address these issues, we introduce the Schr\""odinger
Bridge into diffusion-based sequential recommendation models, creating the
SdifRec model. This allows us to replace the Gaussian prior of the diffusion
model with the user's current state, directly modeling the process from a
user's current state to the target recommendation. Additionally, to better
utilize collaborative information in recommendations, we propose an extended
version of SdifRec called con-SdifRec, which utilizes user clustering
information as a guiding condition to further enhance the posterior
distribution. Finally, extensive experiments on multiple public benchmark
datasets have demonstrated the effectiveness of SdifRec and con-SdifRec through
comparison with several state-of-the-art methods. Further in-depth analysis has
validated their efficiency and robustness.",2024-08-30,"Wenjia Xie, Rui Zhou, Hao Wang, Tingjia Shen, Enhong Chen",http://arxiv.org/pdf/2409.10522v1,cs.LG
Efficient Estimation of Unique Components in Independent Component Analysis by Matrix Representation,"Independent component analysis (ICA) is a widely used method in various
applications of signal processing and feature extraction. It extends principal
component analysis (PCA) and can extract important and complicated components
with small variances. One of the major problems of ICA is that the uniqueness
of the solution is not guaranteed, unlike PCA. That is because there are many
local optima in optimizing the objective function of ICA. It has been shown
previously that the unique global optimum of ICA can be estimated from many
random initializations by handcrafted thread computation. In this paper, the
unique estimation of ICA is highly accelerated by reformulating the algorithm
in matrix representation and reducing redundant calculations. Experimental
results on artificial datasets and EEG data verified the efficiency of the
proposed method.",2024-08-30,"Yoshitatsu Matsuda, Kazunori Yamaguch",http://arxiv.org/pdf/2408.17118v1,cs.LG
Sparse Uncertainty-Informed Sampling from Federated Streaming Data,"We present a numerically robust, computationally efficient approach for
non-I.I.D. data stream sampling in federated client systems, where resources
are limited and labeled data for local model adaptation is sparse and
expensive. The proposed method identifies relevant stream observations to
optimize the underlying client model, given a local labeling budget, and
performs instantaneous labeling decisions without relying on any memory
buffering strategies. Our experiments show enhanced training batch diversity
and an improved numerical robustness of the proposal compared to existing
strategies over large-scale data streams, making our approach an effective and
convenient solution in FL environments.",2024-08-30,"Manuel Röder, Frank-Michael Schleif",http://arxiv.org/pdf/2408.17108v1,cs.LG
LSTM Recurrent Neural Networks for Cybersecurity Named Entity Recognition,"The automated and timely conversion of cybersecurity information from
unstructured online sources, such as blogs and articles to more formal
representations has become a necessity for many applications in the domain
nowadays. Named Entity Recognition (NER) is one of the early phases towards
this goal. It involves the detection of the relevant domain entities, such as
product, version, attack name, etc. in technical documents. Although generally
considered a simple task in the information extraction field, it is quite
challenging in some domains like cybersecurity because of the complex structure
of its entities. The state of the art methods require time-consuming and labor
intensive feature engineering that describes the properties of the entities,
their context, domain knowledge, and linguistic characteristics. The model
demonstrated in this paper is domain independent and does not rely on any
features specific to the entities in the cybersecurity domain, hence does not
require expert knowledge to perform feature engineering. The method used relies
on a type of recurrent neural networks called Long Short-Term Memory (LSTM) and
the Conditional Random Fields (CRFs) method. The results we obtained showed
that this method outperforms the state of the art methods given an annotated
corpus of a decent size.",2024-08-30,"Houssem Gasmi, Jannik Laval, Abdelaziz Bouras",http://arxiv.org/pdf/2409.10521v1,cs.LG
RISSOLE: Parameter-efficient Diffusion Models via Block-wise Generation and Retrieval-Guidance,"Diffusion-based models demonstrate impressive generation capabilities.
However, they also have a massive number of parameters, resulting in enormous
model sizes, thus making them unsuitable for deployment on resource-constraint
devices. Block-wise generation can be a promising alternative for designing
compact-sized (parameter-efficient) deep generative models since the model can
generate one block at a time instead of generating the whole image at once.
However, block-wise generation is also considerably challenging because
ensuring coherence across generated blocks can be non-trivial. To this end, we
design a retrieval-augmented generation (RAG) approach and leverage the
corresponding blocks of the images retrieved by the RAG module to condition the
training and generation stages of a block-wise denoising diffusion model. Our
conditioning schemes ensure coherence across the different blocks during
training and, consequently, during generation. While we showcase our approach
using the latent diffusion model (LDM) as the base model, it can be used with
other variants of denoising diffusion models. We validate the solution of the
coherence problem through the proposed approach by reporting substantive
experiments to demonstrate our approach's effectiveness in compact model size
and excellent generation quality.",2024-08-30,"Avideep Mukherjee, Soumya Banerjee, Piyush Rai, Vinay P. Namboodiri",http://arxiv.org/pdf/2408.17095v2,cs.LG
FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition,"Federated learning is a machine learning paradigm that enables decentralized
clients to collaboratively learn a shared model while keeping all the training
data local. While considerable research has focused on federated image
generation, particularly Generative Adversarial Networks, Variational
Autoencoders have received less attention. In this paper, we address the
challenges of non-IID (independently and identically distributed) data
environments featuring multiple groups of images of different types. Non-IID
data distributions can lead to difficulties in maintaining a consistent latent
space and can also result in local generators with disparate texture features
being blended during aggregation. We thereby introduce FissionVAE that
decouples the latent space and constructs decoder branches tailored to
individual client groups. This method allows for customized learning that
aligns with the unique data distributions of each group. Additionally, we
incorporate hierarchical VAEs and demonstrate the use of heterogeneous decoder
architectures within FissionVAE. We also explore strategies for setting the
latent prior distributions to enhance the decoupling process. To evaluate our
approach, we assemble two composite datasets: the first combines MNIST and
FashionMNIST; the second comprises RGB datasets of cartoon and human faces,
wild animals, marine vessels, and remote sensing images. Our experiments
demonstrate that FissionVAE greatly improves generation quality on these
datasets compared to baseline federated VAE models.",2024-08-30,"Chen Hu, Hanchi Ren, Jingjing Deng, Xianghua Xie, Xiaoke Ma",http://arxiv.org/pdf/2408.17090v2,cs.LG
Instant Adversarial Purification with Adversarial Consistency Distillation,"Neural networks have revolutionized numerous fields with their exceptional
performance, yet they remain susceptible to adversarial attacks through subtle
perturbations. While diffusion-based purification methods like DiffPure offer
promising defense mechanisms, their computational overhead presents a
significant practical limitation. In this paper, we introduce One Step Control
Purification (OSCP), a novel defense framework that achieves robust adversarial
purification in a single Neural Function Evaluation (NFE) within diffusion
models. We propose Gaussian Adversarial Noise Distillation (GAND) as the
distillation objective and Controlled Adversarial Purification (CAP) as the
inference pipeline, which makes OSCP demonstrate remarkable efficiency while
maintaining defense efficacy. Our proposed GAND addresses a fundamental tension
between consistency distillation and adversarial perturbation, bridging the gap
between natural and adversarial manifolds in the latent space, while remaining
computationally efficient through Parameter-Efficient Fine-Tuning (PEFT)
methods such as LoRA, eliminating the high computational budget request from
full parameter fine-tuning. The CAP guides the purification process through the
unlearnable edge detection operator calculated by the input image as an extra
prompt, effectively preventing the purified images from deviating from their
original appearance when large purification steps are used. Our experimental
results on ImageNet showcase OSCP's superior performance, achieving a 74.19%
defense success rate with merely 0.1s per purification -- a 100-fold speedup
compared to conventional approaches.",2024-08-30,"Chun Tong Lei, Hon Ming Yam, Zhongliang Guo, Yifei Qian, Chun Pong Lau",http://arxiv.org/pdf/2408.17064v3,cs.LG
A Survey of the Self Supervised Learning Mechanisms for Vision Transformers,"Deep supervised learning models require high volume of labeled data to attain
sufficiently good results. Although, the practice of gathering and annotating
such big data is costly and laborious. Recently, the application of self
supervised learning (SSL) in vision tasks has gained significant attention. The
intuition behind SSL is to exploit the synchronous relationships within the
data as a form of self-supervision, which can be versatile. In the current big
data era, most of the data is unlabeled, and the success of SSL thus relies in
finding ways to utilize this vast amount of unlabeled data available. Thus it
is better for deep learning algorithms to reduce reliance on human supervision
and instead focus on self-supervision based on the inherent relationships
within the data. With the advent of ViTs, which have achieved remarkable
results in computer vision, it is crucial to explore and understand the various
SSL mechanisms employed for training these models specifically in scenarios
where there is limited labelled data available. In this survey, we develop a
comprehensive taxonomy of systematically classifying the SSL techniques based
upon their representations and pre-training tasks being applied. Additionally,
we discuss the motivations behind SSL, review popular pre-training tasks, and
highlight the challenges and advancements in this field. Furthermore, we
present a comparative analysis of different SSL methods, evaluate their
strengths and limitations, and identify potential avenues for future research.",2024-08-30,"Asifullah Khan, Anabia Sohail, Mustansar Fiaz, Mehdi Hassan, Tariq Habib Afridi, Sibghat Ullah Marwat, Farzeen Munir, Safdar Ali, Hannan Naseem, Muhammad Zaigham Zaheer, Kamran Ali, Tangina Sultana, Ziaurrehman Tanoli, Naeem Akhter",http://arxiv.org/pdf/2408.17059v4,cs.LG
Estimating Conditional Average Treatment Effects via Sufficient Representation Learning,"Estimating the conditional average treatment effects (CATE) is very important
in causal inference and has a wide range of applications across many fields. In
the estimation process of CATE, the unconfoundedness assumption is typically
required to ensure the identifiability of the regression problems. When
estimating CATE using high-dimensional data, there have been many variable
selection methods and neural network approaches based on representation
learning, while these methods do not provide a way to verify whether the subset
of variables after dimensionality reduction or the learned representations
still satisfy the unconfoundedness assumption during the estimation process,
which can lead to ineffective estimates of the treatment effects. Additionally,
these methods typically use data from only the treatment or control group when
estimating the regression functions for each group. This paper proposes a novel
neural network approach named \textbf{CrossNet} to learn a sufficient
representation for the features, based on which we then estimate the CATE,
where cross indicates that in estimating the regression functions, we used data
from their own group as well as cross-utilized data from another group.
Numerical simulations and empirical results demonstrate that our method
outperforms the competitive approaches.",2024-08-30,"Pengfei Shi, Wei Zhong, Xinyu Zhang, Ningtao Wang, Xing Fu, Weiqiang Wang, Yin Jin",http://arxiv.org/pdf/2408.17053v2,cs.LG
Deep Neural Implicit Representation of Accessibility for Multi-Axis Manufacturing,"One of the main concerns in design and process planning for multi-axis
additive and subtractive manufacturing is collision avoidance between moving
objects (e.g., tool assemblies) and stationary objects (e.g., a part unified
with fixtures). The collision measure for various pairs of relative rigid
translations and rotations between the two pointsets can be conceptualized by a
compactly supported scalar field over the 6D non-Euclidean configuration space.
Explicit representation and computation of this field is costly in both time
and space. If we fix $O(m)$ sparsely sampled rotations (e.g., tool
orientations), computation of the collision measure field as a convolution of
indicator functions of the 3D pointsets over a uniform grid (i.e., voxelized
geometry) of resolution $O(n^3)$ via fast Fourier transforms (FFTs) scales as
in $O(mn^3 \log n)$ in time and $O(mn^3)$ in space. In this paper, we develop
an implicit representation of the collision measure field via deep neural
networks (DNNs). We show that our approach is able to accurately interpolate
the collision measure from a sparse sampling of rotations, and can represent
the collision measure field with a small memory footprint. Moreover, we show
that this representation can be efficiently updated through fine-tuning to more
efficiently train the network on multi-resolution data, as well as accommodate
incremental changes to the geometry (such as might occur in iterative processes
such as topology optimization of the part subject to CNC tool accessibility
constraints).",2024-08-30,"George P. Harabin, Amir Mirzendehdel, Morad Behandish",http://arxiv.org/pdf/2409.02115v2,cs.LG
Error-controlled non-additive interaction discovery in machine learning models,"Machine learning (ML) models are powerful tools for detecting complex
patterns within data, yet their ""black box"" nature limits their
interpretability, hindering their use in critical domains like healthcare and
finance. To address this challenge, interpretable ML methods have been
developed to explain how features influence model predictions. However, these
methods often focus on univariate feature importance, overlooking the complex
interactions between features that ML models are capable of capturing.
Recognizing this limitation, recent efforts have aimed to extend these methods
to discover feature interactions, but existing approaches struggle with
robustness and error control, especially under data perturbations. In this
study, we introduce Diamond, a novel method for trustworthy feature interaction
discovery. Diamond uniquely integrates the model-X knockoffs framework to
control the false discovery rate (FDR), ensuring that the proportion of falsely
discovered interactions remains low. A key innovation in Diamond is its
non-additivity distillation procedure, which refines existing interaction
importance measures to distill non-additive interaction effects, ensuring that
FDR control is maintained. This approach addresses the limitations of
off-the-shelf interaction measures, which, when used naively, can lead to
inaccurate discoveries. Diamond's applicability spans a wide range of ML
models, including deep neural networks, transformer models, tree-based models,
and factorization-based models. Our empirical evaluations on both simulated and
real datasets across various biomedical studies demonstrate Diamond's utility
in enabling more reliable data-driven scientific discoveries. This method
represents a significant step forward in the deployment of ML models for
scientific innovation and hypothesis generation.",2024-08-30,"Winston Chen, Yifan Jiang, William Stafford Noble, Yang Young Lu",http://arxiv.org/pdf/2408.17016v2,cs.LG
Disease Classification and Impact of Pretrained Deep Convolution Neural Networks on Diverse Medical Imaging Datasets across Imaging Modalities,"Imaging techniques such as Chest X-rays, whole slide images, and optical
coherence tomography serve as the initial screening and detection for a wide
variety of medical pulmonary and ophthalmic conditions respectively. This paper
investigates the intricacies of using pretrained deep convolutional neural
networks with transfer learning across diverse medical imaging datasets with
varying modalities for binary and multiclass classification. We conducted a
comprehensive performance analysis with ten network architectures and model
families each with pretraining and random initialization. Our finding showed
that the use of pretrained models as fixed feature extractors yields poor
performance irrespective of the datasets. Contrary, histopathology microscopy
whole slide images have better performance. It is also found that deeper and
more complex architectures did not necessarily result in the best performance.
This observation implies that the improvements in ImageNet are not parallel to
the medical imaging tasks. Within a medical domain, the performance of the
network architectures varies within model families with shifts in datasets.
This indicates that the performance of models within a specific modality may
not be conclusive for another modality within the same domain. This study
provides a deeper understanding of the applications of deep learning techniques
in medical imaging and highlights the impact of pretrained networks across
different medical imaging datasets under five different experimental settings.",2024-08-30,"Jutika Borah, Kumaresh Sarmah, Hidam Kumarjit Singh",http://arxiv.org/pdf/2408.17011v2,cs.LG
Improving Time Series Classification with Representation Soft Label Smoothing,"Previous research has indicated that deep neural network based models for
time series classification (TSC) tasks are prone to overfitting. This issue can
be mitigated by employing strategies that prevent the model from becoming
overly confident in its predictions, such as label smoothing and confidence
penalty. Building upon the concept of label smoothing, we propose a novel
approach to generate more reliable soft labels, which we refer to as
representation soft label smoothing. We apply label smoothing, confidence
penalty, and our method representation soft label smoothing to several TSC
models and compare their performance with baseline method which only uses hard
labels for training. Our results demonstrate that the use of these enhancement
techniques yields competitive results compared to the baseline method.
Importantly, our method demonstrates strong performance across models with
varying structures and complexities.",2024-08-30,"Hengyi Ma, Weitong Chen",http://arxiv.org/pdf/2408.17010v1,cs.LG
Evaluation of Table Representations to Answer Questions from Tables in Documents : A Case Study using 3GPP Specifications,"With the ubiquitous use of document corpora for question answering, one
important aspect which is especially relevant for technical documents is the
ability to extract information from tables which are interspersed with text.
The major challenge in this is that unlike free-flow text or isolated set of
tables, the representation of a table in terms of what is a relevant chunk is
not obvious. We conduct a series of experiments examining various
representations of tabular data interspersed with text to understand the
relative benefits of different representations. We choose a corpus of $3^{rd}$
Generation Partnership Project (3GPP) documents since they are heavily
interspersed with tables. We create expert curated dataset of question answers
to evaluate our approach. We conclude that row level representations with
corresponding table header information being included in every cell improves
the performance of the retrieval, thus leveraging the structural information
present in the tabular data.",2024-08-30,"Sujoy Roychowdhury, Sumit Soman, HG Ranjani, Avantika Sharma, Neeraj Gunda, Sai Krishna Bala",http://arxiv.org/pdf/2408.17008v1,cs.LG
A Tighter Convergence Proof of Reverse Experience Replay,"In reinforcement learning, Reverse Experience Replay (RER) is a recently
proposed algorithm that attains better sample complexity than the classic
experience replay method. RER requires the learning algorithm to update the
parameters through consecutive state-action-reward tuples in reverse order.
However, the most recent theoretical analysis only holds for a minimal learning
rate and short consecutive steps, which converge slower than those large
learning rate algorithms without RER. In view of this theoretical and empirical
gap, we provide a tighter analysis that mitigates the limitation on the
learning rate and the length of consecutive steps. Furthermore, we show
theoretically that RER converges with a larger learning rate and a longer
sequence.",2024-08-30,"Nan Jiang, Jinzhao Li, Yexiang Xue",http://arxiv.org/pdf/2408.16999v1,cs.LG
A Scalable k-Medoids Clustering via Whale Optimization Algorithm,"Unsupervised clustering has emerged as a critical tool for uncovering hidden
patterns and insights from vast, unlabeled datasets. However, traditional
methods like Partitioning Around Medoids (PAM) struggle with scalability due to
their quadratic computational complexity. To address this limitation, we
introduce WOA-kMedoids, a novel unsupervised clustering method that
incorporates the Whale Optimization Algorithm (WOA), a nature-inspired
metaheuristic inspired by the hunting strategies of humpback whales. By
optimizing centroid selection, WOA-kMedoids reduces computational complexity of
the k-medoids algorithm from quadratic to near-linear with respect to the
number of observations. This improvement in efficiency enables WOA-kMedoids to
be scalable to large datasets while maintaining high clustering accuracy. We
evaluated the performance of WOA-kMedoids on 25 diverse time series datasets
from the UCR archive. Our empirical results demonstrate that WOA-kMedoids
maintains clustering accuracy similar to PAM. While WOA-kMedoids exhibited
slightly higher runtime than PAM on small datasets (less than 300
observations), it outperformed PAM in computational efficiency on larger
datasets. The scalability of WOA-kMedoids, combined with its consistently high
accuracy, positions it as a promising and practical choice for unsupervised
clustering in big data applications. WOA-kMedoids has implications for
efficient knowledge discovery in massive, unlabeled datasets across various
domains.",2024-08-30,"Huang Chenan, Narumasa Tsutsumida",http://arxiv.org/pdf/2408.16993v1,cs.LG
Semantic-Guided Multimodal Sentiment Decoding with Adversarial Temporal-Invariant Learning,"Multimodal sentiment analysis aims to learn representations from different
modalities to identify human emotions. However, existing works often neglect
the frame-level redundancy inherent in continuous time series, resulting in
incomplete modality representations with noise. To address this issue, we
propose temporal-invariant learning for the first time, which constrains the
distributional variations over time steps to effectively capture long-term
temporal dynamics, thus enhancing the quality of the representations and the
robustness of the model. To fully exploit the rich semantic information in
textual knowledge, we propose a semantic-guided fusion module. By evaluating
the correlations between different modalities, this module facilitates
cross-modal interactions gated by modality-invariant representations.
Furthermore, we introduce a modality discriminator to disentangle
modality-invariant and modality-specific subspaces. Experimental results on two
public datasets demonstrate the superiority of our model. Our code is available
at https://github.com/X-G-Y/SATI.",2024-08-30,"Guoyang Xu, Junqi Xue, Yuxin Liu, Zirui Wang, Min Zhang, Zhenxi Song, Zhiguo Zhang",http://arxiv.org/pdf/2409.00143v2,cs.LG
From Model Explanation to Data Misinterpretation: Uncovering the Pitfalls of Post Hoc Explainers in Business Research,"Machine learning models have been increasingly used in business research.
However, most state-of-the-art machine learning models, such as deep neural
networks and XGBoost, are black boxes in nature. Therefore, post hoc explainers
that provide explanations for machine learning models by, for example,
estimating numerical importance of the input features, have been gaining wide
usage. Despite the intended use of post hoc explainers being explaining machine
learning models, we found a growing trend in business research where post hoc
explanations are used to draw inferences about the data. In this work, we
investigate the validity of such use. Specifically, we investigate with
extensive experiments whether the explanations obtained by the two most popular
post hoc explainers, SHAP and LIME, provide correct information about the true
marginal effects of X on Y in the data, which we call data-alignment. We then
identify what factors influence the alignment of explanations. Finally, we
propose a set of mitigation strategies to improve the data-alignment of
explanations and demonstrate their effectiveness with real-world data in an
econometric context. In spite of this effort, we nevertheless conclude that it
is often not appropriate to infer data insights from post hoc explanations. We
articulate appropriate alternative uses, the most important of which is to
facilitate the proposition and subsequent empirical investigation of
hypotheses. The ultimate goal of this paper is to caution business researchers
against translating post hoc explanations of machine learning models into
potentially false insights and understanding of data.",2024-08-30,"Ronilo Ragodos, Tong Wang, Lu Feng, Yu, Hu",http://arxiv.org/pdf/2408.16987v1,cs.LG
The Sample-Communication Complexity Trade-off in Federated Q-Learning,"We consider the problem of federated Q-learning, where $M$ agents aim to
collaboratively learn the optimal Q-function of an unknown infinite-horizon
Markov decision process with finite state and action spaces. We investigate the
trade-off between sample and communication complexities for the widely used
class of intermittent communication algorithms. We first establish the converse
result, where it is shown that a federated Q-learning algorithm that offers any
speedup with respect to the number of agents in the per-agent sample complexity
needs to incur a communication cost of at least an order of
$\frac{1}{1-\gamma}$ up to logarithmic factors, where $\gamma$ is the discount
factor. We also propose a new algorithm, called Fed-DVR-Q, which is the first
federated Q-learning algorithm to simultaneously achieve order-optimal sample
and communication complexities. Thus, together these results provide a complete
characterization of the sample-communication complexity trade-off in federated
Q-learning.",2024-08-30,"Sudeep Salgia, Yuejie Chi",http://arxiv.org/pdf/2408.16981v2,cs.LG
Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer,"Large Language Models (LLMs) with long context capabilities are integral to
complex tasks in natural language processing and computational biology, such as
text generation and protein sequence analysis. However, training LLMs directly
on extremely long contexts demands considerable GPU resources and increased
memory, leading to higher costs and greater complexity. Alternative approaches
that introduce long context capabilities via downstream finetuning or
adaptations impose significant design limitations. In this paper, we propose
Fully Pipelined Distributed Transformer (FPDT) for efficiently training
long-context LLMs with extreme hardware efficiency. For GPT and Llama models,
we achieve a 16x increase in sequence length that can be trained on the same
hardware compared to current state-of-the-art solutions. With our dedicated
sequence chunk pipeline design, we can now train 8B LLM with 2 million sequence
length on only 4 GPUs, while also maintaining over 55% of MFU. Our proposed
FPDT is agnostic to existing training techniques and is proven to work
efficiently across different LLM models.",2024-08-30,"Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Hari Subramoni, Dhabaleswar K. Panda",http://arxiv.org/pdf/2408.16978v2,cs.LG
Technical Report of HelixFold3 for Biomolecular Structure Prediction,"The AlphaFold series has transformed protein structure prediction with
remarkable accuracy, often matching experimental methods. AlphaFold2,
AlphaFold-Multimer, and the latest AlphaFold3 represent significant strides in
predicting single protein chains, protein complexes, and biomolecular
structures. While AlphaFold2 and AlphaFold-Multimer are open-sourced,
facilitating rapid and reliable predictions, AlphaFold3 remains partially
accessible through a limited online server and has not been open-sourced,
restricting further development. To address these challenges, the PaddleHelix
team is developing HelixFold3, aiming to replicate AlphaFold3's capabilities.
Leveraging insights from previous models and extensive datasets, HelixFold3
achieves accuracy comparable to AlphaFold3 in predicting the structures of the
conventional ligands, nucleic acids, and proteins. The initial release of
HelixFold3 is available as open source on GitHub for academic research,
promising to advance biomolecular research and accelerate discoveries. The
latest version will be continuously updated on the HelixFold3 web server,
providing both interactive visualization and API access.",2024-08-30,"Lihang Liu, Shanzhuo Zhang, Yang Xue, Xianbin Ye, Kunrui Zhu, Yuxin Li, Yang Liu, Jie Gao, Wenlai Zhao, Hongkun Yu, Zhihua Wu, Xiaonan Zhang, Xiaomin Fang",http://arxiv.org/pdf/2408.16975v3,cs.LG
Graph neural network-based lithium-ion battery state of health estimation using partial discharging curve,"Data-driven methods have gained extensive attention in estimating the state
of health (SOH) of lithium-ion batteries. Accurate SOH estimation requires
degradation-relevant features and alignment of statistical distributions
between training and testing datasets. However, current research often
overlooks these needs and relies on arbitrary voltage segment selection. To
address these challenges, this paper introduces an innovative approach
leveraging spatio-temporal degradation dynamics via graph convolutional
networks (GCNs). Our method systematically selects discharge voltage segments
using the Matrix Profile anomaly detection algorithm, eliminating the need for
manual selection and preventing information loss. These selected segments form
a fundamental structure integrated into the GCN-based SOH estimation model,
capturing inter-cycle dynamics and mitigating statistical distribution
incongruities between offline training and online testing data. Validation with
a widely accepted open-source dataset demonstrates that our method achieves
precise SOH estimation, with a root mean squared error of less than 1%.",2024-08-30,"Kate Qi Zhou, Yan Qin, Chau Yuen",http://arxiv.org/pdf/2409.00141v1,cs.LG
Point Neuron Learning: A New Physics-Informed Neural Network Architecture,"Machine learning and neural networks have advanced numerous research domains,
but challenges such as large training data requirements and inconsistent model
performance hinder their application in certain scientific problems. To
overcome these challenges, researchers have investigated integrating physics
principles into machine learning models, mainly through: (i) physics-guided
loss functions, generally termed as physics-informed neural networks, and (ii)
physics-guided architectural design. While both approaches have demonstrated
success across multiple scientific disciplines, they have limitations including
being trapped to a local minimum, poor interpretability, and restricted
generalizability. This paper proposes a new physics-informed neural network
(PINN) architecture that combines the strengths of both approaches by embedding
the fundamental solution of the wave equation into the network architecture,
enabling the learned model to strictly satisfy the wave equation. The proposed
point neuron learning method can model an arbitrary sound field based on
microphone observations without any dataset. Compared to other PINN methods,
our approach directly processes complex numbers and offers better
interpretability and generalizability. We evaluate the versatility of the
proposed architecture by a sound field reconstruction problem in a reverberant
environment. Results indicate that the point neuron method outperforms two
competing methods and can efficiently handle noisy environments with sparse
microphone observations.",2024-08-30,"Hanwen Bi, Thushara D. Abhayapala",http://arxiv.org/pdf/2408.16969v1,cs.LG
UserSumBench: A Benchmark Framework for Evaluating User Summarization Approaches,"Large language models (LLMs) have shown remarkable capabilities in generating
user summaries from a long list of raw user activity data. These summaries
capture essential user information such as preferences and interests, and
therefore are invaluable for LLM-based personalization applications, such as
explainable recommender systems. However, the development of new summarization
techniques is hindered by the lack of ground-truth labels, the inherent
subjectivity of user summaries, and human evaluation which is often costly and
time-consuming. To address these challenges, we introduce \UserSumBench, a
benchmark framework designed to facilitate iterative development of LLM-based
summarization approaches. This framework offers two key components: (1) A
reference-free summary quality metric. We show that this metric is effective
and aligned with human preferences across three diverse datasets (MovieLens,
Yelp and Amazon Review). (2) A novel robust summarization method that leverages
time-hierarchical summarizer and self-critique verifier to produce high-quality
summaries while eliminating hallucination. This method serves as a strong
baseline for further innovation in summarization techniques.",2024-08-30,"Chao Wang, Neo Wu, Lin Ning, Jiaxing Wu, Luyang Liu, Jun Xie, Shawn O'Banion, Bradley Green",http://arxiv.org/pdf/2408.16966v2,cs.LG
Discovery of False Data Injection Schemes on Frequency Controllers with Reinforcement Learning,"While inverter-based distributed energy resources (DERs) play a crucial role
in integrating renewable energy into the power system, they concurrently
diminish the grid's system inertia, elevating the risk of frequency
instabilities. Furthermore, smart inverters, interfaced via communication
networks, pose a potential vulnerability to cyber threats if not diligently
managed. To proactively fortify the power grid against sophisticated cyber
attacks, we propose to employ reinforcement learning (RL) to identify potential
threats and system vulnerabilities. This study concentrates on analyzing
adversarial strategies for false data injection, specifically targeting smart
inverters involved in primary frequency control. Our findings demonstrate that
an RL agent can adeptly discern optimal false data injection methods to
manipulate inverter settings, potentially causing catastrophic consequences.",2024-08-30,"Romesh Prasad, Malik Hassanaly, Xiangyu Zhang, Abhijeet Sahu",http://arxiv.org/pdf/2408.16958v1,cs.LG
An Empirical Study of Scaling Laws for Transfer,"We present a limited empirical study of scaling laws for transfer learning in
transformer models. More specifically, we examine a scaling law that
incorporates a ""transfer gap"" term, indicating the effectiveness of
pre-training on one distribution when optimizing for downstream performance on
another distribution. When the transfer gap is low, pre-training is a
cost-effective strategy for improving downstream performance. Conversely, when
the gap is high, collecting high-quality fine-tuning data becomes relatively
more cost effective. Fitting the scaling law to experiments from diverse
datasets reveals significant variations in the transfer gap across
distributions. In theory, the scaling law can inform optimal data allocation
strategies and highlights how the scarcity of downstream data can bottleneck
performance. Our findings contribute to a principled way to measure transfer
learning efficiency and understand how data availability affects capabilities.",2024-08-30,Matthew Barnett,http://arxiv.org/pdf/2408.16947v1,cs.LG
"Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection","In the pursuit of an effective spam detection system, the focus has often
been on identifying known spam patterns either through rule-based detection
systems or machine learning (ML) solutions that rely on keywords. However, both
systems are susceptible to evasion techniques and zero-day attacks that can be
achieved at low cost. Therefore, an email that bypassed the defense system once
can do it again in the following days, even though rules are updated or the ML
models are retrained. The recurrence of failures to detect emails that exhibit
layout similarities to previously undetected spam is concerning for customers
and can erode their trust in a company. Our observations show that threat
actors reuse email kits extensively and can bypass detection with little
effort, for example, by making changes to the content of emails. In this work,
we propose an email visual similarity detection approach, named Pisco, to
improve the detection capabilities of an email threat defense system. We apply
our proof of concept to some real-world samples received from different
sources. Our results show that email kits are being reused extensively and
visually similar emails are sent to our customers at various time intervals.
Therefore, this method could be very helpful in situations where detection
engines that rely on textual features and keywords are bypassed, an occurrence
our observations show happens frequently.",2024-08-29,"Sachin Shukla, Omid Mirzaei",http://arxiv.org/pdf/2408.16945v3,cs.LG
FlowRetrieval: Flow-Guided Data Retrieval for Few-Shot Imitation Learning,"Few-shot imitation learning relies on only a small amount of task-specific
demonstrations to efficiently adapt a policy for a given downstream tasks.
Retrieval-based methods come with a promise of retrieving relevant past
experiences to augment this target data when learning policies. However,
existing data retrieval methods fall under two extremes: they either rely on
the existence of exact behaviors with visually similar scenes in the prior
data, which is impractical to assume; or they retrieve based on semantic
similarity of high-level language descriptions of the task, which might not be
that informative about the shared low-level behaviors or motions across tasks
that is often a more important factor for retrieving relevant data for policy
learning. In this work, we investigate how we can leverage motion similarity in
the vast amount of cross-task data to improve few-shot imitation learning of
the target task. Our key insight is that motion-similar data carries rich
information about the effects of actions and object interactions that can be
leveraged during few-shot adaptation. We propose FlowRetrieval, an approach
that leverages optical flow representations for both extracting similar motions
to target tasks from prior data, and for guiding learning of a policy that can
maximally benefit from such data. Our results show FlowRetrieval significantly
outperforms prior methods across simulated and real-world domains, achieving on
average 27% higher success rate than the best retrieval-based prior method. In
the Pen-in-Cup task with a real Franka Emika robot, FlowRetrieval achieves 3.7x
the performance of the baseline imitation learning technique that learns from
all prior and target data. Website: https://flow-retrieval.github.io",2024-08-29,"Li-Heng Lin, Yuchen Cui, Amber Xie, Tianyu Hua, Dorsa Sadigh",http://arxiv.org/pdf/2408.16944v2,cs.LG
Efficient Transonic Aeroelastic Model Reduction Using Optimized Sparse Multi-Input Polynomial Functionals,"Nonlinear aeroelastic reduced-order models (ROMs) based on machine learning
or artificial intelligence algorithms can be complex and computationally
demanding to train, meaning that for practical aeroelastic applications, the
conservative nature of linearization is often favored. Therefore, there is a
requirement for novel nonlinear aeroelastic model reduction approaches that are
accurate, simple and, most importantly, efficient to generate. This paper
proposes a novel formulation for the identification of a compact multi-input
Volterra series, where Orthogonal Matching Pursuit is used to obtain a set of
optimally sparse nonlinear multi-input ROM coefficients from unsteady
aerodynamic training data. The framework is exemplified using the Benchmark
Supercritical Wing, considering; forced response, flutter and limit cycle
oscillation. The simple and efficient Optimal Sparsity Multi-Input ROM
(OSM-ROM) framework performs with high accuracy compared to the full-order
aeroelastic model, requiring only a fraction of the tens-of-thousands of
possible multi-input terms to be identified and allowing a 96% reduction in the
number of training samples.",2024-08-29,"Michael Candon, Maciej Balajewicz, Arturo Delgado-Gutierrez, Pier Marzocca, Earl H. Dowell",http://arxiv.org/pdf/2408.16941v1,cs.LG
Theoretical Insights into Overparameterized Models in Multi-Task and Replay-Based Continual Learning,"Multi-task learning (MTL) is a machine learning paradigm that aims to improve
the generalization performance of a model on multiple related tasks by training
it simultaneously on those tasks. Unlike MTL, where the model has instant
access to the training data of all tasks, continual learning (CL) involves
adapting to new sequentially arriving tasks over time without forgetting the
previously acquired knowledge. Despite the wide practical adoption of CL and
MTL and extensive literature on both areas, there remains a gap in the
theoretical understanding of these methods when used with overparameterized
models such as deep neural networks. This paper studies the overparameterized
linear models as a proxy for more complex models. We develop theoretical
results describing the effect of various system parameters on the model's
performance in an MTL setup. Specifically, we study the impact of model size,
dataset size, and task similarity on the generalization error and knowledge
transfer. Additionally, we present theoretical results to characterize the
performance of replay-based CL models. Our results reveal the impact of buffer
size and model capacity on the forgetting rate in a CL setup and help shed
light on some of the state-of-the-art CL methods. Finally, through extensive
empirical evaluations, we demonstrate that our theoretical findings are also
applicable to deep neural networks, offering valuable guidance for designing
MTL and CL models in practice.",2024-08-29,"Amin Banayeeanzade, Mahdi Soltanolkotabi, Mohammad Rostami",http://arxiv.org/pdf/2408.16939v2,cs.LG
Tiny-Toxic-Detector: A compact transformer-based model for toxic content detection,"This paper presents Tiny-toxic-detector, a compact transformer-based model
designed for toxic content detection. Despite having only 2.1 million
parameters, Tiny-toxic-detector achieves competitive performance on benchmark
datasets, with 90.97% accuracy on ToxiGen and 86.98% accuracy on the Jigsaw
dataset, rivaling models over 50 times its size. This efficiency enables
deployment in resource-constrained environments, addressing the need for
effective content moderation tools that balance performance with computational
efficiency. The model architecture features 4 transformer encoder layers, each
with 2 attention heads, an embedding dimension of 64, and a feedforward
dimension of 128. Trained on both public and private datasets,
Tiny-toxic-detector demonstrates the potential of efficient, task-specific
models for addressing online toxicity. The paper covers the model architecture,
training process, performance benchmarks, and limitations, underscoring its
suitability for applications such as social media monitoring and content
moderation. By achieving results comparable to much larger models while
significantly reducing computational demands, Tiny-toxic-detector represents
progress toward more sustainable and scalable AI-driven content moderation
solutions.",2024-08-29,Michiel Kamphuis,http://arxiv.org/pdf/2409.02114v1,cs.LG
AI-driven Reverse Engineering of QML Models,"Quantum machine learning (QML) is a rapidly emerging area of research, driven
by the capabilities of Noisy Intermediate-Scale Quantum (NISQ) devices. With
the progress in the research of QML models, there is a rise in third-party
quantum cloud services to cater to the increasing demand for resources. New
security concerns surface, specifically regarding the protection of
intellectual property (IP) from untrustworthy service providers. One of the
most pressing risks is the potential for reverse engineering (RE) by malicious
actors who may steal proprietary quantum IPs such as trained parameters and QML
architecture, modify them to remove additional watermarks or signatures and
re-transpile them for other quantum hardware. Prior work presents a brute force
approach to RE the QML parameters which takes exponential time overhead. In
this paper, we introduce an autoencoder-based approach to extract the
parameters from transpiled QML models deployed on untrusted third-party
vendors. We experiment on multi-qubit classifiers and note that they can be
reverse-engineered under restricted conditions with a mean error of order
10^-1. The amount of time taken to prepare the dataset and train the model to
reverse engineer the QML circuit being of the order 10^3 seconds (which is
10^2x better than the previously reported value for 4-layered 4-qubit
classifiers) makes the threat of RE highly potent, underscoring the need for
continued development of effective defenses.",2024-08-29,"Archisman Ghosh, Swaroop Ghosh",http://arxiv.org/pdf/2408.16929v1,cs.LG
Analyzing Inference Privacy Risks Through Gradients in Machine Learning,"In distributed learning settings, models are iteratively updated with shared
gradients computed from potentially sensitive user data. While previous work
has studied various privacy risks of sharing gradients, our paper aims to
provide a systematic approach to analyze private information leakage from
gradients. We present a unified game-based framework that encompasses a broad
range of attacks including attribute, property, distributional, and user
disclosures. We investigate how different uncertainties of the adversary affect
their inferential power via extensive experiments on five datasets across
various data modalities. Our results demonstrate the inefficacy of solely
relying on data aggregation to achieve privacy against inference attacks in
distributed learning. We further evaluate five types of defenses, namely,
gradient pruning, signed gradient descent, adversarial perturbations,
variational information bottleneck, and differential privacy, under both static
and adaptive adversary settings. We provide an information-theoretic view for
analyzing the effectiveness of these defenses against inference from gradients.
Finally, we introduce a method for auditing attribute inference privacy,
improving the empirical estimation of worst-case privacy through crafting
adversarial canary records.",2024-08-29,"Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Bradley Malin, Ye Wang",http://arxiv.org/pdf/2408.16913v1,cs.LG
DLFormer: Enhancing Explainability in Multivariate Time Series Forecasting using Distributed Lag Embedding,". Most real-world variables are multivariate time series influenced by past
values and explanatory factors. Consequently, predicting these time series data
using artificial intelligence is ongoing. In particular, in fields such as
healthcare and finance, where reliability is crucial, having understandable
explanations for predictions is essential. However, achieving a balance between
high prediction accuracy and intuitive explainability has proven challenging.
Although attention-based models have limitations in representing the individual
influences of each variable, these models can influence the temporal
dependencies in time series prediction and the magnitude of the influence of
individual variables. To address this issue, this study introduced DLFormer, an
attention-based architecture integrated with distributed lag embedding, to
temporally embed individual variables and capture their temporal influence.
Through validation against various real-world datasets, DLFormer showcased
superior performance improvements compared to existing attention-based
high-performance models. Furthermore, comparing the relationships between
variables enhanced the reliability of explainability.",2024-08-29,"Younghwi Kim, Dohee Kim, Sunghyun Sim",http://arxiv.org/pdf/2408.16896v1,cs.LG
Exploring Multiple Strategies to Improve Multilingual Coreference Resolution in CorefUD,"Coreference resolution, the task of identifying expressions in text that
refer to the same entity, is a critical component in various natural language
processing applications. This paper presents a novel end-to-end neural
coreference resolution system utilizing the CorefUD 1.1 dataset, which spans 17
datasets across 12 languages. The proposed model is based on the standard
end-to-end neural coreference resolution system. We first establish baseline
models, including monolingual and cross-lingual variations, and then propose
several extensions to enhance performance across diverse linguistic contexts.
These extensions include cross-lingual training, incorporation of syntactic
information, a Span2Head model for optimized headword prediction, and advanced
singleton modeling. We also experiment with headword span representation and
long-documents modeling through overlapping segments. The proposed extensions,
particularly the heads-only approach, singleton modeling, and long document
prediction, significantly improve performance across most datasets. We also
perform zero-shot cross-lingual experiments, highlighting the potential and
limitations of cross-lingual transfer in coreference resolution. Our findings
contribute to the development of robust and scalable coreference systems for
multilingual coreference resolution. Finally, we evaluate our model on the
CorefUD 1.1 test set and surpass the best model from the CRAC 2023 shared task
of comparable size by a large margin.",2024-08-29,"Ondřej Pražák, Miloslav Konopík, Pavel Král",http://arxiv.org/pdf/2408.16893v3,cs.LG
"Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector","Deepfakes, which employ GAN to produce highly realistic facial modification,
are widely regarded as the prevailing method. Traditional CNN have been able to
identify bogus media, but they struggle to perform well on different datasets
and are vulnerable to adversarial attacks due to their lack of robustness.
Vision transformers have demonstrated potential in the realm of image
classification problems, but they require enough training data. Motivated by
these limitations, this publication introduces Tex-ViT (Texture-Vision
Transformer), which enhances CNN features by combining ResNet with a vision
transformer. The model combines traditional ResNet features with a texture
module that operates in parallel on sections of ResNet before each
down-sampling operation. The texture module then serves as an input to the dual
branch of the cross-attention vision transformer. It specifically focuses on
improving the global texture module, which extracts feature map correlation.
Empirical analysis reveals that fake images exhibit smooth textures that do not
remain consistent over long distances in manipulations. Experiments were
performed on different categories of FF++, such as DF, f2f, FS, and NT,
together with other types of GAN datasets in cross-domain scenarios.
Furthermore, experiments also conducted on FF++, DFDCPreview, and Celeb-DF
dataset underwent several post-processing situations, such as blurring,
compression, and noise. The model surpassed the most advanced models in terms
of generalization, achieving a 98% accuracy in cross-domain scenarios. This
demonstrates its ability to learn the shared distinguishing textural
characteristics in the manipulated samples. These experiments provide evidence
that the proposed model is capable of being applied to various situations and
is resistant to many post-processing procedures.",2024-08-29,"Deepak Dagar, Dinesh Kumar Vishwakarma",http://arxiv.org/pdf/2408.16892v1,cs.LG
Robotic warehousing operations: a learn-then-optimize approach to large-scale neighborhood search,"The rapid deployment of robotics technologies requires dedicated optimization
algorithms to manage large fleets of autonomous agents. This paper supports
robotic parts-to-picker operations in warehousing by optimizing
order-workstation assignments, item-pod assignments and the schedule of order
fulfillment at workstations. The model maximizes throughput, while managing
human workload at the workstations and congestion in the facility. We solve it
via large-scale neighborhood search, with a novel learn-then-optimize approach
to subproblem generation. The algorithm relies on an offline machine learning
procedure to predict objective improvements based on subproblem features, and
an online optimization model to generate a new subproblem at each iteration. In
collaboration with Amazon Robotics, we show that our model and algorithm
generate much stronger solutions for practical problems than state-of-the-art
approaches. In particular, our solution enhances the utilization of robotic
fleets by coordinating robotic tasks for human operators to pick multiple items
at once, and by coordinating robotic routes to avoid congestion in the
facility.",2024-08-29,"Cynthia Barnhart, Alexandre Jacquillat, Alexandria Schmid",http://arxiv.org/pdf/2408.16890v1,cs.LG
LLaVA-Chef: A Multi-modal Generative Model for Food Recipes,"In the rapidly evolving landscape of online recipe sharing within a
globalized context, there has been a notable surge in research towards
comprehending and generating food recipes. Recent advancements in large
language models (LLMs) like GPT-2 and LLaVA have paved the way for Natural
Language Processing (NLP) approaches to delve deeper into various facets of
food-related tasks, encompassing ingredient recognition and comprehensive
recipe generation. Despite impressive performance and multi-modal adaptability
of LLMs, domain-specific training remains paramount for their effective
application. This work evaluates existing LLMs for recipe generation and
proposes LLaVA-Chef, a novel model trained on a curated dataset of diverse
recipe prompts in a multi-stage approach. First, we refine the mapping of
visual food image embeddings to the language space. Second, we adapt LLaVA to
the food domain by fine-tuning it on relevant recipe data. Third, we utilize
diverse prompts to enhance the model's recipe comprehension. Finally, we
improve the linguistic quality of generated recipes by penalizing the model
with a custom loss function. LLaVA-Chef demonstrates impressive improvements
over pretrained LLMs and prior works. A detailed qualitative analysis reveals
that LLaVA-Chef generates more detailed recipes with precise ingredient
mentions, compared to existing approaches.",2024-08-29,"Fnu Mohbat, Mohammed J. Zaki",http://arxiv.org/pdf/2408.16889v1,cs.LG
Multimodal ELBO with Diffusion Decoders,"Multimodal variational autoencoders have demonstrated their ability to learn
the relationships between different modalities by mapping them into a latent
representation. Their design and capacity to perform any-to-any conditional and
unconditional generation make them appealing. However, different variants of
multimodal VAEs often suffer from generating low-quality output, particularly
when complex modalities such as images are involved. In addition to that, they
frequently exhibit low coherence among the generated modalities when sampling
from the joint distribution. To address these limitations, we propose a new
variant of the multimodal VAE ELBO that incorporates a better decoder using a
diffusion generative model. The diffusion decoder enables the model to learn
complex modalities and generate high-quality outputs. The multimodal model can
also seamlessly integrate with a standard feed-forward decoder for different
types of modality, facilitating end-to-end training and inference. Furthermore,
we introduce an auxiliary score-based model to enhance the unconditional
generation capabilities of our proposed approach. This approach addresses the
limitations imposed by conventional multimodal VAEs and opens up new
possibilities to improve multimodal generation tasks. Our model provides
state-of-the-art results compared to other multimodal VAEs in different
datasets with higher coherence and superior quality in the generated
modalities.",2024-08-29,"Daniel Wesego, Pedram Rooshenas",http://arxiv.org/pdf/2408.16883v2,cs.LG
Coverage Analysis of Multi-Environment Q-Learning Algorithms for Wireless Network Optimization,"Q-learning is widely used to optimize wireless networks with unknown system
dynamics. Recent advancements include ensemble multi-environment hybrid
Q-learning algorithms, which utilize multiple Q-learning algorithms across
structurally related but distinct Markovian environments and outperform
existing Q-learning algorithms in terms of accuracy and complexity in
large-scale wireless networks. We herein conduct a comprehensive coverage
analysis to ensure optimal data coverage conditions for these algorithms.
Initially, we establish upper bounds on the expectation and variance of
different coverage coefficients. Leveraging these bounds, we present an
algorithm for efficient initialization of these algorithms. We test our
algorithm on two distinct real-world wireless networks. Numerical simulations
show that our algorithm can achieve %50 less policy error and %40 less runtime
complexity than state-of-the-art reinforcement learning algorithms.
Furthermore, our algorithm exhibits robustness to changes in network settings
and parameters. We also numerically validate our theoretical results.",2024-08-29,"Talha Bozkus, Urbashi Mitra",http://arxiv.org/pdf/2408.16882v1,cs.LG
"Longitudinal Modularity, a Modularity for Link Streams","Temporal networks are commonly used to model real-life phenomena. When these
phenomena represent interactions and are captured at a fine-grained temporal
resolution, they are modeled as link streams. Community detection is an
essential network analysis task. Although many methods exist for static
networks, and some methods have been developed for temporal networks
represented as sequences of snapshots, few works can handle link streams. This
article introduces the first adaptation of the well-known Modularity quality
function to link streams. Unlike existing methods, it is independent of the
time scale of analysis. After introducing the quality function, and its
relation to existing static and dynamic definitions of Modularity, we show
experimentally its relevance for dynamic community evaluation.",2024-08-29,"Victor Brabant, Yasaman Asgari, Pierre Borgnat, Angela Bonifati, Remy Cazabet",http://arxiv.org/pdf/2408.16877v1,cs.LG
Learning Multi-agent Multi-machine Tending by Mobile Robots,"Robotics can help address the growing worker shortage challenge of the
manufacturing industry. As such, machine tending is a task collaborative robots
can tackle that can also highly boost productivity. Nevertheless, existing
robotics systems deployed in that sector rely on a fixed single-arm setup,
whereas mobile robots can provide more flexibility and scalability. In this
work, we introduce a multi-agent multi-machine tending learning framework by
mobile robots based on Multi-agent Reinforcement Learning (MARL) techniques
with the design of a suitable observation and reward. Moreover, an
attention-based encoding mechanism is developed and integrated into Multi-agent
Proximal Policy Optimization (MAPPO) algorithm to boost its performance for
machine tending scenarios. Our model (AB-MAPPO) outperformed MAPPO in this new
challenging scenario in terms of task success, safety, and resources
utilization. Furthermore, we provided an extensive ablation study to support
our various design decisions.",2024-08-29,"Abdalwhab Abdalwhab, Giovanni Beltrame, Samira Ebrahimi Kahou, David St-Onge",http://arxiv.org/pdf/2408.16875v3,cs.LG
GSTAM: Efficient Graph Distillation with Structural Attention-Matching,"Graph distillation has emerged as a solution for reducing large graph
datasets to smaller, more manageable, and informative ones. Existing methods
primarily target node classification, involve computationally intensive
processes, and fail to capture the true distribution of the full graph dataset.
To address these issues, we introduce Graph Distillation with Structural
Attention Matching (GSTAM), a novel method for condensing graph classification
datasets. GSTAM leverages the attention maps of GNNs to distill structural
information from the original dataset into synthetic graphs. The structural
attention-matching mechanism exploits the areas of the input graph that GNNs
prioritize for classification, effectively distilling such information into the
synthetic graphs and improving overall distillation performance. Comprehensive
experiments demonstrate GSTAM's superiority over existing methods, achieving
0.45% to 6.5% better performance in extreme condensation ratios, highlighting
its potential use in advancing distillation for graph classification tasks
(Code available at https://github.com/arashrasti96/GSTAM).",2024-08-29,"Arash Rasti-Meymandi, Ahmad Sajedi, Zhaopan Xu, Konstantinos N. Plataniotis",http://arxiv.org/pdf/2408.16871v1,cs.LG
Characterization of point-source transient events with a rolling-shutter compressed sensing system,"Point-source transient events (PSTEs) - optical events that are both
extremely fast and extremely small - pose several challenges to an imaging
system. Due to their speed, accurately characterizing such events often
requires detectors with very high frame rates. Due to their size, accurately
detecting such events requires maintaining coverage over an extended
field-of-view, often through the use of imaging focal plane arrays (FPA) with a
global shutter readout. Traditional imaging systems that meet these
requirements are costly in terms of price, size, weight, power consumption, and
data bandwidth, and there is a need for cheaper solutions with adequate
temporal and spatial coverage. To address these issues, we develop a novel
compressed sensing algorithm adapted to the rolling shutter readout of an
imaging system. This approach enables reconstruction of a PSTE signature at the
sampling rate of the rolling shutter, offering a 1-2 order of magnitude
temporal speedup and a proportional reduction in data bandwidth. We present
empirical results demonstrating accurate recovery of PSTEs using measurements
that are spatially undersampled by a factor of 25, and our simulations show
that, relative to other compressed sensing algorithms, our algorithm is both
faster and yields higher quality reconstructions. We also present theoretical
results characterizing our algorithm and corroborating simulations. The
potential impact of our work includes the development of much faster, cheaper
sensor solutions for PSTE detection and characterization.",2024-08-29,"Frank Qiu, Joshua Michalenko, Lilian K. Casias, Cameron J. Radosevich, Jon Slater, Eric A. Shields",http://arxiv.org/pdf/2408.16868v2,cs.LG
Statistical Analysis of the Impact of Quaternion Components in Convolutional Neural Networks,"In recent years, several models using Quaternion-Valued Convolutional Neural
Networks (QCNNs) for different problems have been proposed. Although the
definition of the quaternion convolution layer is the same, there are different
adaptations of other atomic components to the quaternion domain, e.g., pooling
layers, activation functions, fully connected layers, etc. However, the effect
of selecting a specific type of these components and the way in which their
interactions affect the performance of the model still unclear. Understanding
the impact of these choices on model performance is vital for effectively
utilizing QCNNs. This paper presents a statistical analysis carried out on
experimental data to compare the performance of existing components for the
image classification problem. In addition, we introduce a novel Fully
Quaternion ReLU activation function, which exploits the unique properties of
quaternion algebra to improve model performance.",2024-08-29,"Gerardo Altamirano-Gómez, Carlos Gershenson",http://arxiv.org/pdf/2409.00140v1,cs.LG
WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks,"Embeddings-as-a-Service (EaaS) is a service offered by large language model
(LLM) developers to supply embeddings generated by LLMs. Previous research
suggests that EaaS is prone to imitation attacks -- attacks that clone the
underlying EaaS model by training another model on the queried embeddings. As a
result, EaaS watermarks are introduced to protect the intellectual property of
EaaS providers. In this paper, we first show that existing EaaS watermarks can
be removed by paraphrasing when attackers clone the model. Subsequently, we
propose a novel watermarking technique that involves linearly transforming the
embeddings, and show that it is empirically and theoretically robust against
paraphrasing.",2024-08-29,"Anudeex Shetty, Qiongkai Xu, Jey Han Lau",http://arxiv.org/pdf/2409.04459v1,cs.LG
Probabilistic Decomposed Linear Dynamical Systems for Robust Discovery of Latent Neural Dynamics,"Time-varying linear state-space models are powerful tools for obtaining
mathematically interpretable representations of neural signals. For example,
switching and decomposed models describe complex systems using latent variables
that evolve according to simple locally linear dynamics. However, existing
methods for latent variable estimation are not robust to dynamical noise and
system nonlinearity due to noise-sensitive inference procedures and limited
model formulations. This can lead to inconsistent results on signals with
similar dynamics, limiting the model's ability to provide scientific insight.
In this work, we address these limitations and propose a probabilistic approach
to latent variable estimation in decomposed models that improves robustness
against dynamical noise. Additionally, we introduce an extended latent dynamics
model to improve robustness against system nonlinearities. We evaluate our
approach on several synthetic dynamical systems, including an
empirically-derived brain-computer interface experiment, and demonstrate more
accurate latent variable inference in nonlinear systems with diverse noise
conditions. Furthermore, we apply our method to a real-world clinical
neurophysiology dataset, illustrating the ability to identify interpretable and
coherent structure where previous models cannot.",2024-08-29,"Yenho Chen, Noga Mudrik, Kyle A. Johnsen, Sankaraleengam Alagapan, Adam S. Charles, Christopher J. Rozell",http://arxiv.org/pdf/2408.16862v2,cs.LG
The Star Geometry of Critic-Based Regularizer Learning,"Variational regularization is a classical technique to solve statistical
inference tasks and inverse problems, with modern data-driven approaches
parameterizing regularizers via deep neural networks showcasing impressive
empirical performance. Recent works along these lines learn task-dependent
regularizers. This is done by integrating information about the measurements
and ground-truth data in an unsupervised, critic-based loss function, where the
regularizer attributes low values to likely data and high values to unlikely
data. However, there is little theory about the structure of regularizers
learned via this process and how it relates to the two data distributions. To
make progress on this challenge, we initiate a study of optimizing critic-based
loss functions to learn regularizers over a particular family of regularizers:
gauges (or Minkowski functionals) of star-shaped bodies. This family contains
regularizers that are commonly employed in practice and shares properties with
regularizers parameterized by deep neural networks. We specifically investigate
critic-based losses derived from variational representations of statistical
distances between probability measures. By leveraging tools from star geometry
and dual Brunn-Minkowski theory, we illustrate how these losses can be
interpreted as dual mixed volumes that depend on the data distribution. This
allows us to derive exact expressions for the optimal regularizer in certain
cases. Finally, we identify which neural network architectures give rise to
such star body gauges and when do such regularizers have favorable properties
for optimization. More broadly, this work highlights how the tools of star
geometry can aid in understanding the geometry of unsupervised regularizer
learning.",2024-08-29,"Oscar Leong, Eliza O'Reilly, Yong Sheng Soh",http://arxiv.org/pdf/2408.16852v2,cs.LG
Machine Learning-Based Research on the Adaptability of Adolescents to Online Education,"With the rapid advancement of internet technology, the adaptability of
adolescents to online learning has emerged as a focal point of interest within
the educational sphere. However, the academic community's efforts to develop
predictive models for adolescent online learning adaptability require further
refinement and expansion. Utilizing data from the ""Chinese Adolescent Online
Education Survey"" spanning the years 2014 to 2016, this study implements five
machine learning algorithms - logistic regression, K-nearest neighbors, random
forest, XGBoost, and CatBoost - to analyze the factors influencing adolescent
online learning adaptability and to determine the model best suited for
prediction. The research reveals that the duration of courses, the financial
status of the family, and age are the primary factors affecting students'
adaptability in online learning environments. Additionally, age significantly
impacts students' adaptive capacities. Among the predictive models, the random
forest, XGBoost, and CatBoost algorithms demonstrate superior forecasting
capabilities, with the random forest model being particularly adept at
capturing the characteristics of students' adaptability.",2024-08-29,"Mingwei Wang, Sitong Liu",http://arxiv.org/pdf/2408.16849v1,cs.LG
Enabling Local Editing in Diffusion Models by Joint and Individual Component Analysis,"Recent advances in Diffusion Models (DMs) have led to significant progress in
visual synthesis and editing tasks, establishing them as a strong competitor to
Generative Adversarial Networks (GANs). However, the latent space of DMs is not
as well understood as that of GANs. Recent research has focused on unsupervised
semantic discovery in the latent space of DMs by leveraging the bottleneck
layer of the denoising network, which has been shown to exhibit properties of a
semantic latent space. However, these approaches are limited to discovering
global attributes. In this paper we address, the challenge of local image
manipulation in DMs and introduce an unsupervised method to factorize the
latent semantics learned by the denoising network of pre-trained DMs. Given an
arbitrary image and defined regions of interest, we utilize the Jacobian of the
denoising network to establish a relation between the regions of interest and
their corresponding subspaces in the latent space. Furthermore, we disentangle
the joint and individual components of these subspaces to identify latent
directions that enable local image manipulation. Once discovered, these
directions can be applied to different images to produce semantically
consistent edits, making our method suitable for practical applications.
Experimental results on various datasets demonstrate that our method can
produce semantic edits that are more localized and have better fidelity
compared to the state-of-the-art.",2024-08-29,"Theodoros Kouzelis, Manos Plitsis, Mihalis A. Nicolaou, Yannis Panagakis",http://arxiv.org/pdf/2408.16845v2,cs.LG
AdapShare: An RL-Based Dynamic Spectrum Sharing Solution for O-RAN,"The Open Radio Access Network (O-RAN) initiative, characterized by open
interfaces and AI/ML-capable RAN Intelligent Controller (RIC), facilitates
effective spectrum sharing among RANs. In this context, we introduce AdapShare,
an ORAN-compatible solution leveraging Reinforcement Learning (RL) for
intent-based spectrum management, with the primary goal of minimizing resource
surpluses or deficits in RANs. By employing RL agents, AdapShare intelligently
learns network demand patterns and uses them to allocate resources. We
demonstrate the efficacy of AdapShare in the spectrum sharing scenario between
LTE and NR networks, incorporating real-world LTE resource usage data and
synthetic NR usage data to demonstrate its practical use. We use the average
surplus or deficit and fairness index to measure the system's performance in
various scenarios. AdapShare outperforms a quasi-static resource allocation
scheme based on long-term network demand statistics, particularly when
available resources are scarce or exceed the aggregate demand from the
networks. Lastly, we present a high-level O-RAN compatible architecture using
RL agents, which demonstrates the seamless integration of AdapShare into
real-world deployment scenarios.",2024-08-29,"Sneihil Gopal, David Griffith, Richard A. Rouil, Chunmei Liu",http://arxiv.org/pdf/2408.16842v2,cs.LG
Maven: A Multimodal Foundation Model for Supernova Science,"A common setting in astronomy is the availability of a small number of
high-quality observations, and larger amounts of either lower-quality
observations or synthetic data from simplified models. Time-domain astrophysics
is a canonical example of this imbalance, with the number of supernovae
observed photometrically outpacing the number observed spectroscopically by
multiple orders of magnitude. At the same time, no data-driven models exist to
understand these photometric and spectroscopic observables in a common context.
Contrastive learning objectives, which have grown in popularity for aligning
distinct data modalities in a shared embedding space, provide a potential
solution to extract information from these modalities. We present Maven, the
first foundation model for supernova science. To construct Maven, we first
pre-train our model to align photometry and spectroscopy from 0.5M synthetic
supernovae using a constrastive objective. We then fine-tune the model on 4,702
observed supernovae from the Zwicky Transient Facility. Maven reaches
state-of-the-art performance on both classification and redshift estimation,
despite the embeddings not being explicitly optimized for these tasks. Through
ablation studies, we show that pre-training with synthetic data improves
overall performance. In the upcoming era of the Vera C. Rubin Observatory,
Maven serves as a Rosetta Stone for leveraging large, unlabeled and multimodal
time-domain datasets.",2024-08-29,"Gemma Zhang, Thomas Helfer, Alexander T. Gagliano, Siddharth Mishra-Sharma, V. Ashley Villar",http://arxiv.org/pdf/2408.16829v1,cs.LG
"A Score-Based Density Formula, with Applications in Diffusion Generative Models","Score-based generative models (SGMs) have revolutionized the field of
generative modeling, achieving unprecedented success in generating realistic
and diverse content. Despite empirical advances, the theoretical basis for why
optimizing the evidence lower bound (ELBO) on the log-likelihood is effective
for training diffusion generative models, such as DDPMs, remains largely
unexplored. In this paper, we address this question by establishing a density
formula for a continuous-time diffusion process, which can be viewed as the
continuous-time limit of the forward process in an SGM. This formula reveals
the connection between the target density and the score function associated
with each step of the forward process. Building on this, we demonstrate that
the minimizer of the optimization objective for training DDPMs nearly coincides
with that of the true objective, providing a theoretical foundation for
optimizing DDPMs using the ELBO. Furthermore, we offer new insights into the
role of score-matching regularization in training GANs, the use of ELBO in
diffusion classifiers, and the recently proposed diffusion loss.",2024-08-29,"Gen Li, Yuling Yan",http://arxiv.org/pdf/2408.16765v1,cs.LG
UV-free Texture Generation with Denoising and Geodesic Heat Diffusions,"Seams, distortions, wasted UV space, vertex-duplication, and varying
resolution over the surface are the most prominent issues of the standard
UV-based texturing of meshes. These issues are particularly acute when
automatic UV-unwrapping techniques are used. For this reason, instead of
generating textures in automatically generated UV-planes like most
state-of-the-art methods, we propose to represent textures as coloured
point-clouds whose colours are generated by a denoising diffusion probabilistic
model constrained to operate on the surface of 3D objects. Our sampling and
resolution agnostic generative model heavily relies on heat diffusion over the
surface of the meshes for spatial communication between points. To enable
processing of arbitrarily sampled point-cloud textures and ensure long-distance
texture consistency we introduce a fast re-sampling of the mesh spectral
properties used during the heat diffusion and introduce a novel
heat-diffusion-based self-attention mechanism. Our code and pre-trained models
are available at github.com/simofoti/UV3-TeD.",2024-08-29,"Simone Foti, Stefanos Zafeiriou, Tolga Birdal",http://arxiv.org/pdf/2408.16762v2,cs.LG
Reinforcement Learning without Human Feedback for Last Mile Fine-Tuning of Large Language Models,"Reinforcement learning is used to align language models with human preference
signals after first pre-training the model to predict the next token of text
within a large corpus using likelihood maximization. Before being deployed in a
specific domain, models are often further fine-tuned on task specific data.
Since human preferences are often unavailable for the last step, it is
performed using likelihood maximization as that is the typical default method.
However, reinforcement learning has other advantages besides facilitating
alignment to a human derived reward function. For one, whereas likelihood
maximization is a form of imitation learning in which the model is trained on
what to do under ideal conditions, reinforcement learning is not limited to
demonstrating actions just for optimally reached states and trains a model what
to do under a range of scenarios as it explores the policy space. In addition,
it also trains a model what not to do, suppressing competitive but poor
actions. This work develops a framework for last-mile fine-tuning using
reinforcement learning and tests whether it garners performance gains. The
experiments center on abstractive summarization, but the framework is general
and broadly applicable. Use of the procedure produced significantly better
results than likelihood maximization when comparing raw predictions. For the
specific data tested, the gap could be bridged by employing post-processing of
the maximum likelihood outputs. Nonetheless, the framework offers a new avenue
for model optimization in situations where post-processing may be less
straightforward or effective, and it can be extended to include more complex
classes of undesirable outputs to penalize and train against, such as
hallucinations.",2024-08-29,Alec Solway,http://arxiv.org/pdf/2408.16753v1,cs.LG
A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models,"Beyond maximum likelihood estimation (MLE), the standard objective of a
language model (LM) that optimizes good examples probabilities, many studies
have explored ways that also penalize bad examples for enhancing the quality of
output distribution, including unlikelihood training, exponential maximizing
average treatment effect (ExMATE), and direct preference optimization (DPO). To
systematically compare these methods and further provide a unified recipe for
LM optimization, in this paper, we present a unique angle of gradient analysis
of loss functions that simultaneously reward good examples and penalize bad
ones in LMs. Through both mathematical results and experiments on
CausalDialogue and Anthropic HH-RLHF datasets, we identify distinct functional
characteristics among these methods. We find that ExMATE serves as a superior
surrogate for MLE, and that combining DPO with ExMATE instead of MLE further
enhances both the statistical (5-7%) and generative (+18% win rate)
performance.",2024-08-29,"Yi-Lin Tuan, William Yang Wang",http://arxiv.org/pdf/2408.16751v1,cs.LG
"Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming","Recent advances in language models have achieved significant progress.
GPT-4o, as a new milestone, has enabled real-time conversations with humans,
demonstrating near-human natural fluency. Such human-computer interaction
necessitates models with the capability to perform reasoning directly with the
audio modality and generate output in streaming. However, this remains beyond
the reach of current academic models, as they typically depend on extra TTS
systems for speech synthesis, resulting in undesirable latency. This paper
introduces the Mini-Omni, an audio-based end-to-end conversational model,
capable of real-time speech interaction. To achieve this capability, we propose
a text-instructed speech generation method, along with batch-parallel
strategies during inference to further boost the performance. Our method also
helps to retain the original model's language capabilities with minimal
degradation, enabling other works to establish real-time interaction
capabilities. We call this training method ""Any Model Can Talk"". We also
introduce the VoiceAssistant-400K dataset to fine-tune models optimized for
speech output. To our best knowledge, Mini-Omni is the first fully end-to-end,
open-source model for real-time speech interaction, offering valuable potential
for future research.",2024-08-29,"Zhifei Xie, Changqiao Wu",http://arxiv.org/pdf/2408.16725v3,cs.LG
AI Meets the Classroom: When Do Large Language Models Harm Learning?,"The effect of large language models (LLMs) in education is debated: Previous
research shows that LLMs can help as well as hurt learning. In two
pre-registered and incentivized laboratory experiments, we find no effect of
LLMs on overall learning outcomes. In exploratory analyses and a field study,
we provide evidence that the effect of LLMs on learning outcomes depends on
usage behavior. Students who substitute some of their learning activities with
LLMs (e.g., by generating solutions to exercises) increase the volume of topics
they can learn about but decrease their understanding of each topic. Students
who complement their learning activities with LLMs (e.g., by asking for
explanations) do not increase topic volume but do increase their understanding.
We also observe that LLMs widen the gap between students with low and high
prior knowledge. While LLMs show great potential to improve learning, their use
must be tailored to the educational context and students' needs.",2024-08-29,"Matthias Lehmann, Philipp B. Cornelius, Fabian J. Sting",http://arxiv.org/pdf/2409.09047v2,cs.LG
A GREAT Architecture for Edge-Based Graph Problems Like TSP,"In the last years, many neural network-based approaches have been proposed to
tackle combinatorial optimization problems such as routing problems. Many of
these approaches are based on graph neural networks (GNNs) or related
transformers, operating on the Euclidean coordinates representing the routing
problems. However, GNNs are inherently not well suited to operate on dense
graphs, such as in routing problems. Furthermore, models operating on Euclidean
coordinates cannot be applied to non-Euclidean versions of routing problems
that are often found in real-world settings. To overcome these limitations, we
propose a novel GNN-related edge-based neural model called Graph Edge Attention
Network (GREAT). We evaluate the performance of GREAT in the
edge-classification task to predict optimal edges in the Traveling Salesman
Problem (TSP). We can use such a trained GREAT model to produce sparse TSP
graph instances, keeping only the edges GREAT finds promising. Compared to
other, non-learning-based methods to sparsify TSP graphs, GREAT can produce
very sparse graphs while keeping most of the optimal edges. Furthermore, we
build a reinforcement learning-based GREAT framework which we apply to
Euclidean and non-Euclidean asymmetric TSP. This framework achieves
state-of-the-art results.",2024-08-29,"Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani, Balázs Kulcsár",http://arxiv.org/pdf/2408.16717v1,cs.LG
"Enhanced forecasting of stock prices based on variational mode decomposition, PatchTST, and adaptive scale-weighted layer","The significant fluctuations in stock index prices in recent years highlight
the critical need for accurate forecasting to guide investment and financial
strategies. This study introduces a novel composite forecasting framework that
integrates variational mode decomposition (VMD), PatchTST, and adaptive
scale-weighted layer (ASWL) to address these challenges. Utilizing datasets of
four major stock indices--SP500, DJI, SSEC, and FTSE--from 2000 to 2024, the
proposed method first decomposes the raw price series into intrinsic mode
functions (IMFs) using VMD. Each IMF is then modeled with PatchTST to capture
temporal patterns effectively. The ASWL module is applied to incorporate scale
information, enhancing prediction accuracy. The final forecast is derived by
aggregating predictions from all IMFs. The VMD-PatchTST-ASWL framework
demonstrates significant improvements in forecasting accuracy compared to
traditional models, showing robust performance across different indices. This
innovative approach provides a powerful tool for stock index price forecasting,
with potential applications in various financial analysis and investment
decision-making contexts.",2024-08-29,"Xiaorui Xue, Shaofang Li, Xiaonan Wang",http://arxiv.org/pdf/2408.16707v1,cs.LG
SympGNNs: Symplectic Graph Neural Networks for identifiying high-dimensional Hamiltonian systems and node classification,"Existing neural network models to learn Hamiltonian systems, such as
SympNets, although accurate in low-dimensions, struggle to learn the correct
dynamics for high-dimensional many-body systems. Herein, we introduce
Symplectic Graph Neural Networks (SympGNNs) that can effectively handle system
identification in high-dimensional Hamiltonian systems, as well as node
classification. SympGNNs combines symplectic maps with permutation
equivariance, a property of graph neural networks. Specifically, we propose two
variants of SympGNNs: i) G-SympGNN and ii) LA-SympGNN, arising from different
parameterizations of the kinetic and potential energy. We demonstrate the
capabilities of SympGNN on two physical examples: a 40-particle coupled
Harmonic oscillator, and a 2000-particle molecular dynamics simulation in a
two-dimensional Lennard-Jones potential. Furthermore, we demonstrate the
performance of SympGNN in the node classification task, achieving accuracy
comparable to the state-of-the-art. We also empirically show that SympGNN can
overcome the oversmoothing and heterophily problems, two key challenges in the
field of graph neural networks.",2024-08-29,"Alan John Varghese, Zhen Zhang, George Em Karniadakis",http://arxiv.org/pdf/2408.16698v1,cs.LG
CW-CNN & CW-AN: Convolutional Networks and Attention Networks for CW-Complexes,"We present a novel framework for learning on CW-complex structured data
points. Recent advances have discussed CW-complexes as ideal learning
representations for problems in cheminformatics. However, there is a lack of
available machine learning methods suitable for learning on CW-complexes. In
this paper we develop notions of convolution and attention that are well
defined for CW-complexes. These notions enable us to create the first Hodge
informed neural network that can receive a CW-complex as input. We illustrate
and interpret this framework in the context of supervised prediction.",2024-08-29,Rahul Khorana,http://arxiv.org/pdf/2408.16686v2,cs.LG
A Catalog of Fairness-Aware Practices in Machine Learning Engineering,"Machine learning's widespread adoption in decision-making processes raises
concerns about fairness, particularly regarding the treatment of sensitive
features and potential discrimination against minorities. The software
engineering community has responded by developing fairness-oriented metrics,
empirical studies, and approaches. However, there remains a gap in
understanding and categorizing practices for engineering fairness throughout
the machine learning lifecycle. This paper presents a novel catalog of
practices for addressing fairness in machine learning derived from a systematic
mapping study. The study identifies and categorizes 28 practices from existing
literature, mapping them onto different stages of the machine learning
lifecycle. From this catalog, the authors extract actionable items and
implications for both researchers and practitioners in software engineering.
This work aims to provide a comprehensive resource for integrating fairness
considerations into the development and deployment of machine learning systems,
enhancing their reliability, accountability, and credibility.",2024-08-29,"Gianmario Voria, Giulia Sellitto, Carmine Ferrara, Francesco Abate, Andrea De Lucia, Filomena Ferrucci, Gemma Catolino, Fabio Palomba",http://arxiv.org/pdf/2408.16683v2,cs.LG
Preserving Diversity in Supervised Fine-Tuning of Large Language Models,"Large Language Models (LLMs) typically rely on Supervised Fine-Tuning (SFT)
to specialize in downstream tasks, with the Cross Entropy (CE) loss being the
de facto choice. However, CE maximizes the likelihood of observed data without
accounting for alternative possibilities. As such, CE usually leads to reduced
diversity in the model's outputs, which hinders further development that
requires sampling to explore better responses. To address this limitation, this
paper introduces a new game-theoretic formulation for SFT. In this framework,
an auxiliary variable is introduced to regulate the learning process. We prove
that the proposed game-theoretic approach connects to the problem of reverse KL
minimization with entropy regularization. This regularization prevents
over-memorization of training data and promotes output diversity. To implement
this framework, we develop GEM, a new training algorithm that is
computationally efficient as CE by leveraging some unique properties of LLMs.
Empirical studies of pre-trained models from 3B to 70B parameters show that GEM
achieves comparable downstream performance to CE while significantly enhancing
output diversity. This increased diversity translates to performance gains in
test-time compute scaling for chat and code generation tasks. Moreover, we
observe that preserving output diversity has the added benefit of mitigating
forgetting, as maintaining diverse outputs encourages models to retain
pre-trained knowledge throughout the training process.",2024-08-29,"Ziniu Li, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Zhi-Quan Luo, Ruoyu Sun",http://arxiv.org/pdf/2408.16673v2,cs.LG
Iterative Graph Alignment,"By compressing diverse narratives, LLMs go beyond memorization, achieving
intelligence by capturing generalizable causal relationships. However, they
suffer from local 'representation gaps' due to insufficient training data
diversity, limiting their real-world utility, especially in tasks requiring
strict alignment to rules. Traditional alignment methods relying on heavy human
annotations are inefficient and unscalable. Recent self-alignment techniques
also fall short, as they often depend on self-selection based prompting and
memorization-based learning. To address these issues, we introduce Iterative
Graph Alignment (IGA), an annotation-free rule-based alignment algorithm. A
teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical
graphs and reference answers. The student model (LLM) identifies local
knowledge gaps by attempting to align its responses with these references,
collaborating with helper models to generate diverse answers. These aligned
responses are then used for iterative supervised fine-tuning (SFT). Our
evaluations across five rule-based scenarios demonstrate IGP's effectiveness,
with a 73.12\% alignment improvement in Claude Sonnet 3.5, and
Llama3-8B-Instruct achieving an 86.20\% improvement, outperforming Claude
Sonnet 3.5 in rule-based alignment.",2024-08-29,"Fangyuan Yu, Hardeep Singh Arora, Matt Johnson",http://arxiv.org/pdf/2408.16667v1,cs.LG
HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications,"Large Language Models (LLMs) face limitations in AI legal and policy
applications due to outdated knowledge, hallucinations, and poor reasoning in
complex contexts. Retrieval-Augmented Generation (RAG) systems address these
issues by incorporating external knowledge, but suffer from retrieval errors,
ineffective context integration, and high operational costs. This paper
presents the Hybrid Parameter-Adaptive RAG (HyPA-RAG) system, designed for the
AI legal domain, with NYC Local Law 144 (LL144) as the test case. HyPA-RAG
integrates a query complexity classifier for adaptive parameter tuning, a
hybrid retrieval approach combining dense, sparse, and knowledge graph methods,
and a comprehensive evaluation framework with tailored question types and
metrics. Testing on LL144 demonstrates that HyPA-RAG enhances retrieval
accuracy, response fidelity, and contextual precision, offering a robust and
adaptable solution for high-stakes legal and policy applications.",2024-08-29,"Rishi Kalra, Zekun Wu, Ayesha Gulley, Airlie Hilliard, Xin Guan, Adriano Koshiyama, Philip Treleaven",http://arxiv.org/pdf/2409.09046v2,cs.LG
Physics-Informed Neural Networks and Extensions,"In this paper, we review the new method Physics-Informed Neural Networks
(PINNs) that has become the main pillar in scientific machine learning, we
present recent practical extensions, and provide a specific example in
data-driven discovery of governing differential equations.",2024-08-29,"Maziar Raissi, Paris Perdikaris, Nazanin Ahmadi, George Em Karniadakis",http://arxiv.org/pdf/2408.16806v1,cs.LG
Optimal Parallelization of Boosting,"Recent works on the parallel complexity of Boosting have established strong
lower bounds on the tradeoff between the number of training rounds $p$ and the
total parallel work per round $t$. These works have also presented highly
non-trivial parallel algorithms that shed light on different regions of this
tradeoff. Despite these advancements, a significant gap persists between the
theoretical lower bounds and the performance of these algorithms across much of
the tradeoff space. In this work, we essentially close this gap by providing
both improved lower bounds on the parallel complexity of weak-to-strong
learners, and a parallel Boosting algorithm whose performance matches these
bounds across the entire $p$ vs.~$t$ compromise spectrum, up to logarithmic
factors. Ultimately, this work settles the true parallel complexity of Boosting
algorithms that are nearly sample-optimal.",2024-08-29,"Arthur da Cunha, Mikael Møller Høgsgaard, Kasper Green Larsen",http://arxiv.org/pdf/2408.16653v1,cs.LG
Towards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods,"This paper presents an examination of State Space Models (SSM) and
Koopman-based deep learning methods for modelling the dynamics of both linear
and non-linear stiff strings. Through experiments with datasets generated under
different initial conditions and sample rates, we assess the capacity of these
models to accurately model the complex behaviours observed in string dynamics.
Our findings indicate that our proposed Koopman-based model performs as well as
or better than other existing approaches in non-linear cases for long-sequence
modelling.
  We inform the design of these architectures with the structure of the
problems at hand. Although challenges remain in extending model predictions
beyond the training horizon (i.e., extrapolation), the focus of our
investigation lies in the models' ability to generalise across different
initial conditions within the training time interval. This research contributes
insights into the physical modelling of dynamical systems (in particular those
addressing musical acoustics) by offering a comparative overview of these and
previous methods and introducing innovative strategies for model improvement.
Our results highlight the efficacy of these models in simulating non-linear
dynamics and emphasise their wide-ranging applicability in accurately modelling
dynamical systems over extended sequences.",2024-08-29,"Rodrigo Diaz, Carlos De La Vega Martin, Mark Sandler",http://arxiv.org/pdf/2408.16650v1,cs.LG
3D Pose-Based Temporal Action Segmentation for Figure Skating: A Fine-Grained and Jump Procedure-Aware Annotation Approach,"Understanding human actions from videos is essential in many domains,
including sports. In figure skating, technical judgments are performed by
watching skaters' 3D movements, and its part of the judging procedure can be
regarded as a Temporal Action Segmentation (TAS) task. TAS tasks in figure
skating that automatically assign temporal semantics to video are actively
researched. However, there is a lack of datasets and effective methods for TAS
tasks requiring 3D pose data. In this study, we first created the FS-Jump3D
dataset of complex and dynamic figure skating jumps using optical markerless
motion capture. We also propose a new fine-grained figure skating jump TAS
dataset annotation method with which TAS models can learn jump procedures. In
the experimental results, we validated the usefulness of 3D pose features as
input and the fine-grained dataset for the TAS model in figure skating.
FS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D.",2024-08-29,"Ryota Tanaka, Tomohiro Suzuki, Keisuke Fujii",http://arxiv.org/pdf/2408.16638v1,cs.LG
Turbulence Strength $C_n^2$ Estimation from Video using Physics-based Deep Learning,"Images captured from a long distance suffer from dynamic image distortion due
to turbulent flow of air cells with random temperatures, and thus refractive
indices. This phenomenon, known as image dancing, is commonly characterized by
its refractive-index structure constant $C_n^2$ as a measure of the turbulence
strength. For many applications such as atmospheric forecast model,
long-range/astronomy imaging, and aviation safety, optical communication
technology, $C_n^2$ estimation is critical for accurately sensing the turbulent
environment. Previous methods for $C_n^2$ estimation include estimation from
meteorological data (temperature, relative humidity, wind shear, etc.) for
single-point measurements, two-ended pathlength measurements from optical
scintillometer for path-averaged $C_n^2$, and more recently estimating $C_n^2$
from passive video cameras for low cost and hardware complexity. In this paper,
we present a comparative analysis of classical image gradient methods for
$C_n^2$ estimation and modern deep learning-based methods leveraging
convolutional neural networks. To enable this, we collect a dataset of video
capture along with reference scintillometer measurements for ground truth, and
we release this unique dataset to the scientific community. We observe that
deep learning methods can achieve higher accuracy when trained on similar data,
but suffer from generalization errors to other, unseen imagery as compared to
classical methods. To overcome this trade-off, we present a novel physics-based
network architecture that combines learned convolutional layers with a
differentiable image gradient method that maintains high accuracy while being
generalizable across image datasets.",2024-08-29,"Ripon Kumar Saha, Esen Salcin, Jihoo Kim, Joseph Smith, Suren Jayasuriya",http://arxiv.org/pdf/2408.16623v1,cs.LG
Towards Infusing Auxiliary Knowledge for Distracted Driver Detection,"Distracted driving is a leading cause of road accidents globally.
Identification of distracted driving involves reliably detecting and
classifying various forms of driver distraction (e.g., texting, eating, or
using in-car devices) from in-vehicle camera feeds to enhance road safety. This
task is challenging due to the need for robust models that can generalize to a
diverse set of driver behaviors without requiring extensive annotated datasets.
In this paper, we propose KiD3, a novel method for distracted driver detection
(DDD) by infusing auxiliary knowledge about semantic relations between entities
in a scene and the structural configuration of the driver's pose. Specifically,
we construct a unified framework that integrates the scene graphs, and driver
pose information with the visual cues in video frames to create a holistic
representation of the driver's actions.Our results indicate that KiD3 achieves
a 13.64% accuracy improvement over the vision-only baseline by incorporating
such auxiliary knowledge with visual information.",2024-08-29,"Ishwar B Balappanawar, Ashmit Chamoli, Ruwan Wickramarachchi, Aditya Mishra, Ponnurangam Kumaraguru, Amit P. Sheth",http://arxiv.org/pdf/2408.16621v1,cs.LG
Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation,"We construct a two-layered model for learning and generating sequential data
that is both computationally fast and competitive with vanilla Tsetlin
machines, adding numerous advantages. Through the use of hyperdimensional
vector computing (HVC) algebras and Tsetlin machine clause structures, we
demonstrate that the combination of both inherits the generality of data
encoding and decoding of HVC with the fast interpretable nature of Tsetlin
machines to yield a powerful machine learning model. We apply the approach in
two areas, namely in forecasting, generating new sequences, and classification.
For the latter, we derive results for the entire UCR Time Series Archive and
compare with the standard benchmarks to see how well the method competes in
time series classification.",2024-08-29,Christian D. Blakely,http://arxiv.org/pdf/2408.16620v1,cs.LG
Blending Low and High-Level Semantics of Time Series for Better Masked Time Series Generation,"State-of-the-art approaches in time series generation (TSG), such as
TimeVQVAE, utilize vector quantization-based tokenization to effectively model
complex distributions of time series. These approaches first learn to transform
time series into a sequence of discrete latent vectors, and then a prior model
is learned to model the sequence. The discrete latent vectors, however, only
capture low-level semantics (\textit{e.g.,} shapes). We hypothesize that
higher-fidelity time series can be generated by training a prior model on more
informative discrete latent vectors that contain both low and high-level
semantics (\textit{e.g.,} characteristic dynamics). In this paper, we introduce
a novel framework, termed NC-VQVAE, to integrate self-supervised learning into
those TSG methods to derive a discrete latent space where low and high-level
semantics are captured. Our experimental results demonstrate that NC-VQVAE
results in a considerable improvement in the quality of synthetic samples.",2024-08-29,"Johan Vik Mathisen, Erlend Lokna, Daesoo Lee, Erlend Aune",http://arxiv.org/pdf/2408.16613v1,cs.LG
Data Quality Monitoring through Transfer Learning on Anomaly Detection for the Hadron Calorimeters,"The proliferation of sensors brings an immense volume of spatio-temporal (ST)
data in many domains for various purposes, including monitoring, diagnostics,
and prognostics applications. Data curation is a time-consuming process for a
large volume of data, making it challenging and expensive to deploy data
analytics platforms in new environments. Transfer learning (TL) mechanisms
promise to mitigate data sparsity and model complexity by utilizing pre-trained
models for a new task. Despite the triumph of TL in fields like computer vision
and natural language processing, efforts on complex ST models for anomaly
detection (AD) applications are limited. In this study, we present the
potential of TL within the context of AD for the Hadron Calorimeter of the
Compact Muon Solenoid experiment at CERN. We have transferred the ST AD models
trained on data collected from one part of a calorimeter to another. We have
investigated different configurations of TL on semi-supervised autoencoders of
the ST AD models -- transferring convolutional, graph, and recurrent neural
networks of both the encoder and decoder networks. The experiment results
demonstrate that TL effectively enhances the model learning accuracy on a
target subdetector. The TL achieves promising data reconstruction and AD
performance while substantially reducing the trainable parameters of the AD
models. It also improves robustness against anomaly contamination in the
training data sets of the semi-supervised AD models.",2024-08-29,"Mulugeta Weldezgina Asres, Christian Walter Omlin, Long Wang, Pavel Parygin, David Yu, Jay Dittmann, The CMS-HCAL Collaboration",http://arxiv.org/pdf/2408.16612v1,cs.LG
Subspace Representation Learning for Sparse Linear Arrays to Localize More Sources than Sensors: A Deep Learning Methodology,"Localizing more sources than sensors with a sparse linear array (SLA) has
long relied on minimizing a distance between two covariance matrices and recent
algorithms often utilize semidefinite programming (SDP). Although deep neural
network (DNN)-based methods offer new alternatives, they still depend on
covariance matrix fitting. In this paper, we develop a novel methodology that
estimates the co-array subspaces from a sample covariance for SLAs. Our
methodology trains a DNN to learn signal and noise subspace representations
that are invariant to the selection of bases. To learn such representations, we
propose loss functions that gauge the separation between the desired and the
estimated subspace. In particular, we propose losses that measure the length of
the shortest path between subspaces viewed on a union of Grassmannians, and
prove that it is possible for a DNN to approximate signal subspaces. The
computation of learning subspaces of different dimensions is accelerated by a
new batch sampling strategy called consistent rank sampling. The methodology is
robust to array imperfections due to its geometry-agnostic and data-driven
nature. In addition, we propose a fully end-to-end gridless approach that
directly learns angles to study the possibility of bypassing subspace methods.
Numerical results show that learning such subspace representations is more
beneficial than learning covariances or angles. It outperforms conventional
SDP-based methods such as the sparse and parametric approach (SPA) and existing
DNN-based covariance reconstruction methods for a wide range of signal-to-noise
ratios (SNRs), snapshots, and source numbers for both perfect and imperfect
arrays.",2024-08-29,"Kuan-Lin Chen, Bhaskar D. Rao",http://arxiv.org/pdf/2408.16605v2,cs.LG
sEMG-Driven Physics-Informed Gated Recurrent Networks for Modeling Upper Limb Multi-Joint Movement Dynamics,"Exoskeletons and rehabilitation systems have the potential to improve human
strength and recovery by using adaptive human-machine interfaces. Achieving
precise and responsive control in these systems depends on accurately
estimating joint movement dynamics, such as joint angle, velocity,
acceleration, external mass, and torque. While machine learning (ML) approaches
have been employed to predict joint kinematics from surface electromyography
(sEMG) data, traditional ML models often struggle to generalize across dynamic
movements. In contrast, physics-informed neural networks integrate
biomechanical principles, but their effectiveness in predicting full movement
dynamics has not been thoroughly explored. To address this, we introduce the
Physics-informed Gated Recurrent Network (PiGRN), a novel model designed to
predict multi-joint movement dynamics from sEMG data. PiGRN uses a Gated
Recurrent Unit (GRU) to process time-series sEMG inputs, estimate multi-joint
kinematics and external loads, and predict joint torque while incorporating
physics-based constraints during training. Experimental validation, using sEMG
data from five participants performing elbow flexion-extension tasks with 0 kg,
2 kg, and 4 kg loads, showed that PiGRN accurately predicted joint torques for
10 novel movements. RMSE values ranged from 4.02\% to 11.40\%, with correlation
coefficients between 0.87 and 0.98. These results underscore PiGRN's potential
for real-time applications in exoskeletons and rehabilitation. Future work will
focus on expanding datasets, improving musculoskeletal models, and
investigating unsupervised learning approaches.",2024-08-29,"Rajnish Kumar, Anand Gupta, Suriya Prakash Muthukrishnan, Lalan Kumar, Sitikantha Roy",http://arxiv.org/pdf/2408.16599v2,cs.LG
High-Dimensional Sparse Data Low-rank Representation via Accelerated Asynchronous Parallel Stochastic Gradient Descent,"Data characterized by high dimensionality and sparsity are commonly used to
describe real-world node interactions. Low-rank representation (LR) can map
high-dimensional sparse (HDS) data to low-dimensional feature spaces and infer
node interactions via modeling data latent associations. Unfortunately,
existing optimization algorithms for LR models are computationally inefficient
and slowly convergent on large-scale datasets. To address this issue, this
paper proposes an Accelerated Asynchronous Parallel Stochastic Gradient Descent
A2PSGD for High-Dimensional Sparse Data Low-rank Representation with three
fold-ideas: a) establishing a lock-free scheduler to simultaneously respond to
scheduling requests from multiple threads; b) introducing a greedy
algorithm-based load balancing strategy for balancing the computational load
among threads; c) incorporating Nesterov's accelerated gradient into the
learning scheme to accelerate model convergence. Empirical studies show that
A2PSGD outperforms existing optimization algorithms for HDS data LR in both
accuracy and training time.",2024-08-29,"Qicong Hu, Hao Wu",http://arxiv.org/pdf/2408.16592v1,cs.LG
CrisperWhisper: Accurate Timestamps on Verbatim Speech Transcriptions,"We demonstrate that carefully adjusting the tokenizer of the Whisper speech
recognition model significantly improves the precision of word-level timestamps
when applying dynamic time warping to the decoder's cross-attention scores. We
fine-tune the model to produce more verbatim speech transcriptions and employ
several techniques to increase robustness against multiple speakers and
background noise. These adjustments achieve state-of-the-art performance on
benchmarks for verbatim speech transcription, word segmentation, and the timed
detection of filler events, and can further mitigate transcription
hallucinations. The code is available open
https://github.com/nyrahealth/CrisperWhisper.",2024-08-29,"Laurin Wagner, Bernhard Thallinger, Mario Zusag",http://arxiv.org/pdf/2408.16589v1,cs.LG
Transformers Meet ACT-R: Repeat-Aware and Sequential Listening Session Recommendation,"Music streaming services often leverage sequential recommender systems to
predict the best music to showcase to users based on past sequences of
listening sessions. Nonetheless, most sequential recommendation methods ignore
or insufficiently account for repetitive behaviors. This is a crucial
limitation for music recommendation, as repeatedly listening to the same song
over time is a common phenomenon that can even change the way users perceive
this song. In this paper, we introduce PISA (Psychology-Informed Session
embedding using ACT-R), a session-level sequential recommender system that
overcomes this limitation. PISA employs a Transformer architecture learning
embedding representations of listening sessions and users using attention
mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational),
a cognitive architecture modeling human information access and memory dynamics.
This approach enables us to capture dynamic and repetitive patterns from user
behaviors, allowing us to effectively predict the songs they will listen to in
subsequent sessions, whether they are repeated or new ones. We demonstrate the
empirical relevance of PISA using both publicly available listening data from
Last.fm and proprietary data from Deezer, a global music streaming service,
confirming the critical importance of repetition modeling for sequential
listening session recommendation. Along with this paper, we publicly release
our proprietary dataset to foster future research in this field, as well as the
source code of PISA to facilitate its future use.",2024-08-29,"Viet-Anh Tran, Guillaume Salha-Galvan, Bruno Sguerra, Romain Hennequin",http://arxiv.org/pdf/2408.16578v1,cs.LG
Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning,"Probability of necessity and sufficiency (PNS) measures the likelihood of a
feature set being both necessary and sufficient for predicting an outcome. It
has proven effective in guiding representation learning for unimodal data,
enhancing both predictive performance and model robustness. Despite these
benefits, extending PNS to multimodal settings remains unexplored. This
extension presents unique challenges, as the conditions for PNS estimation,
exogeneity and monotonicity, need to be reconsidered in a multimodal context.
We address these challenges by first conceptualizing multimodal representations
as comprising modality-invariant and modality-specific components. We then
analyze how to compute PNS for each component while ensuring non-trivial PNS
estimation. Based on these analyses, we formulate tractable optimization
objectives that enable multimodal models to learn high-PNS representations.
Experiments demonstrate the effectiveness of our method on both synthetic and
real-world data.",2024-08-29,"Boyu Chen, Junjie Liu, Zhu Li, Mengyue Yang",http://arxiv.org/pdf/2408.16577v2,cs.LG
An Adaptive Latent Factorization of Tensors Model for Embedding Dynamic Communication Network,"The Dynamic Communication Network (DCN) describes the interactions over time
among various communication nodes, and it is widely used in Big-data
applications as a data source. As the number of communication nodes increases
and temporal slots accumulate, each node interacts in with only a few nodes in
a given temporal slot, the DCN can be represented by an High-Dimensional Sparse
(HDS) tensor. In order to extract rich behavioral patterns from an HDS tensor
in DCN, this paper proposes an Adaptive Temporal-dependent Tensor low-rank
representation (ATT) model. It adopts a three-fold approach: a) designing a
temporal-dependent method to reconstruct temporal feature matrix, thereby
precisely represent the data by capturing the temporal patterns; b) achieving
hyper-parameters adaptation of the model via the Differential Evolutionary
Algorithms (DEA) to avoid tedious hyper-parameters tuning; c) employing
nonnegative learning schemes for the model parameters to effectively handle an
the nonnegativity inherent in HDS data. The experimental results on four
real-world DCNs demonstrate that the proposed ATT model significantly
outperforms several state-of-the-art models in both prediction errors and
convergence rounds.",2024-08-29,"Xin Liao, Qicong Hu, Peng Tang",http://arxiv.org/pdf/2408.16573v1,cs.LG
Identifying Terrain Physical Parameters from Vision -- Towards Physical-Parameter-Aware Locomotion and Navigation,"Identifying the physical properties of the surrounding environment is
essential for robotic locomotion and navigation to deal with non-geometric
hazards, such as slippery and deformable terrains. It would be of great benefit
for robots to anticipate these extreme physical properties before contact;
however, estimating environmental physical parameters from vision is still an
open challenge. Animals can achieve this by using their prior experience and
knowledge of what they have seen and how it felt. In this work, we propose a
cross-modal self-supervised learning framework for vision-based environmental
physical parameter estimation, which paves the way for future
physical-property-aware locomotion and navigation. We bridge the gap between
existing policies trained in simulation and identification of physical terrain
parameters from vision. We propose to train a physical decoder in simulation to
predict friction and stiffness from multi-modal input. The trained network
allows the labeling of real-world images with physical parameters in a
self-supervised manner to further train a visual network during deployment,
which can densely predict the friction and stiffness from image data. We
validate our physical decoder in simulation and the real world using a
quadruped ANYmal robot, outperforming an existing baseline method. We show that
our visual network can predict the physical properties in indoor and outdoor
experiments while allowing fast adaptation to new environments.",2024-08-29,"Jiaqi Chen, Jonas Frey, Ruyi Zhou, Takahiro Miki, Georg Martius, Marco Hutter",http://arxiv.org/pdf/2408.16567v1,cs.LG
Android Malware Detection Based on RGB Images and Multi-feature Fusion,"With the widespread adoption of smartphones, Android malware has become a
significant challenge in the field of mobile device security. Current Android
malware detection methods often rely on feature engineering to construct
dynamic or static features, which are then used for learning. However, static
feature-based methods struggle to counter code obfuscation, packing, and
signing techniques, while dynamic feature-based methods involve time-consuming
feature extraction. Image-based methods for Android malware detection offer
better resilience against malware variants and polymorphic malware. This paper
proposes an end-to-end Android malware detection technique based on RGB images
and multi-feature fusion. The approach involves extracting Dalvik Executable
(DEX) files, AndroidManifest.xml files, and API calls from APK files,
converting them into grayscale images, and enhancing their texture features
using Canny edge detection, histogram equalization, and adaptive thresholding
techniques. These grayscale images are then combined into an RGB image
containing multi-feature fusion information, which is analyzed using mainstream
image classification models for Android malware detection. Extensive
experiments demonstrate that the proposed method effectively captures Android
malware characteristics, achieving an accuracy of up to 97.25%, outperforming
existing detection methods that rely solely on DEX files as classification
features. Additionally, ablation experiments confirm the effectiveness of using
the three key files for feature representation in the proposed approach.",2024-08-29,"Zhiqiang Wang, Qiulong Yu, Sicheng Yuan",http://arxiv.org/pdf/2408.16555v1,cs.LG
Super-Resolution works for coastal simulations,"Learning fine-scale details of a coastal ocean simulation from a coarse
representation is a challenging task. For real-world applications,
high-resolution simulations are necessary to advance understanding of many
coastal processes, specifically, to predict flooding resulting from tsunamis
and storm surges. We propose a Deep Network for Coastal Super-Resolution
(DNCSR) for spatiotemporal enhancement to efficiently learn the high-resolution
numerical solution. Given images of coastal simulations produced on
low-resolution computational meshes using low polynomial order discontinuous
Galerkin discretizations and a coarse temporal resolution, the proposed DNCSR
learns to produce high-resolution free surface elevation and velocity
visualizations in both time and space. To efficiently model the dynamic changes
over time and space, we propose grid-aware spatiotemporal attention to project
the temporal features to the spatial domain for non-local feature matching. The
coordinate information is also utilized via positional encoding. For the final
reconstruction, we use the spatiotemporal bilinear operation to interpolate the
missing frames and then expand the feature maps to the frequency domain for
residual mapping. Besides data-driven losses, the proposed physics-informed
loss guarantees gradient consistency and momentum changes. Their combination
contributes to the overall 24% improvements in RMSE. To train the proposed
model, we propose a large-scale coastal simulation dataset and use it for model
optimization and evaluation. Our method shows superior super-resolution quality
and fast computation compared to the state-of-the-art methods.",2024-08-29,"Zhi-Song Liu, Markus Buttner, Vadym Aizinger, Andreas Rupp",http://arxiv.org/pdf/2408.16553v1,cs.LG
Statistical and Geometrical properties of regularized Kernel Kullback-Leibler divergence,"In this paper, we study the statistical and geometrical properties of the
Kullback-Leibler divergence with kernel covariance operators (KKL) introduced
by Bach [2022]. Unlike the classical Kullback-Leibler (KL) divergence that
involves density ratios, the KKL compares probability distributions through
covariance operators (embeddings) in a reproducible kernel Hilbert space
(RKHS), and compute the Kullback-Leibler quantum divergence. This novel
divergence hence shares parallel but different aspects with both the standard
Kullback-Leibler between probability distributions and kernel embeddings
metrics such as the maximum mean discrepancy. A limitation faced with the
original KKL divergence is its inability to be defined for distributions with
disjoint supports. To solve this problem, we propose in this paper a
regularised variant that guarantees that the divergence is well defined for all
distributions. We derive bounds that quantify the deviation of the regularised
KKL to the original one, as well as finite-sample bounds. In addition, we
provide a closed-form expression for the regularised KKL, specifically
applicable when the distributions consist of finite sets of points, which makes
it implementable. Furthermore, we derive a Wasserstein gradient descent scheme
of the KKL divergence in the case of discrete distributions, and study
empirically its properties to transport a set of points to a target
distribution.",2024-08-29,"Clémentine Chazal, Anna Korba, Francis Bach",http://arxiv.org/pdf/2408.16543v2,cs.LG
SALSA: Speedy ASR-LLM Synchronous Aggregation,"Harnessing pre-trained LLMs to improve ASR systems, particularly for
low-resource languages, is now an emerging area of research. Existing methods
range from using LLMs for ASR error correction to tightly coupled systems that
replace the ASR decoder with the LLM. These approaches either increase decoding
time or require expensive training of the cross-attention layers. We propose
SALSA, which couples the decoder layers of the ASR to the LLM decoder, while
synchronously advancing both decoders. Such coupling is performed with a simple
projection of the last decoder state, and is thus significantly more training
efficient than earlier approaches. A challenge of our proposed coupling is
handling the mismatch between the tokenizers of the LLM and ASR systems. We
handle this mismatch using cascading tokenization with respect to the LLM and
ASR vocabularies. We evaluate SALSA on 8 low-resource languages in the FLEURS
benchmark, yielding substantial WER reductions of up to 38%.",2024-08-29,"Ashish Mittal, Darshan Prabhu, Sunita Sarawagi, Preethi Jyothi",http://arxiv.org/pdf/2408.16542v1,cs.LG
SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks,"Graph Neural Networks (GNNs) have demonstrated commendable performance for
graph-structured data. Yet, GNNs are often vulnerable to adversarial structural
attacks as embedding generation relies on graph topology. Existing efforts are
dedicated to purifying the maliciously modified structure or applying adaptive
aggregation, thereby enhancing the robustness against adversarial structural
attacks. It is inevitable for a defender to consume heavy computational costs
due to lacking prior knowledge about modified structures. To this end, we
propose an efficient defense method, called Simple and Fast Robust Graph Neural
Network (SFR-GNN), supported by mutual information theory. The SFR-GNN first
pre-trains a GNN model using node attributes and then fine-tunes it over the
modified graph in the manner of contrastive learning, which is free of
purifying modified structures and adaptive aggregation, thus achieving great
efficiency gains. Consequently, SFR-GNN exhibits a 24%--162% speedup compared
to advanced robust models, demonstrating superior robustness for node
classification tasks.",2024-08-29,"Xing Ai, Guanyu Zhu, Yulin Zhu, Yu Zheng, Gaolei Li, Jianhua Li, Kai Zhou",http://arxiv.org/pdf/2408.16537v2,cs.LG
"TinyTNAS: GPU-Free, Time-Bound, Hardware-Aware Neural Architecture Search for TinyML Time Series Classification","In this work, we present TinyTNAS, a novel hardware-aware multi-objective
Neural Architecture Search (NAS) tool specifically designed for TinyML time
series classification. Unlike traditional NAS methods that rely on GPU
capabilities, TinyTNAS operates efficiently on CPUs, making it accessible for a
broader range of applications. Users can define constraints on RAM, FLASH, and
MAC operations to discover optimal neural network architectures within these
parameters. Additionally, the tool allows for time-bound searches, ensuring the
best possible model is found within a user-specified duration. By experimenting
with benchmark dataset UCI HAR, PAMAP2, WISDM, MIT BIH, and PTB Diagnostic ECG
Databas TinyTNAS demonstrates state-of-the-art accuracy with significant
reductions in RAM, FLASH, MAC usage, and latency. For example, on the UCI HAR
dataset, TinyTNAS achieves a 12x reduction in RAM usage, a 144x reduction in
MAC operations, and a 78x reduction in FLASH memory while maintaining superior
accuracy and reducing latency by 149x. Similarly, on the PAMAP2 and WISDM
datasets, it achieves a 6x reduction in RAM usage, a 40x reduction in MAC
operations, an 83x reduction in FLASH, and a 67x reduction in latency, all
while maintaining superior accuracy. Notably, the search process completes
within 10 minutes in a CPU environment. These results highlight TinyTNAS's
capability to optimize neural network architectures effectively for
resource-constrained TinyML applications, ensuring both efficiency and high
performance. The code for TinyTNAS is available at the GitHub repository and
can be accessed at https://github.com/BidyutSaha/TinyTNAS.git.",2024-08-29,"Bidyut Saha, Riya Samanta, Soumya K. Ghosh, Ram Babu Roy",http://arxiv.org/pdf/2408.16535v1,cs.LG
WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling,"Language models have been effectively applied to modeling natural signals,
such as images, video, speech, and audio. A crucial component of these models
is the codec tokenizer, which compresses high-dimensional natural signals into
lower-dimensional discrete tokens. In this paper, we introduce WavTokenizer,
which offers several advantages over previous SOTA acoustic codec models in the
audio domain: 1)extreme compression. By compressing the layers of quantizers
and the temporal dimension of the discrete codec, one-second audio of 24kHz
sampling rate requires only a single quantizer with 40 or 75 tokens. 2)improved
subjective quality. Despite the reduced number of tokens, WavTokenizer achieves
state-of-the-art reconstruction quality with outstanding UTMOS scores and
inherently contains richer semantic information. Specifically, we achieve these
results by designing a broader VQ space, extended contextual windows, and
improved attention networks, as well as introducing a powerful multi-scale
discriminator and an inverse Fourier transform structure. We conducted
extensive reconstruction experiments in the domains of speech, audio, and
music. WavTokenizer exhibited strong performance across various objective and
subjective metrics compared to state-of-the-art models. We also tested semantic
information, VQ utilization, and adaptability to generative models.
Comprehensive ablation studies confirm the necessity of each module in
WavTokenizer. The related code, demos, and pre-trained models are available at
https://github.com/jishengpeng/WavTokenizer.",2024-08-29,"Shengpeng Ji, Ziyue Jiang, Wen Wang, Yifu Chen, Minghui Fang, Jialong Zuo, Qian Yang, Xize Cheng, Zehan Wang, Ruiqi Li, Ziang Zhang, Xiaoda Yang, Rongjie Huang, Yidi Jiang, Qian Chen, Siqi Zheng, Zhou Zhao",http://arxiv.org/pdf/2408.16532v3,cs.LG
Multitask learning for improved scour detection: A dynamic wave tank study,"Population-based structural health monitoring (PBSHM), aims to share
information between members of a population. An offshore wind (OW) farm could
be considered as a population of nominally-identical wind-turbine structures.
However, benign variations exist among members, such as geometry, sea-bed
conditions and temperature differences. These factors could influence
structural properties and therefore the dynamic response, making it more
difficult to detect structural problems via traditional SHM techniques.
  This paper explores the use of a Bayesian hierarchical model as a means of
multitask learning, to infer foundation stiffness distribution parameters at
both population and local levels. To do this, observations of natural frequency
from populations of structures were first generated from both numerical and
experimental models. These observations were then used in a partially-pooled
Bayesian hierarchical model in tandem with surrogate FE models of the
structures to infer foundation stiffness parameters. Finally, it is
demonstrated how the learned parameters may be used as a basis to perform more
robust anomaly detection (as compared to a no-pooling approach) e.g. as a
result of scour.",2024-08-29,"Simon M. Brealy, Aidan J. Hughes, Tina A. Dardeno, Lawrence A. Bull, Robin S. Mills, Nikolaos Dervilis, Keith Worden",http://arxiv.org/pdf/2408.16527v1,cs.LG
Adaptive Variational Continual Learning via Task-Heuristic Modelling,"Variational continual learning (VCL) is a turn-key learning algorithm that
has state-of-the-art performance among the best continual learning models. In
our work, we explore an extension of the generalized variational continual
learning (GVCL) model, named AutoVCL, which combines task heuristics for
informed learning and model optimization. We demonstrate that our model
outperforms the standard GVCL with fixed hyperparameters, benefiting from the
automatic adjustment of the hyperparameter based on the difficulty and
similarity of the incoming task compared to the previous tasks.",2024-08-29,Fan Yang,http://arxiv.org/pdf/2408.16517v1,cs.LG
HLogformer: A Hierarchical Transformer for Representing Log Data,"Transformers have gained widespread acclaim for their versatility in handling
diverse data structures, yet their application to log data remains
underexplored. Log data, characterized by its hierarchical, dictionary-like
structure, poses unique challenges when processed using conventional
transformer models. Traditional methods often rely on manually crafted
templates for parsing logs, a process that is labor-intensive and lacks
generalizability. Additionally, the linear treatment of log sequences by
standard transformers neglects the rich, nested relationships within log
entries, leading to suboptimal representations and excessive memory usage.
  To address these issues, we introduce HLogformer, a novel hierarchical
transformer framework specifically designed for log data. HLogformer leverages
the hierarchical structure of log entries to significantly reduce memory costs
and enhance representation learning. Unlike traditional models that treat log
data as flat sequences, our framework processes log entries in a manner that
respects their inherent hierarchical organization. This approach ensures
comprehensive encoding of both fine-grained details and broader contextual
relationships.
  Our contributions are threefold: First, HLogformer is the first framework to
design a dynamic hierarchical transformer tailored for dictionary-like log
data. Second, it dramatically reduces memory costs associated with processing
extensive log sequences. Third, comprehensive experiments demonstrate that
HLogformer more effectively encodes hierarchical contextual information,
proving to be highly effective for downstream tasks such as synthetic anomaly
detection and product recommendation.",2024-08-29,"Zhichao Hou, Mina Ghashami, Mikhail Kuznetsov, MohamadAli Torkamani",http://arxiv.org/pdf/2408.16803v1,cs.LG
MAPF-GPT: Imitation Learning for Multi-Agent Pathfinding at Scale,"Multi-agent pathfinding (MAPF) is a problem that generally requires finding
collision-free paths for multiple agents in a shared environment. Solving MAPF
optimally, even under restrictive assumptions, is NP-hard, yet efficient
solutions for this problem are critical for numerous applications, such as
automated warehouses and transportation systems. Recently, learning-based
approaches to MAPF have gained attention, particularly those leveraging deep
reinforcement learning. Typically, such learning-based MAPF solvers are
augmented with additional components like single-agent planning or
communication. Orthogonally, in this work we rely solely on imitation learning
that leverages a large dataset of expert MAPF solutions and transformer-based
neural network to create a foundation model for MAPF called MAPF-GPT. The
latter is capable of generating actions without additional heuristics or
communication. MAPF-GPT demonstrates zero-shot learning abilities when solving
the MAPF problems that are not present in the training dataset. We show that
MAPF-GPT notably outperforms the current best-performing learnable MAPF solvers
on a diverse range of problem instances and is computationally efficient during
inference.",2024-08-29,"Anton Andreychuk, Konstantin Yakovlev, Aleksandr Panov, Alexey Skrynnik",http://arxiv.org/pdf/2409.00134v5,cs.LG
On-device AI: Quantization-aware Training of Transformers in Time-Series,"Artificial Intelligence (AI) models for time-series in pervasive computing
keep getting larger and more complicated. The Transformer model is by far the
most compelling of these AI models. However, it is difficult to obtain the
desired performance when deploying such a massive model on a sensor device with
limited resources. My research focuses on optimizing the Transformer model for
time-series forecasting tasks. The optimized model will be deployed as hardware
accelerators on embedded Field Programmable Gate Arrays (FPGAs). I will
investigate the impact of applying Quantization-aware Training to the
Transformer model to reduce its size and runtime memory footprint while
maximizing the advantages of FPGAs.",2024-08-29,"Tianheng Ling, Gregor Schiele",http://arxiv.org/pdf/2408.16495v1,cs.LG
ElasticAI: Creating and Deploying Energy-Efficient Deep Learning Accelerator for Pervasive Computing,"Deploying Deep Learning (DL) on embedded end devices is a scorching trend in
pervasive computing. Since most Microcontrollers on embedded devices have
limited computing power, it is necessary to add a DL accelerator. Embedded
Field Programmable Gate Arrays (FPGAs) are suitable for deploying DL
accelerators for embedded devices, but developing an energy-efficient DL
accelerator on an FPGA is not easy. Therefore, we propose the
ElasticAI-Workflow that aims to help DL developers to create and deploy DL
models as hardware accelerators on embedded FPGAs. This workflow consists of
two key components: the ElasticAI-Creator and the Elastic Node. The former is a
toolchain for automatically generating DL accelerators on FPGAs. The latter is
a hardware platform for verifying the performance of the generated
accelerators. With this combination, the performance of the accelerator can be
sufficiently guaranteed. We will demonstrate the potential of our approach
through a case study.",2024-08-29,"Chao Qian, Tianheng Ling, Gregor Schiele",http://arxiv.org/pdf/2409.09044v1,cs.LG
An Exploratory Deep Learning Approach for Predicting Subsequent Suicidal Acts in Chinese Psychological Support Hotlines,"Psychological support hotlines are an effective suicide prevention measure
that typically relies on professionals using suicide risk assessment scales to
predict individual risk scores. However, the accuracy of scale-based predictive
methods for suicide risk assessment can vary widely depending on the expertise
of the operator. This limitation underscores the need for more reliable
methods, prompting this research's innovative exploration of the use of
artificial intelligence to improve the accuracy and efficiency of suicide risk
prediction within the context of psychological support hotlines. The study
included data from 1,549 subjects from 2015-2017 in China who contacted a
psychological support hotline. Each participant was followed for 12 months to
identify instances of suicidal behavior. We proposed a novel multi-task
learning method that uses the large-scale pre-trained model Whisper for feature
extraction and fits psychological scales while predicting the risk of suicide.
The proposed method yields a 2.4\% points improvement in F1-score compared to
the traditional manual approach based on the psychological scales. Our model
demonstrated superior performance compared to the other eight popular models.
To our knowledge, this study is the first to apply deep learning to long-term
speech data to predict suicide risk in China, indicating grate potential for
clinical applications. The source code is publicly available at:
\url{https://github.com/songchangwei/Suicide-Risk-Prediction}.",2024-08-29,"Changwei Song, Qing Zhao, Jianqiang Li, Yining Chen, Yongsheng Tong, Guanghui Fu",http://arxiv.org/pdf/2408.16463v1,cs.LG
HYGENE: A Diffusion-based Hypergraph Generation Method,"Hypergraphs are powerful mathematical structures that can model complex,
high-order relationships in various domains, including social networks,
bioinformatics, and recommender systems. However, generating realistic and
diverse hypergraphs remains challenging due to their inherent complexity and
lack of effective generative models. In this paper, we introduce a
diffusion-based Hypergraph Generation (HYGENE) method that addresses these
challenges through a progressive local expansion approach. HYGENE works on the
bipartite representation of hypergraphs, starting with a single pair of
connected nodes and iteratively expanding it to form the target hypergraph. At
each step, nodes and hyperedges are added in a localized manner using a
denoising diffusion process, which allows for the construction of the global
structure before refining local details. Our experiments demonstrated the
effectiveness of HYGENE, proving its ability to closely mimic a variety of
properties in hypergraphs. To the best of our knowledge, this is the first
attempt to employ deep learning models for hypergraph generation, and our work
aims to lay the groundwork for future research in this area.",2024-08-29,"Dorian Gailhard, Enzo Tartaglione, Lirida Naviner, Jhony H. Giraldo",http://arxiv.org/pdf/2408.16457v3,cs.LG
CNN Based Detection of Cardiovascular Diseases from ECG Images,"This study develops a Convolutional Neural Network (CNN) model for detecting
myocardial infarction (MI) from Electrocardiogram (ECG) images. The model,
built using the InceptionV3 architecture and optimized through transfer
learning, was trained using ECG data obtained from the Ch. Pervaiz Elahi
Institute of Cardiology in Pakistan. The dataset includes ECG images
representing four different cardiac conditions: myocardial infarction, abnormal
heartbeat, history of myocardial infarction, and normal heart activity. The
developed model successfully detects MI and other cardiovascular conditions
with an accuracy of 93.27%. This study demonstrates that deep learning-based
models can provide significant support to clinicians in the early detection and
prevention of heart attacks.",2024-08-29,"Irem Sayin, Rana Gursoy, Buse Cicek, Yunus Emre Mert, Fatih Ozturk, Taha Emre Pamukcu, Ceylin Deniz Sevimli, Huseyin Uvet",http://arxiv.org/pdf/2408.16800v1,cs.LG
Do Recommender Systems Promote Local Music? A Reproducibility Study Using Music Streaming Data,"This paper examines the influence of recommender systems on local music
representation, discussing prior findings from an empirical study on the LFM-2b
public dataset. This prior study argued that different recommender systems
exhibit algorithmic biases shifting music consumption either towards or against
local content. However, LFM-2b users do not reflect the diverse audience of
music streaming services. To assess the robustness of this study's conclusions,
we conduct a comparative analysis using proprietary listening data from a
global music streaming service, which we publicly release alongside this paper.
We observe significant differences in local music consumption patterns between
our dataset and LFM-2b, suggesting that caution should be exercised when
drawing conclusions on local music based solely on LFM-2b. Moreover, we show
that the algorithmic biases exhibited in the original work vary in our dataset,
and that several unexplored model parameters can significantly influence these
biases and affect the study's conclusion on both datasets. Finally, we discuss
the complexity of accurately labeling local music, emphasizing the risk of
misleading conclusions due to unreliable, biased, or incomplete labels. To
encourage further research and ensure reproducibility, we have publicly shared
our dataset and code.",2024-08-29,"Kristina Matrosova, Lilian Marey, Guillaume Salha-Galvan, Thomas Louail, Olivier Bodini, Manuel Moussallam",http://arxiv.org/pdf/2408.16430v1,cs.LG
Gradient-free variational learning with conditional mixture networks,"Balancing computational efficiency with robust predictive performance is
crucial in supervised learning, especially for critical applications. Standard
deep learning models, while accurate and scalable, often lack probabilistic
features like calibrated predictions and uncertainty quantification. Bayesian
methods address these issues but can be computationally expensive as model and
data complexity increase. Previous work shows that fast variational methods can
reduce the compute requirements of Bayesian methods by eliminating the need for
gradient computation or sampling, but are often limited to simple models. We
introduce CAVI-CMN, a fast, gradient-free variational method for training
conditional mixture networks (CMNs), a probabilistic variant of the
mixture-of-experts (MoE) model. CMNs are composed of linear experts and a
softmax gating network. By exploiting conditional conjugacy and P\'olya-Gamma
augmentation, we furnish Gaussian likelihoods for the weights of both the
linear layers and the gating network. This enables efficient variational
updates using coordinate ascent variational inference (CAVI), avoiding
traditional gradient-based optimization. We validate this approach by training
two-layer CMNs on standard classification benchmarks from the UCI repository.
CAVI-CMN achieves competitive and often superior predictive accuracy compared
to maximum likelihood estimation (MLE) with backpropagation, while maintaining
competitive runtime and full posterior distributions over all model parameters.
Moreover, as input size or the number of experts increases, computation time
scales competitively with MLE and other gradient-based solutions like black-box
variational inference (BBVI), making CAVI-CMN a promising tool for deep, fast,
and gradient-free Bayesian networks.",2024-08-29,"Conor Heins, Hao Wu, Dimitrije Markovic, Alexander Tschantz, Jeff Beck, Christopher Buckley",http://arxiv.org/pdf/2408.16429v2,cs.LG
A Comparative Study of Hyperparameter Tuning Methods,"The study emphasizes the challenge of finding the optimal trade-off between
bias and variance, especially as hyperparameter optimization increases in
complexity. Through empirical analysis, three hyperparameter tuning algorithms
Tree-structured Parzen Estimator (TPE), Genetic Search, and Random Search are
evaluated across regression and classification tasks. The results show that
nonlinear models, with properly tuned hyperparameters, significantly outperform
linear models. Interestingly, Random Search excelled in regression tasks, while
TPE was more effective for classification tasks. This suggests that there is no
one-size-fits-all solution, as different algorithms perform better depending on
the task and model type. The findings underscore the importance of selecting
the appropriate tuning method and highlight the computational challenges
involved in optimizing machine learning models, particularly as search spaces
expand.",2024-08-29,"Subhasis Dasgupta, Jaydip Sen",http://arxiv.org/pdf/2408.16425v1,cs.LG
Spectral Informed Neural Network: An Efficient and Low-Memory PINN,"With growing investigations into solving partial differential equations by
physics-informed neural networks (PINNs), more accurate and efficient PINNs are
required to meet the practical demands of scientific computing. One bottleneck
of current PINNs is computing the high-order derivatives via automatic
differentiation which often necessitates substantial computing resources. In
this paper, we focus on removing the automatic differentiation of the spatial
derivatives and propose a spectral-based neural network that substitutes the
differential operator with a multiplication. Compared to the PINNs, our
approach requires lower memory and shorter training time. Thanks to the
exponential convergence of the spectral basis, our approach is more accurate.
Moreover, to handle the different situations between physics domain and
spectral domain, we provide two strategies to train networks by their spectral
information. Through a series of comprehensive experiments, We validate the
aforementioned merits of our proposed network.",2024-08-29,"Tianchi Yu, Yiming Qi, Ivan Oseledets, Shiyi Chen",http://arxiv.org/pdf/2408.16414v2,cs.LG
DeepSPoC: A Deep Learning-Based PDE Solver Governed by Sequential Propagation of Chaos,"Sequential propagation of chaos (SPoC) is a recently developed tool to solve
mean-field stochastic differential equations and their related nonlinear
Fokker-Planck equations. Based on the theory of SPoC, we present a new method
(deepSPoC) that combines the interacting particle system of SPoC and deep
learning. Under the framework of deepSPoC, two classes of frequently used deep
models include fully connected neural networks and normalizing flows are
considered. For high-dimensional problems, spatial adaptive method are designed
to further improve the accuracy and efficiency of deepSPoC. We analysis the
convergence of the framework of deepSPoC under some simplified conditions and
also provide a posterior error estimation for the algorithm. Finally, we test
our methods on a wide range of different types of mean-field equations.",2024-08-29,"Kai Du, Yongle Xie, Tao Zhou, Yuancheng Zhou",http://arxiv.org/pdf/2408.16403v1,cs.LG
Illuminating the Diversity-Fitness Trade-Off in Black-Box Optimization,"In real-world applications, users often favor structurally diverse design
choices over one high-quality solution. It is hence important to consider more
solutions that decision makers can compare and further explore based on
additional criteria. Alongside the existing approaches of evolutionary
diversity optimization, quality diversity, and multimodal optimization, this
paper presents a fresh perspective on this challenge by considering the problem
of identifying a fixed number of solutions with a pairwise distance above a
specified threshold while maximizing their average quality.
  We obtain first insight into these objectives by performing a subset
selection on the search trajectories of different well-established search
heuristics, whether they have been specifically designed with diversity in mind
or not. We emphasize that the main goal of our work is not to present a new
algorithm but to understand the capability of off-the-shelf algorithms to
quantify the trade-off between the minimum pairwise distance within batches of
solutions and their average quality. We also analyze how this trade-off depends
on the properties of the underlying optimization problem.
  A possibly surprising outcome of our empirical study is the observation that
naive uniform random sampling establishes a very strong baseline for our
problem, hardly ever outperformed by the search trajectories of the considered
heuristics. We interpret these results as a motivation to develop algorithms
tailored to produce diverse solutions of high average quality.",2024-08-29,"Maria Laura Santoni, Elena Raponi, Aneta Neumann, Frank Neumann, Mike Preuss, Carola Doerr",http://arxiv.org/pdf/2408.16393v2,cs.LG
TempoKGAT: A Novel Graph Attention Network Approach for Temporal Graph Analysis,"Graph neural networks (GNN) have shown significant capabilities in handling
structured data, yet their application to dynamic, temporal data remains
limited. This paper presents a new type of graph attention network, called
TempoKGAT, which combines time-decaying weight and a selective neighbor
aggregation mechanism on the spatial domain, which helps uncover latent
patterns in the graph data. In this approach, a top-k neighbor selection based
on the edge weights is introduced to represent the evolving features of the
graph data. We evaluated the performance of our TempoKGAT on multiple datasets
from the traffic, energy, and health sectors involving spatio-temporal data. We
compared the performance of our approach to several state-of-the-art methods
found in the literature on several open-source datasets. Our method shows
superior accuracy on all datasets. These results indicate that TempoKGAT builds
on existing methodologies to optimize prediction accuracy and provide new
insights into model interpretation in temporal contexts.",2024-08-29,"Lena Sasal, Daniel Busby, Abdenour Hadid",http://arxiv.org/pdf/2408.16391v2,cs.LG
Addressing common misinterpretations of KART and UAT in neural network literature,"This note addresses the Kolmogorov-Arnold Representation Theorem (KART) and
the Universal Approximation Theorem (UAT), focusing on their common and
frequent misinterpretations in many papers related to neural network
approximation. Our remarks aim to support a more accurate understanding of KART
and UAT among neural network specialists. In addition, we explore the minimal
number of neurons required for universal approximation, showing that KART's
lower bounds extend to standard multilayer perceptrons, even with smooth
activation functions.",2024-08-29,Vugar Ismailov,http://arxiv.org/pdf/2408.16389v4,cs.LG
TG-PhyNN: An Enhanced Physically-Aware Graph Neural Network framework for forecasting Spatio-Temporal Data,"Accurately forecasting dynamic processes on graphs, such as traffic flow or
disease spread, remains a challenge. While Graph Neural Networks (GNNs) excel
at modeling and forecasting spatio-temporal data, they often lack the ability
to directly incorporate underlying physical laws. This work presents TG-PhyNN,
a novel Temporal Graph Physics-Informed Neural Network framework. TG-PhyNN
leverages the power of GNNs for graph-based modeling while simultaneously
incorporating physical constraints as a guiding principle during training. This
is achieved through a two-step prediction strategy that enables the calculation
of physical equation derivatives within the GNN architecture. Our findings
demonstrate that TG-PhyNN significantly outperforms traditional forecasting
models (e.g., GRU, LSTM, GAT) on real-world spatio-temporal datasets like
PedalMe (traffic flow), COVID-19 spread, and Chickenpox outbreaks. These
datasets are all governed by well-defined physical principles, which TG-PhyNN
effectively exploits to offer more reliable and accurate forecasts in various
domains where physical processes govern the dynamics of data. This paves the
way for improved forecasting in areas like traffic flow prediction, disease
outbreak prediction, and potentially other fields where physics plays a crucial
role.",2024-08-29,"Zakaria Elabid, Lena Sasal, Daniel Busby, Abdenour Hadid",http://arxiv.org/pdf/2408.16379v1,cs.LG
Generative AI in Ship Design,"The process of ship design is intricate, heavily influenced by the hull form
which accounts for approximately 70% of the total cost. Traditional methods
rely on human-driven iterative processes based on naval architecture principles
and engineering analysis. In contrast, generative AI presents a novel approach,
utilizing computational algorithms rooted in machine learning and artificial
intelligence to optimize ship hull design. This report outlines the systematic
creation of a generative AI for this purpose, involving steps such as dataset
collection, model architecture selection, training, and validation. Utilizing
the ""SHIP-D"" dataset, consisting of 30,000 hull forms, the report adopts the
Gaussian Mixture Model (GMM) as the generative model architecture. GMMs offer a
statistical framework to analyze data distribution, crucial for generating
innovative ship designs efficiently. Overall, this approach holds promise in
revolutionizing ship design by exploring a broader design space and integrating
multidisciplinary optimization objectives effectively.",2024-08-29,"Sahil Thakur, Navneet V Saxena, Prof Sitikantha Roy",http://arxiv.org/pdf/2408.16798v1,cs.LG
Machine learning models for daily rainfall forecasting in Northern Tropical Africa using tropical wave predictors,"Numerical weather prediction (NWP) models often underperform compared to
simpler climatology-based precipitation forecasts in northern tropical Africa,
even after statistical postprocessing. AI-based forecasting models show promise
but have avoided precipitation due to its complexity. Synoptic-scale forcings
like African easterly waves and other tropical waves (TWs) are important for
predictability in tropical Africa, yet their value for predicting daily
rainfall remains unexplored. This study uses two machine-learning models--gamma
regression and a convolutional neural network (CNN)--trained on TW predictors
from satellite-based GPM IMERG data to predict daily rainfall during the
July-September monsoon season. Predictor variables are derived from the local
amplitude and phase information of seven TW from the target and
up-and-downstream neighboring grids at 1-degree spatial resolution. The ML
models are combined with Easy Uncertainty Quantification (EasyUQ) to generate
calibrated probabilistic forecasts and are compared with three benchmarks:
Extended Probabilistic Climatology (EPC15), ECMWF operational ensemble forecast
(ENS), and a probabilistic forecast from the ENS control member using EasyUQ
(CTRL EasyUQ). The study finds that downstream predictor variables offer the
highest predictability, with downstream tropical depression (TD)-type
wave-based predictors being most important. Other waves like mixed-Rossby
gravity (MRG), Kelvin, and inertio-gravity waves also contribute significantly
but show regional preferences. ENS forecasts exhibit poor skill due to
miscalibration. CTRL EasyUQ shows improvement over ENS and marginal enhancement
over EPC15. Both gamma regression and CNN forecasts significantly outperform
benchmarks in tropical Africa. This study highlights the potential of ML models
trained on TW-based predictors to improve daily precipitation forecasts in
tropical Africa.",2024-08-29,"Athul Rasheeda Satheesh, Peter Knippertz, Andreas H. Fink",http://arxiv.org/pdf/2408.16349v1,cs.LG
Do Graph Neural Networks Work for High Entropy Alloys?,"Graph neural networks (GNNs) have excelled in predictive modeling for both
crystals and molecules, owing to the expressiveness of graph representations.
High-entropy alloys (HEAs), however, lack chemical long-range order, limiting
the applicability of current graph representations. To overcome this challenge,
we propose a representation of HEAs as a collection of local environment (LE)
graphs. Based on this representation, we introduce the LESets machine learning
model, an accurate, interpretable GNN for HEA property prediction. We
demonstrate the accuracy of LESets in modeling the mechanical properties of
quaternary HEAs. Through analyses and interpretation, we further extract
insights into the modeling and design of HEAs. In a broader sense, LESets
extends the potential applicability of GNNs to disordered materials with
combinatorial complexity formed by diverse constituents and their flexible
configurations.",2024-08-29,"Hengrui Zhang, Ruishu Huang, Jie Chen, James M. Rondinelli, Wei Chen",http://arxiv.org/pdf/2408.16337v1,cs.LG
GL-TSVM: A robust and smooth twin support vector machine with guardian loss function,"Twin support vector machine (TSVM), a variant of support vector machine
(SVM), has garnered significant attention due to its $3/4$ times lower
computational complexity compared to SVM. However, due to the utilization of
the hinge loss function, TSVM is sensitive to outliers or noise. To remedy it,
we introduce the guardian loss (G-loss), a novel loss function distinguished by
its asymmetric, bounded, and smooth characteristics. We then fuse the proposed
G-loss function into the TSVM and yield a robust and smooth classifier termed
GL-TSVM. Further, to adhere to the structural risk minimization (SRM) principle
and reduce overfitting, we incorporate a regularization term into the objective
function of GL-TSVM. To address the optimization challenges of GL-TSVM, we
devise an efficient iterative algorithm. The experimental analysis on UCI and
KEEL datasets substantiates the effectiveness of the proposed GL-TSVM in
comparison to the baseline models. Moreover, to showcase the efficacy of the
proposed GL-TSVM in the biomedical domain, we evaluated it on the breast cancer
(BreaKHis) and schizophrenia datasets. The outcomes strongly demonstrate the
competitiveness of the proposed GL-TSVM against the baseline models.",2024-08-29,"Mushir Akhtar, M. Tanveer, Mohd. Arshad",http://arxiv.org/pdf/2408.16336v1,cs.LG
Self-Improving Diffusion Models with Synthetic Data,"The artificial intelligence (AI) world is running out of real data for
training increasingly large generative models, resulting in accelerating
pressure to train on synthetic data. Unfortunately, training new generative
models with synthetic data from current or past generation models creates an
autophagous (self-consuming) loop that degrades the quality and/or diversity of
the synthetic data in what has been termed model autophagy disorder (MAD) and
model collapse. Current thinking around model autophagy recommends that
synthetic data is to be avoided for model training lest the system deteriorate
into MADness. In this paper, we take a different tack that treats synthetic
data differently from real data. Self-IMproving diffusion models with Synthetic
data (SIMS) is a new training concept for diffusion models that uses
self-synthesized data to provide negative guidance during the generation
process to steer a model's generative process away from the non-ideal synthetic
data manifold and towards the real data distribution. We demonstrate that SIMS
is capable of self-improvement; it establishes new records based on the
Fr\'echet inception distance (FID) metric for CIFAR-10 and ImageNet-64
generation and achieves competitive results on FFHQ-64 and ImageNet-512.
Moreover, SIMS is, to the best of our knowledge, the first prophylactic
generative AI algorithm that can be iteratively trained on self-generated
synthetic data without going MAD. As a bonus, SIMS can adjust a diffusion
model's synthetic data distribution to match any desired in-domain target
distribution to help mitigate biases and ensure fairness.",2024-08-29,"Sina Alemohammad, Ahmed Imtiaz Humayun, Shruti Agarwal, John Collomosse, Richard Baraniuk",http://arxiv.org/pdf/2408.16333v1,cs.LG
Minimising changes to audit when updating decision trees,"Interpretable models are important, but what happens when the model is
updated on new training data? We propose an algorithm for updating a decision
tree while minimising the number of changes to the tree that a human would need
to audit. We achieve this via a greedy approach that incorporates the number of
changes to the tree as part of the objective function. We compare our algorithm
to existing methods and show that it sits in a sweet spot between final
accuracy and number of changes to audit.",2024-08-29,"Anj Simmons, Scott Barnett, Anupam Chaudhuri, Sankhya Singh, Shangeetha Sivasothy",http://arxiv.org/pdf/2408.16321v1,cs.LG
Passenger hazard perception based on EEG signals for highly automated driving vehicles,"Enhancing the safety of autonomous vehicles is crucial, especially given
recent accidents involving automated systems. As passengers in these vehicles,
humans' sensory perception and decision-making can be integrated with
autonomous systems to improve safety. This study explores neural mechanisms in
passenger-vehicle interactions, leading to the development of a Passenger
Cognitive Model (PCM) and the Passenger EEG Decoding Strategy (PEDS). Central
to PEDS is a novel Convolutional Recurrent Neural Network (CRNN) that captures
spatial and temporal EEG data patterns. The CRNN, combined with stacking
algorithms, achieves an accuracy of $85.0\% \pm 3.18\%$. Our findings highlight
the predictive power of pre-event EEG data, enhancing the detection of
hazardous scenarios and offering a network-driven framework for safer
autonomous vehicles.",2024-08-29,"Ashton Yu Xuan Tan, Yingkai Yang, Xiaofei Zhang, Bowen Li, Xiaorong Gao, Sifa Zheng, Jianqiang Wang, Xinyu Gu, Jun Li, Yang Zhao, Yuxin Zhang, Tania Stathaki",http://arxiv.org/pdf/2408.16315v2,cs.LG
Reconsidering the energy efficiency of spiking neural networks,"Spiking neural networks (SNNs) are generally regarded as more
energy-efficient because they do not use multiplications. However, most SNN
works only consider the counting of additions to evaluate energy consumption,
neglecting other overheads such as memory accesses and data movement
operations. This oversight can lead to a misleading perception of efficiency,
especially when state-of-the-art SNN accelerators operate with very small time
window sizes. In this paper, we present a detailed comparison of the energy
consumption of artificial neural networks (ANNs) and SNNs from a hardware
perspective. We provide accurate formulas for energy consumption based on
classical multi-level memory hierarchy architectures, commonly used
neuromorphic dataflow architectures, and our proposed improved spatial-dataflow
architecture. Our research demonstrates that to achieve comparable accuracy and
greater energy efficiency than ANNs, SNNs require strict limitations on both
time window size T and sparsity s. For instance, with the VGG16 model and a
fixed T of 6, the neuron sparsity rate must exceed 93% to ensure energy
efficiency across most architectures. Inspired by our findings, we explore
strategies to enhance energy efficiency by increasing sparsity. We introduce
two regularization terms during training that constrain weights and
activations, effectively boosting the sparsity rate. Our experiments on the
CIFAR-10 dataset, using T of 6, show that our SNNs consume 69% of the energy
used by optimized ANNs on spatial-dataflow architectures, while maintaining an
SNN accuracy of 94.18%. This framework, developed using PyTorch, is publicly
available for use and further research.",2024-08-29,"Zhanglu Yan, Zhenyu Bai, Weng-Fai Wong",http://arxiv.org/pdf/2409.08290v1,cs.LG
"Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems","Language models have demonstrated remarkable performance in solving reasoning
tasks; however, even the strongest models still occasionally make reasoning
mistakes. Recently, there has been active research aimed at improving reasoning
accuracy, particularly by using pretrained language models to ""self-correct""
their mistakes via multi-round prompting. In this paper, we follow this line of
work but focus on understanding the usefulness of incorporating
""error-correction"" data directly into the pretraining stage. This data consists
of erroneous solution steps immediately followed by their corrections. Using a
synthetic math dataset, we show promising results: this type of pretrain data
can help language models achieve higher reasoning accuracy directly (i.e.,
through simple auto-regression, without multi-round prompting) compared to
pretraining on the same amount of error-free data. We also delve into many
details, such as (1) how this approach differs from beam search, (2) how such
data can be prepared, (3) whether masking is needed on the erroneous tokens,
(4) the amount of error required, (5) whether such data can be deferred to the
fine-tuning stage, and many others.",2024-08-29,"Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu",http://arxiv.org/pdf/2408.16293v1,cs.LG
Flexible framework for generating synthetic electrocardiograms and photoplethysmograms,"By generating synthetic biosignals, the quantity and variety of health data
can be increased. This is especially useful when training machine learning
models by enabling data augmentation and introduction of more physiologically
plausible variation to the data. For these purposes, we have developed a
synthetic biosignal model for two signal modalities, electrocardiography (ECG)
and photoplethysmography (PPG). The model produces realistic signals that
account for physiological effects such as breathing modulation and changes in
heart rate due to physical stress. Arrhythmic signals can be generated with
beat intervals extracted from real measurements. The model also includes a
flexible approach to adding different kinds of noise and signal artifacts. The
noise is generated from power spectral densities extracted from both measured
noisy signals and modeled power spectra. Importantly, the model also
automatically produces labels for noise, segmentation (e.g. P and T waves, QRS
complex, for electrocardiograms), and artifacts. We assessed how this
comprehensive model can be used in practice to improve the performance of
models trained on ECG or PPG data. For example, we trained an LSTM to detect
ECG R-peaks using both real ECG signals from the MIT-BIH arrythmia set and our
new generator. The F1 score of the model was 0.83 using real data, in
comparison to 0.98 using our generator. In addition, the model can be used for
example in signal segmentation, quality detection and bench-marking detection
algorithms. The model code has been released in
\url{https://github.com/UTU-Health-Research/framework_for_synthetic_biosignals}",2024-08-29,"Katri Karhinoja, Antti Vasankari, Jukka-Pekka Sirkiä, Antti Airola, David Wong, Matti Kaisti",http://arxiv.org/pdf/2408.16291v1,cs.LG
OpenFGL: A Comprehensive Benchmark for Federated Graph Learning,"Federated graph learning (FGL) is a promising distributed training paradigm
for graph neural networks across multiple local systems without direct data
sharing. This approach inherently involves large-scale distributed graph
processing, which closely aligns with the challenges and research focuses of
graph-based data systems. Despite the proliferation of FGL, the diverse
motivations from real-world applications, spanning various research backgrounds
and settings, pose a significant challenge to fair evaluation. To fill this
gap, we propose OpenFGL, a unified benchmark designed for the primary FGL
scenarios: Graph-FL and Subgraph-FL. Specifically, OpenFGL includes 42 graph
datasets from 18 application domains, 8 federated data simulation strategies
that emphasize different graph properties, and 5 graph-based downstream tasks.
Additionally, it offers 18 recently proposed SOTA FGL algorithms through a
user-friendly API, enabling a thorough comparison and comprehensive evaluation
of their effectiveness, robustness, and efficiency. Our empirical results
demonstrate the capabilities of FGL while also highlighting its potential
limitations, providing valuable insights for future research in this growing
field, particularly in fostering greater interdisciplinary collaboration
between FGL and data systems.",2024-08-29,"Xunkai Li, Yinlin Zhu, Boyang Pang, Guochen Yan, Yeyu Yan, Zening Li, Zhengyu Wu, Wentao Zhang, Rong-Hua Li, Guoren Wang",http://arxiv.org/pdf/2408.16288v2,cs.LG
Mirror contrastive loss based sliding window transformer for subject-independent motor imagery based EEG signal recognition,"While deep learning models have been extensively utilized in motor imagery
based EEG signal recognition, they often operate as black boxes. Motivated by
neurological findings indicating that the mental imagery of left or right-hand
movement induces event-related desynchronization (ERD) in the contralateral
sensorimotor area of the brain, we propose a Mirror Contrastive Loss based
Sliding Window Transformer (MCL-SWT) to enhance subject-independent motor
imagery-based EEG signal recognition. Specifically, our proposed mirror
contrastive loss enhances sensitivity to the spatial location of ERD by
contrasting the original EEG signals with their mirror counterparts-mirror EEG
signals generated by interchanging the channels of the left and right
hemispheres of the EEG signals. Moreover, we introduce a temporal sliding
window transformer that computes self-attention scores from high temporal
resolution features, thereby improving model performance with manageable
computational complexity. We evaluate the performance of MCL-SWT on
subject-independent motor imagery EEG signal recognition tasks, and our
experimental results demonstrate that MCL-SWT achieved accuracies of 66.48% and
75.62%, surpassing the state-of-the-art (SOTA) model by 2.82% and 2.17%,
respectively. Furthermore, ablation experiments confirm the effectiveness of
the proposed mirror contrastive loss. A code demo of MCL-SWT is available at
https://github.com/roniusLuo/MCL_SWT.",2024-08-29,"Jing Luo, Qi Mao, Weiwei Shi, Zhenghao Shi, Xiaofan Wang, Xiaofeng Lu, Xinhong Hei",http://arxiv.org/pdf/2409.00130v1,cs.LG
Near-Optimal Policy Identification in Robust Constrained Markov Decision Processes via Epigraph Form,"Designing a safe policy for uncertain environments is crucial in real-world
control systems. However, this challenge remains inadequately addressed within
the Markov decision process (MDP) framework. This paper presents the first
algorithm guaranteed to identify a near-optimal policy in a robust constrained
MDP (RCMDP), where an optimal policy minimizes cumulative cost while satisfying
constraints in the worst-case scenario across a set of environments. We first
prove that the conventional policy gradient approach to the Lagrangian max-min
formulation can become trapped in suboptimal solutions. This occurs when its
inner minimization encounters a sum of conflicting gradients from the objective
and constraint functions. To address this, we leverage the epigraph form of the
RCMDP problem, which resolves the conflict by selecting a single gradient from
either the objective or the constraints. Building on the epigraph form, we
propose a bisection search algorithm with a policy gradient subroutine and
prove that it identifies an $\varepsilon$-optimal policy in an RCMDP with
$\tilde{\mathcal{O}}(\varepsilon^{-4})$ robust policy evaluations.",2024-08-29,"Toshinori Kitamura, Tadashi Kozuno, Wataru Kumagai, Kenta Hoshino, Yohei Hosoe, Kazumi Kasaura, Masashi Hamaya, Paavo Parmas, Yutaka Matsuo",http://arxiv.org/pdf/2408.16286v4,cs.LG
ART: Actually Robust Training,"Current interest in deep learning captures the attention of many programmers
and researchers. Unfortunately, the lack of a unified schema for developing
deep learning models results in methodological inconsistencies, unclear
documentation, and problems with reproducibility. Some guidelines have been
proposed, yet currently, they lack practical implementations. Furthermore,
neural network training often takes on the form of trial and error, lacking a
structured and thoughtful process. To alleviate these issues, in this paper, we
introduce Art, a Python library designed to help automatically impose rules and
standards while developing deep learning pipelines. Art divides model
development into a series of smaller steps of increasing complexity, each
concluded with a validation check improving the interpretability and robustness
of the process. The current version of Art comes equipped with nine predefined
steps inspired by Andrej Karpathy's Recipe for Training Neural Networks, a
visualization dashboard, and integration with loggers such as Neptune. The code
related to this paper is available at:
https://github.com/SebChw/Actually-Robust-Training.",2024-08-29,"Sebastian Chwilczyński, Kacper Trębacz, Karol Cyganik, Mateusz Małecki, Dariusz Brzezinski",http://arxiv.org/pdf/2408.16285v2,cs.LG
Enhancing Customer Churn Prediction in Telecommunications: An Adaptive Ensemble Learning Approach,"Customer churn, the discontinuation of services by existing customers, poses
a significant challenge to the telecommunications industry. This paper proposes
a novel adaptive ensemble learning framework for highly accurate customer churn
prediction. The framework integrates multiple base models, including XGBoost,
LightGBM, LSTM, a Multi-Layer Perceptron (MLP) neural network, and Support
Vector Machine (SVM). These models are strategically combined using a stacking
ensemble method, further enhanced by meta-feature generation from base model
predictions. A rigorous data preprocessing pipeline, coupled with a
multi-faceted feature engineering approach, optimizes model performance. The
framework is evaluated on three publicly available telecom churn datasets,
demonstrating substantial accuracy improvements over state-of-the-art
techniques. The research achieves a remarkable 99.28% accuracy, signifying a
major advancement in churn prediction.The implications of this research for
developing proactive customer retention strategies withinthe telecommunications
industry are discussed.",2024-08-29,"Mohammed Affan Shaikhsurab, Pramod Magadum",http://arxiv.org/pdf/2408.16284v1,cs.LG
Web Service QoS Prediction via Extended Canonical Polyadic-based Tensor Network,"Today, numerous web services with similar functionalities are available on
the Internet. Users often evaluate the Quality of Service (QoS) to choose the
best option among them. Predicting the QoS values of these web services is a
significant challenge in the field of web services. A Canonical Polyadic
(CP)-based tensor network model has proven to be efficient for predicting
dynamic QoS data. However, current CP-based tensor network models do not
consider the correlation of users and services in the low-dimensional latent
feature space, thereby limiting model's prediction capability. To tackle this
issue, this paper proposes an Extended Canonical polyadic-based Tensor Network
(ECTN) model. It models the correlation of users and services via building a
relation dimension between user feature and service feature in low-dimensional
space, and then designs an extended CP decomposition structure to improve
prediction accuracy. Experiments are conducted on two public dynamic QoS data,
and the results show that compared with state-of-the-art QoS prediction models,
the ECTN obtains higher prediction accuracy.",2024-08-29,"Qu Wang, Hao Wu",http://arxiv.org/pdf/2408.16278v1,cs.LG
On Convergence of Average-Reward Q-Learning in Weakly Communicating Markov Decision Processes,"This paper analyzes reinforcement learning (RL) algorithms for Markov
decision processes (MDPs) under the average-reward criterion. We focus on
Q-learning algorithms based on relative value iteration (RVI), which are
model-free stochastic analogues of the classical RVI method for average-reward
MDPs. These algorithms have low per-iteration complexity, making them
well-suited for large state space problems. We extend the almost-sure
convergence analysis of RVI Q-learning algorithms developed by Abounadi,
Bertsekas, and Borkar (2001) from unichain to weakly communicating MDPs. This
extension is important both practically and theoretically: weakly communicating
MDPs cover a much broader range of applications compared to unichain MDPs, and
their optimality equations have a richer solution structure (with multiple
degrees of freedom), introducing additional complexity in proving algorithmic
convergence. We also characterize the sets to which RVI Q-learning algorithms
converge, showing that they are compact, connected, potentially nonconvex, and
comprised of solutions to the average-reward optimality equation, with exactly
one less degree of freedom than the general solution set of this equation.
Furthermore, we extend our analysis to two RVI-based hierarchical
average-reward RL algorithms using the options framework, proving their
almost-sure convergence and characterizing their sets of convergence under the
assumption that the underlying semi-Markov decision process is weakly
communicating.",2024-08-29,"Yi Wan, Huizhen Yu, Richard S. Sutton",http://arxiv.org/pdf/2408.16262v1,cs.LG
Evaluating Time-Series Training Dataset through Lens of Spectrum in Deep State Space Models,"This study investigates a method to evaluate time-series datasets in terms of
the performance of deep neural networks (DNNs) with state space models (deep
SSMs) trained on the dataset. SSMs have attracted attention as components
inside DNNs to address time-series data. Since deep SSMs have powerful
representation capacities, training datasets play a crucial role in solving a
new task. However, the effectiveness of training datasets cannot be known until
deep SSMs are actually trained on them. This can increase the cost of data
collection for new tasks, as a trial-and-error process of data collection and
time-consuming training are needed to achieve the necessary performance. To
advance the practical use of deep SSMs, the metric of datasets to estimate the
performance early in the training can be one key element. To this end, we
introduce the concept of data evaluation methods used in system identification.
In system identification of linear dynamical systems, the effectiveness of
datasets is evaluated by using the spectrum of input signals. We introduce this
concept to deep SSMs, which are nonlinear dynamical systems. We propose the
K-spectral metric, which is the sum of the top-K spectra of signals inside deep
SSMs, by focusing on the fact that each layer of a deep SSM can be regarded as
a linear dynamical system. Our experiments show that the K-spectral metric has
a large absolute value of the correlation coefficient with the performance and
can be used to evaluate the quality of training datasets.",2024-08-29,"Sekitoshi Kanai, Yasutoshi Ida, Kazuki Adachi, Mihiro Uchida, Tsukasa Yoshida, Shin'ya Yamaguchi",http://arxiv.org/pdf/2408.16261v1,cs.LG
Latent-EnSF: A Latent Ensemble Score Filter for High-Dimensional Data Assimilation with Sparse Observation Data,"Accurate modeling and prediction of complex physical systems often rely on
data assimilation techniques to correct errors inherent in model simulations.
Traditional methods like the Ensemble Kalman Filter (EnKF) and its variants as
well as the recently developed Ensemble Score Filters (EnSF) face significant
challenges when dealing with high-dimensional and nonlinear Bayesian filtering
problems with sparse observations, which are ubiquitous in real-world
applications. In this paper, we propose a novel data assimilation method,
Latent-EnSF, which leverages EnSF with efficient and consistent latent
representations of the full states and sparse observations to address the joint
challenges of high dimensionlity in states and high sparsity in observations
for nonlinear Bayesian filtering. We introduce a coupled Variational
Autoencoder (VAE) with two encoders to encode the full states and sparse
observations in a consistent way guaranteed by a latent distribution matching
and regularization as well as a consistent state reconstruction. With
comparison to several methods, we demonstrate the higher accuracy, faster
convergence, and higher efficiency of Latent-EnSF for two challenging
applications with complex models in shallow water wave propagation and
medium-range weather forecasting, for highly sparse observations in both space
and time.",2024-08-29,"Phillip Si, Peng Chen",http://arxiv.org/pdf/2409.00127v3,cs.LG
Coalitions of AI-based Methods Predict 15-Year Risks of Breast Cancer Metastasis Using Real-World Clinical Data with AUC up to 0.9,"Breast cancer is one of the two cancers responsible for the most deaths in
women, with about 42,000 deaths each year in the US. That there are over
300,000 breast cancers newly diagnosed each year suggests that only a fraction
of the cancers result in mortality. Thus, most of the women undergo seemingly
curative treatment for localized cancers, but a significant later succumb to
metastatic disease for which current treatments are only temporizing for the
vast majority. The current prognostic metrics are of little actionable value
for 4 of the 5 women seemingly cured after local treatment, and many women are
exposed to morbid and even mortal adjuvant therapies unnecessarily, with these
adjuvant therapies reducing metastatic recurrence by only a third. Thus, there
is a need for better prognostics to target aggressive treatment at those who
are likely to relapse and spare those who were actually cured. While there is a
plethora of molecular and tumor-marker assays in use and under-development to
detect recurrence early, these are time consuming, expensive and still often
un-validated as to actionable prognostic utility. A different approach would
use large data techniques to determine clinical and histopathological
parameters that would provide accurate prognostics using existing data. Herein,
we report on machine learning, together with grid search and Bayesian Networks
to develop algorithms that present a AUC of up to 0.9 in ROC analyses, using
only extant data. Such algorithms could be rapidly translated to clinical
management as they do not require testing beyond routine tumor evaluations.",2024-08-29,"Xia Jiang, Yijun Zhou, Alan Wells, Adam Brufsky",http://arxiv.org/pdf/2408.16256v1,cs.LG
Iterated Energy-based Flow Matching for Sampling from Boltzmann Densities,"In this work, we consider the problem of training a generator from
evaluations of energy functions or unnormalized densities. This is a
fundamental problem in probabilistic inference, which is crucial for scientific
applications such as learning the 3D coordinate distribution of a molecule. To
solve this problem, we propose iterated energy-based flow matching (iEFM), the
first off-policy approach to train continuous normalizing flow (CNF) models
from unnormalized densities. We introduce the simulation-free energy-based flow
matching objective, which trains the model to predict the Monte Carlo
estimation of the marginal vector field constructed from known energy
functions. Our framework is general and can be extended to variance-exploding
(VE) and optimal transport (OT) conditional probability paths. We evaluate iEFM
on a two-dimensional Gaussian mixture model (GMM) and an eight-dimensional
four-particle double-well potential (DW-4) energy function. Our results
demonstrate that iEFM outperforms existing methods, showcasing its potential
for efficient and scalable probabilistic modeling in complex high-dimensional
systems.",2024-08-29,"Dongyeop Woo, Sungsoo Ahn",http://arxiv.org/pdf/2408.16249v1,cs.LG
PACiM: A Sparsity-Centric Hybrid Compute-in-Memory Architecture via Probabilistic Approximation,"Approximate computing emerges as a promising approach to enhance the
efficiency of compute-in-memory (CiM) systems in deep neural network
processing. However, traditional approximate techniques often significantly
trade off accuracy for power efficiency, and fail to reduce data transfer
between main memory and CiM banks, which dominates power consumption. This
paper introduces a novel probabilistic approximate computation (PAC) method
that leverages statistical techniques to approximate multiply-and-accumulation
(MAC) operations, reducing approximation error by 4X compared to existing
approaches. PAC enables efficient sparsity-based computation in CiM systems by
simplifying complex MAC vector computations into scalar calculations. Moreover,
PAC enables sparsity encoding and eliminates the LSB activations transmission,
significantly reducing data reads and writes. This sets PAC apart from
traditional approximate computing techniques, minimizing not only computation
power but also memory accesses by 50%, thereby boosting system-level
efficiency. We developed PACiM, a sparsity-centric architecture that fully
exploits sparsity to reduce bit-serial cycles by 81% and achieves a peak 8b/8b
efficiency of 14.63 TOPS/W in 65 nm CMOS while maintaining high accuracy of
93.85/72.36/66.02% on CIFAR-10/CIFAR-100/ImageNet benchmarks using a ResNet-18
model, demonstrating the effectiveness of our PAC methodology.",2024-08-29,"Wenlun Zhang, Shimpei Ando, Yung-Chin Chen, Satomi Miyagi, Shinya Takamaeda-Yamazaki, Kentaro Yoshioka",http://arxiv.org/pdf/2408.16246v1,cs.LG
Large-Scale Multi-omic Biosequence Transformers for Modeling Protein-Nucleic Acid Interactions,"The transformer architecture has revolutionized bioinformatics and driven
progress in the understanding and prediction of the properties of biomolecules.
Almost all research on large-scale biosequence transformers has focused on one
domain at a time (single-omic), usually DNA/RNA or proteins. These models have
seen incredible success in downstream tasks in each domain, and have achieved
particularly noteworthy breakthroughs in sequence modeling and structural
modeling. However, these single-omic models are naturally incapable of
efficiently modeling multi-omic tasks, one of the most biologically critical
being protein-nucleic acid interactions. We present our work training the
largest open-source multi-omic foundation model to date. We show that these
multi-omic models (MOMs) can learn joint representations between various
single-omic distributions that are emergently consistent with the Central Dogma
of molecular biology despite only being trained on unlabeled biosequences. We
further demonstrate that MOMs can be fine-tuned to achieve state-of-the-art
results on protein-nucleic acid interaction tasks, namely predicting the change
in Gibbs free energy ($\Delta G$) of the binding interaction between a given
nucleic acid and protein. Remarkably, we show that multi-omic biosequence
transformers emergently learn useful structural information without any
\textit{a priori} structural training, allowing us to predict which protein
residues are most involved in the protein-nucleic acid binding interaction.
Lastly, we provide evidence that multi-omic biosequence models are in many
cases superior to foundation models trained on single-omics distributions, both
in performance-per-FLOP and absolute performance, suggesting a more generalized
or foundational approach to building these models for biology.",2024-08-29,"Sully F. Chen, Robert J. Steele, Glen M. Hocky, Beakal Lemeneh, Shivanand P. Lad, Eric K. Oermann",http://arxiv.org/pdf/2408.16245v3,cs.LG
Enhancing Conditional Image Generation with Explainable Latent Space Manipulation,"In the realm of image synthesis, achieving fidelity to a reference image
while adhering to conditional prompts remains a significant challenge. This
paper proposes a novel approach that integrates a diffusion model with latent
space manipulation and gradient-based selective attention mechanisms to address
this issue. Leveraging Grad-SAM (Gradient-based Selective Attention
Manipulation), we analyze the cross attention maps of the cross attention
layers and gradients for the denoised latent vector, deriving importance scores
of elements of denoised latent vector related to the subject of interest. Using
this information, we create masks at specific timesteps during denoising to
preserve subjects while seamlessly integrating the reference image features.
This approach ensures the faithful formation of subjects based on conditional
prompts, while concurrently refining the background for a more coherent
composition. Our experiments on places365 dataset demonstrate promising
results, with our proposed model achieving the lowest mean and median Frechet
Inception Distance (FID) scores compared to baseline models, indicating
superior fidelity preservation. Furthermore, our model exhibits competitive
performance in aligning the generated images with provided textual
descriptions, as evidenced by high CLIP scores. These results highlight the
effectiveness of our approach in both fidelity preservation and textual context
preservation, offering a significant advancement in text-to-image synthesis
tasks.",2024-08-29,Kshitij Pathania,http://arxiv.org/pdf/2408.16232v1,cs.LG
Policy Adaptation via Language Optimization: Decomposing Tasks for Few-Shot Imitation,"Learned language-conditioned robot policies often struggle to effectively
adapt to new real-world tasks even when pre-trained across a diverse set of
instructions. We propose a novel approach for few-shot adaptation to unseen
tasks that exploits the semantic understanding of task decomposition provided
by vision-language models (VLMs). Our method, Policy Adaptation via Language
Optimization (PALO), combines a handful of demonstrations of a task with
proposed language decompositions sampled from a VLM to quickly enable rapid
nonparametric adaptation, avoiding the need for a larger fine-tuning dataset.
We evaluate PALO on extensive real-world experiments consisting of challenging
unseen, long-horizon robot manipulation tasks. We find that PALO is able of
consistently complete long-horizon, multi-tier tasks in the real world,
outperforming state of the art pre-trained generalist policies, and methods
that have access to the same demonstrations.",2024-08-29,"Vivek Myers, Bill Chunyuan Zheng, Oier Mees, Sergey Levine, Kuan Fang",http://arxiv.org/pdf/2408.16228v1,cs.LG
Large-Scale Targeted Cause Discovery with Data-Driven Learning,"We propose a novel machine learning approach for inferring causal variables
of a target variable from observations. Our focus is on directly inferring a
set of causal factors without requiring full causal graph reconstruction, which
is computationally challenging in large-scale systems. The identified causal
set consists of all potential regulators of the target variable under
experimental settings, enabling efficient regulation when intervention costs
and feasibility vary across variables. To achieve this, we train a neural
network using supervised learning on simulated data to infer causality. By
employing a local-inference strategy, our approach scales with linear
complexity in the number of variables, efficiently scaling up to thousands of
variables. Empirical results demonstrate superior performance in identifying
causal relationships within large-scale gene regulatory networks, outperforming
existing methods that emphasize full-graph discovery. We validate our model's
generalization capability across out-of-distribution graph structures and
generating mechanisms, including gene regulatory networks of E. coli and the
human K562 cell line. Implementation codes are available at
https://github.com/snu-mllab/Targeted-Cause-Discovery.",2024-08-29,"Jang-Hyun Kim, Claudia Skok Gibbs, Sangdoo Yun, Hyun Oh Song, Kyunghyun Cho",http://arxiv.org/pdf/2408.16218v2,cs.LG
Adversarial Network Optimization under Bandit Feedback: Maximizing Utility in Non-Stationary Multi-Hop Networks,"Stochastic Network Optimization (SNO) concerns scheduling in stochastic
queueing systems. It has been widely studied in network theory. Classical SNO
algorithms require network conditions to be stationary with time, which fails
to capture the non-stationary components in many real-world scenarios. Many
existing algorithms also assume knowledge of network conditions before
decision, which rules out applications where unpredictability presents.
  Motivated by these issues, we consider Adversarial Network Optimization (ANO)
under bandit feedback. Specifically, we consider the task of *i)* maximizing
some unknown and time-varying utility function associated to scheduler's
actions, where *ii)* the underlying network is a non-stationary multi-hop one
whose conditions change arbitrarily with time, and *iii)* only bandit feedback
(effect of actually deployed actions) is revealed after decisions. Our proposed
`UMO2` algorithm ensures network stability and also matches the utility
maximization performance of any ""mildly varying"" reference policy up to a
polynomially decaying gap. To our knowledge, no previous ANO algorithm handled
multi-hop networks or achieved utility guarantees under bandit feedback,
whereas ours can do both.
  Technically, our method builds upon a novel integration of online learning
into Lyapunov analyses: To handle complex inter-dependencies among queues in
multi-hop networks, we propose meticulous techniques to balance online learning
and Lyapunov arguments. To tackle the learning obstacles due to potentially
unbounded queue sizes, we design a new online linear optimization algorithm
that automatically adapts to loss magnitudes. To maximize utility, we propose a
bandit convex optimization algorithm with novel queue-dependent learning rate
scheduling that suites drastically varying queue lengths. Our new insights in
online learning can be of independent interest.",2024-08-29,"Yan Dai, Longbo Huang",http://arxiv.org/pdf/2408.16215v1,cs.LG
The Application of Machine Learning in Tidal Evolution Simulation of Star-Planet Systems,"With the release of a large amount of astronomical data, an increasing number
of close-in hot Jupiters have been discovered. Calculating their evolutionary
curves using star-planet interaction models presents a challenge. To expedite
the generation of evolutionary curves for these close-in hot Jupiter systems,
we utilized tidal interaction models established on MESA to create 15,745
samples of star-planet systems and 7,500 samples of stars. Additionally, we
employed a neural network (Multi-Layer Perceptron - MLP) to predict the
evolutionary curves of the systems, including stellar effective temperature,
radius, stellar rotation period, and planetary orbital period. The median
relative errors of the predicted evolutionary curves were found to be 0.15%,
0.43%, 2.61%, and 0.57%, respectively. Furthermore, the speed at which we
generate evolutionary curves exceeds that of model-generated curves by more
than four orders of magnitude. We also extracted features of planetary
migration states and utilized lightGBM to classify the samples into 6
categories for prediction. We found that by combining three types that undergo
long-term double synchronization into one label, the classifier effectively
recognized these features. Apart from systems experiencing long-term double
synchronization, the median relative errors of the predicted evolutionary
curves were all below 4%. Our work provides an efficient method to save
significant computational resources and time with minimal loss in accuracy.
This research also lays the foundation for analyzing the evolutionary
characteristics of systems under different migration states, aiding in the
understanding of the underlying physical mechanisms of such systems. Finally,
to a large extent, our approach could replace the calculations of theoretical
models.",2024-08-29,"Shuaishuai Guo, Jianheng Guo, KaiFan Ji, Hui Liu, Lei Xing",http://arxiv.org/pdf/2408.16212v1,cs.LG
ReXamine-Global: A Framework for Uncovering Inconsistencies in Radiology Report Generation Metrics,"Given the rapidly expanding capabilities of generative AI models for
radiology, there is a need for robust metrics that can accurately measure the
quality of AI-generated radiology reports across diverse hospitals. We develop
ReXamine-Global, a LLM-powered, multi-site framework that tests metrics across
different writing styles and patient populations, exposing gaps in their
generalization. First, our method tests whether a metric is undesirably
sensitive to reporting style, providing different scores depending on whether
AI-generated reports are stylistically similar to ground-truth reports or not.
Second, our method measures whether a metric reliably agrees with experts, or
whether metric and expert scores of AI-generated report quality diverge for
some sites. Using 240 reports from 6 hospitals around the world, we apply
ReXamine-Global to 7 established report evaluation metrics and uncover serious
gaps in their generalizability. Developers can apply ReXamine-Global when
designing new report evaluation metrics, ensuring their robustness across
sites. Additionally, our analysis of existing metrics can guide users of those
metrics towards evaluation procedures that work reliably at their sites of
interest.",2024-08-29,"Oishi Banerjee, Agustina Saenz, Kay Wu, Warren Clements, Adil Zia, Dominic Buensalido, Helen Kavnoudias, Alain S. Abi-Ghanem, Nour El Ghawi, Cibele Luna, Patricia Castillo, Khaled Al-Surimi, Rayyan A. Daghistani, Yuh-Min Chen, Heng-sheng Chao, Lars Heiliger, Moon Kim, Johannes Haubold, Frederic Jonske, Pranav Rajpurkar",http://arxiv.org/pdf/2408.16208v1,cs.LG
Revisit Micro-batch Clipping: Adaptive Data Pruning via Gradient Manipulation,"Micro-batch clipping, a gradient clipping method, has recently shown
potential in enhancing auto-speech recognition (ASR) model performance.
However, the underlying mechanism behind this improvement remains mysterious,
particularly the observation that only certain micro-batch sizes are
beneficial. In this paper, we make the first attempt to explain this
phenomenon. Inspired by recent data pruning research, we assume that specific
training samples may impede model convergence during certain training phases.
Under this assumption, the convergence analysis shows that micro-batch clipping
can improve the convergence rate asymptotically at the cost of an additional
constant bias that does not diminish with more training iterations. The bias is
dependent on a few factors and can be minimized at specific micro-batch size,
thereby elucidating the existence of the sweet-spot micro-batch size observed
previously. We also verify the effectiveness of micro-batch clipping beyond
speech models on vision and language models, and show promising performance
gains in these domains. An exploration of potential limitations shows that
micro-batch clipping is less effective when training data originates from
multiple distinct domains.",2024-08-29,Lun Wang,http://arxiv.org/pdf/2408.16204v1,cs.LG
Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey,"Short-Term Electricity-Load Forecasting (STELF) refers to the prediction of
the immediate demand (in the next few hours to several days) for the power
system. Various external factors, such as weather changes and the emergence of
new electricity consumption scenarios, can impact electricity demand, causing
load data to fluctuate and become non-linear, which increases the complexity
and difficulty of STELF. In the past decade, deep learning has been applied to
STELF, modeling and predicting electricity demand with high accuracy, and
contributing significantly to the development of STELF. This paper provides a
comprehensive survey on deep-learning-based STELF over the past ten years. It
examines the entire forecasting process, including data pre-processing, feature
extraction, deep-learning modeling and optimization, and results evaluation.
This paper also identifies some research challenges and potential research
directions to be further investigated in future work.",2024-08-29,"Qi Dong, Rubing Huang, Chenhui Cui, Dave Towey, Ling Zhou, Jinyu Tian, Jianzhou Wang",http://arxiv.org/pdf/2408.16202v2,cs.LG
Uni-3DAD: GAN-Inversion Aided Universal 3D Anomaly Detection on Model-free Products,"Anomaly detection is a long-standing challenge in manufacturing systems.
Traditionally, anomaly detection has relied on human inspectors. However, 3D
point clouds have gained attention due to their robustness to environmental
factors and their ability to represent geometric data. Existing 3D anomaly
detection methods generally fall into two categories. One compares scanned 3D
point clouds with design files, assuming these files are always available.
However, such assumptions are often violated in many real-world applications
where model-free products exist, such as fresh produce (i.e., ``Cookie"",
``Potato"", etc.), dentures, bone, etc. The other category compares patches of
scanned 3D point clouds with a library of normal patches named memory bank.
However, those methods usually fail to detect incomplete shapes, which is a
fairly common defect type (i.e., missing pieces of different products). The
main challenge is that missing areas in 3D point clouds represent the absence
of scanned points. This makes it infeasible to compare the missing region with
existing point cloud patches in the memory bank. To address these two
challenges, we proposed a unified, unsupervised 3D anomaly detection framework
capable of identifying all types of defects on model-free products. Our method
integrates two detection modules: a feature-based detection module and a
reconstruction-based detection module. Feature-based detection covers geometric
defects, such as dents, holes, and cracks, while the reconstruction-based
method detects missing regions. Additionally, we employ a One-class Support
Vector Machine (OCSVM) to fuse the detection results from both modules. The
results demonstrate that (1) our proposed method outperforms the
state-of-the-art methods in identifying incomplete shapes and (2) it still
maintains comparable performance with the SOTA methods in detecting all other
types of anomalies.",2024-08-29,"Jiayu Liu, Shancong Mou, Nathan Gaw, Yinan Wang",http://arxiv.org/pdf/2408.16201v2,cs.LG
Variational Mode-Driven Graph Convolutional Network for Spatiotemporal Traffic Forecasting,"This paper focuses on spatiotemporal (ST) traffic prediction using graph
neural networks. Given that ST data consists of non-stationary and complex time
events, interpreting and predicting such trends is comparatively complicated.
Representation of ST data in modes helps us to infer behavior and assess the
impact of noise on prediction applications. We propose a framework that
decomposes ST data into modes using the variational mode decomposition (VMD)
method, which is then fed into the neural network for forecasting future
states. This hybrid approach is known as a variational mode graph convolutional
network (VMGCN). Instead of exhaustively searching for the number of modes,
they are determined using the reconstruction loss from the real-time
application data. We also study the significance of each mode and the impact of
bandwidth constraints on different horizon predictions in traffic flow data. We
evaluate the performance of our proposed network on the LargeST dataset for
both short and long-term predictions. Our framework yields better results
compared to state-of-the-art methods.",2024-08-29,"Osama Ahmad, Zubair Khalid",http://arxiv.org/pdf/2408.16191v2,cs.LG
Adaptive Sample Aggregation In Transfer Learning,"Transfer Learning aims to optimally aggregate samples from a target
distribution, with related samples from a so-called source distribution to
improve target risk. Multiple procedures have been proposed over the last two
decades to address this problem, each driven by one of a multitude of possible
divergence measures between source and target distributions. A first question
asked in this work is whether there exist unified algorithmic approaches that
automatically adapt to many of these divergence measures simultaneously.
  We show that this is indeed the case for a large family of divergences
proposed across classification and regression tasks, as they all happen to
upper-bound the same measure of continuity between source and target risks,
which we refer to as a weak modulus of transfer. This more unified view allows
us, first, to identify algorithmic approaches that are simultaneously adaptive
to these various divergence measures via a reduction to particular confidence
sets. Second, it allows for a more refined understanding of the statistical
limits of transfer under such divergences, and in particular, reveals regimes
with faster rates than might be expected under coarser lenses.
  We then turn to situations that are not well captured by the weak modulus and
corresponding divergences: these are situations where the aggregate of source
and target data can improve target performance significantly beyond what's
possible with either source or target data alone. We show that common such
situations -- as may arise, e.g., under certain causal models with spurious
correlations -- are well described by a so-called strong modulus of transfer
which supersedes the weak modulus. We finally show that the strong modulus also
admits adaptive procedures, which achieve near optimal rates in terms of the
unknown strong modulus, and therefore apply in more general settings.",2024-08-29,"Steve Hanneke, Samory Kpotufe",http://arxiv.org/pdf/2408.16189v2,cs.LG
Real-Time Energy Pricing in New Zealand: An Evolving Stream Analysis,"This paper introduces a group of novel datasets representing real-time
time-series and streaming data of energy prices in New Zealand, sourced from
the Electricity Market Information (EMI) website maintained by the New Zealand
government. The datasets are intended to address the scarcity of proper
datasets for streaming regression learning tasks. We conduct extensive analyses
and experiments on these datasets, covering preprocessing techniques,
regression tasks, prediction intervals, concept drift detection, and anomaly
detection. Our experiments demonstrate the datasets' utility and highlight the
challenges and opportunities for future research in energy price forecasting.",2024-08-29,"Yibin Sun, Heitor Murilo Gomes, Bernhard Pfahringer, Albert Bifet",http://arxiv.org/pdf/2408.16187v1,cs.LG
Single-Loop Deterministic and Stochastic Interior-Point Algorithms for Nonlinearly Constrained Optimization,"An interior-point algorithm framework is proposed, analyzed, and tested for
solving nonlinearly constrained continuous optimization problems. The main
setting of interest is when the objective and constraint functions may be
nonlinear and/or nonconvex, and when constraint values and derivatives are
tractable to compute, but objective function values and derivatives can only be
estimated. The algorithm is intended primarily for a setting that is similar
for stochastic-gradient methods for unconstrained optimization, namely, the
setting when stochastic-gradient estimates are available and employed in place
of gradients of the objective, and when no objective function values (nor
estimates of them) are employed. This is achieved by the interior-point
framework having a single-loop structure rather than the nested-loop structure
that is typical of contemporary interior-point methods. For completeness,
convergence guarantees for the framework are provided both for deterministic
and stochastic settings. Numerical experiments show that the algorithm yields
good performance on a large set of test problems.",2024-08-29,"Frank E. Curtis, Xin Jiang, Qi Wang",http://arxiv.org/pdf/2408.16186v1,cs.LG
A Minibatch-SGD-Based Learning Meta-Policy for Inventory Systems with Myopic Optimal Policy,"Stochastic gradient descent (SGD) has proven effective in solving many
inventory control problems with demand learning. However, it often faces the
pitfall of an infeasible target inventory level that is lower than the current
inventory level. Several recent works (e.g., Huh and Rusmevichientong (2009),
Shi et al.(2016)) are successful to resolve this issue in various inventory
systems. However, their techniques are rather sophisticated and difficult to be
applied to more complicated scenarios such as multi-product and
multi-constraint inventory systems.
  In this paper, we address the infeasible-target-inventory-level issue from a
new technical perspective -- we propose a novel minibatch-SGD-based
meta-policy. Our meta-policy is flexible enough to be applied to a general
inventory systems framework covering a wide range of inventory management
problems with myopic clairvoyant optimal policy. By devising the optimal
minibatch scheme, our meta-policy achieves a regret bound of
$\mathcal{O}(\sqrt{T})$ for the general convex case and $\mathcal{O}(\log T)$
for the strongly convex case. To demonstrate the power and flexibility of our
meta-policy, we apply it to three important inventory control problems:
multi-product and multi-constraint systems, multi-echelon serial systems, and
one-warehouse and multi-store systems by carefully designing
application-specific subroutines.We also conduct extensive numerical
experiments to demonstrate that our meta-policy enjoys competitive regret
performance, high computational efficiency, and low variances among a wide
range of applications.",2024-08-29,"Jiameng Lyu, Jinxing Xie, Shilin Yuan, Yuan Zhou",http://arxiv.org/pdf/2408.16181v1,cs.LG
CardBench: A Benchmark for Learned Cardinality Estimation in Relational Databases,"Cardinality estimation is crucial for enabling high query performance in
relational databases. Recently learned cardinality estimation models have been
proposed to improve accuracy but there is no systematic benchmark or datasets
which allows researchers to evaluate the progress made by new learned
approaches and even systematically develop new learned approaches. In this
paper, we are releasing a benchmark, containing thousands of queries over 20
distinct real-world databases for learned cardinality estimation. In contrast
to other initial benchmarks, our benchmark is much more diverse and can be used
for training and testing learned models systematically. Using this benchmark,
we explored whether learned cardinality estimation can be transferred to an
unseen dataset in a zero-shot manner. We trained GNN-based and
transformer-based models to study the problem in three setups: 1-)
instance-based, 2-) zero-shot, and 3-) fine-tuned. Our results show that while
we get promising results for zero-shot cardinality estimation on simple single
table queries; as soon as we add joins, the accuracy drops. However, we show
that with fine-tuning, we can still utilize pre-trained models for cardinality
estimation, significantly reducing training overheads compared to instance
specific models. We are open sourcing our scripts to collect statistics,
generate queries and training datasets to foster more extensive research, also
from the ML community on the important problem of cardinality estimation and in
particular improve on recent directions such as pre-trained cardinality
estimation.",2024-08-28,"Yannis Chronis, Yawen Wang, Yu Gan, Sami Abu-El-Haija, Chelsea Lin, Carsten Binnig, Fatma Özcan",http://arxiv.org/pdf/2408.16170v1,cs.LG
Simulating realistic short tandem repeat capillary electrophoretic signal using a generative adversarial network,"DNA profiles are made up from multiple series of electrophoretic signal
measuring fluorescence over time. Typically, human DNA analysts 'read' DNA
profiles using their experience to distinguish instrument noise, artefactual
signal, and signal corresponding to DNA fragments of interest. Recent work has
developed an artificial neural network, ANN, to carry out the task of
classifying fluorescence types into categories in DNA profile electrophoretic
signal. But the creation of the necessarily large amount of labelled training
data for the ANN is time consuming and expensive, and a limiting factor in the
ability to robustly train the ANN. If realistic, prelabelled, training data
could be simulated then this would remove the barrier to training an ANN with
high efficacy. Here we develop a generative adversarial network, GAN, modified
from the pix2pix GAN to achieve this task. With 1078 DNA profiles we train the
GAN and achieve the ability to simulate DNA profile information, and then use
the generator from the GAN as a 'realism filter' that applies the noise and
artefact elements exhibited in typical electrophoretic signal.",2024-08-28,"Duncan Taylor, Melissa Humphries",http://arxiv.org/pdf/2408.16169v1,cs.LG
LeMON: Learning to Learn Multi-Operator Networks,"Single-operator learning involves training a deep neural network to learn a
specific operator, whereas recent work in multi-operator learning uses an
operator embedding structure to train a single neural network on data from
multiple operators. Thus, multi-operator learning is capable of predicting a
range of operators within one model. In this work, we propose pretraining and
fine-tuning strategies for solving PDEs using multi-operator learning. One key
aspect is that by increasing the number of families of operators used in
pretraining, a PDE foundation model can be fine-tuned to downstream tasks
involving new PDEs with a limited number of samples, thus outperforming single
operator neural networks. Specifically, a multi-operator learning model
pre-trained with data from diverse PDE families can predict unseen operators
after fine-tuning with only a limited number of operators from the new family,
enabling them to serve as a data-free PDE solver. We also show that the
proposed training and fine-tuning method is able to predict new operators in
zero-shot prediction without samples. Additionally, we introduce a PDE-agnostic
meta-learning algorithm to improve the adaptability of the model to various
PDEs by providing a better parameter initialization process. To address the
needs of applications with limited computing resources, we explore low-rank
adaptation methods that reduce computational costs while enhancing solver
accuracy. Lastly, by examining the scaling law with respect to the number of
operator families, we establish and highlight its potential for broad
adaptation in PDE-solving tasks.",2024-08-28,"Jingmin Sun, Zecheng Zhang, Hayden Schaeffer",http://arxiv.org/pdf/2408.16168v1,cs.LG
Free Lunch in the Forest: Functionally-Identical Pruning of Boosted Tree Ensembles,"Tree ensembles, including boosting methods, are highly effective and widely
used for tabular data. However, large ensembles lack interpretability and
require longer inference times. We introduce a method to prune a tree ensemble
into a reduced version that is ""functionally identical"" to the original model.
In other words, our method guarantees that the prediction function stays
unchanged for any possible input. As a consequence, this pruning algorithm is
lossless for any aggregated metric. We formalize the problem of functionally
identical pruning on ensembles, introduce an exact optimization model, and
provide a fast yet highly effective method to prune large ensembles. Our
algorithm iteratively prunes considering a finite set of points, which is
incrementally augmented using an adversarial model. In multiple computational
experiments, we show that our approach is a ""free lunch"", significantly
reducing the ensemble size without altering the model's behavior. Thus, we can
preserve state-of-the-art performance at a fraction of the original model's
size.",2024-08-28,"Youssouf Emine, Alexandre Forel, Idriss Malek, Thibaut Vidal",http://arxiv.org/pdf/2408.16167v2,cs.LG
CLPNets: Coupled Lie-Poisson Neural Networks for Multi-Part Hamiltonian Systems with Symmetries,"To accurately compute data-based prediction of Hamiltonian systems,
especially the long-term evolution of such systems, it is essential to utilize
methods that preserve the structure of the equations over time. We consider a
case that is particularly challenging for data-based methods: systems with
interacting parts that do not reduce to pure momentum evolution. Such systems
are essential in scientific computations. For example, any discretization of a
continuum elastic rod can be viewed as interacting elements that can move and
rotate in space, with each discrete element moving on the group of rotations
and translations $SE(3)$.
  We develop a novel method of data-based computation and complete phase space
learning of such systems. We follow the original framework of \emph{SympNets}
(Jin et al, 2020) building the neural network from canonical phase space
mappings, and transformations that preserve the Lie-Poisson structure
(\emph{LPNets}) as in (Eldred et al, 2024). We derive a novel system of
mappings that are built into neural networks for coupled systems. We call such
networks Coupled Lie-Poisson Neural Networks, or \emph{CLPNets}. We consider
increasingly complex examples for the applications of CLPNets: rotation of two
rigid bodies about a common axis, the free rotation of two rigid bodies, and
finally the evolution of two connected and interacting $SE(3)$ components. Our
method preserves all Casimir invariants of each system to machine precision,
irrespective of the quality of the training data, and preserves energy to high
accuracy. Our method also shows good resistance to the curse of dimensionality,
requiring only a few thousand data points for all cases studied, with the
effective dimension varying from three to eighteen. Additionally, the method is
highly economical in memory requirements, requiring only about 200 parameters
for the most complex case considered.",2024-08-28,"Christopher Eldred, François Gay-Balmaz, Vakhtang Putkaradze",http://arxiv.org/pdf/2408.16160v1,cs.LG
Does Data-Efficient Generalization Exacerbate Bias in Foundation Models?,"Foundation models have emerged as robust models with label efficiency in
diverse domains. In medical imaging, these models contribute to the advancement
of medical diagnoses due to the difficulty in obtaining labeled data. However,
it is unclear whether using a large amount of unlabeled data, biased by the
presence of sensitive attributes during pre-training, influences the fairness
of the model. This research examines the bias in the Foundation model
(RetFound) when it is applied to fine-tune the Brazilian Multilabel
Ophthalmological Dataset (BRSET), which has a different population than the
pre-training dataset. The model evaluation, in comparison with supervised
learning, shows that the Foundation Model has the potential to reduce the gap
between the maximum AUC and minimum AUC evaluations across gender and age
groups. However, in a data-efficient generalization, the model increases the
bias when the data amount decreases. These findings suggest that when deploying
a Foundation Model in real-life scenarios with limited data, the possibility of
fairness issues should be considered.",2024-08-28,"Dilermando Queiroz, Anderson Carlos, Maíra Fatoretto, Luis Filipe Nakayama, André Anjos, Lilian Berton",http://arxiv.org/pdf/2408.16154v2,cs.LG
A Hybrid Framework for Spatial Interpolation: Merging Data-driven with Domain Knowledge,"Estimating spatially distributed information through the interpolation of
scattered observation datasets often overlooks the critical role of domain
knowledge in understanding spatial dependencies. Additionally, the features of
these data sets are typically limited to the spatial coordinates of the
scattered observation locations. In this paper, we propose a hybrid framework
that integrates data-driven spatial dependency feature extraction with
rule-assisted spatial dependency function mapping to augment domain knowledge.
We demonstrate the superior performance of our framework in two comparative
application scenarios, highlighting its ability to capture more localized
spatial features in the reconstructed distribution fields. Furthermore, we
underscore its potential to enhance nonlinear estimation capabilities through
the application of transformed fuzzy rules and to quantify the inherent
uncertainties associated with the observation data sets. Our framework
introduces an innovative approach to spatial information estimation by
synergistically combining observational data with rule-assisted domain
knowledge.",2024-08-28,"Cong Zhang, Shuyi Du, Hongqing Song, Yuhe Wang",http://arxiv.org/pdf/2409.00125v3,cs.LG
Improving the Prediction of Individual Engagement in Recommendations Using Cognitive Models,"For public health programs with limited resources, the ability to predict how
behaviors change over time and in response to interventions is crucial for
deciding when and to whom interventions should be allocated. Using data from a
real-world maternal health program, we demonstrate how a cognitive model based
on Instance-Based Learning (IBL) Theory can augment existing purely
computational approaches. Our findings show that, compared to general
time-series forecasters (e.g., LSTMs), IBL models, which reflect human
decision-making processes, better predict the dynamics of individuals' states.
Additionally, IBL provides estimates of the volatility in individuals' states
and their sensitivity to interventions, which can improve the efficiency of
training of other time series models.",2024-08-28,"Roderick Seow, Yunfan Zhao, Duncan Wood, Milind Tambe, Cleotilde Gonzalez",http://arxiv.org/pdf/2408.16147v2,cs.LG
Thinner Latent Spaces: Detecting dimension and imposing invariance through autoencoder gradient constraints,"Conformal Autoencoders are a neural network architecture that imposes
orthogonality conditions between the gradients of latent variables towards
achieving disentangled representations of data. In this letter we show that
orthogonality relations within the latent layer of the network can be leveraged
to infer the intrinsic dimensionality of nonlinear manifold data sets (locally
characterized by the dimension of their tangent space), while simultaneously
computing encoding and decoding (embedding) maps. We outline the relevant
theory relying on differential geometry, and describe the corresponding
gradient-descent optimization algorithm. The method is applied to standard data
sets and we highlight its applicability, advantages, and shortcomings. In
addition, we demonstrate that the same computational technology can be used to
build coordinate invariance to local group actions when defined only on a
(reduced) submanifold of the embedding space.",2024-08-28,"George A. Kevrekidis, Mauro Maggioni, Soledad Villar, Yannis G. Kevrekidis",http://arxiv.org/pdf/2408.16138v1,cs.LG
Using Backbone Foundation Model for Evaluating Fairness in Chest Radiography Without Demographic Data,"Ensuring consistent performance across diverse populations and incorporating
fairness into machine learning models are crucial for advancing medical image
diagnostics and promoting equitable healthcare. However, many databases do not
provide protected attributes or contain unbalanced representations of
demographic groups, complicating the evaluation of model performance across
different demographics and the application of bias mitigation techniques that
rely on these attributes. This study aims to investigate the effectiveness of
using the backbone of Foundation Models as an embedding extractor for creating
groups that represent protected attributes, such as gender and age. We propose
utilizing these groups in different stages of bias mitigation, including
pre-processing, in-processing, and evaluation. Using databases in and
out-of-distribution scenarios, it is possible to identify that the method can
create groups that represent gender in both databases and reduce in 4.44% the
difference between the gender attribute in-distribution and 6.16% in
out-of-distribution. However, the model lacks robustness in handling age
attributes, underscoring the need for more fundamentally fair and robust
Foundation models. These findings suggest a role in promoting fairness
assessment in scenarios where we lack knowledge of attributes, contributing to
the development of more equitable medical diagnostics.",2024-08-28,"Dilermando Queiroz, André Anjos, Lilian Berton",http://arxiv.org/pdf/2408.16130v1,cs.LG
"Improving Generalization of Speech Separation in Real-World Scenarios: Strategies in Simulation, Optimization, and Evaluation","Achieving robust speech separation for overlapping speakers in various
acoustic environments with noise and reverberation remains an open challenge.
Although existing datasets are available to train separators for specific
scenarios, they do not effectively generalize across diverse real-world
scenarios. In this paper, we present a novel data simulation pipeline that
produces diverse training data from a range of acoustic environments and
content, and propose new training paradigms to improve quality of a general
speech separation model. Specifically, we first introduce AC-SIM, a data
simulation pipeline that incorporates broad variations in both content and
acoustics. Then we integrate multiple training objectives into the permutation
invariant training (PIT) to enhance separation quality and generalization of
the trained model. Finally, we conduct comprehensive objective and human
listening experiments across separation architectures and benchmarks to
validate our methods, demonstrating substantial improvement of generalization
on both non-homologous and real-world test sets.",2024-08-28,"Ke Chen, Jiaqi Su, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Zeyu Jin",http://arxiv.org/pdf/2408.16126v1,cs.LG
ChartEye: A Deep Learning Framework for Chart Information Extraction,"The widespread use of charts and infographics as a means of data
visualization in various domains has inspired recent research in automated
chart understanding. However, information extraction from chart images is a
complex multitasked process due to style variations and, as a consequence, it
is challenging to design an end-to-end system. In this study, we propose a deep
learning-based framework that provides a solution for key steps in the chart
information extraction pipeline. The proposed framework utilizes hierarchal
vision transformers for the tasks of chart-type and text-role classification,
while YOLOv7 for text detection. The detected text is then enhanced using Super
Resolution Generative Adversarial Networks to improve the recognition output of
the OCR. Experimental results on a benchmark dataset show that our proposed
framework achieves excellent performance at every stage with F1-scores of 0.97
for chart-type classification, 0.91 for text-role classification, and a mean
Average Precision of 0.95 for text detection.",2024-08-28,"Osama Mustafa, Muhammad Khizer Ali, Momina Moetesum, Imran Siddiqi",http://arxiv.org/pdf/2408.16123v1,cs.LG
Variational Mode Decomposition and Linear Embeddings are What You Need For Time-Series Forecasting,"Time-series forecasting often faces challenges due to data volatility, which
can lead to inaccurate predictions. Variational Mode Decomposition (VMD) has
emerged as a promising technique to mitigate volatility by decomposing data
into distinct modes, thereby enhancing forecast accuracy. In this study, we
integrate VMD with linear models to develop a robust forecasting framework. Our
approach is evaluated on 13 diverse datasets, including ETTm2, WindTurbine, M4,
and 10 air quality datasets from various Southeast Asian cities. The
effectiveness of the VMD strategy is assessed by comparing Root Mean Squared
Error (RMSE) values from models utilizing VMD against those without it.
Additionally, we benchmark linear-based models against well-known neural
network architectures such as LSTM, Bidirectional LSTM, and RNN. The results
demonstrate a significant reduction in RMSE across nearly all models following
VMD application. Notably, the Linear + VMD model achieved the lowest average
RMSE in univariate forecasting at 0.619. In multivariate forecasting, the
DLinear + VMD model consistently outperformed others, attaining the lowest RMSE
across all datasets with an average of 0.019. These findings underscore the
effectiveness of combining VMD with linear models for superior time-series
forecasting.",2024-08-28,"Hafizh Raihan Kurnia Putra, Novanto Yudistira, Tirana Noor Fatyanosa",http://arxiv.org/pdf/2408.16122v2,cs.LG
RAIN: Reinforcement Algorithms for Improving Numerical Weather and Climate Models,"This study explores integrating reinforcement learning (RL) with idealised
climate models to address key parameterisation challenges in climate science.
Current climate models rely on complex mathematical parameterisations to
represent sub-grid scale processes, which can introduce substantial
uncertainties. RL offers capabilities to enhance these parameterisation
schemes, including direct interaction, handling sparse or delayed feedback,
continuous online learning, and long-term optimisation. We evaluate the
performance of eight RL algorithms on two idealised environments: one for
temperature bias correction, another for radiative-convective equilibrium (RCE)
imitating real-world computational constraints. Results show different RL
approaches excel in different climate scenarios with exploration algorithms
performing better in bias correction, while exploitation algorithms proving
more effective for RCE. These findings support the potential of RL-based
parameterisation schemes to be integrated into global climate models, improving
accuracy and efficiency in capturing complex climate dynamics. Overall, this
work represents an important first step towards leveraging RL to enhance
climate model accuracy, critical for improving climate understanding and
predictions. Code accessible at https://github.com/p3jitnath/climate-rl.",2024-08-28,"Pritthijit Nath, Henry Moss, Emily Shuckburgh, Mark Webb",http://arxiv.org/pdf/2408.16118v3,cs.LG
Uncertainty Modeling in Graph Neural Networks via Stochastic Differential Equations,"We propose a novel Stochastic Differential Equation (SDE) framework to
address the problem of learning uncertainty-aware representations for
graph-structured data. While Graph Neural Ordinary Differential Equations
(GNODEs) have shown promise in learning node representations, they lack the
ability to quantify uncertainty. To address this, we introduce Latent Graph
Neural Stochastic Differential Equations (LGNSDE), which enhance GNODE by
embedding randomness through a Bayesian prior-posterior mechanism for epistemic
uncertainty and Brownian motion for aleatoric uncertainty. By leveraging the
existence and uniqueness of solutions to graph-based SDEs, we prove that the
variance of the latent space bounds the variance of model outputs, thereby
providing theoretically sensible guarantees for the uncertainty estimates.
Furthermore, we show mathematically that LGNSDEs are robust to small
perturbations in the input, maintaining stability over time. Empirical results
across several benchmarks demonstrate that our framework is competitive in
out-of-distribution detection, robustness to noise, and active learning,
underscoring the ability of LGNSDEs to quantify uncertainty reliably.",2024-08-28,"Richard Bergna, Sergio Calvo-Ordoñez, Felix L. Opolka, Pietro Liò, Jose Miguel Hernandez-Lobato",http://arxiv.org/pdf/2408.16115v4,cs.LG
Negative Binomial Matrix Completion,"Matrix completion focuses on recovering missing or incomplete information in
matrices. This problem arises in various applications, including image
processing and network analysis. Previous research proposed Poisson matrix
completion for count data with noise that follows a Poisson distribution, which
assumes that the mean and variance are equal. Since overdispersed count data,
whose variance is greater than the mean, is more likely to occur in realistic
settings, we assume that the noise follows the negative binomial (NB)
distribution, which can be more general than the Poisson distribution. In this
paper, we introduce NB matrix completion by proposing a nuclear-norm
regularized model that can be solved by proximal gradient descent. In our
experiments, we demonstrate that the NB model outperforms Poisson matrix
completion in various noise and missing data settings on real data.",2024-08-28,"Yu Lu, Kevin Bui, Roummel F. Marcia",http://arxiv.org/pdf/2408.16113v1,cs.LG
A nudge to the truth: atom conservation as a hard constraint in models of atmospheric composition using an uncertainty-weighted correction,"Computational models of atmospheric composition are not always physically
consistent. For example, not all models respect fundamental conservation laws
such as conservation of atoms in an interconnected chemical system. In well
performing models, these nonphysical deviations are often ignored because they
are frequently minor, and thus only need a small nudge to perfectly conserve
mass. Here we introduce a method that anchors a prediction from any numerical
model to physically consistent hard constraints, nudging concentrations to the
nearest solution that respects the conservation laws. This closed-form
model-agnostic correction uses a single matrix operation to minimally perturb
the predicted concentrations to ensure that atoms are conserved to machine
precision. To demonstrate this approach, we train a gradient boosting decision
tree ensemble to emulate a small reference model of ozone photochemistry and
test the effect of the correction on accurate but non-conservative predictions.
The nudging approach minimally perturbs the already well-predicted results for
most species, but decreases the accuracy of important oxidants, including
radicals. We develop a weighted extension of this nudging approach that
considers the uncertainty and magnitude of each species in the correction. This
species-level weighting approach is essential to accurately predict important
low concentration species such as radicals. We find that applying the
uncertainty-weighted correction to the nonphysical predictions slightly
improves overall accuracy, by nudging the predictions to a more likely
mass-conserving solution.",2024-08-28,"Patrick Obin Sturm, Sam J. Silva",http://arxiv.org/pdf/2408.16109v1,cs.LG
EPO: Hierarchical LLM Agents with Environment Preference Optimization,"Long-horizon decision-making tasks present significant challenges for
LLM-based agents due to the need for extensive planning over multiple steps. In
this paper, we propose a hierarchical framework that decomposes complex tasks
into manageable subgoals, utilizing separate LLMs for subgoal prediction and
low-level action generation. To address the challenge of creating training
signals for unannotated datasets, we develop a reward model that leverages
multimodal environment feedback to automatically generate reward signals. We
introduce Environment Preference Optimization (EPO), a novel method that
generates preference signals from the environment's feedback and uses them to
train LLM-based agents. Extensive experiments on ALFRED demonstrate the
state-of-the-art performance of our framework, achieving first place on the
ALFRED public leaderboard and showcasing its potential to improve long-horizon
decision-making in diverse environments.",2024-08-28,"Qi Zhao, Haotian Fu, Chen Sun, George Konidaris",http://arxiv.org/pdf/2408.16090v2,cs.LG
Unlocking Global Optimality in Bilevel Optimization: A Pilot Study,"Bilevel optimization has witnessed a resurgence of interest, driven by its
critical role in trustworthy and efficient AI applications. While many recent
works have established convergence to stationary points or local minima,
obtaining the global optimum of bilevel optimization remains an important yet
open problem. The difficulty lies in the fact that, unlike many prior
non-convex single-level problems, bilevel problems often do not admit a benign
landscape, and may indeed have multiple spurious local solutions. Nevertheless,
attaining global optimality is indispensable for ensuring reliability, safety,
and cost-effectiveness, particularly in high-stakes engineering applications
that rely on bilevel optimization. In this paper, we first explore the
challenges of establishing a global convergence theory for bilevel
optimization, and present two sufficient conditions for global convergence. We
provide algorithm-dependent proofs to rigorously substantiate these sufficient
conditions on two specific bilevel learning scenarios: representation learning
and data hypercleaning (a.k.a. reweighting). Experiments corroborate the
theoretical findings, demonstrating convergence to the global minimum in both
cases.",2024-08-28,"Quan Xiao, Tianyi Chen",http://arxiv.org/pdf/2408.16087v2,cs.LG
Q-MRS: A Deep Learning Framework for Quantitative Magnetic Resonance Spectra Analysis,"Magnetic resonance spectroscopy (MRS) is an established technique for
studying tissue metabolism, particularly in central nervous system disorders.
While powerful and versatile, MRS is often limited by challenges associated
with data quality, processing, and quantification. Existing MRS quantification
methods face difficulties in balancing model complexity and reproducibility
during spectral modeling, often falling into the trap of either
oversimplification or over-parameterization. To address these limitations, this
study introduces a deep learning (DL) framework that employs transfer learning,
in which the model is pre-trained on simulated datasets before it undergoes
fine-tuning on in vivo data. The proposed framework showed promising
performance when applied to the Philips dataset from the BIG GABA repository
and represents an exciting advancement in MRS data analysis.",2024-08-28,"Christopher J. Wu, Lawrence S. Kegeles, Jia Guo",http://arxiv.org/pdf/2408.15999v1,cs.LG
Scaling Up Diffusion and Flow-based XGBoost Models,"Novel machine learning methods for tabular data generation are often
developed on small datasets which do not match the scale required for
scientific applications. We investigate a recent proposal to use XGBoost as the
function approximator in diffusion and flow-matching models on tabular data,
which proved to be extremely memory intensive, even on tiny datasets. In this
work, we conduct a critical analysis of the existing implementation from an
engineering perspective, and show that these limitations are not fundamental to
the method; with better implementation it can be scaled to datasets 370x larger
than previously used. Our efficient implementation also unlocks scaling models
to much larger sizes which we show directly leads to improved performance on
benchmark tasks. We also propose algorithmic improvements that can further
benefit resource usage and model performance, including multi-output trees
which are well-suited to generative modeling. Finally, we present results on
large-scale scientific datasets derived from experimental particle physics as
part of the Fast Calorimeter Simulation Challenge. Code is available at
https://github.com/layer6ai-labs/calo-forest.",2024-08-28,"Jesse C. Cresswell, Taewoo Kim",http://arxiv.org/pdf/2408.16046v1,cs.LG
Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders,"The ability to accurately interpret complex visual information is a crucial
topic of multimodal large language models (MLLMs). Recent work indicates that
enhanced visual perception significantly reduces hallucinations and improves
performance on resolution-sensitive tasks, such as optical character
recognition and document analysis. A number of recent MLLMs achieve this goal
using a mixture of vision encoders. Despite their success, there is a lack of
systematic comparisons and detailed ablation studies addressing critical
aspects, such as expert selection and the integration of multiple vision
experts. This study provides an extensive exploration of the design space for
MLLMs using a mixture of vision encoders and resolutions. Our findings reveal
several underlying principles common to various existing strategies, leading to
a streamlined yet effective design approach. We discover that simply
concatenating visual tokens from a set of complementary vision encoders is as
effective as more complex mixing architectures or strategies. We additionally
introduce Pre-Alignment to bridge the gap between vision-focused encoders and
language tokens, enhancing model coherence. The resulting family of MLLMs,
Eagle, surpasses other leading open-source models on major MLLM benchmarks.",2024-08-28,"Min Shi, Fuxiao Liu, Shihao Wang, Shijia Liao, Subhashree Radhakrishnan, Yilin Zhao, De-An Huang, Hongxu Yin, Karan Sapra, Yaser Yacoob, Humphrey Shi, Bryan Catanzaro, Andrew Tao, Jan Kautz, Zhiding Yu, Guilin Liu",http://arxiv.org/pdf/2408.15998v2,cs.LG
Mamba or Transformer for Time Series Forecasting? Mixture of Universals (MoU) Is All You Need,"Time series forecasting requires balancing short-term and long-term
dependencies for accurate predictions. Existing methods mainly focus on
long-term dependency modeling, neglecting the complexities of short-term
dynamics, which may hinder performance. Transformers are superior in modeling
long-term dependencies but are criticized for their quadratic computational
cost. Mamba provides a near-linear alternative but is reported less effective
in time series longterm forecasting due to potential information loss. Current
architectures fall short in offering both high efficiency and strong
performance for long-term dependency modeling. To address these challenges, we
introduce Mixture of Universals (MoU), a versatile model to capture both
short-term and long-term dependencies for enhancing performance in time series
forecasting. MoU is composed of two novel designs: Mixture of Feature
Extractors (MoF), an adaptive method designed to improve time series patch
representations for short-term dependency, and Mixture of Architectures (MoA),
which hierarchically integrates Mamba, FeedForward, Convolution, and
Self-Attention architectures in a specialized order to model long-term
dependency from a hybrid perspective. The proposed approach achieves
state-of-the-art performance while maintaining relatively low computational
costs. Extensive experiments on seven real-world datasets demonstrate the
superiority of MoU. Code is available at https://github.com/lunaaa95/mou/.",2024-08-28,"Sijia Peng, Yun Xiong, Yangyong Zhu, Zhiqiang Shen",http://arxiv.org/pdf/2408.15997v1,cs.LG
ClimDetect: A Benchmark Dataset for Climate Change Detection and Attribution,"Detecting and attributing temperature increases driven by climate change is
crucial for understanding global warming and informing adaptation strategies.
However, distinguishing human-induced climate signals from natural variability
remains challenging for traditional detection and attribution (D&A) methods,
which rely on identifying specific ""fingerprints"" -- spatial patterns expected
to emerge from external forcings such as greenhouse gas emissions. Deep
learning offers promise in discerning these complex patterns within expansive
spatial datasets, yet the lack of standardized protocols has hindered
consistent comparisons across studies.
  To address this gap, we introduce ClimDetect, a standardized dataset
comprising 1.17M daily climate snapshots paired with target climate change
indicator variables. The dataset is curated from both CMIP6 climate model
simulations and real-world observation-assimilated reanalysis datasets (ERA5,
JRA-3Q, and MERRA-2), and is designed to enhance model accuracy in detecting
climate change signals. ClimDetect integrates various input and target
variables used in previous research, ensuring comparability and consistency
across studies. We also explore the application of vision transformers (ViT) to
climate data -- a novel approach that, to our knowledge, has not been attempted
before for climate change detection tasks. Our open-access data serve as a
benchmark for advancing climate science by enabling end-to-end model
development and evaluation. ClimDetect is publicly accessible via Hugging Face
dataset repository at: https://huggingface.co/datasets/ClimDetect/ClimDetect.",2024-08-28,"Sungduk Yu, Brian L. White, Anahita Bhiwandiwalla, Musashi Hinck, Matthew Lyle Olson, Yaniv Gurwicz, Raanan Y. Rohekar, Tung Nguyen, Vasudev Lal",http://arxiv.org/pdf/2408.15993v2,cs.LG
CoGen: Learning from Feedback with Coupled Comprehension and Generation,"Systems with both language comprehension and generation capabilities can
benefit from the tight connection between the two. This work studies coupling
comprehension and generation with focus on continually learning from
interaction with users. We propose techniques to tightly integrate the two
capabilities for both learning and inference. We situate our studies in
two-player reference games, and deploy various models for thousands of
interactions with human users, while learning from interaction feedback
signals. We show dramatic improvements in performance over time, with
comprehension-generation coupling leading to performance improvements up to 26%
in absolute terms and up to 17% higher accuracies compared to a non-coupled
system. Our analysis also shows coupling has substantial qualitative impact on
the system's language, making it significantly more human-like.",2024-08-28,"Mustafa Omer Gul, Yoav Artzi",http://arxiv.org/pdf/2408.15992v1,cs.LG
"Fairness, Accuracy, and Unreliable Data","This thesis investigates three areas targeted at improving the reliability of
machine learning; fairness in machine learning, strategic classification, and
algorithmic robustness. Each of these domains has special properties or
structure that can complicate learning. A theme throughout this thesis is
thinking about ways in which a `plain' empirical risk minimization algorithm
will be misleading or ineffective because of a mis-match between classical
learning theory assumptions and specific properties of some data distribution
in the wild. Theoretical understanding in eachof these domains can help guide
best practices and allow for the design of effective, reliable, and robust
systems.",2024-08-28,Kevin Stangl,http://arxiv.org/pdf/2408.16040v1,cs.LG
Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems,"We examine stability properties of primal-dual gradient flow dynamics for
composite convex optimization problems with multiple, possibly nonsmooth, terms
in the objective function under the generalized consensus constraint. The
proposed dynamics are based on the proximal augmented Lagrangian and they
provide a viable alternative to ADMM which faces significant challenges from
both analysis and implementation viewpoints in large-scale multi-block
scenarios. In contrast to customized algorithms with individualized convergence
guarantees, we provide a systematic approach for solving a broad class of
challenging composite optimization problems. We leverage various structural
properties to establish global (exponential) convergence guarantees for the
proposed dynamics. Our assumptions are much weaker than those required to prove
(exponential) stability of various primal-dual dynamics as well as (linear)
convergence of discrete-time methods, e.g., standard two-block and multi-block
ADMM and EXTRA algorithms. Finally, we show necessity of some of our structural
assumptions for exponential stability and provide computational experiments to
demonstrate the convenience of the proposed dynamics for parallel and
distributed computing applications.",2024-08-28,"Ibrahim K. Ozaslan, Panagiotis Patrinos, Mihailo R. Jovanović",http://arxiv.org/pdf/2408.15969v1,cs.LG
Efficient Slice Anomaly Detection Network for 3D Brain MRI Volume,"Current anomaly detection methods excel with benchmark industrial data but
struggle with natural images and medical data due to varying definitions of
'normal' and 'abnormal.' This makes accurate identification of deviations in
these fields particularly challenging. Especially for 3D brain MRI data, all
the state-of-the-art models are reconstruction-based with 3D convolutional
neural networks which are memory-intensive, time-consuming and producing noisy
outputs that require further post-processing. We propose a framework called
Simple Slice-based Network (SimpleSliceNet), which utilizes a model pre-trained
on ImageNet and fine-tuned on a separate MRI dataset as a 2D slice feature
extractor to reduce computational cost. We aggregate the extracted features to
perform anomaly detection tasks on 3D brain MRI volumes. Our model integrates a
conditional normalizing flow to calculate log likelihood of features and
employs the Semi-Push-Pull Mechanism to enhance anomaly detection accuracy. The
results indicate improved performance, showcasing our model's remarkable
adaptability and effectiveness when addressing the challenges exists in brain
MRI data. In addition, for the large-scale 3D brain volumes, our model
SimpleSliceNet outperforms the state-of-the-art 2D and 3D models in terms of
accuracy, memory usage and time consumption. Code is available at:
https://anonymous.4open.science/r/SimpleSliceNet-8EA3.",2024-08-28,"Zeduo Zhang, Yalda Mohsenzadeh",http://arxiv.org/pdf/2408.15958v1,cs.LG
Leveraging Large Language Models for Wireless Symbol Detection via In-Context Learning,"Deep neural networks (DNNs) have made significant strides in tackling
challenging tasks in wireless systems, especially when an accurate wireless
model is not available. However, when available data is limited, traditional
DNNs often yield subpar results due to underfitting. At the same time, large
language models (LLMs) exemplified by GPT-3, have remarkably showcased their
capabilities across a broad range of natural language processing tasks. But
whether and how LLMs can benefit challenging non-language tasks in wireless
systems is unexplored. In this work, we propose to leverage the in-context
learning ability (a.k.a. prompting) of LLMs to solve wireless tasks in the low
data regime without any training or fine-tuning, unlike DNNs which require
training. We further demonstrate that the performance of LLMs varies
significantly when employed with different prompt templates. To solve this
issue, we employ the latest LLM calibration methods. Our results reveal that
using LLMs via ICL methods generally outperforms traditional DNNs on the symbol
demodulation task and yields highly confident predictions when coupled with
calibration techniques.",2024-08-28,"Momin Abbas, Koushik Kar, Tianyi Chen",http://arxiv.org/pdf/2409.00124v2,cs.LG
Generating Binary Species Range Maps,"Accurately predicting the geographic ranges of species is crucial for
assisting conservation efforts. Traditionally, range maps were manually created
by experts. However, species distribution models (SDMs) and, more recently,
deep learning-based variants offer a potential automated alternative. Deep
learning-based SDMs generate a continuous probability representing the
predicted presence of a species at a given location, which must be binarized by
setting per-species thresholds to obtain binary range maps. However, selecting
appropriate per-species thresholds to binarize these predictions is non-trivial
as different species can require distinct thresholds. In this work, we evaluate
different approaches for automatically identifying the best thresholds for
binarizing range maps using presence-only data. This includes approaches that
require the generation of additional pseudo-absence data, along with ones that
only require presence data. We also propose an extension of an existing
presence-only technique that is more robust to outliers. We perform a detailed
evaluation of different thresholding techniques on the tasks of binary range
estimation and large-scale fine-grained visual classification, and we
demonstrate improved performance over existing pseudo-absence free approaches
using our method.",2024-08-28,"Filip Dorm, Christian Lange, Scott Loarie, Oisin Mac Aodha",http://arxiv.org/pdf/2408.15956v1,cs.LG
Modeling and Analyzing the Influence of Non-Item Pages on Sequential Next-Item Prediction,"Analyzing sequences of interactions between users and items, sequential
recommendation models can learn user intent and make predictions about the next
item. Next to item interactions, most systems also have interactions with what
we call non-item pages: these pages are not related to specific items but still
can provide insights into the user's interests, as, for example, navigation
pages. We therefore propose a general way to include these non-item pages in
sequential recommendation models to enhance next-item prediction.
  First, we demonstrate the influence of non-item pages on following
interactions using the hypotheses testing framework HypTrails and propose
methods for representing non-item pages in sequential recommendation models.
Subsequently, we adapt popular sequential recommender models to integrate
non-item pages and investigate their performance with different item
representation strategies as well as their ability to handle noisy data. To
show the general capabilities of the models to integrate non-item pages, we
create a synthetic dataset for a controlled setting and then evaluate the
improvements from including non-item pages on two real-world datasets.
  Our results show that non-item pages are a valuable source of information,
and incorporating them in sequential recommendation models increases the
performance of next-item prediction across all analyzed model architectures.",2024-08-28,"Elisabeth Fischer, Albin Zehe, Andreas Hotho, Daniel Schlör",http://arxiv.org/pdf/2408.15953v4,cs.LG
Sigma Flows for Image and Data Labeling and Learning Structured Prediction,"This paper introduces the sigma flow model for the prediction of structured
labelings of data observed on Riemannian manifolds, including Euclidean image
domains as special case. The approach combines the Laplace-Beltrami framework
for image denoising and enhancement, introduced by Sochen, Kimmel and Malladi
about 25 years ago, and the assignment flow approach introduced and studied by
the authors.
  The sigma flow arises as Riemannian gradient flow of generalized harmonic
energies and thus is governed by a nonlinear geometric PDE which determines a
harmonic map from a closed Riemannian domain manifold to a statistical
manifold, equipped with the Fisher-Rao metric from information geometry. A
specific ingredient of the sigma flow is the mutual dependency of the
Riemannian metric of the domain manifold on the evolving state. This makes the
approach amenable to machine learning in a specific way, by realizing this
dependency through a mapping with compact time-variant parametrization that can
be learned from data. Proof of concept experiments demonstrate the expressivity
of the sigma flow model and prediction performance.
  Structural similarities to transformer network architectures and networks
generated by the geometric integration of sigma flows are pointed out, which
highlights the connection to deep learning and, conversely, may stimulate the
use of geometric design principles for structured prediction in other areas of
scientific machine learning.",2024-08-28,"Jonas Cassel, Bastian Boll, Stefania Petra, Peter Albers, Christoph Schnörr",http://arxiv.org/pdf/2408.15946v1,cs.LG
Generalized Naive Bayes,"In this paper we introduce the so-called Generalized Naive Bayes structure as
an extension of the Naive Bayes structure. We give a new greedy algorithm that
finds a good fitting Generalized Naive Bayes (GNB) probability distribution. We
prove that this fits the data at least as well as the probability distribution
determined by the classical Naive Bayes (NB). Then, under a not very
restrictive condition, we give a second algorithm for which we can prove that
it finds the optimal GNB probability distribution, i.e. best fitting structure
in the sense of KL divergence. Both algorithms are constructed to maximize the
information content and aim to minimize redundancy. Based on these algorithms,
new methods for feature selection are introduced. We discuss the similarities
and differences to other related algorithms in terms of structure, methodology,
and complexity. Experimental results show, that the algorithms introduced
outperform the related algorithms in many cases.",2024-08-28,"Edith Alice Kovács, Anna Ország, Dániel Pfeifer, András Benczúr",http://arxiv.org/pdf/2408.15923v1,cs.LG
Uncertainty-aware segmentation for rainfall prediction post processing,"Accurate precipitation forecasts are crucial for applications such as flood
management, agricultural planning, water resource allocation, and weather
warnings. Despite advances in numerical weather prediction (NWP) models, they
still exhibit significant biases and uncertainties, especially at high spatial
and temporal resolutions. To address these limitations, we explore
uncertainty-aware deep learning models for post-processing daily cumulative
quantitative precipitation forecasts to obtain forecast uncertainties that lead
to a better trade-off between accuracy and reliability. Our study compares
different state-of-the-art models, and we propose a variant of the well-known
SDE-Net, called SDE U-Net, tailored to segmentation problems like ours. We
evaluate its performance for both typical and intense precipitation events.
  Our results show that all deep learning models significantly outperform the
average baseline NWP solution, with our implementation of the SDE U-Net showing
the best trade-off between accuracy and reliability. Integrating these models,
which account for uncertainty, into operational forecasting systems can improve
decision-making and preparedness for weather-related events.",2024-08-28,"Simone Monaco, Luca Monaco, Daniele Apiletti",http://arxiv.org/pdf/2408.16792v1,cs.LG
Multi-modal Adversarial Training for Zero-Shot Voice Cloning,"A text-to-speech (TTS) model trained to reconstruct speech given text tends
towards predictions that are close to the average characteristics of a dataset,
failing to model the variations that make human speech sound natural. This
problem is magnified for zero-shot voice cloning, a task that requires training
data with high variance in speaking styles. We build off of recent works which
have used Generative Advsarial Networks (GAN) by proposing a Transformer
encoder-decoder architecture to conditionally discriminates between real and
generated speech features. The discriminator is used in a training pipeline
that improves both the acoustic and prosodic features of a TTS model. We
introduce our novel adversarial training technique by applying it to a
FastSpeech2 acoustic model and training on Libriheavy, a large multi-speaker
dataset, for the task of zero-shot voice cloning. Our model achieves
improvements over the baseline in terms of speech quality and speaker
similarity. Audio examples from our system are available online.",2024-08-28,"John Janiczek, Dading Chong, Dongyang Dai, Arlo Faria, Chao Wang, Tao Wang, Yuzong Liu",http://arxiv.org/pdf/2408.15916v1,cs.LG
MetaGFN: Exploring Distant Modes with Adapted Metadynamics for Continuous GFlowNets,"Generative Flow Networks (GFlowNets) are a class of generative models that
sample objects in proportion to a specified reward function through a learned
policy. They can be trained either on-policy or off-policy, needing a balance
between exploration and exploitation for fast convergence to a target
distribution. While exploration strategies for discrete GFlowNets have been
studied, exploration in the continuous case remains to be investigated, despite
the potential for novel exploration algorithms due to the local connectedness
of continuous domains. Here, we introduce Adapted Metadynamics, a variant of
metadynamics that can be applied to arbitrary black-box reward functions on
continuous domains. We use Adapted Metadynamics as an exploration strategy for
continuous GFlowNets. We show several continuous domains where the resulting
algorithm, MetaGFN, accelerates convergence to the target distribution and
discovers more distant reward modes than previous off-policy exploration
strategies used for GFlowNets.",2024-08-28,"Dominic Phillips, Flaviu Cipcigan",http://arxiv.org/pdf/2408.15905v2,cs.LG
Nexus: Specialization meets Adaptability for Efficiently Training Mixture of Experts,"Efficiency, specialization, and adaptability to new data distributions are
qualities that are hard to combine in current Large Language Models. The
Mixture of Experts (MoE) architecture has been the focus of significant
research because its inherent conditional computation enables such desirable
properties. In this work, we focus on ""upcycling"" dense expert models into an
MoE, aiming to improve specialization while also adding the ability to adapt to
new tasks easily. We introduce Nexus, an enhanced MoE architecture with
adaptive routing where the model learns to project expert embeddings from
domain representations. This approach allows Nexus to flexibly add new experts
after the initial upcycling through separately trained dense models, without
requiring large-scale MoE training for unseen data domains. Our experiments
show that Nexus achieves a relative gain of up to 2.1% over the baseline for
initial upcycling, and a 18.8% relative gain for extending the MoE with a new
expert by using limited finetuning data. This flexibility of Nexus is crucial
to enable an open-source ecosystem where every user continuously assembles
their own MoE-mix according to their needs.",2024-08-28,"Nikolas Gritsch, Qizhen Zhang, Acyr Locatelli, Sara Hooker, Ahmet Üstün",http://arxiv.org/pdf/2408.15901v1,cs.LG
Airfoil Diffusion: Denoising Diffusion Model For Conditional Airfoil Generation,"The design of aerodynamic shapes, such as airfoils, has traditionally
required significant computational resources and relied on predefined design
parameters, which limit the potential for novel shape synthesis. In this work,
we introduce a data-driven methodology for airfoil generation using a diffusion
model. Trained on a dataset of preexisting airfoils, our model can generate an
arbitrary number of new airfoils from random vectors, which can be conditioned
on specific aerodynamic performance metrics such as lift and drag, or geometric
criteria. Our results demonstrate that the diffusion model effectively produces
airfoil shapes with realistic aerodynamic properties, offering substantial
improvements in efficiency, flexibility, and the potential for discovering
innovative airfoil designs. This approach significantly expands the design
space, facilitating the synthesis of high-performance aerodynamic shapes that
transcend the limitations of traditional methods.",2024-08-28,"Reid Graves, Amir Barati Farimani",http://arxiv.org/pdf/2408.15898v3,cs.LG
A New Method for Cross-Lingual-based Semantic Role Labeling,"Semantic role labeling is a crucial task in natural language processing,
enabling better comprehension of natural language. However, the lack of
annotated data in multiple languages has posed a challenge for researchers. To
address this, a deep learning algorithm based on model transfer has been
proposed. The algorithm utilizes a dataset consisting of the English portion of
CoNLL2009 and a corpus of semantic roles in Persian. To optimize the efficiency
of training, only ten percent of the educational data from each language is
used. The results of the proposed model demonstrate significant improvements
compared to Niksirt et al.'s model. In monolingual mode, the proposed model
achieved a 2.05 percent improvement on F1-score, while in cross-lingual mode,
the improvement was even more substantial, reaching 6.23 percent. Worth noting
is that the compared model only trained two of the four stages of semantic role
labeling and employed golden data for the remaining two stages. This suggests
that the actual superiority of the proposed model surpasses the reported
numbers by a significant margin. The development of cross-lingual methods for
semantic role labeling holds promise, particularly in addressing the scarcity
of annotated data for various languages. These advancements pave the way for
further research in understanding and processing natural language across
different linguistic contexts.",2024-08-28,"Mohammad Ebrahimi, Behrouz Minaei Bidgoli, Nasim Khozouei",http://arxiv.org/pdf/2408.15896v1,cs.LG
Bias in LLMs as Annotators: The Effect of Party Cues on Labelling Decision by Large Language Models,"Human coders are biased. We test similar biases in Large Language Models
(LLMs) as annotators. By replicating an experiment run by Ennser-Jedenastik and
Meyer (2018), we find evidence that LLMs use political information, and
specifically party cues, to judge political statements. Not only do LLMs use
relevant information to contextualize whether a statement is positive,
negative, or neutral based on the party cue, they also reflect the biases of
the human-generated data upon which they have been trained. We also find that
unlike humans, who are only biased when faced with statements from extreme
parties, LLMs exhibit significant bias even when prompted with statements from
center-left and center-right parties. The implications of our findings are
discussed in the conclusion.",2024-08-28,"Sebastian Vallejo Vera, Hunter Driggers",http://arxiv.org/pdf/2408.15895v1,cs.LG
The Role of Fibration Symmetries in Geometric Deep Learning,"Geometric Deep Learning (GDL) unifies a broad class of machine learning
techniques from the perspectives of symmetries, offering a framework for
introducing problem-specific inductive biases like Graph Neural Networks
(GNNs). However, the current formulation of GDL is limited to global symmetries
that are not often found in real-world problems. We propose to relax GDL to
allow for local symmetries, specifically fibration symmetries in graphs, to
leverage regularities of realistic instances. We show that GNNs apply the
inductive bias of fibration symmetries and derive a tighter upper bound for
their expressive power. Additionally, by identifying symmetries in networks, we
collapse network nodes, thereby increasing their computational efficiency
during both inference and training of deep neural networks. The mathematical
extension introduced here applies beyond graphs to manifolds, bundles, and
grids for the development of models with inductive biases induced by local
symmetries that can lead to better generalization.",2024-08-28,"Osvaldo Velarde, Lucas Parra, Paolo Boldi, Hernan Makse",http://arxiv.org/pdf/2408.15894v1,cs.LG
Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version),"Outlier detection algorithms typically assign an outlier score to each
observation in a dataset, indicating the degree to which an observation is an
outlier. However, these scores are often not comparable across algorithms and
can be difficult for humans to interpret. Statistical scaling addresses this
problem by transforming outlier scores into outlier probabilities without using
ground-truth labels, thereby improving interpretability and comparability
across algorithms. However, the quality of this transformation can be different
for outliers and inliers. Missing outliers in scenarios where they are of
particular interest - such as healthcare, finance, or engineering - can be
costly or dangerous. Thus, ensuring good probabilities for outliers is
essential. This paper argues that statistical scaling, as commonly used in the
literature, does not produce equally good probabilities for outliers as for
inliers. Therefore, we propose robust statistical scaling, which uses robust
estimators to improve the probabilities for outliers. We evaluate several
variants of our method against other outlier score transformations for
real-world datasets and outlier detection algorithms, where it can improve the
probabilities for outliers.",2024-08-28,"Philipp Röchner, Henrique O. Marques, Ricardo J. G. B. Campello, Arthur Zimek, Franz Rothlauf",http://arxiv.org/pdf/2408.15874v3,cs.LG
Retrieval-Augmented Instruction Tuning for Automated Process Engineering Calculations : A Tool-Chaining Problem-Solving Framework with Attributable Reflection,"The current technology landscape lacks a foundational AI model for solving
process engineering calculations. In this work, we introduce a novel autonomous
agent framework leveraging Retrieval-Augmented Instruction-Tuning (RAIT) to
enhance open, customizable small code language models (SLMs) for these
calculations. By combining instruction tuned code SLMs with Retrieval-Augmented
Code Generation (RACG) using external tools, the agent generates, debugs, and
optimizes code from natural language specifications. Our approach addresses the
limitations of the current lack of a foundational AI model for specialized
process engineering tasks and offers benefits of explainability, knowledge
editing, and cost-effectiveness. Additionally, we curate custom datasets of
chemical and process engineering problems and solutions to overcome data
scarcity. Experimental results show that our framework matches the performance
of large-scale proprietary models on benchmark datasets, proving its
effectiveness and usability.",2024-08-28,"Sagar Srinivas Sakhinana, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2408.15866v1,cs.LG
microYOLO: Towards Single-Shot Object Detection on Microcontrollers,"This work-in-progress paper presents results on the feasibility of
single-shot object detection on microcontrollers using YOLO. Single-shot object
detectors like YOLO are widely used, however due to their complexity mainly on
larger GPU-based platforms. We present microYOLO, which can be used on Cortex-M
based microcontrollers, such as the OpenMV H7 R2, achieving about 3.5 FPS when
classifying 128x128 RGB images while using less than 800 KB Flash and less than
350 KB RAM. Furthermore, we share experimental results for three different
object detection tasks, analyzing the accuracy of microYOLO on them.",2024-08-28,"Mark Deutel, Christopher Mutschler, Jürgen Teich",http://arxiv.org/pdf/2408.15865v1,cs.LG
Fusing Pruned and Backdoored Models: Optimal Transport-based Data-free Backdoor Mitigation,"Backdoor attacks present a serious security threat to deep neuron networks
(DNNs). Although numerous effective defense techniques have been proposed in
recent years, they inevitably rely on the availability of either clean or
poisoned data. In contrast, data-free defense techniques have evolved slowly
and still lag significantly in performance. To address this issue, different
from the traditional approach of pruning followed by fine-tuning, we propose a
novel data-free defense method named Optimal Transport-based Backdoor Repairing
(OTBR) in this work. This method, based on our findings on neuron weight
changes (NWCs) of random unlearning, uses optimal transport (OT)-based model
fusion to combine the advantages of both pruned and backdoored models.
Specifically, we first demonstrate our findings that the NWCs of random
unlearning are positively correlated with those of poison unlearning. Based on
this observation, we propose a random-unlearning NWC pruning technique to
eliminate the backdoor effect and obtain a backdoor-free pruned model. Then,
motivated by the OT-based model fusion, we propose the pruned-to-backdoored
OT-based fusion technique, which fuses pruned and backdoored models to combine
the advantages of both, resulting in a model that demonstrates high clean
accuracy and a low attack success rate. To our knowledge, this is the first
work to apply OT and model fusion techniques to backdoor defense. Extensive
experiments show that our method successfully defends against all seven
backdoor attacks across three benchmark datasets, outperforming both
state-of-the-art (SOTA) data-free and data-dependent methods. The code
implementation and Appendix are provided in the Supplementary Material.",2024-08-28,"Weilin Lin, Li Liu, Jianze Li, Hui Xiong",http://arxiv.org/pdf/2408.15861v1,cs.LG
chemtrain: Learning Deep Potential Models via Automatic Differentiation and Statistical Physics,"Neural Networks (NNs) are effective models for refining the accuracy of
molecular dynamics, opening up new fields of application. Typically trained
bottom-up, atomistic NN potential models can reach first-principle accuracy,
while coarse-grained implicit solvent NN potentials surpass classical continuum
solvent models. However, overcoming the limitations of costly generation of
accurate reference data and data inefficiency of common bottom-up training
demands efficient incorporation of data from many sources. This paper
introduces the framework chemtrain to learn sophisticated NN potential models
through customizable training routines and advanced training algorithms. These
routines can combine multiple top-down and bottom-up algorithms, e.g., to
incorporate both experimental and simulation data or pre-train potentials with
less costly algorithms. chemtrain provides an object-oriented high-level
interface to simplify the creation of custom routines. On the lower level,
chemtrain relies on JAX to compute gradients and scale the computations to use
available resources. We demonstrate the simplicity and importance of combining
multiple algorithms in the examples of parametrizing an all-atomistic model of
titanium and a coarse-grained implicit solvent model of alanine dipeptide.",2024-08-28,"Paul Fuchs, Stephan Thaler, Sebastien Röcken, Julija Zavadlav",http://arxiv.org/pdf/2408.15852v2,cs.LG
AutoGeo: Automating Geometric Image Dataset Creation for Enhanced Geometry Understanding,"With the rapid advancement of large language models, there has been a growing
interest in their capabilities in mathematical reasoning. However, existing
research has primarily focused on text-based algebra problems, neglecting the
study of geometry due to the lack of high-quality geometric datasets. To
address this gap, this paper introduces AutoGeo, a novel approach for
automatically generating mathematical geometric images to fulfill the demand
for large-scale and diverse geometric datasets. AutoGeo facilitates the
creation of AutoGeo-100k, an extensive repository comprising 100k high-quality
geometry image-text pairs. By leveraging precisely defined geometric clauses,
AutoGeo-100k contains a wide variety of geometric shapes, including lines,
polygons, circles, and complex spatial relationships, etc. Furthermore, this
paper demonstrates the efficacy of AutoGeo-100k in enhancing the performance of
multimodal large language models through fine-tuning. Experimental results
indicate significant improvements in the model's ability in handling geometric
images, as evidenced by enhanced accuracy in tasks such as geometric captioning
and mathematical reasoning. This research not only fills a critical gap in the
availability of geometric datasets but also paves the way for the advancement
of sophisticated AI-driven tools in education and research. Project page:
https://autogeo-official.github.io/.",2024-08-28,"Zihan Huang, Tao Wu, Wang Lin, Shengyu Zhang, Jingyuan Chen, Fei Wu",http://arxiv.org/pdf/2409.09039v1,cs.LG
Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification,"As the field of artificial intelligence progresses, assistive technologies
are becoming more widely used across all industries. The healthcare industry is
no different, with numerous studies being done to develop assistive tools for
healthcare professionals. Automatic diagnostic systems are one such beneficial
tool that can assist with a variety of tasks, including collecting patient
information, analyzing test results, and diagnosing patients. However, the idea
of developing systems that can provide a differential diagnosis has been
largely overlooked in most of these research studies. In this study, we propose
a transformer-based approach for providing differential diagnoses based on a
patient's age, sex, medical history, and symptoms. We use the DDXPlus dataset,
which provides differential diagnosis information for patients based on 49
disease types. Firstly, we propose a method to process the tabular patient data
from the dataset and engineer them into patient reports to make them suitable
for our research. In addition, we introduce two data modification modules to
diversify the training data and consequently improve the robustness of the
models. We approach the task as a multi-label classification problem and
conduct extensive experiments using four transformer models. All the models
displayed promising results by achieving over 97% F1 score on the held-out test
set. Moreover, we design additional behavioral tests to get a broader
understanding of the models. In particular, for one of our test cases, we
prepared a custom test set of 100 samples with the assistance of a doctor. The
results on the custom set showed that our proposed data modification modules
improved the model's generalization capabilities. We hope our findings will
provide future researchers with valuable insights and inspire them to develop
reliable systems for automatic differential diagnosis.",2024-08-28,"Abu Adnan Sadi, Mohammad Ashrafuzzaman Khan, Lubaba Binte Saber",http://arxiv.org/pdf/2408.15827v1,cs.LG
Automated Mixture Analysis via Structural Evaluation,"The determination of chemical mixture components is vital to a multitude of
scientific fields. Oftentimes spectroscopic methods are employed to decipher
the composition of these mixtures. However, the sheer density of spectral
features present in spectroscopic databases can make unambiguous assignment to
individual species challenging. Yet, components of a mixture are commonly
chemically related due to environmental processes or shared precursor
molecules. Therefore, analysis of the chemical relevance of a molecule is
important when determining which species are present in a mixture. In this
paper, we combine machine-learning molecular embedding methods with a
graph-based ranking system to determine the likelihood of a molecule being
present in a mixture based on the other known species and/or chemical priors.
By incorporating this metric in a rotational spectroscopy mixture analysis
algorithm, we demonstrate that the mixture components can be identified with
extremely high accuracy (>97%) in an efficient manner.",2024-08-28,"Zachary T. P. Fried, Brett A. McGuire",http://arxiv.org/pdf/2408.15819v1,cs.LG
"Analysis of Diagnostics (Part II): Prevalence, Linear Independence, and Unsupervised Learning","This is the second manuscript in a two-part series that uses diagnostic
testing to understand the connection between prevalence (i.e. number of
elements in a class), uncertainty quantification (UQ), and classification
theory. Part I considered the context of supervised machine learning (ML) and
established a duality between prevalence and the concept of relative
conditional probability. The key idea of that analysis was to train a family of
discriminative classifiers by minimizing a sum of prevalence-weighted empirical
risk functions. The resulting outputs can be interpreted as relative
probability level-sets, which thereby yield uncertainty estimates in the class
labels. This procedure also demonstrated that certain discriminative and
generative ML models are equivalent. Part II considers the extent to which
these results can be extended to tasks in unsupervised learning through
recourse to ideas in linear algebra. We first observe that the distribution of
an impure population, for which the class of a corresponding sample is unknown,
can be parameterized in terms of a prevalence. This motivates us to introduce
the concept of linearly independent populations, which have different but
unknown prevalence values. Using this, we identify an isomorphism between
classifiers defined in terms of impure and pure populations. In certain cases,
this also leads to a nonlinear system of equations whose solution yields the
prevalence values of the linearly independent populations, fully realizing
unsupervised learning as a generalization of supervised learning. We illustrate
our methods in the context of synthetic data and a research-use-only SARS-CoV-2
enzyme-linked immunosorbent assay (ELISA).",2024-08-28,"Paul N. Patrone, Raquel A. Binder, Catherine S. Forconi, Ann M. Moormann, Anthony J. Kearsley",http://arxiv.org/pdf/2408.16035v1,cs.LG
Language Adaptation on a Tight Academic Compute Budget: Tokenizer Swapping Works and Pure bfloat16 Is Enough,"We investigate continued pretraining of LLMs for language adaptation on a
tight academic budget: a setting in which only a few GPUs can be used in
parallel, for a heavily constrained duration. We focus on adapting Mistral-7B
to German or Arabic and evaluate several techniques to improve efficiency and
effectiveness in this setting. Our German models adapted on this tight compute
budget underperform compared to the base Mistral-7B, while our Arabic models
outperform several baselines, showing that for sufficiently well-represented
languages, continued pretraining for specialization is not always helpful. Our
main findings focus on training precision and tokenizer swapping. Our results
show that pure bfloat16 training is a viable alternative to mixed-precision
training, while being much faster when only using a few GPUs. Swapping the
tokenizer for a specialized one yields more efficient tokenization and is
competitive with the original tokenizer, which already contains some German
tokens, but did not significantly increase performance for German. Code and
model weights are available at on GitHub.",2024-08-28,"Konstantin Dobler, Gerard de Melo",http://arxiv.org/pdf/2408.15793v1,cs.LG
Efficient LLM Scheduling by Learning to Rank,"In Large Language Model (LLM) inference, the output length of an LLM request
is typically regarded as not known a priori. Consequently, most LLM serving
systems employ a simple First-come-first-serve (FCFS) scheduling strategy,
leading to Head-Of-Line (HOL) blocking and reduced throughput and service
quality. In this paper, we reexamine this assumption -- we show that, although
predicting the exact generation length of each request is infeasible, it is
possible to predict the relative ranks of output lengths in a batch of
requests, using learning to rank. The ranking information offers valuable
guidance for scheduling requests. Building on this insight, we develop a novel
scheduler for LLM inference and serving that can approximate the
shortest-job-first (SJF) schedule better than existing approaches. We integrate
this scheduler with the state-of-the-art LLM serving system and show
significant performance improvement in several important applications: 2.8x
lower latency in chatbot serving and 6.5x higher throughput in synthetic data
generation. Our code is available at https://github.com/hao-ai-lab/vllm-ltr.git",2024-08-28,"Yichao Fu, Siqi Zhu, Runlong Su, Aurick Qiao, Ion Stoica, Hao Zhang",http://arxiv.org/pdf/2408.15792v1,cs.LG
Brant-X: A Unified Physiological Signal Alignment Framework,"Physiological signals serve as indispensable clues for understanding various
physiological states of human bodies. Most existing works have focused on a
single type of physiological signals for a range of application scenarios.
However, as the body is a holistic biological system, the inherent
interconnection among various physiological data should not be neglected. In
particular, given the brain's role as the control center for vital activities,
electroencephalogram (EEG) exhibits significant correlations with other
physiological signals. Therefore, the correlation between EEG and other
physiological signals holds potential to improve performance in various
scenarios. Nevertheless, achieving this goal is still constrained by several
challenges: the scarcity of simultaneously collected physiological data, the
differences in correlations between various signals, and the correlation
differences between various tasks. To address these issues, we propose a
unified physiological signal alignment framework, Brant-X, to model the
correlation between EEG and other signals. Our approach (1) employs the EEG
foundation model to data-efficiently transfer the rich knowledge in EEG to
other physiological signals, and (2) introduces the two-level alignment to
fully align the semantics of EEG and other signals from different semantic
scales. In the experiments, Brant-X achieves state-of-the-art performance
compared with task-agnostic and task-specific baselines on various downstream
tasks in diverse scenarios, including sleep stage classification, emotion
recognition, freezing of gaits detection, and eye movement communication.
Moreover, the analysis on the arrhythmia detection task and the visualization
in case study further illustrate the effectiveness of Brant-X in the knowledge
transfer from EEG to other physiological signals. The model's homepage is at
https://github.com/zjunet/Brant-X/.",2024-08-28,"Daoze Zhang, Zhizhang Yuan, Junru Chen, Kerui Chen, Yang Yang",http://arxiv.org/pdf/2409.00122v1,cs.LG
Implicit Regularization Paths of Weighted Neural Representations,"We study the implicit regularization effects induced by (observation)
weighting of pretrained features. For weight and feature matrices of bounded
operator norms that are infinitesimally free with respect to (normalized) trace
functionals, we derive equivalence paths connecting different weighting
matrices and ridge regularization levels. Specifically, we show that ridge
estimators trained on weighted features along the same path are asymptotically
equivalent when evaluated against test vectors of bounded norms. These paths
can be interpreted as matching the effective degrees of freedom of ridge
estimators fitted with weighted features. For the special case of subsampling
without replacement, our results apply to independently sampled random features
and kernel features and confirm recent conjectures (Conjectures 7 and 8) of the
authors on the existence of such paths in Patil et al. We also present an
additive risk decomposition for ensembles of weighted estimators and show that
the risks are equivalent along the paths when the ensemble size goes to
infinity. As a practical consequence of the path equivalences, we develop an
efficient cross-validation method for tuning and apply it to subsampled
pretrained representations across several models (e.g., ResNet-50) and datasets
(e.g., CIFAR-100).",2024-08-28,"Jin-Hong Du, Pratik Patil",http://arxiv.org/pdf/2408.15784v1,cs.LG
wav2pos: Sound Source Localization using Masked Autoencoders,"We present a novel approach to the 3D sound source localization task for
distributed ad-hoc microphone arrays by formulating it as a set-to-set
regression problem. By training a multi-modal masked autoencoder model that
operates on audio recordings and microphone coordinates, we show that such a
formulation allows for accurate localization of the sound source, by
reconstructing coordinates masked in the input. Our approach is flexible in the
sense that a single model can be used with an arbitrary number of microphones,
even when a subset of audio recordings and microphone coordinates are missing.
We test our method on simulated and real-world recordings of music and speech
in indoor environments, and demonstrate competitive performance compared to
both classical and other learning based localization methods.",2024-08-28,"Axel Berg, Jens Gulin, Mark O'Connor, Chuteng Zhou, Karl Åström, Magnus Oskarsson",http://arxiv.org/pdf/2408.15771v1,cs.LG
Learning Harmonized Representations for Speculative Sampling,"Speculative sampling is a promising approach to accelerate the decoding stage
for Large Language Models (LLMs). Recent advancements that leverage target
LLM's contextual information, such as hidden states and KV cache, have shown
significant practical improvements. However, these approaches suffer from
inconsistent context between training and decoding. We also observe another
discrepancy between the training and decoding objectives in existing
speculative sampling methods. In this work, we propose a solution named
HArmonized Speculative Sampling (HASS) that learns harmonized representations
to address these issues. HASS accelerates the decoding stage without adding
inference overhead through harmonized objective distillation and harmonized
context alignment. Experiments on four LLaMA models demonstrate that HASS
achieves 2.81x-4.05x wall-clock time speedup ratio averaging across three
datasets, surpassing EAGLE-2 by 8%-20%. The code is available at
https://github.com/HArmonizedSS/HASS.",2024-08-28,"Lefan Zhang, Xiaodan Wang, Yanhua Huang, Ruiwen Xu",http://arxiv.org/pdf/2408.15766v3,cs.LG
Systematic Evaluation of Synthetic Data Augmentation for Multi-class NetFlow Traffic,"The detection of cyber-attacks in computer networks is a crucial and ongoing
research challenge. Machine learning-based attack classification offers a
promising solution, as these models can be continuously updated with new data,
enhancing the effectiveness of network intrusion detection systems (NIDS).
Unlike binary classification models that simply indicate the presence of an
attack, multi-class models can identify specific types of attacks, allowing for
more targeted and effective incident responses. However, a significant drawback
of these classification models is their sensitivity to imbalanced training
data. Recent advances suggest that generative models can assist in data
augmentation, claiming to offer superior solutions for imbalanced datasets.
Classical balancing methods, although less novel, also provide potential
remedies for this issue. Despite these claims, a comprehensive comparison of
these methods within the NIDS domain is lacking. Most existing studies focus
narrowly on individual methods, making it difficult to compare results due to
varying experimental setups. To close this gap, we designed a systematic
framework to compare classical and generative resampling methods for class
balancing across multiple popular classification models in the NIDS domain,
evaluated on several NIDS benchmark datasets. Our experiments indicate that
resampling methods for balancing training data do not reliably improve
classification performance. Although some instances show performance
improvements, the majority of results indicate decreased performance, with no
consistent trend in favor of a specific resampling technique enhancing a
particular classifier.",2024-08-28,"Maximilian Wolf, Dieter Landes, Andreas Hotho, Daniel Schlör",http://arxiv.org/pdf/2408.16034v1,cs.LG
A Neural Material Point Method for Particle-based Emulation,"Mesh-free Lagrangian methods are widely used for simulating fluids, solids,
and their complex interactions due to their ability to handle large
deformations and topological changes. These physics simulators, however,
require substantial computational resources for accurate simulations. To
address these issues, deep learning emulators promise faster and scalable
simulations, yet they often remain expensive and difficult to train, limiting
their practical use. Inspired by the Material Point Method (MPM), we present
NeuralMPM, a neural emulation framework for particle-based simulations.
NeuralMPM interpolates Lagrangian particles onto a fixed-size grid, computes
updates on grid nodes using image-to-image neural networks, and interpolates
back to the particles. Similarly to MPM, NeuralMPM benefits from the regular
voxelized representation to simplify the computation of the state dynamics,
while avoiding the drawbacks of mesh-based Eulerian methods. We demonstrate the
advantages of NeuralMPM on several datasets, including fluid dynamics and
fluid-solid interactions. Compared to existing methods, NeuralMPM reduces
training times from days to hours, while achieving comparable or superior
long-term accuracy, making it a promising approach for practical forward and
inverse problems. A project page is available at https://neuralmpm.isach.be",2024-08-28,"Omer Rochman Sharabi, Sacha Lewin, Gilles Louppe",http://arxiv.org/pdf/2408.15753v3,cs.LG
BELT-2: Bootstrapping EEG-to-Language representation alignment for multi-task brain decoding,"The remarkable success of large language models (LLMs) across various
multi-modality applications is well established. However, integrating large
language models with humans, or brain dynamics, remains relatively unexplored.
In this paper, we introduce BELT-2, a pioneering multi-task model designed to
enhance both encoding and decoding performance from EEG signals. To bolster the
quality of the EEG encoder, BELT-2 is the first work to innovatively 1) adopt
byte-pair encoding (BPE)-level EEG-language alignment and 2) integrate
multi-task training and decoding in the EEG domain. Inspired by the idea of
\textbf{\textit{Bridging the Brain with GPT}}, we further connect the
multi-task EEG encoder with LLMs by utilizing prefix-tuning on intermediary
output from the EEG encoder. These innovative efforts make BELT-2 a pioneering
breakthrough, making it the first work in the field capable of decoding
coherent and readable sentences from non-invasive brain signals. Our
experiments highlight significant advancements over prior techniques in both
quantitative and qualitative measures, achieving a decoding performance with a
BLEU-1 score of 52.2\% on the ZuCo dataset. Furthermore, BELT-2 shows a
remarkable improvement ranging from 31\% to 162\% on other translation
benchmarks. Codes can be accessed via the provided anonymous
link~\footnote{https://anonymous.4open.science/r/BELT-2-0048}.",2024-08-28,"Jinzhao Zhou, Yiqun Duan, Fred Chang, Thomas Do, Yu-Kai Wang, Chin-Teng Lin",http://arxiv.org/pdf/2409.00121v1,cs.LG
Advanced POD-Based Performance Evaluation of Classifiers Applied to Human Driver Lane Changing Prediction,"Machine learning (ML) classifiers serve as essential tools facilitating
classification and prediction across various domains. The performance of these
algorithms should be known to ensure their reliable application. In certain
fields, receiver operating characteristic and precision-recall curves are
frequently employed to assess machine learning algorithms without accounting
for the impact of process parameters. However, it may be essential to evaluate
the performance of these algorithms in relation to such parameters. As a
performance evaluation metric capable of considering the effects of process
parameters, this paper uses a modified probability of detection (POD) approach
to assess the reliability of ML-based algorithms. As an example, the POD-based
approach is employed to assess ML models used for predicting the lane changing
behavior of a vehicle driver. The time remaining to the predicted (and
therefore unknown) lane changing event is considered as process parameter. The
hit/miss approach to POD is taken here and modified by considering the
probability of lane changing derived from ML algorithms at each time step, and
obtaining the final result of the analysis accordingly. This improves the
reliability of results compared to the standard hit/miss approach, which
considers the outcome of the classifiers as either 0 or 1, while also
simplifying evaluation compared to the \^a versus a approach. Performance
evaluation results of the proposed approach are compared with those obtained
with the standard hit/miss approach and a pre-developed \^a versus a approach
to validate the effectiveness of the proposed method. The comparison shows that
this method provides an averaging conservative behavior with the advantage of
enhancing the reliability of the hit/miss approach to POD while retaining its
simplicity.",2024-08-28,"Zahra Rastin, Dirk Söffker",http://arxiv.org/pdf/2408.15722v1,cs.LG
Autoregressive model path dependence near Ising criticality,"Autoregressive models are a class of generative model that probabilistically
predict the next output of a sequence based on previous inputs. The
autoregressive sequence is by definition one-dimensional (1D), which is natural
for language tasks and hence an important component of modern architectures
like recurrent neural networks (RNNs) and transformers. However, when language
models are used to predict outputs on physical systems that are not
intrinsically 1D, the question arises of which choice of autoregressive
sequence -- if any -- is optimal. In this paper, we study the reconstruction of
critical correlations in the two-dimensional (2D) Ising model, using RNNs and
transformers trained on binary spin data obtained near the thermal phase
transition. We compare the training performance for a number of different 1D
autoregressive sequences imposed on finite-size 2D lattices. We find that paths
with long 1D segments are more efficient at training the autoregressive models
compared to space-filling curves that better preserve the 2D locality. Our
results illustrate the potential importance in choosing the optimal
autoregressive sequence ordering when training modern language models for tasks
in physics.",2024-08-28,"Yi Hong Teoh, Roger G. Melko",http://arxiv.org/pdf/2408.15715v1,cs.LG
Pixels to Prose: Understanding the art of Image Captioning,"In the era of evolving artificial intelligence, machines are increasingly
emulating human-like capabilities, including visual perception and linguistic
expression. Image captioning stands at the intersection of these domains,
enabling machines to interpret visual content and generate descriptive text.
This paper provides a thorough review of image captioning techniques, catering
to individuals entering the field of machine learning who seek a comprehensive
understanding of available options, from foundational methods to
state-of-the-art approaches. Beginning with an exploration of primitive
architectures, the review traces the evolution of image captioning models to
the latest cutting-edge solutions. By dissecting the components of these
architectures, readers gain insights into the underlying mechanisms and can
select suitable approaches tailored to specific problem requirements without
duplicating efforts. The paper also delves into the application of image
captioning in the medical domain, illuminating its significance in various
real-world scenarios.
  Furthermore, the review offers guidance on evaluating the performance of
image captioning systems, highlighting key metrics for assessment. By
synthesizing theoretical concepts with practical application, this paper equips
readers with the knowledge needed to navigate the complex landscape of image
captioning and harness its potential for diverse applications in machine
learning and beyond.",2024-08-28,"Hrishikesh Singh, Aarti Sharma, Millie Pant",http://arxiv.org/pdf/2408.15714v1,cs.LG
Activation function optimization method: Learnable series linear units (LSLUs),"Effective activation functions introduce non-linear transformations,
providing neural networks with stronger fitting capa-bilities, which help them
better adapt to real data distributions. Huawei Noah's Lab believes that
dynamic activation functions are more suitable than static activation functions
for enhancing the non-linear capabilities of neural networks. Tsinghua
University's related research also suggests using dynamically adjusted
activation functions. Building on the ideas of using fine-tuned activation
functions from Tsinghua University and Huawei Noah's Lab, we propose a
series-based learnable ac-tivation function called LSLU (Learnable Series
Linear Units). This method simplifies deep learning networks while im-proving
accuracy. This method introduces learnable parameters {\theta} and {\omega} to
control the activation function, adapting it to the current layer's training
stage and improving the model's generalization. The principle is to increase
non-linearity in each activation layer, boosting the network's overall
non-linearity. We evaluate LSLU's performance on CIFAR10, CIFAR100, and
specific task datasets (e.g., Silkworm), validating its effectiveness. The
convergence behavior of the learnable parameters {\theta} and {\omega}, as well
as their effects on generalization, are analyzed. Our empirical results show
that LSLU enhances the general-ization ability of the original model in various
tasks while speeding up training. In VanillaNet training, parameter {\theta}
initially decreases, then increases before stabilizing, while {\omega} shows an
opposite trend. Ultimately, LSLU achieves a 3.17% accuracy improvement on
CIFAR100 for VanillaNet (Table 3). Codes are available at
https://github.com/vontran2021/Learnable-series-linear-units-LSLU.",2024-08-28,"Chuan Feng, Xi Lin, Shiping Zhu, Hongkang Shi, Maojie Tang, Hua Huang",http://arxiv.org/pdf/2409.08283v1,cs.LG
Evaluating Model Robustness Using Adaptive Sparse L0 Regularization,"Deep Neural Networks have demonstrated remarkable success in various domains
but remain susceptible to adversarial examples, which are slightly altered
inputs designed to induce misclassification. While adversarial attacks
typically optimize under Lp norm constraints, attacks based on the L0 norm,
prioritising input sparsity, are less studied due to their complex and non
convex nature. These sparse adversarial examples challenge existing defenses by
altering a minimal subset of features, potentially uncovering more subtle DNN
weaknesses. However, the current L0 norm attack methodologies face a trade off
between accuracy and efficiency either precise but computationally intense or
expedient but imprecise. This paper proposes a novel, scalable, and effective
approach to generate adversarial examples based on the L0 norm, aimed at
refining the robustness evaluation of DNNs against such perturbations.",2024-08-28,"Weiyou Liu, Zhenyang Li, Weitong Chen",http://arxiv.org/pdf/2408.15702v1,cs.LG
An Extremely Data-efficient and Generative LLM-based Reinforcement Learning Agent for Recommenders,"Recent advancements in large language models (LLMs) have enabled
understanding webpage contexts, product details, and human instructions.
Utilizing LLMs as the foundational architecture for either reward models or
policies in reinforcement learning has gained popularity -- a notable
achievement is the success of InstructGPT. RL algorithms have been instrumental
in maximizing long-term customer satisfaction and avoiding short-term, myopic
goals in industrial recommender systems, which often rely on deep learning
models to predict immediate clicks or purchases.
  In this project, several RL methods are implemented and evaluated using the
WebShop benchmark environment, data, simulator, and pre-trained model
checkpoints. The goal is to train an RL agent to maximize the purchase reward
given a detailed human instruction describing a desired product. The RL agents
are developed by fine-tuning a pre-trained BERT model with various objectives,
learning from preferences without a reward model, and employing contemporary
training techniques such as Proximal Policy Optimization (PPO) as used in
InstructGPT, and Direct Preference Optimization (DPO). This report also
evaluates the RL agents trained using generative trajectories. Evaluations were
conducted using Thompson sampling in the WebShop simulator environment.
  The simulated online experiments demonstrate that agents trained on generated
trajectories exhibited comparable task performance to those trained using human
trajectories. This has demonstrated an example of an extremely low-cost
data-efficient way of training reinforcement learning agents. Also, with
limited training time (<2hours), without utilizing any images, a DPO agent
achieved a 19% success rate after approximately 3000 steps or 30 minutes of
training on T4 GPUs, compared to a PPO agent, which reached a 15% success rate.",2024-08-28,"Shuang Feng, Grace Feng",http://arxiv.org/pdf/2408.16032v1,cs.LG
EMP: Enhance Memory in Data Pruning,"Recently, large language and vision models have shown strong performance, but
due to high pre-training and fine-tuning costs, research has shifted towards
faster training via dataset pruning. Previous methods used sample loss as an
evaluation criterion, aiming to select the most ""difficult"" samples for
training. However, when the pruning rate increases, the number of times each
sample is trained becomes more evenly distributed, which causes many critical
or general samples to not be effectively fitted. We refer to this as
Low-Frequency Learning (LFL). In other words, LFL prevents the model from
remembering most samples. In our work, we decompose the scoring function of
LFL, provide a theoretical explanation for the inefficiency of LFL, and propose
adding a memory term to the scoring function to enhance the model's memory
capability, along with an approximation of this memory term. Similarly, we
explore memory in Self-Supervised Learning (SSL), marking the first discussion
on SSL memory. Using contrastive learning, we derive the memory term both
theoretically and experimentally. Finally, we propose Enhance Memory Pruning
(EMP), which addresses the issue of insufficient memory under high pruning
rates by enhancing the model's memory of data, thereby improving its
performance. We evaluated the performance of EMP in tasks such as image
classification, natural language understanding, and model pre-training. The
results show that EMP can improve model performance under extreme pruning
rates. For example, in the CIFAR100-ResNet50 pre-training task, with 70\%
pruning, EMP outperforms current methods by 2.2\%.",2024-08-28,"Jinying Xiao, Ping Li, Jie Nie, Zhe Tang",http://arxiv.org/pdf/2408.16031v1,cs.LG
Towards reliable respiratory disease diagnosis based on cough sounds and vision transformers,"Recent advancements in deep learning techniques have sparked performance
boosts in various real-world applications including disease diagnosis based on
multi-modal medical data. Cough sound data-based respiratory disease (e.g.,
COVID-19 and Chronic Obstructive Pulmonary Disease) diagnosis has also
attracted much attention. However, existing works usually utilise traditional
machine learning or deep models of moderate scales. On the other hand, the
developed approaches are trained and evaluated on small-scale data due to the
difficulty of curating and annotating clinical data on scale. To address these
issues in prior works, we create a unified framework to evaluate various deep
models from lightweight Convolutional Neural Networks (e.g., ResNet18) to
modern vision transformers and compare their performance in respiratory disease
classification. Based on the observations from such an extensive empirical
study, we propose a novel approach to cough-based disease classification based
on both self-supervised and supervised learning on a large-scale cough data
set. Experimental results demonstrate our proposed approach outperforms prior
arts consistently on two benchmark datasets for COVID-19 diagnosis and a
proprietary dataset for COPD/non-COPD classification with an AUROC of 92.5%.",2024-08-28,"Qian Wang, Zhaoyang Bu, Jiaxuan Mao, Wenyu Zhu, Jingya Zhao, Wei Du, Guochao Shi, Min Zhou, Si Chen, Jieming Qu",http://arxiv.org/pdf/2408.15667v2,cs.LG
Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts,"For Mixture-of-Experts (MoE) models, an unbalanced expert load will lead to
routing collapse or increased computational overhead. Existing methods commonly
employ an auxiliary loss to encourage load balance, but a large auxiliary loss
will introduce non-negligible interference gradients into training and thus
impair the model performance. In order to control load balance while not
producing undesired gradients during training, we propose Loss-Free Balancing,
featured by an auxiliary-loss-free load balancing strategy. To be specific,
before the top-K routing decision, Loss-Free Balancing will first apply an
expert-wise bias to the routing scores of each expert. By dynamically updating
the bias of each expert according to its recent load, Loss-Free Balancing can
consistently maintain a balanced distribution of expert load. In addition,
since Loss-Free Balancing does not produce any interference gradients, it also
elevates the upper bound of model performance gained from MoE training. We
validate the performance of Loss-Free Balancing on MoE models with up to 3B
parameters trained on up to 200B tokens. Experimental results show that
Loss-Free Balancing achieves both better performance and better load balance
compared with traditional auxiliary-loss-controlled load balancing strategies.",2024-08-28,"Lean Wang, Huazuo Gao, Chenggang Zhao, Xu Sun, Damai Dai",http://arxiv.org/pdf/2408.15664v1,cs.LG
Deep Learning-Based Automatic Multi-Level Airway Collapse Monitoring on Obstructive Sleep Apnea Patients,"This study investigated the use of deep learning to identify multi-level
upper airway collapses in obstructive sleep apnea (OSA) patients based on
snoring sounds. We fi-ne-tuned ResNet-50 and Audio Spectrogram Transformer
(AST) models using snoring recordings from 37 subjects undergoing drug-induced
sleep endoscopy (DISE) between 2020 and 2021. Snoring sounds were labeled
according to the VOTE (Velum, Orophar-ynx, Tongue Base, Epiglottis)
classification, resulting in 259 V, 403 O, 77 T, 13 E, 1016 VO, 46 VT, 140 OT,
39 OE, 30 VOT, and 3150 non-snoring (N) 0.5-second clips. The models were
trained for two multi-label classification tasks: identifying obstructions at
V, O, T, and E levels, and identifying retropalatal (RP) and retroglossal (RG)
obstruc-tions. Results showed AST slightly outperformed ResNet-50,
demonstrating good abil-ity to identify V (F1-score: 0.71, MCC: 0.61, AUC:
0.89), O (F1-score: 0.80, MCC: 0.72, AUC: 0.94), and RP obstructions (F1-score:
0.86, MCC: 0.77, AUC: 0.97). However, both models struggled with T, E, and RG
classifications due to limited data. Retrospective analysis of a full-night
recording showed the potential to profile airway obstruction dynamics. We
expect this information, combined with polysomnography and other clinical
parameters, can aid clinical triage and treatment planning for OSA patients.",2024-08-28,"Ying-Chieh Hsu, Stanley Yung-Chuan Liu, Chao-Jung Huang, Chi-Wei Wu, Ren-Kai Cheng, Jane Yung-Jen Hsu, Shang-Ran Huang, Yuan-Ren Cheng, Fu-Shun Hsu",http://arxiv.org/pdf/2408.16030v2,cs.LG
GANs Conditioning Methods: A Survey,"In recent years, Generative Adversarial Networks (GANs) have seen significant
advancements, leading to their widespread adoption across various fields. The
original GAN architecture enables the generation of images without any specific
control over the content, making it an unconditional generation process.
However, many practical applications require precise control over the generated
output, which has led to the development of conditional GANs (cGANs) that
incorporate explicit conditioning to guide the generation process. cGANs extend
the original framework by incorporating additional information (conditions),
enabling the generation of samples that adhere to that specific criteria.
Various conditioning methods have been proposed, each differing in how they
integrate the conditioning information into both the generator and the
discriminator networks. In this work, we review the conditioning methods
proposed for GANs, exploring the characteristics of each method and
highlighting their unique mechanisms and theoretical foundations. Furthermore,
we conduct a comparative analysis of these methods, evaluating their
performance on various image datasets. Through these analyses, we aim to
provide insights into the strengths and limitations of various conditioning
techniques, guiding future research and application in generative modeling.",2024-08-28,"Anis Bourou, Valérie Mezger, Auguste Genovesio",http://arxiv.org/pdf/2408.15640v3,cs.LG
"3-in-1: 2D Rotary Adaptation for Efficient Finetuning, Efficient Batching and Composability","Parameter-efficient finetuning (PEFT) methods effectively adapt large
language models (LLMs) to diverse downstream tasks, reducing storage and GPU
memory demands. Despite these advantages, several applications pose new
challenges to PEFT beyond mere parameter efficiency. One notable challenge
involves the efficient deployment of LLMs equipped with multiple task- or
user-specific adapters, particularly when different adapters are needed for
distinct requests within the same batch. Another challenge is the
interpretability of LLMs, which is crucial for understanding how LLMs function.
Previous studies introduced various approaches to address different challenges.
In this paper, we introduce a novel method, RoAd, which employs a
straightforward 2D rotation to adapt LLMs and addresses all the above
challenges: (1) RoAd is remarkably parameter-efficient, delivering optimal
performance on GLUE, eight commonsense reasoning tasks and four arithmetic
reasoning tasks with $<0.1\%$ trainable parameters; (2) RoAd facilitates the
efficient serving of requests requiring different adapters within a batch, with
an overhead comparable to element-wise multiplication instead of batch matrix
multiplication; (3) RoAd enhances LLM's interpretability through integration
within a framework of distributed interchange intervention, demonstrated via
composition experiments.",2024-08-28,"Baohao Liao, Christof Monz",http://arxiv.org/pdf/2409.00119v2,cs.LG
Comparison of Model Predictive Control and Proximal Policy Optimization for a 1-DOF Helicopter System,"This study conducts a comparative analysis of Model Predictive Control (MPC)
and Proximal Policy Optimization (PPO), a Deep Reinforcement Learning (DRL)
algorithm, applied to a 1-Degree of Freedom (DOF) Quanser Aero 2 system.
Classical control techniques such as MPC and Linear Quadratic Regulator (LQR)
are widely used due to their theoretical foundation and practical
effectiveness. However, with advancements in computational techniques and
machine learning, DRL approaches like PPO have gained traction in solving
optimal control problems through environment interaction. This paper
systematically evaluates the dynamic response characteristics of PPO and MPC,
comparing their performance, computational resource consumption, and
implementation complexity. Experimental results show that while LQR achieves
the best steady-state accuracy, PPO excels in rise-time and adaptability,
making it a promising approach for applications requiring rapid response and
adaptability. Additionally, we have established a baseline for future
RL-related research on this specific testbed. We also discuss the strengths and
limitations of each control strategy, providing recommendations for selecting
appropriate controllers for real-world scenarios.",2024-08-28,"Georg Schäfer, Jakob Rehrl, Stefan Huber, Simon Hirlaender",http://arxiv.org/pdf/2408.15633v1,cs.LG
Convergent Differential Privacy Analysis for General Federated Learning: the $f$-DP Perspective,"Federated learning (FL) is an efficient collaborative training paradigm
extensively developed with a focus on local privacy, and differential privacy
(DP) is a classical approach to capture and ensure the reliability of private
security. Their powerful cooperation provides a promising paradigm for the
large-scale private clients. As a predominant implementation, the noisy
perturbation has been widely studied, being theoretically proven to offer
significant protections. However, existing analyses in FL-DP mostly rely on the
composition theorem and cannot tightly quantify the privacy leakage challenges,
which is tight for a few communication rounds but yields an arbitrarily loose
and divergent bound eventually. This also implies a counterintuitive judgment,
suggesting that FL-DP may not provide adequate privacy support during long-term
training. To further investigate the convergent privacy and reliability of the
FL-DP framework, in this paper, we comprehensively evaluate the worst privacy
of two classical methods under the non-convex and smooth objectives based on
the $f$-DP analysis. With the aid of the shifted interpolation technique, we
successfully prove that privacy in {\ttfamily Noisy-FedAvg} has a tight
convergent bound. Moreover, with the regularization of the proxy term, privacy
in {\ttfamily Noisy-FedProx} has a stable constant lower bound. Our analysis
further demonstrates a solid theoretical foundation for the reliability of
privacy in FL-DP. Meanwhile, our conclusions can also be losslessly converted
to other classical DP analytical frameworks, e.g. $(\epsilon,\delta)$-DP and
R$\acute{\text{e}}$nyi-DP (RDP).",2024-08-28,"Yan Sun, Li Shen, Dacheng Tao",http://arxiv.org/pdf/2408.15621v2,cs.LG
CAPER: Enhancing Career Trajectory Prediction using Temporal Knowledge Graph and Ternary Relationship,"The problem of career trajectory prediction (CTP) aims to predict one's
future employer or job position. While several CTP methods have been developed
for this problem, we posit that none of these methods (1) jointly considers the
mutual ternary dependency between three key units (i.e., user, position, and
company) of a career and (2) captures the characteristic shifts of key units in
career over time, leading to an inaccurate understanding of the job movement
patterns in the labor market. To address the above challenges, we propose a
novel solution, named as CAPER, that solves the challenges via sophisticated
temporal knowledge graph (TKG) modeling. It enables the utilization of a
graph-structured knowledge base with rich expressiveness, effectively
preserving the changes in job movement patterns. Furthermore, we devise an
extrapolated career reasoning task on TKG for a realistic evaluation. The
experiments on a real-world career trajectory dataset demonstrate that CAPER
consistently and significantly outperforms four baselines, two recent TKG
reasoning methods, and five state-of-the-art CTP methods in predicting one's
future companies and positions--i.e., on average, yielding 6.80% and 34.58%
more accurate predictions, respectively. The codebase of CAPER is available at
https://github.com/Bigdasgit/CAPER.",2024-08-28,"Yeon-Chang Lee, JaeHyun Lee, Michiharu Yamashita, Dongwon Lee, Sang-Wook Kim",http://arxiv.org/pdf/2408.15620v2,cs.LG
Ionospheric Scintillation Forecasting Using Machine Learning,"This study explores the use of historical data from Global Navigation
Satellite System (GNSS) scintillation monitoring receivers to predict the
severity of amplitude scintillation, a phenomenon where electron density
irregularities in the ionosphere cause fluctuations in GNSS signal power. These
fluctuations can be measured using the S4 index, but real-time data is not
always available. The research focuses on developing a machine learning (ML)
model that can forecast the intensity of amplitude scintillation, categorizing
it into low, medium, or high severity levels based on various time and
space-related factors. Among six different ML models tested, the XGBoost model
emerged as the most effective, demonstrating a remarkable 77% prediction
accuracy when trained with a balanced dataset. This work underscores the
effectiveness of machine learning in enhancing the reliability and performance
of GNSS signals and navigation systems by accurately predicting amplitude
scintillation severity.",2024-08-28,"Sultan Halawa, Maryam Alansaari, Maryam Sharif, Amel Alhammadi, Ilias Fernini",http://arxiv.org/pdf/2409.00118v1,cs.LG
Multi-Graph Inductive Representation Learning for Large-Scale Urban Rail Demand Prediction under Disruptions,"With the expansion of cities over time, URT (Urban Rail Transit) networks
have also grown significantly. Demand prediction plays an important role in
supporting planning, scheduling, fleet management, and other operational
decisions. In this study, we propose an Origin-Destination (OD) demand
prediction model called Multi-Graph Inductive Representation Learning
(mGraphSAGE) for large-scale URT networks under operational uncertainties. Our
main contributions are twofold: we enhance prediction results while ensuring
scalability for large networks by relying simultaneously on multiple graphs,
where each OD pair is a node on a graph and distinct OD relationships, such as
temporal and spatial correlations; we show the importance of including
operational uncertainties such as train delays and cancellations as inputs in
demand prediction for daily operations. The model is validated on three
different scales of the URT network in Copenhagen, Denmark. Experimental
results show that by leveraging information from neighboring ODs and learning
node representations via sampling and aggregation, mGraphSAGE is particularly
suitable for OD demand prediction in large-scale URT networks, outperforming
reference machine learning methods. Furthermore, during periods with train
cancellations and delays, the performance gap between mGraphSAGE and other
methods improves compared to normal operating conditions, demonstrating its
ability to leverage system reliability information for predicting OD demand
under uncertainty.",2024-08-28,"Dang Viet Anh Nguyen, J. Victor Flensburg, Fabrizio Cerreto, Bianca Pascariu, Paola Pellegrini, Carlos Lima Azevedo, Filipe Rodrigues",http://arxiv.org/pdf/2408.15619v2,cs.LG
Statistical QoS Provision in Business-Centric Networks,"More refined resource management and Quality of Service (QoS) provisioning is
a critical goal of wireless communication technologies. In this paper, we
propose a novel Business-Centric Network (BCN) aimed at enabling scalable QoS
provisioning, based on a cross-layer framework that captures the relationship
between application, transport parameters, and channels. We investigate both
continuous flow and event-driven flow models, presenting key QoS metrics such
as throughput, delay, and reliability. By jointly considering power and
bandwidth allocation, transmission parameters, and AP network topology across
layers, we optimize weighted resource efficiency with statistical QoS
provisioning. To address the coupling among parameters, we propose a novel deep
reinforcement learning (DRL) framework, which is Collaborative Optimization
among Heterogeneous Actors with Experience Sharing (COHA-ES). Power and
sub-channel (SC) Actors representing multiple APs are jointly optimized under
the unified guidance of a common critic. Additionally, we introduce a novel
multithreaded experience-sharing mechanism to accelerate training and enhance
rewards. Extensive comparative experiments validate the effectiveness of our
DRL framework in terms of convergence and efficiency. Moreover, comparative
analyses demonstrate the comprehensive advantages of the BCN structure in
enhancing both spectral and energy efficiency.",2024-08-28,"Chang Wu, Yuang Chen, Hancheng Lu",http://arxiv.org/pdf/2408.15609v1,cs.LG
Grand canonical generative diffusion model for crystalline phases and grain boundaries,"The diffusion model has emerged as a powerful tool for generating atomic
structures for materials science. This work calls attention to the deficiency
of current particle-based diffusion models, which represent atoms as a point
cloud, in generating even the simplest ordered crystalline structures. The
problem is attributed to particles being trapped in local minima during the
score-driven simulated annealing of the diffusion process, similar to the
physical process of force-driven simulated annealing. We develop a solution,
the grand canonical diffusion model, which adopts an alternative voxel-based
representation with continuous rather than fixed number of particles. The
method is applied towards generation of several common crystalline phases as
well as the technologically important and challenging problem of grain boundary
structures.",2024-08-28,"Bo Lei, Enze Chen, Hyuna Kwon, Tim Hsu, Babak Sadigh, Vincenzo Lordi, Timofey Frolov, Fei Zhou",http://arxiv.org/pdf/2408.15601v1,cs.LG
Exploring Selective Layer Fine-Tuning in Federated Learning,"Federated learning (FL) has emerged as a promising paradigm for fine-tuning
foundation models using distributed data in a privacy-preserving manner. Under
limited computational resources, clients often find it more practical to
fine-tune a selected subset of layers, rather than the entire model, based on
their task-specific data. In this study, we provide a thorough theoretical
exploration of selective layer fine-tuning in FL, emphasizing a flexible
approach that allows the clients to adjust their selected layers according to
their local data and resources. We theoretically demonstrate that the layer
selection strategy has a significant impact on model convergence in two
critical aspects: the importance of selected layers and the heterogeneous
choices across clients. Drawing from these insights, we further propose a
strategic layer selection method that utilizes local gradients and regulates
layer selections across clients. The extensive experiments on both image and
text datasets demonstrate the effectiveness of the proposed strategy compared
with several baselines, highlighting its advances in identifying critical
layers that adapt to the client heterogeneity and training dynamics in FL.",2024-08-28,"Yuchang Sun, Yuexiang Xie, Bolin Ding, Yaliang Li, Jun Zhang",http://arxiv.org/pdf/2408.15600v3,cs.LG
Skills Regularized Task Decomposition for Multi-task Offline Reinforcement Learning,"Reinforcement learning (RL) with diverse offline datasets can have the
advantage of leveraging the relation of multiple tasks and the common skills
learned across those tasks, hence allowing us to deal with real-world complex
problems efficiently in a data-driven way. In offline RL where only offline
data is used and online interaction with the environment is restricted, it is
yet difficult to achieve the optimal policy for multiple tasks, especially when
the data quality varies for the tasks. In this paper, we present a skill-based
multi-task RL technique on heterogeneous datasets that are generated by
behavior policies of different quality. To learn the shareable knowledge across
those datasets effectively, we employ a task decomposition method for which
common skills are jointly learned and used as guidance to reformulate a task in
shared and achievable subtasks. In this joint learning, we use Wasserstein
auto-encoder (WAE) to represent both skills and tasks on the same latent space
and use the quality-weighted loss as a regularization term to induce tasks to
be decomposed into subtasks that are more consistent with high-quality skills
than others. To improve the performance of offline RL agents learned on the
latent space, we also augment datasets with imaginary trajectories relevant to
high-quality skills for each task. Through experiments, we show that our
multi-task offline RL approach is robust to the mixed configurations of
different-quality datasets and it outperforms other state-of-the-art algorithms
for several robotic manipulation tasks and drone navigation tasks.",2024-08-28,"Minjong Yoo, Sangwoo Cho, Honguk Woo",http://arxiv.org/pdf/2408.15593v1,cs.LG
VFLIP: A Backdoor Defense for Vertical Federated Learning via Identification and Purification,"Vertical Federated Learning (VFL) focuses on handling vertically partitioned
data over FL participants. Recent studies have discovered a significant
vulnerability in VFL to backdoor attacks which specifically target the distinct
characteristics of VFL. Therefore, these attacks may neutralize existing
defense mechanisms designed primarily for Horizontal Federated Learning (HFL)
and deep neural networks. In this paper, we present the first backdoor defense,
called VFLIP, specialized for VFL. VFLIP employs the identification and
purification techniques that operate at the inference stage, consequently
improving the robustness against backdoor attacks to a great extent. VFLIP
first identifies backdoor-triggered embeddings by adopting a participant-wise
anomaly detection approach. Subsequently, VFLIP conducts purification which
removes the embeddings identified as malicious and reconstructs all the
embeddings based on the remaining embeddings. We conduct extensive experiments
on CIFAR10, CINIC10, Imagenette, NUS-WIDE, and BankMarketing to demonstrate
that VFLIP can effectively mitigate backdoor attacks in VFL.
https://github.com/blingcho/VFLIP-esorics24",2024-08-28,"Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek",http://arxiv.org/pdf/2408.15591v2,cs.LG
Bayesian optimization of atomic structures with prior probabilities from universal interatomic potentials,"The optimization of atomic structures plays a pivotal role in understanding
and designing materials with desired properties. However, conventional
computational methods often struggle with the formidable task of navigating the
vast potential energy surface, especially in high-dimensional spaces with
numerous local minima. Recent advancements in machine learning-driven surrogate
models offer a promising avenue for alleviating this computational burden. In
this study, we propose a novel approach that combines the strengths of
universal machine learning potentials with a Bayesian approach using Gaussian
processes. By using the machine learning potentials as priors for the Gaussian
process, the Gaussian process has to learn only the difference between the
machine learning potential and the target energy surface calculated for example
by density functional theory. This turns out to improve the speed by which the
global optimal structure is identified across diverse systems for a
well-behaved machine learning potential. The approach is tested on periodic
bulk materials, surface structures, and a cluster.",2024-08-28,"Peder Lyngby, Casper Larsen, Karsten Wedel Jacobsen",http://arxiv.org/pdf/2408.15590v2,cs.LG
Boosting Lossless Speculative Decoding via Feature Sampling and Partial Alignment Distillation,"Lossless speculative decoding accelerates target large language model (LLM)
inference by employing a lightweight draft model for generating tree-structured
candidates, which are subsequently verified in parallel by the target LLM.
Currently, effective approaches leverage feature-level rather than token-level
autoregression within the draft model to facilitate more straightforward
predictions and enhanced knowledge distillation. In this paper, we reassess
these approaches and propose FSPAD (Feature Sampling and Partial Alignment
Distillation for Lossless Speculative Decoding), which introduces two
straightforward and effective components within the existing framework to boost
lossless speculative decoding. Firstly, FSPAD utilizes token embeddings to
sample features of the target LLM in high-dimensional space before feeding them
into the draft model, due to the inherent uncertainty of the features
preventing the draft model from obtaining the specific token output by the
target LLM. Secondly, FSPAD introduces partial alignment distillation to weaken
the draft model's connection between features and logits, aiming to reduce the
conflict between feature alignment and logit confidence during training. Our
experiments include both greedy and non-greedy decoding on the largest and
smallest models from the Vicuna and LLaMA3-Instruct series, as well as tasks in
multi-turn conversation, translation, summarization, question answering,
mathematical reasoning, and retrieval-augmented generation. The results show
that FSPAD outperforms the state-of-the-art method across all the
aforementioned tasks and target LLMs.",2024-08-28,"Lujun Gui, Bin Xiao, Lei Su, Weipeng Chen",http://arxiv.org/pdf/2408.15562v1,cs.LG
GlaLSTM: A Concurrent LSTM Stream Framework for Glaucoma Detection via Biomarker Mining,"Glaucoma is a complex group of eye diseases marked by optic nerve damage,
commonly linked to elevated intraocular pressure and biomarkers like retinal
nerve fiber layer thickness. Understanding how these biomarkers interact is
crucial for unraveling glaucoma's underlying mechanisms. In this paper, we
propose GlaLSTM, a novel concurrent LSTM stream framework for glaucoma
detection, leveraging latent biomarker relationships. Unlike traditional
CNN-based models that primarily detect glaucoma from images, GlaLSTM provides
deeper interpretability, revealing the key contributing factors and enhancing
model transparency. This approach not only improves detection accuracy but also
empowers clinicians with actionable insights, facilitating more informed
decision-making. Experimental evaluations confirm that GlaLSTM surpasses
existing state-of-the-art methods, demonstrating its potential for both
advanced biomarker analysis and reliable glaucoma detection.",2024-08-28,"Cheng Huang, Weizheng Xie, Jian Zhou, Tsengdar Lee, Karanjit Kooner, Jia Zhang",http://arxiv.org/pdf/2408.15555v2,cs.LG
A Novel Denoising Technique and Deep Learning Based Hybrid Wind Speed Forecasting Model for Variable Terrain Conditions,"Wind flow can be highly unpredictable and can suffer substantial fluctuations
in speed and direction due to the shape and height of hills, mountains, and
valleys, making accurate wind speed (WS) forecasting essential in complex
terrain. This paper presents a novel and adaptive model for short-term
forecasting of WS. The paper's key contributions are as follows: (a) The
Partial Auto Correlation Function (PACF) is utilised to minimise the dimension
of the set of Intrinsic Mode Functions (IMF), hence reducing training time; (b)
The sample entropy (SampEn) was used to calculate the complexity of the reduced
set of IMFs. The proposed technique is adaptive since a specific Deep Learning
(DL) model-feature combination was chosen based on complexity; (c) A novel
bidirectional feature-LSTM framework for complicated IMFs has been suggested,
resulting in improved forecasting accuracy; (d) The proposed model shows
superior forecasting performance compared to the persistence, hybrid, Ensemble
empirical mode decomposition (EEMD), and Variational Mode Decomposition
(VMD)-based deep learning models. It has achieved the lowest variance in terms
of forecasting accuracy between simple and complex terrain conditions 0.70%.
Dimension reduction of IMF's and complexity-based model-feature selection helps
reduce the training time by 68.77% and improve forecasting quality by 58.58% on
average.",2024-08-28,"Sourav Malakar, Saptarsi Goswami, Amlan Chakrabarti, Bhaswati Ganguli",http://arxiv.org/pdf/2408.15554v1,cs.LG
SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding,"Scientific literature understanding is crucial for extracting targeted
information and garnering insights, thereby significantly advancing scientific
discovery. Despite the remarkable success of Large Language Models (LLMs), they
face challenges in scientific literature understanding, primarily due to (1) a
lack of scientific knowledge and (2) unfamiliarity with specialized scientific
tasks.
  To develop an LLM specialized in scientific literature understanding, we
propose a hybrid strategy that integrates continual pre-training (CPT) and
supervised fine-tuning (SFT), to simultaneously infuse scientific domain
knowledge and enhance instruction-following capabilities for domain-specific
tasks.cIn this process, we identify two key challenges: (1) constructing
high-quality CPT corpora, and (2) generating diverse SFT instructions. We
address these challenges through a meticulous pipeline, including PDF text
extraction, parsing content error correction, quality filtering, and synthetic
instruction creation. Applying this strategy, we present a suite of LLMs:
SciLitLLM, specialized in scientific literature understanding. These models
demonstrate promising performance on scientific literature understanding
benchmarks.
  Our contributions are threefold: (1) We present an effective framework that
integrates CPT and SFT to adapt LLMs to scientific literature understanding,
which can also be easily adapted to other domains. (2) We propose an LLM-based
synthesis method to generate diverse and high-quality scientific instructions,
resulting in a new instruction set -- SciLitIns -- for supervised fine-tuning
in less-represented scientific domains. (3) SciLitLLM achieves promising
performance improvements on scientific literature understanding benchmarks.",2024-08-28,"Sihang Li, Jin Huang, Jiaxi Zhuang, Yaorui Shi, Xiaochen Cai, Mingjun Xu, Xiang Wang, Linfeng Zhang, Guolin Ke, Hengxing Cai",http://arxiv.org/pdf/2408.15545v5,cs.LG
Improving Thompson Sampling via Information Relaxation for Budgeted Multi-armed Bandits,"We consider a Bayesian budgeted multi-armed bandit problem, in which each arm
consumes a different amount of resources when selected and there is a budget
constraint on the total amount of resources that can be used. Budgeted Thompson
Sampling (BTS) offers a very effective heuristic to this problem, but its
arm-selection rule does not take into account the remaining budget information.
We adopt \textit{Information Relaxation Sampling} framework that generalizes
Thompson Sampling for classical $K$-armed bandit problems, and propose a series
of algorithms that are randomized like BTS but more carefully optimize their
decisions with respect to the budget constraint. In a one-to-one correspondence
with these algorithms, a series of performance benchmarks that improve the
conventional benchmark are also suggested. Our theoretical analysis and
simulation results show that our algorithms (and our benchmarks) make
incremental improvements over BTS (respectively, the conventional benchmark)
across various settings including a real-world example.",2024-08-28,"Woojin Jeong, Seungki Min",http://arxiv.org/pdf/2408.15535v1,cs.LG
FedMCP: Parameter-Efficient Federated Learning with Model-Contrastive Personalization,"With increasing concerns and regulations on data privacy, fine-tuning
pretrained language models (PLMs) in federated learning (FL) has become a
common paradigm for NLP tasks. Despite being extensively studied, the existing
methods for this problem still face two primary challenges. First, the huge
number of parameters in large-scale PLMs leads to excessive communication and
computational overhead. Second, the heterogeneity of data and tasks across
clients poses a significant obstacle to achieving the desired fine-tuning
performance. To address the above problems, we propose FedMCP, a novel
parameter-efficient fine-tuning method with model-contrastive personalization
for FL. Specifically, FedMCP adds two lightweight adapter modules, i.e., the
global adapter and the private adapter, to the frozen PLMs within clients. In a
communication round, each client sends only the global adapter to the server
for federated aggregation. Furthermore, FedMCP introduces a model-contrastive
regularization term between the two adapters. This, on the one hand, encourages
the global adapter to assimilate universal knowledge and, on the other hand,
the private adapter to capture client-specific knowledge. By leveraging both
adapters, FedMCP can effectively provide fine-tuned personalized models
tailored to individual clients. Extensive experiments on highly heterogeneous
cross-task, cross-silo datasets show that FedMCP achieves substantial
performance improvements over state-of-the-art FL fine-tuning approaches for
PLMs.",2024-08-28,"Qianyi Zhao, Chen Qu, Cen Chen, Mingyuan Fan, Yanhao Wang",http://arxiv.org/pdf/2409.00116v1,cs.LG
Self-Adaptive Quantum Kernel Principal Components Analysis for Compact Readout of Chemiresistive Sensor Arrays,"The rapid growth of Internet of Things (IoT) devices necessitates efficient
data compression techniques to handle the vast amounts of data generated by
these devices. Chemiresistive sensor arrays (CSAs), a simple-to-fabricate but
crucial component in IoT systems, generate large volumes of data due to their
simultaneous multi-sensor operations. Classical principal component analysis
(cPCA) methods, a common solution to the data compression challenge, face
limitations in preserving critical information during dimensionality reduction.
In this study, we present self-adaptive quantum kernel (SAQK) PCA as a superior
alternative to enhance information retention. Our findings demonstrate that
SAQK PCA outperforms cPCA in various back-end machine-learning tasks,
especially in low-dimensional scenarios where access to quantum bits is
limited. These results highlight the potential of noisy intermediate-scale
quantum (NISQ) computers to revolutionize data processing in real-world IoT
applications by improving the efficiency and reliability of CSA data
compression and readout, despite the current constraints on qubit availability.",2024-08-28,"Zeheng Wang, Timothy van der Laan, Muhammad Usman",http://arxiv.org/pdf/2409.00115v2,cs.LG
How Reliable are Causal Probing Interventions?,"Causal probing aims to analyze foundation models by examining how intervening
on their representation of various latent properties impacts their outputs.
Recent works have cast doubt on the theoretical basis of several leading causal
probing methods, but it has been unclear how to systematically evaluate the
effectiveness of these methods in practice. To address this, we define two key
causal probing desiderata: completeness (how thoroughly the representation of
the target property has been transformed) and selectivity (how little
non-targeted properties have been impacted). We find that there is an inherent
tradeoff between the two, which we define as reliability, their harmonic mean.
We introduce an empirical analysis framework to measure and evaluate these
quantities, allowing us to make the first direct comparisons between different
families of leading causal probing methods (e.g., linear vs. nonlinear, or
concept removal vs. counterfactual interventions). We find that: (1) no method
is reliable across all layers; (2) more reliable methods have a greater impact
on LLM behavior; (3) nonlinear interventions are more reliable in early and
intermediate layers, and linear interventions are more reliable in later
layers; and (4) concept removal methods are far less reliable than
counterfactual interventions, suggesting that they may not be an effective
approach to causal probing.",2024-08-28,"Marc Canby, Adam Davies, Chirag Rastogi, Julia Hockenmaier",http://arxiv.org/pdf/2408.15510v3,cs.LG
Meta-Learn Unimodal Signals with Weak Supervision for Multimodal Sentiment Analysis,"Multimodal sentiment analysis aims to effectively integrate information from
various sources to infer sentiment, where in many cases there are no
annotations for unimodal labels. Therefore, most works rely on multimodal
labels for training. However, there exists the noisy label problem for the
learning of unimodal signals as multimodal annotations are not always the ideal
substitutes for the unimodal ones, failing to achieve finer optimization for
individual modalities. In this paper, we explore the learning of unimodal
labels under the weak supervision from the annotated multimodal labels.
Specifically, we propose a novel meta uni-label generation (MUG) framework to
address the above problem, which leverages the available multimodal labels to
learn the corresponding unimodal labels by the meta uni-label correction
network (MUCN). We first design a contrastive-based projection module to bridge
the gap between unimodal and multimodal representations, so as to use
multimodal annotations to guide the learning of MUCN. Afterwards, we propose
unimodal and multimodal denoising tasks to train MUCN with explicit supervision
via a bi-level optimization strategy. We then jointly train unimodal and
multimodal learning tasks to extract discriminative unimodal features for
multimodal inference. Experimental results suggest that MUG outperforms
competitive baselines and can learn accurate unimodal labels.",2024-08-28,"Sijie Mai, Yu Zhao, Ying Zeng, Jianhua Yao, Haifeng Hu",http://arxiv.org/pdf/2408.16029v2,cs.LG
ANVIL: Anomaly-based Vulnerability Identification without Labelled Training Data,"Supervised learning-based software vulnerability detectors often fall short
due to the inadequate availability of labelled training data. In contrast,
Large Language Models (LLMs) such as GPT-4, are not trained on labelled data,
but when prompted to detect vulnerabilities, LLM prediction accuracy is only
marginally better than random guessing. In this paper, we explore a different
approach by reframing vulnerability detection as one of anomaly detection.
Since the vast majority of code does not contain vulnerabilities and LLMs are
trained on massive amounts of such code, vulnerable code can be viewed as an
anomaly from the LLM's predicted code distribution, freeing the model from the
need for labelled data to provide a learnable representation of vulnerable
code. Leveraging this perspective, we demonstrate that LLMs trained for code
generation exhibit a significant gap in prediction accuracy when prompted to
reconstruct vulnerable versus non-vulnerable code.
  Using this insight, we implement ANVIL, a detector that identifies software
vulnerabilities at line-level granularity. Our experiments explore the
discriminating power of different anomaly scoring methods, as well as the
sensitivity of ANVIL to context size. We also study the effectiveness of ANVIL
on various LLM families, and conduct leakage experiments on vulnerabilities
that were discovered after the knowledge cutoff of our evaluated LLMs. On a
collection of vulnerabilities from the Magma benchmark, ANVIL outperforms
state-of-the-art line-level vulnerability detectors, LineVul and LineVD, which
have been trained with labelled data, despite ANVIL having never been trained
with labelled vulnerabilities. Specifically, our approach achieves $1.62\times$
to $2.18\times$ better Top-5 accuracies and $1.02\times$ to $1.29\times$ times
better ROC scores on line-level vulnerability detection tasks.",2024-08-28,"Weizhou Wang, Eric Liu, Xiangyu Guo, Xiao Hu, Ilya Grishchenko, David Lie",http://arxiv.org/pdf/2408.16028v2,cs.LG
MODULI: Unlocking Preference Generalization via Diffusion Models for Offline Multi-Objective Reinforcement Learning,"Multi-objective Reinforcement Learning (MORL) seeks to develop policies that
simultaneously optimize multiple conflicting objectives, but it requires
extensive online interactions. Offline MORL provides a promising solution by
training on pre-collected datasets to generalize to any preference upon
deployment. However, real-world offline datasets are often conservatively and
narrowly distributed, failing to comprehensively cover preferences, leading to
the emergence of out-of-distribution (OOD) preference areas. Existing offline
MORL algorithms exhibit poor generalization to OOD preferences, resulting in
policies that do not align with preferences. Leveraging the excellent
expressive and generalization capabilities of diffusion models, we propose
MODULI (Multi-objective Diffusion Planner with Sliding Guidance), which employs
a preference-conditioned diffusion model as a planner to generate trajectories
that align with various preferences and derive action for decision-making. To
achieve accurate generation, MODULI introduces two return normalization methods
under diverse preferences for refining guidance. To further enhance
generalization to OOD preferences, MODULI proposes a novel sliding guidance
mechanism, which involves training an additional slider adapter to capture the
direction of preference changes. Incorporating the slider, it transitions from
in-distribution (ID) preferences to generating OOD preferences, patching, and
extending the incomplete Pareto front. Extensive experiments on the D4MORL
benchmark demonstrate that our algorithm outperforms state-of-the-art Offline
MORL baselines, exhibiting excellent generalization to OOD preferences.",2024-08-28,"Yifu Yuan, Zhenrui Zheng, Zibin Dong, Jianye Hao",http://arxiv.org/pdf/2408.15501v1,cs.LG
Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep Feed-forward Neural Network,"While machine learning has advanced in medicine, its widespread use in
clinical applications, especially in predicting breast cancer metastasis, is
still limited. We have been dedicated to constructing a DFNN model to predict
breast cancer metastasis n years in advance. However, the challenge lies in
efficiently identifying optimal hyperparameter values through grid search,
given the constraints of time and resources. Issues such as the infinite
possibilities for continuous hyperparameters like l1 and l2, as well as the
time-consuming and costly process, further complicate the task. To address
these challenges, we developed Single Hyperparameter Grid Search (SHGS)
strategy, serving as a preselection method before grid search. Our experiments
with SHGS applied to DFNN models for breast cancer metastasis prediction focus
on analyzing eight target hyperparameters: epochs, batch size, dropout, L1, L2,
learning rate, decay, and momentum. We created three figures, each depicting
the experiment results obtained from three LSM-I-10-Plus-year datasets. These
figures illustrate the relationship between model performance and the target
hyperparameter values. For each hyperparameter, we analyzed whether changes in
this hyperparameter would affect model performance, examined if there were
specific patterns, and explored how to choose values for the particular
hyperparameter. Our experimental findings reveal that the optimal value of a
hyperparameter is not only dependent on the dataset but is also significantly
influenced by the settings of other hyperparameters. Additionally, our
experiments suggested some reduced range of values for a target hyperparameter,
which may be helpful for low-budget grid search. This approach serves as a
prior experience and foundation for subsequent use of grid search to enhance
model performance.",2024-08-28,"Yijun Zhou, Om Arora-Jain, Xia Jiang",http://arxiv.org/pdf/2408.15498v1,cs.LG
Remove Symmetries to Control Model Expressivity and Improve Optimization,"When symmetry is present in the loss function, the model is likely to be
trapped in a low-capacity state that is sometimes known as a ""collapse"". Being
trapped in these low-capacity states can be a major obstacle to training across
many scenarios where deep learning technology is applied. We first prove two
concrete mechanisms through which symmetries lead to reduced capacities and
ignored features during training and inference. We then propose a simple and
theoretically justified algorithm, syre, to remove almost all symmetry-induced
low-capacity states in neural networks. When this type of entrapment is
especially a concern, removing symmetries with the proposed method is shown to
correlate well with improved optimization or performance. A remarkable merit of
the proposed method is that it is model-agnostic and does not require any
knowledge of the symmetry.",2024-08-28,"Liu Ziyin, Yizhou Xu, Isaac Chuang",http://arxiv.org/pdf/2408.15495v3,cs.LG
CTRQNets & LQNets: Continuous Time Recurrent and Liquid Quantum Neural Networks,"Neural networks have continued to gain prevalence in the modern era for their
ability to model complex data through pattern recognition and behavior
remodeling. However, the static construction of traditional neural networks
inhibits dynamic intelligence. This makes them inflexible to temporal changes
in data and unfit to capture complex dependencies. With the advent of quantum
technology, there has been significant progress in creating quantum algorithms.
In recent years, researchers have developed quantum neural networks that
leverage the capabilities of qubits to outperform classical networks. However,
their current formulation exhibits a static construction limiting the system's
dynamic intelligence. To address these weaknesses, we develop a Liquid Quantum
Neural Network (LQNet) and a Continuous Time Recurrent Quantum Neural Network
(CTRQNet). Both models demonstrate a significant improvement in accuracy
compared to existing quantum neural networks (QNNs), achieving accuracy
increases as high as 40\% on CIFAR 10 through binary classification. We propose
LQNets and CTRQNets might shine a light on quantum machine learning's black
box.",2024-08-28,"Alejandro Mayorga, Alexander Yuan, Andrew Yuan, Tyler Wooldridge, Xiaodi Wang",http://arxiv.org/pdf/2408.15462v1,cs.LG
PersonalizedUS: Interpretable Breast Cancer Risk Assessment with Local Coverage Uncertainty Quantification,"Correctly assessing the malignancy of breast lesions identified during
ultrasound examinations is crucial for effective clinical decision-making.
However, the current ""golden standard"" relies on manual BI-RADS scoring by
clinicians, often leading to unnecessary biopsies and a significant mental
health burden on patients and their families. In this paper, we introduce
PersonalizedUS, an interpretable machine learning system that leverages recent
advances in conformal prediction to provide precise and personalized risk
estimates with local coverage guarantees and sensitivity, specificity, and
predictive values above 0.9 across various threshold levels. In particular, we
identify meaningful lesion subgroups where distribution-free, model-agnostic
conditional coverage holds, with approximately 90% of our prediction sets
containing only the ground truth in most lesion subgroups, thus explicitly
characterizing for which patients the model is most suitably applied. Moreover,
we make available a curated tabular dataset of 1936 biopsied breast lesions
from a recent observational multicenter study and benchmark the performance of
several state-of-the-art learning algorithms. We also report a successful case
study of the deployed system in the same multicenter context. Concrete clinical
benefits include up to a 65% reduction in requested biopsies among BI-RADS 4a
and 4b lesions, with minimal to no missed cancer cases.",2024-08-28,"Alek Fröhlich, Thiago Ramos, Gustavo Cabello, Isabela Buzatto, Rafael Izbicki, Daniel Tiezzi",http://arxiv.org/pdf/2408.15458v1,cs.LG
Certified Causal Defense with Generalizable Robustness,"While machine learning models have proven effective across various scenarios,
it is widely acknowledged that many models are vulnerable to adversarial
attacks. Recently, there have emerged numerous efforts in adversarial defense.
Among them, certified defense is well known for its theoretical guarantees
against arbitrary adversarial perturbations on input within a certain range
(e.g., $l_2$ ball). However, most existing works in this line struggle to
generalize their certified robustness in other data domains with distribution
shifts. This issue is rooted in the difficulty of eliminating the negative
impact of spurious correlations on robustness in different domains. To address
this problem, in this work, we propose a novel certified defense framework
GLEAN, which incorporates a causal perspective into the generalization problem
in certified defense. More specifically, our framework integrates a certifiable
causal factor learning component to disentangle the causal relations and
spurious correlations between input and label, and thereby exclude the negative
effect of spurious correlations on defense. On top of that, we design a
causally certified defense strategy to handle adversarial attacks on latent
causal factors. In this way, our framework is not only robust against malicious
noises on data in the training distribution but also can generalize its
robustness across domains with distribution shifts. Extensive experiments on
benchmark datasets validate the superiority of our framework in certified
robustness generalization in different data domains. Code is available in the
supplementary materials.",2024-08-28,"Yiran Qiao, Yu Yin, Chen Chen, Jing Ma",http://arxiv.org/pdf/2408.15451v2,cs.LG
Avoiding Generative Model Writer's Block With Embedding Nudging,"Generative image models, since introduction, have become a global phenomenon.
From new arts becoming possible to new vectors of abuse, many new capabilities
have become available. One of the challenging issues with generative models is
controlling the generation process specially to prevent specific generations
classes or instances . There are several reasons why one may want to control
the output of generative models, ranging from privacy and safety concerns to
application limitations or user preferences
  To address memorization and privacy challenges, there has been considerable
research dedicated to filtering prompts or filtering the outputs of these
models. What all these solutions have in common is that at the end of the day
they stop the model from producing anything, hence limiting the usability of
the model. In this paper, we propose a method for addressing this usability
issue by making it possible to steer away from unwanted concepts (when detected
in model's output) and still generating outputs. In particular we focus on the
latent diffusion image generative models and how one can prevent them to
generate particular images while generating similar images with limited
overhead.
  We focus on mitigating issues like image memorization, demonstrating our
technique's effectiveness through qualitative and quantitative evaluations. Our
method successfully prevents the generation of memorized training images while
maintaining comparable image quality and relevance to the unmodified model.",2024-08-28,"Ali Zand, Milad Nasr",http://arxiv.org/pdf/2408.15450v1,cs.LG
Graph Attention Inference of Network Topology in Multi-Agent Systems,"Accurately identifying the underlying graph structures of multi-agent systems
remains a difficult challenge. Our work introduces a novel machine
learning-based solution that leverages the attention mechanism to predict
future states of multi-agent systems by learning node representations. The
graph structure is then inferred from the strength of the attention values.
This approach is applied to both linear consensus dynamics and the non-linear
dynamics of Kuramoto oscillators, resulting in implicit learning of the graph
by learning good agent representations. Our results demonstrate that the
presented data-driven graph attention machine learning model can identify the
network topology in multi-agent systems, even when the underlying dynamic model
is not known, as evidenced by the F1 scores achieved in the link prediction.",2024-08-27,"Akshay Kolli, Reza Azadeh, Kshitj Jerath",http://arxiv.org/pdf/2408.15449v2,cs.LG
Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning,"The tuning of hyperparameters in reinforcement learning (RL) is critical, as
these parameters significantly impact an agent's performance and learning
efficiency. Dynamic adjustment of hyperparameters during the training process
can significantly enhance both the performance and stability of learning.
Population-based training (PBT) provides a method to achieve this by
continuously tuning hyperparameters throughout the training. This ongoing
adjustment enables models to adapt to different learning stages, resulting in
faster convergence and overall improved performance. In this paper, we propose
an enhancement to PBT by simultaneously utilizing both first- and second-order
optimizers within a single population. We conducted a series of experiments
using the TD3 algorithm across various MuJoCo environments. Our results, for
the first time, empirically demonstrate the potential of incorporating
second-order optimizers within PBT-based RL. Specifically, the combination of
the K-FAC optimizer with Adam led to up to a 10% improvement in overall
performance compared to PBT using only Adam. Additionally, in environments
where Adam occasionally fails, such as the Swimmer environment, the mixed
population with K-FAC exhibited more reliable learning outcomes, offering a
significant advantage in training stability without a substantial increase in
computational time.",2024-08-27,"Felix Pfeiffer, Shahram Eivazi",http://arxiv.org/pdf/2408.15421v2,cs.LG
Understanding GNNs for Boolean Satisfiability through Approximation Algorithms,"The paper deals with the interpretability of Graph Neural Networks in the
context of Boolean Satisfiability. The goal is to demystify the internal
workings of these models and provide insightful perspectives into their
decision-making processes. This is done by uncovering connections to two
approximation algorithms studied in the domain of Boolean Satisfiability:
Belief Propagation and Semidefinite Programming Relaxations. Revealing these
connections has empowered us to introduce a suite of impactful enhancements.
The first significant enhancement is a curriculum training procedure, which
incrementally increases the problem complexity in the training set, together
with increasing the number of message passing iterations of the Graph Neural
Network. We show that the curriculum, together with several other
optimizations, reduces the training time by more than an order of magnitude
compared to the baseline without the curriculum. Furthermore, we apply
decimation and sampling of initial embeddings, which significantly increase the
percentage of solved problems.",2024-08-27,"Jan Hůla, David Mojžíšek, Mikoláš Janota",http://arxiv.org/pdf/2408.15418v1,cs.LG
Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns to Model Representations,"Next-token prediction (NTP) over large text corpora has become the go-to
paradigm to train large language models. Yet, it remains unclear how NTP
influences the mapping of linguistic patterns to geometric properties of the
resulting model representations. We frame training of large language models as
soft-label classification over sparse probabilistic label vectors, coupled with
an analytical approximation that allows unrestricted generation of context
embeddings. This approach links NTP training to rank-constrained, nuclear-norm
regularized optimization in the logit domain, offering a framework for
analyzing the geometry of word and context embeddings. In large embedding
spaces, we find that NTP implicitly favors learning logits with a sparse plus
low-rank structure. While the sparse component captures the co-occurrence
frequency of context-word pairs, the orthogonal low-rank component, which
becomes dominant as training progresses, depends solely on the sparsity pattern
of the co-occurrence matrix. Consequently, when projected onto an appropriate
subspace, representations of contexts that are followed by the same set of
next-tokens collapse, a phenomenon we term subspace-collapse. We validate our
findings on synthetic and small-scale real language datasets. Finally, we
outline potential research directions aimed at deepening the understanding of
NTP's influence on the learning of linguistic patterns and regularities.",2024-08-27,"Yize Zhao, Tina Behnia, Vala Vakilian, Christos Thrampoulidis",http://arxiv.org/pdf/2408.15417v2,cs.LG
A physics-encoded Fourier neural operator approach for surrogate modeling of divergence-free stress fields in solids,"The purpose of the current work is the development of a so-called
physics-encoded Fourier neural operator (PeFNO) for surrogate modeling of the
quasi-static equilibrium stress field in solids. Rather than accounting for
constraints from physics in the loss function as done in the (now standard)
physics-informed approach, the physics-encoded approach incorporates or
""encodes"" such constraints directly into the network or operator architecture.
As a result, in contrast to the physics-informed approach in which only
training is physically constrained, both training and output are physically
constrained in the physics-encoded approach. For the current constraint of
divergence-free stress, a novel encoding approach based on a stress potential
is proposed.
  As a ""proof-of-concept"" example application of the proposed PeFNO, a
heterogeneous polycrystalline material consisting of isotropic elastic grains
subject to uniaxial extension is considered. Stress field data for training are
obtained from the numerical solution of a corresponding boundary-value problem
for quasi-static mechanical equilibrium. This data is also employed to train an
analogous physics-guided FNO (PgFNO) and physics-informed FNO (PiFNO) for
comparison. As confirmed by this comparison and as expected on the basis of
their differences, the output of the trained PeFNO is significantly more
accurate in satisfying mechanical equilibrium than the output of either the
trained PgFNO or the trained PiFNO.",2024-08-27,"Mohammad S. Khorrami, Pawan Goyal, Jaber R. Mianroodi, Bob Svendsen, Peter Benner, Dierk Raabe",http://arxiv.org/pdf/2408.15408v2,cs.LG
Evaluating Credit VIX (CDS IV) Prediction Methods with Incremental Batch Learning,"This paper presents the experimental process and results of SVM, Gradient
Boosting, and an Attention-GRU Hybrid model in predicting the Implied
Volatility of rolled-over five-year spread contracts of credit default swaps
(CDS) on European corporate debt during the quarter following mid-May '24, as
represented by the iTraxx/Cboe Europe Main 1-Month Volatility Index (BP
Volatility). The analysis employs a feature matrix inspired by Merton's
determinants of default probability. Our comparative assessment aims to
identify strengths in SOTA and classical machine learning methods for financial
risk prediction",2024-08-27,Robert Taylor,http://arxiv.org/pdf/2408.15404v1,cs.LG
Exploring the origins of switching dynamics in a multifunctional reservoir computer,"The concept of multifunctionality has enabled reservoir computers (RCs), a
type of dynamical system that is typically realised as an artificial neural
network, to reconstruct multiple attractors simultaneously using the same set
of trained weights. However there are many additional phenomena that arise when
training a RC to reconstruct more than one attractor. Previous studies have
found that, in certain cases, if the RC fails to reconstruct a coexistence of
attractors then it exhibits a form of metastability whereby, without any
external input, the state of the RC switches between different modes of
behaviour that resemble properties of the attractors it failed to reconstruct.
In this paper we explore the origins of these switching dynamics in a
paradigmatic setting via the `seeing double' problem.",2024-08-27,"Andrew Flynn, Andreas Amann",http://arxiv.org/pdf/2408.15400v1,cs.LG
A Statistical Framework for Data-dependent Retrieval-Augmented Models,"Modern ML systems increasingly augment input instances with additional
relevant information to enhance final prediction. Despite growing interest in
such retrieval-augmented models, their fundamental properties and training are
not well understood. We propose a statistical framework to study such models
with two components: 1) a {\em retriever} to identify the relevant information
out of a large corpus via a data-dependent metric; and 2) a {\em predictor}
that consumes the input instances along with the retrieved information to make
the final predictions. We present a principled method for end-to-end training
of both components and draw connections with various training approaches in the
literature. Furthermore, we establish excess risk bounds for
retrieval-augmented models while delineating the contributions of both
retriever and predictor towards the model performance. We validate the utility
of our proposed training methods along with the key takeaways from our
statistical analysis on open domain question answering task where retrieval
augmentation is important.",2024-08-27,"Soumya Basu, Ankit Singh Rawat, Manzil Zaheer",http://arxiv.org/pdf/2408.15399v1,cs.LG
Evaluating Pre-Training Bias on Severe Acute Respiratory Syndrome Dataset,"Machine learning (ML) is a growing field of computer science that has found
many practical applications in several domains, including Health. However, as
data grows in size and availability, and the number of models that aim to aid
or replace human decisions, it raises the concern that these models can be
susceptible to bias, which can lead to harm to specific individuals by basing
its decisions on protected attributes such as gender, religion, sexual
orientation, ethnicity, and others. Visualization techniques might generate
insights and help summarize large datasets, enabling data scientists to
understand the data better before training a model by evaluating pre-training
metrics applied to the datasets before training, which might contribute to
identifying potential harm before any effort is put into training and deploying
the models. This work uses the severe acute respiratory syndrome dataset from
OpenDataSUS to visualize three pre-training bias metrics and their distribution
across different regions in Brazil. A random forest model is trained in each
region and applied to the others. The aim is to compare the bias for the
different regions, focusing on their protected attributes and comparing the
model's performance with the metric values.",2024-08-27,Diego Dimer Rodrigues,http://arxiv.org/pdf/2408.15398v1,cs.LG
SCAN-Edge: Finding MobileNet-speed Hybrid Networks for Diverse Edge Devices via Hardware-Aware Evolutionary Search,"Designing low-latency and high-efficiency hybrid networks for a variety of
low-cost commodity edge devices is both costly and tedious, leading to the
adoption of hardware-aware neural architecture search (NAS) for finding optimal
architectures. However, unifying NAS for a wide range of edge devices presents
challenges due to the variety of hardware designs, supported operations, and
compilation optimizations. Existing methods often fix the search space of
architecture choices (e.g., activation, convolution, or self-attention) and
estimate latency using hardware-agnostic proxies (e.g., FLOPs), which fail to
achieve proclaimed latency across various edge devices. To address this issue,
we propose SCAN-Edge, a unified NAS framework that jointly searches for
self-attention, convolution, and activation to accommodate the wide variety of
edge devices, including CPU-, GPU-, and hardware accelerator-based systems. To
handle the large search space, SCAN-Edge relies on with a hardware-aware
evolutionary algorithm that improves the quality of the search space to
accelerate the sampling process. Experiments on large-scale datasets
demonstrate that our hybrid networks match the actual MobileNetV2 latency for
224x224 input resolution on various commodity edge devices.",2024-08-27,"Hung-Yueh Chiang, Diana Marculescu",http://arxiv.org/pdf/2408.15395v1,cs.LG
Stability Analysis of Physics-Informed Neural Networks for Stiff Linear Differential Equations,"We present a stability analysis of Physics-Informed Neural Networks (PINNs)
coupled with random projections, for the numerical solution of (stiff) linear
differential equations. For our analysis, we consider systems of linear ODEs,
and linear parabolic PDEs. We prove that properly designed PINNs offer
consistent and asymptotically stable numerical schemes, thus convergent
schemes. In particular, we prove that multi-collocation random projection PINNs
guarantee asymptotic stability for very high stiffness and that
single-collocation PINNs are $A$-stable. To assess the performance of the PINNs
in terms of both numerical approximation accuracy and computational cost, we
compare it with other implicit schemes and in particular backward Euler, the
midpoint, trapezoidal (Crank-Nikolson), the 2-stage Gauss scheme and the 2 and
3 stages Radau schemes. We show that the proposed PINNs outperform the above
traditional schemes, in both numerical approximation accuracy and importantly
computational cost, for a wide range of step sizes.",2024-08-27,"Gianluca Fabiani, Erik Bollt, Constantinos Siettos, Athanasios N. Yannacopoulos",http://arxiv.org/pdf/2408.15393v1,cs.LG
Panoptic Perception for Autonomous Driving: A Survey,"Panoptic perception represents a forefront advancement in autonomous driving
technology, unifying multiple perception tasks into a singular, cohesive
framework to facilitate a thorough understanding of the vehicle's surroundings.
This survey reviews typical panoptic perception models for their unique inputs
and architectures and compares them to performance, responsiveness, and
resource utilization. It also delves into the prevailing challenges faced in
panoptic perception and explores potential trajectories for future research.
Our goal is to furnish researchers in autonomous driving with a detailed
synopsis of panoptic perception, positioning this survey as a pivotal reference
in the ever-evolving landscape of autonomous driving technologies.",2024-08-27,"Yunge Li, Lanyu Xu",http://arxiv.org/pdf/2408.15388v1,cs.LG
Toward Time-Continuous Data Inference in Sparse Urban CrowdSensing,"Mobile Crowd Sensing (MCS) is a promising paradigm that leverages mobile
users and their smart portable devices to perform various real-world tasks.
However, due to budget constraints and the inaccessibility of certain areas,
Sparse MCS has emerged as a more practical alternative, collecting data from a
limited number of target subareas and utilizing inference algorithms to
complete the full sensing map. While existing approaches typically assume a
time-discrete setting with data remaining constant within each sensing cycle,
this simplification can introduce significant errors, especially when dealing
with long cycles, as real-world sensing data often changes continuously. In
this paper, we go from fine-grained completion, i.e., the subdivision of
sensing cycles into minimal time units, towards a more accurate,
time-continuous completion. We first introduce Deep Matrix Factorization (DMF)
as a neural network-enabled framework and enhance it with a Recurrent Neural
Network (RNN-DMF) to capture temporal correlations in these finer time slices.
To further deal with the continuous data, we propose TIME-DMF, which captures
temporal information across unequal intervals, enabling time-continuous
completion. Additionally, we present the Query-Generate (Q-G) strategy within
TIME-DMF to model the infinite states of continuous data. Extensive experiments
across five types of sensing tasks demonstrate the effectiveness of our models
and the advantages of time-continuous completion.",2024-08-27,"Ziyu Sun, Haoyang Su, Hanqi Sun, En Wang, Wenbin Liu",http://arxiv.org/pdf/2408.16027v1,cs.LG
CycleGAN with Better Cycles,"CycleGAN provides a framework to train image-to-image translation with
unpaired datasets using cycle consistency loss [4]. While results are great in
many applications, the pixel level cycle consistency can potentially be
problematic and causes unrealistic images in certain cases. In this project, we
propose three simple modifications to cycle consistency, and show that such an
approach achieves better results with fewer artifacts.",2024-08-27,"Tongzhou Wang, Yihan Lin",http://arxiv.org/pdf/2408.15374v2,cs.LG
Handling Geometric Domain Shifts in Semantic Segmentation of Surgical RGB and Hyperspectral Images,"Robust semantic segmentation of intraoperative image data holds promise for
enabling automatic surgical scene understanding and autonomous robotic surgery.
While model development and validation are primarily conducted on idealistic
scenes, geometric domain shifts, such as occlusions of the situs, are common in
real-world open surgeries. To close this gap, we (1) present the first analysis
of state-of-the-art (SOA) semantic segmentation models when faced with
geometric out-of-distribution (OOD) data, and (2) propose an augmentation
technique called ""Organ Transplantation"", to enhance generalizability. Our
comprehensive validation on six different OOD datasets, comprising 600 RGB and
hyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes,
reveals a large performance drop in SOA organ segmentation models on geometric
OOD data. This performance decline is observed not only in conventional RGB
data (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI
data (with a DSC drop of 45 %), despite the richer spectral information
content. The performance decline increases with the spatial granularity of the
input data. Our augmentation technique improves SOA model performance by up to
67 % for RGB data and 90 % for HSI data, achieving performance at the level of
in-distribution performance on real OOD test data. Given the simplicity and
effectiveness of our augmentation method, it is a valuable tool for addressing
geometric domain shifts in surgical scene segmentation, regardless of the
underlying model. Our code and pre-trained models are publicly available at
https://github.com/IMSY-DKFZ/htc.",2024-08-27,"Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Alessandro Motta, Berkin Özdemir, Beat P. Müller-Stich, Felix Nickel, Lena Maier-Hein",http://arxiv.org/pdf/2408.15373v1,cs.LG
Temporal Graph Neural Network-Powered Paper Recommendation on Dynamic Citation Networks,"Due to the rapid growth of scientific publications, identifying all related
reference articles in the literature has become increasingly challenging yet
highly demanding. Existing methods primarily assess candidate publications from
a static perspective, focusing on the content of articles and their structural
information, such as citation relationships. There is a lack of research
regarding how to account for the evolving impact among papers on their
embeddings. Toward this goal, this paper introduces a temporal dimension to
paper recommendation strategies. The core idea is to continuously update a
paper's embedding when new citation relationships appear, enhancing its
relevance for future recommendations. Whenever a citation relationship is added
to the literature upon the publication of a paper, the embeddings of the two
related papers are updated through a Temporal Graph Neural Network (TGN). A
learnable memory update module based on a Recurrent Neural Network (RNN) is
utilized to study the evolution of the embedding of a paper in order to predict
its reference impact in a future timestamp. Such a TGN-based model learns a
pattern of how people's views of the paper may evolve, aiming to guide paper
recommendations more precisely. Extensive experiments on an open citation
network dataset, including 313,278 articles from
https://paperswithcode.com/about PaperWithCode, have demonstrated the
effectiveness of the proposed approach.",2024-08-27,"Junhao Shen, Mohammad Ausaf Ali Haqqani, Beichen Hu, Cheng Huang, Xihao Xie, Tsengdar Lee, Jia Zhang",http://arxiv.org/pdf/2408.15371v1,cs.LG
Optimization Solution Functions as Deterministic Policies for Offline Reinforcement Learning,"Offline reinforcement learning (RL) is a promising approach for many control
applications but faces challenges such as limited data coverage and value
function overestimation. In this paper, we propose an implicit actor-critic
(iAC) framework that employs optimization solution functions as a deterministic
policy (actor) and a monotone function over the optimal value of optimization
as a critic. By encoding optimality in the actor policy, we show that the
learned policies are robust to the suboptimality of the learned actor
parameters via the exponentially decaying sensitivity (EDS) property. We obtain
performance guarantees for the proposed iAC framework and show its benefits
over general function approximation schemes. Finally, we validate the proposed
framework on two real-world applications and show a significant improvement
over state-of-the-art (SOTA) offline RL methods.",2024-08-27,"Vanshaj Khattar, Ming Jin",http://arxiv.org/pdf/2408.15368v1,cs.LG
On the effectiveness of smartphone IMU sensors and Deep Learning in the detection of cardiorespiratory conditions,"This research introduces an innovative method for the early screening of
cardiorespiratory diseases based on an acquisition protocol, which leverages
commodity smartphone's Inertial Measurement Units (IMUs) and deep learning
techniques. We collected, in a clinical setting, a dataset featuring recordings
of breathing kinematics obtained by accelerometer and gyroscope readings from
five distinct body regions. We propose an end-to-end deep learning pipeline for
early cardiorespiratory disease screening, incorporating a preprocessing step
segmenting the data into individual breathing cycles, and a recurrent
bidirectional module capturing features from diverse body regions. We employed
Leave-one-out-cross-validation with Bayesian optimization for hyperparameter
tuning and model selection. The experimental results consistently demonstrated
the superior performance of a bidirectional Long-Short Term Memory (Bi-LSTM) as
a feature encoder architecture, yielding an average sensitivity of $0.81 \pm
0.02$, specificity of $0.82 \pm 0.05$, F1 score of $0.81 \pm 0.02$, and
accuracy of $80.2\% \pm 3.9$ across diverse seed variations. We also assessed
generalization capabilities on a skewed distribution, comprising exclusively
healthy patients not used in training, revealing a true negative rate of $74.8
\% \pm 4.5$. The sustained accuracy of predictions over time during breathing
cycles within a single patient underscores the efficacy of the preprocessing
strategy, highlighting the model's ability to discern significant patterns
throughout distinct phases of the respiratory cycle. This investigation
underscores the potential usefulness of widely available smartphones as devices
for timely cardiorespiratory disease screening in the general population, in
at-home settings, offering crucial assistance to public health efforts
(especially during a pandemic outbreaks, such as the recent COVID-19).",2024-08-27,"Lorenzo Simone, Luca Miglior, Vincenzo Gervasi, Luca Moroni, Emanuele Vignali, Emanuele Gasparotti, Simona Celi",http://arxiv.org/pdf/2408.15357v1,cs.LG
Optimal level set estimation for non-parametric tournament and crowdsourcing problems,"Motivated by crowdsourcing, we consider a problem where we partially observe
the correctness of the answers of $n$ experts on $d$ questions. In this paper,
we assume that both the experts and the questions can be ordered, namely that
the matrix $M$ containing the probability that expert $i$ answers correctly to
question $j$ is bi-isotonic up to a permutation of it rows and columns. When
$n=d$, this also encompasses the strongly stochastic transitive (SST) model
from the tournament literature. Here, we focus on the relevant problem of
deciphering small entries of $M$ from large entries of $M$, which is key in
crowdsourcing for efficient allocation of workers to questions. More precisely,
we aim at recovering a (or several) level set $p$ of the matrix up to a
precision $h$, namely recovering resp. the sets of positions $(i,j)$ in $M$
such that $M_{ij}>p+h$ and $M_{i,j}<p-h$. We consider, as a loss measure, the
number of misclassified entries. As our main result, we construct an efficient
polynomial-time algorithm that turns out to be minimax optimal for this
classification problem. This heavily contrasts with existing literature in the
SST model where, for the stronger reconstruction loss,
statistical-computational gaps have been conjectured. More generally, this
shades light on the nature of statistical-computational gaps for permutations
models.",2024-08-27,"Maximilian Graf, Alexandra Carpentier, Nicolas Verzelen",http://arxiv.org/pdf/2408.15356v1,cs.LG
Optimizing Lung Cancer Detection in CT Imaging: A Wavelet Multi-Layer Perceptron (WMLP) Approach Enhanced by Dragonfly Algorithm (DA),"Lung cancer stands as the preeminent cause of cancer-related mortality
globally. Prompt and precise diagnosis, coupled with effective treatment, is
imperative to reduce the fatality rates associated with this formidable
disease. This study introduces a cutting-edge deep learning framework for the
classification of lung cancer from CT scan imagery. The research encompasses a
suite of image pre-processing strategies, notably Canny edge detection, and
wavelet transformations, which precede the extraction of salient features and
subsequent classification via a Multi-Layer Perceptron (MLP). The optimization
process is further refined using the Dragonfly Algorithm (DA). The methodology
put forth has attained an impressive training and testing accuracy of 99.82\%,
underscoring its efficacy and reliability in the accurate diagnosis of lung
cancer.",2024-08-27,"Bitasadat Jamshidi, Nastaran Ghorbani, Mohsen Rostamy-Malkhalifeh",http://arxiv.org/pdf/2408.15355v1,cs.LG
Conformal Disentanglement: A Neural Framework for Perspective Synthesis and Differentiation,"For multiple scientific endeavors it is common to measure a phenomenon of
interest in more than one ways. We make observations of objects from several
different perspectives in space, at different points in time; we may also
measure different properties of a mixture using different types of instruments.
After collecting this heterogeneous information, it is necessary to be able to
synthesize a complete picture of what is `common' across its sources: the
subject we ultimately want to study. However, isolated (`clean') observations
of a system are not always possible: observations often contain information
about other systems in its environment, or about the measuring instruments
themselves. In that sense, each observation may contain information that `does
not matter' to the original object of study; this `uncommon' information
between sensors observing the same object may still be important, and
decoupling it from the main signal(s) useful. We introduce a neural network
autoencoder framework capable of both tasks: it is structured to identify
`common' variables, and, making use of orthogonality constraints to define
geometric independence, to also identify disentangled `uncommon' information
originating from the heterogeneous sensors. We demonstrate applications in
several computational examples.",2024-08-27,"George A. Kevrekidis, Eleni D. Koronaki, Yannis G. Kevrekidis",http://arxiv.org/pdf/2408.15344v1,cs.LG
"UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function","An LLM is pretrained on trillions of tokens, but the pretrained LLM may still
generate undesired responses. To solve this problem, alignment techniques such
as RLHF, DPO and KTO are proposed. However, these alignment techniques have
limitations. For example, RLHF requires training the reward model and policy
separately, which is complex, time-consuming, memory intensive and unstable
during training processes. DPO proposes a mapping between an optimal policy and
a reward, greatly simplifying the training process of RLHF. However, it can not
take full advantages of a reward model and it is limited to pairwise preference
data.
  In this paper, we propose \textbf{UN}ified \textbf{A}lignment (UNA) which
unifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the
classical RLHF objective, the optimal policy is induced by a generalize
implicit reward function. With this novel mapping between a reward model and an
optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised
learning of minimizing the difference between an implicit reward and an
explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and
reduce memory burden of RL fine-tuning process; 3. accommodate different
feedback types including pairwise, binary and scalar feedback. Downstream
experiments show UNA outperforms DPO, KTO and RLHF.",2024-08-27,"Zhichao Wang, Bin Bi, Can Huang, Shiva Kumar Pentyala, Zixu James Zhu, Sitaram Asur, Na Claire Cheng",http://arxiv.org/pdf/2408.15339v3,cs.LG
What makes math problems hard for reinforcement learning: a case study,"Using a long-standing conjecture from combinatorial group theory, we explore,
from multiple perspectives, the challenges of finding rare instances carrying
disproportionately high rewards. Based on lessons learned in the context
defined by the Andrews-Curtis conjecture, we propose algorithmic enhancements
and a topological hardness measure with implications for a broad class of
search problems. As part of our study, we also address several open
mathematical questions. Notably, we demonstrate the length reducibility of all
but two presentations in the Akbulut-Kirby series (1981), and resolve various
potential counterexamples in the Miller-Schupp series (1991), including three
infinite subfamilies.",2024-08-27,"Ali Shehper, Anibal M. Medina-Mardones, Lucas Fagan, Bartłomiej Lewandowski, Angus Gruen, Yang Qiu, Piotr Kucharski, Zhenghan Wang, Sergei Gukov",http://arxiv.org/pdf/2408.15332v2,cs.LG
Artificially intelligent Maxwell's demon for optimal control of open quantum systems,"Feedback control of open quantum systems is of fundamental importance for
practical applications in various contexts, ranging from quantum computation to
quantum error correction and quantum metrology. Its use in the context of
thermodynamics further enables the study of the interplay between information
and energy. However, deriving optimal feedback control strategies is highly
challenging, as it involves the optimal control of open quantum systems, the
stochastic nature of quantum measurement, and the inclusion of policies that
maximize a long-term time- and trajectory-averaged goal. In this work, we
employ a reinforcement learning approach to automate and capture the role of a
quantum Maxwell's demon: the agent takes the literal role of discovering
optimal feedback control strategies in qubit-based systems that maximize a
trade-off between measurement-powered cooling and measurement efficiency.
Considering weak or projective quantum measurements, we explore different
regimes based on the ordering between the thermalization, the measurement, and
the unitary feedback timescales, finding different and highly non-intuitive,
yet interpretable, strategies. In the thermalization-dominated regime, we find
strategies with elaborate finite-time thermalization protocols conditioned on
measurement outcomes. In the measurement-dominated regime, we find that optimal
strategies involve adaptively measuring different qubit observables reflecting
the acquired information, and repeating multiple weak measurements until the
quantum state is ""sufficiently pure"", leading to random walks in state space.
Finally, we study the case when all timescales are comparable, finding new
feedback control strategies that considerably outperform more intuitive ones.
We discuss a two-qubit example where we explore the role of entanglement and
conclude discussing the scaling of our results to quantum many-body systems.",2024-08-27,"Paolo Andrea Erdman, Robert Czupryniak, Bibek Bhandari, Andrew N. Jordan, Frank Noé, Jens Eisert, Giacomo Guarnieri",http://arxiv.org/pdf/2408.15328v1,cs.LG
Generative Verifiers: Reward Modeling as Next-Token Prediction,"Verifiers or reward models are often used to enhance the reasoning
performance of large language models (LLMs). A common approach is the Best-of-N
method, where N candidate solutions generated by the LLM are ranked by a
verifier, and the best one is selected. While LLM-based verifiers are typically
trained as discriminative classifiers to score solutions, they do not utilize
the text generation capabilities of pretrained LLMs. To overcome this
limitation, we instead propose training verifiers using the ubiquitous
next-token prediction objective, jointly on verification and solution
generation. Compared to standard verifiers, such generative verifiers (GenRM)
can benefit from several advantages of LLMs: they integrate seamlessly with
instruction tuning, enable chain-of-thought reasoning, and can utilize
additional test-time compute via majority voting for better verification. We
demonstrate that GenRM outperforms discriminative, DPO verifiers, and
LLM-as-a-Judge, resulting in large performance gains with Best-of-N, namely 5%
$\rightarrow$ 45.3% on algorithmic tasks and 73% $\rightarrow$ 93.4% on GSM8K.
In easy-to-hard generalization settings, we observe improvements of 28%
$\rightarrow$ 44.6% on MATH, and 37.9% $\rightarrow$ 53.5% on MMLU abstract
algebra. Furthermore, we find that training GenRM with synthetic verification
rationales is sufficient to pick out subtle errors on math problems. Finally,
we demonstrate that GenRM scales favorably with model size and test-time
compute.",2024-08-27,"Lunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar, Rishabh Agarwal",http://arxiv.org/pdf/2408.15240v3,cs.LG
The Mamba in the Llama: Distilling and Accelerating Hybrid Models,"Linear RNN architectures, like Mamba, can be competitive with Transformer
models in language modeling while having advantageous deployment
characteristics. Given the focus on training large-scale Transformer models, we
consider the challenge of converting these pretrained models for deployment. We
demonstrate that it is feasible to distill large Transformers into linear RNNs
by reusing the linear projection weights from attention layers with academic
GPU resources. The resulting hybrid model, which incorporates a quarter of the
attention layers, achieves performance comparable to the original Transformer
in chat benchmarks and outperforms open-source hybrid Mamba models trained from
scratch with trillions of tokens in both chat benchmarks and general
benchmarks. Moreover, we introduce a hardware-aware speculative decoding
algorithm that accelerates the inference speed of Mamba and hybrid models.
Overall we show how, with limited computation resources, we can remove many of
the original attention layers and generate from the resulting model more
efficiently. Our top-performing model, distilled from Llama3-8B-Instruct,
achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and
7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN
model. We also find that the distilled model has natural length extrapolation,
showing almost perfect accuracy in the needle-in-a-haystack test at 20x the
distillation length. Code and pre-trained checkpoints are open-sourced at
https://github.com/jxiw/MambaInLlama and
https://github.com/itsdaniele/speculative_mamba.",2024-08-27,"Junxiong Wang, Daniele Paliotta, Avner May, Alexander M. Rush, Tri Dao",http://arxiv.org/pdf/2408.15237v3,cs.LG
DCT-CryptoNets: Scaling Private Inference in the Frequency Domain,"The convergence of fully homomorphic encryption (FHE) and machine learning
offers unprecedented opportunities for private inference of sensitive data. FHE
enables computation directly on encrypted data, safeguarding the entire machine
learning pipeline, including data and model confidentiality. However, existing
FHE-based implementations for deep neural networks face significant challenges
in computational cost, latency, and scalability, limiting their practical
deployment. This paper introduces DCT-CryptoNets, a novel approach that
operates directly in the frequency-domain to reduce the burden of
computationally expensive non-linear activations and homomorphic bootstrap
operations during private inference. It does so by utilizing the discrete
cosine transform (DCT), commonly employed in JPEG encoding, which has inherent
compatibility with remote computing services where images are generally stored
and transmitted in this encoded format. DCT-CryptoNets demonstrates a
substantial latency reductions of up to 5.3$\times$ compared to prior work on
benchmark image classification tasks. Notably, it demonstrates inference on the
ImageNet dataset within 2.5 hours (down from 12.5 hours on equivalent 96-thread
compute resources). Furthermore, by learning perceptually salient low-frequency
information DCT-CryptoNets improves the reliability of encrypted predictions
compared to RGB-based networks by reducing error accumulating homomorphic
bootstrap operations. DCT-CryptoNets also demonstrates superior scalability to
RGB-based networks by further reducing computational cost as image size
increases. This study demonstrates a promising avenue for achieving efficient
and practical private inference of deep learning models on high resolution
images seen in real-world applications.",2024-08-27,"Arjun Roy, Kaushik Roy",http://arxiv.org/pdf/2408.15231v2,cs.LG
LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet,"Recent large language model (LLM) defenses have greatly improved models'
ability to refuse harmful queries, even when adversarially attacked. However,
LLM defenses are primarily evaluated against automated adversarial attacks in a
single turn of conversation, an insufficient threat model for real-world
malicious use. We demonstrate that multi-turn human jailbreaks uncover
significant vulnerabilities, exceeding 70% attack success rate (ASR) on
HarmBench against defenses that report single-digit ASRs with automated
single-turn attacks. Human jailbreaks also reveal vulnerabilities in machine
unlearning defenses, successfully recovering dual-use biosecurity knowledge
from unlearned models. We compile these results into Multi-Turn Human
Jailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks.
We publicly release MHJ alongside a compendium of jailbreak tactics developed
across dozens of commercial red teaming engagements, supporting research
towards stronger LLM defenses.",2024-08-27,"Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, Summer Yue",http://arxiv.org/pdf/2408.15221v2,cs.LG
Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models,"Fine-tuning large language models (LLMs) on human preferences, typically
through reinforcement learning from human feedback (RLHF), has proven
successful in enhancing their capabilities. However, ensuring the safety of
LLMs during fine-tuning remains a critical concern, and mitigating the
potential conflicts in safety and helpfulness is costly in RLHF. To address
this issue, we propose a supervised learning framework called Bi-Factorial
Preference Optimization (BFPO), which re-parameterizes a joint RLHF objective
of both safety and helpfulness into a single supervised learning objective. In
supervised optimization, a labeling function is used to capture the global
preferences ranking to balance both safety and helpfulness. To evaluate BFPO,
we develop a benchmark that includes comprehensive discriminative and
generative tasks for helpfulness and harmlessness. The results indicate that
our method significantly outperforms existing approaches in both safety and
helpfulness. Moreover, BFPO achieves the same level of safety as methods that
heavily rely on human labor with less than 10\% of the computational resources
and human prompting and annotation process. The training recipes can be found
here: https://github.com/wx-zhang/bfpo.",2024-08-27,"Wenxuan Zhang, Philip H. S. Torr, Mohamed Elhoseiny, Adel Bibi",http://arxiv.org/pdf/2408.15313v2,cs.LG
Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy,"While Large Language Models (LLMs) are being quickly adapted to many domains,
including healthcare, their strengths and pitfalls remain under-explored. In
our study, we examine the effects of prompt engineering to guide Large Language
Models (LLMs) in delivering parts of a Problem-Solving Therapy (PST) session
via text, particularly during the symptom identification and assessment phase
for personalized goal setting. We present evaluation results of the models'
performances by automatic metrics and experienced medical professionals. We
demonstrate that the models' capability to deliver protocolized therapy can be
improved with the proper use of prompt engineering methods, albeit with
limitations. To our knowledge, this study is among the first to assess the
effects of various prompting techniques in enhancing a generalist model's
ability to deliver psychotherapy, focusing on overall quality, consistency, and
empathy. Exploring LLMs' potential in delivering psychotherapy holds promise
with the current shortage of mental health professionals amid significant
needs, enhancing the potential utility of AI-based and AI-enhanced care
services.",2024-08-27,"Daniil Filienko, Yinzhou Wang, Caroline El Jazmi, Serena Xie, Trevor Cohen, Martine De Cock, Weichao Yuwen",http://arxiv.org/pdf/2409.00112v1,cs.LG
RGDA-DDI: Residual graph attention network and dual-attention based framework for drug-drug interaction prediction,"Recent studies suggest that drug-drug interaction (DDI) prediction via
computational approaches has significant importance for understanding the
functions and co-prescriptions of multiple drugs. However, the existing silico
DDI prediction methods either ignore the potential interactions among drug-drug
pairs (DDPs), or fail to explicitly model and fuse the multi-scale drug feature
representations for better prediction. In this study, we propose RGDA-DDI, a
residual graph attention network (residual-GAT) and dual-attention based
framework for drug-drug interaction prediction. A residual-GAT module is
introduced to simultaneously learn multi-scale feature representations from
drugs and DDPs. In addition, a dual-attention based feature fusion block is
constructed to learn local joint interaction representations. A series of
evaluation metrics demonstrate that the RGDA-DDI significantly improved DDI
prediction performance on two public benchmark datasets, which provides a new
insight into drug development.",2024-08-27,"Changjian Zhou, Xin Zhang, Jiafeng Li, Jia Song, Wensheng Xiang",http://arxiv.org/pdf/2408.15310v1,cs.LG
Pattern based learning and optimisation through pricing for bin packing problem,"As a popular form of knowledge and experience, patterns and their
identification have been critical tasks in most data mining applications.
However, as far as we are aware, no study has systematically examined the
dynamics of pattern values and their reuse under varying conditions. We argue
that when problem conditions such as the distributions of random variables
change, the patterns that performed well in previous circumstances may become
less effective and adoption of these patterns would result in sub-optimal
solutions. In response, we make a connection between data mining and the
duality theory in operations research and propose a novel scheme to efficiently
identify patterns and dynamically quantify their values for each specific
condition. Our method quantifies the value of patterns based on their ability
to satisfy stochastic constraints and their effects on the objective value,
allowing high-quality patterns and their combinations to be detected. We use
the online bin packing problem to evaluate the effectiveness of the proposed
scheme and illustrate the online packing procedure with the guidance of
patterns that address the inherent uncertainty of the problem. Results show
that the proposed algorithm significantly outperforms the state-of-the-art
methods. We also analysed in detail the distinctive features of the proposed
methods that lead to performance improvement and the special cases where our
method can be further improved.",2024-08-27,"Huayan Zhang, Ruibin Bai, Tie-Yan Liu, Jiawei Li, Bingchen Lin, Jianfeng Ren",http://arxiv.org/pdf/2409.04456v1,cs.LG
Improving Adversarial Robustness in Android Malware Detection by Reducing the Impact of Spurious Correlations,"Machine learning (ML) has demonstrated significant advancements in Android
malware detection (AMD); however, the resilience of ML against realistic
evasion attacks remains a major obstacle for AMD. One of the primary factors
contributing to this challenge is the scarcity of reliable generalizations.
Malware classifiers with limited generalizability tend to overfit spurious
correlations derived from biased features. Consequently, adversarial examples
(AEs), generated by evasion attacks, can modify these features to evade
detection. In this study, we propose a domain adaptation technique to improve
the generalizability of AMD by aligning the distribution of malware samples and
AEs. Specifically, we utilize meaningful feature dependencies, reflecting
domain constraints in the feature space, to establish a robust feature space.
Training on the proposed robust feature space enables malware classifiers to
learn from predefined patterns associated with app functionality rather than
from individual features. This approach helps mitigate spurious correlations
inherent in the initial feature space. Our experiments conducted on DREBIN, a
renowned Android malware detector, demonstrate that our approach surpasses the
state-of-the-art defense, Sec-SVM, when facing realistic evasion attacks. In
particular, our defense can improve adversarial robustness by up to 55% against
realistic evasion attacks compared to Sec-SVM.",2024-08-27,"Hamid Bostani, Zhengyu Zhao, Veelasha Moonsamy",http://arxiv.org/pdf/2408.16025v1,cs.LG
Automatic 8-tissue Segmentation for 6-month Infant Brains,"Numerous studies have highlighted that atypical brain development,
particularly during infancy and toddlerhood, is linked to an increased
likelihood of being diagnosed with a neurodevelopmental condition, such as
autism. Accurate brain tissue segmentations for morphological analysis are
essential in numerous infant studies. However, due to ongoing white matter (WM)
myelination changing tissue contrast in T1- and T2-weighted images, automatic
tissue segmentation in 6-month infants is particularly difficult. On the other
hand, manual labelling by experts is time-consuming and labor-intensive. In
this study, we propose the first 8-tissue segmentation pipeline for
six-month-old infant brains. This pipeline utilizes domain adaptation (DA)
techniques to leverage our longitudinal data, including neonatal images
segmented with the neonatal Developing Human Connectome Project structural
pipeline. Our pipeline takes raw 6-month images as inputs and generates the
8-tissue segmentation as outputs, forming an end-to-end segmentation pipeline.
The segmented tissues include WM, gray matter (GM), cerebrospinal fluid (CSF),
ventricles, cerebellum, basal ganglia, brainstem, and hippocampus/amygdala.
Cycle-Consistent Generative Adversarial Network (CycleGAN) and Attention U-Net
were employed to achieve the image contrast transformation between neonatal and
6-month images and perform tissue segmentation on the synthesized 6-month
images (neonatal images with 6-month intensity contrast), respectively.
Moreover, we incorporated the segmentation outputs from Infant Brain Extraction
and Analysis Toolbox (iBEAT) and another Attention U-Net to further enhance the
performance and construct the end-to-end segmentation pipeline. Our evaluation
with real 6-month images achieved a DICE score of 0.92, an HD95 of 1.6, and an
ASSD of 0.42.",2024-08-27,"Yilan Dong, Vanessa Kyriakopoulou, Irina Grigorescu, Grainne McAlonan, Dafnis Batalle, Maria Deprez",http://arxiv.org/pdf/2408.15198v1,cs.LG
In-ear ECG Signal Enhancement with Denoising Convolutional Autoencoders,"The cardiac dipole has been shown to propagate to the ears, now a common site
for consumer wearable electronics, enabling the recording of electrocardiogram
(ECG) signals. However, in-ear ECG recordings often suffer from significant
noise due to their small amplitude and the presence of other physiological
signals, such as electroencephalogram (EEG), which complicates the extraction
of cardiovascular features. This study addresses this issue by developing a
denoising convolutional autoencoder (DCAE) to enhance ECG information from
in-ear recordings, producing cleaner ECG outputs. The model is evaluated using
a dataset of in-ear ECGs and corresponding clean Lead I ECGs from 45 healthy
participants. The results demonstrate a substantial improvement in
signal-to-noise ratio (SNR), with a median increase of 5.9 dB. Additionally,
the model significantly improved heart rate estimation accuracy, reducing the
mean absolute error by almost 70% and increasing R-peak detection precision to
a median value of 90%. We also trained and validated the model using a
synthetic dataset, generated from real ECG signals, including abnormal cardiac
morphologies, corrupted by pink noise. The results obtained show effective
removal of noise sources with clinically plausible waveform reconstruction
ability.",2024-08-27,"Edoardo Occhipinti, Marek Zylinski, Harry J. Davies, Amir Nassibi, Matteo Bermond, Patrik Bachtiger, Nicholas S. Peters, Danilo P. Mandic",http://arxiv.org/pdf/2409.05891v1,cs.LG
On latent dynamics learning in nonlinear reduced order modeling,"In this work, we present the novel mathematical framework of latent dynamics
models (LDMs) for reduced order modeling of parameterized nonlinear
time-dependent PDEs. Our framework casts this latter task as a nonlinear
dimensionality reduction problem, while constraining the latent state to evolve
accordingly to an (unknown) dynamical system. A time-continuous setting is
employed to derive error and stability estimates for the LDM approximation of
the full order model (FOM) solution. We analyze the impact of using an explicit
Runge-Kutta scheme in the time-discrete setting, resulting in the
$\Delta\text{LDM}$ formulation, and further explore the learnable setting,
$\Delta\text{LDM}_\theta$, where deep neural networks approximate the discrete
LDM components, while providing a bounded approximation error with respect to
the FOM. Moreover, we extend the concept of parameterized Neural ODE - recently
proposed as a possible way to build data-driven dynamical systems with varying
input parameters - to be a convolutional architecture, where the input
parameters information is injected by means of an affine modulation mechanism,
while designing a convolutional autoencoder neural network able to retain
spatial-coherence, thus enhancing interpretability at the latent level.
Numerical experiments, including the Burgers' and the
advection-reaction-diffusion equations, demonstrate the framework's ability to
obtain, in a multi-query context, a time-continuous approximation of the FOM
solution, thus being able to query the LDM approximation at any given time
instance while retaining a prescribed level of accuracy. Our findings highlight
the remarkable potential of the proposed LDMs, representing a mathematically
rigorous framework to enhance the accuracy and approximation capabilities of
reduced order modeling for time-dependent parameterized PDEs.",2024-08-27,"Nicola Farenga, Stefania Fresca, Simone Brivio, Andrea Manzoni",http://arxiv.org/pdf/2408.15183v2,cs.LG
Exploiting Approximate Symmetry for Efficient Multi-Agent Reinforcement Learning,"Mean-field games (MFG) have become significant tools for solving large-scale
multi-agent reinforcement learning problems under symmetry. However, the
assumption of exact symmetry limits the applicability of MFGs, as real-world
scenarios often feature inherent heterogeneity. Furthermore, most works on MFG
assume access to a known MFG model, which might not be readily available for
real-world finite-agent games. In this work, we broaden the applicability of
MFGs by providing a methodology to extend any finite-player, possibly
asymmetric, game to an ""induced MFG"". First, we prove that $N$-player dynamic
games can be symmetrized and smoothly extended to the infinite-player continuum
via explicit Kirszbraun extensions. Next, we propose the notion of
$\alpha,\beta$-symmetric games, a new class of dynamic population games that
incorporate approximate permutation invariance. For $\alpha,\beta$-symmetric
games, we establish explicit approximation bounds, demonstrating that a Nash
policy of the induced MFG is an approximate Nash of the $N$-player dynamic
game. We show that TD learning converges up to a small bias using trajectories
of the $N$-player game with finite-sample guarantees, permitting symmetrized
learning without building an explicit MFG model. Finally, for certain games
satisfying monotonicity, we prove a sample complexity of
$\widetilde{\mathcal{O}}(\varepsilon^{-6})$ for the $N$-agent game to learn an
$\varepsilon$-Nash up to symmetrization bias. Our theory is supported by
evaluations on MARL benchmarks with thousands of agents.",2024-08-27,"Batuhan Yardim, Niao He",http://arxiv.org/pdf/2408.15173v1,cs.LG
Latent Ewald summation for machine learning of long-range interactions,"Machine learning interatomic potentials (MLIPs) often neglect long-range
interactions, such as electrostatic and dispersion forces. In this work, we
introduce a straightforward and efficient method to account for long-range
interactions by learning a latent variable from local atomic descriptors and
applying an Ewald summation to this variable. We demonstrate that in systems
including charged and polar molecular dimers, bulk water, and water-vapor
interface, standard short-ranged MLIPs can lead to unphysical predictions even
when employing message passing. The long-range models effectively eliminate
these artifacts, with only about twice the computational cost of short-range
MLIPs.",2024-08-27,Bingqing Cheng,http://arxiv.org/pdf/2408.15165v2,cs.LG
Parameter-Efficient Quantized Mixture-of-Experts Meets Vision-Language Instruction Tuning for Semiconductor Electron Micrograph Analysis,"Semiconductors, crucial to modern electronics, are generally under-researched
in foundational models. It highlights the need for research to enhance the
semiconductor device technology portfolio and aid in high-end device
fabrication. In this paper, we introduce sLAVA, a small-scale vision-language
assistant tailored for semiconductor manufacturing, with a focus on electron
microscopy image analysis. It addresses challenges of data scarcity and
acquiring high-quality, expert-annotated data. We employ a teacher-student
paradigm, using a foundational vision language model like GPT-4 as a teacher to
create instruction-following multimodal data for customizing the student model,
sLAVA, for electron microscopic image analysis tasks on consumer hardware with
limited budgets. Our approach allows enterprises to further fine-tune the
proposed framework with their proprietary data securely within their own
infrastructure, protecting intellectual property. Rigorous experiments validate
that our framework surpasses traditional methods, handles data shifts, and
enables high-throughput screening.",2024-08-27,"Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2408.15305v1,cs.LG
Delay as Payoff in MAB,"In this paper, we investigate a variant of the classical stochastic
Multi-armed Bandit (MAB) problem, where the payoff received by an agent (either
cost or reward) is both delayed, and directly corresponds to the magnitude of
the delay. This setting models faithfully many real world scenarios such as the
time it takes for a data packet to traverse a network given a choice of route
(where delay serves as the agent's cost); or a user's time spent on a web page
given a choice of content (where delay serves as the agent's reward).
  Our main contributions are tight upper and lower bounds for both the cost and
reward settings. For the case that delays serve as costs, which we are the
first to consider, we prove optimal regret that scales as $\sum_{i:\Delta_i >
0}\frac{\log T}{\Delta_i} + d^*$, where $T$ is the maximal number of steps,
$\Delta_i$ are the sub-optimality gaps and $d^*$ is the minimal expected delay
amongst arms. For the case that delays serves as rewards, we show optimal
regret of $\sum_{i:\Delta_i > 0}\frac{\log T}{\Delta_i} + \bar{d}$, where $\bar
d$ is the second maximal expected delay. These improve over the regret in the
general delay-dependent payoff setting, which scales as $\sum_{i:\Delta_i >
0}\frac{\log T}{\Delta_i} + D$, where $D$ is the maximum possible delay. Our
regret bounds highlight the difference between the cost and reward scenarios,
showing that the improvement in the cost scenario is more significant than for
the reward. Finally, we accompany our theoretical results with an empirical
evaluation.",2024-08-27,"Ofir Schlisselberg, Ido Cohen, Tal Lancewicki, Yishay Mansour",http://arxiv.org/pdf/2408.15158v2,cs.LG
Multi-Modal Instruction-Tuning Small-Scale Language-and-Vision Assistant for Semiconductor Electron Micrograph Analysis,"We present a novel framework for analyzing and interpreting electron
microscopy images in semiconductor manufacturing using vision-language
instruction tuning. The framework employs a unique teacher-student approach,
leveraging pre-trained multimodal large language models such as GPT-4 to
generate instruction-following data for zero-shot visual question answering
(VQA) and classification tasks, customizing smaller multimodal models (SMMs)
for microscopy image analysis, resulting in an instruction-tuned
language-and-vision assistant. Our framework merges knowledge engineering with
machine learning to integrate domain-specific expertise from larger to smaller
multimodal models within this specialized field, greatly reducing the need for
extensive human labeling. Our study presents a secure, cost-effective, and
customizable approach for analyzing microscopy images, addressing the
challenges of adopting proprietary models in semiconductor manufacturing.",2024-08-27,"Sakhinana Sagar Srinivas, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2409.07463v1,cs.LG
TCNFormer: Temporal Convolutional Network Former for Short-Term Wind Speed Forecasting,"Global environmental challenges and rising energy demands have led to
extensive exploration of wind energy technologies. Accurate wind speed
forecasting (WSF) is crucial for optimizing wind energy capture and ensuring
system stability. However, predicting wind speed remains challenging due to its
inherent randomness, fluctuation, and unpredictability. This study proposes the
Temporal Convolutional Network Former (TCNFormer) for short-term (12-hour) wind
speed forecasting. The TCNFormer integrates the Temporal Convolutional Network
(TCN) and transformer encoder to capture the spatio-temporal features of wind
speed. The transformer encoder consists of two distinct attention mechanisms:
causal temporal multi-head self-attention (CT-MSA) and temporal external
attention (TEA). CT-MSA ensures that the output of a step derives only from
previous steps, i.e., causality. Locality is also introduced to improve
efficiency. TEA explores potential relationships between different sample
sequences in wind speed data. This study utilizes wind speed data from the NASA
Prediction of Worldwide Energy Resources (NASA POWER) of Patenga Sea Beach,
Chittagong, Bangladesh (latitude 22.2352{\deg} N, longitude 91.7914{\deg} E)
over a year (six seasons). The findings indicate that the TCNFormer outperforms
state-of-the-art models in prediction accuracy. The proposed TCNFormer presents
a promising method for spatio-temporal WSF and may achieve desirable
performance in real-world applications of wind power systems.",2024-08-27,"Abid Hasan Zim, Aquib Iqbal, Asad Malik, Zhicheng Dong, Hanzhou Wu",http://arxiv.org/pdf/2408.15737v1,cs.LG
How transformers learn structured data: insights from hierarchical filtering,"Understanding the learning process and the embedded computation in
transformers is becoming a central goal for the development of interpretable
AI. In the present study, we introduce a hierarchical filtering procedure for
generative models of sequences on trees, allowing us to hand-tune the range of
positional correlations in the data. Leveraging this controlled setting, we
provide evidence that vanilla encoder-only transformers can approximate the
exact inference algorithm when trained on root classification and masked
language modeling tasks, and study how this computation is discovered and
implemented. We find that correlations at larger distances, corresponding to
increasing layers of the hierarchy, are sequentially included by the network
during training. Moreover, by comparing attention maps from models trained with
varying degrees of filtering and by probing the different encoder levels, we
find clear evidence of a reconstruction of correlations on successive length
scales corresponding to the various levels of the hierarchy, which we relate to
a plausible implementation of the exact inference algorithm within the same
architecture.",2024-08-27,"Jerome Garnier-Brun, Marc Mézard, Emanuele Moscato, Luca Saglietti",http://arxiv.org/pdf/2408.15138v2,cs.LG
Low-Budget Simulation-Based Inference with Bayesian Neural Networks,"Simulation-based inference methods have been shown to be inaccurate in the
data-poor regime, when training simulations are limited or expensive. Under
these circumstances, the inference network is particularly prone to
overfitting, and using it without accounting for the computational uncertainty
arising from the lack of identifiability of the network weights can lead to
unreliable results. To address this issue, we propose using Bayesian neural
networks in low-budget simulation-based inference, thereby explicitly
accounting for the computational uncertainty of the posterior approximation. We
design a family of Bayesian neural network priors that are tailored for
inference and show that they lead to well-calibrated posteriors on tested
benchmarks, even when as few as $O(10)$ simulations are available. This opens
up the possibility of performing reliable simulation-based inference using very
expensive simulators, as we demonstrate on a problem from the field of
cosmology where single simulations are computationally expensive. We show that
Bayesian neural networks produce informative and well-calibrated posterior
estimates with only a few hundred simulations.",2024-08-27,"Arnaud Delaunoy, Maxence de la Brassinne Bonardeaux, Siddharth Mishra-Sharma, Gilles Louppe",http://arxiv.org/pdf/2408.15136v1,cs.LG
Using LLMs for Explaining Sets of Counterfactual Examples to Final Users,"Causality is vital for understanding true cause-and-effect relationships
between variables within predictive models, rather than relying on mere
correlations, making it highly relevant in the field of Explainable AI. In an
automated decision-making scenario, causal inference methods can analyze the
underlying data-generation process, enabling explanations of a model's decision
by manipulating features and creating counterfactual examples. These
counterfactuals explore hypothetical scenarios where a minimal number of
factors are altered, providing end-users with valuable information on how to
change their situation. However, interpreting a set of multiple counterfactuals
can be challenging for end-users who are not used to analyzing raw data
records. In our work, we propose a novel multi-step pipeline that uses
counterfactuals to generate natural language explanations of actions that will
lead to a change in outcome in classifiers of tabular data using LLMs. This
pipeline is designed to guide the LLM through smaller tasks that mimic human
reasoning when explaining a decision based on counterfactual cases. We
conducted various experiments using a public dataset and proposed a method of
closed-loop evaluation to assess the coherence of the final explanation with
the counterfactuals, as well as the quality of the content. Results are
promising, although further experiments with other datasets and human
evaluations should be carried out.",2024-08-27,"Arturo Fredes, Jordi Vitria",http://arxiv.org/pdf/2408.15133v1,cs.LG
Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments,"Monitoring, understanding, and optimizing the energy consumption of Machine
Learning (ML) are various reasons why it is necessary to evaluate the energy
usage of ML. However, there exists no universal tool that can answer this
question for all use cases, and there may even be disagreement on how to
evaluate energy consumption for a specific use case. Tools and methods are
based on different approaches, each with their own advantages and drawbacks,
and they need to be mapped out and explained in order to select the most
suitable one for a given situation. We address this challenge through two
approaches. First, we conduct a systematic literature review of all tools and
methods that permit to evaluate the energy consumption of ML (both at training
and at inference), irrespective of whether they were originally designed for
machine learning or general software. Second, we develop and use an
experimental protocol to compare a selection of these tools and methods. The
comparison is both qualitative and quantitative on a range of ML tasks of
different nature (vision, language) and computational complexity. The
systematic literature review serves as a comprehensive guide for understanding
the array of tools and methods used in evaluating energy consumption of ML, for
various use cases going from basic energy monitoring to consumption
optimization. Two open-source repositories are provided for further
exploration. The first one contains tools that can be used to replicate this
work or extend the current review. The second repository houses the
experimental protocol, allowing users to augment the protocol with new ML
computing tasks and additional energy evaluation tools.",2024-08-27,"Charlotte Rodriguez, Laura Degioanni, Laetitia Kameni, Richard Vidal, Giovanni Neglia",http://arxiv.org/pdf/2408.15128v1,cs.LG
Force-Guided Bridge Matching for Full-Atom Time-Coarsened Dynamics of Peptides,"Molecular Dynamics (MD) is crucial in various fields such as materials
science, chemistry, and pharmacology to name a few. Conventional MD software
struggles with the balance between time cost and prediction accuracy, which
restricts its wider application. Recently, data-driven approaches based on deep
generative models have been devised for time-coarsened dynamics, which aim at
learning dynamics of diverse molecular systems over a long timestep, enjoying
both universality and efficiency. Nevertheless, most current methods are
designed solely to learn from the data distribution regardless of the
underlying Boltzmann distribution, and the physics priors such as energies and
forces are constantly overlooked. In this work, we propose a conditional
generative model called Force-guided Bridge Matching (FBM), which learns
full-atom time-coarsened dynamics and targets the Boltzmann-constrained
distribution. With the guidance of our delicately-designed intermediate force
field, FBM leverages favourable physics priors into the generation process,
giving rise to enhanced simulations. Experiments on two datasets consisting of
peptides verify our superiority in terms of comprehensive metrics and
demonstrate transferability to unseen systems.",2024-08-27,"Ziyang Yu, Wenbing Huang, Yang Liu",http://arxiv.org/pdf/2408.15126v6,cs.LG
The Uniqueness of LLaMA3-70B Series with Per-Channel Quantization,"We have observed a distinctive quantization-related behavior in the
LLaMA3/3.1-70B models that is absent in both the LLaMA2-70B and
LLaMA3/3.1/3.2-1B/3B/8B/405B models. Quantization is a crucial technique for
deploying large language models (LLMs) efficiently. The impact of W8A8
post-training quantization on model accuracy, especially on the recently
released LLaMA3/3.1 model series, remains contentious. In this paper, we
explore three key questions: What makes the LLaMA3-70B model series uniquely
vulnerable to quantization? Why is this the case? And how can the issue be
addressed? We empirically investigate multiple LLMs featured on an open LLM
leaderboard, discovering that the LLaMA3-70B model series have a unique
accuracy degradation behavior with W8A8 per-channel post-training quantization.
In contrast, other model series such as LLaMA2, LLaMA3/3.1-8B, LLaMA3.2, Qwen,
Mixtral, Mistral, Phi-3, and Falcon demonstrate robust performance with W8A8.
Contrary to previous assertions attributing degradation to the large dynamic
range of activations, our findings indicate that the weight distribution of the
LLaMA3-70B is the primary factor behind the vulnerability. By meticulously
analyzing the distinct characteristics of weight distributions across
Transformer blocks, we propose two solutions that make different tradeoffs in
hardware/software overhead. First, we propose a mixed strategy where less than
3\% of the layers employ finer per-group W8A8 quantization granularity. Second,
we introduce a bi-smoothing strategy that balances quantization errors between
weights and activations while maintaining per-channel quantization throughout.
Experimental results demonstrate that both strategies effectively preserve the
accuracy of the entire LLaMA3-70B model series under W8A8 quantization,
achieving performance on par with their FP16 counterparts.",2024-08-27,Minghai Qin,http://arxiv.org/pdf/2408.15301v2,cs.LG
Evaluating the Impact of Multiple DER Aggregators on Wholesale Energy Markets: A Hybrid Mean Field Approach,"The integration of distributed energy resources (DERs) into wholesale energy
markets can greatly enhance grid flexibility, improve market efficiency, and
contribute to a more sustainable energy future. As DERs -- such as solar PV
panels and energy storage -- proliferate, effective mechanisms are needed to
ensure that small prosumers can participate meaningfully in these markets. We
study a wholesale market model featuring multiple DER aggregators, each
controlling a portfolio of DER resources and bidding into the market on behalf
of the DER asset owners. The key of our approach lies in recognizing the
repeated nature of market interactions the ability of participants to learn and
adapt over time. Specifically, Aggregators repeatedly interact with each other
and with other suppliers in the wholesale market, collectively shaping
wholesale electricity prices (aka the locational marginal prices (LMPs)). We
model this multi-agent interaction using a mean-field game (MFG), which uses
market information -- reflecting the average behavior of market participants --
to enable each aggregator to predict long-term LMP trends and make informed
decisions. For each aggregator, because they control the DERs within their
portfolio under certain contract structures, we employ a mean-field control
(MFC) approach (as opposed to a MFG) to learn an optimal policy that maximizes
the total rewards of the DERs under their management. We also propose a
reinforcement learning (RL)-based method to help each agent learn optimal
strategies within the MFG framework, enhancing their ability to adapt to market
conditions and uncertainties. Numerical simulations show that LMPs quickly
reach a steady state in the hybrid mean-field approach. Furthermore, our
results demonstrate that the combination of energy storage and mean-field
learning significantly reduces price volatility compared to scenarios without
storage.",2024-08-27,"Jun He, Andrew L. Liu",http://arxiv.org/pdf/2409.00107v1,cs.LG
Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries,"Implicit Neural Representations have gained prominence as a powerful
framework for capturing complex data modalities, encompassing a wide range from
3D shapes to images and audio. Within the realm of 3D shape representation,
Neural Signed Distance Functions (SDF) have demonstrated remarkable potential
in faithfully encoding intricate shape geometry. However, learning SDFs from
sparse 3D point clouds in the absence of ground truth supervision remains a
very challenging task. While recent methods rely on smoothness priors to
regularize the learning, our method introduces a regularization term that
leverages adversarial samples around the shape to improve the learned SDFs.
Through extensive experiments and evaluations, we illustrate the efficacy of
our proposed method, highlighting its capacity to improve SDF learning with
respect to baselines and the state-of-the-art using synthetic and real data.",2024-08-27,"Amine Ouasfi, Adnane Boukhayma",http://arxiv.org/pdf/2408.15114v1,cs.LG
S-MolSearch: 3D Semi-supervised Contrastive Learning for Bioactive Molecule Search,"Virtual Screening is an essential technique in the early phases of drug
discovery, aimed at identifying promising drug candidates from vast molecular
libraries. Recently, ligand-based virtual screening has garnered significant
attention due to its efficacy in conducting extensive database screenings
without relying on specific protein-binding site information. Obtaining binding
affinity data for complexes is highly expensive, resulting in a limited amount
of available data that covers a relatively small chemical space. Moreover,
these datasets contain a significant amount of inconsistent noise. It is
challenging to identify an inductive bias that consistently maintains the
integrity of molecular activity during data augmentation. To tackle these
challenges, we propose S-MolSearch, the first framework to our knowledge, that
leverages molecular 3D information and affinity information in semi-supervised
contrastive learning for ligand-based virtual screening. Drawing on the
principles of inverse optimal transport, S-MolSearch efficiently processes both
labeled and unlabeled data, training molecular structural encoders while
generating soft labels for the unlabeled data. This design allows S-MolSearch
to adaptively utilize unlabeled data within the learning process. Empirically,
S-MolSearch demonstrates superior performance on widely-used benchmarks
LIT-PCBA and DUD-E. It surpasses both structure-based and ligand-based virtual
screening methods for AUROC, BEDROC and EF.",2024-08-27,"Gengmo Zhou, Zhen Wang, Feng Yu, Guolin Ke, Zhewei Wei, Zhifeng Gao",http://arxiv.org/pdf/2409.07462v2,cs.LG
Zero-Shot Visual Reasoning by Vision-Language Models: Benchmarking and Analysis,"Vision-language models (VLMs) have shown impressive zero- and few-shot
performance on real-world visual question answering (VQA) benchmarks, alluding
to their capabilities as visual reasoning engines. However, the benchmarks
being used conflate ""pure"" visual reasoning with world knowledge, and also have
questions that involve a limited number of reasoning steps. Thus, it remains
unclear whether a VLM's apparent visual reasoning performance is due to its
world knowledge, or due to actual visual reasoning capabilities.
  To clarify this ambiguity, we systematically benchmark and dissect the
zero-shot visual reasoning capabilities of VLMs through synthetic datasets that
require minimal world knowledge, and allow for analysis over a broad range of
reasoning steps. We focus on two novel aspects of zero-shot visual reasoning:
i) evaluating the impact of conveying scene information as either visual
embeddings or purely textual scene descriptions to the underlying large
language model (LLM) of the VLM, and ii) comparing the effectiveness of
chain-of-thought prompting to standard prompting for zero-shot visual
reasoning.
  We find that the underlying LLMs, when provided textual scene descriptions,
consistently perform better compared to being provided visual embeddings. In
particular, 18% higher accuracy is achieved on the PTR dataset. We also find
that CoT prompting performs marginally better than standard prompting only for
the comparatively large GPT-3.5-Turbo (175B) model, and does worse for
smaller-scale models. This suggests the emergence of CoT abilities for visual
reasoning in LLMs at larger scales even when world knowledge is limited.
Overall, we find limitations in the abilities of VLMs and LLMs for more complex
visual reasoning, and highlight the important role that LLMs can play in visual
reasoning.",2024-08-27,"Aishik Nagar, Shantanu Jaiswal, Cheston Tan",http://arxiv.org/pdf/2409.00106v1,cs.LG
GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs,"Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and
democratized the usage of Large Language Models (LLMs). Recent studies have
shown that a small subset of weights significantly impacts performance. Based
on this observation, we introduce a novel PEFT method, called Gaussian noise
Injected Fine Tuning of Salient Weights (GIFT-SW). Our method updates only
salient columns, while injecting Gaussian noise into non-salient ones. To
identify these columns, we developeda generalized sensitivity metric that
extends and unifies metrics from previous studies. Experiments with LLaMA
models demonstrate that GIFT-SW outperforms full fine-tuning and modern PEFT
methods under the same computational budget. Moreover, GIFT-SW offers practical
advantages to recover performance of models subjected to mixed-precision
quantization with keeping salient weights in full precision.",2024-08-27,"Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Egor Venediktov, Mariya Krylova, Aleksandr Zuev, Evgeny Burnaev",http://arxiv.org/pdf/2408.15300v1,cs.LG
Negation Blindness in Large Language Models: Unveiling the NO Syndrome in Image Generation,"Foundational Large Language Models (LLMs) have changed the way we perceive
technology. They have been shown to excel in tasks ranging from poem writing
and coding to essay generation and puzzle solving. With the incorporation of
image generation capability, they have become more comprehensive and versatile
AI tools. At the same time, researchers are striving to identify the
limitations of these tools to improve them further. Currently identified flaws
include hallucination, biases, and bypassing restricted commands to generate
harmful content. In the present work, we have identified a fundamental
limitation related to the image generation ability of LLMs, and termed it The
NO Syndrome. This negation blindness refers to LLMs inability to correctly
comprehend NO related natural language prompts to generate the desired images.
Interestingly, all tested LLMs including GPT-4, Gemini, and Copilot were found
to be suffering from this syndrome. To demonstrate the generalization of this
limitation, we carried out simulation experiments and conducted entropy-based
and benchmark statistical analysis tests on various LLMs in multiple languages,
including English, Hindi, and French. We conclude that the NO syndrome is a
significant flaw in current LLMs that needs to be addressed. A related finding
of this study showed a consistent discrepancy between image and textual
responses as a result of this NO syndrome. We posit that the introduction of a
negation context-aware reinforcement learning based feedback loop between the
LLMs textual response and generated image could help ensure the generated text
is based on both the LLMs correct contextual understanding of the negation
query and the generated visual output.",2024-08-27,"Mohammad Nadeem, Shahab Saquib Sohail, Erik Cambria, Björn W. Schuller, Amir Hussain",http://arxiv.org/pdf/2409.00105v2,cs.LG
No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery,"What data or environments to use for training to improve downstream
performance is a longstanding and very topical question in reinforcement
learning. In particular, Unsupervised Environment Design (UED) methods have
gained recent attention as their adaptive curricula promise to enable agents to
be robust to in- and out-of-distribution tasks. This work investigates how
existing UED methods select training environments, focusing on task
prioritisation metrics. Surprisingly, despite methods aiming to maximise regret
in theory, the practical approximations do not correlate with regret but with
success rate. As a result, a significant portion of an agent's experience comes
from environments it has already mastered, offering little to no contribution
toward enhancing its abilities. Put differently, current methods fail to
predict intuitive measures of ``learnability.'' Specifically, they are unable
to consistently identify those scenarios that the agent can sometimes solve,
but not always. Based on our analysis, we develop a method that directly trains
on scenarios with high learnability. This simple and intuitive approach
outperforms existing UED methods in several binary-outcome environments,
including the standard domain of Minigrid and a novel setting closely inspired
by a real-world robotics problem. We further introduce a new adversarial
evaluation procedure for directly measuring robustness, closely mirroring the
conditional value at risk (CVaR). We open-source all our code and present
visualisations of final policies here:
https://github.com/amacrutherford/sampling-for-learnability.",2024-08-27,"Alexander Rutherford, Michael Beukman, Timon Willi, Bruno Lacerda, Nick Hawes, Jakob Foerster",http://arxiv.org/pdf/2408.15099v3,cs.LG
Data-Driven Nonlinear Deformation Design of 3D-Printable Shells,"Designing and fabricating structures with specific mechanical properties
requires understanding the intricate relationship between design parameters and
performance. Understanding the design-performance relationship becomes
increasingly complicated for nonlinear deformations. Though successful at
modeling elastic deformations, simulation-based techniques struggle to model
large elastoplastic deformations exhibiting plasticity and densification. We
propose a neural network trained on experimental data to learn the
design-performance relationship between 3D-printable shells and their
compressive force-displacement behavior. Trained on thousands of physical
experiments, our network aids in both forward and inverse design to generate
shells exhibiting desired elastoplastic and hyperelastic deformations. We
validate a subset of generated designs through fabrication and testing.
Furthermore, we demonstrate the network's inverse design efficacy in generating
custom shells for several applications.",2024-08-27,"Samuel Silverman, Kelsey L. Snapp, Keith A. Brown, Emily Whiting",http://arxiv.org/pdf/2408.15097v1,cs.LG
Ensuring Equitable Financial Decisions: Leveraging Counterfactual Fairness and Deep Learning for Bias,"Concerns regarding fairness and bias have been raised in recent years due to
the growing use of machine learning models in crucial decision-making
processes, especially when it comes to delicate characteristics like gender. In
order to address biases in machine learning models, this research paper
investigates advanced bias mitigation techniques, with a particular focus on
counterfactual fairness in conjunction with data augmentation. The study looks
into how these integrated approaches can lessen gender bias in the financial
industry, specifically in loan approval procedures. We show that these
approaches are effective in achieving more equitable results through thorough
testing and assessment on a skewed financial dataset. The findings emphasize
how crucial it is to use fairness-aware techniques when creating machine
learning models in order to guarantee morally righteous and impartial
decision-making.",2024-08-27,Saish Shinde,http://arxiv.org/pdf/2408.16088v1,cs.LG
Post-processing fairness with minimal changes,"In this paper, we introduce a novel post-processing algorithm that is both
model-agnostic and does not require the sensitive attribute at test time. In
addition, our algorithm is explicitly designed to enforce minimal changes
between biased and debiased predictions; a property that, while highly
desirable, is rarely prioritized as an explicit objective in fairness
literature. Our approach leverages a multiplicative factor applied to the logit
value of probability scores produced by a black-box classifier. We demonstrate
the efficacy of our method through empirical evaluations, comparing its
performance against other four debiasing algorithms on two widely used datasets
in fairness research.",2024-08-27,"Federico Di Gennaro, Thibault Laugel, Vincent Grari, Xavier Renard, Marcin Detyniecki",http://arxiv.org/pdf/2408.15096v2,cs.LG
Constrained Diffusion Models via Dual Training,"Diffusion models have attained prominence for their ability to synthesize a
probability distribution for a given dataset via a diffusion process, enabling
the generation of new data points with high fidelity. However, diffusion
processes are prone to generating samples that reflect biases in a training
dataset. To address this issue, we develop constrained diffusion models by
imposing diffusion constraints based on desired distributions that are informed
by requirements. Specifically, we cast the training of diffusion models under
requirements as a constrained distribution optimization problem that aims to
reduce the distribution difference between original and generated data while
obeying constraints on the distribution of generated data. We show that our
constrained diffusion models generate new data from a mixture data distribution
that achieves the optimal trade-off among objective and constraints. To train
constrained diffusion models, we develop a dual training algorithm and
characterize the optimality of the trained constrained diffusion model. We
empirically demonstrate the effectiveness of our constrained models in two
constrained generation tasks: (i) we consider a dataset with one or more
underrepresented classes where we train the model with constraints to ensure
fairly sampling from all classes during inference; (ii) we fine-tune a
pre-trained diffusion model to sample from a new dataset while avoiding
overfitting.",2024-08-27,"Shervin Khalafi, Dongsheng Ding, Alejandro Ribeiro",http://arxiv.org/pdf/2408.15094v2,cs.LG
SiHGNN: Leveraging Properties of Semantic Graphs for Efficient HGNN Acceleration,"Heterogeneous Graph Neural Networks (HGNNs) have expanded graph
representation learning to heterogeneous graph fields. Recent studies have
demonstrated their superior performance across various applications, including
medical analysis and recommendation systems, often surpassing existing methods.
However, GPUs often experience inefficiencies when executing HGNNs due to their
unique and complex execution patterns. Compared to traditional Graph Neural
Networks, these patterns further exacerbate irregularities in memory access. To
tackle these challenges, recent studies have focused on developing
domain-specific accelerators for HGNNs. Nonetheless, most of these efforts have
concentrated on optimizing the datapath or scheduling data accesses, while
largely overlooking the potential benefits that could be gained from leveraging
the inherent properties of the semantic graph, such as its topology, layout,
and generation.
  In this work, we focus on leveraging the properties of semantic graphs to
enhance HGNN performance. First, we analyze the Semantic Graph Build (SGB)
stage and identify significant opportunities for data reuse during semantic
graph generation. Next, we uncover the phenomenon of buffer thrashing during
the Graph Feature Processing (GFP) stage, revealing potential optimization
opportunities in semantic graph layout. Furthermore, we propose a lightweight
hardware accelerator frontend for HGNNs, called SiHGNN. This accelerator
frontend incorporates a tree-based Semantic Graph Builder for efficient
semantic graph generation and features a novel Graph Restructurer for
optimizing semantic graph layouts. Experimental results show that SiHGNN
enables the state-of-the-art HGNN accelerator to achieve an average performance
improvement of 2.95$\times$.",2024-08-27,"Runzhen Xue, Mingyu Yan, Dengke Han, Zhimin Tang, Xiaochun Ye, Dongrui Fan",http://arxiv.org/pdf/2408.15089v1,cs.LG
MMASD+: A Novel Dataset for Privacy-Preserving Behavior Analysis of Children with Autism Spectrum Disorder,"Autism spectrum disorder (ASD) is characterized by significant challenges in
social interaction and comprehending communication signals. Recently,
therapeutic interventions for ASD have increasingly utilized Deep learning
powered-computer vision techniques to monitor individual progress over time.
These models are trained on private, non-public datasets from the autism
community, creating challenges in comparing results across different models due
to privacy-preserving data-sharing issues. This work introduces MMASD+, an
enhanced version of the novel open-source dataset called Multimodal ASD
(MMASD). MMASD+ consists of diverse data modalities, including 3D-Skeleton, 3D
Body Mesh, and Optical Flow data. It integrates the capabilities of Yolov8 and
Deep SORT algorithms to distinguish between the therapist and children,
addressing a significant barrier in the original dataset. Additionally, a
Multimodal Transformer framework is proposed to predict 11 action types and the
presence of ASD. This framework achieves an accuracy of 95.03% for predicting
action types and 96.42% for predicting ASD presence, demonstrating over a 10%
improvement compared to models trained on single data modalities. These
findings highlight the advantages of integrating multiple data modalities
within the Multimodal Transformer framework.",2024-08-27,"Pavan Uttej Ravva, Behdokht Kiafar, Pinar Kullu, Jicheng Li, Anjana Bhat, Roghayeh Leila Barmaki",http://arxiv.org/pdf/2408.15077v2,cs.LG
MiWaves Reinforcement Learning Algorithm,"The escalating prevalence of cannabis use poses a significant public health
challenge globally. In the U.S., cannabis use is more prevalent among emerging
adults (EAs) (ages 18-25) than any other age group, with legalization in the
multiple states contributing to a public perception that cannabis is less risky
than in prior decades. To address this growing concern, we developed MiWaves, a
reinforcement learning (RL) algorithm designed to optimize the delivery of
personalized intervention prompts to reduce cannabis use among EAs. MiWaves
leverages domain expertise and prior data to tailor the likelihood of delivery
of intervention messages. This paper presents a comprehensive overview of the
algorithm's design, including key decisions and experimental outcomes. The
finalized MiWaves RL algorithm was deployed in a clinical trial from March to
May 2024.",2024-08-27,"Susobhan Ghosh, Yongyi Guo, Pei-Yao Hung, Lara Coughlin, Erin Bonar, Inbal Nahum-Shani, Maureen Walton, Susan Murphy",http://arxiv.org/pdf/2408.15076v1,cs.LG
Interactive dense pixel visualizations for time series and model attribution explanations,"The field of Explainable Artificial Intelligence (XAI) for Deep Neural
Network models has developed significantly, offering numerous techniques to
extract explanations from models. However, evaluating explanations is often not
trivial, and differences in applied metrics can be subtle, especially with
non-intelligible data. Thus, there is a need for visualizations tailored to
explore explanations for domains with such data, e.g., time series. We propose
DAVOTS, an interactive visual analytics approach to explore raw time series
data, activations of neural networks, and attributions in a dense-pixel
visualization to gain insights into the data, models' decisions, and
explanations. To further support users in exploring large datasets, we apply
clustering approaches to the visualized data domains to highlight groups and
present ordering strategies for individual and combined data exploration to
facilitate finding patterns. We visualize a CNN trained on the FordA dataset to
demonstrate the approach.",2024-08-27,"Udo Schlegel, Daniel A. Keim",http://arxiv.org/pdf/2408.15073v1,cs.LG
The Benefits of Balance: From Information Projections to Variance Reduction,"Data balancing across multiple modalities and sources appears in various
forms in foundation models in machine learning and AI, e.g. in CLIP and DINO.
We show that data balancing across modalities and sources actually offers an
unsuspected benefit: variance reduction. We present a non-asymptotic
statistical bound that quantifies this variance reduction effect and relates it
to the eigenvalue decay of Markov operators. Furthermore, we describe how
various forms of data balancing in contrastive multimodal learning and
self-supervised clustering can be better understood, and even improved upon,
owing to our variance reduction viewpoint.",2024-08-27,"Lang Liu, Ronak Mehta, Soumik Pal, Zaid Harchaoui",http://arxiv.org/pdf/2408.15065v2,cs.LG
Subgroup Analysis via Model-based Rule Forest,"Machine learning models are often criticized for their black-box nature,
raising concerns about their applicability in critical decision-making
scenarios. Consequently, there is a growing demand for interpretable models in
such contexts. In this study, we introduce Model-based Deep Rule Forests
(mobDRF), an interpretable representation learning algorithm designed to
extract transparent models from data. By leveraging IF-THEN rules with
multi-level logic expressions, mobDRF enhances the interpretability of existing
models without compromising accuracy. We apply mobDRF to identify key risk
factors for cognitive decline in an elderly population, demonstrating its
effectiveness in subgroup analysis and local model optimization. Our method
offers a promising solution for developing trustworthy and interpretable
machine learning models, particularly valuable in fields like healthcare, where
understanding differential effects across patient subgroups can lead to more
personalized and effective treatments.",2024-08-27,"I-Ling Cheng, Chan Hsu, Chantung Ku, Pei-Ju Lee, Yihuang Kang",http://arxiv.org/pdf/2408.15057v1,cs.LG
TourSynbio: A Multi-Modal Large Model and Agent Framework to Bridge Text and Protein Sequences for Protein Engineering,"The structural similarities between protein sequences and natural languages
have led to parallel advancements in deep learning across both domains. While
large language models (LLMs) have achieved much progress in the domain of
natural language processing, their potential in protein engineering remains
largely unexplored. Previous approaches have equipped LLMs with protein
understanding capabilities by incorporating external protein encoders, but this
fails to fully leverage the inherent similarities between protein sequences and
natural languages, resulting in sub-optimal performance and increased model
complexity. To address this gap, we present TourSynbio-7B, the first
multi-modal large model specifically designed for protein engineering tasks
without external protein encoders. TourSynbio-7B demonstrates that LLMs can
inherently learn to understand proteins as language. The model is post-trained
and instruction fine-tuned on InternLM2-7B using ProteinLMDataset, a dataset
comprising 17.46 billion tokens of text and protein sequence for
self-supervised pretraining and 893K instructions for supervised fine-tuning.
TourSynbio-7B outperforms GPT-4 on the ProteinLMBench, a benchmark of 944
manually verified multiple-choice questions, with 62.18% accuracy. Leveraging
TourSynbio-7B's enhanced protein sequence understanding capability, we
introduce TourSynbio-Agent, an innovative framework capable of performing
various protein engineering tasks, including mutation analysis, inverse
folding, protein folding, and visualization. TourSynbio-Agent integrates
previously disconnected deep learning models in the protein engineering domain,
offering a unified conversational user interface for improved usability.
Finally, we demonstrate the efficacy of TourSynbio-7B and TourSynbio-Agent
through two wet lab case studies on vanilla key enzyme modification and steroid
compound catalysis.",2024-08-27,"Yiqing Shen, Zan Chen, Michail Mamalakis, Yungeng Liu, Tianbin Li, Yanzhou Su, Junjun He, Pietro Liò, Yu Guang Wang",http://arxiv.org/pdf/2408.15299v1,cs.LG
Causal Rule Forest: Toward Interpretable and Precise Treatment Effect Estimation,"Understanding and inferencing Heterogeneous Treatment Effects (HTE) and
Conditional Average Treatment Effects (CATE) are vital for developing
personalized treatment recommendations. Many state-of-the-art approaches
achieve inspiring performance in estimating HTE on benchmark datasets or
simulation studies. However, the indirect predicting manner and complex model
architecture reduce the interpretability of these approaches. To mitigate the
gap between predictive performance and heterogeneity interpretability, we
introduce the Causal Rule Forest (CRF), a novel approach to learning hidden
patterns from data and transforming the patterns into interpretable multi-level
Boolean rules. By training the other interpretable causal inference models with
data representation learned by CRF, we can reduce the predictive errors of
these models in estimating HTE and CATE, while keeping their interpretability
for identifying subgroups that a treatment is more effective. Our experiments
underscore the potential of CRF to advance personalized interventions and
policies, paving the way for future research to enhance its scalability and
application across complex causal inference challenges.",2024-08-27,"Chan Hsu, Jun-Ting Wu, Yihuang Kang",http://arxiv.org/pdf/2408.15055v1,cs.LG
Urban context and delivery performance: Modelling service time for cargo bikes and vans across diverse urban environments,"Light goods vehicles (LGV) used extensively in the last mile of delivery are
one of the leading polluters in cities. Cargo-bike logistics and Light Electric
Vehicles (LEVs) have been put forward as a high impact candidate for replacing
LGVs. Studies have estimated over half of urban van deliveries being
replaceable by cargo-bikes, due to their faster speeds, shorter parking times
and more efficient routes across cities. However, the logistics sector suffers
from a lack of publicly available data, particularly pertaining to cargo-bike
deliveries, thus limiting the understanding of their potential benefits.
Specifically, service time (which includes cruising for parking, and walking to
destination) is a major, but often overlooked component of delivery time
modelling. The aim of this study is to establish a framework for measuring the
performance of delivery vehicles, with an initial focus on modelling service
times of vans and cargo-bikes across diverse urban environments. We introduce
two datasets that allow for in-depth analysis and modelling of service times of
cargo bikes and use existing datasets to reason about differences in delivery
performance across vehicle types. We introduce a modelling framework to predict
the service times of deliveries based on urban context. We employ Uber's H3
index to divide cities into hexagonal cells and aggregate OpenStreetMap tags
for each cell, providing a detailed assessment of urban context. Leveraging
this spatial grid, we use GeoVex to represent micro-regions as points in a
continuous vector space, which then serve as input for predicting vehicle
service times. We show that geospatial embeddings can effectively capture urban
contexts and facilitate generalizations to new contexts and cities. Our
methodology addresses the challenge of limited comparative data available for
different vehicle types within the same urban settings.",2024-08-27,"Maxwell Schrader, Navish Kumar, Esben Sørig, Soonmyeong Yoon, Akash Srivastava, Kai Xu, Maria Astefanoaei, Nicolas Collignon",http://arxiv.org/pdf/2409.06730v1,cs.LG
Earth Observation Satellite Scheduling with Graph Neural Networks,"The Earth Observation Satellite Planning (EOSP) is a difficult optimization
problem with considerable practical interest. A set of requested observations
must be scheduled on an agile Earth observation satellite while respecting
constraints on their visibility window, as well as maneuver constraints that
impose varying delays between successive observations. In addition, the problem
is largely oversubscribed: there are much more candidate observations than what
can possibly be achieved. Therefore, one must select the set of observations
that will be performed while maximizing their weighted cumulative benefit, and
propose a feasible schedule for these observations. As previous work mostly
focused on heuristic and iterative search algorithms, this paper presents a new
technique for selecting and scheduling observations based on Graph Neural
Networks (GNNs) and Deep Reinforcement Learning (DRL). GNNs are used to extract
relevant information from the graphs representing instances of the EOSP, and
DRL drives the search for optimal schedules. Our simulations show that it is
able to learn on small problem instances and generalize to larger real-world
instances, with very competitive performance compared to traditional
approaches.",2024-08-27,"Antoine Jacquet, Guillaume Infantes, Nicolas Meuleau, Emmanuel Benazera, Stéphanie Roussel, Vincent Baudoui, Jonathan Guerra",http://arxiv.org/pdf/2408.15041v1,cs.LG
NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals,"Recent advancements for large-scale pre-training with neural signals such as
electroencephalogram (EEG) have shown promising results, significantly boosting
the development of brain-computer interfaces (BCIs) and healthcare. However,
these pre-trained models often require full fine-tuning on each downstream task
to achieve substantial improvements, limiting their versatility and usability,
and leading to considerable resource wastage. To tackle these challenges, we
propose NeuroLM, the first multi-task foundation model that leverages the
capabilities of Large Language Models (LLMs) by regarding EEG signals as a
foreign language, endowing the model with multi-task learning and inference
capabilities. Our approach begins with learning a text-aligned neural tokenizer
through vector-quantized temporal-frequency prediction, which encodes EEG
signals into discrete neural tokens. These EEG tokens, generated by the frozen
vector-quantized (VQ) encoder, are then fed into an LLM that learns causal EEG
information via multi-channel autoregression. Consequently, NeuroLM can
understand both EEG and language modalities. Finally, multi-task instruction
tuning adapts NeuroLM to various downstream tasks. We are the first to
demonstrate that, by specific incorporation with LLMs, NeuroLM unifies diverse
EEG tasks within a single model through instruction tuning. The largest variant
NeuroLM-XL has record-breaking 1.7B parameters for EEG signal processing, and
is pre-trained on a large-scale corpus comprising approximately 25,000-hour EEG
data. When evaluated on six diverse downstream datasets, NeuroLM showcases the
huge potential of this multi-task learning paradigm.",2024-08-27,"Wei-Bang Jiang, Yansen Wang, Bao-Liang Lu, Dongsheng Li",http://arxiv.org/pdf/2409.00101v3,cs.LG
Prior-free Balanced Replay: Uncertainty-guided Reservoir Sampling for Long-Tailed Continual Learning,"Even in the era of large models, one of the well-known issues in continual
learning (CL) is catastrophic forgetting, which is significantly challenging
when the continual data stream exhibits a long-tailed distribution, termed as
Long-Tailed Continual Learning (LTCL). Existing LTCL solutions generally
require the label distribution of the data stream to achieve re-balance
training. However, obtaining such prior information is often infeasible in real
scenarios since the model should learn without pre-identifying the majority and
minority classes. To this end, we propose a novel Prior-free Balanced Replay
(PBR) framework to learn from long-tailed data stream with less forgetting.
Concretely, motivated by our experimental finding that the minority classes are
more likely to be forgotten due to the higher uncertainty, we newly design an
uncertainty-guided reservoir sampling strategy to prioritize rehearsing
minority data without using any prior information, which is based on the mutual
dependence between the model and samples. Additionally, we incorporate two
prior-free components to further reduce the forgetting issue: (1) Boundary
constraint is to preserve uncertain boundary supporting samples for continually
re-estimating task boundaries. (2) Prototype constraint is to maintain the
consistency of learned class prototypes along with training. Our approach is
evaluated on three standard long-tailed benchmarks, demonstrating superior
performance to existing CL methods and previous SOTA LTCL approach in both
task- and class-incremental learning settings, as well as ordered- and
shuffled-LTCL settings.",2024-08-27,"Lei Liu, Li Liu, Yawen Cui",http://arxiv.org/pdf/2408.14976v1,cs.LG
Cross-Modal Learning for Chemistry Property Prediction: Large Language Models Meet Graph Machine Learning,"In the field of chemistry, the objective is to create novel molecules with
desired properties, facilitating accurate property predictions for applications
such as material design and drug screening. However, existing graph deep
learning methods face limitations that curb their expressive power. To address
this, we explore the integration of vast molecular domain knowledge from Large
Language Models (LLMs) with the complementary strengths of Graph Neural
Networks (GNNs) to enhance performance in property prediction tasks. We
introduce a Multi-Modal Fusion (MMF) framework that synergistically harnesses
the analytical prowess of GNNs and the linguistic generative and predictive
abilities of LLMs, thereby improving accuracy and robustness in predicting
molecular properties. Our framework combines the effectiveness of GNNs in
modeling graph-structured data with the zero-shot and few-shot learning
capabilities of LLMs, enabling improved predictions while reducing the risk of
overfitting. Furthermore, our approach effectively addresses distributional
shifts, a common challenge in real-world applications, and showcases the
efficacy of learning cross-modal representations, surpassing state-of-the-art
baselines on benchmark datasets for property prediction tasks.",2024-08-27,"Sakhinana Sagar Srinivas, Venkataramana Runkana",http://arxiv.org/pdf/2408.14964v1,cs.LG
Leveraging RNNs and LSTMs for Synchronization Analysis in the Indian Stock Market: A Threshold-Based Classification Approach,"Our research presents a new approach for forecasting the synchronization of
stock prices using machine learning and non-linear time-series analysis. To
capture the complex non-linear relationships between stock prices, we utilize
recurrence plots (RP) and cross-recurrence quantification analysis (CRQA). By
transforming Cross Recurrence Plot (CRP) data into a time-series format, we
enable the use of Recurrent Neural Networks (RNN) and Long Short-Term Memory
(LSTM) networks for predicting stock price synchronization through both
regression and classification. We apply this methodology to a dataset of 20
highly capitalized stocks from the Indian market over a 21-year period. The
findings reveal that our approach can predict stock price synchronization, with
an accuracy of 0.98 and F1 score of 0.83 offering valuable insights for
developing effective trading strategies and risk management tools.",2024-08-27,"Sanjay Sathish, Charu C Sharma",http://arxiv.org/pdf/2409.06728v1,cs.LG
Domain-decoupled Physics-informed Neural Networks with Closed-form Gradients for Fast Model Learning of Dynamical Systems,"Physics-informed neural networks (PINNs) are trained using physical equations
and can also incorporate unmodeled effects by learning from data. PINNs for
control (PINCs) of dynamical systems are gaining interest due to their
prediction speed compared to classical numerical integration methods for
nonlinear state-space models, making them suitable for real-time control
applications. We introduce the domain-decoupled physics-informed neural network
(DD-PINN) to address current limitations of PINC in handling large and complex
nonlinear dynamical systems. The time domain is decoupled from the feed-forward
neural network to construct an Ansatz function, allowing for calculation of
gradients in closed form. This approach significantly reduces training times,
especially for large dynamical systems, compared to PINC, which relies on
graph-based automatic differentiation. Additionally, the DD-PINN inherently
fulfills the initial condition and supports higher-order excitation inputs,
simplifying the training process and enabling improved prediction accuracy.
Validation on three systems - a nonlinear mass-spring-damper, a
five-mass-chain, and a two-link robot - demonstrates that the DD-PINN achieves
significantly shorter training times. In cases where the PINC's prediction
diverges, the DD-PINN's prediction remains stable and accurate due to higher
physics loss reduction or use of a higher-order excitation input. The DD-PINN
allows for fast and accurate learning of large dynamical systems previously out
of reach for the PINC.",2024-08-27,"Henrik Krauss, Tim-Lukas Habich, Max Bartholdt, Thomas Seel, Moritz Schappler",http://arxiv.org/pdf/2408.14951v2,cs.LG
Feature Representations for Automatic Meerkat Vocalization Classification,"Understanding evolution of vocal communication in social animals is an
important research problem. In that context, beyond humans, there is an
interest in analyzing vocalizations of other social animals such as, meerkats,
marmosets, apes. While existing approaches address vocalizations of certain
species, a reliable method tailored for meerkat calls is lacking. To that
extent, this paper investigates feature representations for automatic meerkat
vocalization analysis. Both traditional signal processing-based representations
and data-driven representations facilitated by advances in deep learning are
explored. Call type classification studies conducted on two data sets reveal
that feature extraction methods developed for human speech processing can be
effectively employed for automatic meerkat call analysis.",2024-08-27,"Imen Ben Mahmoud, Eklavya Sarkar, Marta Manser, Mathew Magimai. -Doss",http://arxiv.org/pdf/2408.15296v1,cs.LG
Quotient Normalized Maximum Likelihood Criterion for Learning Bayesian Network Structures,"We introduce an information theoretic criterion for Bayesian network
structure learning which we call quotient normalized maximum likelihood (qNML).
In contrast to the closely related factorized normalized maximum likelihood
criterion, qNML satisfies the property of score equivalence. It is also
decomposable and completely free of adjustable hyperparameters. For practical
computations, we identify a remarkably accurate approximation proposed earlier
by Szpankowski and Weinberger. Experiments on both simulated and real data
demonstrate that the new criterion leads to parsimonious models with good
predictive accuracy.",2024-08-27,"Tomi Silander, Janne Leppä-aho, Elias Jääsaari, Teemu Roos",http://arxiv.org/pdf/2408.14935v1,cs.LG
Targeting the partition function of chemically disordered materials with a generative approach based on inverse variational autoencoders,"Computing atomic-scale properties of chemically disordered materials requires
an efficient exploration of their vast configuration space. Traditional
approaches such as Monte Carlo or Special Quasirandom Structures either entail
sampling an excessive amount of configurations or do not ensure that the
configuration space has been properly covered. In this work, we propose a novel
approach where generative machine learning is used to yield a representative
set of configurations for accurate property evaluation and provide accurate
estimations of atomic-scale properties with minimal computational cost. Our
method employs a specific type of variational autoencoder with inverse roles
for the encoder and decoder, enabling the application of an unsupervised active
learning scheme that does not require any initial training database. The model
iteratively generates configuration batches, whose properties are computed with
conventional atomic-scale methods. These results are then fed back into the
model to estimate the partition function, repeating the process until
convergence. We illustrate our approach by computing point-defect formation
energies and concentrations in (U, Pu)O2 mixed-oxide fuels. In addition, the ML
model provides valuable insights into the physical factors influencing the
target property. Our method is generally applicable to explore other
properties, such as atomic-scale diffusion coefficients, in ideally or
non-ideally disordered materials like high-entropy alloys.",2024-08-27,"Maciej J. Karcz, Luca Messina, Eiji Kawasaki, Emeric Bourasseau",http://arxiv.org/pdf/2408.14928v2,cs.LG
Evaluating the Predictive Features of Person-Centric Knowledge Graph Embeddings: Unfolding Ablation Studies,"Developing novel predictive models with complex biomedical information is
challenging due to various idiosyncrasies related to heterogeneity,
standardization or sparseness of the data. We previously introduced a
person-centric ontology to organize information about individual patients, and
a representation learning framework to extract person-centric knowledge graphs
(PKGs) and to train Graph Neural Networks (GNNs). In this paper, we propose a
systematic approach to examine the results of GNN models trained with both
structured and unstructured information from the MIMIC-III dataset. Through
ablation studies on different clinical, demographic, and social data, we show
the robustness of this approach in identifying predictive features in PKGs for
the task of readmission prediction.",2024-08-27,"Christos Theodoropoulos, Natasha Mulligan, Joao Bettencourt-Silva",http://arxiv.org/pdf/2408.15294v2,cs.LG
Can Transformers Do Enumerative Geometry?,"How can Transformers model and learn enumerative geometry? What is a robust
procedure for using Transformers in abductive knowledge discovery within a
mathematician-machine collaboration? In this work, we introduce a
Transformer-based approach to computational enumerative geometry, specifically
targeting the computation of $\psi$-class intersection numbers on the moduli
space of curves. By reformulating the problem as a continuous optimization
task, we compute intersection numbers across a wide value range from $10^{-45}$
to $10^{45}$. To capture the recursive nature inherent in these intersection
numbers, we propose the Dynamic Range Activator (DRA), a new activation
function that enhances the Transformer's ability to model recursive patterns
and handle severe heteroscedasticity. Given precision requirements for
computing the intersections, we quantify the uncertainty of the predictions
using Conformal Prediction with a dynamic sliding window adaptive to the
partitions of equivalent number of marked points. To the best of our knowledge,
there has been no prior work on modeling recursive functions with such a
high-variance and factorial growth. Beyond simply computing intersection
numbers, we explore the enumerative ""world-model"" of Transformers. Our
interpretability analysis reveals that the network is implicitly modeling the
Virasoro constraints in a purely data-driven manner. Moreover, through
abductive hypothesis testing, probing, and causal inference, we uncover
evidence of an emergent internal representation of the the large-genus
asymptotic of $\psi$-class intersection numbers. These findings suggest that
the network internalizes the parameters of the asymptotic closed-form and the
polynomiality phenomenon of $\psi$-class intersection numbers in a non-linear
manner.",2024-08-27,"Baran Hashemi, Roderic G. Corominas, Alessandro Giacchetto",http://arxiv.org/pdf/2408.14915v2,cs.LG
SpikingSSMs: Learning Long Sequences with Sparse and Parallel Spiking State Space Models,"Known as low energy consumption networks, spiking neural networks (SNNs) have
gained a lot of attention within the past decades. While SNNs are increasing
competitive with artificial neural networks (ANNs) for vision tasks, they are
rarely used for long sequence tasks, despite their intrinsic temporal dynamics.
In this work, we develop spiking state space models (SpikingSSMs) for long
sequence learning by leveraging on the sequence learning abilities of state
space models (SSMs). Inspired by dendritic neuron structure, we hierarchically
integrate neuronal dynamics with the original SSM block, meanwhile realizing
sparse synaptic computation. Furthermore, to solve the conflict of event-driven
neuronal dynamics with parallel computing, we propose a light-weight surrogate
dynamic network which accurately predicts the after-reset membrane potential
and compatible to learnable thresholds, enabling orders of acceleration in
training speed compared with conventional iterative methods. On the long range
arena benchmark task, SpikingSSM achieves competitive performance to
state-of-the-art SSMs meanwhile realizing on average 90\% of network sparsity.
On language modeling, our network significantly surpasses existing spiking
large language models (spikingLLMs) on the WikiText-103 dataset with only a
third of the model size, demonstrating its potential as backbone architecture
for low computation cost LLMs.",2024-08-27,"Shuaijie Shen, Chao Wang, Renzhuo Huang, Yan Zhong, Qinghai Guo, Zhichao Lu, Jianguo Zhang, Luziwei Leng",http://arxiv.org/pdf/2408.14909v2,cs.LG
Development of Large Annotated Music Datasets using HMM-based Forced Viterbi Alignment,"Datasets are essential for any machine learning task. Automatic Music
Transcription (AMT) is one such task, where considerable amount of data is
required depending on the way the solution is achieved. Considering the fact
that a music dataset, complete with audio and its time-aligned transcriptions
would require the effort of people with musical experience, it could be stated
that the task becomes even more challenging. Musical experience is required in
playing the musical instrument(s), and in annotating and verifying the
transcriptions. We propose a method that would help in streamlining this
process, making the task of obtaining a dataset from a particular instrument
easy and efficient. We use predefined guitar exercises and hidden Markov
model(HMM) based forced viterbi alignment to accomplish this. The guitar
exercises are designed to be simple. Since the note sequence are already
defined, HMM based forced viterbi alignment provides time-aligned
transcriptions of these audio files. The onsets of the transcriptions are
manually verified and the labels are accurate up to 10ms, averaging at 5ms. The
contributions of the proposed work is two fold, i) a well streamlined and
efficient method for generating datasets for any instrument, especially
monophonic and, ii) an acoustic plectrum guitar dataset containing wave files
and transcriptions in the form of label files. This method will aid as a
preliminary step towards building concrete datasets for building AMT systems
for different instruments.",2024-08-27,"S. Johanan Joysingh, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.14890v1,cs.LG
Turbine location-aware multi-decadal wind power predictions for Germany using CMIP6,"Climate change will impact wind and therefore wind power generation with
largely unknown effect and magnitude. Climate models can provide insights and
should be used for long-term power planning. In this work we use Gaussian
processes to predict power output given wind speeds from a global climate model
and compare the aggregated predictions to actual power generation. Analyzing
past climate model data supports the use of CMIP6 climate model data for
multi-decadal wind power predictions and highlights the importance of being
location-aware. Our predictions up to 2050 reveal only minor changes in yearly
wind power generation. We find that wind power projections of the two
in-between climate scenarios SSP2-4.5 and SSP3-7.0 closely align with actual
wind power generation between 2015 and 2023. Our analysis also reveals larger
uncertainty associated with Germany's coastal areas in the North as compared to
Germany's South, motivating wind power expansion in regions where future wind
is likely more reliable. Overall, our results indicate that wind energy will
likely remain a reliable energy source in the future.",2024-08-27,"Nina Effenberger, Nicole Ludwig",http://arxiv.org/pdf/2408.14889v2,cs.LG
Literary and Colloquial Dialect Identification for Tamil using Acoustic Features,"The evolution and diversity of a language is evident from it's various
dialects. If the various dialects are not addressed in technological
advancements like automatic speech recognition and speech synthesis, there is a
chance that these dialects may disappear. Speech technology plays a role in
preserving various dialects of a language from going extinct. In order to build
a full fledged automatic speech recognition system that addresses various
dialects, an Automatic Dialect Identification (ADI) system acting as the front
end is required. This is similar to how language identification systems act as
front ends to automatic speech recognition systems that handle multiple
languages. The current work proposes a way to identify two popular and broadly
classified Tamil dialects, namely literary and colloquial Tamil. Acoustical
characteristics rather than phonetics and phonotactics are used, alleviating
the requirement of language-dependant linguistic tools. Hence one major
advantage of the proposed method is that it does not require an annotated
corpus, hence it can be easily adapted to other languages. Gaussian Mixture
Models (GMM) using Mel Frequency Cepstral Coefficient (MFCC) features are used
to perform the classification task. The experiments yielded an error rate of
12%. Vowel nasalization, as being the reason for this good performance, is
discussed. The number of mixture models for the GMM is varied and the
performance is analysed.",2024-08-27,"M. Nanmalar, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.14887v1,cs.LG
Adversarial Attacks and Defenses in Multivariate Time-Series Forecasting for Smart and Connected Infrastructures,"The emergence of deep learning models has revolutionized various industries
over the last decade, leading to a surge in connected devices and
infrastructures. However, these models can be tricked into making incorrect
predictions with high confidence, leading to disastrous failures and security
concerns. To this end, we explore the impact of adversarial attacks on
multivariate time-series forecasting and investigate methods to counter them.
Specifically, we employ untargeted white-box attacks, namely the Fast Gradient
Sign Method (FGSM) and the Basic Iterative Method (BIM), to poison the inputs
to the training process, effectively misleading the model. We also illustrate
the subtle modifications to the inputs after the attack, which makes detecting
the attack using the naked eye quite difficult. Having demonstrated the
feasibility of these attacks, we develop robust models through adversarial
training and model hardening. We are among the first to showcase the
transferability of these attacks and defenses by extrapolating our work from
the benchmark electricity data to a larger, 10-year real-world data used for
predicting the time-to-failure of hard disks. Our experimental results confirm
that the attacks and defenses achieve the desired security thresholds, leading
to a 72.41% and 94.81% decrease in RMSE for the electricity and hard disk
datasets respectively after implementing the adversarial defenses.",2024-08-27,"Pooja Krishan, Rohan Mohapatra, Saptarshi Sengupta",http://arxiv.org/pdf/2408.14875v1,cs.LG
Learning Robust Reward Machines from Noisy Labels,"This paper presents PROB-IRM, an approach that learns robust reward machines
(RMs) for reinforcement learning (RL) agents from noisy execution traces. The
key aspect of RM-driven RL is the exploitation of a finite-state machine that
decomposes the agent's task into different subtasks. PROB-IRM uses a
state-of-the-art inductive logic programming framework robust to noisy examples
to learn RMs from noisy traces using the Bayesian posterior degree of beliefs,
thus ensuring robustness against inconsistencies. Pivotal for the results is
the interleaving between RM learning and policy learning: a new RM is learned
whenever the RL agent generates a trace that is believed not to be accepted by
the current RM. To speed up the training of the RL agent, PROB-IRM employs a
probabilistic formulation of reward shaping that uses the posterior Bayesian
beliefs derived from the traces. Our experimental analysis shows that PROB-IRM
can learn (potentially imperfect) RMs from noisy traces and exploit them to
train an RL agent to solve its tasks successfully. Despite the complexity of
learning the RM from noisy traces, agents trained with PROB-IRM perform
comparably to agents provided with handcrafted RMs.",2024-08-27,"Roko Parac, Lorenzo Nodari, Leo Ardon, Daniel Furelos-Blanco, Federico Cerutti, Alessandra Russo",http://arxiv.org/pdf/2408.14871v2,cs.LG
Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models,"Language Language Models (LLMs) face safety concerns due to potential misuse
by malicious users. Recent red-teaming efforts have identified adversarial
suffixes capable of jailbreaking LLMs using the gradient-based search algorithm
Greedy Coordinate Gradient (GCG). However, GCG struggles with computational
inefficiency, limiting further investigations regarding suffix transferability
and scalability across models and data. In this work, we bridge the connection
between search efficiency and suffix transferability. We propose a two-stage
transfer learning framework, DeGCG, which decouples the search process into
behavior-agnostic pre-searching and behavior-relevant post-searching.
Specifically, we employ direct first target token optimization in pre-searching
to facilitate the search process. We apply our approach to cross-model,
cross-data, and self-transfer scenarios. Furthermore, we introduce an
interleaved variant of our approach, i-DeGCG, which iteratively leverages
self-transferability to accelerate the search process. Experiments on HarmBench
demonstrate the efficiency of our approach across various models and domains.
Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of
$43.9$ ($+22.2$) and $39.0$ ($+19.5$) on valid and test sets, respectively.
Further analysis on cross-model transfer indicates the pivotal role of first
target token optimization in leveraging suffix transferability for efficient
searching.",2024-08-27,"Hongfu Liu, Yuxi Xie, Ye Wang, Michael Shieh",http://arxiv.org/pdf/2408.14866v2,cs.LG
Data downlink prioritization using image classification on-board a 6U CubeSat,"Nanosatellites are proliferating as low-cost dedicated sensing systems with
lean development cycles. Kyushu Institute of Technology and collaborators have
launched a joint venture for a nanosatellite mission, VERTECS. The primary
mission is to elucidate the formation history of stars by observing the
optical-wavelength cosmic background radiation. The VERTECS satellite will be
equipped with a small-aperture telescope and a high-precision attitude control
system to capture the cosmic data for analysis on the ground. However,
nanosatellites are limited by their onboard memory resources and downlink speed
capabilities. Additionally, due to a limited number of ground stations, the
satellite mission will face issues meeting the required data budget for mission
success. To alleviate this issue, we propose an on-orbit system to autonomously
classify and then compress desirable image data for data downlink
prioritization and optimization. The system comprises a prototype Camera
Controller Board (CCB) which carries a Raspberry Pi Compute Module 4 which is
used for classification and compression. The system uses a lightweight
Convolutional Neural Network (CNN) model to classify and determine the
desirability of captured image data. The model is designed to be lean and
robust to reduce the computational and memory load on the satellite. The model
is trained and tested on a novel star field dataset consisting of data captured
by the Sloan Digital Sky Survey (SDSS). The dataset is meant to simulate the
expected data produced by the 6U satellite. The compression step implements
GZip, RICE or HCOMPRESS compression, which are standards for astronomical data.
Preliminary testing on the proposed CNN model results in a classification
accuracy of about 100\% on the star field dataset, with compression ratios of
3.99, 5.16 and 5.43 for GZip, RICE and HCOMPRESS that were achieved on tested
FITS image data.",2024-08-27,"Keenan A. A. Chatar, Ezra Fielding, Kei Sano, Kentaro Kitamura",http://arxiv.org/pdf/2408.14865v1,cs.LG
Dynamic operator management in meta-heuristics using reinforcement learning: an application to permutation flowshop scheduling problems,"This study develops a framework based on reinforcement learning to
dynamically manage a large portfolio of search operators within
meta-heuristics. Using the idea of tabu search, the framework allows for
continuous adaptation by temporarily excluding less efficient operators and
updating the portfolio composition during the search. A Q-learning-based
adaptive operator selection mechanism is used to select the most suitable
operator from the dynamically updated portfolio at each stage. Unlike
traditional approaches, the proposed framework requires no input from the
experts regarding the search operators, allowing domain-specific non-experts to
effectively use the framework. The performance of the proposed framework is
analyzed through an application to the permutation flowshop scheduling problem.
The results demonstrate the superior performance of the proposed framework
against state-of-the-art algorithms in terms of optimality gap and convergence
speed.",2024-08-27,"Maryam Karimi Mamaghan, Mehrdad Mohammadi, Wout Dullaert, Daniele Vigo, Amir Pirayesh",http://arxiv.org/pdf/2408.14864v1,cs.LG
Characterizing Physician Referral Networks with Ricci Curvature,"Identifying (a) systemic barriers to quality healthcare access and (b) key
indicators of care efficacy in the United States remains a significant
challenge. To improve our understanding of regional disparities in care
delivery, we introduce a novel application of curvature, a
geometrical-topological property of networks, to Physician Referral Networks.
Our initial findings reveal that Forman-Ricci and Ollivier-Ricci curvature
measures, which are known for their expressive power in characterizing network
structure, offer promising indicators for detecting variations in healthcare
efficacy while capturing a range of significant regional demographic features.
We also present APPARENT, an open-source tool that leverages Ricci curvature
and other network features to examine correlations between regional Physician
Referral Networks structure, local census data, healthcare effectiveness, and
patient outcomes.",2024-08-27,"Jeremy Wayland, Russel J. Funk, Bastian Rieck",http://arxiv.org/pdf/2408.16022v2,cs.LG
Learning Granularity Representation for Temporal Knowledge Graph Completion,"Temporal Knowledge Graphs (TKGs) incorporate temporal information to reflect
the dynamic structural knowledge and evolutionary patterns of real-world facts.
Nevertheless, TKGs are still limited in downstream applications due to the
problem of incompleteness. Consequently, TKG completion (also known as link
prediction) has been widely studied, with recent research focusing on
incorporating independent embeddings of time or combining them with entities
and relations to form temporal representations. However, most existing methods
overlook the impact of history from a multi-granularity aspect. The inherent
semantics of human-defined temporal granularities, such as ordinal dates,
reveal general patterns to which facts typically adhere. To counter this
limitation, this paper proposes \textbf{L}earning \textbf{G}ranularity
\textbf{Re}presentation (termed $\mathsf{LGRe}$) for TKG completion. It
comprises two main components: Granularity Representation Learning (GRL) and
Adaptive Granularity Balancing (AGB). Specifically, GRL employs time-specific
multi-layer convolutional neural networks to capture interactions between
entities and relations at different granularities. After that, AGB generates
adaptive weights for these embeddings according to temporal semantics,
resulting in expressive representations of predictions. Moreover, to reflect
similar semantics of adjacent timestamps, a temporal loss function is
introduced. Extensive experimental results on four event benchmarks demonstrate
the effectiveness of $\mathsf{LGRe}$ in learning time-related representations.
To ensure reproducibility, our code is available at
https://github.com/KcAcoZhang/LGRe.",2024-08-27,"Jinchuan Zhang, Tianqi Wan, Chong Mu, Guangxi Lu, Ling Tian",http://arxiv.org/pdf/2408.15293v1,cs.LG
Intraoperative Glioma Segmentation with YOLO + SAM for Improved Accuracy in Tumor Resection,"Gliomas, a common type of malignant brain tumor, present significant surgical
challenges due to their similarity to healthy tissue. Preoperative Magnetic
Resonance Imaging (MRI) images are often ineffective during surgery due to
factors such as brain shift, which alters the position of brain structures and
tumors. This makes real-time intraoperative MRI (ioMRI) crucial, as it provides
updated imaging that accounts for these shifts, ensuring more accurate tumor
localization and safer resections. This paper presents a deep learning pipeline
combining You Only Look Once Version 8 (YOLOv8) and Segment Anything Model
Vision Transformer-base (SAM ViT-b) to enhance glioma detection and
segmentation during ioMRI. Our model was trained using the Brain Tumor
Segmentation 2021 (BraTS 2021) dataset, which includes standard magnetic
resonance imaging (MRI) images, and noise-augmented MRI images that simulate
ioMRI images. Noised MRI images are harder for a deep learning pipeline to
segment, but they are more representative of surgical conditions. Achieving a
Dice Similarity Coefficient (DICE) score of 0.79, our model performs comparably
to state-of-the-art segmentation models tested on noiseless data. This
performance demonstrates the model's potential to assist surgeons in maximizing
tumor resection and improving surgical outcomes.",2024-08-27,"Samir Kassam, Angelo Markham, Katie Vo, Yashas Revanakara, Michael Lam, Kevin Zhu",http://arxiv.org/pdf/2408.14847v1,cs.LG
Correntropy-Based Improper Likelihood Model for Robust Electrophysiological Source Imaging,"Bayesian learning provides a unified skeleton to solve the
electrophysiological source imaging task. From this perspective, existing
source imaging algorithms utilize the Gaussian assumption for the observation
noise to build the likelihood function for Bayesian inference. However, the
electromagnetic measurements of brain activity are usually affected by
miscellaneous artifacts, leading to a potentially non-Gaussian distribution for
the observation noise. Hence the conventional Gaussian likelihood model is a
suboptimal choice for the real-world source imaging task. In this study, we aim
to solve this problem by proposing a new likelihood model which is robust with
respect to non-Gaussian noises. Motivated by the robust maximum correntropy
criterion, we propose a new improper distribution model concerning the noise
assumption. This new noise distribution is leveraged to structure a robust
likelihood function and integrated with hierarchical prior distributions to
estimate source activities by variational inference. In particular, the score
matching is adopted to determine the hyperparameters for the improper
likelihood model. A comprehensive performance evaluation is performed to
compare the proposed noise assumption to the conventional Gaussian model.
Simulation results show that, the proposed method can realize more precise
source reconstruction by designing known ground-truth. The real-world dataset
also demonstrates the superiority of our new method with the visual perception
task. This study provides a new backbone for Bayesian source imaging, which
would facilitate its application using real-world noisy brain signal.",2024-08-27,"Yuanhao Li, Badong Chen, Zhongxu Hu, Keita Suzuki, Wenjun Bai, Yasuharu Koike, Okito Yamashita",http://arxiv.org/pdf/2408.14843v1,cs.LG
From Bias to Balance: Detecting Facial Expression Recognition Biases in Large Multimodal Foundation Models,"This study addresses the racial biases in facial expression recognition (FER)
systems within Large Multimodal Foundation Models (LMFMs). Despite advances in
deep learning and the availability of diverse datasets, FER systems often
exhibit higher error rates for individuals with darker skin tones. Existing
research predominantly focuses on traditional FER models (CNNs, RNNs, ViTs),
leaving a gap in understanding racial biases in LMFMs. We benchmark four
leading LMFMs: GPT-4o, PaliGemma, Gemini, and CLIP to assess their performance
in facial emotion detection across different racial demographics. A linear
classifier trained on CLIP embeddings obtains accuracies of 95.9\% for RADIATE,
90.3\% for Tarr, and 99.5\% for Chicago Face. Furthermore, we identify that
Anger is misclassified as Disgust 2.1 times more often in Black Females than
White Females. This study highlights the need for fairer FER systems and
establishes a foundation for developing unbiased, accurate FER technologies.
Visit https://kvjvhub.github.io/FERRacialBias/ for further information
regarding the biases within facial expression recognition.",2024-08-27,"Kaylee Chhua, Zhoujinyi Wen, Vedant Hathalia, Kevin Zhu, Sean O'Brien",http://arxiv.org/pdf/2408.14842v1,cs.LG
CL4KGE: A Curriculum Learning Method for Knowledge Graph Embedding,"Knowledge graph embedding (KGE) constitutes a foundational task, directed
towards learning representations for entities and relations within knowledge
graphs (KGs), with the objective of crafting representations comprehensive
enough to approximate the logical and symbolic interconnections among entities.
In this paper, we define a metric Z-counts to measure the difficulty of
training each triple ($<$head entity, relation, tail entity$>$) in KGs with
theoretical analysis. Based on this metric, we propose \textbf{CL4KGE}, an
efficient \textbf{C}urriculum \textbf{L}earning based training strategy for
\textbf{KGE}. This method includes a difficulty measurer and a training
scheduler that aids in the training of KGE models. Our approach possesses the
flexibility to act as a plugin within a wide range of KGE models, with the
added advantage of adaptability to the majority of KGs in existence. The
proposed method has been evaluated on popular KGE models, and the results
demonstrate that it enhances the state-of-the-art methods. The use of Z-counts
as a metric has enabled the identification of challenging triples in KGs, which
helps in devising effective training strategies.",2024-08-27,"Yang Liu, Chuan Zhou, Peng Zhang, Yanan Cao, Yongchao Liu, Zhao Li, Hongyang Chen",http://arxiv.org/pdf/2408.14840v2,cs.LG
Diffusion Models Are Real-Time Game Engines,"We present GameNGen, the first game engine powered entirely by a neural model
that also enables real-time interaction with a complex environment over long
trajectories at high quality. When trained on the classic game DOOM, GameNGen
extracts gameplay and uses it to generate a playable environment that can
interactively simulate new trajectories. GameNGen runs at 20 frames per second
on a single TPU and remains stable over extended multi-minute play sessions.
Next frame prediction achieves a PSNR of 29.4, comparable to lossy JPEG
compression. Human raters are only slightly better than random chance at
distinguishing short clips of the game from clips of the simulation, even after
5 minutes of auto-regressive generation. GameNGen is trained in two phases: (1)
an RL-agent learns to play the game and the training sessions are recorded, and
(2) a diffusion model is trained to produce the next frame, conditioned on the
sequence of past frames and actions. Conditioning augmentations help ensure
stable auto-regressive generation over long trajectories, and decoder
fine-tuning improves the fidelity of visual details and text.",2024-08-27,"Dani Valevski, Yaniv Leviathan, Moab Arar, Shlomi Fruchter",http://arxiv.org/pdf/2408.14837v2,cs.LG
DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing,"Intelligent Transportation Systems (ITS) leverage Integrated Sensing and
Communications (ISAC) to enhance data exchange between vehicles and
infrastructure in the Internet of Vehicles (IoV). This integration inevitably
increases computing demands, risking real-time system stability. Vehicle Edge
Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU),
ensuring timely services. Our previous work FLSimCo algorithm, which uses local
resources for Federated Self-Supervised Learning (SSL), though vehicles often
can't complete all iterations task. Our improved algorithm offloads partial
task to RSU and optimizes energy consumption by adjusting transmission power,
CPU frequency, and task assignment ratios, balancing local and RSU-based
training. Meanwhile, setting an offloading threshold further prevents
inefficiencies. Simulation results show that the enhanced algorithm reduces
energy consumption, improves offloading efficiency and the accuracy of
Federated SSL.",2024-08-27,"Xueying Gu, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Khaled B. Letaief",http://arxiv.org/pdf/2408.14831v1,cs.LG
"From Rule-Based Models to Deep Learning Transformers Architectures for Natural Language Processing and Sign Language Translation Systems: Survey, Taxonomy and Performance Evaluation","With the growing Deaf and Hard of Hearing population worldwide and the
persistent shortage of certified sign language interpreters, there is a
pressing need for an efficient, signs-driven, integrated end-to-end translation
system, from sign to gloss to text and vice-versa. There has been a wealth of
research on machine translations and related reviews. However, there are few
works on sign language machine translation considering the particularity of the
language being continuous and dynamic. This paper aims to address this void,
providing a retrospective analysis of the temporal evolution of sign language
machine translation algorithms and a taxonomy of the Transformers
architectures, the most used approach in language translation. We also present
the requirements of a real-time Quality-of-Service sign language ma-chine
translation system underpinned by accurate deep learning algorithms. We propose
future research directions for sign language translation systems.",2024-08-27,"Nada Shahin, Leila Ismail",http://arxiv.org/pdf/2408.14825v1,cs.LG
Data-driven Effective Modeling of Multiscale Stochastic Dynamical Systems,"We present a numerical method for learning the dynamics of slow components of
unknown multiscale stochastic dynamical systems. While the governing equations
of the systems are unknown, bursts of observation data of the slow variables
are available. By utilizing the observation data, our proposed method is
capable of constructing a generative stochastic model that can accurately
capture the effective dynamics of the slow variables in distribution. We
present a comprehensive set of numerical examples to demonstrate the
performance of the proposed method.",2024-08-27,"Yuan Chen, Dongbin Xiu",http://arxiv.org/pdf/2408.14821v1,cs.LG
A Comprehensive Benchmark of Machine and Deep Learning Across Diverse Tabular Datasets,"The analysis of tabular datasets is highly prevalent both in scientific
research and real-world applications of Machine Learning (ML). Unlike many
other ML tasks, Deep Learning (DL) models often do not outperform traditional
methods in this area. Previous comparative benchmarks have shown that DL
performance is frequently equivalent or even inferior to models such as
Gradient Boosting Machines (GBMs). In this study, we introduce a comprehensive
benchmark aimed at better characterizing the types of datasets where DL models
excel. Although several important benchmarks for tabular datasets already
exist, our contribution lies in the variety and depth of our comparison: we
evaluate 111 datasets with 20 different models, including both regression and
classification tasks. These datasets vary in scale and include both those with
and without categorical variables. Importantly, our benchmark contains a
sufficient number of datasets where DL models perform best, allowing for a
thorough analysis of the conditions under which DL models excel. Building on
the results of this benchmark, we train a model that predicts scenarios where
DL models outperform alternative methods with 86.1% accuracy (AUC 0.78). We
present insights derived from this characterization and compare these findings
to previous benchmarks.",2024-08-27,"Assaf Shmuel, Oren Glickman, Teddy Lazebnik",http://arxiv.org/pdf/2408.14817v1,cs.LG
Poly2Vec: Polymorphic Fourier-Based Encoding of Geospatial Objects for GeoAI Applications,"Encoding geospatial objects is fundamental for geospatial artificial
intelligence (GeoAI) applications, which leverage machine learning (ML) models
to analyze spatial information. Common approaches transform each object into
known formats, like image and text, for compatibility with ML models. However,
this process often discards crucial spatial information, such as the object's
position relative to the entire space, reducing downstream task effectiveness.
Alternative encoding methods that preserve some spatial properties are often
devised for specific data objects (e.g., point encoders), making them
unsuitable for tasks that involve different data types (i.e., points,
polylines, and polygons). To this end, we propose Poly2Vec, a polymorphic
Fourier-based encoding approach that unifies the representation of geospatial
objects, while preserving the essential spatial properties. Poly2Vec
incorporates a learned fusion module that adaptively integrates the magnitude
and phase of the Fourier transform for different tasks and geometries. We
evaluate Poly2Vec on five diverse tasks, organized into two categories. The
first empirically demonstrates that Poly2Vec consistently outperforms
object-specific baselines in preserving three key spatial relationships:
topology, direction, and distance. The second shows that integrating Poly2Vec
into a state-of-the-art GeoAI workflow improves the performance in two popular
tasks: population prediction and land use inference.",2024-08-27,"Maria Despoina Siampou, Jialiang Li, John Krumm, Cyrus Shahabi, Hua Lu",http://arxiv.org/pdf/2408.14806v2,cs.LG
MaskCycleGAN-based Whisper to Normal Speech Conversion,"Whisper to normal speech conversion is an active area of research. Various
architectures based on generative adversarial networks have been proposed in
the recent past. Especially, recent study shows that MaskCycleGAN, which is a
mask guided, and cyclic consistency keeping, generative adversarial network,
performs really well for voice conversion from spectrogram representations. In
the current work we present a MaskCycleGAN approach for the conversion of
whispered speech to normal speech. We find that tuning the mask parameters, and
pre-processing the signal with a voice activity detector provides superior
performance when compared to the existing approach. The wTIMIT dataset is used
for evaluation. Objective metrics such as PESQ and G-Loss are used to evaluate
the converted speech, along with subjective evaluation using mean opinion
score. The results show that the proposed approach offers considerable
benefits.",2024-08-27,"K. Rohith Gupta, K. Ramnath, S. Johanan Joysingh, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.14797v1,cs.LG
Learning from Complementary Features,"While precise data observation is essential for the learning processes of
predictive models, it can be challenging owing to factors such as insufficient
observation accuracy, high collection costs, and privacy constraints. In this
paper, we examines cases where some qualitative features are unavailable as
precise information indicating ""what it is,"" but rather as complementary
information indicating ""what it is not."" We refer to features defined by
precise information as ordinary features (OFs) and those defined by
complementary information as complementary features (CFs). We then formulate a
new learning scenario termed Complementary Feature Learning (CFL), where
predictive models are constructed using instances consisting of OFs and CFs.
The simplest formalization of CFL applies conventional supervised learning
directly using the observed values of CFs. However, this approach does not
resolve the ambiguity associated with CFs, making learning challenging and
complicating the interpretation of the predictive model's specific predictions.
Therefore, we derive an objective function from an information-theoretic
perspective to estimate the OF values corresponding to CFs and to predict
output labels based on these estimations. Based on this objective function, we
propose a theoretically guaranteed graph-based estimation method along with its
practical approximation, for estimating OF values corresponding to CFs. The
results of numerical experiments conducted with real-world data demonstrate
that our proposed method effectively estimates OF values corresponding to CFs
and predicts output labels.",2024-08-27,"Kosuke Sugiyama, Masato Uchida",http://arxiv.org/pdf/2408.14788v2,cs.LG
Unsupervised-to-Online Reinforcement Learning,"Offline-to-online reinforcement learning (RL), a framework that trains a
policy with offline RL and then further fine-tunes it with online RL, has been
considered a promising recipe for data-driven decision-making. While sensible,
this framework has drawbacks: it requires domain-specific offline RL
pre-training for each task, and is often brittle in practice. In this work, we
propose unsupervised-to-online RL (U2O RL), which replaces domain-specific
supervised offline RL with unsupervised offline RL, as a better alternative to
offline-to-online RL. U2O RL not only enables reusing a single pre-trained
model for multiple downstream tasks, but also learns better representations,
which often result in even better performance and stability than supervised
offline-to-online RL. To instantiate U2O RL in practice, we propose a general
recipe for U2O RL to bridge task-agnostic unsupervised offline skill-based
policy pre-training and supervised online fine-tuning. Throughout our
experiments in nine state-based and pixel-based environments, we empirically
demonstrate that U2O RL achieves strong performance that matches or even
outperforms previous offline-to-online RL approaches, while being able to reuse
a single pre-trained model for a number of different downstream tasks.",2024-08-27,"Junsu Kim, Seohong Park, Sergey Levine",http://arxiv.org/pdf/2408.14785v1,cs.LG
GINN-KAN: Interpretability pipelining with applications in Physics Informed Neural Networks,"Neural networks are powerful function approximators, yet their ``black-box""
nature often renders them opaque and difficult to interpret. While many
post-hoc explanation methods exist, they typically fail to capture the
underlying reasoning processes of the networks. A truly interpretable neural
network would be trained similarly to conventional models using techniques such
as backpropagation, but additionally provide insights into the learned
input-output relationships. In this work, we introduce the concept of
interpretability pipelineing, to incorporate multiple interpretability
techniques to outperform each individual technique. To this end, we first
evaluate several architectures that promise such interpretability, with a
particular focus on two recent models selected for their potential to
incorporate interpretability into standard neural network architectures while
still leveraging backpropagation: the Growing Interpretable Neural Network
(GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations and
strengths of each and introduce a novel interpretable neural network GINN-KAN
that synthesizes the advantages of both models. When tested on the Feynman
symbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN.
To highlight the capabilities and the generalizability of this approach, we
position GINN-KAN as an alternative to conventional black-box networks in
Physics-Informed Neural Networks (PINNs). We expect this to have far-reaching
implications in the application of deep learning pipelines in the natural
sciences. Our experiments with this interpretable PINN on 15 different partial
differential equations demonstrate that GINN-KAN augmented PINNs outperform
PINNs with black-box networks in solving differential equations and surpass the
capabilities of both GINN and KAN.",2024-08-27,"Nisal Ranasinghe, Yu Xia, Sachith Seneviratne, Saman Halgamuge",http://arxiv.org/pdf/2408.14780v2,cs.LG
GPU-Accelerated Counterfactual Regret Minimization,"Counterfactual regret minimization is a family of algorithms of no-regret
learning dynamics capable of solving large-scale imperfect information games.
We propose implementing this algorithm as a series of dense and sparse matrix
and vector operations, thereby making it highly parallelizable for a graphical
processing unit, at a cost of higher memory usage. Our experiments show that
our implementation performs up to about 401.2 times faster than OpenSpiel's
Python implementation and, on an expanded set of games, up to about 203.6 times
faster than OpenSpiel's C++ implementation and the speedup becomes more
pronounced as the size of the game being solved grows.",2024-08-27,Juho Kim,http://arxiv.org/pdf/2408.14778v5,cs.LG
Quartered Chirp Spectral Envelope for Whispered vs Normal Speech Classification,"Whispered speech as an acceptable form of human-computer interaction is
gaining traction. Systems that address multiple modes of speech require a
robust front-end speech classifier. Performance of whispered vs normal speech
classification drops in the presence of additive white Gaussian noise, since
normal speech takes on some of the characteristics of whispered speech. In this
work, we propose a new feature named the quartered chirp spectral envelope, a
combination of the chirp spectrum and the quartered spectral envelope, to
classify whispered and normal speech. The chirp spectrum can be fine-tuned to
obtain customized features for a given task, and the quartered spectral
envelope has been proven to work especially well for the current task. The
feature is trained on a one dimensional convolutional neural network, that
captures the trends in the spectral envelope. The proposed system performs
better than the state of the art, in the presence of white noise.",2024-08-27,"S. Johanan Joysingh, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.14777v1,cs.LG
Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning,"We introduce Instruct-SkillMix, an automated approach for creating diverse,
high quality SFT data. The Instruct-SkillMix pipeline involves two stages, each
leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to
extract core ""skills"" for instruction-following, either from existing datasets,
or by directly prompting the model; (2) Data generation: uses the powerful LLM
to generate (instruction, response) data that exhibit a randomly chosen pair of
these skills. Here, the use of random skill combinations promotes diversity and
difficulty.
  Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from
Instruct-SkillMix leads to strong gains on instruction following benchmarks
such as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples,
LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.
To our knowledge, this achieves state-of-the-art performance among all models
that have only undergone SFT (no RL methods) and competes with proprietary
models such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.
  Ablation studies also suggest plausible reasons for why creating open
instruction-tuning datasets via naive crowd-sourcing has proved difficult.
Introducing low quality answers (""shirkers"") in $20\%$ of Instruct-SkillMix
examples causes performance to plummet, sometimes catastrophically.
  The Instruct-SkillMix pipeline is flexible and is adaptable to other
settings.",2024-08-27,"Simran Kaur, Simon Park, Anirudh Goyal, Sanjeev Arora",http://arxiv.org/pdf/2408.14774v3,cs.LG
Channel-wise Influence: Estimating Data Influence for Multivariate Time Series,"The influence function, a technique from robust statistics, measures the
impact on model parameters or related functions when training data is removed
or modified. This effective and valuable post-hoc method allows for studying
the interpretability of machine learning models without requiring costly model
retraining. It would provide extensions like increasing model performance,
improving model generalization, and offering interpretability. Recently,
Multivariate Time Series (MTS) analysis has become an important yet challenging
task, attracting significant attention. However, there is no preceding research
on the influence functions of MTS to shed light on the effects of modifying the
channel of training MTS. Given that each channel in an MTS plays a crucial role
in its analysis, it is essential to characterize the influence of different
channels. To fill this gap, we propose a channel-wise influence function, which
is the first method that can estimate the influence of different channels in
MTS, utilizing a first-order gradient approximation that leverages the more
informative average gradient of the data set. Additionally, we demonstrate how
this influence function can be used to estimate the impact of a channel in MTS.
Finally, we validated the accuracy and effectiveness of our influence
estimation function in critical MTS analysis tasks, such as MTS anomaly
detection and MTS forecasting. According to abundant experiments on real-world
dataset, the original influence function performs worse than our method and
even fail for the channel pruning problem, which demonstrate the superiority
and necessity of channel-wise influence function in MTS analysis tasks.",2024-08-27,"Muyao Wang, Zeke Xie, Bo Chen",http://arxiv.org/pdf/2408.14763v1,cs.LG
Explainable Hierarchical Urban Representation Learning for Commuting Flow Prediction,"Commuting flow prediction is an essential task for municipal operations in
the real world. Previous studies have revealed that it is feasible to estimate
the commuting origin-destination (OD) demand within a city using multiple
auxiliary data. However, most existing methods are not suitable to deal with a
similar task at a large scale, namely within a prefecture or the whole nation,
owing to the increased number of geographical units that need to be maintained.
In addition, region representation learning is a universal approach for gaining
urban knowledge for diverse metropolitan downstream tasks. Although many
researchers have developed comprehensive frameworks to describe urban units
from multi-source data, they have not clarified the relationship between the
selected geographical elements. Furthermore, metropolitan areas naturally
preserve ranked structures, like cities and their inclusive districts, which
makes elucidating relations between cross-level urban units necessary.
Therefore, we develop a heterogeneous graph-based model to generate meaningful
region embeddings at multiple spatial resolutions for predicting different
types of inter-level OD flows. To demonstrate the effectiveness of the proposed
method, extensive experiments were conducted using real-world aggregated mobile
phone datasets collected from Shizuoka Prefecture, Japan. The results indicate
that our proposed model outperforms existing models in terms of a uniform urban
structure. We extend the understanding of predicted results using reasonable
explanations to enhance the credibility of the model.",2024-08-27,"Mingfei Cai, Yanbo Pang, Yoshihide Sekimoto",http://arxiv.org/pdf/2408.14762v4,cs.LG
Learning effective pruning at initialization from iterative pruning,"Pruning at initialization (PaI) reduces training costs by removing weights
before training, which becomes increasingly crucial with the growing network
size. However, current PaI methods still have a large accuracy gap with
iterative pruning, especially at high sparsity levels. This raises an
intriguing question: can we get inspiration from iterative pruning to improve
the PaI performance? In the lottery ticket hypothesis, the iterative rewind
pruning (IRP) finds subnetworks retroactively by rewinding the parameter to the
original initialization in every pruning iteration, which means all the
subnetworks are based on the initial state. Here, we hypothesise the surviving
subnetworks are more important and bridge the initial feature and their
surviving score as the PaI criterion. We employ an end-to-end neural network
(\textbf{AutoS}parse) to learn this correlation, input the model's initial
features, output their score and then prune the lowest score parameters before
training. To validate the accuracy and generalization of our method, we
performed PaI across various models. Results show that our approach outperforms
existing methods in high-sparsity settings. Notably, as the underlying logic of
model pruning is consistent in different models, only one-time IRP on one model
is needed (e.g., once IRP on ResNet-18/CIFAR-10, AutoS can be generalized to
VGG-16/CIFAR-10, ResNet-18/TinyImageNet, et al.). As the first neural
network-based PaI method, we conduct extensive experiments to validate the
factors influencing this approach. These results reveal the learning tendencies
of neural networks and provide new insights into our understanding and research
of PaI from a practical perspective. Our code is available at:
https://github.com/ChengYaofeng/AutoSparse.git.",2024-08-27,"Shengkai Liu, Yaofeng Cheng, Fusheng Zha, Wei Guo, Lining Sun, Zhenshan Bing, Chenguang Yang",http://arxiv.org/pdf/2408.14757v1,cs.LG
Training-Free Time-Series Anomaly Detection: Leveraging Image Foundation Models,"Recent advancements in time-series anomaly detection have relied on deep
learning models to handle the diverse behaviors of time-series data. However,
these models often suffer from unstable training and require extensive
hyperparameter tuning, leading to practical limitations. Although foundation
models present a potential solution, their use in time series is limited. To
overcome these issues, we propose an innovative image-based, training-free
time-series anomaly detection (ITF-TAD) approach. ITF-TAD converts time-series
data into images using wavelet transform and compresses them into a single
representation, leveraging image foundation models for anomaly detection. This
approach achieves high-performance anomaly detection without unstable neural
network training or hyperparameter tuning. Furthermore, ITF-TAD identifies
anomalies across different frequencies, providing users with a detailed
visualization of anomalies and their corresponding frequencies. Comprehensive
experiments on five benchmark datasets, including univariate and multivariate
time series, demonstrate that ITF-TAD offers a practical and effective solution
with performance exceeding or comparable to that of deep models.",2024-08-27,"Nobuo Namura, Yuma Ichikawa",http://arxiv.org/pdf/2408.14756v1,cs.LG
Benchmarking Reinforcement Learning Methods for Dexterous Robotic Manipulation with a Three-Fingered Gripper,"Reinforcement Learning (RL) training is predominantly conducted in
cost-effective and controlled simulation environments. However, the transfer of
these trained models to real-world tasks often presents unavoidable challenges.
This research explores the direct training of RL algorithms in controlled yet
realistic real-world settings for the execution of dexterous manipulation. The
benchmarking results of three RL algorithms trained on intricate in-hand
manipulation tasks within practical real-world contexts are presented. Our
study not only demonstrates the practicality of RL training in authentic
real-world scenarios, facilitating direct real-world applications, but also
provides insights into the associated challenges and considerations.
Additionally, our experiences with the employed experimental methods are
shared, with the aim of empowering and engaging fellow researchers and
practitioners in this dynamic field of robotics.",2024-08-27,"Elizabeth Cutler, Yuning Xing, Tony Cui, Brendan Zhou, Koen van Rijnsoever, Ben Hart, David Valencia, Lee Violet C. Ong, Trevor Gee, Minas Liarokapis, Henry Williams",http://arxiv.org/pdf/2408.14747v1,cs.LG
How to Train Text Summarization Model with Weak Supervisions,"Currently, machine learning techniques have seen significant success across
various applications. Most of these techniques rely on supervision from
human-generated labels or a mixture of noisy and imprecise labels from multiple
sources. However, for certain complex tasks, even noisy or inexact labels are
unavailable due to the intricacy of the objectives. To tackle this issue, we
propose a method that breaks down the complex objective into simpler tasks and
generates supervision signals for each one. We then integrate these supervision
signals into a manageable form, resulting in a straightforward learning
procedure. As a case study, we demonstrate a system used for topic-based
summarization. This system leverages rich supervision signals to promote both
summarization and topic relevance. Remarkably, we can train the model
end-to-end without any labels. Experimental results indicate that our approach
performs exceptionally well on the CNN and DailyMail datasets.",2024-08-27,"Yanbo Wang, Wenyu Chen, Shimin Shan",http://arxiv.org/pdf/2409.00098v1,cs.LG
Feedback-based Modal Mutual Search for Attacking Vision-Language Pre-training Models,"Although vision-language pre-training (VLP) models have achieved remarkable
progress on cross-modal tasks, they remain vulnerable to adversarial attacks.
Using data augmentation and cross-modal interactions to generate transferable
adversarial examples on surrogate models, transfer-based black-box attacks have
become the mainstream methods in attacking VLP models, as they are more
practical in real-world scenarios. However, their transferability may be
limited due to the differences on feature representation across different
models. To this end, we propose a new attack paradigm called Feedback-based
Modal Mutual Search (FMMS). FMMS introduces a novel modal mutual loss (MML),
aiming to push away the matched image-text pairs while randomly drawing
mismatched pairs closer in feature space, guiding the update directions of the
adversarial examples. Additionally, FMMS leverages the target model feedback to
iteratively refine adversarial examples, driving them into the adversarial
region. To our knowledge, this is the first work to exploit target model
feedback to explore multi-modality adversarial boundaries. Extensive empirical
evaluations on Flickr30K and MSCOCO datasets for image-text matching tasks show
that FMMS significantly outperforms the state-of-the-art baselines.",2024-08-27,"Renhua Ding, Xinze Zhang, Xiao Yang, Kun He",http://arxiv.org/pdf/2409.06726v1,cs.LG
Learning Differentially Private Diffusion Models via Stochastic Adversarial Distillation,"While the success of deep learning relies on large amounts of training
datasets, data is often limited in privacy-sensitive domains. To address this
challenge, generative model learning with differential privacy has emerged as a
solution to train private generative models for desensitized data generation.
However, the quality of the images generated by existing methods is limited due
to the complexity of modeling data distribution. We build on the success of
diffusion models and introduce DP-SAD, which trains a private diffusion model
by a stochastic adversarial distillation method. Specifically, we first train a
diffusion model as a teacher and then train a student by distillation, in which
we achieve differential privacy by adding noise to the gradients from other
models to the student. For better generation quality, we introduce a
discriminator to distinguish whether an image is from the teacher or the
student, which forms the adversarial training. Extensive experiments and
analysis clearly demonstrate the effectiveness of our proposed method.",2024-08-27,"Bochao Liu, Pengju Wang, Shiming Ge",http://arxiv.org/pdf/2408.14738v1,cs.LG
Bandwidth-Aware and Overlap-Weighted Compression for Communication-Efficient Federated Learning,"Current data compression methods, such as sparsification in Federated
Averaging (FedAvg), effectively enhance the communication efficiency of
Federated Learning (FL). However, these methods encounter challenges such as
the straggler problem and diminished model performance due to heterogeneous
bandwidth and non-IID (Independently and Identically Distributed) data. To
address these issues, we introduce a bandwidth-aware compression framework for
FL, aimed at improving communication efficiency while mitigating the problems
associated with non-IID data. First, our strategy dynamically adjusts
compression ratios according to bandwidth, enabling clients to upload their
models at a close pace, thus exploiting the otherwise wasted time to transmit
more data. Second, we identify the non-overlapped pattern of retained
parameters after compression, which results in diminished client update signals
due to uniformly averaged weights. Based on this finding, we propose a
parameter mask to adjust the client-averaging coefficients at the parameter
level, thereby more closely approximating the original updates, and improving
the training convergence under heterogeneous environments. Our evaluations
reveal that our method significantly boosts model accuracy, with a maximum
improvement of 13% over the uncompressed FedAvg. Moreover, it achieves a
$3.37\times$ speedup in reaching the target accuracy compared to FedAvg with a
Top-K compressor, demonstrating its effectiveness in accelerating convergence
with compression. The integration of common compression techniques into our
framework further establishes its potential as a versatile foundation for
future cross-device, communication-efficient FL research, addressing critical
challenges in FL and advancing the field of distributed machine learning.",2024-08-27,"Zichen Tang, Junlin Huang, Rudan Yan, Yuxin Wang, Zhenheng Tang, Shaohuai Shi, Amelie Chi Zhou, Xiaowen Chu",http://arxiv.org/pdf/2408.14736v1,cs.LG
General-Kindred Physics-Informed Neural Network to the Solutions of Singularly Perturbed Differential Equations,"Physics-Informed Neural Networks (PINNs) have become a promising research
direction in the field of solving Partial Differential Equations (PDEs).
Dealing with singular perturbation problems continues to be a difficult
challenge in the field of PINN. The solution of singular perturbation problems
often exhibits sharp boundary layers and steep gradients, and traditional PINN
cannot achieve approximation of boundary layers. In this manuscript, we propose
the General-Kindred Physics-Informed Neural Network (GKPINN) for solving
Singular Perturbation Differential Equations (SPDEs). This approach utilizes
asymptotic analysis to acquire prior knowledge of the boundary layer from the
equation and establishes a novel network to assist PINN in approximating the
boundary layer. It is compared with traditional PINN by solving examples of
one-dimensional, two-dimensional, and time-varying SPDE equations. The research
findings underscore the exceptional performance of our novel approach, GKPINN,
which delivers a remarkable enhancement in reducing the $L_2$ error by two to
four orders of magnitude compared to the established PINN methodology. This
significant improvement is accompanied by a substantial acceleration in
convergence rates, without compromising the high precision that is critical for
our applications. Furthermore, GKPINN still performs well in extreme cases with
perturbation parameters of ${1\times10}^{-38}$, demonstrating its excellent
generalization ability.",2024-08-27,"Sen Wang, Peizhi Zhao, Qinglong Ma, Tao Song",http://arxiv.org/pdf/2408.14734v1,cs.LG
TART: Boosting Clean Accuracy Through Tangent Direction Guided Adversarial Training,"Adversarial training has been shown to be successful in enhancing the
robustness of deep neural networks against adversarial attacks. However, this
robustness is accompanied by a significant decline in accuracy on clean data.
In this paper, we propose a novel method, called Tangent Direction Guided
Adversarial Training (TART), that leverages the tangent space of the data
manifold to ameliorate the existing adversarial defense algorithms. We argue
that training with adversarial examples having large normal components
significantly alters the decision boundary and hurts accuracy. TART mitigates
this issue by estimating the tangent direction of adversarial examples and
allocating an adaptive perturbation limit according to the norm of their
tangential component. To the best of our knowledge, our paper is the first work
to consider the concept of tangent space and direction in the context of
adversarial defense. We validate the effectiveness of TART through extensive
experiments on both simulated and benchmark datasets. The results demonstrate
that TART consistently boosts clean accuracy while retaining a high level of
robustness against adversarial attacks. Our findings suggest that incorporating
the geometric properties of data can lead to more effective and efficient
adversarial training methods.",2024-08-27,"Bongsoo Yi, Rongjie Lai, Yao Li",http://arxiv.org/pdf/2408.14728v1,cs.LG
Non-instructional Fine-tuning: Enabling Instruction-Following Capabilities in Pre-trained Language Models without Instruction-Following Data,"Instruction fine-tuning is crucial for today's large language models (LLMs)
to learn to follow instructions and align with human preferences.
Conventionally, supervised data, including the instruction and the correct
response, is required for instruction fine-tuning. To obtain such data, some
researchers prompted well-trained models like GPT-4 to generate instructions
and correct responses. In this paper, we propose a novel approach that uses the
first half of a random text from OpenWebText as the instruction and
GPT-3.5-turbo or GPT-4-turbo to complete the text as the response. Despite the
data being ""non-instructional"", we found that pre-trained LLMs fine-tuned on
this data can gain instruction-following capabilities. This observation is
verified by fine-tuning several well-known pre-trained LLMs (e.g., LLaMA-2-7B,
LLaMA-3-8B, LLaMA-3-70B, Mistral-7B-v0.1). The ""non-instructional data"" also
improved some models that underwent supervised fine-tuning and human preference
alignment. Our LLaMA-3-70B-Instruct fine-tuned through ""non-instructional data""
is comparable with LLaMA-3.1-70B-Instruct on the Arena Hard leaderboard. We
analyzed the ""non-instructional data"" and ensured it is devoid of content
related to instruction fine-tuning. Our findings will inspire further
investigation into how to develop instruction-following capabilities without
explicit instruction-related data.",2024-08-27,"Juncheng Xie, Shensian Syu, Hung-yi Lee",http://arxiv.org/pdf/2409.00096v1,cs.LG
XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model,"In the rapidly evolving field of cybersecurity, the integration of flow-level
and packet-level information for real-time intrusion detection remains a
largely untapped area of research. This paper introduces ""XG-NID,"" a novel
framework that, to the best of our knowledge, is the first to fuse flow-level
and packet-level data within a heterogeneous graph structure, offering a
comprehensive analysis of network traffic. Leveraging a heterogeneous graph
neural network (GNN) with graph-level classification, XG-NID uniquely enables
real-time inference while effectively capturing the intricate relationships
between flow and packet payload data. Unlike traditional GNN-based
methodologies that predominantly analyze historical data, XG-NID is designed to
accommodate the heterogeneous nature of network traffic, providing a robust and
real-time defense mechanism. Our framework extends beyond mere classification;
it integrates Large Language Models (LLMs) to generate detailed, human-readable
explanations and suggest potential remedial actions, ensuring that the insights
produced are both actionable and comprehensible. Additionally, we introduce a
new set of flow features based on temporal information, further enhancing the
contextual and explainable inferences provided by our model. To facilitate
practical application and accessibility, we developed ""GNN4ID,"" an open-source
tool that enables the extraction and transformation of raw network traffic into
the proposed heterogeneous graph structure, seamlessly integrating flow and
packet-level data. Our comprehensive quantitative comparative analysis
demonstrates that XG-NID achieves an F1 score of 97\% in multi-class
classification, outperforming existing baseline and state-of-the-art methods.
This sets a new standard in Network Intrusion Detection Systems by combining
innovative data fusion with enhanced interpretability and real-time
capabilities.",2024-08-27,"Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian",http://arxiv.org/pdf/2408.16021v2,cs.LG
PAT: Pruning-Aware Tuning for Large Language Models,"Large language models (LLMs) excel in language tasks, especially with
supervised fine-tuning after pre-training. However, their substantial memory
and computational requirements hinder practical applications. Structural
pruning, which reduces less significant weight dimensions, is one solution.
Yet, traditional post-hoc pruning often leads to significant performance loss,
with limited recovery from further fine-tuning due to reduced capacity. Since
the model fine-tuning refines the general and chaotic knowledge in pre-trained
models, we aim to incorporate structural pruning with the fine-tuning, and
propose the Pruning-Aware Tuning (PAT) paradigm to eliminate model redundancy
while preserving the model performance to the maximum extend. Specifically, we
insert the innovative Hybrid Sparsification Modules (HSMs) between the
Attention and FFN components to accordingly sparsify the upstream and
downstream linear modules. The HSM comprises a lightweight operator and a
globally shared trainable mask. The lightweight operator maintains a training
overhead comparable to that of LoRA, while the trainable mask unifies the
channels to be sparsified, ensuring structural pruning. Additionally, we
propose the Identity Loss which decouples the transformation and scaling
properties of the HSMs to enhance training robustness. Extensive experiments
demonstrate that PAT excels in both performance and efficiency. For example,
our Llama2-7b model with a 25\% pruning ratio achieves 1.33$\times$ speedup
while outperforming the LoRA-finetuned model by up to 1.26\% in accuracy with a
similar training cost. Code:
https://github.com/kriskrisliu/PAT_Pruning-Aware-Tuning",2024-08-27,"Yijiang Liu, Huanrui Yang, Youxin Chen, Rongyu Zhang, Miao Wang, Yuan Du, Li Du",http://arxiv.org/pdf/2408.14721v2,cs.LG
A Synthetic Benchmark to Explore Limitations of Localized Drift Detections,"Concept drift is a common phenomenon in data streams where the statistical
properties of the target variable change over time. Traditionally, drift is
assumed to occur globally, affecting the entire dataset uniformly. However,
this assumption does not always hold true in real-world scenarios where only
specific subpopulations within the data may experience drift. This paper
explores the concept of localized drift and evaluates the performance of
several drift detection techniques in identifying such localized changes. We
introduce a synthetic dataset based on the Agrawal generator, where drift is
induced in a randomly chosen subgroup. Our experiments demonstrate that
commonly adopted drift detection methods may fail to detect drift when it is
confined to a small subpopulation. We propose and test various drift detection
approaches to quantify their effectiveness in this localized drift scenario. We
make the source code for the generation of the synthetic benchmark available at
https://github.com/fgiobergia/subgroup-agrawal-drift.",2024-08-26,"Flavio Giobergia, Eliana Pastor, Luca de Alfaro, Elena Baralis",http://arxiv.org/pdf/2408.14687v1,cs.LG
Model-Based Reinforcement Learning for Control of Strongly-Disturbed Unsteady Aerodynamic Flows,"The intrinsic high dimension of fluid dynamics is an inherent challenge to
control of aerodynamic flows, and this is further complicated by a flow's
nonlinear response to strong disturbances. Deep reinforcement learning, which
takes advantage of the exploratory aspects of reinforcement learning (RL) and
the rich nonlinearity of a deep neural network, provides a promising approach
to discover feasible control strategies. However, the typical model-free
approach to reinforcement learning requires a significant amount of interaction
between the flow environment and the RL agent during training, and this high
training cost impedes its development and application. In this work, we propose
a model-based reinforcement learning (MBRL) approach by incorporating a novel
reduced-order model as a surrogate for the full environment. The model consists
of a physics-augmented autoencoder, which compresses high-dimensional CFD flow
field snaphsots into a three-dimensional latent space, and a latent dynamics
model that is trained to accurately predict the long-time dynamics of
trajectories in the latent space in response to action sequences. The accuracy
and robustness of the model are demonstrated in the scenario of a pitching
airfoil within a highly disturbed environment. Additionally, an application to
a vertical-axis wind turbine in a disturbance-free environment is discussed in
the Appendix Based on the model trained in the pitching airfoil problem, we
realize an MBRL strategy to mitigate lift variation during gust-airfoil
encounters. We demonstrate that the policy learned in the reduced-order
environment translates to an effective control strategy in the full CFD
environment.",2024-08-26,"Zhecheng Liu, Diederik Beckers, Jeff D. Eldredge",http://arxiv.org/pdf/2408.14685v2,cs.LG
Detecting Interpretable Subgroup Drifts,"The ability to detect and adapt to changes in data distributions is crucial
to maintain the accuracy and reliability of machine learning models. Detection
is generally approached by observing the drift of model performance from a
global point of view. However, drifts occurring in (fine-grained) data
subgroups may go unnoticed when monitoring global drift. We take a different
perspective, and introduce methods for observing drift at the finer granularity
of subgroups. Relevant data subgroups are identified during training and
monitored efficiently throughout the model's life. Performance drifts in any
subgroup are detected, quantified and characterized so as to provide an
interpretable summary of the model behavior over time. Experimental results
confirm that our subgroup-level drift analysis identifies drifts that do not
show at the (coarser) global dataset level. The proposed approach provides a
valuable tool for monitoring model performance in dynamic real-world
applications, offering insights into the evolving nature of data and ultimately
contributing to more robust and adaptive models.",2024-08-26,"Flavio Giobergia, Eliana Pastor, Luca de Alfaro, Elena Baralis",http://arxiv.org/pdf/2408.14682v1,cs.LG
Enhancing Neural Network Interpretability Through Conductance-Based Information Plane Analysis,"The Information Plane is a conceptual framework used to analyze the flow of
information in neural networks, but traditional methods based on activations
may not fully capture the dynamics of information processing. This paper
introduces a new approach that uses layer conductance, a measure of sensitivity
to input features, to enhance the Information Plane analysis. By incorporating
gradient-based contributions, we provide a more precise characterization of
information dynamics within the network. The proposed conductance-based
Information Plane and a new Information Transformation Efficiency (ITE) metric
are evaluated on pretrained ResNet50 and VGG16 models using the ImageNet
dataset. Our results demonstrate the ability to identify critical hidden layers
that contribute significantly to model performance and interpretability, giving
insights into information compression, preservation, and utilization across
layers. The conductance-based approach offers a granular perspective on feature
attribution, enhancing our understanding of the decision-making processes
within neural networks. Furthermore, our empirical findings challenge certain
theoretical predictions of the Information Bottleneck theory, highlighting the
complexities of information dynamics in real-world data scenarios. The proposed
method not only advances our understanding of information dynamics in neural
networks but also has the potential to significantly impact the broader field
of Artificial Intelligence by enabling the development of more interpretable,
efficient, and robust models.",2024-08-26,"Jaouad Dabounou, Amine Baazzouz",http://arxiv.org/pdf/2408.14681v1,cs.LG
"On-Chip Learning with Memristor-Based Neural Networks: Assessing Accuracy and Efficiency Under Device Variations, Conductance Errors, and Input Noise","This paper presents a memristor-based compute-in-memory hardware accelerator
for on-chip training and inference, focusing on its accuracy and efficiency
against device variations, conductance errors, and input noise. Utilizing
realistic SPICE models of commercially available silver-based metal
self-directed channel (M-SDC) memristors, the study incorporates inherent
device non-idealities into the circuit simulations. The hardware, consisting of
30 memristors and 4 neurons, utilizes three different M-SDC structures with
tungsten, chromium, and carbon media to perform binary image classification
tasks. An on-chip training algorithm precisely tunes memristor conductance to
achieve target weights. Results show that incorporating moderate noise (<15%)
during training enhances robustness to device variations and noisy input data,
achieving up to 97% accuracy despite conductance variations and input noises.
The network tolerates a 10% conductance error without significant accuracy
loss. Notably, omitting the initial memristor reset pulse during training
considerably reduces training time and energy consumption. The hardware
designed with chromium-based memristors exhibits superior performance,
achieving a training time of 2.4 seconds and an energy consumption of 18.9 mJ.
This research provides insights for developing robust and energy-efficient
memristor-based neural networks for on-chip learning in edge applications.",2024-08-26,"M. Reza Eslami, Dhiman Biswas, Soheib Takhtardeshir, Sarah S. Sharif, Yaser M. Banad",http://arxiv.org/pdf/2408.14680v1,cs.LG
Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems,"Knowledge Distillation (KD) is a powerful approach for compressing a large
model into a smaller, more efficient model, particularly beneficial for
latency-sensitive applications like recommender systems. However, current KD
research predominantly focuses on Computer Vision (CV) and NLP tasks,
overlooking unique data characteristics and challenges inherent to recommender
systems. This paper addresses these overlooked challenges, specifically: (1)
mitigating data distribution shifts between teacher and student models, (2)
efficiently identifying optimal teacher configurations within time and
budgetary constraints, and (3) enabling computationally efficient and rapid
sharing of teacher labels to support multiple students. We present a robust KD
system developed and rigorously evaluated on multiple large-scale personalized
video recommendation systems within Google. Our live experiment results
demonstrate significant improvements in student model performance while
ensuring consistent and reliable generation of high quality teacher labels from
a continuous data stream of data.",2024-08-26,"Nikhil Khani, Shuo Yang, Aniruddh Nath, Yang Liu, Pendo Abbo, Li Wei, Shawn Andrews, Maciej Kula, Jarrod Kahn, Zhe Zhao, Lichan Hong, Ed Chi",http://arxiv.org/pdf/2408.14678v1,cs.LG
Can Optimization Trajectories Explain Multi-Task Transfer?,"Despite the widespread adoption of multi-task training in deep learning,
little is understood about how multi-task learning (MTL) affects
generalization. Prior work has conjectured that the negative effects of MTL are
due to optimization challenges that arise during training, and many
optimization methods have been proposed to improve multi-task performance.
However, recent work has shown that these methods fail to consistently improve
multi-task generalization. In this work, we seek to improve our understanding
of these failures by empirically studying how MTL impacts the optimization of
tasks, and whether this impact can explain the effects of MTL on
generalization. We show that MTL results in a generalization gap (a gap in
generalization at comparable training loss) between single-task and multi-task
trajectories early into training. However, we find that factors of the
optimization trajectory previously proposed to explain generalization gaps in
single-task settings cannot explain the generalization gaps between single-task
and multi-task models. Moreover, we show that the amount of gradient conflict
between tasks is correlated with negative effects to task optimization, but is
not predictive of generalization. Our work sheds light on the underlying causes
for failures in MTL and, importantly, raises questions about the role of
general purpose multi-task optimization algorithms.",2024-08-26,"David Mueller, Mark Dredze, Nicholas Andrews",http://arxiv.org/pdf/2408.14677v2,cs.LG
DefectTwin: When LLM Meets Digital Twin for Railway Defect Inspection,"A Digital Twin (DT) replicates objects, processes, or systems for real-time
monitoring, simulation, and predictive maintenance. Recent advancements like
Large Language Models (LLMs) have revolutionized traditional AI systems and
offer immense potential when combined with DT in industrial applications such
as railway defect inspection. Traditionally, this inspection requires extensive
defect samples to identify patterns, but limited samples can lead to
overfitting and poor performance on unseen defects. Integrating pre-trained
LLMs into DT addresses this challenge by reducing the need for vast sample
data. We introduce DefectTwin, which employs a multimodal and multi-model (M^2)
LLM-based AI pipeline to analyze both seen and unseen visual defects in
railways. This application enables a railway agent to perform expert-level
defect analysis using consumer electronics (e.g., tablets). A multimodal
processor ensures responses are in a consumable format, while an instant user
feedback mechanism (instaUF) enhances Quality-of-Experience (QoE). The proposed
M^2 LLM outperforms existing models, achieving high precision (0.76-0.93)
across multimodal inputs including text, images, and videos of pre-trained
defects, and demonstrates superior zero-shot generalizability for unseen
defects. We also evaluate the latency, token count, and usefulness of responses
generated by DefectTwin on consumer devices. To our knowledge, DefectTwin is
the first LLM-integrated DT designed for railway defect inspection.",2024-08-26,"Rahatara Ferdousi, M. Anwar Hossain, Chunsheng Yang, Abdulmotaleb El Saddik",http://arxiv.org/pdf/2409.06725v1,cs.LG
KGPrune: a Web Application to Extract Subgraphs of Interest from Wikidata with Analogical Pruning,"Knowledge graphs (KGs) have become ubiquitous publicly available knowledge
sources, and are nowadays covering an ever increasing array of domains.
However, not all knowledge represented is useful or pertaining when considering
a new application or specific task. Also, due to their increasing size,
handling large KGs in their entirety entails scalability issues. These two
aspects asks for efficient methods to extract subgraphs of interest from
existing KGs. To this aim, we introduce KGPrune, a Web Application that, given
seed entities of interest and properties to traverse, extracts their
neighboring subgraphs from Wikidata. To avoid topical drift, KGPrune relies on
a frugal pruning algorithm based on analogical reasoning to only keep relevant
neighbors while pruning irrelevant ones. The interest of KGPrune is illustrated
by two concrete applications, namely, bootstrapping an enterprise KG and
extracting knowledge related to looted artworks.",2024-08-26,"Pierre Monnin, Cherif-Hassan Nousradine, Lucas Jarnac, Laurel Zuckerman, Miguel Couceiro",http://arxiv.org/pdf/2408.14658v1,cs.LG
"MLP, XGBoost, KAN, TDNN, and LSTM-GRU Hybrid RNN with Attention for SPX and NDX European Call Option Pricing","We explore the performance of various artificial neural network
architectures, including a multilayer perceptron (MLP), Kolmogorov-Arnold
network (KAN), LSTM-GRU hybrid recursive neural network (RNN) models, and a
time-delay neural network (TDNN) for pricing European call options. In this
study, we attempt to leverage the ability of supervised learning methods, such
as ANNs, KANs, and gradient-boosted decision trees, to approximate complex
multivariate functions in order to calibrate option prices based on past market
data. The motivation for using ANNs and KANs is the Universal Approximation
Theorem and Kolmogorov-Arnold Representation Theorem, respectively.
Specifically, we use S\&P 500 (SPX) and NASDAQ 100 (NDX) index options traded
during 2015-2023 with times to maturity ranging from 15 days to over 4 years
(OptionMetrics IvyDB US dataset). Black \& Scholes's (BS) PDE \cite{Black1973}
model's performance in pricing the same options compared to real data is used
as a benchmark. This model relies on strong assumptions, and it has been
observed and discussed in the literature that real data does not match its
predictions. Supervised learning methods are widely used as an alternative for
calibrating option prices due to some of the limitations of this model. In our
experiments, the BS model underperforms compared to all of the others. Also,
the best TDNN model outperforms the best MLP model on all error metrics. We
implement a simple self-attention mechanism to enhance the RNN models,
significantly improving their performance. The best-performing model overall is
the LSTM-GRU hybrid RNN model with attention. Also, the KAN model outperforms
the TDNN and MLP models. We analyze the performance of all models by ticker,
moneyness category, and over/under/correctly-priced percentage.",2024-08-26,"Boris Ter-Avanesov, Homayoon Beigi",http://arxiv.org/pdf/2409.06724v3,cs.LG
Relationships are Complicated! An Analysis of Relationships Between Datasets on the Web,"The Web today has millions of datasets, and the number of datasets continues
to grow at a rapid pace. These datasets are not standalone entities; rather,
they are intricately connected through complex relationships. Semantic
relationships between datasets provide critical insights for research and
decision-making processes. In this paper, we study dataset relationships from
the perspective of users who discover, use, and share datasets on the Web: what
relationships are important for different tasks? What contextual information
might users want to know? We first present a comprehensive taxonomy of
relationships between datasets on the Web and map these relationships to user
tasks performed during dataset discovery. We develop a series of methods to
identify these relationships and compare their performance on a large corpus of
datasets generated from Web pages with schema.org markup. We demonstrate that
machine-learning based methods that use dataset metadata achieve multi-class
classification accuracy of 90%. Finally, we highlight gaps in available
semantic markup for datasets and discuss how incorporating comprehensive
semantics can facilitate the identification of dataset relationships. By
providing a comprehensive overview of dataset relationships at scale, this
paper sets a benchmark for future research.",2024-08-26,"Kate Lin, Tarfah Alrashed, Natasha Noy",http://arxiv.org/pdf/2408.14636v1,cs.LG
Hybrid Deep Convolutional Neural Networks Combined with Autoencoders And Augmented Data To Predict The Look-Up Table 2006,"This study explores the development of a hybrid deep convolutional neural
network (DCNN) model enhanced by autoencoders and data augmentation techniques
to predict critical heat flux (CHF) with high accuracy. By augmenting the
original input features using three different autoencoder configurations, the
model's predictive capabilities were significantly improved. The hybrid models
were trained and tested on a dataset of 7225 samples, with performance metrics
including the coefficient of determination (R2), Nash-Sutcliffe efficiency
(NSE), mean absolute error (MAE), and normalized root-mean-squared error
(NRMSE) used for evaluation. Among the tested models, the DCNN_3F-A2
configuration demonstrated the highest accuracy, achieving an R2 of 0.9908
during training and 0.9826 during testing, outperforming the base model and
other augmented versions. These results suggest that the proposed hybrid
approach, combining deep learning with feature augmentation, offers a robust
solution for CHF prediction, with the potential to generalize across a wider
range of conditions.",2024-08-26,"Messaoud Djeddou, Aouatef Hellal, Ibrahim A. Hameed, Xingang Zhao, Djehad Al Dallal",http://arxiv.org/pdf/2408.14626v1,cs.LG
General targeted machine learning for modern causal mediation analysis,"Causal mediation analyses investigate the mechanisms through which causes
exert their effects, and are therefore central to scientific progress. The
literature on the non-parametric definition and identification of mediational
effects in rigourous causal models has grown significantly in recent years, and
there has been important progress to address challenges in the interpretation
and identification of such effects. Despite great progress in the causal
inference front, statistical methodology for non-parametric estimation has
lagged behind, with few or no methods available for tackling non-parametric
estimation in the presence of multiple, continuous, or high-dimensional
mediators. In this paper we show that the identification formulas for six
popular non-parametric approaches to mediation analysis proposed in recent
years can be recovered from just two statistical estimands. We leverage this
finding to propose an all-purpose one-step estimation algorithm that can be
coupled with machine learning in any mediation study that uses any of these six
definitions of mediation. The estimators have desirable properties, such as
$\sqrt{n}$-convergence and asymptotic normality. Estimating the first-order
correction for the one-step estimator requires estimation of complex density
ratios on the potentially high-dimensional mediators, a challenge that is
solved using recent advancements in so-called Riesz learning. We illustrate the
properties of our methods in a simulation study and illustrate its use on real
data to estimate the extent to which pain management practices mediate the
total effect of having a chronic pain disorder on opioid use disorder.",2024-08-26,"Richard Liu, Nicholas T. Williams, Kara E. Rudolph, Iván Díaz",http://arxiv.org/pdf/2408.14620v1,cs.LG
Meta Flow Matching: Integrating Vector Fields on the Wasserstein Manifold,"Numerous biological and physical processes can be modeled as systems of
interacting entities evolving continuously over time, e.g. the dynamics of
communicating cells or physical particles. Learning the dynamics of such
systems is essential for predicting the temporal evolution of populations
across novel samples and unseen environments. Flow-based models allow for
learning these dynamics at the population level - they model the evolution of
the entire distribution of samples. However, current flow-based models are
limited to a single initial population and a set of predefined conditions which
describe different dynamics. We argue that multiple processes in natural
sciences have to be represented as vector fields on the Wasserstein manifold of
probability densities. That is, the change of the population at any moment in
time depends on the population itself due to the interactions between samples.
In particular, this is crucial for personalized medicine where the development
of diseases and their respective treatment response depend on the
microenvironment of cells specific to each patient. We propose Meta Flow
Matching (MFM), a practical approach to integrate along these vector fields on
the Wasserstein manifold by amortizing the flow model over the initial
populations. Namely, we embed the population of samples using a Graph Neural
Network (GNN) and use these embeddings to train a Flow Matching model. This
gives MFM the ability to generalize over the initial distributions, unlike
previously proposed methods. We demonstrate the ability of MFM to improve the
prediction of individual treatment responses on a large-scale multi-patient
single-cell drug screen dataset.",2024-08-26,"Lazar Atanackovic, Xi Zhang, Brandon Amos, Mathieu Blanchette, Leo J. Lee, Yoshua Bengio, Alexander Tong, Kirill Neklyudov",http://arxiv.org/pdf/2408.14608v2,cs.LG
Biased Dueling Bandits with Stochastic Delayed Feedback,"The dueling bandit problem, an essential variation of the traditional
multi-armed bandit problem, has become significantly prominent recently due to
its broad applications in online advertising, recommendation systems,
information retrieval, and more. However, in many real-world applications, the
feedback for actions is often subject to unavoidable delays and is not
immediately available to the agent. This partially observable issue poses a
significant challenge to existing dueling bandit literature, as it
significantly affects how quickly and accurately the agent can update their
policy on the fly. In this paper, we introduce and examine the biased dueling
bandit problem with stochastic delayed feedback, revealing that this new
practical problem will delve into a more realistic and intriguing scenario
involving a preference bias between the selections. We present two algorithms
designed to handle situations involving delay. Our first algorithm, requiring
complete delay distribution information, achieves the optimal regret bound for
the dueling bandit problem when there is no delay. The second algorithm is
tailored for situations where the distribution is unknown, but only the
expected value of delay is available. We provide a comprehensive regret
analysis for the two proposed algorithms and then evaluate their empirical
performance on both synthetic and real datasets.",2024-08-26,"Bongsoo Yi, Yue Kang, Yao Li",http://arxiv.org/pdf/2408.14603v2,cs.LG
Efficient fine-tuning of 37-level GraphCast with the Canadian global deterministic analysis,"This work describes a process for efficiently fine-tuning the GraphCast
data-driven forecast model to simulate another analysis system, here the Global
Deterministic Prediction System (GDPS) of Environment and Climate Change Canada
(ECCC). Using two years of training data (July 2019 -- December 2021) and 37
GPU-days of computation to tune the 37-level, quarter-degree version of
GraphCast, the resulting model significantly outperforms both the unmodified
GraphCast and operational forecast, showing significant forecast skill in the
troposphere over lead times from 1 to 10 days. This fine-tuning is accomplished
through abbreviating DeepMind's original training curriculum for GraphCast,
relying on a shorter single-step forecast stage to accomplish the bulk of the
adaptation work and consolidating the autoregressive stages into separate 12hr,
1d, 2d, and 3d stages with larger learning rates. Additionally, training over
3d forecasts is split into two sub-steps to conserve host memory while
maintaining a strong correlation with training over the full period.",2024-08-26,Christopher Subich,http://arxiv.org/pdf/2408.14587v2,cs.LG
Automated Quantification of White Blood Cells in Light Microscopic Images of Injured Skeletal Muscle,"White blood cells (WBCs) are the most diverse cell types observed in the
healing process of injured skeletal muscles. In the course of healing, WBCs
exhibit dynamic cellular response and undergo multiple protein expression
changes. The progress of healing can be analyzed by quantifying the number of
WBCs or the amount of specific proteins in light microscopic images obtained at
different time points after injury. In this paper, we propose an automated
quantifying and analysis framework to analyze WBCs using light microscopic
images of uninjured and injured muscles. The proposed framework is based on the
Localized Iterative Otsu's threshold method with muscle edge detection and
region of interest extraction. Compared with the threshold methods used in
ImageJ, the LI Otsu's threshold method has high resistance to background area
and achieves better accuracy. The CD68-positive cell results are presented for
demonstrating the effectiveness of the proposed work.",2024-08-26,"Yang Jiao, Hananeh Derakhshan, Barbara St. Pierre Schneider, Emma Regentova, Mei Yang",http://arxiv.org/pdf/2409.06722v1,cs.LG
CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation,"This paper introduces CURLoRA, a novel approach to fine-tuning large language
models (LLMs) that leverages CUR matrix decomposition in the context of
Low-Rank Adaptation (LoRA). Our method addresses two critical challenges in LLM
fine-tuning: mitigating catastrophic forgetting during continual learning and
reducing the number of trainable parameters. We propose a unique modification
to the CUR decomposition process, utilizing inverted probabilities for column
and row selection which acts as an implicit regularization, and initializing
the $U$ matrix as a zero matrix, and only fine-tuning it. We demonstrate
through experiments on multiple datasets that CURLoRA outperforms standard LoRA
in mitigating catastrophic forgetting. It maintains model stability and
performance across tasks while significantly reducing the number of trainable
parameters. Our results show that CURLoRA achieves very good and stable task
accuracy while maintaining base model's perplexity scores fixed compared to
LoRA upon continual fine-tuning, particularly in scenarios with limited data.",2024-08-26,Muhammad Fawi,http://arxiv.org/pdf/2408.14572v1,cs.LG
Exploring the Potential of Synthetic Data to Replace Real Data,"The potential of synthetic data to replace real data creates a huge demand
for synthetic data in data-hungry AI. This potential is even greater when
synthetic data is used for training along with a small number of real images
from domains other than the test domain. We find that this potential varies
depending on (i) the number of cross-domain real images and (ii) the test set
on which the trained model is evaluated. We introduce two new metrics, the
train2test distance and $\text{AP}_\text{t2t}$, to evaluate the ability of a
cross-domain training set using synthetic data to represent the characteristics
of test instances in relation to training performance. Using these metrics, we
delve deeper into the factors that influence the potential of synthetic data
and uncover some interesting dynamics about how synthetic data impacts training
performance. We hope these discoveries will encourage more widespread use of
synthetic data.",2024-08-26,"Hyungtae Lee, Yan Zhang, Heesung Kwon, Shuvra S. Bhattacharrya",http://arxiv.org/pdf/2408.14559v1,cs.LG
Aiding Humans in Financial Fraud Decision Making: Toward an XAI-Visualization Framework,"AI prevails in financial fraud detection and decision making. Yet, due to
concerns about biased automated decision making or profiling, regulations
mandate that final decisions are made by humans. Financial fraud investigators
face the challenge of manually synthesizing vast amounts of unstructured
information, including AI alerts, transaction histories, social media insights,
and governmental laws. Current Visual Analytics (VA) systems primarily support
isolated aspects of this process, such as explaining binary AI alerts and
visualizing transaction patterns, thus adding yet another layer of information
to the overall complexity. In this work, we propose a framework where the VA
system supports decision makers throughout all stages of financial fraud
investigation, including data collection, information synthesis, and human
criteria iteration. We illustrate how VA can claim a central role in AI-aided
decision making, ensuring that human judgment remains in control while
minimizing potential biases and labor-intensive tasks.",2024-08-26,"Angelos Chatzimparmpas, Evanthia Dimara",http://arxiv.org/pdf/2408.14552v1,cs.LG
A Practitioner's Guide to Continual Multimodal Pretraining,"Multimodal foundation models serve numerous applications at the intersection
of vision and language. Still, despite being pretrained on extensive data, they
become outdated over time. To keep models updated, research into continual
pretraining mainly explores scenarios with either (1) infrequent,
indiscriminate updates on large-scale new data, or (2) frequent, sample-level
updates. However, practical model deployment often operates in the gap between
these two limit cases, as real-world applications often demand adaptation to
specific subdomains, tasks or concepts -- spread over the entire, varying life
cycle of a model. In this work, we complement current perspectives on continual
pretraining through a research test bed as well as provide comprehensive
guidance for effective continual model updates in such scenarios. We first
introduce FoMo-in-Flux, a continual multimodal pretraining benchmark with
realistic compute constraints and practical deployment requirements,
constructed over 63 datasets with diverse visual and semantic coverage. Using
FoMo-in-Flux, we explore the complex landscape of practical continual
pretraining through multiple perspectives: (1) A data-centric investigation of
data mixtures and stream orderings that emulate real-world deployment
situations, (2) a method-centric investigation ranging from simple fine-tuning
and traditional continual learning strategies to parameter-efficient updates
and model merging, (3) meta learning rate schedules and mechanistic design
choices, and (4) the influence of model and compute scaling. Together, our
insights provide a practitioner's guide to continual multimodal pretraining for
real-world deployment. Our benchmark and code is here:
https://github.com/ExplainableML/fomo_in_flux.",2024-08-26,"Karsten Roth, Vishaal Udandarao, Sebastian Dziadzio, Ameya Prabhu, Mehdi Cherti, Oriol Vinyals, Olivier Hénaff, Samuel Albanie, Matthias Bethge, Zeynep Akata",http://arxiv.org/pdf/2408.14471v2,cs.LG
A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations,"In this paper, we propose a domain-decomposition-based deep learning (DL)
framework, named transient-CoMLSim, for accurately modeling unsteady and
nonlinear partial differential equations (PDEs). The framework consists of two
key components: (a) a convolutional neural network (CNN)-based autoencoder
architecture and (b) an autoregressive model composed of fully connected
layers. Unlike existing state-of-the-art methods that operate on the entire
computational domain, our CNN-based autoencoder computes a lower-dimensional
basis for solution and condition fields represented on subdomains. Timestepping
is performed entirely in the latent space, generating embeddings of the
solution variables from the time history of embeddings of solution and
condition variables. This approach not only reduces computational complexity
but also enhances scalability, making it well-suited for large-scale
simulations. Furthermore, to improve the stability of our rollouts, we employ a
curriculum learning (CL) approach during the training of the autoregressive
model. The domain-decomposition strategy enables scaling to out-of-distribution
domain sizes while maintaining the accuracy of predictions -- a feature not
easily integrated into popular DL-based approaches for physics simulations. We
benchmark our model against two widely-used DL architectures, Fourier Neural
Operator (FNO) and U-Net, and demonstrate that our framework outperforms them
in terms of accuracy, extrapolation to unseen timesteps, and stability for a
wide range of use cases.",2024-08-26,"Sheel Nidhan, Haoliang Jiang, Lalit Ghule, Clancy Umphrey, Rishikesh Ranade, Jay Pathak",http://arxiv.org/pdf/2408.14461v3,cs.LG
Reconstructing physiological signals from fMRI across the adult lifespan,"Interactions between the brain and body are of fundamental importance for
human behavior and health. Functional magnetic resonance imaging (fMRI)
captures whole-brain activity noninvasively, and modeling how fMRI signals
interact with physiological dynamics of the body can provide new insight into
brain function and offer potential biomarkers of disease. However,
physiological recordings are not always possible to acquire since they require
extra equipment and setup, and even when they are, the recorded physiological
signals may contain substantial artifacts. To overcome this limitation, machine
learning models have been proposed to directly extract features of respiratory
and cardiac activity from resting-state fMRI signals. To date, such work has
been carried out only in healthy young adults and in a pediatric population,
leaving open questions about the efficacy of these approaches on older adults.
Here, we propose a novel framework that leverages Transformer-based
architectures for reconstructing two key physiological signals - low-frequency
respiratory volume (RV) and heart rate (HR) fluctuations - from fMRI data, and
test these models on a dataset of individuals aged 36-89 years old. Our
framework outperforms previously proposed approaches (attaining median
correlations between predicted and measured signals of r ~ .698 for RV and r ~
.618 for HR), indicating the potential of leveraging attention mechanisms to
model fMRI-physiological signal relationships. We also evaluate several model
training and fine-tuning strategies, and find that incorporating young-adult
data during training improves the performance when predicting physiological
signals in the aging cohort. Overall, our approach successfully infers key
physiological variables directly from fMRI data from individuals across a wide
range of the adult lifespan.",2024-08-26,"Shiyu Wang, Ziyuan Xu, Laurent M. Lochard, Yamin Li, Jiawen Fan, Jingyuan E. Chen, Yuankai Huo, Mara Mather, Roza G. Bayrak, Catie Chang",http://arxiv.org/pdf/2408.14453v2,cs.LG
Symmetry & Critical Points,"Critical points of an invariant function may or may not be symmetric. We
prove, however, that if a symmetric critical point exists, those adjacent to it
are generically symmetry breaking. This mathematical mechanism is shown to
carry important implications for our ability to efficiently minimize invariant
nonconvex functions, in particular those associated with neural networks.",2024-08-26,Yossi Arjevani,http://arxiv.org/pdf/2408.14445v1,cs.LG
Model Parallel Training and Transfer Learning for Convolutional Neural Networks by Domain Decomposition,"Deep convolutional neural networks (CNNs) have been shown to be very
successful in a wide range of image processing applications. However, due to
their increasing number of model parameters and an increasing availability of
large amounts of training data, parallelization strategies to efficiently train
complex CNNs are necessary. In previous work by the authors, a novel model
parallel CNN architecture was proposed which is loosely inspired by domain
decomposition. In particular, the novel network architecture is based on a
decomposition of the input data into smaller subimages. For each of these
subimages, local CNNs with a proportionally smaller number of parameters are
trained in parallel and the resulting local classifications are then aggregated
in a second step by a dense feedforward neural network (DNN). In the present
work, we compare the resulting CNN-DNN architecture to less costly alternatives
to combine the local classifications into a final, global decision.
Additionally, we investigate the performance of the CNN-DNN trained as one
coherent model as well as using a transfer learning strategy, where the
parameters of the pre-trained local CNNs are used as initial values for a
subsequently trained global coherent CNN-DNN model.",2024-08-26,"Axel Klawonn, Martin Lanser, Janine Weber",http://arxiv.org/pdf/2408.14442v1,cs.LG
Social perception of faces in a vision-language model,"We explore social perception of human faces in CLIP, a widely used
open-source vision-language model. To this end, we compare the similarity in
CLIP embeddings between different textual prompts and a set of face images. Our
textual prompts are constructed from well-validated social psychology terms
denoting social perception. The face images are synthetic and are
systematically and independently varied along six dimensions: the legally
protected attributes of age, gender, and race, as well as facial expression,
lighting, and pose. Independently and systematically manipulating face
attributes allows us to study the effect of each on social perception and
avoids confounds that can occur in wild-collected data due to uncontrolled
systematic correlations between attributes. Thus, our findings are experimental
rather than observational. Our main findings are three. First, while CLIP is
trained on the widest variety of images and texts, it is able to make
fine-grained human-like social judgments on face images. Second, age, gender,
and race do systematically impact CLIP's social perception of faces, suggesting
an undesirable bias in CLIP vis-a-vis legally protected attributes. Most
strikingly, we find a strong pattern of bias concerning the faces of Black
women, where CLIP produces extreme values of social perception across different
ages and facial expressions. Third, facial expression impacts social perception
more than age and lighting as much as age. The last finding predicts that
studies that do not control for unprotected visual attributes may reach the
wrong conclusions on bias. Our novel method of investigation, which is founded
on the social psychology literature and on the experiments involving the
manipulation of individual attributes, yields sharper and more reliable
observations than previous observational methods and may be applied to study
biases in any vision-language model.",2024-08-26,"Carina I. Hausladen, Manuel Knott, Colin F. Camerer, Pietro Perona",http://arxiv.org/pdf/2408.14435v1,cs.LG
Employing Artificial Intelligence to Steer Exascale Workflows with Colmena,"Computational workflows are a common class of application on supercomputers,
yet the loosely coupled and heterogeneous nature of workflows often fails to
take full advantage of their capabilities. We created Colmena to leverage the
massive parallelism of a supercomputer by using Artificial Intelligence (AI) to
learn from and adapt a workflow as it executes. Colmena allows scientists to
define how their application should respond to events (e.g., task completion)
as a series of cooperative agents. In this paper, we describe the design of
Colmena, the challenges we overcame while deploying applications on exascale
systems, and the science workflows we have enhanced through interweaving AI.
The scaling challenges we discuss include developing steering strategies that
maximize node utilization, introducing data fabrics that reduce communication
overhead of data-intensive tasks, and implementing workflow tasks that cache
costly operations between invocations. These innovations coupled with a variety
of application patterns accessible through our agent-based steering model have
enabled science advances in chemistry, biophysics, and materials science using
different types of AI. Our vision is that Colmena will spur creative solutions
that harness AI across many domains of scientific computing.",2024-08-26,"Logan Ward, J. Gregory Pauloski, Valerie Hayot-Sasson, Yadu Babuji, Alexander Brace, Ryan Chard, Kyle Chard, Rajeev Thakur, Ian Foster",http://arxiv.org/pdf/2408.14434v1,cs.LG
Contextual Bandit with Herding Effects: Algorithms and Recommendation Applications,"Contextual bandits serve as a fundamental algorithmic framework for
optimizing recommendation decisions online. Though extensive attention has been
paid to tailoring contextual bandits for recommendation applications, the
""herding effects"" in user feedback have been ignored. These herding effects
bias user feedback toward historical ratings, breaking down the assumption of
unbiased feedback inherent in contextual bandits. This paper develops a novel
variant of the contextual bandit that is tailored to address the feedback bias
caused by the herding effects. A user feedback model is formulated to capture
this feedback bias. We design the TS-Conf (Thompson Sampling under Conformity)
algorithm, which employs posterior sampling to balance the exploration and
exploitation tradeoff. We prove an upper bound for the regret of the algorithm,
revealing the impact of herding effects on learning speed. Extensive
experiments on datasets demonstrate that TS-Conf outperforms four benchmark
algorithms. Analysis reveals that TS-Conf effectively mitigates the negative
impact of herding effects, resulting in faster learning and improved
recommendation accuracy.",2024-08-26,"Luyue Xu, Liming Wang, Hong Xie, Mingqiang Zhou",http://arxiv.org/pdf/2408.14432v2,cs.LG
Evaluating saliency scores in point clouds of natural environments by learning surface anomalies,"In recent years, three-dimensional point clouds are used increasingly to
document natural environments. Each dataset contains a diverse set of objects,
at varying shapes and sizes, distributed throughout the data and intricately
intertwined with the topography. Therefore, regions of interest are difficult
to find and consequent analyses become a challenge. Inspired from visual
perception principles, we propose to differentiate objects of interest from the
cluttered environment by evaluating how much they stand out from their
surroundings, i.e., their geometric salience. Previous saliency detection
approaches suggested mostly handcrafted attributes for the task. However, such
methods fail when the data are too noisy or have high levels of texture. Here
we propose a learning-based mechanism that accommodates noise and textured
surfaces. We assume that within the natural environment any change from the
prevalent surface would suggest a salient object. Thus, we first learn the
underlying surface and then search for anomalies within it. Initially, a deep
neural network is trained to reconstruct the surface. Regions where the
reconstructed part deviates significantly from the original point cloud yield a
substantial reconstruction error, signifying an anomaly, i.e., saliency. We
demonstrate the effectiveness of the proposed approach by searching for salient
features in various natural scenarios, which were acquired by different
acquisition platforms. We show the strong correlation between the
reconstruction error and salient objects.",2024-08-26,"Reuma Arav, Dennis Wittich, Franz Rottensteiner",http://arxiv.org/pdf/2408.14421v1,cs.LG
Hyperdimensional Computing Empowered Federated Foundation Model over Wireless Networks for Metaverse,"The Metaverse, a burgeoning collective virtual space merging augmented
reality and persistent virtual worlds, necessitates advanced artificial
intelligence (AI) and communication technologies to support immersive and
interactive experiences. Federated learning (FL) has emerged as a promising
technique for collaboratively training AI models while preserving data privacy.
However, FL faces challenges such as high communication overhead and
substantial computational demands, particularly for neural network (NN) models.
To address these issues, we propose an integrated federated split learning and
hyperdimensional computing (FSL-HDC) framework for emerging foundation models.
This novel approach reduces communication costs, computation load, and privacy
risks, making it particularly suitable for resource-constrained edge devices in
the Metaverse, ensuring real-time responsive interactions. Additionally, we
introduce an optimization algorithm that concurrently optimizes transmission
power and bandwidth to minimize the maximum transmission time among all users
to the server. The simulation results based on the MNIST dataset indicate that
FSL-HDC achieves an accuracy rate of approximately 87.5%, which is slightly
lower than that of FL-HDC. However, FSL-HDC exhibits a significantly faster
convergence speed, approximately 3.733x that of FSL-NN, and demonstrates
robustness to non-IID data distributions. Moreover, our proposed optimization
algorithm can reduce the maximum transmission time by up to 64% compared with
the baseline.",2024-08-26,"Yahao Ding, Wen Shang, Minrui Xu, Zhaohui Yang, Ye Hu, Dusit Niyato, Mohammad Shikh-Bahaei",http://arxiv.org/pdf/2408.14416v1,cs.LG
LoG-VMamba: Local-Global Vision Mamba for Medical Image Segmentation,"Mamba, a State Space Model (SSM), has recently shown competitive performance
to Convolutional Neural Networks (CNNs) and Transformers in Natural Language
Processing and general sequence modeling. Various attempts have been made to
adapt Mamba to Computer Vision tasks, including medical image segmentation
(MIS). Vision Mamba (VM)-based networks are particularly attractive due to
their ability to achieve global receptive fields, similar to Vision
Transformers, while also maintaining linear complexity in the number of tokens.
However, the existing VM models still struggle to maintain both spatially local
and global dependencies of tokens in high dimensional arrays due to their
sequential nature. Employing multiple and/or complicated scanning strategies is
computationally costly, which hinders applications of SSMs to high-dimensional
2D and 3D images that are common in MIS problems. In this work, we propose
Local-Global Vision Mamba, LoG-VMamba, that explicitly enforces spatially
adjacent tokens to remain nearby on the channel axis, and retains the global
context in a compressed form. Our method allows the SSMs to access the local
and global contexts even before reaching the last token while requiring only a
simple scanning strategy. Our segmentation models are computationally efficient
and substantially outperform both CNN and Transformers-based baselines on a
diverse set of 2D and 3D MIS tasks. The implementation of LoG-VMamba is
available at \url{https://github.com/Oulu-IMEDS/LoG-VMamba}.",2024-08-26,"Trung Dinh Quoc Dang, Huy Hoang Nguyen, Aleksei Tiulpin",http://arxiv.org/pdf/2408.14415v1,cs.LG
Spectrally Informed Learning of Fluid Flows,"Accurate and efficient fluid flow models are essential for applications
relating to many physical phenomena including geophysical, aerodynamic, and
biological systems. While these flows may exhibit rich and multiscale dynamics,
in many cases underlying low-rank structures exist which describe the bulk of
the motion. These structures tend to be spatially large and temporally slow,
and may contain most of the energy in a given flow. The extraction and
parsimonious representation of these low-rank dynamics from high-dimensional
data is a key challenge. Inspired by the success of physics-informed machine
learning methods, we propose a spectrally-informed approach to extract low-rank
models of fluid flows by leveraging known spectral properties in the learning
process. We incorporate this knowledge by imposing regularizations on the
learned dynamics, which bias the training process towards learning
low-frequency structures with corresponding higher power. We demonstrate the
effectiveness of this method to improve prediction and produce learned models
which better match the underlying spectral properties of prototypical fluid
flows.",2024-08-26,"Benjamin D. Shaffer, Jeremy R. Vorenberg, M. Ani Hsieh",http://arxiv.org/pdf/2408.14407v1,cs.LG
Application of Neural Ordinary Differential Equations for ITER Burning Plasma Dynamics,"The dynamics of burning plasmas in tokamaks are crucial for advancing
controlled thermonuclear fusion. This study applies the NeuralPlasmaODE, a
multi-region multi-timescale transport model, to simulate the complex energy
transfer processes in ITER deuterium-tritium (D-T) plasmas. Our model captures
the interactions between energetic alpha particles, electrons, and ions, which
are vital for understanding phenomena such as thermal runaway instability. We
employ neural ordinary differential equations (Neural ODEs) for the numerical
derivation of diffusivity parameters, enabling precise modeling of energy
interactions between different plasma regions. By leveraging transfer learning,
we utilize model parameters derived from DIII-D experimental data, enhancing
the efficiency and accuracy of our simulations without training from scratch.
Applying this model to ITER's inductive and non-inductive operational
scenarios, our results demonstrate that radiation and transport processes
effectively remove excess heat from the core plasma, preventing thermal runaway
instability. This study underscores the potential of machine learning in
advancing our understanding and control of burning plasma dynamics in fusion
reactors.",2024-08-26,"Zefang Liu, Weston M. Stacey",http://arxiv.org/pdf/2408.14404v2,cs.LG
Satellite Sunroof: High-res Digital Surface Models and Roof Segmentation for Global Solar Mapping,"The transition to renewable energy, particularly solar, is key to mitigating
climate change. Google's Solar API aids this transition by estimating solar
potential from aerial imagery, but its impact is constrained by geographical
coverage. This paper proposes expanding the API's reach using satellite
imagery, enabling global solar potential assessment. We tackle challenges
involved in building a Digital Surface Model (DSM) and roof instance
segmentation from lower resolution and single oblique views using deep learning
models. Our models, trained on aligned satellite and aerial datasets, produce
25cm DSMs and roof segments. With ~1m DSM MAE on buildings, ~5deg roof pitch
error and ~56% IOU on roof segmentation, they significantly enhance the Solar
API's potential to promote solar adoption.",2024-08-26,"Vishal Batchu, Alex Wilson, Betty Peng, Carl Elkin, Umangi Jain, Christopher Van Arsdale, Ross Goroshin, Varun Gulshan",http://arxiv.org/pdf/2408.14400v2,cs.LG
Investigating Language-Specific Calibration For Pruning Multilingual Large Language Models,"Recent advances in large language model (LLM) pruning have shown
state-of-the-art (SotA) compression results in post-training and
retraining-free settings while maintaining high predictive performance.
However, previous research mainly considered calibrating based on English text,
despite the multilingual nature of modern LLMs and their frequent use in
non-English languages. In this paper, we set out to investigate calibrating the
pruning of multilingual language models for monolingual applications. We
present the first comprehensive empirical study, comparing different
calibration languages for pruning multilingual models across diverse languages,
tasks, models, and SotA pruning techniques. Our results offer practical
suggestions, for example, calibrating in the target language can efficiently
retain the language modeling capability but does not necessarily benefit
downstream tasks. Through further analysis of latent subspaces, pruning masks,
and individual neurons within pruned models, we find that while pruning
generally preserves strong language-specific features, it may fail to retain
language-specific neuron activation patterns and subtle, language-agnostic
features associated with knowledge and reasoning that are needed for complex
tasks.",2024-08-26,"Simon Kurz, Jian-Jia Chen, Lucie Flek, Zhixue Zhao",http://arxiv.org/pdf/2408.14398v3,cs.LG
CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper Influence,"With increasing privacy concerns in artificial intelligence, regulations have
mandated the right to be forgotten, granting individuals the right to withdraw
their data from models. Machine unlearning has emerged as a potential solution
to enable selective forgetting in models, particularly in recommender systems
where historical data contains sensitive user information. Despite recent
advances in recommendation unlearning, evaluating unlearning methods
comprehensively remains challenging due to the absence of a unified evaluation
framework and overlooked aspects of deeper influence, e.g., fairness. To
address these gaps, we propose CURE4Rec, the first comprehensive benchmark for
recommendation unlearning evaluation. CURE4Rec covers four aspects, i.e.,
unlearning Completeness, recommendation Utility, unleaRning efficiency, and
recommendation fairnEss, under three data selection strategies, i.e., core
data, edge data, and random data. Specifically, we consider the deeper
influence of unlearning on recommendation fairness and robustness towards data
with varying impact levels. We construct multiple datasets with CURE4Rec
evaluation and conduct extensive experiments on existing recommendation
unlearning methods. Our code is released at
https://github.com/xiye7lai/CURE4Rec.",2024-08-26,"Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan",http://arxiv.org/pdf/2408.14393v2,cs.LG
Reprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning,"Spatio-temporal forecasting plays a crucial role in various sectors such as
transportation systems, logistics, and supply chain management. However,
existing methods are limited by their ability to handle large, complex
datasets. To overcome this limitation, we introduce a hybrid approach that
combines the strengths of open-source large and small-scale language models
(LLMs and LMs) with traditional forecasting methods. We augment traditional
methods with dynamic prompting and a grouped-query, multi-head attention
mechanism to more effectively capture both intra-series and inter-series
dependencies in evolving nonlinear time series data. In addition, we facilitate
on-premises customization by fine-tuning smaller open-source LMs for time
series trend analysis utilizing descriptions generated by open-source large LMs
on consumer-grade hardware using Low-Rank Adaptation with Activation Memory
Reduction (LoRA-AMR) technique to reduce computational overhead and activation
storage memory demands while preserving inference latency. We combine language
model processing for time series trend analysis with traditional time series
representation learning method for cross-modal integration, achieving robust
and accurate forecasts. The framework effectiveness is demonstrated through
extensive experiments on various real-world datasets, outperforming existing
methods by significant margins in terms of forecast accuracy.",2024-08-26,"Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2408.14387v1,cs.LG
Learning Tree-Structured Composition of Data Augmentation,"Data augmentation is widely used for training a neural network given little
labeled data. A common practice of augmentation training is applying a
composition of multiple transformations sequentially to the data. Existing
augmentation methods such as RandAugment randomly sample from a list of
pre-selected transformations, while methods such as AutoAugment apply advanced
search to optimize over an augmentation set of size $k^d$, which is the number
of transformation sequences of length $d$, given a list of $k$ transformations.
  In this paper, we design efficient algorithms whose running time complexity
is much faster than the worst-case complexity of $O(k^d)$, provably. We propose
a new algorithm to search for a binary tree-structured composition of $k$
transformations, where each tree node corresponds to one transformation. The
binary tree generalizes sequential augmentations, such as the SimCLR
augmentation scheme for contrastive learning. Using a top-down, recursive
search procedure, our algorithm achieves a runtime complexity of $O(2^d k)$,
which is much faster than $O(k^d)$ as $k$ increases above $2$. We apply our
algorithm to tackle data distributions with heterogeneous subpopulations by
searching for one tree in each subpopulation and then learning a weighted
combination, resulting in a forest of trees.
  We validate our proposed algorithms on numerous graph and image datasets,
including a multi-label graph classification dataset we collected. The dataset
exhibits significant variations in the sizes of graphs and their average
degrees, making it ideal for studying data augmentation. We show that our
approach can reduce the computation cost by 43% over existing search methods
while improving performance by 4.3%. The tree structures can be used to
interpret the relative importance of each transformation, such as identifying
the important transformations on small vs. large graphs.",2024-08-26,"Dongyue Li, Kailai Chen, Predrag Radivojac, Hongyang R. Zhang",http://arxiv.org/pdf/2408.14381v1,cs.LG
Adaptive Resolution Inference (ARI): Energy-Efficient Machine Learning for Internet of Things,"The implementation of machine learning in Internet of Things devices poses
significant operational challenges due to limited energy and computation
resources. In recent years, significant efforts have been made to implement
simplified ML models that can achieve reasonable performance while reducing
computation and energy, for example by pruning weights in neural networks, or
using reduced precision for the parameters and arithmetic operations. However,
this type of approach is limited by the performance of the ML implementation,
i.e., by the loss for example in accuracy due to the model simplification. In
this article, we present adaptive resolution inference (ARI), a novel approach
that enables to evaluate new tradeoffs between energy dissipation and model
performance in ML implementations. The main principle of the proposed approach
is to run inferences with reduced precision (quantization) and use the margin
over the decision threshold to determine if either the result is reliable, or
the inference must run with the full model. The rationale is that quantization
only introduces small deviations in the inference scores, such that if the
scores have a sufficient margin over the decision threshold, it is unlikely
that the full model would have a different result. Therefore, we can run the
quantized model first, and only when the scores do not have a sufficient
margin, the full model is run. This enables most inferences to run with the
reduced precision model and only a small fraction requires the full model, so
significantly reducing computation and energy while not affecting model
performance. The proposed ARI approach is presented, analyzed in detail, and
evaluated using different data sets for floating-point and stochastic computing
implementations. The results show that ARI can significantly reduce the energy
for inference in different configurations with savings between 40% and 85%.",2024-08-26,"Ziheng Wang, Pedro Reviriego, Farzad Niknia, Javier Conde, Shanshan Liu, Fabrizio Lombardi",http://arxiv.org/pdf/2408.14528v1,cs.LG
SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery,"In this paper, we address Generalized Category Discovery, aiming to
simultaneously uncover novel categories and accurately classify known ones.
Traditional methods, which lean heavily on self-supervision and contrastive
learning, often fall short when distinguishing between fine-grained categories.
To address this, we introduce a novel concept called `self-expertise', which
enhances the model's ability to recognize subtle differences and uncover
unknown categories. Our approach combines unsupervised and supervised
self-expertise strategies to refine the model's discernment and generalization.
Initially, hierarchical pseudo-labeling is used to provide `soft supervision',
improving the effectiveness of self-expertise. Our supervised technique differs
from traditional methods by utilizing more abstract positive and negative
samples, aiding in the formation of clusters that can generalize to novel
categories. Meanwhile, our unsupervised strategy encourages the model to
sharpen its category distinctions by considering within-category examples as
`hard' negatives. Supported by theoretical insights, our empirical results
showcase that our method outperforms existing state-of-the-art techniques in
Generalized Category Discovery across several fine-grained datasets. Our code
is available at: https://github.com/SarahRastegar/SelEx.",2024-08-26,"Sarah Rastegar, Mohammadreza Salehi, Yuki M. Asano, Hazel Doughty, Cees G. M. Snoek",http://arxiv.org/pdf/2408.14371v2,cs.LG
Exploiting Conjugate Label Information for Multi-Instance Partial-Label Learning,"Multi-instance partial-label learning (MIPL) addresses scenarios where each
training sample is represented as a multi-instance bag associated with a
candidate label set containing one true label and several false positives.
Existing MIPL algorithms have primarily focused on mapping multi-instance bags
to candidate label sets for disambiguation, disregarding the intrinsic
properties of the label space and the supervised information provided by
non-candidate label sets. In this paper, we propose an algorithm named ELIMIPL,
i.e., Exploiting conjugate Label Information for Multi-Instance Partial-Label
learning, which exploits the conjugate label information to improve the
disambiguation performance. To achieve this, we extract the label information
embedded in both candidate and non-candidate label sets, incorporating the
intrinsic properties of the label space. Experimental results obtained from
benchmark and real-world datasets demonstrate the superiority of the proposed
ELIMIPL over existing MIPL algorithms and other well-established partial-label
learning algorithms.",2024-08-26,"Wei Tang, Weijia Zhang, Min-Ling Zhang",http://arxiv.org/pdf/2408.14369v1,cs.LG
An Embedding is Worth a Thousand Noisy Labels,"The performance of deep neural networks scales with dataset size and label
quality, rendering the efficient mitigation of low-quality data annotations
crucial for building robust and cost-effective systems. Existing strategies to
address label noise exhibit severe limitations due to computational complexity
and application dependency. In this work, we propose WANN, a Weighted Adaptive
Nearest Neighbor approach that builds on self-supervised feature
representations obtained from foundation models. To guide the weighted voting
scheme, we introduce a reliability score $\eta$, which measures the likelihood
of a data label being correct. WANN outperforms reference methods, including a
linear layer trained with robust loss functions, on diverse datasets of varying
size and under various noise types and severities. WANN also exhibits superior
generalization on imbalanced data compared to both Adaptive-NNs (ANN) and fixed
k-NNs. Furthermore, the proposed weighting scheme enhances supervised
dimensionality reduction under noisy labels. This yields a significant boost in
classification performance with 10x and 100x smaller image embeddings,
minimizing latency and storage requirements. Our approach, emphasizing
efficiency and explainability, emerges as a simple, robust solution to overcome
inherent limitations of deep neural network training. The code is available at
https://github.com/francescodisalvo05/wann-noisy-labels .",2024-08-26,"Francesco Di Salvo, Sebastian Doerrich, Ines Rieger, Christian Ledig",http://arxiv.org/pdf/2408.14358v3,cs.LG
Assessing Contamination in Large Language Models: Introducing the LogProber method,"In machine learning, contamination refers to situations where testing data
leak into the training set. The issue is particularly relevant for the
evaluation of the performance of Large Language Models (LLMs), which are
generally trained on gargantuan, and generally opaque, corpora of text scraped
from the world wide web. Developing tools to detect contamination is therefore
crucial to be able to fairly and properly track the evolution of the
performance of LLMs. Most recent works in the field are not tailored to
quantify contamination on short sequences of text like we find in psychology
questionnaires. In the present paper we introduce LogProber, a novel,
efficient, algorithm that we show able to detect contamination using token
probability in given sentences. In the second part we investigate the
limitations of the method and discuss how different training methods can
contaminate models without leaving traces in the token probabilities.",2024-08-26,"Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri",http://arxiv.org/pdf/2408.14352v1,cs.LG
Dual Adversarial Perturbators Generate rich Views for Recommendation,"Graph contrastive learning (GCL) has been extensively studied and leveraged
as a potent tool in recommender systems. Most existing GCL-based recommenders
generate contrastive views by altering the graph structure or introducing
perturbations to embedding. While these methods effectively enhance learning
from sparse data, they risk performance degradation or even training collapse
when the differences between contrastive views become too pronounced. To
mitigate this issue, we employ curriculum learning to incrementally increase
the disparity between contrastive views, enabling the model to gain from more
challenging scenarios. In this paper, we propose a dual-adversarial graph
learning approach, AvoGCL, which emulates curriculum learning by progressively
applying adversarial training to graph structures and embedding perturbations.
Specifically, AvoGCL construct contrastive views by reducing graph redundancy
and generating adversarial perturbations in the embedding space, and achieve
better results by gradually increasing the difficulty of contrastive views.
Extensive experiments on three real-world datasets demonstrate that AvoGCL
significantly outperforms the state-of-the-art competitors.",2024-08-26,"Lijun Zhang, Yuan Yao, Haibo Ye",http://arxiv.org/pdf/2409.06719v1,cs.LG
Unsupervised Representation Learning of Complex Time Series for Maneuverability State Identification in Smart Mobility,"Multivariate Time Series (MTS) data capture temporal behaviors to provide
invaluable insights into various physical dynamic phenomena. In smart mobility,
MTS plays a crucial role in providing temporal dynamics of behaviors such as
maneuver patterns, enabling early detection of anomalous behaviors while
facilitating pro-activity in Prognostics and Health Management (PHM). In this
work, we aim to address challenges associated with modeling MTS data collected
from a vehicle using sensors. Our goal is to investigate the effectiveness of
two distinct unsupervised representation learning approaches in identifying
maneuvering states in smart mobility. Specifically, we focus on some bivariate
accelerations extracted from 2.5 years of driving, where the dataset is
non-stationary, long, noisy, and completely unlabeled, making manual labeling
impractical. The approaches of interest are Temporal Neighborhood Coding for
Maneuvering (TNC4Maneuvering) and Decoupled Local and Global Representation
learner for Maneuvering (DLG4Maneuvering).
  The main advantage of these frameworks is that they capture transferable
insights in a form of representations from the data that can be effectively
applied in multiple subsequent tasks, such as time-series classification,
clustering, and multi-linear regression, which are the quantitative measures
and qualitative measures, including visualization of representations themselves
and resulting reconstructed MTS, respectively. We compare their effectiveness,
where possible, in order to gain insights into which approach is more effective
in identifying maneuvering states in smart mobility.",2024-08-26,Thabang Lebese,http://arxiv.org/pdf/2409.06718v1,cs.LG
Foundation Models for Music: A Survey,"In recent years, foundation models (FMs) such as large language models (LLMs)
and latent diffusion models (LDMs) have profoundly impacted diverse sectors,
including music. This comprehensive review examines state-of-the-art (SOTA)
pre-trained models and foundation models in music, spanning from representation
learning, generative learning and multimodal learning. We first contextualise
the significance of music in various industries and trace the evolution of AI
in music. By delineating the modalities targeted by foundation models, we
discover many of the music representations are underexplored in FM development.
Then, emphasis is placed on the lack of versatility of previous methods on
diverse music applications, along with the potential of FMs in music
understanding, generation and medical application. By comprehensively exploring
the details of the model pre-training paradigm, architectural choices,
tokenisation, finetuning methodologies and controllability, we emphasise the
important topics that should have been well explored, like instruction tuning
and in-context learning, scaling law and emergent ability, as well as
long-sequence modelling etc. A dedicated section presents insights into music
agents, accompanied by a thorough analysis of datasets and evaluations
essential for pre-training and downstream tasks. Finally, by underscoring the
vital importance of ethical considerations, we advocate that following research
on FM for music should focus more on such issues as interpretability,
transparency, human responsibility, and copyright issues. The paper offers
insights into future challenges and trends on FMs for music, aiming to shape
the trajectory of human-AI collaboration in the music realm.",2024-08-26,"Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wenhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang",http://arxiv.org/pdf/2408.14340v3,cs.LG
Machine Learning for Quantifier Selection in cvc5,"In this work we considerably improve the state-of-the-art SMT solving on
first-order quantified problems by efficient machine learning guidance of
quantifier selection. Quantifiers represent a significant challenge for SMT and
are technically a source of undecidability. In our approach, we train an
efficient machine learning model that informs the solver which quantifiers
should be instantiated and which not. Each quantifier may be instantiated
multiple times and the set of the active quantifiers changes as the solving
progresses. Therefore, we invoke the ML predictor many times, during the whole
run of the solver. To make this efficient, we use fast ML models based on
gradient boosting decision trees. We integrate our approach into the
state-of-the-art cvc5 SMT solver and show a considerable increase of the
system's holdout-set performance after training it on a large set of
first-order problems collected from the Mizar Mathematical Library.",2024-08-26,"Jan Jakubův, Mikoláš Janota, Jelle Piepenbrock, Josef Urban",http://arxiv.org/pdf/2408.14338v1,cs.LG
One-layer transformers fail to solve the induction heads task,"A simple communication complexity argument proves that no one-layer
transformer can solve the induction heads task unless its size is exponentially
larger than the size sufficient for a two-layer transformer.",2024-08-26,"Clayton Sanford, Daniel Hsu, Matus Telgarsky",http://arxiv.org/pdf/2408.14332v1,cs.LG
Automated Machine Learning in Insurance,"Machine Learning (ML) has gained popularity in actuarial research and
insurance industrial applications. However, the performance of most ML tasks
heavily depends on data preprocessing, model selection, and hyperparameter
optimization, which are considered to be intensive in terms of domain
knowledge, experience, and manual labor. Automated Machine Learning (AutoML)
aims to automatically complete the full life-cycle of ML tasks and provides
state-of-the-art ML models without human intervention or supervision. This
paper introduces an AutoML workflow that allows users without domain knowledge
or prior experience to achieve robust and effortless ML deployment by writing
only a few lines of code. This proposed AutoML is specifically tailored for the
insurance application, with features like the balancing step in data
preprocessing, ensemble pipelines, and customized loss functions. These
features are designed to address the unique challenges of the insurance domain,
including the imbalanced nature of common insurance datasets. The full code and
documentation are available on the GitHub repository.
(https://github.com/PanyiDong/InsurAutoML)",2024-08-26,"Panyi Dong, Zhiyu Quan",http://arxiv.org/pdf/2408.14331v1,cs.LG
Streamline tractography of the fetal brain in utero with machine learning,"Diffusion-weighted magnetic resonance imaging (dMRI) is the only non-invasive
tool for studying white matter tracts and structural connectivity of the brain.
These assessments rely heavily on tractography techniques, which reconstruct
virtual streamlines representing white matter fibers. Much effort has been
devoted to improving tractography methodology for adult brains, while
tractography of the fetal brain has been largely neglected. Fetal tractography
faces unique difficulties due to low dMRI signal quality, immature and rapidly
developing brain structures, and paucity of reference data. This work presents
the first machine learning model for fetal tractography. The model input
consists of five sources of information: (1) Fiber orientation, inferred from a
diffusion tensor fit to the dMRI signal; (2) Directions of recent propagation
steps; (3) Global spatial information, encoded as distances to keypoints in the
brain cortex; (4) Tissue segmentation information; and (5) Prior information
about the expected local fiber orientations supplied with an atlas. In order to
mitigate the local tensor estimation error, a large spatial context around the
current point in the diffusion tensor image is encoded using convolutional and
attention neural network modules. Moreover, the diffusion tensor information at
a hypothetical next point is included in the model input. Filtering rules based
on anatomically constrained tractography are applied to prune implausible
streamlines. We trained the model on manually-refined whole-brain fetal
tractograms and validated the trained model on an independent set of 11 test
scans with gestational ages between 23 and 36 weeks. Results show that our
proposed method achieves superior performance across all evaluated tracts. The
new method can significantly advance the capabilities of dMRI for studying
normal and abnormal brain development in utero.",2024-08-26,"Weide Liu, Camilo Calixto, Simon K. Warfield, Davood Karimi",http://arxiv.org/pdf/2408.14326v1,cs.LG
Function-Space MCMC for Bayesian Wide Neural Networks,"Bayesian Neural Networks represent a fascinating confluence of deep learning
and probabilistic reasoning, offering a compelling framework for understanding
uncertainty in complex predictive models. In this paper, we investigate the use
of the preconditioned Crank-Nicolson algorithm and its Langevin version to
sample from a reparametrised posterior distribution of the neural network's
weights, as the widths grow larger. In addition to being robust in the
infinite-dimensional setting, we prove that the acceptance probabilities of the
proposed algorithms approach 1 as the width of the network increases,
independently of any stepsize tuning. Moreover, we examine and compare how the
mixing speeds of the underdamped Langevin Monte Carlo, the preconditioned
Crank-Nicolson and the preconditioned Crank-Nicolson Langevin samplers are
influenced by changes in the network width in some real-world cases. Our
findings suggest that, in wide Bayesian Neural Networks configurations, the
preconditioned Crank-Nicolson algorithm allows for a scalable and more
efficient sampling of the reparametrised posterior distribution, as also
evidenced by a higher effective sample size and improved diagnostic results
compared with the other analysed algorithms.",2024-08-26,"Lucia Pezzetti, Stefano Favaro, Stefano Peluchetti",http://arxiv.org/pdf/2408.14325v4,cs.LG
Rethinking Knowledge Transfer in Learning Using Privileged Information,"In supervised machine learning, privileged information (PI) is information
that is unavailable at inference, but is accessible during training time.
Research on learning using privileged information (LUPI) aims to transfer the
knowledge captured in PI onto a model that can perform inference without PI. It
seems that this extra bit of information ought to make the resulting model
better. However, finding conclusive theoretical or empirical evidence that
supports the ability to transfer knowledge using PI has been challenging. In
this paper, we critically examine the assumptions underlying existing
theoretical analyses and argue that there is little theoretical justification
for when LUPI should work. We analyze LUPI methods and reveal that apparent
improvements in empirical risk of existing research may not directly result
from PI. Instead, these improvements often stem from dataset anomalies or
modifications in model design misguidedly attributed to PI. Our experiments for
a wide variety of application domains further demonstrate that state-of-the-art
LUPI approaches fail to effectively transfer knowledge from PI. Thus, we
advocate for practitioners to exercise caution when working with PI to avoid
unintended inductive biases.",2024-08-26,"Danil Provodin, Bram van den Akker, Christina Katsimerou, Maurits Kaptein, Mykola Pechenizkiy",http://arxiv.org/pdf/2408.14319v1,cs.LG
LLM-3D Print: Large Language Models To Monitor and Control 3D Printing,"Industry 4.0 has revolutionized manufacturing by driving digitalization and
shifting the paradigm toward additive manufacturing (AM). Fused Deposition
Modeling (FDM), a key AM technology, enables the creation of highly customized,
cost-effective products with minimal material waste through layer-by-layer
extrusion, posing a significant challenge to traditional subtractive methods.
However, the susceptibility of material extrusion techniques to errors often
requires expert intervention to detect and mitigate defects that can severely
compromise product quality. While automated error detection and machine
learning models exist, their generalizability across diverse 3D printer setups,
firmware, and sensors is limited, and deep learning methods require extensive
labeled datasets, hindering scalability and adaptability. To address these
challenges, we present a process monitoring and control framework that
leverages pre-trained Large Language Models (LLMs) alongside 3D printers to
detect and address printing defects. The LLM evaluates print quality by
analyzing images captured after each layer or print segment, identifying
failure modes and querying the printer for relevant parameters. It then
generates and executes a corrective action plan. We validated the effectiveness
of the proposed framework in identifying defects by comparing it against a
control group of engineers with diverse AM expertise. Our evaluation
demonstrated that LLM-based agents not only accurately identify common 3D
printing errors, such as inconsistent extrusion, stringing, warping, and layer
adhesion, but also effectively determine the parameters causing these failures
and autonomously correct them without any need for human intervention.",2024-08-26,"Yayati Jadhav, Peter Pak, Amir Barati Farimani",http://arxiv.org/pdf/2408.14307v2,cs.LG
Resource Efficient Asynchronous Federated Learning for Digital Twin Empowered IoT Network,"As an emerging technology, digital twin (DT) can provide real-time status and
dynamic topology mapping for Internet of Things (IoT) devices. However, DT and
its implementation within industrial IoT networks necessitates substantial,
distributed data support, which often leads to ``data silos'' and raises
privacy concerns. To address these issues, we develop a dynamic resource
scheduling algorithm tailored for the asynchronous federated learning
(FL)-based lightweight DT empowered IoT network. Specifically, our approach
aims to minimize a multi-objective function that encompasses both energy
consumption and latency by optimizing IoT device selection and transmit power
control, subject to FL model performance constraints. We utilize the Lyapunov
method to decouple the formulated problem into a series of one-slot
optimization problems and develop a two-stage optimization algorithm to achieve
the optimal transmission power control and IoT device scheduling strategies. In
the first stage, we derive closed-form solutions for optimal transmit power on
the IoT device side. In the second stage, since partial state information is
unknown, e.g., the transmitting power and computational frequency of IoT
device, the edge server employs a multi-armed bandit (MAB) framework to model
the IoT device selection problem and utilizes an efficient online algorithm,
namely the client utility-based upper confidence bound (CU-UCB), to address it.
Numerical results validate our algorithm's superiority over benchmark schemes,
and simulations demonstrate that our algorithm achieves faster training speeds
on the Fashion-MNIST and CIFAR-10 datasets within the same training duration.",2024-08-26,"Shunfeng Chu, Jun Li, Jianxin Wang, Yiyang Ni, Kang Wei, Wen Chen, Shi Jin",http://arxiv.org/pdf/2408.14298v1,cs.LG
May the Forgetting Be with You: Alternate Replay for Learning with Noisy Labels,"Forgetting presents a significant challenge during incremental training,
making it particularly demanding for contemporary AI systems to assimilate new
knowledge in streaming data environments. To address this issue, most
approaches in Continual Learning (CL) rely on the replay of a restricted buffer
of past data. However, the presence of noise in real-world scenarios, where
human annotation is constrained by time limitations or where data is
automatically gathered from the web, frequently renders these strategies
vulnerable. In this study, we address the problem of CL under Noisy Labels
(CLN) by introducing Alternate Experience Replay (AER), which takes advantage
of forgetting to maintain a clear distinction between clean, complex, and noisy
samples in the memory buffer. The idea is that complex or mislabeled examples,
which hardly fit the previously learned data distribution, are most likely to
be forgotten. To grasp the benefits of such a separation, we equip AER with
Asymmetric Balanced Sampling (ABS): a new sample selection strategy that
prioritizes purity on the current task while retaining relevant samples from
the past. Through extensive computational comparisons, we demonstrate the
effectiveness of our approach in terms of both accuracy and purity of the
obtained buffer, resulting in a remarkable average gain of 4.71% points in
accuracy with respect to existing loss-based purification strategies. Code is
available at https://github.com/aimagelab/mammoth.",2024-08-26,"Monica Millunzi, Lorenzo Bonicelli, Angelo Porrello, Jacopo Credi, Petter N. Kolm, Simone Calderara",http://arxiv.org/pdf/2408.14284v1,cs.LG
Uncertainties of Latent Representations in Computer Vision,"Uncertainty quantification is a key pillar of trustworthy machine learning.
It enables safe reactions under unsafe inputs, like predicting only when the
machine learning model detects sufficient evidence, discarding anomalous data,
or emitting warnings when an error is likely to be inbound. This is
particularly crucial in safety-critical areas like medical image classification
or self-driving cars. Despite the plethora of proposed uncertainty
quantification methods achieving increasingly higher scores on performance
benchmarks, uncertainty estimates are often shied away from in practice. Many
machine learning projects start from pretrained latent representations that
come without uncertainty estimates. Uncertainties would need to be trained by
practitioners on their own, which is notoriously difficult and
resource-intense.
  This thesis makes uncertainty estimates easily accessible by adding them to
the latent representation vectors of pretrained computer vision models. Besides
proposing approaches rooted in probability and decision theory, such as
Monte-Carlo InfoNCE (MCInfoNCE) and loss prediction, we delve into both
theoretical and empirical questions. We show that these unobservable
uncertainties about unobservable latent representations are indeed provably
correct. We also provide an uncertainty-aware representation learning (URL)
benchmark to compare these unobservables against observable ground-truths.
Finally, we compile our findings to pretrain lightweight representation
uncertainties on large-scale computer vision models that transfer to unseen
datasets in a zero-shot manner.
  Our findings do not only advance the current theoretical understanding of
uncertainties over latent variables, but also facilitate the access to
uncertainty quantification for future researchers inside and outside the field,
enabling straightforward but trustworthy machine learning.",2024-08-26,Michael Kirchhof,http://arxiv.org/pdf/2408.14281v1,cs.LG
Detailed delineation of the fetal brain in diffusion MRI via multi-task learning,"Diffusion-weighted MRI is increasingly used to study the normal and abnormal
development of fetal brain in-utero. Recent studies have shown that dMRI can
offer invaluable insights into the neurodevelopmental processes in the fetal
stage. However, because of the low data quality and rapid brain development,
reliable analysis of fetal dMRI data requires dedicated computational methods
that are currently unavailable. The lack of automated methods for fast,
accurate, and reproducible data analysis has seriously limited our ability to
tap the potential of fetal brain dMRI for medical and scientific applications.
In this work, we developed and validated a unified computational framework to
(1) segment the brain tissue into white matter, cortical/subcortical gray
matter, and cerebrospinal fluid, (2) segment 31 distinct white matter tracts,
and (3) parcellate the brain's cortex and delineate the deep gray nuclei and
white matter structures into 96 anatomically meaningful regions. We utilized a
set of manual, semi-automatic, and automatic approaches to annotate 97 fetal
brains. Using these labels, we developed and validated a multi-task deep
learning method to perform the three computations. Our evaluations show that
the new method can accurately carry out all three tasks, achieving a mean Dice
similarity coefficient of 0.865 on tissue segmentation, 0.825 on white matter
tract segmentation, and 0.819 on parcellation. The proposed method can greatly
advance the field of fetal neuroimaging as it can lead to substantial
improvements in fetal brain tractography, tract-specific analysis, and
structural connectivity assessment.",2024-08-26,"Davood Karimi, Camilo Calixto, Haykel Snoussi, Maria Camila Cortes-Albornoz, Clemente Velasco-Annis, Caitlin Rollins, Camilo Jaimes, Ali Gholipour, Simon K. Warfield",http://arxiv.org/pdf/2409.06716v2,cs.LG
1-Bit FQT: Pushing the Limit of Fully Quantized Training to 1-bit,"Fully quantized training (FQT) accelerates the training of deep neural
networks by quantizing the activations, weights, and gradients into lower
precision. To explore the ultimate limit of FQT (the lowest achievable
precision), we make a first attempt to 1-bit FQT. We provide a theoretical
analysis of FQT based on Adam and SGD, revealing that the gradient variance
influences the convergence of FQT. Building on these theoretical results, we
introduce an Activation Gradient Pruning (AGP) strategy. The strategy leverages
the heterogeneity of gradients by pruning less informative gradients and
enhancing the numerical precision of remaining gradients to mitigate gradient
variance. Additionally, we propose Sample Channel joint Quantization (SCQ),
which utilizes different quantization strategies in the computation of weight
gradients and activation gradients to ensure that the method is friendly to
low-bitwidth hardware. Finally, we present a framework to deploy our algorithm.
For fine-tuning VGGNet-16 and ResNet-18 on multiple datasets, our algorithm
achieves an average accuracy improvement of approximately 6%, compared to
per-sample quantization. Moreover, our training speedup can reach a maximum of
5.13x compared to full precision training.",2024-08-26,"Chang Gao, Jianfei Chen, Kang Zhao, Jiaqi Wang, Liping Jing",http://arxiv.org/pdf/2408.14267v1,cs.LG
HyperSBINN: A Hypernetwork-Enhanced Systems Biology-Informed Neural Network for Efficient Drug Cardiosafety Assessment,"Mathematical modeling in systems toxicology enables a comprehensive
understanding of the effects of pharmaceutical substances on cardiac health.
However, the complexity of these models limits their widespread application in
early drug discovery. In this paper, we introduce a novel approach to solving
parameterized models of cardiac action potentials by combining meta-learning
techniques with Systems Biology-Informed Neural Networks (SBINNs). The proposed
method, HyperSBINN, effectively addresses the challenge of predicting the
effects of various compounds at different concentrations on cardiac action
potentials, outperforming traditional differential equation solvers in speed.
Our model efficiently handles scenarios with limited data and complex
parameterized differential equations. The HyperSBINN model demonstrates robust
performance in predicting APD90 values, indicating its potential as a reliable
tool for modeling cardiac electrophysiology and aiding in preclinical drug
development. This framework represents an advancement in computational
modeling, offering a scalable and efficient solution for simulating and
understanding complex biological systems.",2024-08-26,"Inass Soukarieh, Gerhard Hessler, Hervé Minoux, Marcel Mohr, Friedemann Schmidt, Jan Wenzel, Pierre Barbillon, Hugo Gangloff, Pierre Gloaguen",http://arxiv.org/pdf/2408.14266v1,cs.LG
Estimating Uncertainty with Implicit Quantile Network,"Uncertainty quantification is an important part of many performance critical
applications. This paper provides a simple alternative to existing approaches
such as ensemble learning and bayesian neural networks. By directly modeling
the loss distribution with an Implicit Quantile Network, we get an estimate of
how uncertain the model is of its predictions. For experiments with MNIST and
CIFAR datasets, the mean of the estimated loss distribution is 2x higher for
incorrect predictions. When data with high estimated uncertainty is removed
from the test dataset, the accuracy of the model goes up as much as 10%. This
method is simple to implement while offering important information to
applications where the user has to know when the model could be wrong (e.g.
deep learning for healthcare).",2024-08-26,Yi Hung Lim,http://arxiv.org/pdf/2408.14525v1,cs.LG
Towards Sustainable Personalized On-Device Human Activity Recognition with TinyML and Cloud-Enabled Auto Deployment,"Human activity recognition (HAR) holds immense potential for transforming
health and fitness monitoring, yet challenges persist in achieving personalized
outcomes and sustainability for on-device continuous inferences. This work
introduces a wrist-worn smart band designed to address these challenges through
a novel combination of on-device TinyML-driven computing and cloud-enabled
auto-deployment. Leveraging inertial measurement unit (IMU) sensors and a
customized 1D Convolutional Neural Network (CNN) for personalized HAR, users
can tailor activity classes to their unique movement styles with minimal
calibration. By utilising TinyML for local computations, the smart band reduces
the necessity for constant data transmission and radio communication, which in
turn lowers power consumption and reduces carbon footprint. This method also
enhances the privacy and security of user data by limiting its transmission.
Through transfer learning and fine-tuning on user-specific data, the system
achieves a 37\% increase in accuracy over generalized models in personalized
settings. Evaluation using three benchmark datasets, WISDM, PAMAP2, and the
BandX demonstrates its effectiveness across various activity domains.
Additionally, this work presents a cloud-supported framework for the automatic
deployment of TinyML models to remote wearables, enabling seamless
customization and on-device inference, even with limited target data. By
combining personalized HAR with sustainable strategies for on-device continuous
inferences, this system represents a promising step towards fostering healthier
and more sustainable societies worldwide.",2024-08-26,"Bidyut Saha, Riya Samanta, Soumya K Ghosh, Ram Babu Roy",http://arxiv.org/pdf/2409.00093v1,cs.LG
"Integrated Brain Connectivity Analysis with fMRI, DTI, and sMRI Powered by Interpretable Graph Neural Networks","Multimodal neuroimaging modeling has becomes a widely used approach but
confronts considerable challenges due to heterogeneity, which encompasses
variability in data types, scales, and formats across modalities. This
variability necessitates the deployment of advanced computational methods to
integrate and interpret these diverse datasets within a cohesive analytical
framework. In our research, we amalgamate functional magnetic resonance
imaging, diffusion tensor imaging, and structural MRI into a cohesive
framework. This integration capitalizes on the unique strengths of each
modality and their inherent interconnections, aiming for a comprehensive
understanding of the brain's connectivity and anatomical characteristics.
Utilizing the Glasser atlas for parcellation, we integrate imaging derived
features from various modalities: functional connectivity from fMRI, structural
connectivity from DTI, and anatomical features from sMRI within consistent
regions. Our approach incorporates a masking strategy to differentially weight
neural connections, thereby facilitating a holistic amalgamation of multimodal
imaging data. This technique enhances interpretability at connectivity level,
transcending traditional analyses centered on singular regional attributes. The
model is applied to the Human Connectome Project's Development study to
elucidate the associations between multimodal imaging and cognitive functions
throughout youth. The analysis demonstrates improved predictive accuracy and
uncovers crucial anatomical features and essential neural connections,
deepening our understanding of brain structure and function.",2024-08-26,"Gang Qu, Ziyu Zhou, Vince D. Calhoun, Aiying Zhang, Yu-Ping Wang",http://arxiv.org/pdf/2408.14254v2,cs.LG
An Evaluation of Explanation Methods for Black-Box Detectors of Machine-Generated Text,"The increasing difficulty to distinguish language-model-generated from
human-written text has led to the development of detectors of machine-generated
text (MGT). However, in many contexts, a black-box prediction is not
sufficient, it is equally important to know on what grounds a detector made
that prediction. Explanation methods that estimate feature importance promise
to provide indications of which parts of an input are used by classifiers for
prediction. However, the quality of different explanation methods has not
previously been assessed for detectors of MGT. This study conducts the first
systematic evaluation of explanation quality for this task. The dimensions of
faithfulness and stability are assessed with five automated experiments, and
usefulness is evaluated in a user study. We use a dataset of ChatGPT-generated
and human-written documents, and pair predictions of three existing
language-model-based detectors with the corresponding SHAP, LIME, and Anchor
explanations. We find that SHAP performs best in terms of faithfulness,
stability, and in helping users to predict the detector's behavior. In
contrast, LIME, perceived as most useful by users, scores the worst in terms of
user performance at predicting the detectors' behavior.",2024-08-26,"Loris Schoenegger, Yuxi Xia, Benjamin Roth",http://arxiv.org/pdf/2408.14252v1,cs.LG
Scalable Multivariate Fronthaul Quantization for Cell-Free Massive MIMO,"The conventional approach to the fronthaul design for cell-free massive MIMO
system follows the compress-and-precode (CP) paradigm. Accordingly, encoded
bits and precoding coefficients are shared by the distributed unit (DU) on the
fronthaul links, and precoding takes place at the radio units (RUs). Previous
theoretical work has shown that CP can be potentially improved by a significant
margin by precode-and-compress (PC) methods, in which all baseband processing
is carried out at the DU, which compresses the precoded signals for
transmission on the fronthaul links. The theoretical performance gain of PC
methods are particularly pronounced when the DU implements multivariate
quantization (MQ), applying joint quantization across the signals for all the
RUs. However, existing solutions for MQ are characterized by a computational
complexity that grows exponentially with the sum-fronthaul capacity from the DU
to all RUs. This work sets out to design scalable MQ strategies for PC-based
cell-free massive MIMO systems. For the low-fronthaul capacity regime, we
present alpha-parallel MQ (alpha-PMQ), whose complexity is exponential only in
the fronthaul capacity towards an individual RU, while performing close to full
MQ. alpha-PMQ tailors MQ to the topology of the network by allowing for
parallel local quantization steps for RUs that do not interfere too much with
each other. For the high-fronthaul capacity regime, we then introduce neural
MQ, which replaces the exhaustive search in MQ with gradient-based updates for
a neural-network-based decoder, attaining a complexity that grows linearly with
the sum-fronthaul capacity. Numerical results demonstrate that the proposed
scalable MQ strategies outperform CP for both the low and high-fronthaul
capacity regimes at the cost of increased computational complexity at the DU
(but not at the RUs).",2024-08-26,"Sangwoo Park, Ahmet Hasim Gokceoglu, Li Wang, Osvaldo Simeone",http://arxiv.org/pdf/2409.06715v1,cs.LG
DSTI at LLMs4OL 2024 Task A: Intrinsic versus extrinsic knowledge for type classification,"We introduce semantic towers, an extrinsic knowledge representation method,
and compare it to intrinsic knowledge in large language models for ontology
learning. Our experiments show a trade-off between performance and semantic
grounding for extrinsic knowledge compared to a fine-tuned model intrinsic
knowledge. We report our findings on the Large Language Models for Ontology
Learning (LLMs4OL) 2024 challenge.",2024-08-26,Hanna Abi Akl,http://arxiv.org/pdf/2408.14236v1,cs.LG
FSDEM: Feature Selection Dynamic Evaluation Metric,"Expressive evaluation metrics are indispensable for informative experiments
in all areas, and while several metrics are established in some areas, in
others, such as feature selection, only indirect or otherwise limited
evaluation metrics are found. In this paper, we propose a novel evaluation
metric to address several problems of its predecessors and allow for flexible
and reliable evaluation of feature selection algorithms. The proposed metric is
a dynamic metric with two properties that can be used to evaluate both the
performance and the stability of a feature selection algorithm. We conduct
several empirical experiments to illustrate the use of the proposed metric in
the successful evaluation of feature selection algorithms. We also provide a
comparison and analysis to show the different aspects involved in the
evaluation of the feature selection algorithms. The results indicate that the
proposed metric is successful in carrying out the evaluation task for feature
selection algorithms.
  This paper is an extended version of a paper published at SISAP 2024.",2024-08-26,"Muhammad Rajabinasab, Anton D. Lautrup, Tobias Hyrup, Arthur Zimek",http://arxiv.org/pdf/2408.14234v3,cs.LG
A Dual-Path neural network model to construct the flame nonlinear thermoacoustic response in the time domain,"Traditional numerical simulation methods require substantial computational
resources to accurately determine the complete nonlinear thermoacoustic
response of flames to various perturbation frequencies and amplitudes. In this
paper, we have developed deep learning algorithms that can construct a
comprehensive flame nonlinear response from limited numerical simulation data.
To achieve this, we propose using a frequency-sweeping data type as the
training dataset, which incorporates a rich array of learnable information
within a constrained dataset. To enhance the precision in learning flame
nonlinear response patterns from the training data, we introduce a Dual-Path
neural network. This network consists of a Chronological Feature Path and a
Temporal Detail Feature Path. The Dual-Path network is specifically designed to
focus intensively on the temporal characteristics of velocity perturbation
sequences, yielding more accurate flame response patterns and enhanced
generalization capabilities. Validations confirm that our approach can
accurately model flame nonlinear responses, even under conditions of
significant nonlinearity, and exhibits robust generalization capabilities
across various test scenarios.",2024-08-26,"Jiawei Wu, Teng Wang, Jiaqi Nan, Lijun Yang, Jingxuan Li",http://arxiv.org/pdf/2409.05885v1,cs.LG
Gallery-Aware Uncertainty Estimation For Open-Set Face Recognition,"Accurately estimating image quality and model robustness improvement are
critical challenges in unconstrained face recognition, which can be addressed
through uncertainty estimation via probabilistic face embeddings. Previous
research mainly focused on uncertainty estimation in face verification, leaving
the open-set face recognition task underexplored. In open-set face recognition,
one seeks to classify an image, which could also be unknown. Here, the low
variance of probabilistic embedding does not imply a low error probability: an
image embedding could be close to several classes in a gallery, thus yielding
high uncertainty. We propose a method aware of two sources of ambiguity in the
open-set recognition system: (1) the gallery uncertainty caused by overlapping
classes and (2) the uncertainty of the face embeddings. To detect both types,
we use a Bayesian probabilistic model of embedding distribution, which provides
a principled uncertainty estimate. Challenging open-set face recognition
datasets, such as IJB-C, serve as a testbed for our method. We also propose a
new open-set recognition protocol for whale and dolphin identification. The
proposed approach better identifies recognition errors than uncertainty
estimation methods based solely on image quality.",2024-08-26,"Leonid Erlygin, Alexey Zaytsev",http://arxiv.org/pdf/2408.14229v1,cs.LG
Provable Imbalanced Point Clustering,"We suggest efficient and provable methods to compute an approximation for
imbalanced point clustering, that is, fitting $k$-centers to a set of points in
$\mathbb{R}^d$, for any $d,k\geq 1$. To this end, we utilize \emph{coresets},
which, in the context of the paper, are essentially weighted sets of points in
$\mathbb{R}^d$ that approximate the fitting loss for every model in a given
set, up to a multiplicative factor of $1\pm\varepsilon$. We provide [Section 3
and Section E in the appendix] experiments that show the empirical contribution
of our suggested methods for real images (novel and reference), synthetic data,
and real-world data. We also propose choice clustering, which by combining
clustering algorithms yields better performance than each one separately.",2024-08-26,"David Denisov, Dan Feldman, Shlomi Dolev, Michael Segal",http://arxiv.org/pdf/2408.14225v2,cs.LG
Integrating the Expected Future in Load Forecasts with Contextually Enhanced Transformer Models,"Accurate and reliable energy forecasting is essential for power grid
operators who strive to minimize extreme forecasting errors that pose
significant operational challenges and incur high intra-day trading costs.
Incorporating planning information -- such as anticipated user behavior,
scheduled events or timetables -- provides substantial contextual information
to enhance forecast accuracy and reduce the occurrence of large forecasting
errors. Existing approaches, however, lack the flexibility to effectively
integrate both dynamic, forward-looking contextual inputs and historical data.
In this work, we conceptualize forecasting as a combined forecasting-regression
task, formulated as a sequence-to-sequence prediction problem, and introduce
contextually-enhanced transformer models designed to leverage all contextual
information effectively. We demonstrate the effectiveness of our approach
through a primary case study on nationwide railway energy consumption
forecasting, where integrating contextual information into transformer models,
particularly timetable data, resulted in a significant average mean absolute
error reduction of 26.6%. An auxiliary case study on building energy
forecasting, leveraging planned office occupancy data, further illustrates the
generalizability of our method, showing an average reduction of 56.3% in mean
absolute error. Compared to other state-of-the-art methods, our approach
consistently outperforms existing models, underscoring the value of
context-aware deep learning techniques in energy forecasting applications.",2024-08-26,"Raffael Theiler, Leandro Von Krannichfeldt, Giovanni Sansavini, Michael F. Howland, Olga Fink",http://arxiv.org/pdf/2409.05884v2,cs.LG
Lemon and Orange Disease Classification using CNN-Extracted Features and Machine Learning Classifier,"Lemons and oranges, both are the most economically significant citrus fruits
globally. The production of lemons and oranges is severely affected due to
diseases in its growth stages. Fruit quality has degraded due to the presence
of flaws. Thus, it is necessary to diagnose the disease accurately so that we
can avoid major loss of lemons and oranges. To improve citrus farming, we
proposed a disease classification approach for lemons and oranges. This
approach would enable early disease detection and intervention, reduce yield
losses, and optimize resource allocation. For the initial modeling of disease
classification, the research uses innovative deep learning architectures such
as VGG16, VGG19 and ResNet50. In addition, for achieving better accuracy, the
basic machine learning algorithms used for classification problems include
Random Forest, Naive Bayes, K-Nearest Neighbors (KNN) and Logistic Regression.
The lemon and orange fruits diseases are classified more accurately (95.0% for
lemon and 99.69% for orange) by the model. The model's base features were
extracted from the ResNet50 pre-trained model and the diseases are classified
by the Logistic Regression which beats the performance given by VGG16 and VGG19
for other classifiers. Experimental outcomes show that the proposed model also
outperforms existing models in which most of them classified the diseases using
the Softmax classifier without using any individual classifiers.",2024-08-26,"Khandoker Nosiba Arifin, Sayma Akter Rupa, Md Musfique Anwar, Israt Jahan",http://arxiv.org/pdf/2408.14206v2,cs.LG
Representative Arm Identification: A fixed confidence approach to identify cluster representatives,"We study the representative arm identification (RAI) problem in the
multi-armed bandits (MAB) framework, wherein we have a collection of arms, each
associated with an unknown reward distribution. An underlying instance is
defined by a partitioning of the arms into clusters of predefined sizes, such
that for any $j > i$, all arms in cluster $i$ have a larger mean reward than
those in cluster $j$. The goal in RAI is to reliably identify a certain
prespecified number of arms from each cluster, while using as few arm pulls as
possible. The RAI problem covers as special cases several well-studied MAB
problems such as identifying the best arm or any $M$ out of the top $K$, as
well as both full and coarse ranking. We start by providing an
instance-dependent lower bound on the sample complexity of any feasible
algorithm for this setting. We then propose two algorithms, based on the idea
of confidence intervals, and provide high probability upper bounds on their
sample complexity, which orderwise match the lower bound. Finally, we do an
empirical comparison of both algorithms along with an LUCB-type alternative on
both synthetic and real-world datasets, and demonstrate the superior
performance of our proposed schemes in most cases.",2024-08-26,"Sarvesh Gharat, Aniket Yadav, Nikhil Karamchandani, Jayakrishnan Nair",http://arxiv.org/pdf/2408.14195v1,cs.LG
Robot Navigation with Entity-Based Collision Avoidance using Deep Reinforcement Learning,"Efficient navigation in dynamic environments is crucial for autonomous robots
interacting with various environmental entities, including both moving agents
and static obstacles. In this study, we present a novel methodology that
enhances the robot's interaction with different types of agents and obstacles
based on specific safety requirements. This approach uses information about the
entity types, improving collision avoidance and ensuring safer navigation. We
introduce a new reward function that penalizes the robot for collisions with
different entities such as adults, bicyclists, children, and static obstacles,
and additionally encourages the robot's proximity to the goal. It also
penalizes the robot for being close to entities, and the safe distance also
depends on the entity type. Additionally, we propose an optimized algorithm for
training and testing, which significantly accelerates train, validation, and
test steps and enables training in complex environments. Comprehensive
experiments conducted using simulation demonstrate that our approach
consistently outperforms conventional navigation and collision avoidance
methods, including state-of-the-art techniques. To sum up, this work
contributes to enhancing the safety and efficiency of navigation systems for
autonomous robots in dynamic, crowded environments.",2024-08-26,"Yury Kolomeytsev, Dmitry Golembiovsky",http://arxiv.org/pdf/2408.14183v1,cs.LG
MONAS: Efficient Zero-Shot Neural Architecture Search for MCUs,"Neural Architecture Search (NAS) has proven effective in discovering new
Convolutional Neural Network (CNN) architectures, particularly for scenarios
with well-defined accuracy optimization goals. However, previous approaches
often involve time-consuming training on super networks or intensive
architecture sampling and evaluations. Although various zero-cost proxies
correlated with CNN model accuracy have been proposed for efficient
architecture search without training, their lack of hardware consideration
makes it challenging to target highly resource-constrained edge devices such as
microcontroller units (MCUs). To address these challenges, we introduce MONAS,
a novel hardware-aware zero-shot NAS framework specifically designed for MCUs
in edge computing. MONAS incorporates hardware optimality considerations into
the search process through our proposed MCU hardware latency estimation model.
By combining this with specialized performance indicators (proxies), MONAS
identifies optimal neural architectures without incurring heavy training and
evaluation costs, optimizing for both hardware latency and accuracy under
resource constraints. MONAS achieves up to a 1104x improvement in search
efficiency over previous work targeting MCUs and can discover CNN models with
over 3.23x faster inference on MCUs while maintaining similar accuracy compared
to more general NAS approaches.",2024-08-26,"Ye Qiao, Haocheng Xu, Yifan Zhang, Sitao Huang",http://arxiv.org/pdf/2408.15034v1,cs.LG
Application of Disentanglement to Map Registration Problem,"Geospatial data come from various sources, such as satellites, aircraft, and
LiDAR. The variability of the source is not limited to the types of data
acquisition techniques, as we have maps from different time periods. To
incorporate these data for a coherent analysis, it is essential to first align
different ""styles"" of geospatial data to its matching images that point to the
same location on the surface of the Earth. In this paper, we approach the image
registration as a two-step process of (1) extracting geospatial contents
invariant to visual (and any other non-content-related) information, and (2)
matching the data based on such (purely) geospatial contents. We hypothesize
that a combination of $\beta$-VAE-like architecture [2] and adversarial
training will achieve both the disentanglement of the geographic information
and artistic styles and generation of new map tiles by composing the encoded
geographic information with any artistic style.",2024-08-26,"Hae Jin Song, Patrycja Krawczuk, Po-Hsuan Huang",http://arxiv.org/pdf/2408.14152v1,cs.LG
TSAK: Two-Stage Semantic-Aware Knowledge Distillation for Efficient Wearable Modality and Model Optimization in Manufacturing Lines,"Smaller machine learning models, with less complex architectures and sensor
inputs, can benefit wearable sensor-based human activity recognition (HAR)
systems in many ways, from complexity and cost to battery life. In the specific
case of smart factories, optimizing human-robot collaboration hinges on the
implementation of cutting-edge, human-centric AI systems. To this end, workers'
activity recognition enables accurate quantification of performance metrics,
improving efficiency holistically. We present a two-stage semantic-aware
knowledge distillation (KD) approach, TSAK, for efficient, privacy-aware, and
wearable HAR in manufacturing lines, which reduces the input sensor modalities
as well as the machine learning model size, while reaching similar recognition
performance as a larger multi-modal and multi-positional teacher model. The
first stage incorporates a teacher classifier model encoding attention, causal,
and combined representations. The second stage encompasses a semantic
classifier merging the three representations from the first stage. To evaluate
TSAK, we recorded a multi-modal dataset at a smart factory testbed with
wearable and privacy-aware sensors (IMU and capacitive) located on both
workers' hands. In addition, we evaluated our approach on OpenPack, the only
available open dataset mimicking the wearable sensor placements on both hands
in the manufacturing HAR scenario. We compared several KD strategies with
different representations to regulate the training process of a smaller student
model. Compared to the larger teacher model, the student model takes fewer
sensor channels from a single hand, has 79% fewer parameters, runs 8.88 times
faster, and requires 96.6% less computing power (FLOPS).",2024-08-26,"Hymalai Bello, Daniel Geißler, Sungho Suh, Bo Zhou, Paul Lukowicz",http://arxiv.org/pdf/2408.14146v1,cs.LG
Neighborhood and Global Perturbations Supported SAM in Federated Learning: From Local Tweaks To Global Awareness,"Federated Learning (FL) can be coordinated under the orchestration of a
central server to collaboratively build a privacy-preserving model without the
need for data exchange. However, participant data heterogeneity leads to local
optima divergence, subsequently affecting convergence outcomes. Recent research
has focused on global sharpness-aware minimization (SAM) and dynamic
regularization techniques to enhance consistency between global and local
generalization and optimization objectives. Nonetheless, the estimation of
global SAM introduces additional computational and memory overhead, while
dynamic regularization suffers from bias in the local and global dual variables
due to training isolation. In this paper, we propose a novel FL algorithm,
FedTOGA, designed to consider optimization and generalization objectives while
maintaining minimal uplink communication overhead. By linking local
perturbations to global updates, global generalization consistency is improved.
Additionally, global updates are used to correct local dynamic regularizers,
reducing dual variables bias and enhancing optimization consistency. Global
updates are passively received by clients, reducing overhead. We also propose
neighborhood perturbation to approximate local perturbation, analyzing its
strengths and limitations. Theoretical analysis shows FedTOGA achieves faster
convergence $O(1/T)$ under non-convex functions. Empirical studies demonstrate
that FedTOGA outperforms state-of-the-art algorithms, with a 1\% accuracy
increase and 30\% faster convergence, achieving state-of-the-art.",2024-08-26,"Boyuan Li, Zihao Peng, Yafei Li, Mingliang Xu, Shengbo Chen, Baofeng Ji, Cong Shen",http://arxiv.org/pdf/2408.14144v2,cs.LG
2D-Malafide: Adversarial Attacks Against Face Deepfake Detection Systems,"We introduce 2D-Malafide, a novel and lightweight adversarial attack designed
to deceive face deepfake detection systems. Building upon the concept of 1D
convolutional perturbations explored in the speech domain, our method leverages
2D convolutional filters to craft perturbations which significantly degrade the
performance of state-of-the-art face deepfake detectors. Unlike traditional
additive noise approaches, 2D-Malafide optimises a small number of filter
coefficients to generate robust adversarial perturbations which are
transferable across different face images. Experiments, conducted using the
FaceForensics++ dataset, demonstrate that 2D-Malafide substantially degrades
detection performance in both white-box and black-box settings, with larger
filter sizes having the greatest impact. Additionally, we report an
explainability analysis using GradCAM which illustrates how 2D-Malafide
misleads detection systems by altering the image areas used most for
classification. Our findings highlight the vulnerability of current deepfake
detection systems to convolutional adversarial attacks as well as the need for
future work to enhance detection robustness through improved image fidelity
constraints.",2024-08-26,"Chiara Galdi, Michele Panariello, Massimiliano Todisco, Nicholas Evans",http://arxiv.org/pdf/2408.14143v1,cs.LG
Exploring the Potential of Large Language Models for Heterophilic Graphs,"Large language models (LLMs) have presented significant opportunities to
enhance various machine learning applications, including graph neural networks
(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more
effectively interpret and utilize textual data to better characterize
heterophilic graphs, where neighboring nodes often have different labels.
However, existing approaches for heterophilic graphs overlook the rich textual
data associated with nodes, which could unlock deeper insights into their
heterophilic contexts. In this work, we explore the potential of LLMs for
modeling heterophilic graphs and propose a novel two-stage framework:
LLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first
stage, we fine-tune the LLM to better identify homophilic and heterophilic
edges based on the textual content of their nodes. In the second stage, we
adaptively manage message propagation in GNNs for different edge types based on
node features, structures, and heterophilic or homophilic characteristics. To
cope with the computational demands when deploying LLMs in practical scenarios,
we further explore model distillation techniques to fine-tune smaller, more
efficient models that maintain competitive performance. Extensive experiments
validate the effectiveness of our framework, demonstrating the feasibility of
using LLMs to enhance node classification on heterophilic graphs.",2024-08-26,"Yuxia Wu, Shujie Li, Yuan Fang, Chuan Shi",http://arxiv.org/pdf/2408.14134v3,cs.LG
Theoretical Proportion Label Perturbation for Learning from Label Proportions in Large Bags,"Learning from label proportions (LLP) is a kind of weakly supervised learning
that trains an instance-level classifier from label proportions of bags, which
consist of sets of instances without using instance labels. A challenge in LLP
arises when the number of instances in a bag (bag size) is numerous, making the
traditional LLP methods difficult due to GPU memory limitations. This study
aims to develop an LLP method capable of learning from bags with large sizes.
In our method, smaller bags (mini-bags) are generated by sampling instances
from large-sized bags (original bags), and these mini-bags are used in place of
the original bags. However, the proportion of a mini-bag is unknown and differs
from that of the original bag, leading to overfitting. To address this issue,
we propose a perturbation method for the proportion labels of sampled mini-bags
to mitigate overfitting to noisy label proportions. This perturbation is added
based on the multivariate hypergeometric distribution, which is statistically
modeled. Additionally, loss weighting is implemented to reduce the negative
impact of proportions sampled from the tail of the distribution. Experimental
results demonstrate that the proportion label perturbation and loss weighting
achieve classification accuracy comparable to that obtained without sampling.
Our codes are available at https://github.com/stainlessnight/LLP-LargeBags.",2024-08-26,"Shunsuke Kubo, Shinnosuke Matsuo, Daiki Suehiro, Kazuhiro Terada, Hiroaki Ito, Akihiko Yoshizawa, Ryoma Bise",http://arxiv.org/pdf/2408.14130v1,cs.LG
Retrieval Augmented Generation for Dynamic Graph Modeling,"Modeling dynamic graphs, such as those found in social networks,
recommendation systems, and e-commerce platforms, is crucial for capturing
evolving relationships and delivering relevant insights over time. Traditional
approaches primarily rely on graph neural networks with temporal components or
sequence generation models, which often focus narrowly on the historical
context of target nodes. This limitation restricts the ability to adapt to new
and emerging patterns in dynamic graphs. To address this challenge, we propose
a novel framework, Retrieval-Augmented Generation for Dynamic Graph modeling
(RAG4DyG), which enhances dynamic graph predictions by incorporating
contextually and temporally relevant examples from broader graph structures.
Our approach includes a time- and context-aware contrastive learning module to
identify high-quality demonstrations and a graph fusion strategy to effectively
integrate these examples with historical contexts. The proposed framework is
designed to be effective in both transductive and inductive scenarios, ensuring
adaptability to previously unseen nodes and evolving graph structures.
Extensive experiments across multiple real-world datasets demonstrate the
effectiveness of RAG4DyG in improving predictive accuracy and adaptability for
dynamic graph modeling. The code and datasets are publicly available at
https://github.com/YuxiaWu/RAG4DyG.",2024-08-26,"Yuxia Wu, Lizi Liao, Yuan Fang",http://arxiv.org/pdf/2408.14523v2,cs.LG
Enhancing Fairness through Reweighting: A Path to Attain the Sufficiency Rule,"We introduce an innovative approach to enhancing the empirical risk
minimization (ERM) process in model training through a refined reweighting
scheme of the training data to enhance fairness. This scheme aims to uphold the
sufficiency rule in fairness by ensuring that optimal predictors maintain
consistency across diverse sub-groups. We employ a bilevel formulation to
address this challenge, wherein we explore sample reweighting strategies.
Unlike conventional methods that hinge on model size, our formulation bases
generalization complexity on the space of sample weights. We discretize the
weights to improve training speed. Empirical validation of our method showcases
its effectiveness and robustness, revealing a consistent improvement in the
balance between prediction performance and fairness metrics across various
experiments.",2024-08-26,"Xuan Zhao, Klaus Broelemann, Salvatore Ruggieri, Gjergji Kasneci",http://arxiv.org/pdf/2408.14126v2,cs.LG
Towards Lifelong Learning Embeddings: An Algorithmic Approach to Dynamically Extend Embeddings,"The rapid evolution of technology has transformed business operations and
customer interactions worldwide, with personalization emerging as a key
opportunity for e-commerce companies to engage customers more effectively. The
application of machine learning, particularly that of deep learning models, has
gained significant traction due to its ability to rapidly recognize patterns in
large datasets, thereby offering numerous possibilities for personalization.
These models use embeddings to map discrete information, such as product IDs,
into a latent vector space, a method increasingly popular in recent years.
However, e-commerce's dynamic nature, characterized by frequent new product
introductions, poses challenges for these embeddings, which typically require
fixed dimensions and inputs, leading to the need for periodic retraining from
scratch. This paper introduces a modular algorithm that extends embedding input
size while preserving learned knowledge, addressing the challenges posed by
e-commerce's dynamism. The proposed algorithm also incorporates strategies to
mitigate the cold start problem associated with new products. The results of
initial experiments suggest that this method outperforms traditional
embeddings.",2024-08-26,"Miguel Alves Gomes, Philipp Meisen, Tobias Meisen",http://arxiv.org/pdf/2408.14118v1,cs.LG
Hierarchical Learning and Computing over Space-Ground Integrated Networks,"Space-ground integrated networks hold great promise for providing global
connectivity, particularly in remote areas where large amounts of valuable data
are generated by Internet of Things (IoT) devices, but lacking terrestrial
communication infrastructure. The massive data is conventionally transferred to
the cloud server for centralized artificial intelligence (AI) models training,
raising huge communication overhead and privacy concerns. To address this, we
propose a hierarchical learning and computing framework, which leverages the
lowlatency characteristic of low-earth-orbit (LEO) satellites and the global
coverage of geostationary-earth-orbit (GEO) satellites, to provide global
aggregation services for locally trained models on ground IoT devices. Due to
the time-varying nature of satellite network topology and the energy
constraints of LEO satellites, efficiently aggregating the received local
models from ground devices on LEO satellites is highly challenging. By
leveraging the predictability of inter-satellite connectivity, modeling the
space network as a directed graph, we formulate a network energy minimization
problem for model aggregation, which turns out to be a Directed Steiner Tree
(DST) problem. We propose a topologyaware energy-efficient routing (TAEER)
algorithm to solve the DST problem by finding a minimum spanning arborescence
on a substitute directed graph. Extensive simulations under realworld
space-ground integrated network settings demonstrate that the proposed TAEER
algorithm significantly reduces energy consumption and outperforms benchmarks.",2024-08-26,"Jingyang Zhu, Yuanming Shi, Yong Zhou, Chunxiao Jiang, Linling Kuang",http://arxiv.org/pdf/2408.14116v2,cs.LG
Estimating Causal Effects from Learned Causal Networks,"The standard approach to answering an identifiable causal-effect query (e.g.,
$P(Y|do(X)$) when given a causal diagram and observational data is to first
generate an estimand, or probabilistic expression over the observable
variables, which is then evaluated using the observational data. In this paper,
we propose an alternative paradigm for answering causal-effect queries over
discrete observable variables. We propose to instead learn the causal Bayesian
network and its confounding latent variables directly from the observational
data. Then, efficient probabilistic graphical model (PGM) algorithms can be
applied to the learned model to answer queries. Perhaps surprisingly, we show
that this \emph{model completion} learning approach can be more effective than
estimand approaches, particularly for larger models in which the estimand
expressions become computationally difficult.
  We illustrate our method's potential using a benchmark collection of Bayesian
networks and synthetically generated causal models.",2024-08-26,"Anna Raichev, Alexander Ihler, Jin Tian, Rina Dechter",http://arxiv.org/pdf/2408.14101v2,cs.LG
Classification of Safety Events at Nuclear Sites using Large Language Models,"This paper proposes the development of a Large Language Model (LLM) based
machine learning classifier designed to categorize Station Condition Records
(SCRs) at nuclear power stations into safety-related and non-safety-related
categories. The primary objective is to augment the existing manual review
process by enhancing the efficiency and accuracy of the safety classification
process at nuclear stations. The paper discusses experiments performed to
classify a labeled SCR dataset and evaluates the performance of the classifier.
It explores the construction of several prompt variations and their observed
effects on the LLM's decision-making process. Additionally, it introduces a
numerical scoring mechanism that could offer a more nuanced and flexible
approach to SCR safety classification. This method represents an innovative
step in nuclear safety management, providing a scalable tool for the
identification of safety events.",2024-08-26,"Mishca de Costa, Muhammad Anwar, Daniel Lau, Issam Hammad",http://arxiv.org/pdf/2409.00091v1,cs.LG
ReLExS: Reinforcement Learning Explanations for Stackelberg No-Regret Learners,"With the constraint of a no regret follower, will the players in a two-player
Stackelberg game still reach Stackelberg equilibrium? We first show when the
follower strategy is either reward-average or transform-reward-average, the two
players can always get the Stackelberg Equilibrium. Then, we extend that the
players can achieve the Stackelberg equilibrium in the two-player game under
the no regret constraint. Also, we show a strict upper bound of the follower's
utility difference between with and without no regret constraint. Moreover, in
constant-sum two-player Stackelberg games with non-regret action sequences, we
ensure the total optimal utility of the game remains also bounded.",2024-08-26,"Xiangge Huang, Jingyuan Li, Jiaqing Xie",http://arxiv.org/pdf/2408.14086v1,cs.LG
SONICS: Synthetic Or Not -- Identifying Counterfeit Songs,"The recent surge in AI-generated songs presents exciting possibilities and
challenges. These innovations necessitate the ability to distinguish between
human-composed and synthetic songs to safeguard artistic integrity and protect
human musical artistry. Existing research and datasets in fake song detection
only focus on singing voice deepfake detection (SVDD), where the vocals are
AI-generated but the instrumental music is sourced from real songs. However,
these approaches are inadequate for detecting contemporary end-to-end
artificial songs where all components (vocals, music, lyrics, and style) could
be AI-generated. Additionally, existing datasets lack music-lyrics diversity,
long-duration songs, and open-access fake songs. To address these gaps, we
introduce SONICS, a novel dataset for end-to-end Synthetic Song Detection
(SSD), comprising over 97k songs (4,751 hours) with over 49k synthetic songs
from popular platforms like Suno and Udio. Furthermore, we highlight the
importance of modeling long-range temporal dependencies in songs for effective
authenticity detection, an aspect entirely overlooked in existing methods. To
utilize long-range patterns, we introduce SpecTTTra, a novel architecture that
significantly improves time and memory efficiency over conventional CNN and
Transformer-based models. For long songs, our top-performing variant
outperforms ViT by 8% in F1 score, is 38% faster, and uses 26% less memory,
while also surpassing ConvNeXt with a 1% F1 score gain, 20% speed boost, and
67% memory reduction.",2024-08-26,"Md Awsafur Rahman, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Bishmoy Paul, Shaikh Anowarul Fattah",http://arxiv.org/pdf/2408.14080v4,cs.LG
Score-based change point detection via tracking the best of infinitely many experts,"We suggest a novel algorithm for online change point detection based on
sequential score function estimation and tracking the best expert approach. The
core of the procedure is a version of the fixed share forecaster for the case
of infinite number of experts and quadratic loss functions. The algorithm shows
a promising performance in numerical experiments on artificial and real-world
data sets. We also derive new upper bounds on the dynamic regret of the fixed
share forecaster with varying parameter, which are of independent interest.",2024-08-26,"Anna Markovich, Nikita Puchkin",http://arxiv.org/pdf/2408.14073v1,cs.LG
"Bridging the gap between Learning-to-plan, Motion Primitives and Safe Reinforcement Learning","Trajectory planning under kinodynamic constraints is fundamental for advanced
robotics applications that require dexterous, reactive, and rapid skills in
complex environments. These constraints, which may represent task, safety, or
actuator limitations, are essential for ensuring the proper functioning of
robotic platforms and preventing unexpected behaviors. Recent advances in
kinodynamic planning demonstrate that learning-to-plan techniques can generate
complex and reactive motions under intricate constraints. However, these
techniques necessitate the analytical modeling of both the robot and the entire
task, a limiting assumption when systems are extremely complex or when
constructing accurate task models is prohibitive. This paper addresses this
limitation by combining learning-to-plan methods with reinforcement learning,
resulting in a novel integration of black-box learning of motion primitives and
optimization. We evaluate our approach against state-of-the-art safe
reinforcement learning methods, showing that our technique, particularly when
exploiting task structure, outperforms baseline methods in challenging
scenarios such as planning to hit in robot air hockey. This work demonstrates
the potential of our integrated approach to enhance the performance and safety
of robots operating under complex kinodynamic constraints.",2024-08-26,"Piotr Kicki, Davide Tateo, Puze Liu, Jonas Guenster, Jan Peters, Krzysztof Walas",http://arxiv.org/pdf/2408.14063v1,cs.LG
Multi-Class Plant Leaf Disease Detection: A CNN-based Approach with Mobile App Integration,"Plant diseases significantly impact agricultural productivity, resulting in
economic losses and food insecurity. Prompt and accurate detection is crucial
for the efficient management and mitigation of plant diseases. This study
investigates advanced techniques in plant disease detection, emphasizing the
integration of image processing, machine learning, deep learning methods, and
mobile technologies. High-resolution images of plant leaves were captured and
analyzed using convolutional neural networks (CNNs) to detect symptoms of
various diseases, such as blight, mildew, and rust. This study explores 14
classes of plants and diagnoses 26 unique plant diseases. We focus on common
diseases affecting various crops. The model was trained on a diverse dataset
encompassing multiple crops and disease types, achieving 98.14% accuracy in
disease diagnosis. Finally integrated this model into mobile apps for real-time
disease diagnosis.",2024-08-26,"Md Aziz Hosen Foysal, Foyez Ahmed, Md Zahurul Haque",http://arxiv.org/pdf/2408.15289v1,cs.LG
PAGE: Parametric Generative Explainer for Graph Neural Network,"This article introduces PAGE, a parameterized generative interpretive
framework. PAGE is capable of providing faithful explanations for any graph
neural network without necessitating prior knowledge or internal details.
Specifically, we train the auto-encoder to generate explanatory substructures
by designing appropriate training strategy. Due to the dimensionality reduction
of features in the latent space of the auto-encoder, it becomes easier to
extract causal features leading to the model's output, which can be easily
employed to generate explanations. To accomplish this, we introduce an
additional discriminator to capture the causality between latent causal
features and the model's output. By designing appropriate optimization
objectives, the well-trained discriminator can be employed to constrain the
encoder in generating enhanced causal features. Finally, these features are
mapped to substructures of the input graph through the decoder to serve as
explanations. Compared to existing methods, PAGE operates at the sample scale
rather than nodes or edges, eliminating the need for perturbation or encoding
processes as seen in previous methods. Experimental results on both
artificially synthesized and real-world datasets demonstrate that our approach
not only exhibits the highest faithfulness and accuracy but also significantly
outperforms baseline models in terms of efficiency.",2024-08-26,"Yang Qiu, Wei Liu, Jun Wang, Ruixuan Li",http://arxiv.org/pdf/2408.14042v2,cs.LG
Towards Graph Prompt Learning: A Survey and Beyond,"Large-scale ""pre-train and prompt learning"" paradigms have demonstrated
remarkable adaptability, enabling broad applications across diverse domains
such as question answering, image recognition, and multimodal retrieval. This
approach fully leverages the potential of large-scale pre-trained models,
reducing downstream data requirements and computational costs while enhancing
model applicability across various tasks. Graphs, as versatile data structures
that capture relationships between entities, play pivotal roles in fields such
as social network analysis, recommender systems, and biological graphs. Despite
the success of pre-train and prompt learning paradigms in Natural Language
Processing (NLP) and Computer Vision (CV), their application in graph domains
remains nascent. In graph-structured data, not only do the node and edge
features often have disparate distributions, but the topological structures
also differ significantly. This diversity in graph data can lead to
incompatible patterns or gaps between pre-training and fine-tuning on
downstream graphs. We aim to bridge this gap by summarizing methods for
alleviating these disparities. This includes exploring prompt design
methodologies, comparing related techniques, assessing application scenarios
and datasets, and identifying unresolved problems and challenges. This survey
categorizes over 100 relevant works in this field, summarizing general design
principles and the latest applications, including text-attributed graphs,
molecules, proteins, and recommendation systems. Through this extensive review,
we provide a foundational understanding of graph prompt learning, aiming to
impact not only the graph mining community but also the broader Artificial
General Intelligence (AGI) community.",2024-08-26,"Qingqing Long, Yuchen Yan, Peiyan Zhang, Chen Fang, Wentao Cui, Zhiyuan Ning, Meng Xiao, Ning Cao, Xiao Luo, Lingjun Xu, Shiyue Jiang, Zheng Fang, Chong Chen, Xian-Sheng Hua, Yuanchun Zhou",http://arxiv.org/pdf/2408.14520v3,cs.LG
A Multilateral Attention-enhanced Deep Neural Network for Disease Outbreak Forecasting: A Case Study on COVID-19,"The worldwide impact of the recent COVID-19 pandemic has been substantial,
necessitating the development of accurate forecasting models to predict the
spread and course of a pandemic. Previous methods for outbreak forecasting have
faced limitations by not utilizing multiple sources of input and yielding
suboptimal performance due to the limited availability of data. In this study,
we propose a novel approach to address the challenges of infectious disease
forecasting. We introduce a Multilateral Attention-enhanced GRU model that
leverages information from multiple sources, thus enabling a comprehensive
analysis of factors influencing the spread of a pandemic. By incorporating
attention mechanisms within a GRU framework, our model can effectively capture
complex relationships and temporal dependencies in the data, leading to
improved forecasting performance. Further, we have curated a well-structured
multi-source dataset for the recent COVID-19 pandemic that the research
community can utilize as a great resource to conduct experiments and analysis
on time-series forecasting. We evaluated the proposed model on our COVID-19
dataset and reported the output in terms of RMSE and MAE. The experimental
results provide evidence that our proposed model surpasses existing techniques
in terms of performance. We also performed performance gain and qualitative
analysis on our dataset to evaluate the impact of the attention mechanism and
show that the proposed model closely follows the trajectory of the pandemic.",2024-08-26,"Ashutosh Anshul, Jhalak Gupta, Mohammad Zia Ur Rehman, Nagendra Kumar",http://arxiv.org/pdf/2408.14519v1,cs.LG
Re-Mix: Optimizing Data Mixtures for Large Scale Imitation Learning,"Increasingly large imitation learning datasets are being collected with the
goal of training foundation models for robotics. However, despite the fact that
data selection has been of utmost importance in vision and natural language
processing, little work in robotics has questioned what data such models should
actually be trained on. In this work we investigate how to weigh different
subsets or ``domains'' of robotics datasets for robot foundation model
pre-training. Concrete, we use distributionally robust optimization (DRO) to
maximize worst-case performance across all possible downstream domains. Our
method, Re-Mix, addresses the wide range of challenges that arise when applying
DRO to robotics datasets including variability in action spaces and dynamics
across different datasets. Re-Mix employs early stopping, action normalization,
and discretization to counteract these issues. Through extensive
experimentation on the largest open-source robot manipulation dataset, the Open
X-Embodiment dataset, we demonstrate that data curation can have an outsized
impact on downstream performance. Specifically, domain weights learned by
Re-Mix outperform uniform weights by 38\% on average and outperform
human-selected weights by 32\% on datasets used to train existing generalist
robot policies, specifically the RT-X models.",2024-08-26,"Joey Hejna, Chethan Bhateja, Yichen Jiang, Karl Pertsch, Dorsa Sadigh",http://arxiv.org/pdf/2408.14037v1,cs.LG
MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents,"Machine learning research, crucial for technological advancements and
innovation, often faces significant challenges due to its inherent complexity,
slow pace of experimentation, and the necessity for specialized expertise.
Motivated by this, we present a new systematic framework, autonomous Machine
Learning Research with large language models (MLR-Copilot), designed to enhance
machine learning research productivity through the automatic generation and
implementation of research ideas using Large Language Model (LLM) agents. The
framework consists of three phases: research idea generation, experiment
implementation, and implementation execution. First, existing research papers
are used to generate hypotheses and experimental plans vis IdeaAgent powered by
LLMs. Next, the implementation generation phase translates these plans into
executables with ExperimentAgent. This phase leverages retrieved prototype code
and optionally retrieves candidate models and data. Finally, the execution
phase, also managed by ExperimentAgent, involves running experiments with
mechanisms for human feedback and iterative debugging to enhance the likelihood
of achieving executable research outcomes. We evaluate our framework on five
machine learning research tasks and the experimental results show the
framework's potential to facilitate the research progress and innovations.",2024-08-26,"Ruochen Li, Teerth Patel, Qingyun Wang, Xinya Du",http://arxiv.org/pdf/2408.14033v2,cs.LG
SurGen: Text-Guided Diffusion Model for Surgical Video Generation,"Diffusion-based video generation models have made significant strides,
producing outputs with improved visual fidelity, temporal coherence, and user
control. These advancements hold great promise for improving surgical education
by enabling more realistic, diverse, and interactive simulation environments.
In this study, we introduce SurGen, a text-guided diffusion model tailored for
surgical video synthesis. SurGen produces videos with the highest resolution
and longest duration among existing surgical video generation models. We
validate the visual and temporal quality of the outputs using standard image
and video generation metrics. Additionally, we assess their alignment to the
corresponding text prompts through a deep learning classifier trained on
surgical data. Our results demonstrate the potential of diffusion models to
serve as valuable educational tools for surgical trainees.",2024-08-26,"Joseph Cho, Samuel Schmidgall, Cyril Zakka, Mrudang Mathur, Dhamanpreet Kaur, Rohan Shad, William Hiesinger",http://arxiv.org/pdf/2408.14028v3,cs.LG
An Item Response Theory-based R Module for Algorithm Portfolio Analysis,"Experimental evaluation is crucial in AI research, especially for assessing
algorithms across diverse tasks. Many studies often evaluate a limited set of
algorithms, failing to fully understand their strengths and weaknesses within a
comprehensive portfolio. This paper introduces an Item Response Theory (IRT)
based analysis tool for algorithm portfolio evaluation called AIRT-Module.
Traditionally used in educational psychometrics, IRT models test question
difficulty and student ability using responses to test questions. Adapting IRT
to algorithm evaluation, the AIRT-Module contains a Shiny web application and
the R package airt. AIRT-Module uses algorithm performance measures to compute
anomalousness, consistency, and difficulty limits for an algorithm and the
difficulty of test instances. The strengths and weaknesses of algorithms are
visualised using the difficulty spectrum of the test instances. AIRT-Module
offers a detailed understanding of algorithm capabilities across varied test
instances, thus enhancing comprehensive AI method assessment. It is available
at https://sevvandi.shinyapps.io/AIRT/ .",2024-08-26,"Brodie Oldfield, Sevvandi Kandanaarachchi, Ziqi Xu, Mario Andrés Muñoz",http://arxiv.org/pdf/2408.14025v2,cs.LG
Category-Theoretical and Topos-Theoretical Frameworks in Machine Learning: A Survey,"In this survey, we provide an overview of category theory-derived machine
learning from four mainstream perspectives: gradient-based learning,
probability-based learning, invariance and equivalence-based learning, and
topos-based learning. For the first three topics, we primarily review research
in the past five years, updating and expanding on the previous survey by
Shiebler et al.. The fourth topic, which delves into higher category theory,
particularly topos theory, is surveyed for the first time in this paper. In
certain machine learning methods, the compositionality of functors plays a
vital role, prompting the development of specific categorical frameworks.
However, when considering how the global properties of a network reflect in
local structures and how geometric properties are expressed with logic, the
topos structure becomes particularly significant and profound.",2024-08-26,"Yiyang Jia, Guohong Peng, Zheng Yang, Tianhao Chen",http://arxiv.org/pdf/2408.14014v3,cs.LG
Improving Water Quality Time-Series Prediction in Hong Kong using Sentinel-2 MSI Data and Google Earth Engine Cloud Computing,"Effective water quality monitoring in coastal regions is crucial due to the
progressive deterioration caused by pollution and human activities. To address
this, this study develops time-series models to predict chlorophyll-a (Chl-a),
suspended solids (SS), and turbidity using Sentinel-2 satellite data and Google
Earth Engine (GEE) in the coastal regions of Hong Kong. Leveraging Long
Short-Term Memory (LSTM) Recurrent Neural Networks, the study incorporates
extensive temporal datasets to enhance prediction accuracy. The models utilize
spectral data from Sentinel-2, focusing on optically active components, and
demonstrate that selected variables closely align with the spectral
characteristics of Chl-a and SS. The results indicate improved predictive
performance over previous methods, highlighting the potential for remote
sensing technology in continuous and comprehensive water quality assessment.",2024-08-26,"Rohin Sood, Kevin Zhu",http://arxiv.org/pdf/2408.14010v2,cs.LG
Decentralized Federated Learning with Model Caching on Mobile Agents,"Federated Learning (FL) trains a shared model using data and computation
power on distributed agents coordinated by a central server. Decentralized FL
(DFL) utilizes local model exchange and aggregation between agents to reduce
the communication and computation overheads on the central server. However,
when agents are mobile, the communication opportunity between agents can be
sporadic, largely hindering the convergence and accuracy of DFL. In this paper,
we propose Cached Decentralized Federated Learning (Cached-DFL) to investigate
delay-tolerant model spreading and aggregation enabled by model caching on
mobile agents. Each agent stores not only its own model, but also models of
agents encountered in the recent past. When two agents meet, they exchange
their own models as well as the cached models. Local model aggregation utilizes
all models stored in the cache. We theoretically analyze the convergence of
Cached-DFL, explicitly taking into account the model staleness introduced by
caching. We design and compare different model caching algorithms for different
DFL and mobility scenarios. We conduct detailed case studies in a vehicular
network to systematically investigate the interplay between agent mobility,
cache staleness, and model convergence. In our experiments, Cached-DFL
converges quickly, and significantly outperforms DFL without caching.",2024-08-26,"Xiaoyu Wang, Guojun Xiong, Houwei Cao, Jian Li, Yong Liu",http://arxiv.org/pdf/2408.14001v2,cs.LG
Dual-CBA: Improving Online Continual Learning via Dual Continual Bias Adaptors from a Bi-level Optimization Perspective,"In online continual learning (CL), models trained on changing distributions
easily forget previously learned knowledge and bias toward newly received
tasks. To address this issue, we present Continual Bias Adaptor (CBA), a
bi-level framework that augments the classification network to adapt to
catastrophic distribution shifts during training, enabling the network to
achieve a stable consolidation of all seen tasks. However, the CBA module
adjusts distribution shifts in a class-specific manner, exacerbating the
stability gap issue and, to some extent, fails to meet the need for continual
testing in online CL. To mitigate this challenge, we further propose a novel
class-agnostic CBA module that separately aggregates the posterior
probabilities of classes from new and old tasks, and applies a stable
adjustment to the resulting posterior probabilities. We combine the two kinds
of CBA modules into a unified Dual-CBA module, which thus is capable of
adapting to catastrophic distribution shifts and simultaneously meets the
real-time testing requirements of online CL. Besides, we propose Incremental
Batch Normalization (IBN), a tailored BN module to re-estimate its population
statistics for alleviating the feature bias arising from the inner loop
optimization problem of our bi-level framework. To validate the effectiveness
of the proposed method, we theoretically provide some insights into how it
mitigates catastrophic distribution shifts, and empirically demonstrate its
superiority through extensive experiments based on four rehearsal-based
baselines and three public continual learning benchmarks.",2024-08-26,"Quanziang Wang, Renzhen Wang, Yichen Wu, Xixi Jia, Minghao Zhou, Deyu Meng",http://arxiv.org/pdf/2408.13991v1,cs.LG
LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU,"Stock price prediction is a challenging problem in the field of finance and
receives widespread attention. In recent years, with the rapid development of
technologies such as deep learning and graph neural networks, more research
methods have begun to focus on exploring the interrelationships between stocks.
However, existing methods mostly focus on the short-term dynamic relationships
of stocks and directly integrating relationship information with temporal
information. They often overlook the complex nonlinear dynamic characteristics
and potential higher-order interaction relationships among stocks in the stock
market. Therefore, we propose a stock price trend prediction model named
LSR-IGRU in this paper, which is based on long short-term stock relationships
and an improved GRU input. Firstly, we construct a long short-term relationship
matrix between stocks, where secondary industry information is employed for the
first time to capture long-term relationships of stocks, and overnight price
information is utilized to establish short-term relationships. Next, we improve
the inputs of the GRU model at each step, enabling the model to more
effectively integrate temporal information and long short-term relationship
information, thereby significantly improving the accuracy of predicting stock
trend changes. Finally, through extensive experiments on multiple datasets from
stock markets in China and the United States, we validate the superiority of
the proposed LSR-IGRU model over the current state-of-the-art baseline models.
We also apply the proposed model to the algorithmic trading system of a
financial company, achieving significantly higher cumulative portfolio returns
compared to other baseline methods. Our sources are released at
https://github.com/ZP1481616577/Baselines_LSR-IGRU.",2024-08-26,"Peng Zhu, Yuante Li, Yifan Hu, Qinyuan Liu, Dawei Cheng, Yuqi Liang",http://arxiv.org/pdf/2409.08282v3,cs.LG
Question answering system of bridge design specification based on large language model,"This paper constructs question answering system for bridge design
specification based on large language model. Three implementation schemes are
tried: full fine-tuning of the Bert pretrained model, parameter-efficient
fine-tuning of the Bert pretrained model, and self-built language model from
scratch. Through the self-built question and answer task dataset, based on the
tensorflow and keras deep learning platform framework, the model is constructed
and trained to predict the start position and end position of the answer in the
bridge design specification given by the user. The experimental results show
that full fine-tuning of the Bert pretrained model achieves 100% accuracy in
the training-dataset, validation-dataset and test-dataset, and the system can
extract the answers from the bridge design specification given by the user to
answer various questions of the user; While parameter-efficient fine-tuning of
the Bert pretrained model and self-built language model from scratch perform
well in the training-dataset, their generalization ability in the test-dataset
needs to be improved. The research of this paper provides a useful reference
for the development of question answering system in professional field.",2024-08-26,"Leye Zhang, Xiangxiang Tian, Hongjun Zhang",http://arxiv.org/pdf/2408.13282v1,cs.LG
AgentMove: A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction,"Next location prediction plays a crucial role in various real-world
applications. Recently, due to the limitation of existing deep learning
methods, attempts have been made to apply large language models (LLMs) to
zero-shot next location prediction task. However, they directly generate the
final output using LLMs without systematic design, which limits the potential
of LLMs to uncover complex mobility patterns and underestimates their extensive
reserve of global geospatial knowledge. In this paper, we introduce AgentMove,
a systematic agentic prediction framework to achieve generalized next location
prediction. In AgentMove, we first decompose the mobility prediction task and
design specific modules to complete them, including spatial-temporal memory for
individual mobility pattern mining, world knowledge generator for modeling the
effects of urban structure and collective knowledge extractor for capturing the
shared patterns among population. Finally, we combine the results of three
modules and conduct a reasoning step to generate the final predictions.
Extensive experiments utilizing mobility data from two distinct sources reveal
that AgentMove surpasses the leading baseline by 3.33% to 8.57% across 8 out of
12 metrics and it shows robust predictions with various LLMs as base and also
less geographical bias across cities. Our codes are available via
https://github.com/tsinghua-fib-lab/AgentMove.",2024-08-26,"Jie Feng, Yuwei Du, Jie Zhao, Yong Li",http://arxiv.org/pdf/2408.13986v2,cs.LG
Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models,"With the prevalence of large-scale pretrained vision-language models (VLMs),
such as CLIP, soft-prompt tuning has become a popular method for adapting these
models to various downstream tasks. However, few works delve into the inherent
properties of learnable soft-prompt vectors, specifically the impact of their
norms to the performance of VLMs. This motivates us to pose an unexplored
research question: ``Do we need to normalize the soft prompts in VLMs?'' To
fill this research gap, we first uncover a phenomenon, called the
\textbf{Low-Norm Effect} by performing extensive corruption experiments,
suggesting that reducing the norms of certain learned prompts occasionally
enhances the performance of VLMs, while increasing them often degrades it. To
harness this effect, we propose a novel method named \textbf{N}ormalizing
th\textbf{e} soft-pro\textbf{m}pt v\textbf{e}ctors of vi\textbf{si}on-language
model\textbf{s} (\textbf{Nemesis}) to normalize soft-prompt vectors in VLMs. To
the best of our knowledge, our work is the first to systematically investigate
the role of norms of soft-prompt vector in VLMs, offering valuable insights for
future research in soft-prompt tuning. The code is available at
\texttt{\href{https://github.com/ShyFoo/Nemesis}{https://github.com/ShyFoo/Nemesis}}.",2024-08-26,"Shuai Fu, Xiequn Wang, Qiushi Huang, Yu Zhang",http://arxiv.org/pdf/2408.13979v1,cs.LG
Towards Battery-Free Wireless Sensing via Radio-Frequency Energy Harvesting,"Diverse Wi-Fi-based wireless applications have been proposed, ranging from
daily activity recognition to vital sign monitoring. Despite their remarkable
sensing accuracy, the high energy consumption and the requirement for
customized hardware modification hinder the wide deployment of the existing
sensing solutions. In this paper, we propose REHSense, an energy-efficient
wireless sensing solution based on Radio-Frequency (RF) energy harvesting.
Instead of relying on a power-hungry Wi-Fi receiver, REHSense leverages an RF
energy harvester as the sensor and utilizes the voltage signals harvested from
the ambient Wi-Fi signals to enable simultaneous context sensing and energy
harvesting. We design and implement REHSense using a commercial-off-the-shelf
(COTS) RF energy harvester. Extensive evaluation of three fine-grained wireless
sensing tasks (i.e., respiration monitoring, human activity, and hand gesture
recognition) shows that REHSense can achieve comparable sensing accuracy with
conventional Wi-Fi-based solutions while adapting to different sensing
environments, reducing the power consumption by 98.7% and harvesting up to
4.5mW of power from RF energy.",2024-08-26,"Tao Ni, Zehua Sun, Mingda Han, Guohao Lan, Yaxiong Xie, Zhenjiang Li, Tao Gu, Weitao Xu",http://arxiv.org/pdf/2409.00086v1,cs.LG
A Survey on Reinforcement Learning Applications in SLAM,"The emergence of mobile robotics, particularly in the automotive industry,
introduces a promising era of enriched user experiences and adept handling of
complex navigation challenges. The realization of these advancements
necessitates a focused technological effort and the successful execution of
numerous intricate tasks, particularly in the critical domain of Simultaneous
Localization and Mapping (SLAM). Various artificial intelligence (AI)
methodologies, such as deep learning and reinforcement learning, present viable
solutions to address the challenges in SLAM. This study specifically explores
the application of reinforcement learning in the context of SLAM. By enabling
the agent (the robot) to iteratively interact with and receive feedback from
its environment, reinforcement learning facilitates the acquisition of
navigation and mapping skills, thereby enhancing the robot's decision-making
capabilities. This approach offers several advantages, including improved
navigation proficiency, increased resilience, reduced dependence on sensor
precision, and refinement of the decision-making process. The findings of this
study, which provide an overview of reinforcement learning's utilization in
SLAM, reveal significant advancements in the field. The investigation also
highlights the evolution and innovative integration of these techniques.",2024-08-26,"Mohammad Dehghani Tezerjani, Mohammad Khoshnazar, Mohammadhamed Tangestanizadeh, Arman Kiani, Qing Yang",http://arxiv.org/pdf/2408.14518v2,cs.LG
Optimizing Luxury Vehicle Dealership Networks: A Graph Neural Network Approach to Site Selection,"This study presents a novel application of Graph Neural Networks (GNNs) to
optimize dealership network planning for a luxury car manufacturer in the U.S.
By conducting a comprehensive literature review on dealership location
determinants, the study identifies 65 county-level explanatory variables,
augmented by two additional measures of regional interconnectedness derived
from social and mobility data. An ablation study involving 34 variable
combinations and ten state-of-the-art GNN operators reveals key insights into
the predictive power of various variables, particularly highlighting the
significance of competition, demographic factors, and mobility patterns in
influencing dealership location decisions. The analysis pinpoints seven
specific counties as promising targets for network expansion. This research not
only illustrates the effectiveness of GNNs in solving complex geospatial
decision-making problems but also provides actionable recommendations and
valuable methodological insights for industry practitioners.",2024-08-25,"Luca Silvano Carocci, Qiwei Han",http://arxiv.org/pdf/2408.13961v2,cs.LG
"Time Series Analysis for Education: Methods, Applications, and Future Directions","Recent advancements in the collection and analysis of sequential educational
data have brought time series analysis to a pivotal position in educational
research, highlighting its essential role in facilitating data-driven
decision-making. However, there is a lack of comprehensive summaries that
consolidate these advancements. To the best of our knowledge, this paper is the
first to provide a comprehensive review of time series analysis techniques
specifically within the educational context. We begin by exploring the
landscape of educational data analytics, categorizing various data sources and
types relevant to education. We then review four prominent time series
methods-forecasting, classification, clustering, and anomaly
detection-illustrating their specific application points in educational
settings. Subsequently, we present a range of educational scenarios and
applications, focusing on how these methods are employed to address diverse
educational tasks, which highlights the practical integration of multiple time
series methods to solve complex educational problems. Finally, we conclude with
a discussion on future directions, including personalized learning analytics,
multimodal data fusion, and the role of large language models (LLMs) in
educational time series. The contributions of this paper include a detailed
taxonomy of educational data, a synthesis of time series techniques with
specific educational applications, and a forward-looking perspective on
emerging trends and future research opportunities in educational analysis. The
related papers and resources are available and regularly updated at the project
page.",2024-08-25,"Shengzhong Mao, Chaoli Zhang, Yichi Song, Jindong Wang, Xiao-Jun Zeng, Zenglin Xu, Qingsong Wen",http://arxiv.org/pdf/2408.13960v2,cs.LG
"Prediction of COPD Using Machine Learning, Clinical Summary Notes, and Vital Signs","Chronic obstructive pulmonary disease (COPD) is a chronic inflammatory lung
disease that causes obstructed airflow from the lungs. In the United States,
more than 15.7 million Americans have been diagnosed with COPD, with 96% of
individuals living with at least one other chronic health condition. It is the
4th leading cause of death in the country. Over 2.2 million patients are
admitted to hospitals annually due to COPD exacerbations. Monitoring and
predicting patient exacerbations on-time could save their life. This paper
presents two different predictive models to predict COPD exacerbation using AI
and natural language processing (NLP) approaches. These models use respiration
summary notes, symptoms, and vital signs. To train and test these models, data
records containing physiologic signals and vital signs time series were used.
These records were captured from patient monitors and comprehensive clinical
data obtained from hospital medical information systems for tens of thousands
of Intensive Care Unit (ICU) patients. We achieved an area under the Receiver
operating characteristic (ROC) curve of 0.82 in detection and prediction of
COPD exacerbation.",2024-08-25,Negar Orangi-Fard,http://arxiv.org/pdf/2408.13958v2,cs.LG
Learning to Move Like Professional Counter-Strike Players,"In multiplayer, first-person shooter games like Counter-Strike: Global
Offensive (CS:GO), coordinated movement is a critical component of high-level
strategic play. However, the complexity of team coordination and the variety of
conditions present in popular game maps make it impractical to author
hand-crafted movement policies for every scenario. We show that it is possible
to take a data-driven approach to creating human-like movement controllers for
CS:GO. We curate a team movement dataset comprising 123 hours of professional
game play traces, and use this dataset to train a transformer-based movement
model that generates human-like team movement for all players in a ""Retakes""
round of the game. Importantly, the movement prediction model is efficient.
Performing inference for all players takes less than 0.5 ms per game step
(amortized cost) on a single CPU core, making it plausible for use in
commercial games today. Human evaluators assess that our model behaves more
like humans than both commercially-available bots and procedural movement
controllers scripted by experts (16% to 59% higher by TrueSkill rating of
""human-like""). Using experiments involving in-game bot vs. bot self-play, we
demonstrate that our model performs simple forms of teamwork, makes fewer
common movement mistakes, and yields movement distributions, player lifetimes,
and kill locations similar to those observed in professional CS:GO match play.",2024-08-25,"David Durst, Feng Xie, Vishnu Sarukkai, Brennan Shacklett, Iuri Frosio, Chen Tessler, Joohwan Kim, Carly Taylor, Gilbert Bernstein, Sanjiban Choudhury, Pat Hanrahan, Kayvon Fatahalian",http://arxiv.org/pdf/2408.13934v1,cs.LG
FedGlu: A personalized federated learning-based glucose forecasting algorithm for improved performance in glycemic excursion regions,"Continuous glucose monitoring (CGM) devices provide real-time glucose
monitoring and timely alerts for glycemic excursions, improving glycemic
control among patients with diabetes. However, identifying rare events like
hypoglycemia and hyperglycemia remain challenging due to their infrequency.
Moreover, limited access to sensitive patient data hampers the development of
robust machine learning models. Our objective is to accurately predict glycemic
excursions while addressing data privacy concerns. To tackle excursion
prediction, we propose a novel Hypo-Hyper (HH) loss function, which
significantly improves performance in the glycemic excursion regions. The HH
loss function demonstrates a 46% improvement over mean-squared error (MSE) loss
across 125 patients. To address privacy concerns, we propose FedGlu, a machine
learning model trained in a federated learning (FL) framework. FL allows
collaborative learning without sharing sensitive data by training models
locally and sharing only model parameters across other patients. FedGlu
achieves a 35% superior glycemic excursion detection rate compared to local
models. This improvement translates to enhanced performance in predicting both,
hypoglycemia and hyperglycemia, for 105 out of 125 patients. These results
underscore the effectiveness of the proposed HH loss function in augmenting the
predictive capabilities of glucose predictions. Moreover, implementing models
within a federated learning framework not only ensures better predictive
capabilities but also safeguards sensitive data concurrently.",2024-08-25,"Darpit Dave, Kathan Vyas, Jagadish Kumaran Jayagopal, Alfredo Garcia, Madhav Erraguntla, Mark Lawley",http://arxiv.org/pdf/2408.13926v1,cs.LG
Splatt3R: Zero-shot Gaussian Splatting from Uncalibrated Image Pairs,"In this paper, we introduce Splatt3R, a pose-free, feed-forward method for
in-the-wild 3D reconstruction and novel view synthesis from stereo pairs. Given
uncalibrated natural images, Splatt3R can predict 3D Gaussian Splats without
requiring any camera parameters or depth information. For generalizability, we
build Splatt3R upon a ``foundation'' 3D geometry reconstruction method, MASt3R,
by extending it to deal with both 3D structure and appearance. Specifically,
unlike the original MASt3R which reconstructs only 3D point clouds, we predict
the additional Gaussian attributes required to construct a Gaussian primitive
for each point. Hence, unlike other novel view synthesis methods, Splatt3R is
first trained by optimizing the 3D point cloud's geometry loss, and then a
novel view synthesis objective. By doing this, we avoid the local minima
present in training 3D Gaussian Splats from stereo views. We also propose a
novel loss masking strategy that we empirically find is critical for strong
performance on extrapolated viewpoints. We train Splatt3R on the ScanNet++
dataset and demonstrate excellent generalisation to uncalibrated, in-the-wild
images. Splatt3R can reconstruct scenes at 4FPS at 512 x 512 resolution, and
the resultant splats can be rendered in real-time.",2024-08-25,"Brandon Smart, Chuanxia Zheng, Iro Laina, Victor Adrian Prisacariu",http://arxiv.org/pdf/2408.13912v2,cs.LG
ConVis: Contrastive Decoding with Hallucination Visualization for Mitigating Hallucinations in Multimodal Large Language Models,"Hallucinations in Multimodal Large Language Models (MLLMs) where generated
responses fail to accurately reflect the given image pose a significant
challenge to their reliability. To address this, we introduce ConVis, a novel
training-free contrastive decoding method. ConVis leverages a text-to-image
(T2I) generation model to semantically reconstruct the given image from
hallucinated captions. By comparing the contrasting probability distributions
produced by the original and reconstructed images, ConVis enables MLLMs to
capture visual contrastive signals that penalize hallucination generation.
Notably, this method operates purely within the decoding process, eliminating
the need for additional data or model updates. Our extensive experiments on
five popular benchmarks demonstrate that ConVis effectively reduces
hallucinations across various MLLMs, highlighting its potential to enhance
model reliability.",2024-08-25,"Yeji Park, Deokyeong Lee, Junsuk Choe, Buru Chang",http://arxiv.org/pdf/2408.13906v1,cs.LG
TraIL-Det: Transformation-Invariant Local Feature Networks for 3D LiDAR Object Detection with Unsupervised Pre-Training,"3D point clouds are essential for perceiving outdoor scenes, especially
within the realm of autonomous driving. Recent advances in 3D LiDAR Object
Detection focus primarily on the spatial positioning and distribution of points
to ensure accurate detection. However, despite their robust performance in
variable conditions, these methods are hindered by their sole reliance on
coordinates and point intensity, resulting in inadequate isometric invariance
and suboptimal detection outcomes. To tackle this challenge, our work
introduces Transformation-Invariant Local (TraIL) features and the associated
TraIL-Det architecture. Our TraIL features exhibit rigid transformation
invariance and effectively adapt to variations in point density, with a design
focus on capturing the localized geometry of neighboring structures. They
utilize the inherent isotropic radiation of LiDAR to enhance local
representation, improve computational efficiency, and boost detection
performance. To effectively process the geometric relations among points within
each proposal, we propose a Multi-head self-Attention Encoder (MAE) with
asymmetric geometric features to encode high-dimensional TraIL features into
manageable representations. Our method outperforms contemporary self-supervised
3D object detection approaches in terms of mAP on KITTI (67.8, 20% label,
moderate) and Waymo (68.9, 20% label, moderate) datasets under various label
ratios (20%, 50%, and 100%).",2024-08-25,"Li Li, Tanqiu Qiao, Hubert P. H. Shum, Toby P. Breckon",http://arxiv.org/pdf/2408.13902v1,cs.LG
Quantum-Powered Personalized Learning,"This paper explores the transformative potential of quantum computing in the
realm of personalized learning. Traditional machine learning models and
GPU-based approaches have long been utilized to tailor educational experiences
to individual student needs. However, these methods face significant challenges
in terms of scalability, computational efficiency, and real-time adaptation to
the dynamic nature of educational data. This study proposes leveraging quantum
computing to address these limitations. We review existing personalized
learning systems, classical machine learning methods, and emerging quantum
computing applications in education. We then outline a protocol for data
collection, privacy preservation using quantum techniques, and preprocessing,
followed by the development and implementation of quantum algorithms
specifically designed for personalized learning. Our findings indicate that
quantum algorithms offer substantial improvements in efficiency, scalability,
and personalization quality compared to classical methods. This paper discusses
the implications of integrating quantum computing into educational systems,
highlighting the potential for enhanced teaching methodologies, curriculum
design, and overall student experiences. We conclude by summarizing the
advantages of quantum computing in education and suggesting future research
directions.",2024-08-25,"Yifan Zhou, Chong Cheng Xu, Mingi Song, Yew Kee Wong",http://arxiv.org/pdf/2408.15287v1,cs.LG
SPICED: Syntactical Bug and Trojan Pattern Identification in A/MS Circuits using LLM-Enhanced Detection,"Analog and mixed-signal (A/MS) integrated circuits (ICs) are crucial in
modern electronics, playing key roles in signal processing, amplification,
sensing, and power management. Many IC companies outsource manufacturing to
third-party foundries, creating security risks such as stealthy analog Trojans.
Traditional detection methods, including embedding circuit watermarks or
conducting hardware-based monitoring, often impose significant area and power
overheads, and may not effectively identify all types of Trojans. To address
these shortcomings, we propose SPICED, a Large Language Model (LLM)-based
framework that operates within the software domain, eliminating the need for
hardware modifications for Trojan detection and localization. This is the first
work using LLM-aided techniques for detecting and localizing syntactical bugs
and analog Trojans in circuit netlists, requiring no explicit training and
incurring zero area overhead. Our framework employs chain-of-thought reasoning
and few-shot examples to teach anomaly detection rules to LLMs. With the
proposed method, we achieve an average Trojan coverage of 93.32% and an average
true positive rate of 93.4% in identifying Trojan-impacted nodes for the
evaluated analog benchmark circuits. These experimental results validate the
effectiveness of LLMs in detecting and locating both syntactical bugs and
Trojans within analog netlists.",2024-08-25,"Jayeeta Chaudhuri, Dhruv Thapar, Arjun Chaudhuri, Farshad Firouzi, Krishnendu Chakrabarty",http://arxiv.org/pdf/2408.16018v1,cs.LG
Neural Spacetimes for DAG Representation Learning,"We propose a class of trainable deep learning-based geometries called Neural
Spacetimes (NSTs), which can universally represent nodes in weighted directed
acyclic graphs (DAGs) as events in a spacetime manifold. While most works in
the literature focus on undirected graph representation learning or causality
embedding separately, our differentiable geometry can encode both graph edge
weights in its spatial dimensions and causality in the form of edge
directionality in its temporal dimensions. We use a product manifold that
combines a quasi-metric (for space) and a partial order (for time). NSTs are
implemented as three neural networks trained in an end-to-end manner: an
embedding network, which learns to optimize the location of nodes as events in
the spacetime manifold, and two other networks that optimize the space and time
geometries in parallel, which we call a neural (quasi-)metric and a neural
partial order, respectively. The latter two networks leverage recent ideas at
the intersection of fractal geometry and deep learning to shape the geometry of
the representation space in a data-driven fashion, unlike other works in the
literature that use fixed spacetime manifolds such as Minkowski space or De
Sitter space to embed DAGs. Our main theoretical guarantee is a universal
embedding theorem, showing that any $k$-point DAG can be embedded into an NST
with $1+\mathcal{O}(\log(k))$ distortion while exactly preserving its causal
structure. The total number of parameters defining the NST is sub-cubic in $k$
and linear in the width of the DAG. If the DAG has a planar Hasse diagram, this
is improved to $\mathcal{O}(\log(k)) + 2)$ spatial and 2 temporal dimensions.
We validate our framework computationally with synthetic weighted DAGs and
real-world network embeddings; in both cases, the NSTs achieve lower embedding
distortions than their counterparts using fixed spacetime geometries.",2024-08-25,"Haitz Sáez de Ocáriz Borde, Anastasis Kratsios, Marc T. Law, Xiaowen Dong, Michael Bronstein",http://arxiv.org/pdf/2408.13885v2,cs.LG
Safe Policy Exploration Improvement via Subgoals,"Reinforcement learning is a widely used approach to autonomous navigation,
showing potential in various tasks and robotic setups. Still, it often
struggles to reach distant goals when safety constraints are imposed (e.g., the
wheeled robot is prohibited from moving close to the obstacles). One of the
main reasons for poor performance in such setups, which is common in practice,
is that the need to respect the safety constraints degrades the exploration
capabilities of an RL agent. To this end, we introduce a novel learnable
algorithm that is based on decomposing the initial problem into smaller
sub-problems via intermediate goals, on the one hand, and respects the limit of
the cumulative safety constraints, on the other hand -- SPEIS(Safe Policy
Exploration Improvement via Subgoals). It comprises the two coupled policies
trained end-to-end: subgoal and safe. The subgoal policy is trained to generate
the subgoal based on the transitions from the buffer of the safe (main) policy
that helps the safe policy to reach distant goals. Simultaneously, the safe
policy maximizes its rewards while attempting not to violate the limit of the
cumulative safety constraints, thus providing a certain level of safety. We
evaluate SPEIS in a wide range of challenging (simulated) environments that
involve different types of robots in two different environments: autonomous
vehicles from the POLAMP environment and car, point, doggo, and sweep from the
safety-gym environment. We demonstrate that our method consistently outperforms
state-of-the-art competitors and can significantly reduce the collision rate
while maintaining high success rates (higher by 80% compared to the
best-performing methods).",2024-08-25,"Brian Angulo, Gregory Gorbov, Aleksandr Panov, Konstantin Yakovlev",http://arxiv.org/pdf/2408.13881v1,cs.LG
Generalization of Graph Neural Networks is Robust to Model Mismatch,"Graph neural networks (GNNs) have demonstrated their effectiveness in various
tasks supported by their generalization capabilities. However, the current
analysis of GNN generalization relies on the assumption that training and
testing data are independent and identically distributed (i.i.d). This imposes
limitations on the cases where a model mismatch exists when generating testing
data. In this paper, we examine GNNs that operate on geometric graphs generated
from manifold models, explicitly focusing on scenarios where there is a
mismatch between manifold models generating training and testing data. Our
analysis reveals the robustness of the GNN generalization in the presence of
such model mismatch. This indicates that GNNs trained on graphs generated from
a manifold can still generalize well to unseen nodes and graphs generated from
a mismatched manifold. We attribute this mismatch to both node feature
perturbations and edge perturbations within the generated graph. Our findings
indicate that the generalization gap decreases as the number of nodes grows in
the training graph while increasing with larger manifold dimension as well as
larger mismatch. Importantly, we observe a trade-off between the generalization
of GNNs and the capability to discriminate high-frequency components when
facing a model mismatch. The most important practical consequence of this
analysis is to shed light on the filter design of generalizable GNNs robust to
model mismatch. We verify our theoretical findings with experiments on multiple
real-world datasets.",2024-08-25,"Zhiyang Wang, Juan Cervino, Alejandro Ribeiro",http://arxiv.org/pdf/2408.13878v2,cs.LG
AlphaViT: A Flexible Game-Playing AI for Multiple Games and Variable Board Sizes,"This paper presents novel game-playing AI agents based on the AlphaZero
framework, enhanced with Vision Transformer (ViT): AlphaViT, AlphaViD, and
AlphaVDA. These agents are designed to play multiple board games of various
sizes using a single network with shared weights, thereby overcoming
AlphaZero's limitation of fixed-board-size constraints. AlphaViT employs only a
transformer encoder, whereas AlphaViD and AlphaVDA incorporate both transformer
encoders and decoders. In AlphaViD, the decoder processes outputs from the
encoder, whereas AlphaVDA uses a learnable embeddings as the decoder input. The
additional decoder layers in AlphaViD and AlphaVDA provide flexibility to adapt
to various action spaces and board sizes. Experimental results show that the
proposed agents, trained on either individual games or multiple games
simultaneously, consistently outperform traditional algorithms such as Minimax
and Monte Carlo Tree Search and approach the performance of AlphaZero, despite
using a single deep neural network (DNN) with shared weights. In particular,
AlphaViT shows strong performance across all tested games. Furthermore,
fine-tuning the DNN using pre-trained weights from small-board games
accelerates convergence and improves performance, particularly in Gomoku.
Interestingly, simultaneous training on multiple games yields performance
comparable to, or even surpassing, single-game training. These results indicate
the potential of transformer-based architectures to develop more flexible and
robust game-playing AI agents that excel in multiple games and dynamic
environments.",2024-08-25,Kazuhisa Fujita,http://arxiv.org/pdf/2408.13871v2,cs.LG
"Draw Like an Artist: Complex Scene Generation with Diffusion Model via Composition, Painting, and Retouching","Recent advances in text-to-image diffusion models have demonstrated
impressive capabilities in image quality. However, complex scene generation
remains relatively unexplored, and even the definition of `complex scene'
itself remains unclear. In this paper, we address this gap by providing a
precise definition of complex scenes and introducing a set of Complex
Decomposition Criteria (CDC) based on this definition. Inspired by the artists
painting process, we propose a training-free diffusion framework called Complex
Diffusion (CxD), which divides the process into three stages: composition,
painting, and retouching. Our method leverages the powerful chain-of-thought
capabilities of large language models (LLMs) to decompose complex prompts based
on CDC and to manage composition and layout. We then develop an attention
modulation method that guides simple prompts to specific regions to complete
the complex scene painting. Finally, we inject the detailed output of the LLM
into a retouching model to enhance the image details, thus implementing the
retouching stage. Extensive experiments demonstrate that our method outperforms
previous SOTA approaches, significantly improving the generation of
high-quality, semantically consistent, and visually diverse images for complex
scenes, even with intricate prompts.",2024-08-25,"Minghao Liu, Le Zhang, Yingjie Tian, Xiaochao Qu, Luoqi Liu, Ting Liu",http://arxiv.org/pdf/2408.13858v1,cs.LG
Condensed Sample-Guided Model Inversion for Knowledge Distillation,"Knowledge distillation (KD) is a key element in neural network compression
that allows knowledge transfer from a pre-trained teacher model to a more
compact student model. KD relies on access to the training dataset, which may
not always be fully available due to privacy concerns or logistical issues
related to the size of the data. To address this, ""data-free"" KD methods use
synthetic data, generated through model inversion, to mimic the target data
distribution. However, conventional model inversion methods are not designed to
utilize supplementary information from the target dataset, and thus, cannot
leverage it to improve performance, even when it is available. In this paper,
we consider condensed samples, as a form of supplementary information, and
introduce a method for using them to better approximate the target data
distribution, thereby enhancing the KD performance. Our approach is versatile,
evidenced by improvements of up to 11.4% in KD accuracy across various datasets
and model inversion-based methods. Importantly, it remains effective even when
using as few as one condensed sample per class, and can also enhance
performance in few-shot scenarios where only limited real data samples are
available.",2024-08-25,"Kuluhan Binici, Shivam Aggarwal, Cihan Acar, Nam Trung Pham, Karianto Leman, Gim Hee Lee, Tulika Mitra",http://arxiv.org/pdf/2408.13850v1,cs.LG
Consistent machine learning for topology optimization with microstructure-dependent neural network material models,"Additive manufacturing methods together with topology optimization have
enabled the creation of multiscale structures with controlled spatially-varying
material microstructure. However, topology optimization or inverse design of
such structures in the presence of nonlinearities remains a challenge due to
the expense of computational homogenization methods and the complexity of
differentiably parameterizing the microstructural response. A solution to this
challenge lies in machine learning techniques that offer efficient,
differentiable mappings between the material response and its microstructural
descriptors. This work presents a framework for designing multiscale
heterogeneous structures with spatially varying microstructures by merging a
homogenization-based topology optimization strategy with a consistent machine
learning approach grounded in hyperelasticity theory. We leverage neural
architectures that adhere to critical physical principles such as
polyconvexity, objectivity, material symmetry, and thermodynamic consistency to
supply the framework with a reliable constitutive model that is dependent on
material microstructural descriptors. Our findings highlight the potential of
integrating consistent machine learning models with density-based topology
optimization for enhancing design optimization of heterogeneous hyperelastic
structures under finite deformations.",2024-08-25,"Harikrishnan Vijayakumaran, Jonathan B. Russ, Glaucio H. Paulino, Miguel A. Bessa",http://arxiv.org/pdf/2408.13843v2,cs.LG
RoCP-GNN: Robust Conformal Prediction for Graph Neural Networks in Node-Classification,"Graph Neural Networks (GNNs) have emerged as powerful tools for predicting
outcomes in graph-structured data. However, a notable limitation of GNNs is
their inability to provide robust uncertainty estimates, which undermines their
reliability in contexts where errors are costly. One way to address this issue
is by providing prediction sets that contain the true label with a predefined
probability margin. Our approach builds upon conformal prediction (CP), a
framework that promises to construct statistically robust prediction sets or
intervals. There are two primary challenges: first, given dependent data like
graphs, it is unclear whether the critical assumption in CP - exchangeability -
still holds when applied to node classification. Second, even if the
exchangeability assumption is valid for conformalized link prediction, we need
to ensure high efficiency, i.e., the resulting prediction set or the interval
length is small enough to provide useful information. In this article, we
propose a novel approach termed Robust Conformal Prediction for GNNs
(RoCP-GNN), which integrates conformal prediction (CP) directly into the GNN
training process. This method generates prediction sets, instead of just point
predictions, that are valid at a user-defined confidence level, assuming only
exchangeability. Our approach robustly predicts outcomes with any predictive
GNN model while quantifying the uncertainty in predictions within the realm of
graph-based semi-supervised learning (SSL). Experimental results demonstrate
that GNN models with size loss provide a statistically significant increase in
performance. We validate our approach on standard graph benchmark datasets by
coupling it with various state-of-the-art GNNs in node classification. The code
will be made available after publication.",2024-08-25,S. Akansha,http://arxiv.org/pdf/2408.13825v2,cs.LG
A proof of contribution in blockchain using game theoretical deep learning model,"Building elastic and scalable edge resources is an inevitable prerequisite
for providing platform-based smart city services. Smart city services are
delivered through edge computing to provide low-latency applications. However,
edge computing has always faced the challenge of limited resources. A single
edge device cannot undertake the various intelligent computations in a smart
city, and the large-scale deployment of edge devices from different service
providers to build an edge resource platform has become a necessity. Selecting
computing power from different service providers is a game-theoretic problem.
To incentivize service providers to actively contribute their valuable
resources and provide low-latency collaborative computing power, we introduce a
game-theoretic deep learning model to reach a consensus among service providers
on task scheduling and resource provisioning. Traditional centralized resource
management approaches are inefficient and lack credibility, while the
introduction of blockchain technology can enable decentralized resource trading
and scheduling. We propose a contribution-based proof mechanism to provide the
low-latency service of edge computing. The deep learning model consists of dual
encoders and a single decoder, where the GNN (Graph Neural Network) encoder
processes structured decision action data, and the RNN (Recurrent Neural
Network) encoder handles time-series task scheduling data. Extensive
experiments have demonstrated that our model reduces latency by 584% compared
to the state-of-the-art.",2024-08-25,Jin Wang,http://arxiv.org/pdf/2409.07460v1,cs.LG
CF-KAN: Kolmogorov-Arnold Network-based Collaborative Filtering to Mitigate Catastrophic Forgetting in Recommender Systems,"Collaborative filtering (CF) remains essential in recommender systems,
leveraging user--item interactions to provide personalized recommendations.
Meanwhile, a number of CF techniques have evolved into sophisticated model
architectures based on multi-layer perceptrons (MLPs). However, MLPs often
suffer from catastrophic forgetting, and thus lose previously acquired
knowledge when new information is learned, particularly in dynamic environments
requiring continual learning. To tackle this problem, we propose CF-KAN, a new
CF method utilizing Kolmogorov-Arnold networks (KANs). By learning nonlinear
functions on the edge level, KANs are more robust to the catastrophic
forgetting problem than MLPs. Built upon a KAN-based autoencoder, CF-KAN is
designed in the sense of effectively capturing the intricacies of sparse
user--item interactions and retaining information from previous data instances.
Despite its simplicity, our extensive experiments demonstrate 1) CF-KAN's
superiority over state-of-the-art methods in recommendation accuracy, 2)
CF-KAN's resilience to catastrophic forgetting, underscoring its effectiveness
in both static and dynamic recommendation scenarios, and 3) CF-KAN's edge-level
interpretation facilitating the explainability of recommendations.",2024-08-25,"Jin-Duk Park, Kyung-Min Kim, Won-Yong Shin",http://arxiv.org/pdf/2409.05878v2,cs.LG
A Joint Learning Model with Variational Interaction for Multilingual Program Translation,"Programs implemented in various programming languages form the foundation of
software applications. To alleviate the burden of program migration and
facilitate the development of software systems, automated program translation
across languages has garnered significant attention. Previous approaches
primarily focus on pairwise translation paradigms, learning translation between
pairs of languages using bilingual parallel data. However, parallel data is
difficult to collect for some language pairs, and the distribution of program
semantics across languages can shift, posing challenges for pairwise program
translation. In this paper, we argue that jointly learning a unified model to
translate code across multiple programming languages is superior to separately
learning from bilingual parallel data. We propose Variational Interaction for
Multilingual Program Translation~(VIM-PT), a disentanglement-based generative
approach that jointly trains a unified model for multilingual program
translation across multiple languages. VIM-PT disentangles code into
language-shared and language-specific features, using variational inference and
interaction information with a novel lower bound, then achieves program
translation through conditional generation. VIM-PT demonstrates four
advantages: 1) captures language-shared information more accurately from
various implementations and improves the quality of multilingual program
translation, 2) mines and leverages the capability of non-parallel data, 3)
addresses the distribution shift of program semantics across languages, 4) and
serves as a unified model, reducing deployment complexity.",2024-08-25,"Yali Du, Hui Sun, Ming Li",http://arxiv.org/pdf/2408.14515v2,cs.LG
Improving Nonlinear Projection Heads using Pretrained Autoencoder Embeddings,"This empirical study aims at improving the effectiveness of the standard
2-layer MLP projection head $g(\cdot)$ featured in the SimCLR framework through
the use of pretrained autoencoder embeddings. Given a contrastive learning task
with a largely unlabeled image classification dataset, we first train a shallow
autoencoder architecture and extract its compressed representations contained
in the encoder's embedding layer. After freezing the weights within this
pretrained layer, we use it as a drop-in replacement for the input layer of
SimCLR's default projector. Additionally, we also apply further architectural
changes to the projector by decreasing its width and changing its activation
function. The different projection heads are then used to contrastively train
and evaluate a feature extractor $f(\cdot)$ following the SimCLR protocol,
while also examining the performance impact of Z-score normalized datasets. Our
experiments indicate that using a pretrained autoencoder embedding in the
projector can not only increase classification accuracy by up to 2.9% or 1.7%
on average but can also significantly decrease the dimensionality of the
projection space. Our results also suggest, that using the sigmoid and tanh
activation functions within the projector can outperform ReLU in terms of peak
and average classification accuracy. When applying our presented projectors,
then not applying Z-score normalization to datasets often increases peak
performance. In contrast, the default projection head can benefit more from
normalization. All experiments involving our pretrained projectors are
conducted with frozen embeddings, since our test results indicate an advantage
compared to using their non-frozen counterparts.",2024-08-25,"Andreas Schliebitz, Heiko Tapken, Martin Atzmueller",http://arxiv.org/pdf/2408.14514v1,cs.LG
Prior Learning in Introspective VAEs,"Variational Autoencoders (VAEs) are a popular framework for unsupervised
learning and data generation. A plethora of methods have been proposed focusing
on improving VAEs, with the incorporation of adversarial objectives and the
integration of prior learning mechanisms being prominent directions. When it
comes to the former, an indicative instance is the recently introduced family
of Introspective VAEs aiming at ensuring that a low likelihood is assigned to
unrealistic samples. In this study, we focus on the Soft-IntroVAE (S-IntroVAE)
and investigate the implication of incorporating a multimodal and learnable
prior into this framework. Namely, we formulate the prior as a third player and
show that when trained in cooperation with the decoder constitutes an effective
way for prior learning, which shares the Nash Equilibrium with the vanilla
S-IntroVAE. Furthermore, based on a modified formulation of the optimal ELBO in
S-IntroVAE, we develop theoretically motivated regularizations, that is (i)
adaptive variance clipping to stabilize training when learning the prior and
(ii) responsibility regularization to discourage the formation of inactive
prior mode. Finally, we perform a series of targeted experiments on a 2D
density estimation benchmark and in an image generation setting comprised of
the (F)-MNIST and CIFAR-10 datasets demonstrating the benefit of prior learning
in S-IntroVAE in generation and representation learning.",2024-08-25,"Ioannis Athanasiadis, Fredrik Lindsten, Michael Felsberg",http://arxiv.org/pdf/2408.13805v2,cs.LG
Mask-Encoded Sparsification: Mitigating Biased Gradients in Communication-Efficient Split Learning,"This paper introduces a novel framework designed to achieve a high
compression ratio in Split Learning (SL) scenarios where resource-constrained
devices are involved in large-scale model training. Our investigations
demonstrate that compressing feature maps within SL leads to biased gradients
that can negatively impact the convergence rates and diminish the
generalization capabilities of the resulting models. Our theoretical analysis
provides insights into how compression errors critically hinder SL performance,
which previous methodologies underestimate. To address these challenges, we
employ a narrow bit-width encoded mask to compensate for the sparsification
error without increasing the order of time complexity. Supported by rigorous
theoretical analysis, our framework significantly reduces compression errors
and accelerates the convergence. Extensive experiments also verify that our
method outperforms existing solutions regarding training efficiency and
communication complexity.",2024-08-25,"Wenxuan Zhou, Zhihao Qu, Shen-Huan Lyu, Miao Cai, Baoliu Ye",http://arxiv.org/pdf/2408.13787v3,cs.LG
Variational autoencoder-based neural network model compression,"Variational Autoencoders (VAEs), as a form of deep generative model, have
been widely used in recent years, and shown great great peformance in a number
of different domains, including image generation and anomaly detection, etc..
This paper aims to explore neural network model compression method based on
VAE. The experiment uses different neural network models for MNIST recognition
as compression targets, including Feedforward Neural Network (FNN),
Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and Long
Short-Term Memory (LSTM). These models are the most basic models in deep
learning, and other more complex and advanced models are based on them or
inherit their features and evolve. In the experiment, the first step is to
train the models mentioned above, each trained model will have different
accuracy and number of total parameters. And then the variants of parameters
for each model are processed as training data in VAEs separately, and the
trained VAEs are tested by the true model parameters. The experimental results
show that using the latent space as a representation of the model compression
can improve the compression rate compared to some traditional methods such as
pruning and quantization, meanwhile the accuracy is not greatly affected using
the model parameters reconstructed based on the latent space. In the future, a
variety of different large-scale deep learning models will be used more widely,
so exploring different ways to save time and space on saving or transferring
models will become necessary, and the use of VAE in this paper can provide a
basis for these further explorations.",2024-08-25,"Liang Cheng, Peiyuan Guan, Amir Taherkordi, Lei Liu, Dapeng Lan",http://arxiv.org/pdf/2408.14513v1,cs.LG
Lecture Notes on Linear Neural Networks: A Tale of Optimization and Generalization in Deep Learning,"These notes are based on a lecture delivered by NC on March 2021, as part of
an advanced course in Princeton University on the mathematical understanding of
deep learning. They present a theory (developed by NC, NR and collaborators) of
linear neural networks -- a fundamental model in the study of optimization and
generalization in deep learning. Practical applications born from the presented
theory are also discussed. The theory is based on mathematical tools that are
dynamical in nature. It showcases the potential of such tools to push the
envelope of our understanding of optimization and generalization in deep
learning. The text assumes familiarity with the basics of statistical learning
theory. Exercises (without solutions) are included.",2024-08-25,"Nadav Cohen, Noam Razin",http://arxiv.org/pdf/2408.13767v2,cs.LG
On-device Learning of EEGNet-based Network For Wearable Motor Imagery Brain-Computer Interface,"Electroencephalogram (EEG)-based Brain-Computer Interfaces (BCIs) have
garnered significant interest across various domains, including rehabilitation
and robotics. Despite advancements in neural network-based EEG decoding,
maintaining performance across diverse user populations remains challenging due
to feature distribution drift. This paper presents an effective approach to
address this challenge by implementing a lightweight and efficient on-device
learning engine for wearable motor imagery recognition. The proposed approach,
applied to the well-established EEGNet architecture, enables real-time and
accurate adaptation to EEG signals from unregistered users. Leveraging the
newly released low-power parallel RISC-V-based processor, GAP9 from
Greeenwaves, and the Physionet EEG Motor Imagery dataset, we demonstrate a
remarkable accuracy gain of up to 7.31\% with respect to the baseline with a
memory footprint of 15.6 KByte. Furthermore, by optimizing the input stream, we
achieve enhanced real-time performance without compromising inference accuracy.
Our tailored approach exhibits inference time of 14.9 ms and 0.76 mJ per single
inference and 20 us and 0.83 uJ per single update during online training. These
findings highlight the feasibility of our method for edge EEG devices as well
as other battery-powered wearable AI systems suffering from subject-dependant
feature distribution drift.",2024-08-25,"Sizhen Bian, Pixi Kang, Julian Moosmann, Mengxi Liu, Pietro Bonazzi, Roman Rosipal, Michele Magno",http://arxiv.org/pdf/2409.00083v1,cs.LG
Enhancing Robustness of Human Detection Algorithms in Maritime SAR through Augmented Aerial Images to Simulate Weather Conditions,"7,651 cases of Search and Rescue Missions (SAR) were reported by the United
States Coast Guard in 2024, with over 1322 SAR helicopters deployed in the 6
first months alone. Through the utilizations of YOLO, we were able to run
different weather conditions and lighting from our augmented dataset for
training. YOLO then utilizes CNNs to apply a series of convolutions and pooling
layers to the input image, where the convolution layers are able to extract the
main features of the image. Through this, our YOLO model is able to learn to
differentiate different objects which may considerably improve its accuracy,
possibly enhancing the efficiency of SAR operations through enhanced detection
accuracy. This paper aims to improve the model's accuracy of human detection in
maritime SAR by evaluating a robust datasets containing various elevations and
geological locations, as well as through data augmentation which simulates
different weather and lighting. We observed that models trained on augmented
datasets outperformed their non-augmented counterparts in which the human
recall scores ranged from 0.891 to 0.911 with an improvement rate of 3.4\% on
the YOLOv5l model. Results showed that these models demonstrate greater
robustness to real-world conditions in varying of weather, brightness, tint,
and contrast.",2024-08-25,"Miguel Tjia, Artem Kim, Elaine Wynette Wijaya, Hanna Tefara, Kevin Zhu",http://arxiv.org/pdf/2408.13766v2,cs.LG
Improved identification of breakpoints in piecewise regression and its applications,"Identifying breakpoints in piecewise regression is critical in enhancing the
reliability and interpretability of data fitting. In this paper, we propose
novel algorithms based on the greedy algorithm to accurately and efficiently
identify breakpoints in piecewise polynomial regression. The algorithm updates
the breakpoints to minimize the error by exploring the neighborhood of each
breakpoint. It has a fast convergence rate and stability to find optimal
breakpoints. Moreover, it can determine the optimal number of breakpoints. The
computational results for real and synthetic data show that its accuracy is
better than any existing methods. The real-world datasets demonstrate that
breakpoints through the proposed algorithm provide valuable data information.",2024-08-25,"Taehyeong Kim, Hyungu Lee, Hayoung Choi",http://arxiv.org/pdf/2408.13751v2,cs.LG
Quartered Spectral Envelope and 1D-CNN-based Classification of Normally Phonated and Whispered Speech,"Whisper, as a form of speech, is not sufficiently addressed by mainstream
speech applications. This is due to the fact that systems built for normal
speech do not work as expected for whispered speech. A first step to building a
speech application that is inclusive of whispered speech, is the successful
classification of whispered speech and normal speech. Such a front-end
classification system is expected to have high accuracy and low computational
overhead, which is the scope of this paper. One of the characteristics of
whispered speech is the absence of the fundamental frequency (or pitch), and
hence the pitch harmonics as well. The presence of the pitch and pitch
harmonics in normal speech, and its absence in whispered speech, is evident in
the spectral envelope of the Fourier transform. We observe that this
characteristic is predominant in the first quarter of the spectrum, and exploit
the same as a feature. We propose the use of one dimensional convolutional
neural networks (1D-CNN) to capture these features from the quartered spectral
envelope (QSE). The system yields an accuracy of 99.31% when trained and tested
on the wTIMIT dataset, and 100% on the CHAINS dataset. The proposed feature is
compared with Mel frequency cepstral coefficients (MFCC), a staple in the
speech domain. The proposed classification system is also compared with the
state-of-the-art system based on log-filterbank energy (LFBE) features trained
on long short-term memory (LSTM) network. The proposed system based on 1D-CNN
performs better than, or as good as, the state-of-the-art across multiple
experiments. It also converges sooner, with lesser computational overhead.
Finally, the proposed system is evaluated under the presence of white noise at
various signal-to-noise ratios and found to be robust.",2024-08-25,"S. Johanan Joysingh, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.13746v1,cs.LG
Literary and Colloquial Tamil Dialect Identification,"Culture and language evolve together. The old literary form of Tamil is used
commonly for writing and the contemporary colloquial Tamil is used for
speaking. Human-computer interaction applications require Colloquial Tamil (CT)
to make it more accessible and easy for the everyday user and, it requires
Literary Tamil (LT) when information is needed in a formal written format.
Continuing the use of LT alongside CT in computer aided language learning
applications will both preserve LT, and provide ease of use via CT, at the same
time. Hence there is a need for the conversion between LT and CT dialects,
which demands as a first step, dialect identification. Dialect Identification
(DID) of LT and CT is an unexplored area of research. In the current work,
keeping the nuances of both these dialects in mind, five methods are explored
which include two implicit methods - Gaussian Mixture Model (GMM) and
Convolutional Neural Network (CNN); two explicit methods - Parallel Phone
Recognition (PPR) and Parallel Large Vocabulary Continuous Speech Recognition
(P-LVCSR); two versions of the proposed explicit Unified Phone Recognition
method (UPR-1 and UPR-2). These methods vary based on: the need for annotated
data, the size of the unit, the way in which modelling is carried out, and the
way in which the final decision is made. Even though the average duration of
the test utterances is less - 4.9s for LT and 2.5s for CT - the systems
performed well, offering the following identification accuracies: 87.72% (GMM),
93.97% (CNN), 89.24% (PPR), 94.21% (P-LVCSR), 88.57% (UPR-1), 93.53% (UPR-1
with P-LVCSR), 94.55% (UPR-2), and 95.61% (UPR-2 with P-LVCSR).",2024-08-25,"M. Nanmalar, P. Vijayalakshmi, T. Nagarajan",http://arxiv.org/pdf/2408.13739v1,cs.LG
LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings,"Zero-shot graph machine learning, especially with graph neural networks
(GNNs), has garnered significant interest due to the challenge of scarce
labeled data. While methods like self-supervised learning and graph prompt
learning have been extensively explored, they often rely on fine-tuning with
task-specific labels, limiting their effectiveness in zero-shot scenarios.
Inspired by the zero-shot capabilities of instruction-fine-tuned large language
models (LLMs), we introduce a novel framework named Token Embedding-Aligned
Graph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and
cross-task zero-shot learners for graph machine learning. Concretely, we
pretrain a GNN, aligning its representations with token embeddings of an LLM.
We then train a linear projector that transforms the GNN's representations into
a fixed number of graph token embeddings without tuning the LLM. A unified
instruction is designed for various graph tasks at different levels, such as
node classification (node-level) and link prediction (edge-level). These design
choices collectively enhance our method's effectiveness in zero-shot learning,
setting it apart from existing methods. Experiments show that our graph token
embeddings help the LLM predictor achieve state-of-the-art performance on
unseen datasets and tasks compared to other methods using LLMs as predictors.",2024-08-25,"Duo Wang, Yuan Zuo, Fengzhi Li, Junjie Wu",http://arxiv.org/pdf/2408.14512v3,cs.LG
A prototype-based model for set classification,"Classification of sets of inputs (e.g., images and texts) is an active area
of research within both computer vision (CV) and natural language processing
(NLP). A common way to represent a set of vectors is to model them as linear
subspaces. In this contribution, we present a prototype-based approach for
learning on the manifold formed from such linear subspaces, the Grassmann
manifold. Our proposed method learns a set of subspace prototypes capturing the
representative characteristics of classes and a set of relevance factors
automating the selection of the dimensionality of the subspaces. This leads to
a transparent classifier model which presents the computed impact of each input
vector on its decision. Through experiments on benchmark image and text
datasets, we have demonstrated the efficiency of our proposed classifier,
compared to the transformer-based models in terms of not only performance and
explainability but also computational resource requirements.",2024-08-25,"Mohammad Mohammadi, Sreejita Ghosh",http://arxiv.org/pdf/2408.13720v2,cs.LG
Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods,"Chain-of-Thought (CoT) prompting and its variants have gained popularity as
effective methods for solving multi-step reasoning problems using pretrained
large language models (LLMs). In this work, we analyze CoT prompting from a
statistical estimation perspective, providing a comprehensive characterization
of its sample complexity. To this end, we introduce a multi-step latent
variable model that encapsulates the reasoning process, where the latent
variable encodes the task information. Under this framework, we demonstrate
that when the pretraining dataset is sufficiently large, the estimator formed
by CoT prompting is equivalent to a Bayesian estimator. This estimator
effectively solves the multi-step reasoning problem by aggregating a posterior
distribution inferred from the demonstration examples in the prompt. Moreover,
we prove that the statistical error of the CoT estimator can be decomposed into
two main components: (i) a prompting error, which arises from inferring the
true task using CoT prompts, and (ii) the statistical error of the pretrained
LLM. We establish that, under appropriate assumptions, the prompting error
decays exponentially to zero as the number of demonstrations increases.
Additionally, we explicitly characterize the approximation and generalization
errors of the pretrained LLM. Notably, we construct a transformer model that
approximates the target distribution of the multi-step reasoning problem with
an error that decreases exponentially in the number of transformer blocks. Our
analysis extends to other variants of CoT, including Self-Consistent CoT,
Tree-of-Thought, and Selection-Inference, offering a broad perspective on the
efficacy of these methods. We also provide numerical experiments to validate
the theoretical findings.",2024-08-25,"Xinyang Hu, Fengzhuo Zhang, Siyu Chen, Zhuoran Yang",http://arxiv.org/pdf/2408.14511v2,cs.LG
Verifiable cloud-based variational quantum algorithms,"Variational quantum algorithms (VQAs) have shown potential for quantum
advantage with noisy intermediate-scale quantum (NISQ) devices for quantum
machine learning (QML). However, given the high cost and limited availability
of quantum resources, delegating VQAs via cloud networks is a more practical
solution for clients with limited quantum capabilities. Recently, Shingu et
al.[Physical Review A, 105, 022603 (2022)] proposed a variational secure cloud
quantum computing protocol, utilizing ancilla-driven quantum computation (ADQC)
for cloud-based VQAs with minimal quantum resource consumption. However, their
protocol lacks verifiability, which exposes it to potential malicious behaviors
by the server. Additionally, channel loss requires frequent re-delegation as
the size of the delegated variational circuit grows, complicating verification
due to increased circuit complexity. This paper introduces a new protocol to
address these challenges and enhance both verifiability and tolerance to
channel loss in cloud-based VQAs.",2024-08-25,"Junhong Yang, Banghai Wang, Junyu Quan, Qin Li",http://arxiv.org/pdf/2408.13713v3,cs.LG
InSpaceType: Dataset and Benchmark for Reconsidering Cross-Space Type Performance in Indoor Monocular Depth,"Indoor monocular depth estimation helps home automation, including robot
navigation or AR/VR for surrounding perception. Most previous methods primarily
experiment with the NYUv2 Dataset and concentrate on the overall performance in
their evaluation. However, their robustness and generalization to diversely
unseen types or categories for indoor spaces (spaces types) have yet to be
discovered. Researchers may empirically find degraded performance in a released
pretrained model on custom data or less-frequent types. This paper studies the
common but easily overlooked factor-space type and realizes a model's
performance variances across spaces. We present InSpaceType Dataset, a
high-quality RGBD dataset for general indoor scenes, and benchmark 13 recent
state-of-the-art methods on InSpaceType. Our examination shows that most of
them suffer from performance imbalance between head and tailed types, and some
top methods are even more severe. The work reveals and analyzes underlying bias
in detail for transparency and robustness. We extend the analysis to a total of
4 datasets and discuss the best practice in synthetic data curation for
training indoor monocular depth. Further, dataset ablation is conducted to find
out the key factor in generalization. This work marks the first in-depth
investigation of performance variances across space types and, more
importantly, releases useful tools, including datasets and codes, to closely
examine your pretrained depth models. Data and code:
https://depthcomputation.github.io/DepthPublic/",2024-08-25,"Cho-Ying Wu, Quankai Gao, Chin-Cheng Hsu, Te-Lin Wu, Jing-Wen Chen, Ulrich Neumann",http://arxiv.org/pdf/2408.13708v1,cs.LG
A Note On Deterministic Submodular Maximization With Bounded Curvature,"We show that the recent breakthrough result of [Buchbinder and Feldman,
FOCS'24] could further lead to a deterministic
$(1-\kappa_{f}/e-\varepsilon)$-approximate algorithm for maximizing a
submodular function with curvature $\kappa_{f}$ under matroid constraint.",2024-08-25,Wenxin Li,http://arxiv.org/pdf/2409.02943v1,cs.LG
Revisiting DNN Training for Intermittently-Powered Energy-Harvesting Micro-Computers,"The deployment of Deep Neural Networks in energy-constrained environments,
such as Energy Harvesting Wireless Sensor Networks, presents unique challenges,
primarily due to the intermittent nature of power availability. To address
these challenges, this study introduces and evaluates a novel training
methodology tailored for DNNs operating within such contexts. In particular, we
propose a dynamic dropout technique that adapts to both the architecture of the
device and the variability in energy availability inherent in energy harvesting
scenarios. Our proposed approach leverages a device model that incorporates
specific parameters of the network architecture and the energy harvesting
profile to optimize dropout rates dynamically during the training phase. By
modulating the network's training process based on predicted energy
availability, our method not only conserves energy but also ensures sustained
learning and inference capabilities under power constraints. Our preliminary
results demonstrate that this strategy provides 6 to 22 percent accuracy
improvements compared to the state of the art with less than 5 percent
additional compute. This paper details the development of the device model,
describes the integration of energy profiles with intermittency aware dropout
and quantization algorithms, and presents a comprehensive evaluation of the
proposed approach using real-world energy harvesting data.",2024-08-25,"Cyan Subhra Mishra, Deeksha Chaudhary, Jack Sampson, Mahmut Taylan Knademir, Chita Das",http://arxiv.org/pdf/2408.13696v2,cs.LG
StockTime: A Time Series Specialized Large Language Model Architecture for Stock Price Prediction,"The stock price prediction task holds a significant role in the financial
domain and has been studied for a long time. Recently, large language models
(LLMs) have brought new ways to improve these predictions. While recent
financial large language models (FinLLMs) have shown considerable progress in
financial NLP tasks compared to smaller pre-trained language models (PLMs),
challenges persist in stock price forecasting. Firstly, effectively integrating
the modalities of time series data and natural language to fully leverage these
capabilities remains complex. Secondly, FinLLMs focus more on analysis and
interpretability, which can overlook the essential features of time series
data. Moreover, due to the abundance of false and redundant information in
financial markets, models often produce less accurate predictions when faced
with such input data. In this paper, we introduce StockTime, a novel LLM-based
architecture designed specifically for stock price data. Unlike recent FinLLMs,
StockTime is specifically designed for stock price time series data. It
leverages the natural ability of LLMs to predict the next token by treating
stock prices as consecutive tokens, extracting textual information such as
stock correlations, statistical trends and timestamps directly from these stock
prices. StockTime then integrates both textual and time series data into the
embedding space. By fusing this multimodal data, StockTime effectively predicts
stock prices across arbitrary look-back periods. Our experiments demonstrate
that StockTime outperforms recent LLMs, as it gives more accurate predictions
while reducing memory usage and runtime costs.",2024-08-25,"Shengkun Wang, Taoran Ji, Linhan Wang, Yanshen Sun, Shang-Ching Liu, Amit Kumar, Chang-Tien Lu",http://arxiv.org/pdf/2409.08281v1,cs.LG
Understanding Uncertainty-based Active Learning Under Model Mismatch,"Instead of randomly acquiring training data points, Uncertainty-based Active
Learning (UAL) operates by querying the label(s) of pivotal samples from an
unlabeled pool selected based on the prediction uncertainty, thereby aiming at
minimizing the labeling cost for model training. The efficacy of UAL critically
depends on the model capacity as well as the adopted uncertainty-based
acquisition function. Within the context of this study, our analytical focus is
directed toward comprehending how the capacity of the machine learning model
may affect UAL efficacy. Through theoretical analysis, comprehensive
simulations, and empirical studies, we conclusively demonstrate that UAL can
lead to worse performance in comparison with random sampling when the machine
learning model class has low capacity and is unable to cover the underlying
ground truth. In such situations, adopting acquisition functions that directly
target estimating the prediction performance may be beneficial for improving
the performance of UAL.",2024-08-24,"Amir Hossein Rahmati, Mingzhou Fan, Ruida Zhou, Nathan M. Urban, Byung-Jun Yoon, Xiaoning Qian",http://arxiv.org/pdf/2408.13690v1,cs.LG
Differentially Private Publication of Electricity Time Series Data in Smart Grids,"Smart grids are a valuable data source to study consumer behavior and guide
energy policy decisions. In particular, time-series of power consumption over
geographical areas are essential in deciding the optimal placement of expensive
resources (e.g., transformers, storage elements) and their activation
schedules. However, publication of such data raises significant privacy issues,
as it may reveal sensitive details about personal habits and lifestyles.
Differential privacy (DP) is well-suited for sanitization of individual data,
but current DP techniques for time series lead to significant loss in utility,
due to the existence of temporal correlation between data readings. We
introduce {\em STPT (Spatio-Temporal Private Timeseries)}, a novel method for
DP-compliant publication of electricity consumption data that analyzes
spatio-temporal attributes and captures both micro and macro patterns by
leveraging RNNs. Additionally, it employs a partitioning method for releasing
electricity consumption time series based on identified patterns. We
demonstrate through extensive experiments, on both real-world and synthetic
datasets, that STPT significantly outperforms existing benchmarks, providing a
well-balanced trade-off between data utility and user privacy.",2024-08-24,"Sina Shaham, Gabriel Ghinita, Bhaskar Krishnamachari, Cyrus Shahabi",http://arxiv.org/pdf/2408.16017v1,cs.LG
Decentralised Variational Inference Frameworks for Multi-object Tracking on Sensor Networks: Additional Notes,"This paper tackles the challenge of multi-sensor multi-object tracking by
proposing various decentralised Variational Inference (VI) schemes that match
the tracking performance of centralised sensor fusion with only local message
exchanges among neighboring sensors. We first establish a centralised VI sensor
fusion scheme as a benchmark and analyse the limitations of its decentralised
counterpart, which requires sensors to await consensus at each VI iteration.
Therefore, we propose a decentralised gradient-based VI framework that
optimises the Locally Maximised Evidence Lower Bound (LM-ELBO) instead of the
standard ELBO, which reduces the parameter search space and enables faster
convergence, making it particularly beneficial for decentralised tracking. This
proposed framework is inherently self-evolving, improving with advancements in
decentralised optimisation techniques for convergence guarantees and
efficiency. Further, we enhance the convergence speed of proposed decentralised
schemes using natural gradients and gradient tracking strategies. Results
verify that our decentralised VI schemes are empirically equivalent to
centralised fusion in tracking performance. Notably, the decentralised natural
gradient VI method is the most communication-efficient, with communication
costs comparable to suboptimal decentralised strategies while delivering
notably higher tracking accuracy.",2024-08-24,"Qing Li, Runze Gan, Simon Godsill",http://arxiv.org/pdf/2408.13689v4,cs.LG
Submodular Maximization Approaches for Equitable Client Selection in Federated Learning,"In a conventional Federated Learning framework, client selection for training
typically involves the random sampling of a subset of clients in each
iteration. However, this random selection often leads to disparate performance
among clients, raising concerns regarding fairness, particularly in
applications where equitable outcomes are crucial, such as in medical or
financial machine learning tasks. This disparity typically becomes more
pronounced with the advent of performance-centric client sampling techniques.
This paper introduces two novel methods, namely SUBTRUNC and UNIONFL, designed
to address the limitations of random client selection. Both approaches utilize
submodular function maximization to achieve more balanced models. By modifying
the facility location problem, they aim to mitigate the fairness concerns
associated with random selection. SUBTRUNC leverages client loss information to
diversify solutions, while UNIONFL relies on historical client selection data
to ensure a more equitable performance of the final model. Moreover, these
algorithms are accompanied by robust theoretical guarantees regarding
convergence under reasonable assumptions. The efficacy of these methods is
demonstrated through extensive evaluations across heterogeneous scenarios,
revealing significant improvements in fairness as measured by a client
dissimilarity metric.",2024-08-24,"Andrés Catalino Castillo Jiménez, Ege C. Kaya, Lintao Ye, Abolfazl Hashemi",http://arxiv.org/pdf/2408.13683v2,cs.LG
Outlier Detection Bias Busted: Understanding Sources of Algorithmic Bias through Data-centric Factors,"The astonishing successes of ML have raised growing concern for the fairness
of modern methods when deployed in real world settings. However, studies on
fairness have mostly focused on supervised ML, while unsupervised outlier
detection (OD), with numerous applications in finance, security, etc., have
attracted little attention. While a few studies proposed fairness-enhanced OD
algorithms, they remain agnostic to the underlying driving mechanisms or
sources of unfairness. Even within the supervised ML literature, there exists
debate on whether unfairness stems solely from algorithmic biases (i.e. design
choices) or from the biases encoded in the data on which they are trained. To
close this gap, this work aims to shed light on the possible sources of
unfairness in OD by auditing detection models under different data-centric
factors. By injecting various known biases into the input data -- as pertain to
sample size disparity, under-representation, feature measurement noise, and
group membership obfuscation -- we find that the OD algorithms under the study
all exhibit fairness pitfalls, although differing in which types of data bias
they are more susceptible to. Most notable of our study is to demonstrate that
OD algorithm bias is not merely a data bias problem. A key realization is that
the data properties that emerge from bias injection could as well be organic --
as pertain to natural group differences w.r.t. sparsity, base rate, variance,
and multi-modality. Either natural or biased, such data properties can give
rise to unfairness as they interact with certain algorithmic design choices.",2024-08-24,"Xueying Ding, Rui Xi, Leman Akoglu",http://arxiv.org/pdf/2408.13667v1,cs.LG
Discovery and Simulation of Data-Aware Business Processes,"Simulation is a common approach to predict the effect of business process
changes on quantitative performance. The starting point of Business Process
Simulation (BPS) is a process model enriched with simulation parameters. To
cope with the typically large parameter spaces of BPS models, several methods
have been proposed to automatically discover BPS models from event logs.
Virtually all these approaches neglect the data perspective of business
processes. Yet, the data attributes manipulated by a business process often
determine which activities are performed, how many times, and when. This paper
addresses this gap by introducing a data-aware BPS modeling approach and a
method to discover data-aware BPS models from event logs. The BPS modeling
approach supports three types of data attributes (global, case-level, and
event-level) as well as deterministic and stochastic attribute update rules and
data-aware branching conditions. An empirical evaluation shows that the
proposed method accurately discovers the type of each data attribute and its
associated update rules, and that the resulting BPS models more closely
replicate the process execution control flow relative to data-unaware BPS
models.",2024-08-24,"Orlenys López-Pintado, Serhii Murashko, Marlon Dumas",http://arxiv.org/pdf/2408.13666v1,cs.LG
"Towards Human-Level Understanding of Complex Process Engineering Schematics: A Pedagogical, Introspective Multi-Agent Framework for Open-Domain Question Answering","In the chemical and process industries, Process Flow Diagrams (PFDs) and
Piping and Instrumentation Diagrams (P&IDs) are critical for design,
construction, and maintenance. Recent advancements in Generative AI, such as
Large Multimodal Models (LMMs) like GPT4 (Omni), have shown promise in
understanding and interpreting process diagrams for Visual Question Answering
(VQA). However, proprietary models pose data privacy risks, and their
computational complexity prevents knowledge editing for domain-specific
customization on consumer hardware. To overcome these challenges, we propose a
secure, on-premises enterprise solution using a hierarchical, multi-agent
Retrieval Augmented Generation (RAG) framework for open-domain question
answering (ODQA) tasks, offering enhanced data privacy, explainability, and
cost-effectiveness. Our novel multi-agent framework employs introspective and
specialized sub-agents using open-source, small-scale multimodal models with
the ReAct (Reason+Act) prompting technique for PFD and P&ID analysis,
integrating multiple information sources to provide accurate and contextually
relevant answers. Our approach, supported by iterative self-correction, aims to
deliver superior performance in ODQA tasks. We conducted rigorous experimental
studies, and the empirical results validated the proposed approach
effectiveness.",2024-08-24,"Sagar Srinivas Sakhinana, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2409.00082v1,cs.LG
Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models,"Characterizing materials with electron micrographs is a crucial task in
fields such as semiconductors and quantum materials. The complex hierarchical
structure of micrographs often poses challenges for traditional classification
methods. In this study, we propose an innovative backbone architecture for
analyzing electron micrographs. We create multi-modal representations of the
micrographs by tokenizing them into patch sequences and, additionally,
representing them as vision graphs, commonly referred to as patch attributed
graphs. We introduce the Hierarchical Network Fusion (HNF), a multi-layered
network structure architecture that facilitates information exchange between
the multi-modal representations and knowledge integration across different
patch resolutions. Furthermore, we leverage large language models (LLMs) to
generate detailed technical descriptions of nanomaterials as auxiliary
information to assist in the downstream task. We utilize a cross-modal
attention mechanism for knowledge fusion across cross-domain
representations(both image-based and linguistic insights) to predict the
nanomaterial category. This multi-faceted approach promises a more
comprehensive and accurate representation and classification of micrographs for
nanomaterial identification. Our framework outperforms traditional methods,
overcoming challenges posed by distributional shifts, and facilitating
high-throughput screening.",2024-08-24,"Sakhinana Sagar Srinivas, Geethan Sannidhi, Venkataramana Runkana",http://arxiv.org/pdf/2408.13661v1,cs.LG
ReactZyme: A Benchmark for Enzyme-Reaction Prediction,"Enzymes, with their specific catalyzed reactions, are necessary for all
aspects of life, enabling diverse biological processes and adaptations.
Predicting enzyme functions is essential for understanding biological pathways,
guiding drug development, enhancing bioproduct yields, and facilitating
evolutionary studies. Addressing the inherent complexities, we introduce a new
approach to annotating enzymes based on their catalyzed reactions. This method
provides detailed insights into specific reactions and is adaptable to newly
discovered reactions, diverging from traditional classifications by protein
family or expert-derived reaction classes. We employ machine learning
algorithms to analyze enzyme reaction datasets, delivering a much more refined
view on the functionality of enzymes. Our evaluation leverages the largest
enzyme-reaction dataset to date, derived from the SwissProt and Rhea databases
with entries up to January 8, 2024. We frame the enzyme-reaction prediction as
a retrieval problem, aiming to rank enzymes by their catalytic ability for
specific reactions. With our model, we can recruit proteins for novel reactions
and predict reactions in novel proteins, facilitating enzyme discovery and
function annotation (https://github.com/WillHua127/ReactZyme).",2024-08-24,"Chenqing Hua, Bozitao Zhong, Sitao Luan, Liang Hong, Guy Wolf, Doina Precup, Shuangjia Zheng",http://arxiv.org/pdf/2408.13659v3,cs.LG
Beamline Steering Using Deep Learning Models,"Beam steering involves the calibration of the angle and position at which a
particle accelerator's electron beam is incident upon the x-ray target with
respect to the rotation axis of the collimator. Beam Steering is an essential
task for light sources. The Linac To Undulator is very difficult to steer and
aim due to the changes of each use of the accelerator there must be
re-calibration of magnets. However with each use of the Beamline its current
method of steering runs into issues when faced with calibrating angles and
positions. Human operators spend a substantial amount of time and resources on
the task. We developed multiple different feed-forward-neural networks with
varying hyper-parameters, inputs, and outputs, seeking to compare their
performance. Specifically, our smaller models with 33 inputs and 13 outputs
outperformed the larger models with 73 inputs and 50 outputs. We propose the
following explanations for this lack of performance in larger models. First, a
lack of training time and computational power limited the ability of our models
to mature. Given more time, our models would outperform SVD. Second, when the
input size of the model increases the noise increases as well. In this case
more inputs corresponded to a greater length upon the LINAC accelerator. Less
specific and larger models that seek to make more predictions will inherently
perform worse than SVD.",2024-08-24,"Dexter Allen, Isaac Kante, Dorian Bohler",http://arxiv.org/pdf/2408.13657v1,cs.LG
Localize-and-Stitch: Efficient Model Merging via Sparse Task Arithmetic,"Model merging offers an effective strategy to combine the strengths of
multiple finetuned models into a unified model that preserves the specialized
capabilities of each. Existing methods merge models in a global manner,
performing arithmetic operations across all model parameters. However, such
global merging often leads to task interference, degrading the performance of
the merged model. In this work, we introduce Localize-and-Stitch, a novel
approach that merges models in a localized way. Our algorithm works in two
steps: i) Localization: identify tiny ($1\%$ of the total parameters) localized
regions in the finetuned models containing essential skills for the downstream
tasks, and ii) Stitching: reintegrate only these essential regions back into
the pretrained model for task synergy. We demonstrate that our approach
effectively locates sparse regions responsible for finetuned performance, and
the localized regions could be treated as compact and interpretable
representations of the finetuned models (tasks). Empirically, we evaluate our
method on various vision and language benchmarks, showing that it outperforms
existing model merging methods under different data availability scenarios.
Beyond strong empirical performance, our algorithm also facilitates model
compression and preserves pretrained knowledge, enabling flexible and continual
skill composition from multiple finetuned models with minimal storage and
computational overhead. Our code is available at
https://github.com/uiuctml/Localize-and-Stitch.",2024-08-24,"Yifei He, Yuzheng Hu, Yong Lin, Tong Zhang, Han Zhao",http://arxiv.org/pdf/2408.13656v2,cs.LG
Examining Different Research Communities: Authorship Network,"Google Scholar is one of the top search engines to access research articles
across multiple disciplines for scholarly literature. Google scholar advance
search option gives the privilege to extract articles based on phrases,
publishers name, authors name, time duration etc. In this work, we collected
Google Scholar data (2000-2021) for two different research domains in computer
science: Data Mining and Software Engineering. The scholar database resources
are powerful for network analysis, data mining, and identify links between
authors via authorship network. We examined coauthor-ship network for each
domain and studied their network structure. Extensive experiments are performed
to analyze publications trend and identifying influential authors and
affiliated organizations for each domain. The network analysis shows that the
networks features are distinct from one another and exhibit small communities
within the influential authors of a particular domain.",2024-08-24,Shrabani Ghosh,http://arxiv.org/pdf/2409.00081v1,cs.LG
Tree-structured Markov random fields with Poisson marginal distributions,"A new family of tree-structured Markov random fields for a vector of discrete
counting random variables is introduced. According to the characteristics of
the family, the marginal distributions of the Markov random fields are all
Poisson with the same mean, and are untied from the strength or structure of
their built-in dependence. This key feature is uncommon for Markov random
fields and most convenient for applications purposes. The specific properties
of this new family confer a straightforward sampling procedure and analytic
expressions for the joint probability mass function and the joint probability
generating function of the vector of counting random variables, thus granting
computational methods that scale well to vectors of high dimension. We study
the distribution of the sum of random variables constituting a Markov random
field from the proposed family, analyze a random variable's individual
contribution to that sum through expected allocations, and establish stochastic
orderings to assess a wide understanding of their behavior.",2024-08-24,"Benjamin Côté, Hélène Cossette, Etienne Marceau",http://arxiv.org/pdf/2408.13649v2,cs.LG
