title,summary,published,authors,pdf_url,category
Neural spell-checker: Beyond words with synthetic data generation,"Spell-checkers are valuable tools that enhance communication by identifying
misspelled words in written texts. Recent improvements in deep learning, and in
particular in large language models, have opened new opportunities to improve
traditional spell-checkers with new functionalities that not only assess
spelling correctness but also the suitability of a word for a given context. In
our work, we present and compare two new spell-checkers and evaluate them on
synthetic, learner, and more general-domain Slovene datasets. The first
spell-checker is a traditional, fast, word-based approach, based on a
morphological lexicon with a significantly larger word list compared to
existing spell-checkers. The second approach uses a language model trained on a
large corpus with synthetically inserted errors. We present the training data
construction strategies, which turn out to be a crucial component of neural
spell-checkers. Further, the proposed neural model significantly outperforms
all existing spell-checkers for Slovene in both precision and recall.",2024-10-30,"Matej Klemen, Martin Božič, Špela Arhar Holdt, Marko Robnik-Šikonja",http://arxiv.org/pdf/2410.23514v1,cs.CL
Dynamic Strategy Planning for Efficient Question Answering with Large Language Models,"Research has shown the effectiveness of reasoning (e.g., Chain-of-Thought),
planning (e.g., SelfAsk), and retrieval augmented generation strategies to
improve the performance of Large Language Models (LLMs) on various tasks, such
as question answering. However, using a single fixed strategy to answer
different kinds of questions is suboptimal in performance and inefficient in
terms of generated output tokens and performed retrievals. In our work, we
propose a novel technique DyPlan, to induce a dynamic strategy selection
process in LLMs, to improve performance and reduce costs in question-answering.
DyPlan incorporates an initial decision step to select the most suitable
strategy conditioned on the input question and guides the LLM's response
generation accordingly. We extend DyPlan to DyPlan-verify, adding an internal
verification and correction process to further enrich the generated answer.
Experiments on three prominent multi-hop question answering (MHQA) datasets
reveal how DyPlan can improve model performance by 7-13% while reducing the
cost by 11-32% relative to the best baseline model.",2024-10-30,"Tanmay Parekh, Pradyot Prakash, Alexander Radovic, Akshay Shekher, Denis Savenkov",http://arxiv.org/pdf/2410.23511v2,cs.CL
Tiny Transformers Excel at Sentence Compression,"It is staggering that words of the English language, which are on average
represented by 5--6 bytes of ASCII, require as much as 24 kilobytes when served
to large language models. We show that there is room for more information in
every token embedding. We demonstrate that 1--3-layer transformers are capable
of encoding and subsequently decoding standard English sentences into as little
as a single 3-kilobyte token. Our work implies that even small networks can
learn to construct valid English sentences and suggests the possibility of
optimising large language models by moving from sub-word token embeddings
towards larger fragments of text.",2024-10-30,"Peter Belcak, Roger Wattenhofer",http://arxiv.org/pdf/2410.23510v1,cs.CL
Efficient and Interpretable Grammatical Error Correction with Mixture of Experts,"Error type information has been widely used to improve the performance of
grammatical error correction (GEC) models, whether for generating corrections,
re-ranking them, or combining GEC models. Combining GEC models that have
complementary strengths in correcting different error types is very effective
in producing better corrections. However, system combination incurs a high
computational cost due to the need to run inference on the base systems before
running the combination method itself. Therefore, it would be more efficient to
have a single model with multiple sub-networks that specialize in correcting
different error types. In this paper, we propose a mixture-of-experts model,
MoECE, for grammatical error correction. Our model successfully achieves the
performance of T5-XL with three times fewer effective parameters. Additionally,
our model produces interpretable corrections by also identifying the error type
during inference.",2024-10-30,"Muhammad Reza Qorib, Alham Fikri Aji, Hwee Tou Ng",http://arxiv.org/pdf/2410.23507v1,cs.CL
The Belief State Transformer,"We introduce the ""Belief State Transformer"", a next-token predictor that
takes both a prefix and suffix as inputs, with a novel objective of predicting
both the next token for the prefix and the previous token for the suffix. The
Belief State Transformer effectively learns to solve challenging problems that
conventional forward-only transformers struggle with, in a domain-independent
fashion. Key to this success is learning a compact belief state that captures
all relevant information necessary for accurate predictions. Empirical
ablations show that each component of the model is essential in difficult
scenarios where standard Transformers fall short. For the task of story writing
with known prefixes and suffixes, our approach outperforms the
Fill-in-the-Middle method for reaching known goals and demonstrates improved
performance even when the goals are unknown. Altogether, the Belief State
Transformer enables more efficient goal-conditioned decoding, better test-time
inference, and high-quality text representations on small scale problems.
Website: https://sites.google.com/view/belief-state-transformer",2024-10-30,"Edward S. Hu, Kwangjun Ahn, Qinghua Liu, Haoran Xu, Manan Tomar, Ada Langford, Dinesh Jayaraman, Alex Lamb, John Langford",http://arxiv.org/pdf/2410.23506v2,cs.CL
All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling,"We analyze identifiability as a possible explanation for the ubiquity of
linear properties across language models, such as the vector difference between
the representations of ""easy"" and ""easiest"" being parallel to that between
""lucky"" and ""luckiest"". For this, we ask whether finding a linear property in
one model implies that any model that induces the same distribution has that
property, too. To answer that, we first prove an identifiability result to
characterize distribution-equivalent next-token predictors, lifting a diversity
requirement of previous results. Second, based on a refinement of relational
linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how
many notions of linearity are amenable to our analysis. Finally, we show that
under suitable conditions, these linear properties either hold in all or none
distribution-equivalent next-token predictors.",2024-10-30,"Emanuele Marconato, Sébastien Lachapelle, Sebastian Weichwald, Luigi Gresele",http://arxiv.org/pdf/2410.23501v2,cs.CL
Smaller Large Language Models Can Do Moral Self-Correction,"Self-correction is one of the most amazing emerging capabilities of Large
Language Models (LLMs), enabling LLMs to self-modify an inappropriate output
given a natural language feedback which describes the problems of that output.
Moral self-correction is a post-hoc approach correcting unethical generations
without requiring a gradient update, making it both computationally lightweight
and capable of preserving the language modeling ability. Previous works have
shown that LLMs can self-debias, and it has been reported that small models,
i.e., those with less than 22B parameters, are not capable of moral
self-correction. However, there is no direct proof as to why such smaller
models fall short of moral self-correction, though previous research
hypothesizes that larger models are skilled in following instructions and
understanding abstract social norms. In this paper, we empirically validate
this hypothesis in the context of social stereotyping, through meticulous
prompting. Our experimental results indicate that (i) surprisingly, 3.8B LLMs
with proper safety alignment fine-tuning can achieve very good moral
self-correction performance, highlighting the significant effects of safety
alignment; and (ii) small LLMs are indeed weaker than larger-scale models in
terms of comprehending social norms and self-explanation through CoT, but all
scales of LLMs show bad self-correction performance given unethical
instructions.",2024-10-30,"Guangliang Liu, Zhiyu Xue, Xitong Zhang, Rongrong Wang, Kristen Marie Johnson",http://arxiv.org/pdf/2410.23496v2,cs.CL
Collage: Decomposable Rapid Prototyping for Information Extraction on Scientific PDFs,"Recent years in NLP have seen the continued development of domain-specific
information extraction tools for scientific documents, alongside the release of
increasingly multimodal pretrained transformer models. While the opportunity
for scientists outside of NLP to evaluate and apply such systems to their own
domains has never been clearer, these models are difficult to compare: they
accept different input formats, are often black-box and give little insight
into processing failures, and rarely handle PDF documents, the most common
format of scientific publication. In this work, we present Collage, a tool
designed for rapid prototyping, visualization, and evaluation of different
information extraction models on scientific PDFs. Collage allows the use and
evaluation of any HuggingFace token classifier, several LLMs, and multiple
other task-specific models out of the box, and provides extensible software
interfaces to accelerate experimentation with new models. Further, we enable
both developers and users of NLP-based tools to inspect, debug, and better
understand modeling pipelines by providing granular views of intermediate
states of processing. We demonstrate our system in the context of information
extraction to assist with literature review in materials science.",2024-10-30,"Sireesh Gururaja, Yueheng Zhang, Guannan Tang, Tianhao Zhang, Kevin Murphy, Yu-Tsen Yi, Junwon Seo, Anthony Rollett, Emma Strubell",http://arxiv.org/pdf/2410.23478v1,cs.CL
Generating Diverse Negations from Affirmative Sentences,"Despite the impressive performance of large language models across various
tasks, they often struggle with reasoning under negated statements. Negations
are important in real-world applications as they encode negative polarity in
verb phrases, clauses, or other expressions. Nevertheless, they are
underrepresented in current benchmarks, which mainly include basic negation
forms and overlook more complex ones, resulting in insufficient data for
training a language model. In this work, we propose NegVerse, a method that
tackles the lack of negation datasets by producing a diverse range of negation
types from affirmative sentences, including verbal, non-verbal, and affixal
forms commonly found in English text. We provide new rules for masking parts of
sentences where negations are most likely to occur, based on syntactic
structure and use a frozen baseline LLM and prompt tuning to generate negated
sentences. We also propose a filtering mechanism to identify negation cues and
remove degenerate examples, producing a diverse range of meaningful
perturbations. Our results show that NegVerse outperforms existing methods and
generates negations with higher lexical similarity to the original sentences,
better syntactic preservation and negation diversity. The code is available in
https://github.com/DarianRodriguez/NegVerse",2024-10-30,"Darian Rodriguez Vasquez, Afroditi Papadaki",http://arxiv.org/pdf/2411.00056v1,cs.CL
MDCure: A Scalable Pipeline for Multi-Document Instruction-Following,"Multi-document (MD) processing is crucial for LLMs to handle real-world tasks
such as summarization and question-answering across large sets of documents.
While LLMs have improved at processing long inputs, MD contexts still present
unique difficulties, including management of inter-document dependencies,
redundancy, and incoherent structures. To address this challenge, we introduce
MDCure, a scalable and effective instruction data generation framework to
enhance the MD capabilities of LLMs without the computational cost of
pre-training or reliance on human-annotated data. MDCure generates high-quality
synthetic MD instruction data over sets of articles via targeted prompts. We
also introduce MDCureRM, a cost-effective, MD-specific reward model to score
and filter generated data based on their training utility for MD settings.
MDCure is compatible with open- and closed-source models in addition to policy
optimization methods such as PPO, enabling even small open-source models to
surpass proprietary LLMs as strong generators of high-quality MD instruction
data without further data filtering. With MDCure, we fine-tune a wide variety
of LLMs up to 70B parameters in size from the FlanT5, Qwen2, and LLAMA3.1 model
families. Extensive evaluations on a wide range of MD and long-context
benchmarks spanning various tasks and domains show MDCure consistently improves
performance over pre-trained baselines and base models by up to 75.1%. Our
code, datasets, and models are available at https://github.com/yale-nlp/MDCure.",2024-10-30,"Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan",http://arxiv.org/pdf/2410.23463v3,cs.CL
Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document,"This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.",2024-10-30,"Vicky Dong, Hao Yu, Yao Chen",http://arxiv.org/pdf/2410.23452v1,cs.CL
Learning and Transferring Sparse Contextual Bigrams with Linear Transformers,"Transformers have excelled in natural language modeling and one reason behind
this success is their exceptional ability to combine contextual informal and
global knowledge. However, the theoretical basis remains unclear. In this
paper, first we introduce the Sparse Contextual Bigram (SCB), a natural
extension of the classical bigram model, where the next token's generation
depends on a sparse set of earlier positions determined by the last token. We
then analyze the training dynamics and sample complexity of learning SCB using
a one-layer linear transformer with a gradient-based algorithm. We show that
when trained from scratch, the training process can be split into an initial
sample-intensive stage where the correlation is boosted from zero to a
nontrivial value, followed by a more sample-efficient stage of further
improvement. Additionally, we prove that, provided a nontrivial correlation
between the downstream and pretraining tasks, finetuning from a pretrained
model allows us to bypass the initial sample-intensive stage. We also
empirically demonstrate that our algorithm can outperform SGD in this setting
and discuss its relationship with the usual softmax-based transformers.",2024-10-30,"Yunwei Ren, Zixuan Wang, Jason D. Lee",http://arxiv.org/pdf/2410.23438v1,cs.CL
Mind the Gap: A Generalized Approach for Cross-Modal Embedding Alignment,"Retrieval-Augmented Generation (RAG) systems enhance text generation by
incorporating external knowledge but often struggle when retrieving context
across different text modalities due to semantic gaps. We introduce a
generalized projection-based method, inspired by adapter modules in transfer
learning, that efficiently bridges these gaps between various text types, such
as programming code and pseudocode, or English and French sentences. Our
approach emphasizes speed, accuracy, and data efficiency, requiring minimal
resources for training and inference. By aligning embeddings from heterogeneous
text modalities into a unified space through a lightweight projection network,
our model significantly outperforms traditional retrieval methods like the
Okapi BM25 algorithm and models like Dense Passage Retrieval (DPR), while
approaching the accuracy of Sentence Transformers. Extensive evaluations
demonstrate the effectiveness and generalizability of our method across
different tasks, highlighting its potential for real-time, resource-constrained
applications.",2024-10-30,"Arihan Yadav, Alan McMillan",http://arxiv.org/pdf/2410.23437v1,cs.CL
Social Science Meets LLMs: How Reliable Are Large Language Models in Social Simulations?,"Large Language Models (LLMs) are increasingly employed for simulations,
enabling applications in role-playing agents and Computational Social Science
(CSS). However, the reliability of these simulations is under-explored, which
raises concerns about the trustworthiness of LLMs in these applications. In
this paper, we aim to answer ``How reliable is LLM-based simulation?'' To
address this, we introduce TrustSim, an evaluation dataset covering 10
CSS-related topics, to systematically investigate the reliability of the LLM
simulation. We conducted experiments on 14 LLMs and found that inconsistencies
persist in the LLM-based simulated roles. In addition, the consistency level of
LLMs does not strongly correlate with their general performance. To enhance the
reliability of LLMs in simulation, we proposed Adaptive Learning Rate Based
ORPO (AdaORPO), a reinforcement learning-based algorithm to improve the
reliability in simulation across 7 LLMs. Our research provides a foundation for
future studies to explore more robust and trustworthy LLM-based simulations.",2024-10-30,"Yue Huang, Zhengqing Yuan, Yujun Zhou, Kehan Guo, Xiangqi Wang, Haomin Zhuang, Weixiang Sun, Lichao Sun, Jindong Wang, Yanfang Ye, Xiangliang Zhang",http://arxiv.org/pdf/2410.23426v1,cs.CL
Demo-Craft: Using In-Context Learning to Improve Code Generation in Large Language Models,"Generating executable code from natural language instructions using Large
Language Models (LLMs) poses challenges such as semantic ambiguity and
understanding taskspecific contexts. To address these issues, we propose a
system called DemoCraft, which enhances code generation by leveraging
in-context learning and demonstration selection, combined with latent concept
learning. Latent concept learning introduces additional concept tokens, which
are trainable embeddings that capture task-specific knowledge. We then test our
system on two major datasets: MBPP and Humaneval. Our experimental results
demonstrate that the proposed system achieves an approximate 2x increase in the
pass@k metric compared to baseline models. Furthermore, we introduce two novel
evaluation metrics: correctness@k and similarity@k. Our empirical studies
indicate that our system attains nearly a 3x improvement in these metrics as
well.",2024-10-30,"Nirmal Joshua Kapu, Mihit Sreejith",http://arxiv.org/pdf/2411.00865v2,cs.CL
ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration,"Large language models (LLMs) have demonstrated a remarkable ability to serve
as general-purpose tools for various language-based tasks. Recent works have
demonstrated that the efficacy of such models can be improved through iterative
dialog between multiple models. While these paradigms show promise in improving
model efficacy, most works in this area treat collaboration as an emergent
behavior, rather than a learned behavior. In doing so, current multi-agent
frameworks rely on collaborative behaviors to have been sufficiently trained
into off-the-shelf models. To address this limitation, we propose ACC-Collab,
an Actor-Critic based learning framework to produce a two-agent team (an
actor-agent and a critic-agent) specialized in collaboration. We demonstrate
that ACC-Collab outperforms SotA multi-agent techniques on a wide array of
benchmarks.",2024-10-30,"Andrew Estornell, Jean-Francois Ton, Yuanshun Yao, Yang Liu",http://arxiv.org/pdf/2411.00053v3,cs.CL
Leveraging Language Models and Bandit Algorithms to Drive Adoption of Battery-Electric Vehicles,"Behavior change interventions are important to coordinate societal action
across a wide array of important applications, including the adoption of
electrified vehicles to reduce emissions. Prior work has demonstrated that
interventions for behavior must be personalized, and that the intervention that
is most effective on average across a large group can result in a backlash
effect that strengthens opposition among some subgroups. Thus, it is important
to target interventions to different audiences, and to present them in a
natural, conversational style. In this context, an important emerging
application domain for large language models (LLMs) is conversational
interventions for behavior change. In this work, we leverage prior work on
understanding values motivating the adoption of battery electric vehicles. We
leverage new advances in LLMs, combined with a contextual bandit, to develop
conversational interventions that are personalized to the values of each study
participant. We use a contextual bandit algorithm to learn to target values
based on the demographics of each participant. To train our bandit algorithm in
an offline manner, we leverage LLMs to play the role of study participants. We
benchmark the persuasive effectiveness of our bandit-enhanced LLM against an
unaided LLM generating conversational interventions without
demographic-targeted values.",2024-10-30,"Keiichi Namikoshi, David A. Shamma, Rumen Iliev, Jingchao Fang, Alexandre Filipowicz, Candice L Hogan, Charlene Wu, Nikos Arechiga",http://arxiv.org/pdf/2410.23371v1,cs.CL
Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation,"In the field of large language model (LLM)-based proof generation, despite
being trained on extensive corpora such as OpenWebMath and Arxiv, these models
still exhibit only modest performance on proving tasks of moderate difficulty.
We believe that this is partly due to the suboptimal order of each proof data
used in training. Published proofs often follow a purely logical order, where
each step logically proceeds from the previous steps based on the deductive
rules. However, this order aims to facilitate the verification of the proof's
soundness, rather than to help people and models learn the discovery process of
the proof. In proof generation, we argue that the optimal order for one
training data sample occurs when the relevant intermediate supervision for a
particular proof step in the proof is always positioned to the left of that
proof step. We call such order the intuitively sequential order. We validate
our claims using two tasks: intuitionistic propositional logic theorem-proving
and digit multiplication. Our experiments verify the order effect and provide
support for our explanations. We demonstrate that training is most effective
when the proof is in the intuitively sequential order. Moreover, the order
effect and the performance gap between models trained on different data orders
are substantial -- with an 11 percent improvement in proof success rate
observed in the propositional logic theorem-proving task, between models
trained on the optimal order compared to the worst order.",2024-10-30,"Chenyang An, Shima Imani, Feng Yao, Chengyu Dong, Ali Abbasi, Harsh Shrivastava, Samuel Buss, Jingbo Shang, Gayathri Mahalingam, Pramod Sharma, Maurice Diesendruck",http://arxiv.org/pdf/2411.00863v1,cs.CL
Can Models Help Us Create Better Models? Evaluating LLMs as Data Scientists,"We present a benchmark for large language models designed to tackle one of
the most knowledge-intensive tasks in data science: writing feature engineering
code, which requires domain knowledge in addition to a deep understanding of
the underlying problem and data structure. The model is provided with a dataset
description in a prompt and asked to generate code transforming it. The
evaluation score is derived from the improvement achieved by an XGBoost model
fit on the modified dataset compared to the original data. By an extensive
evaluation of state-of-the-art models and comparison to well-established
benchmarks, we demonstrate that the FeatEng of our proposal can cheaply and
efficiently assess the broad capabilities of LLMs, in contrast to the existing
methods.",2024-10-30,"Michał Pietruszka, Łukasz Borchmann, Aleksander Jędrosz, Paweł Morawiecki",http://arxiv.org/pdf/2410.23331v1,cs.CL
Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation,"This work focuses on the efficiency of the knowledge distillation approach in
generating a lightweight yet powerful BERT based model for natural language
processing applications. After the model creation, we applied the resulting
model, LastBERT, to a real-world task classifying severity levels of Attention
Deficit Hyperactivity Disorder (ADHD)-related concerns from social media text
data. Referring to LastBERT, a customized student BERT model, we significantly
lowered model parameters from 110 million BERT base to 29 million, resulting in
a model approximately 73.64% smaller. On the GLUE benchmark, comprising
paraphrase identification, sentiment analysis, and text classification, the
student model maintained strong performance across many tasks despite this
reduction. The model was also used on a real-world ADHD dataset with an
accuracy and F1 score of 85%. When compared to DistilBERT (66M) and
ClinicalBERT (110M), LastBERT demonstrated comparable performance, with
DistilBERT slightly outperforming it at 87%, and ClinicalBERT achieving 86%
across the same metrics. These findings highlight the LastBERT model's capacity
to classify degrees of ADHD severity properly, so it offers a useful tool for
mental health professionals to assess and comprehend material produced by users
on social networking platforms. The study emphasizes the possibilities of
knowledge distillation to produce effective models fit for use in
resource-limited conditions, hence advancing NLP and mental health diagnosis.
Furthermore underlined by the considerable decrease in model size without
appreciable performance loss is the lower computational resources needed for
training and deployment, hence facilitating greater applicability. Especially
using readily available computational tools like Google Colab. This study shows
the accessibility and usefulness of advanced NLP methods in pragmatic world
applications.",2024-10-30,"Ahmed Akib Jawad Karim, Kazi Hafiz Md. Asad, Md. Golam Rabiul Alam",http://arxiv.org/pdf/2411.00052v1,cs.CL
SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation,"Human beings are endowed with a complementary learning system, which bridges
the slow learning of general world dynamics with fast storage of episodic
memory from a new experience. Previous video generation models, however,
primarily focus on slow learning by pre-training on vast amounts of data,
overlooking the fast learning phase crucial for episodic memory storage. This
oversight leads to inconsistencies across temporally distant frames when
generating longer videos, as these frames fall beyond the model's context
window. To this end, we introduce SlowFast-VGen, a novel dual-speed learning
system for action-driven long video generation. Our approach incorporates a
masked conditional video diffusion model for the slow learning of world
dynamics, alongside an inference-time fast learning strategy based on a
temporal LoRA module. Specifically, the fast learning process updates its
temporal LoRA parameters based on local inputs and outputs, thereby efficiently
storing episodic memory in its parameters. We further propose a slow-fast
learning loop algorithm that seamlessly integrates the inner fast learning loop
into the outer slow learning loop, enabling the recall of prior multi-episode
experiences for context-aware skill learning. To facilitate the slow learning
of an approximate world model, we collect a large-scale dataset of 200k videos
with language action annotations, covering a wide range of scenarios. Extensive
experiments show that SlowFast-VGen outperforms baselines across various
metrics for action-driven video generation, achieving an FVD score of 514
compared to 782, and maintaining consistency in longer videos, with an average
of 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm
significantly enhances performances on long-horizon planning tasks as well.
Project Website: https://slowfast-vgen.github.io",2024-10-30,"Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Linjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang",http://arxiv.org/pdf/2410.23277v2,cs.CL
TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models,"Existing benchmarks often highlight the remarkable performance achieved by
state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal
context for video understanding. However, how well do the models truly perform
visual temporal reasoning? Our study of existing benchmarks shows that this
capability of MFMs is likely overestimated as many questions can be solved by
using a single, few, or out-of-order frames. To systematically examine current
visual temporal reasoning tasks, we propose three principles with corresponding
metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame
Information Disparity. Following these principles, we introduce TOMATO,
Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to
rigorously assess MFMs' temporal reasoning capabilities in video understanding.
TOMATO comprises 1,484 carefully curated, human-annotated questions spanning
six tasks (i.e., action count, direction, rotation, shape & trend, velocity &
frequency, and visual cues), applied to 1,417 videos, including 805
self-recorded and -generated videos, that encompass human-centric, real-world,
and simulated scenarios. Our comprehensive evaluation reveals a human-model
performance gap of 57.3% with the best-performing model. Moreover, our in-depth
analysis uncovers more fundamental limitations beyond this gap in current MFMs.
While they can accurately recognize events in isolated frames, they fail to
interpret these frames as a continuous sequence. We believe TOMATO will serve
as a crucial testbed for evaluating the next-generation MFMs and as a call to
the community to develop AI systems capable of comprehending human world
dynamics through the video modality.",2024-10-30,"Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan",http://arxiv.org/pdf/2410.23266v1,cs.CL
EMMA: End-to-End Multimodal Model for Autonomous Driving,"We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.",2024-10-30,"Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan",http://arxiv.org/pdf/2410.23262v2,cs.CL
$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources,"Pre-training is notoriously compute-intensive and academic researchers are
notoriously under-resourced. It is, therefore, commonly assumed that academics
can't pre-train models. In this paper, we seek to clarify this assumption. We
first survey academic researchers to learn about their available compute and
then empirically measure the time to replicate models on such resources. We
introduce a benchmark to measure the time to pre-train models on given GPUs and
also identify ideal settings for maximizing training speed. We run our
benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on
our experiments. Our results reveal a brighter picture for academic
pre-training: for example, although Pythia-1B was originally trained on 64 GPUs
for 3 days, we find it is also possible to replicate this model (with the same
hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We conclude
with a cost-benefit analysis to help clarify the trade-offs between price and
pre-training time. We believe our benchmark will help academic researchers
conduct experiments that require training larger models on more data. We fully
release our codebase at: https://github.com/apoorvkh/academic-pretraining.",2024-10-30,"Apoorv Khandelwal, Tian Yun, Nihal V. Nayak, Jack Merullo, Stephen H. Bach, Chen Sun, Ellie Pavlick",http://arxiv.org/pdf/2410.23261v1,cs.CL
Evaluating Cultural and Social Awareness of LLM Web Agents,"As large language models (LLMs) expand into performing as agents for
real-world applications beyond traditional NLP tasks, evaluating their
robustness becomes increasingly important. However, existing benchmarks often
overlook critical dimensions like cultural and social awareness. To address
these, we introduce CASA, a benchmark designed to assess LLM agents'
sensitivity to cultural and social norms across two web-based tasks: online
shopping and social discussion forums. Our approach evaluates LLM agents'
ability to detect and appropriately respond to norm-violating user queries and
observations. Furthermore, we propose a comprehensive evaluation framework that
measures awareness coverage, helpfulness in managing user queries, and the
violation rate when facing misleading web content. Experiments show that
current LLMs perform significantly better in non-agent than in web-based agent
environments, with agents achieving less than 10% awareness coverage and over
40% violation rates. To improve performance, we explore two methods: prompting
and fine-tuning, and find that combining both methods can offer complementary
advantages -- fine-tuning on culture-specific datasets significantly enhances
the agents' ability to generalize across different regions, while prompting
boosts the agents' ability to navigate complex tasks. These findings highlight
the importance of constantly benchmarking LLM agents' cultural and social
awareness during the development cycle.",2024-10-30,"Haoyi Qiu, Alexander R. Fabbri, Divyansh Agarwal, Kung-Hsiang Huang, Sarah Tan, Nanyun Peng, Chien-Sheng Wu",http://arxiv.org/pdf/2410.23252v3,cs.CL
COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences,"Many alignment methods, including reinforcement learning from human feedback
(RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to
capture the full range of general human preferences. To achieve robust
alignment with general preferences, we model the alignment problem as a
two-player zero-sum game, where the Nash equilibrium policy guarantees a 50%
win rate against any competing policy. However, previous algorithms for finding
the Nash policy either diverge or converge to a Nash policy in a modified game,
even in a simple synthetic setting, thereby failing to maintain the 50% win
rate guarantee against all other policies. We propose a meta-algorithm,
Convergent Meta Alignment Algorithm (COMAL), for language model alignment with
general preferences, inspired by convergent algorithms in game theory.
Theoretically, we prove that our meta-algorithm converges to an exact Nash
policy in the last iterate. Additionally, our meta-algorithm is simple and can
be integrated with many existing methods designed for RLHF and preference
optimization with minimal changes. Experimental results demonstrate the
effectiveness of the proposed framework when combined with existing preference
policy optimization methods.",2024-10-30,"Yixin Liu, Argyris Oikonomou, Weiqiang Zheng, Yang Cai, Arman Cohan",http://arxiv.org/pdf/2410.23223v1,cs.CL
OS-ATLAS: A Foundation Action Model for Generalist GUI Agents,"Existing efforts in building GUI agents heavily rely on the availability of
robust commercial Vision-Language Models (VLMs) such as GPT-4o and
GeminiProVision. Practitioners are often reluctant to use open-source VLMs due
to their significant performance lag compared to their closed-source
counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD)
scenarios. To facilitate future research in this area, we developed OS-Atlas -
a foundational GUI action model that excels at GUI grounding and OOD agentic
tasks through innovations in both data and modeling. We have invested
significant engineering effort in developing an open-source toolkit for
synthesizing GUI grounding data across multiple platforms, including Windows,
Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing
the largest open-source cross-platform GUI grounding corpus to date, which
contains over 13 million GUI elements. This dataset, combined with innovations
in model training, provides a solid foundation for OS-Atlas to understand GUI
screenshots and generalize to unseen interfaces. Through extensive evaluation
across six benchmarks spanning three different platforms (mobile, desktop, and
web), OS-Atlas demonstrates significant performance improvements over previous
state-of-the-art models. Our evaluation also uncovers valuable insights into
continuously improving and scaling the agentic capabilities of open-source
VLMs.",2024-10-30,"Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, Yian Wang, Qiushi Sun, Chengyou Jia, Kanzhi Cheng, Zichen Ding, Liheng Chen, Paul Pu Liang, Yu Qiao",http://arxiv.org/pdf/2410.23218v1,cs.CL
Reliability of Topic Modeling,"Topic models allow researchers to extract latent factors from text data and
use those variables in downstream statistical analyses. However, these
methodologies can vary significantly due to initialization differences,
randomness in sampling procedures, or noisy data. Reliability of these methods
is of particular concern as many researchers treat learned topic models as
ground truth for subsequent analyses. In this work, we show that the standard
practice for quantifying topic model reliability fails to capture essential
aspects of the variation in two widely-used topic models. Drawing from a
extensive literature on measurement theory, we provide empirical and
theoretical analyses of three other metrics for evaluating the reliability of
topic models. On synthetic and real-world data, we show that McDonald's
$\omega$ provides the best encapsulation of reliability. This metric provides
an essential tool for validation of topic model methodologies that should be a
standard component of any topic model-based research.",2024-10-30,"Kayla Schroeder, Zach Wood-Doughty",http://arxiv.org/pdf/2410.23186v2,cs.CL
ProTransformer: Robustify Transformers via Plug-and-Play Paradigm,"Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.",2024-10-30,"Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu",http://arxiv.org/pdf/2410.23182v1,cs.CL
Survey of Cultural Awareness in Language Models: Text and Beyond,"Large-scale deployment of large language models (LLMs) in various
applications, such as chatbots and virtual assistants, requires LLMs to be
culturally sensitive to the user to ensure inclusivity. Culture has been widely
studied in psychology and anthropology, and there has been a recent surge in
research on making LLMs more culturally inclusive in LLMs that goes beyond
multilinguality and builds on findings from psychology and anthropology. In
this paper, we survey efforts towards incorporating cultural awareness into
text-based and multimodal LLMs. We start by defining cultural awareness in
LLMs, taking the definitions of culture from anthropology and psychology as a
point of departure. We then examine methodologies adopted for creating
cross-cultural datasets, strategies for cultural inclusion in downstream tasks,
and methodologies that have been used for benchmarking cultural awareness in
LLMs. Further, we discuss the ethical implications of cultural alignment, the
role of Human-Computer Interaction in driving cultural inclusion in LLMs, and
the role of cultural alignment in driving social science research. We finally
provide pointers to future research based on our findings about gaps in the
literature.",2024-10-30,"Siddhesh Pawar, Junyeong Park, Jiho Jin, Arnav Arora, Junho Myung, Srishti Yadav, Faiz Ghifari Haznitrama, Inhwa Song, Alice Oh, Isabelle Augenstein",http://arxiv.org/pdf/2411.00860v1,cs.CL
SciPIP: An LLM-based Scientific Paper Idea Proposer,"The rapid advancement of large language models (LLMs) has opened new
possibilities for automating the proposal of innovative scientific ideas. This
process involves two key phases: literature retrieval and idea generation.
However, existing approaches often fall short due to their reliance on
keyword-based search tools during the retrieval phase, which neglects crucial
semantic information and frequently results in incomplete retrieval outcomes.
Similarly, in the idea generation phase, current methodologies tend to depend
solely on the internal knowledge of LLMs or metadata from retrieved papers,
thereby overlooking significant valuable insights contained within the full
texts. To address these limitations, we introduce SciPIP, an innovative
framework designed to enhance the LLM-based proposal of scientific ideas
through improvements in both literature retrieval and idea generation. Our
approach begins with the construction of a comprehensive literature database
that supports advanced retrieval based not only on keywords but also on
semantics and citation relationships. This is complemented by the introduction
of a multi-granularity retrieval algorithm aimed at ensuring more thorough and
exhaustive retrieval results. For the idea generation phase, we propose a
dual-path framework that effectively integrates both the content of retrieved
papers and the extensive internal knowledge of LLMs. This integration
significantly boosts the novelty, feasibility, and practical value of proposed
ideas. Our experiments, conducted across various domains such as natural
language processing and computer vision, demonstrate SciPIP's capability to
generate a multitude of innovative and useful ideas. These findings underscore
SciPIP's potential as a valuable tool for researchers seeking to advance their
fields with groundbreaking concepts.",2024-10-30,"Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang Xie, Binbin Lin, Xiaofei He, Jieping Ye",http://arxiv.org/pdf/2410.23166v2,cs.CL
"The Good, the Bad, and the Ugly: The Role of AI Quality Disclosure in Lie Detection","We investigate how low-quality AI advisors, lacking quality disclosures, can
help spread text-based lies while seeming to help people detect lies.
Participants in our experiment discern truth from lies by evaluating
transcripts from a game show that mimicked deceptive social media exchanges on
topics with objective truths. We find that when relying on low-quality advisors
without disclosures, participants' truth-detection rates fall below their own
abilities, which recovered once the AI's true effectiveness was revealed.
Conversely, high-quality advisor enhances truth detection, regardless of
disclosure. We discover that participants' expectations about AI capabilities
contribute to their undue reliance on opaque, low-quality advisors.",2024-10-30,"Haimanti Bhattacharya, Subhasish Dugar, Sanchaita Hazra, Bodhisattwa Prasad Majumder",http://arxiv.org/pdf/2410.23143v2,cs.CL
Crowdsourcing Lexical Diversity,"Lexical-semantic resources (LSRs), such as online lexicons or wordnets, are
fundamental for natural language processing applications. In many languages,
however, such resources suffer from quality issues: incorrect entries,
incompleteness, but also, the rarely addressed issue of bias towards the
English language and Anglo-Saxon culture. Such bias manifests itself in the
absence of concepts specific to the language or culture at hand, the presence
of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit
indication of untranslatability, also known as cross-lingual \emph{lexical
gaps}, when a term has no equivalent in another language. This paper proposes a
novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers
compare lexemes from two languages, focusing on domains rich in lexical
diversity, such as kinship or food. Our LingoGap crowdsourcing tool facilitates
comparisons through microtasks identifying equivalent terms, language-specific
terms, and lexical gaps across languages. We validated our method by applying
it to two case studies focused on food-related terminology: (1) English and
Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified
2,140 lexical gaps in the first case study and 951 in the second. The success
of these experiments confirmed the usability of our method and tool for future
large-scale lexicon enrichment tasks.",2024-10-30,"Hadi Khalilia, Jahna Otterbacher, Gabor Bella, Rusma Noortyani, Shandy Darma, Fausto Giunchiglia",http://arxiv.org/pdf/2410.23133v1,cs.CL
On Memorization of Large Language Models in Logical Reasoning,"Large language models (LLMs) achieve good performance on challenging
reasoning benchmarks, yet could also make basic reasoning mistakes. This
contrasting behavior is puzzling when it comes to understanding the mechanisms
behind LLMs' reasoning capabilities. One hypothesis is that the increasingly
high and nearly saturated performance on common reasoning benchmarks could be
due to the memorization of similar problems. In this paper, we systematically
investigate this hypothesis with a quantitative measurement of memorization in
reasoning tasks, using a dynamically generated logical reasoning benchmark
based on Knights and Knaves (K&K) puzzles. We find that LLMs could interpolate
and memorize the training puzzles (achieving near-perfect accuracy) after
fine-tuning, yet they struggle with slight variations of these puzzles. On the
other hand, we show that while fine-tuning leads to heavy memorization, it also
consistently improves generalization performance. Through in-depth analyses
with perturbation tests, cross difficulty-level transferability, probing model
internals, and fine-tuning with wrong answers, we establish that LLMs develop
reasoning skills on K&K puzzles alongside memorization. Finally, our analysis
based on a per-sample memorization score sheds light on how LLMs switch between
reasoning and memorization when solving logical puzzles. Our code and data are
available at https://memkklogic.github.io.",2024-10-30,"Chulin Xie, Yangsibo Huang, Chiyuan Zhang, Da Yu, Xinyun Chen, Bill Yuchen Lin, Bo Li, Badih Ghazi, Ravi Kumar",http://arxiv.org/pdf/2410.23123v2,cs.CL
Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set,"Language models can achieve high accuracy on natural language tasks such as
NLI, but performance suffers on manually created adversarial examples. We
investigate the performance of a language model trained on the Stanford Natural
Language Inference (SNLI) corpus on a manually created adversarial test set. We
then improve the model's performance by fine tuning the model on a small,
manually created adversarial training set, designed to help the language model
to learn to differentiate between similar words and phrases in the data. We
show an increase in accuracy on the adversarial test set (+ 13%) while still
maintaining good performance on the original NLI task. We also show an increase
in accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI
test set (as judged by cosine similarity).",2024-10-30,Chris Achard,http://arxiv.org/pdf/2410.23118v1,cs.CL
Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models,"Despite the outstanding performance in vision-language reasoning, Large
Vision-Language Models (LVLMs) might generate hallucinated contents that do not
exist in the given image. Most existing LVLM hallucination benchmarks are
constrained to evaluate the object-related hallucinations. However, the
potential hallucination on the relations between two objects, i.e., relation
hallucination, still lacks investigation. To remedy that, in this paper we
design a unified framework to measure object and relation hallucination in
LVLMs simultaneously. The core idea of our framework is to conduct
hallucination evaluation on (object, relation, object) triplets extracted from
LVLMs' responses, and thus, could be easily generalized to different
vision-language tasks. Based on our framework, we further introduce Tri-HE, a
novel Triplet-level Hallucination Evaluation benchmark which can be used to
study both object and relation hallucination at the same time. We conduct
comprehensive evaluations on Tri-HE and observe that the relation hallucination
issue is even more serious than object hallucination among existing LVLMs,
highlighting a previously neglected problem towards reliable LVLMs. Moreover,
based on our findings, we design a simple yet effective training-free approach
to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced
counterparts on Tri-HE, achieving comparable performance with the powerful
GPT-4V. Our dataset and code for the reproduction of our experiments are
available publicly at https://github.com/wujunjie1998/Tri-HE.",2024-10-30,"Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung",http://arxiv.org/pdf/2410.23114v2,cs.CL
Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning,"In-context learning can help Large Language Models (LLMs) to adapt new tasks
without additional training. However, this performance heavily depends on the
quality of the demonstrations, driving research into effective demonstration
selection algorithms to optimize this process. These algorithms assist users in
selecting the best $k$ input-label pairs (demonstration examples) based on a
given test input, enabling LLMs to in-context learn the relationship between
the provided examples and the test inputs. Despite all the proposed
demonstration selection algorithms, their efficiency and effectiveness remain
unclear. This lack of clarity make it difficult to apply these algorithms in
real-world scenarios and poses challenges for future research aimed at
developing improved methods. This paper revisits six proposed algorithms,
evaluating them on five datasets from both efficiency and effectiveness
perspectives. Our experiments reveal significant variations in algorithm
performance across different tasks, with some methods struggling to outperform
random selection in certain scenarios. We also find that increasing the number
of demonstrations does not always lead to better performance, and that there
are often trade-offs between accuracy and computational efficiency. Our code is
available at https://github.com/Tizzzzy/Demonstration_Selection_Overview.",2024-10-30,"Dong Shu, Mengnan Du",http://arxiv.org/pdf/2410.23099v1,cs.CL
CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation,"Retrieval-Augmented Generation (RAG) has become a powerful paradigm for
enhancing large language models (LLMs) through external knowledge retrieval.
Despite its widespread attention, existing academic research predominantly
focuses on single-turn RAG, leaving a significant gap in addressing the
complexities of multi-turn conversations found in real-world applications. To
bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess
RAG systems in realistic multi-turn conversational settings. CORAL includes
diverse information-seeking conversations automatically derived from Wikipedia
and tackles key challenges such as open-domain coverage, knowledge intensity,
free-form responses, and topic shifts. It supports three core tasks of
conversational RAG: passage retrieval, response generation, and citation
labeling. We propose a unified framework to standardize various conversational
RAG methods and conduct a comprehensive evaluation of these methods on CORAL,
demonstrating substantial opportunities for improving existing approaches.",2024-10-30,"Yiruo Cheng, Kelong Mao, Ziliang Zhao, Guanting Dong, Hongjin Qian, Yongkang Wu, Tetsuya Sakai, Ji-Rong Wen, Zhicheng Dou",http://arxiv.org/pdf/2410.23090v1,cs.CL
BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference,"Large language models (LLMs) are essential in natural language processing but
often struggle with inference speed and computational efficiency, limiting
real-time deployment. The key-value (KV) cache mechanism reduces computational
overhead in transformer models, but challenges in maintaining contextual
understanding remain. In this paper, we propose BUZZ, a novel KV caching
algorithm that leverages structured contextual information to minimize cache
memory usage while enhancing inference speed. BUZZ employs a beehive-structured
sparse cache, incorporating a sliding window to capture recent information and
dynamically segmenting historical tokens into chunks to prioritize important
tokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:
CNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ
(1) reduces cache memory usage by $\textbf{2.5}\times$ in LLM inference while
maintaining over 99% accuracy in long-text summarization, and (2) surpasses
state-of-the-art performance in multi-document question answering by
$\textbf{7.69%}$ under the same memory limit, where full cache methods
encounter out-of-memory issues. Additionally, BUZZ achieves significant
inference speedup with a $\log{n}$ time complexity. The code is available at
https://github.com/JunqiZhao888/buzz-llm.",2024-10-30,"Junqi Zhao, Zhijin Fang, Shu Li, Shaohui Yang, Shichao He",http://arxiv.org/pdf/2410.23079v1,cs.CL
Multi-Programming Language Sandbox for LLMs,"We introduce MPLSandbox, an out-of-the-box multi-programming language sandbox
designed to provide unified and comprehensive feedback from compiler and
analysis tools for Large Language Models (LLMs). It can automatically identify
the programming language of the code, compiling and executing it within an
isolated sub-sandbox to ensure safety and stability. In addition, MPLSandbox
also integrates both traditional and LLM-based code analysis tools, providing a
comprehensive analysis of generated code. MPLSandbox can be effortlessly
integrated into the training and deployment of LLMs to improve the quality and
correctness of their generated code. It also helps researchers streamline their
workflows for various LLM-based code-related tasks, reducing the development
cost. To validate the effectiveness of MPLSandbox, we integrate it into
training and deployment approaches, and also employ it to optimize workflows
for a wide range of real-world code-related tasks. Our goal is to enhance
researcher productivity on LLM-based code-related tasks by simplifying and
automating workflows through delegation to MPLSandbox.",2024-10-30,"Shihan Dou, Jiazheng Zhang, Jianxiang Zang, Yunbo Tao, Weikang Zhou, Haoxiang Jia, Shichun Liu, Yuming Yang, Zhiheng Xi, Shenxi Wu, Shaoqing Zhang, Muling Wu, Changze Lv, Limao Xiong, Wenyu Zhan, Lin Zhang, Rongxiang Weng, Jingang Wang, Xunliang Cai, Yueming Wu, Ming Wen, Rui Zheng, Tao Ji, Yixin Cao, Tao Gui, Xipeng Qiu, Qi Zhang, Xuanjing Huang",http://arxiv.org/pdf/2410.23074v2,cs.CL
Vision-Language Models Can Self-Improve Reasoning via Reflection,"Chain-of-thought (CoT) has proven to improve the reasoning capability of
large language models (LLMs). However, due to the complexity of multimodal
scenarios and the difficulty in collecting high-quality CoT data, CoT reasoning
in multimodal LLMs has been largely overlooked. To this end, we propose a
simple yet effective self-training framework, R3V, which iteratively enhances
the model's Vision-language Reasoning by Reflecting on CoT Rationales. Our
framework consists of two interleaved parts: (1) iteratively bootstrapping
positive and negative solutions for reasoning datasets, and (2) reflection on
rationale for learning from mistakes. Specifically, we introduce the
self-refine and self-select losses, enabling the model to refine flawed
rationale and derive the correct answer by comparing rationale candidates.
Experiments on a wide range of vision-language tasks show that R3V consistently
improves multimodal LLM reasoning, achieving a relative improvement of 23 to 60
percent over GPT-distilled baselines. Additionally, our approach supports
self-reflection on generated solutions, further boosting performance through
test-time computation.",2024-10-30,"Kanzhi Cheng, Yantao Li, Fangzhi Xu, Jianbing Zhang, Hao Zhou, Yang Liu",http://arxiv.org/pdf/2411.00855v1,cs.CL
"Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification","State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely
heavily on multi-label attention layers to focus on key tokens in input text,
but obtaining optimal attention weights is challenging and resource-intensive.
To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a
novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses
existing state-of-the-art methods across all metrics on mimicfull, mimicfifty,
mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot
scenarios, outperforming previous models specifically designed for few-shot
scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36
percentage points on mimicfew, demonstrating its superior capability in
handling rare codes. PLANT also shows remarkable data efficiency in few-shot
scenarios, achieving precision comparable to traditional models with
significantly less data. These results are achieved through key technical
innovations: leveraging a pretrained Learning-to-Rank model as the planted
attention layer, integrating mutual-information gain to enhance attention,
introducing an inattention mechanism, and implementing a stateful-decoder to
maintain context. Comprehensive ablation studies validate the importance of
these contributions in realizing the performance gains.",2024-10-30,"Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu",http://arxiv.org/pdf/2410.23066v1,cs.CL
Controlling Language and Diffusion Models by Transporting Activations,"The increasing capabilities of large generative models and their ever more
widespread deployment have raised concerns about their reliability, safety, and
potential misuse. To address these issues, recent works have proposed to
control model generation by steering model activations in order to effectively
induce or prevent the emergence of concepts or behaviors in the generated
output. In this paper we introduce Activation Transport (AcT), a general
framework to steer activations guided by optimal transport theory that
generalizes many previous activation-steering works. AcT is modality-agnostic
and provides fine-grained control over the model behavior with negligible
computational overhead, while minimally impacting model abilities. We
experimentally show the effectiveness and versatility of our approach by
addressing key challenges in large language models (LLMs) and text-to-image
diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate
toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,
we show how AcT enables fine-grained style control and concept negation.",2024-10-30,"Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zappella, Nicholas Apostoloff, Marco Cuturi, Xavier Suau",http://arxiv.org/pdf/2410.23054v2,cs.CL
Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback,"Automatically synthesizing dense rewards from natural language descriptions
is a promising paradigm in reinforcement learning (RL), with applications to
sparse reward problems, open-ended exploration, and hierarchical skill design.
Recent works have made promising steps by exploiting the prior knowledge of
large language models (LLMs). However, these approaches suffer from important
limitations: they are either not scalable to problems requiring billions of
environment samples, due to requiring LLM annotations for each observation, or
they require a diverse offline dataset, which may not exist or be impossible to
collect. In this work, we address these limitations through a combination of
algorithmic and systems-level contributions. We propose \oni, a distributed
architecture that simultaneously learns an RL policy and an intrinsic reward
function using LLM feedback. Our approach annotates the agent's collected
experience via an asynchronous LLM server, which is then distilled into an
intrinsic reward model. We explore a range of algorithmic choices for reward
modeling with varying complexity, including hashing, classification, and
ranking models. By studying their relative tradeoffs, we shed light on
questions regarding intrinsic reward design for sparse reward problems. Our
approach achieves state-of-the-art performance across a range of challenging,
sparse reward tasks from the NetHack Learning Environment in a simple unified
process, solely using the agent's gathered experience, without requiring
external datasets. We make our code available at
\url{https://github.com/facebookresearch/oni}.",2024-10-30,"Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos",http://arxiv.org/pdf/2410.23022v2,cs.CL
Long$^2$RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall,"Retrieval-augmented generation (RAG) is a promising approach to address the
limitations of fixed knowledge in large language models (LLMs). However,
current benchmarks for evaluating RAG systems suffer from two key deficiencies:
(1) they fail to adequately measure LLMs' capability in handling long-context
retrieval due to a lack of datasets that reflect the characteristics of
retrieved documents, and (2) they lack a comprehensive evaluation method for
assessing LLMs' ability to generate long-form responses that effectively
exploits retrieved information. To address these shortcomings, we introduce the
Long$^2$RAG benchmark and the Key Point Recall (KPR) metric. Long$^2$RAG
comprises 280 questions spanning 10 domains and across 8 question categories,
each associated with 5 retrieved documents with an average length of 2,444
words. KPR evaluates the extent to which LLMs incorporate key points extracted
from the retrieved documents into their generated responses, providing a more
nuanced assessment of their ability to exploit retrieved information.",2024-10-30,"Zehan Qi, Rongwu Xu, Zhijiang Guo, Cunxiang Wang, Hao Zhang, Wei Xu",http://arxiv.org/pdf/2410.23000v3,cs.CL
VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning,"Although previous research on large language models (LLMs) and large
multi-modal models (LMMs) has systematically explored mathematical
problem-solving (MPS) within visual contexts, the analysis of how these models
process visual information during problem-solving remains insufficient. To
address this gap, we present VisAidMath, a benchmark for evaluating the MPS
process related to visual information. We follow a rigorous data curation
pipeline involving both automated processes and manual annotations to ensure
data quality and reliability. Consequently, this benchmark includes 1,200
challenging problems from various mathematical branches, vision-aid
formulations, and difficulty levels, collected from diverse sources such as
textbooks, examination papers, and Olympiad problems. Based on the proposed
benchmark, we conduct comprehensive evaluations on ten mainstream LLMs and
LMMs, highlighting deficiencies in the visual-aided reasoning process. For
example, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning
task, even with a drop of 2 points when provided with golden visual aids.
In-depth analysis reveals that the main cause of deficiencies lies in
hallucination regarding the implicit visual reasoning process, shedding light
on future research directions in the visual-aided MPS process.",2024-10-30,"Jingkun Ma, Runzhe Zhan, Derek F. Wong, Yang Li, Di Sun, Hou Pong Chan, Lidia S. Chao",http://arxiv.org/pdf/2410.22995v1,cs.CL
Accelerated AI Inference via Dynamic Execution Methods,"In this paper, we focus on Dynamic Execution techniques that optimize the
computation flow based on input. This aims to identify simpler problems that
can be solved using fewer resources, similar to human cognition. The techniques
discussed include early exit from deep networks, speculative sampling for
language models, and adaptive steps for diffusion models. Experimental results
demonstrate that these dynamic approaches can significantly improve latency and
throughput without compromising quality. When combined with model-based
optimizations, such as quantization, dynamic execution provides a powerful
multi-pronged strategy to optimize AI inference.
  Generative AI requires a large amount of compute resources. This is expected
to grow, and demand for resources in data centers through to the edge is
expected to continue to increase at high rates. We take advantage of existing
research and provide additional innovations for some generative optimizations.
In the case of LLMs, we provide more efficient sampling methods that depend on
the complexity of the data. In the case of diffusion model generation, we
provide a new method that also leverages the difficulty of the input prompt to
predict an optimal early stopping point.
  Therefore, dynamic execution methods are relevant because they add another
dimension of performance optimizations. Performance is critical from a
competitive point of view, but increasing capacity can result in significant
power savings and cost savings. We have provided several integrations of these
techniques into several Intel performance libraries and Huggingface Optimum.
These integrations will make them easier to use and increase the adoption of
these techniques.",2024-10-30,"Haim Barad, Jascha Achterberg, Tien Pei Chou, Jean Yu",http://arxiv.org/pdf/2411.00853v1,cs.CL
Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution,"In this work, we present two systems -- Named Entity Resolution (NER) and
Natural Language Inference (NLI) -- for detecting legal violations within
unstructured textual data and for associating these violations with potentially
affected individuals, respectively. Both these systems are lightweight DeBERTa
based encoders that outperform the LLM baselines. The proposed NER system
achieved an F1 score of 60.01\% on Subtask A of the LegalLens challenge, which
focuses on identifying violations. The proposed NLI system achieved an F1 score
of 84.73\% on Subtask B of the LegalLens challenge, which focuses on resolving
these violations by matching them with pre-existing legal complaints of class
action cases. Our NER system ranked sixth and NLI system ranked fifth on the
LegalLens leaderboard. We release the trained models and inference scripts.",2024-10-30,Shikha Bordia,http://arxiv.org/pdf/2410.22977v1,cs.CL
Private Synthetic Text Generation with Diffusion Models,"How capable are diffusion models of generating synthetics texts? Recent
research shows their strengths, with performance reaching that of
auto-regressive LLMs. But are they also good in generating synthetic data if
the training was under differential privacy? Here the evidence is missing, yet
the promises from private image generation look strong. In this paper we
address this open question by extensive experiments. At the same time, we
critically assess (and reimplement) previous works on synthetic private text
generation with LLMs and reveal some unmet assumptions that might have led to
violating the differential privacy guarantees. Our results partly contradict
previous non-private findings and show that fully open-source LLMs outperform
diffusion models in the privacy regime. Our complete source codes, datasets,
and experimental setup is publicly available to foster future research.",2024-10-30,"Sebastian Ochs, Ivan Habernal",http://arxiv.org/pdf/2410.22971v1,cs.CL
"Focus On This, Not That! Steering LLMs With Adaptive Feature Specification","Despite the success of Instruction Tuning (IT) in training large language
models (LLMs) to perform arbitrary user-specified tasks, these models often
still leverage spurious or biased features learned from their training data,
leading to undesired behaviours when deploying them in new contexts. In this
work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to
condition their responses by focusing on specific features whilst ignoring
others, leading to different behaviours based on what features are specified.
Across several experimental settings, we show that focus-tuned models can be
adaptively steered by focusing on different features at inference-time: for
instance, robustness can be improved by focusing on task-causal features and
ignoring spurious features, and social bias can be mitigated by ignoring
demographic categories. Furthermore, FIT can steer behaviour in new contexts,
generalising under distribution shift and to new unseen features at inference
time, and thereby facilitating more robust, fair, and controllable LLM
applications in real-world environments.",2024-10-30,"Tom A. Lamb, Adam Davies, Alasdair Paren, Philip H. S. Torr, Francesco Pinto",http://arxiv.org/pdf/2410.22944v3,cs.CL
Multi-Agent Large Language Models for Conversational Task-Solving,"In an era where single large language models have dominated the landscape of
artificial intelligence for years, multi-agent systems arise as new
protagonists in conversational task-solving. While previous studies have
showcased their potential in reasoning tasks and creative endeavors, an
analysis of their limitations concerning the conversational paradigms and the
impact of individual agents is missing. It remains unascertained how
multi-agent discussions perform across tasks of varying complexity and how the
structure of these conversations influences the process. To fill that gap, this
work systematically evaluates multi-agent systems across various discussion
paradigms, assessing their strengths and weaknesses in both generative tasks
and question-answering tasks. Alongside the experiments, I propose a taxonomy
of 20 multi-agent research studies from 2022 to 2024, followed by the
introduction of a framework for deploying multi-agent LLMs in conversational
task-solving. I demonstrate that while multi-agent systems excel in complex
reasoning tasks, outperforming a single model by leveraging expert personas,
they fail on basic tasks. Concretely, I identify three challenges that arise:
1) While longer discussions enhance reasoning, agents fail to maintain
conformity to strict task requirements, which leads to problem drift, making
shorter conversations more effective for basic tasks. 2) Prolonged discussions
risk alignment collapse, raising new safety concerns for these systems. 3) I
showcase discussion monopolization through long generations, posing the problem
of fairness in decision-making for tasks like summarization. This work uncovers
both the potential and challenges that arise with multi-agent interaction and
varying conversational paradigms, providing insights into how future research
could improve the efficiency, performance, and safety of multi-agent LLMs.",2024-10-30,Jonas Becker,http://arxiv.org/pdf/2410.22932v2,cs.CL
GWQ: Gradient-Aware Weight Quantization for Large Language Models,"Large language models (LLMs) show impressive performance in solving complex
language tasks. However, its large number of parameters presents significant
challenges for the deployment. So, compressing LLMs to low bits can enable to
deploy on resource-constrained devices. To address this problem, we propose
gradient-aware weight quantization (GWQ), the first quantization approach for
low-bit weight quantization that leverages gradients to localize outliers,
requiring only a minimal amount of calibration data for outlier detection. GWQ
retains the top 1\% outliers preferentially at FP16 precision, while the
remaining non-outlier weights are stored in a low-bit. We widely evaluate GWQ
on different task include language modeling, grounding detection, massive
multitask language understanding and vision-language question and answering.
Results show that models quantified by GWQ performs better than other
quantization method. During quantization process, GWQ only need one calibration
set to realize effective quant. Also, GWQ achieves 1.2x inference speedup in
comparison to the original model and effectively reduces the inference memory.",2024-10-30,"Yihua Shao, Yan Gu, Siyu Chen, Haiyang Liu, Zijian Ling, Minxi Yan, Ziyang Yan, Chenyu Zhang, Michele Magno, Haotong Qin, Yan Wang, Jingcai Guo, Ling Shao, Hao Tang",http://arxiv.org/pdf/2411.00850v3,cs.CL
Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration,"Autonomous mobile app interaction has become increasingly important with
growing complexity of mobile applications. Developing intelligent agents that
can effectively navigate and interact with mobile apps remains a significant
challenge. In this paper, we propose an Explainable Behavior Cloning LLM Agent
(EBC-LLMAgent), a novel approach that combines large language models (LLMs)
with behavior cloning by learning demonstrations to create intelligent and
explainable agents for autonomous mobile app interaction. EBC-LLMAgent consists
of three core modules: Demonstration Encoding, Code Generation, and UI Mapping,
which work synergistically to capture user demonstrations, generate executable
codes, and establish accurate correspondence between code and UI elements. We
introduce the Behavior Cloning Chain Fusion technique to enhance the
generalization capabilities of the agent. Extensive experiments on five popular
mobile applications from diverse domains demonstrate the superior performance
of EBC-LLMAgent, achieving high success rates in task completion, efficient
generalization to unseen scenarios, and the generation of meaningful
explanations.",2024-10-30,"Yanchu Guan, Dong Wang, Yan Wang, Haiqing Wang, Renen Sun, Chenyi Zhuang, Jinjie Gu, Zhixuan Chu",http://arxiv.org/pdf/2410.22916v1,cs.CL
From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes,"Language models are typically trained on large corpora of text in their
default orthographic form. However, this is not the only option; representing
data as streams of phonemes can offer unique advantages, from deeper insights
into phonological language acquisition to improved performance on sound-based
tasks. The challenge lies in evaluating the impact of phoneme-based training,
as most benchmarks are also orthographic. To address this, we develop a
pipeline to convert text datasets into a continuous stream of phonemes. We
apply this pipeline to the 100-million-word pre-training dataset from the
BabyLM challenge, as well as to standard language and grammatical benchmarks,
enabling us to pre-train and evaluate a model using phonemic input
representations. Our results show that while phoneme-based training slightly
reduces performance on traditional language understanding tasks, it offers
valuable analytical and practical benefits.",2024-10-30,"Zébulon Goriely, Richard Diehl Martinez, Andrew Caines, Lisa Beinborn, Paula Buttery",http://arxiv.org/pdf/2410.22906v1,cs.CL
Combining psychoanalysis and computer science: an empirical study of the relationship between emotions and the Lacanian discourses,"This research explores the interdisciplinary interaction between
psychoanalysis and computer science, suggesting a mutually beneficial exchange.
Indeed, psychoanalytic concepts can enrich technological applications involving
unconscious, elusive aspects of the human factor, such as social media and
other interactive digital platforms. Conversely, computer science, especially
Artificial Intelligence (AI), can contribute quantitative concepts and methods
to psychoanalysis, identifying patterns and emotional cues in human expression.
In particular, this research aims to apply computer science methods to
establish fundamental relationships between emotions and Lacanian discourses.
Such relations are discovered in our approach via empirical investigation and
statistical analysis, and are eventually validated in a theoretical
(psychoanalytic) way. It is worth noting that, although emotions have been
sporadically studied in Lacanian theory, to the best of our knowledge a
systematic, detailed investigation of their role is missing. Such fine-grained
understanding of the role of emotions can also make the identification of
Lacanian discourses more effective and easy in practise. In particular, our
methods indicate the emotions with highest differentiation power in terms of
corresponding discourses; conversely, we identify for each discourse the most
characteristic emotions it admits. As a matter of fact, we develop a method
which we call Lacanian Discourse Discovery (LDD), that simplifies (via
systematizing) the identification of Lacanian discourses in texts. Although the
main contribution of this paper is inherently theoretical (psychoanalytic), it
can also facilitate major practical applications in the realm of interactive
digital systems. Indeed, our approach can be automated through Artificial
Intelligence methods that effectively identify emotions (and corresponding
discourses) in texts.",2024-10-30,"Minas Gadalla, Sotiris Nikoletseas, José Roberto de A. Amazonas",http://arxiv.org/pdf/2410.22895v1,cs.CL
VPO: Leveraging the Number of Votes in Preference Optimization,"Direct Preference Optimization (DPO) trains a language model using human
preference data, bypassing the explicit reward modeling phase of Reinforcement
Learning from Human Feedback (RLHF). By iterating over sentence pairs in a
preference dataset, DPO enhances generation quality by increasing the
likelihood of producing preferred sentences over less favored ones. Preference
datasets are typically created by selecting preferred sentences through a
voting process involving multiple individuals, as opinions can vary due to the
subjective nature of human preferences. While the number of votes offers
insight into whether a sentence pair is clearly preferable or controversial,
current methods do not fully leverage this information. In this paper, we
introduce a technique that leverages user voting data to better align with
diverse subjective preferences. We employ the Bayesian Minimum Mean Square
Error (Bayesian MMSE) estimator to model the probability that one generation is
preferable to another. Using this estimated probability as a target, we develop
the Vote-based Preference Optimization (VPO) framework, which incorporates the
number of votes on both sides to distinguish between controversial and obvious
generation pairs. We show that previous algorithms, such as DPO and Identity
Preference Optimization (IPO), can be extended using the proposed framework,
termed VDPO and VIPO. Our experiments demonstrate that these proposed
algorithms outperform various existing methods, including their base
algorithms.",2024-10-30,"Jae Hyeon Cho, Minkyung Park, Byung-Jun Lee",http://arxiv.org/pdf/2410.22891v1,cs.CL
Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector,"Visual Language Models (VLMs) are vulnerable to adversarial attacks,
especially those from adversarial images, which is however under-explored in
literature. To facilitate research on this critical safety problem, we first
construct a new laRge-scale Adervsarial images dataset with Diverse hArmful
Responses (RADAR), given that existing datasets are either small-scale or only
contain limited types of harmful responses. With the new RADAR dataset, we
further develop a novel and effective iN-time Embedding-based AdveRSarial Image
DEtection (NEARSIDE) method, which exploits a single vector that distilled from
the hidden states of VLMs, which we call the attacking direction, to achieve
the detection of adversarial images against benign ones in the input. Extensive
experiments with two victim VLMs, LLaVA and MiniGPT-4, well demonstrate the
effectiveness, efficiency, and cross-model transferrability of our proposed
method. Our code is available at https://github.com/mob-scu/RADAR-NEARSIDE",2024-10-30,"Youcheng Huang, Fengbin Zhu, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua",http://arxiv.org/pdf/2410.22888v1,cs.CL
Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies,"Curriculum Learning has been a popular strategy to improve the cognitive
plausibility of Small-Scale Language Models (SSLMs) in the BabyLM Challenge.
However, it has not led to considerable improvements over non-curriculum
models. We assess whether theoretical linguistic acquisition theories can be
used to specify more fine-grained curriculum learning strategies, creating
age-ordered corpora of Child-Directed Speech for four typologically distant
language families to implement SSLMs and acquisition-inspired curricula
cross-lingually. Comparing the success of three objective curricula (Growing,
Inwards and MMM) that precisely replicate the predictions of acquisition
theories on a standard SSLM architecture, we find fine-grained
acquisition-inspired curricula can outperform non-curriculum baselines and
performance benefits of curricula strategies in SSLMs can be derived by
specifying fine-grained language-specific curricula that precisely replicate
language acquisition theories.",2024-10-30,"Suchir Salhan, Richard Diehl Martinez, Zébulon Goriely, Paula Buttery",http://arxiv.org/pdf/2410.22886v2,cs.CL
Stealing User Prompts from Mixture of Experts,"Mixture-of-Experts (MoE) models improve the efficiency and scalability of
dense language models by routing each token to a small number of experts in
each layer. In this paper, we show how an adversary that can arrange for their
queries to appear in the same batch of examples as a victim's queries can
exploit Expert-Choice-Routing to fully disclose a victim's prompt. We
successfully demonstrate the effectiveness of this attack on a two-layer
Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA
implementation. Our results show that we can extract the entire prompt using
$O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100
queries on average per token in the setting we consider. This is the first
attack to exploit architectural flaws for the purpose of extracting user
prompts, introducing a new class of LLM vulnerabilities.",2024-10-30,"Itay Yona, Ilia Shumailov, Jamie Hayes, Nicholas Carlini",http://arxiv.org/pdf/2410.22884v1,cs.CL
Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations,"Retrieval-augmented generation (RAG) has emerged as a critical mechanism in
contemporary NLP to support Large Language Models(LLMs) in systematically
accessing richer factual context. However, the integration of RAG mechanisms
brings its inherent challenges, as LLMs need to deal with potentially noisy
contexts. Recent studies have shown that LLMs still struggle to critically
analyse RAG-based in-context information, a limitation that may lead to
incorrect inferences and hallucinations. In this paper, we investigate how to
elicit critical reasoning in RAG via contrastive explanations. In particular,
we propose Contrastive-RAG (C-RAG), a framework that (i) retrieves relevant
documents given a query, (ii) selects and exemplifies relevant passages, and
(iii) generates explanations that explicitly contrast the relevance of the
passages to (iv) support the final answer. We show the impact of C-RAG building
contrastive reasoning demonstrations from LLMs to instruct smaller models for
retrieval-augmented tasks. Extensive experiments demonstrate that C-RAG
improves state-of-the-art RAG models while (a) requiring significantly fewer
prompts and demonstrations and (b) being robust to perturbations in the
retrieved documents.",2024-10-30,"Leonardo Ranaldi, Marco Valentino, Andrè Freitas",http://arxiv.org/pdf/2410.22874v1,cs.CL
Exploiting Phonological Similarities between African Languages to achieve Speech to Speech Translation,"This paper presents a pilot study on direct speech-to-speech translation
(S2ST) by leveraging linguistic similarities among selected African languages
within the same phylum, particularly in cases where traditional data annotation
is expensive or impractical. We propose a segment-based model that maps speech
segments both within and across language phyla, effectively eliminating the
need for large paired datasets. By utilizing paired segments and guided
diffusion, our model enables translation between any two languages in the
dataset. We evaluate the model on a proprietary dataset from the Kenya
Broadcasting Corporation (KBC), which includes five languages: Swahili, Luo,
Kikuyu, Nandi, and English. The model demonstrates competitive performance in
segment pairing and translation quality, particularly for languages within the
same phylum. Our experiments reveal that segment length significantly
influences translation accuracy, with average-length segments yielding the
highest pairing quality. Comparative analyses with traditional cascaded ASR-MT
techniques show that the proposed model delivers nearly comparable translation
performance. This study underscores the potential of exploiting linguistic
similarities within language groups to perform efficient S2ST, especially in
low-resource language contexts.",2024-10-30,"Peter Ochieng, Dennis Kaburu",http://arxiv.org/pdf/2410.23323v1,cs.CL
Deep Learning and Machine Learning -- Natural Language Processing: From Theory to Application,"With a focus on natural language processing (NLP) and the role of large
language models (LLMs), we explore the intersection of machine learning, deep
learning, and artificial intelligence. As artificial intelligence continues to
revolutionize fields from healthcare to finance, NLP techniques such as
tokenization, text classification, and entity recognition are essential for
processing and understanding human language. This paper discusses advanced data
preprocessing techniques and the use of frameworks like Hugging Face for
implementing transformer-based models. Additionally, it highlights challenges
such as handling multilingual data, reducing bias, and ensuring model
robustness. By addressing key aspects of data processing and model fine-tuning,
this work aims to provide insights into deploying effective and ethically sound
AI solutions.",2024-10-30,"Keyu Chen, Cheng Fei, Ziqian Bi, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Caitlyn Heqi Yin, Yichao Zhang, Pohsun Feng, Yizhu Wen, Tianyang Wang, Ming Li, Jintao Ren, Qian Niu, Silin Chen, Weiche Hsieh, Lawrence K. Q. Yan, Chia Xin Liang, Han Xu, Hong-Ming Tseng, Xinyuan Song, Ming Liu",http://arxiv.org/pdf/2411.05026v2,cs.CL
Danoliteracy of Generative Large Language Models,"The language technology moonshot moment of Generative Large Language Models
(GLLMs) was not limited to English: These models brought a surge of
technological applications, investments, and hype to low-resource languages as
well. However, the capabilities of these models in languages such as Danish
were, until recently, difficult to verify beyond qualitative demonstrations due
to a lack of applicable evaluation corpora. We present a GLLM benchmark to
evaluate \emph{Danoliteracy}, a measure of Danish language and cultural
competency across eight diverse scenarios such as Danish citizenship tests and
abstractive social media question answering. This limited-size benchmark was
found to produce a robust ranking that correlates to human feedback at $\rho
\sim 0.8$ with GPT-4 and Claude Opus models achieving the highest rankings.
Analyzing these model results across scenarios, we find one strong underlying
factor explaining $95\%$ of scenario performance variance for GLLMs in Danish,
suggesting a $g$ factor of model consistency in language adaptation.",2024-10-30,"Søren Vejlgaard Holm, Lars Kai Hansen, Martin Carsten Nielsen",http://arxiv.org/pdf/2410.22839v2,cs.CL
How Well Do Large Language Models Disambiguate Swedish Words?,"We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.",2024-10-30,Richard Johansson,http://arxiv.org/pdf/2410.22827v1,cs.CL
EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations,"How to evaluate Large Language Models (LLMs) in code generation remains an
open question. Existing benchmarks have two limitations - data leakage and lack
of domain-specific evaluation. The former hurts the fairness of benchmarks, and
the latter hinders practitioners from selecting superior LLMs for specific
programming domains. To address these two limitations, we propose a new
benchmark - EvoCodeBench, which has the following advances: (1) Evolving data.
EvoCodeBench will be dynamically updated every period (e.g., 6 months) to avoid
data leakage. This paper releases the first version - EvoCodeBench-2403,
containing 275 samples from 25 repositories. (2) A domain taxonomy and domain
labels. Based on the statistics of open-source communities, we design a
programming domain taxonomy consisting of 10 popular domains. Based on the
taxonomy, we annotate each sample in EvoCodeBench with a domain label. (3)
Domain-specific evaluations. Besides the Pass@k, we compute the Domain-Specific
Improvement (DSI) and define LLMs' comfort and strange domains. These
evaluations help practitioners select superior LLMs in specific domains and
discover the shortcomings of existing LLMs. We evaluate 8 popular LLMs (e.g.,
gpt-4, DeepSeek Coder) on EvoCodeBench and summarize some insights.
EvoCodeBench reveals the actual abilities of these LLMs in real-world
repositories. For example, the highest Pass@1 of gpt-4 on EvoCodeBench-2403 is
only 20.74%. Besides, we evaluate LLMs in different domains and discover their
comfort and strange domains. For example, gpt-4 performs best in most domains
but falls behind others in the Internet domain. StarCoder 2-15B unexpectedly
performs well in the Database domain and even outperforms 33B LLMs.
EvoCodeBench has been released.",2024-10-30,"Jia Li, Ge Li, Xuanming Zhang, Yunfei Zhao, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li",http://arxiv.org/pdf/2410.22821v1,cs.CL
Rule by Rule: Learning with Confidence through Vocabulary Expansion,"In this paper, we present an innovative iterative approach to rule learning
specifically designed for (but not limited to) text-based data. Our method
focuses on progressively expanding the vocabulary utilized in each iteration
resulting in a significant reduction of memory consumption. Moreover, we
introduce a Value of Confidence as an indicator of the reliability of the
generated rules. By leveraging the Value of Confidence, our approach ensures
that only the most robust and trustworthy rules are retained, thereby improving
the overall quality of the rule learning process. We demonstrate the
effectiveness of our method through extensive experiments on various textual as
well as non-textual datasets including a use case of significant interest to
insurance industries, showcasing its potential for real-world applications.",2024-10-30,"Albert Nössig, Tobias Hell, Georg Moser",http://arxiv.org/pdf/2411.00049v1,cs.CL
MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning,"Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have significantly
improved the adaptation of LLMs to downstream tasks in a resource-efficient
manner. However, in multi-task scenarios, challenges such as training imbalance
and the seesaw effect frequently emerge. Mixture-of-LoRA (MoLoRA), which
combines LoRA with sparse Mixture-of-Experts, mitigates some of these issues by
promoting task-specific learning across experts. Despite this, MoLoRA remains
inefficient in terms of training speed, parameter utilization, and overall
multi-task performance. In this paper, we propose Mixture of Asymmetric
Low-Rank Adaptaion (MALoRA), a flexible fine-tuning framework that leverages
asymmetric optimization across LoRA experts. MALoRA reduces the number of
trainable parameters by 30% to 48%, increases training speed by 1.2x, and
matches the computational efficiency of single-task LoRA models. Additionally,
MALoRA addresses overfitting issues commonly seen in high-rank configurations,
enhancing performance stability. Extensive experiments across diverse
multi-task learning scenarios demonstrate that MALoRA consistently outperforms
all baseline methods in both inter-domain and intra-domain tasks.",2024-10-30,"Xujia Wang, Haiyan Zhao, Shuo Wang, Hanqing Wang, Zhiyuan Liu",http://arxiv.org/pdf/2410.22782v1,cs.CL
InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models,"Prompt injection attacks pose a critical threat to large language models
(LLMs), enabling goal hijacking and data leakage. Prompt guard models, though
effective in defense, suffer from over-defense -- falsely flagging benign
inputs as malicious due to trigger word bias. To address this issue, we
introduce NotInject, an evaluation dataset that systematically measures
over-defense across various prompt guard models. NotInject contains 339 benign
samples enriched with trigger words common in prompt injection attacks,
enabling fine-grained evaluation. Our results show that state-of-the-art models
suffer from over-defense issues, with accuracy dropping close to random
guessing levels (60%). To mitigate this, we propose InjecGuard, a novel prompt
guard model that incorporates a new training strategy, Mitigating Over-defense
for Free (MOF), which significantly reduces the bias on trigger words.
InjecGuard demonstrates state-of-the-art performance on diverse benchmarks
including NotInject, surpassing the existing best model by 30.8%, offering a
robust and open-source solution for detecting prompt injection attacks. The
code and datasets are released at https://github.com/leolee99/InjecGuard.",2024-10-30,"Hao Li, Xiaogeng Liu",http://arxiv.org/pdf/2410.22770v3,cs.CL
Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot,"Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.",2024-10-30,"Sejin Lee, Dongha Kim, Min Song",http://arxiv.org/pdf/2410.22767v1,cs.CL
Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model,"To develop high-performing Visual Language Models (VLMs), it is essential to
prepare multimodal resources, such as image-text pairs, interleaved data, and
instruction data. While multimodal resources for English are abundant, there is
a significant lack of corresponding resources for non-English languages, such
as Japanese. To address this problem, we take Japanese as a non-English
language and propose a method for rapidly creating Japanese multimodal datasets
from scratch. We collect Japanese image-text pairs and interleaved data from
web archives and generate Japanese instruction data directly from images using
an existing VLM. Our experimental results show that a VLM trained on these
native datasets outperforms those relying on machine-translated content.",2024-10-30,"Keito Sasagawa, Koki Maeda, Issa Sugiura, Shuhei Kurita, Naoaki Okazaki, Daisuke Kawahara",http://arxiv.org/pdf/2410.22736v1,cs.CL
A Comprehensive Study on Quantization Techniques for Large Language Models,"Large Language Models (LLMs) have been extensively researched and used in
both academia and industry since the rise in popularity of the Transformer
model, which demonstrates excellent performance in AI. However, the
computational demands of LLMs are immense, and the energy resources required to
run them are often limited. For instance, popular models like GPT-3, with 175
billion parameters and a storage requirement of 350 GB, present significant
challenges for deployment on resource-constrained IoT devices and embedded
systems. These systems often lack the computational capacity to handle such
large models. Quantization, a technique that reduces the precision of model
values to a smaller set of discrete values, offers a promising solution by
reducing the size of LLMs and accelerating inference. In this research, we
provide a comprehensive analysis of quantization techniques within the machine
learning field, with a particular focus on their application to LLMs. We begin
by exploring the mathematical theory of quantization, followed by a review of
common quantization methods and how they are implemented. Furthermore, we
examine several prominent quantization methods applied to LLMs, detailing their
algorithms and performance outcomes.",2024-10-30,"Jiedong Lang, Zhehao Guo, Shuyu Huang",http://arxiv.org/pdf/2411.02530v1,cs.CL
Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings,"Accurately quantifying uncertainty in large language models (LLMs) is crucial
for their reliable deployment, especially in high-stakes applications. Current
state-of-the-art methods for measuring semantic uncertainty in LLMs rely on
strict bidirectional entailment criteria between multiple generated responses
and also depend on sequence likelihoods. While effective, these approaches
often overestimate uncertainty due to their sensitivity to minor wording
differences, additional correct information, and non-important words in the
sequence. We propose a novel approach that leverages semantic embeddings to
achieve smoother and more robust estimation of semantic uncertainty in LLMs. By
capturing semantic similarities without depending on sequence likelihoods, our
method inherently reduces any biases introduced by irrelevant words in the
answers. Furthermore, we introduce an amortised version of our approach by
explicitly modelling semantics as latent variables in a joint probabilistic
model. This allows for uncertainty estimation in the embedding space with a
single forward pass, significantly reducing computational overhead compared to
existing multi-pass methods. Experiments across multiple question-answering
datasets and frontier LLMs demonstrate that our embedding-based methods provide
more accurate and nuanced uncertainty quantification than traditional
approaches.",2024-10-30,"Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui",http://arxiv.org/pdf/2410.22685v1,cs.CL
LLMs as Research Tools: A Large Scale Survey of Researchers' Usage and Perceptions,"The rise of large language models (LLMs) has led many researchers to consider
their usage for scientific work. Some have found benefits using LLMs to augment
or automate aspects of their research pipeline, while others have urged caution
due to risks and ethical concerns. Yet little work has sought to quantify and
characterize how researchers use LLMs and why. We present the first large-scale
survey of 816 verified research article authors to understand how the research
community leverages and perceives LLMs as research tools. We examine
participants' self-reported LLM usage, finding that 81% of researchers have
already incorporated LLMs into different aspects of their research workflow. We
also find that traditionally disadvantaged groups in academia (non-White,
junior, and non-native English speaking researchers) report higher LLM usage
and perceived benefits, suggesting potential for improved research equity.
However, women, non-binary, and senior researchers have greater ethical
concerns, potentially hindering adoption.",2024-10-30,"Zhehui Liao, Maria Antoniak, Inyoung Cheong, Evie Yu-Yen Cheng, Ai-Heng Lee, Kyle Lo, Joseph Chee Chang, Amy X. Zhang",http://arxiv.org/pdf/2411.05025v1,cs.CL
The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation,"Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. This work proposes
augmenting LLMs with predictor networks trained to estimate circuit quality
directly from HDL code. To enhance performance, the model is regularized using
embeddings from graph neural networks (GNNs) trained on Look-Up Table (LUT)
graphs, thereby incorporating lower-level circuit insights. The proposed method
demonstrates superior performance compared to existing graph-based RTL-level
estimation techniques on the established benchmark OpenABCD, while providing
instant feedback on HDL code quality.",2024-10-30,"Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan",http://arxiv.org/pdf/2411.00843v2,cs.CL
Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers,"Machine learning (ML) for text classification has been widely used in various
domains. These applications can significantly impact ethics, economics, and
human behavior, raising serious concerns about trusting ML decisions. Studies
indicate that conventional metrics are insufficient to build human trust in ML
models. These models often learn spurious correlations and predict based on
them. In the real world, their performance can deteriorate significantly. To
avoid this, a common practice is to test whether predictions are reasonable
based on valid patterns in the data. Along with this, a challenge known as the
trustworthiness oracle problem has been introduced. Due to the lack of
automated trustworthiness oracles, the assessment requires manual validation of
the decision process disclosed by explanation methods. However, this is
time-consuming, error-prone, and unscalable.
  We propose TOKI, the first automated trustworthiness oracle generation method
for text classifiers. TOKI automatically checks whether the words contributing
the most to a prediction are semantically related to the predicted class.
Specifically, we leverage ML explanations to extract the decision-contributing
words and measure their semantic relatedness with the class based on word
embeddings. We also introduce a novel adversarial attack method that targets
trustworthiness vulnerabilities identified by TOKI. To evaluate their alignment
with human judgement, experiments are conducted. We compare TOKI with a naive
baseline based solely on model confidence and TOKI-guided adversarial attack
method with A2T, a SOTA adversarial attack method. Results show that relying on
prediction uncertainty cannot effectively distinguish between trustworthy and
untrustworthy predictions, TOKI achieves 142% higher accuracy than the naive
baseline, and TOKI-guided attack method is more effective with fewer
perturbations than A2T.",2024-10-30,"Lam Nguyen Tung, Steven Cho, Xiaoning Du, Neelofar Neelofar, Valerio Terragni, Stefano Ruberto, Aldeida Aleti",http://arxiv.org/pdf/2410.22663v4,cs.CL
Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models,"Code-switching, the phenomenon of alternating between two or more languages
in a single conversation, presents unique challenges for Natural Language
Processing (NLP). Most existing research focuses on either syntactic
constraints or neural generation, with few efforts to integrate linguistic
theory with large language models (LLMs) for generating natural code-switched
text. In this paper, we introduce EZSwitch, a novel framework that combines
Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid
and fluent code-switched text. We evaluate our method using both human
judgments and automatic metrics, demonstrating a significant improvement in the
quality of generated code-switching sentences compared to baseline LLMs. To
address the lack of suitable evaluation metrics, we conduct a comprehensive
correlation study of various automatic metrics against human scores, revealing
that current metrics often fail to capture the nuanced fluency of code-switched
text. Additionally, we create CSPref, a human preference dataset based on human
ratings and analyze model performance across ``hard`` and ``easy`` examples.
Our findings indicate that incorporating linguistic constraints into LLMs leads
to more robust and human-aligned generation, paving the way for scalable
code-switching text generation across diverse language pairs.",2024-10-30,"Garry Kuwanto, Chaitanya Agarwal, Genta Indra Winata, Derry Tanti Wijaya",http://arxiv.org/pdf/2410.22660v1,cs.CL
Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation,"Argumentative essay generation (AEG) aims to generate complete texts on
specific controversial topics or debates. Although current AEG methods can
generate individual opinions, they often overlook the high-level connections
between these opinions. This often leads to the generated results being mired
in logical confusion, unable to proof their own arguments effectively. The
generated essay may present evidence that contradicts the claims or they may
fail to assemble the claims into logical flow. In this paper, we present a
unified two-stage framework: Proof-Enhancement and Self-Annotation (PESA) for
AEG with a focus on logical enhancement. Specifically, we first construct
pseudo-labels for logical information,claims and grounds, using a large
language model. We then propose a tree planning approach that introduces proof
principles and ensures logical consistency. Extensive experimental results show
that, benefiting from proof principle guidance, PESA generates argumentative
essays with better logical validity and persuasiveness than strong baseline
models.",2024-10-30,"Ruiyu Xiao, Lei Wu, Yuhang Gou, Weinan Zhang, Ting Liu",http://arxiv.org/pdf/2410.22642v1,cs.CL
A Theoretical Perspective for Speculative Decoding Algorithm,"Transformer-based autoregressive sampling has been the major bottleneck for
slowing down large language model inferences. One effective way to accelerate
inference is \emph{Speculative Decoding}, which employs a small model to sample
a sequence of draft tokens and a large model to validate. Given its empirical
effectiveness, the theoretical understanding of Speculative Decoding is falling
behind. This paper tackles this gap by conceptualizing the decoding problem via
markov chain abstraction and studying the key properties, \emph{output quality
and inference acceleration}, from a theoretical perspective. Our analysis
covers the theoretical limits of speculative decoding, batch algorithms, and
output quality-inference acceleration tradeoffs. Our results reveal the
fundamental connections between different components of LLMs via total
variation distances and show how they jointly affect the efficiency of decoding
algorithms.",2024-10-30,"Ming Yin, Minshuo Chen, Kaixuan Huang, Mengdi Wang",http://arxiv.org/pdf/2411.00841v1,cs.CL
Characterizing the Role of Similarity in the Property Inferences of Language Models,"Property inheritance -- a phenomenon where novel properties are projected
from higher level categories (e.g., birds) to lower level ones (e.g., sparrows)
-- provides a unique window into how humans organize and deploy conceptual
knowledge. It is debated whether this ability arises due to explicitly stored
taxonomic knowledge vs. simple computations of similarity between mental
representations. How are these mechanistic hypotheses manifested in
contemporary language models? In this work, we investigate how LMs perform
property inheritance with behavioral and causal representational analysis
experiments. We find that taxonomy and categorical similarities are not
mutually exclusive in LMs' property inheritance behavior. That is, LMs are more
likely to project novel properties from one category to the other when they are
taxonomically related and at the same time, highly similar. Our findings
provide insight into the conceptual structure of language models and may
suggest new psycholinguistic experiments for human subjects.",2024-10-29,"Juan Diego Rodriguez, Aaron Mueller, Kanishka Misra",http://arxiv.org/pdf/2410.22590v2,cs.CL
Toxicity of the Commons: Curating Open-Source Pre-Training Data,"Open-source large language models are becoming increasingly available and
popular among researchers and practitioners. While significant progress has
been made on open-weight models, open training data is a practice yet to be
adopted by the leading open-weight models creators. At the same time, there
researchers are working to make language models safer. We propose a data
curation pipeline to reduce harmful outputs by models trained on public domain
data. There are unique challenges to working with public domain data, as these
sources differ from web text in both form and content. Many sources are
historical documents and are the result of Optical Character Recognition (OCR).
Consequently, current state-of-the-art approaches to toxicity filtering are
often infeasible or inappropriate for open data models. In this paper, we
introduce a new fully open-source pipeline for open-data toxicity filtering.
Our contributions are threefold. We create a custom training dataset,
ToxicCommons, which is composed of texts which have been classified across five
different dimensions (racial/origin-based, gender/sex-based, religious,
ability-based discrimination, and violence). We use this dataset to train a
custom classifier, Celadon, that can be used to detect toxic content in open
data more efficiently at a larger scale. Finally, we describe the balanced
approach to content filtration that optimizes safety filtering with respect to
the filtered data available for training.",2024-10-29,"Catherine Arnett, Eliot Jones, Ivan P. Yamshchikov, Pierre-Carl Langlais",http://arxiv.org/pdf/2410.22587v2,cs.CL
BENCHAGENTS: Automated Benchmark Creation with Agent Interaction,"Evaluations are limited by benchmark availability. As models evolve, there is
a need to create benchmarks that can measure progress on new generative
capabilities. However, creating new benchmarks through human annotations is
slow and expensive, restricting comprehensive evaluations for any capability.
We introduce BENCHAGENTS, a framework that methodically leverages large
language models (LLMs) to automate benchmark creation for complex capabilities
while inherently ensuring data and metric quality. BENCHAGENTS decomposes the
benchmark creation process into planning, generation, data verification, and
evaluation, each of which is executed by an LLM agent. These agents interact
with each other and utilize human-in-the-loop feedback from benchmark
developers to explicitly improve and flexibly control data diversity and
quality. We use BENCHAGENTS to create benchmarks to evaluate capabilities
related to planning and constraint satisfaction during text generation. We then
use these benchmarks to study seven state-of-the-art models and extract new
insights on common failure modes and model differences.",2024-10-29,"Natasha Butt, Varun Chandrasekaran, Neel Joshi, Besmira Nushi, Vidhisha Balachandran",http://arxiv.org/pdf/2410.22584v1,cs.CL
Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents,"In this paper, we introduce Auto-Intent, a method to adapt a pre-trained
large language model (LLM) as an agent for a target domain without direct
fine-tuning, where we empirically focus on web navigation tasks. Our approach
first discovers the underlying intents from target domain demonstrations
unsupervisedly, in a highly compact form (up to three words). With the
extracted intents, we train our intent predictor to predict the next intent
given the agent's past observations and actions. In particular, we propose a
self-exploration approach where top-k probable intent predictions are provided
as a hint to the pre-trained LLM agent, which leads to enhanced decision-making
capabilities. Auto-Intent substantially improves the performance of GPT-{3.5,
4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation
benchmarks from Mind2Web and online navigation tasks from WebArena with its
cross-benchmark generalization from Mind2Web.",2024-10-29,"Jaekyeom Kim, Dong-Ki Kim, Lajanugen Logeswaran, Sungryull Sohn, Honglak Lee",http://arxiv.org/pdf/2410.22552v1,cs.CL
Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models,"We explore the internal mechanisms of how bias emerges in large language
models (LLMs) when provided with ambiguous comparative prompts: inputs that
compare or enforce choosing between two or more entities without providing
clear context for preference. Most approaches for bias mitigation focus on
either post-hoc analysis or data augmentation. However, these are transient
solutions, without addressing the root cause: the model itself. Numerous prior
works show the influence of the attention module towards steering generations.
We believe that analyzing attention is also crucial for understanding bias, as
it provides insight into how the LLM distributes its focus across different
entities and how this contributes to biased decisions. To this end, we first
introduce a metric to quantify the LLM's preference for one entity over
another. We then propose $\texttt{ATLAS}$ (Attention-based Targeted Layer
Analysis and Scaling), a technique to localize bias to specific layers of the
LLM by analyzing attention scores and then reduce bias by scaling attention in
these biased layers. To evaluate our method, we conduct experiments across 3
datasets (BBQ, Crows-Pairs, and WinoGender) using $\texttt{GPT-2 XL}$ (1.5B),
$\texttt{GPT-J}$ (6B), $\texttt{LLaMA-2}$ (7B) and $\texttt{LLaMA-3}$ (8B). Our
experiments demonstrate that bias is concentrated in the later layers,
typically around the last third. We also show how $\texttt{ATLAS}$ effectively
mitigates bias through targeted interventions without compromising downstream
performance and an average increase of only 0.82% in perplexity when the
intervention is applied. We see an average improvement of 0.28 points in the
bias score across all the datasets.",2024-10-29,"Rishabh Adiga, Besmira Nushi, Varun Chandrasekaran",http://arxiv.org/pdf/2410.22517v1,cs.CL
VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration,"Vision-Language Models (VLMs) have demonstrated impressive performance across
a versatile set of tasks. A key challenge in accelerating VLMs is storing and
accessing the large Key-Value (KV) cache that encodes long visual contexts,
such as images or videos. While existing KV cache compression methods are
effective for Large Language Models (LLMs), directly migrating them to VLMs
yields suboptimal accuracy and speedup. To bridge the gap, we propose VL-Cache,
a novel KV cache compression recipe tailored for accelerating VLM inference. In
this paper, we first investigate the unique sparsity pattern of VLM attention
by distinguishing visual and text tokens in prefill and decoding phases. Based
on these observations, we introduce a layer-adaptive sparsity-aware cache
budget allocation method that effectively distributes the limited cache budget
across different layers, further reducing KV cache size without compromising
accuracy. Additionally, we develop a modality-aware token scoring policy to
better evaluate the token importance. Empirical results on multiple benchmark
datasets demonstrate that retaining only 10% of KV cache achieves accuracy
comparable to that with full cache. In a speed benchmark, our method
accelerates end-to-end latency of generating 100 tokens by up to 2.33x and
speeds up decoding by up to 7.08x, while reducing the memory footprint of KV
cache in GPU by 90%.",2024-10-29,"Dezhan Tu, Danylo Vashchilenko, Yuzhe Lu, Panpan Xu",http://arxiv.org/pdf/2410.23317v1,cs.CL
CurateGPT: A flexible language-model assisted biocuration tool,"Effective data-driven biomedical discovery requires data curation: a
time-consuming process of finding, organizing, distilling, integrating,
interpreting, annotating, and validating diverse information into a structured
form suitable for databases and knowledge bases. Accurate and efficient
curation of these digital assets is critical to ensuring that they are FAIR,
trustworthy, and sustainable. Unfortunately, expert curators face significant
time and resource constraints. The rapid pace of new information being
published daily is exceeding their capacity for curation. Generative AI,
exemplified by instruction-tuned large language models (LLMs), has opened up
new possibilities for assisting human-driven curation. The design philosophy of
agents combines the emerging abilities of generative AI with more precise
methods. A curator's tasks can be aided by agents for performing reasoning,
searching ontologies, and integrating knowledge across external sources, all
efforts otherwise requiring extensive manual effort. Our LLM-driven annotation
tool, CurateGPT, melds the power of generative AI together with trusted
knowledge bases and literature sources. CurateGPT streamlines the curation
process, enhancing collaboration and efficiency in common workflows. Compared
to direct interaction with an LLM, CurateGPT's agents enable access to
information beyond that in the LLM's training data and they provide direct
links to the data supporting each claim. This helps curators, researchers, and
engineers scale up curation efforts to keep pace with the ever-increasing
volume of scientific data.",2024-10-29,"Harry Caufield, Carlo Kroll, Shawn T O'Neil, Justin T Reese, Marcin P Joachimiak, Harshad Hegde, Nomi L Harris, Madan Krishnamurthy, James A McLaughlin, Damian Smedley, Melissa A Haendel, Peter N Robinson, Christopher J Mungall",http://arxiv.org/pdf/2411.00046v1,cs.CL
Anticipating Future with Large Language Model for Simultaneous Machine Translation,"Simultaneous machine translation (SMT) takes streaming input utterances and
incrementally produces target text. Existing SMT methods only use the partial
utterance that has already arrived at the input and the generated hypothesis.
Motivated by human interpreters' technique to forecast future words before
hearing them, we propose $\textbf{T}$ranslation by $\textbf{A}$nticipating
$\textbf{F}$uture (TAF), a method to improve translation quality while
retraining low latency. Its core idea is to use a large language model (LLM) to
predict future source words and opportunistically translate without introducing
too much risk. We evaluate our TAF and multiple baselines of SMT on four
language directions. Experiments show that TAF achieves the best translation
quality-latency trade-off and outperforms the baselines by up to 5 BLEU points
at the same latency (three words).",2024-10-29,"Siqi Ouyang, Oleksii Hrinchuk, Zhehuai Chen, Vitaly Lavrukhin, Jagadeesh Balam, Lei Li, Boris Ginsburg",http://arxiv.org/pdf/2410.22499v1,cs.CL
A Novel Psychometrics-Based Approach to Developing Professional Competency Benchmark for Large Language Models,"The era of large language models (LLM) raises questions not only about how to
train models, but also about how to evaluate them. Despite numerous existing
benchmarks, insufficient attention is often given to creating assessments that
test LLMs in a valid and reliable manner. To address this challenge, we
accommodate the Evidence-centered design (ECD) methodology and propose a
comprehensive approach to benchmark development based on rigorous psychometric
principles. In this paper, we have made the first attempt to illustrate this
approach by creating a new benchmark in the field of pedagogy and education,
highlighting the limitations of existing benchmark development approach and
taking into account the development of LLMs. We conclude that a new approach to
benchmarking is required to match the growing complexity of AI applications in
the educational context. We construct a novel benchmark guided by the Bloom's
taxonomy and rigorously designed by a consortium of education experts trained
in test development. Thus the current benchmark provides an academically robust
and practical assessment tool tailored for LLMs, rather than human
participants. Tested empirically on the GPT model in the Russian language, it
evaluates model performance across varied task complexities, revealing critical
gaps in current LLM capabilities. Our results indicate that while generative AI
tools hold significant promise for education - potentially supporting tasks
such as personalized tutoring, real-time feedback, and multilingual learning -
their reliability as autonomous teachers' assistants right now remain rather
limited, particularly in tasks requiring deeper cognitive engagement.",2024-10-29,"Elena Kardanova, Alina Ivanova, Ksenia Tarasova, Taras Pashchenko, Aleksei Tikhoniuk, Elen Yusupova, Anatoly Kasprzhak, Yaroslav Kuzminov, Ekaterina Kruchinskaia, Irina Brun",http://arxiv.org/pdf/2411.00045v1,cs.CL
MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary embolism phenotype in the MIMIC-IV dataset,"Pulmonary embolism (PE) is a leading cause of preventable in-hospital
mortality. Advances in diagnosis, risk stratification, and prevention can
improve outcomes. There are few large publicly available datasets that contain
PE labels for research. Using the MIMIC-IV database, we extracted all available
radiology reports of computed tomography pulmonary angiography (CTPA) scans and
two physicians manually labeled the results as PE positive (acute PE) or PE
negative. We then applied a previously finetuned Bio_ClinicalBERT transformer
language model, VTE-BERT, to extract labels automatically. We verified
VTE-BERT's reliability by measuring its performance against manual
adjudication. We also compared the performance of VTE-BERT to diagnosis codes.
We found that VTE-BERT has a sensitivity of 92.4% and positive predictive value
(PPV) of 87.8% on all 19,942 patients with CTPA radiology reports from the
emergency room and/or hospital admission. In contrast, diagnosis codes have a
sensitivity of 95.4% and PPV of 83.8% on the subset of 11,990 hospitalized
patients with discharge diagnosis codes. We successfully add nearly 20,000
labels to CTPAs in a publicly available dataset and demonstrate the external
validity of a semi-supervised language model in accelerating hematologic
research.",2024-10-29,"B. D. Lam, S. Ma, I. Kovalenko, P. Wang, O. Jafari, A. Li, S. Horng",http://arxiv.org/pdf/2411.00044v1,cs.CL
Scaling LLM Inference with Optimized Sample Compute Allocation,"Sampling is a basic operation in many inference-time algorithms of large
language models (LLMs). To scale up inference efficiently with a limited
compute, it is crucial to find an optimal allocation for sample compute
budgets: Which sampling configurations (model, temperature, language, etc.) do
we use? How many samples do we generate in each configuration? We formulate
these choices as a learning problem and propose OSCA, an algorithm that
Optimizes Sample Compute Allocation by finding an optimal mix of different
inference configurations. Our experiments show that with our learned mixed
allocation, we can achieve accuracy better than the best single configuration
with 128x less compute on code generation and 25x less compute on 4 reasoning
tasks. OSCA is also shown to be effective in agentic workflows beyond
single-turn tasks, achieving a better accuracy on SWE-Bench with 3x less
compute than the default configuration. Our code and generations are released
at https://github.com/LeiLiLab/OSCA.",2024-10-29,"Kexun Zhang, Shang Zhou, Danqing Wang, William Yang Wang, Lei Li",http://arxiv.org/pdf/2410.22480v1,cs.CL
A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents,"In task-oriented dialogue systems, intent detection is crucial for
interpreting user queries and providing appropriate responses. Existing
research primarily addresses simple queries with a single intent, lacking
effective systems for handling complex queries with multiple intents and
extracting different intent spans. Additionally, there is a notable absence of
multilingual, multi-intent datasets. This study addresses three critical tasks:
extracting multiple intent spans from queries, detecting multiple intents, and
developing a multi-lingual multi-label intent dataset. We introduce a novel
multi-label multi-class intent detection dataset (MLMCID-dataset) curated from
existing benchmark datasets. We also propose a pointer network-based
architecture (MLMCID) to extract intent spans and detect multiple intents with
coarse and fine-grained labels in the form of sextuplets. Comprehensive
analysis demonstrates the superiority of our pointer network-based system over
baseline approaches in terms of accuracy and F1-score across various datasets.",2024-10-29,"Ankan Mullick, Sombit Bose, Abhilash Nandy, Gajula Sai Chaitanya, Pawan Goyal",http://arxiv.org/pdf/2410.22476v1,cs.CL
Multimodal Quantum Natural Language Processing: A Novel Framework for using Quantum Methods to Analyse Real Data,"Despite significant advances in quantum computing across various domains,
research on applying quantum approaches to language compositionality - such as
modeling linguistic structures and interactions - remains limited. This gap
extends to the integration of quantum language data with real-world data from
sources like images, video, and audio. This thesis explores how quantum
computational methods can enhance the compositional modeling of language
through multimodal data integration. Specifically, it advances Multimodal
Quantum Natural Language Processing (MQNLP) by applying the Lambeq toolkit to
conduct a comparative analysis of four compositional models and evaluate their
influence on image-text classification tasks. Results indicate that
syntax-based models, particularly DisCoCat and TreeReader, excel in effectively
capturing grammatical structures, while bag-of-words and sequential models
struggle due to limited syntactic awareness. These findings underscore the
potential of quantum methods to enhance language modeling and drive
breakthroughs as quantum technology evolves.",2024-10-29,Hala Hawashin,http://arxiv.org/pdf/2411.05023v1,cs.CL
"Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset","Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.",2024-10-29,"Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar",http://arxiv.org/pdf/2410.22457v1,cs.CL
A Closer Look at Neural Codec Resynthesis: Bridging the Gap between Codec and Waveform Generation,"Neural Audio Codecs, initially designed as a compression technique, have
gained more attention recently for speech generation. Codec models represent
each audio frame as a sequence of tokens, i.e., discrete embeddings. The
discrete and low-frequency nature of neural codecs introduced a new way to
generate speech with token-based models. As these tokens encode information at
various levels of granularity, from coarse to fine, most existing works focus
on how to better generate the coarse tokens. In this paper, we focus on an
equally important but often overlooked question: How can we better resynthesize
the waveform from coarse tokens? We point out that both the choice of learning
target and resynthesis approach have a dramatic impact on the generated audio
quality. Specifically, we study two different strategies based on token
prediction and regression, and introduce a new method based on Schr\""odinger
Bridge. We examine how different design choices affect machine and human
perception.",2024-10-29,"Alexander H. Liu, Qirui Wang, Yuan Gong, James Glass",http://arxiv.org/pdf/2410.22448v1,cs.CL
Do Large Language Models Align with Core Mental Health Counseling Competencies?,"The rapid evolution of Large Language Models (LLMs) presents a promising
solution to the global shortage of mental health professionals. However, their
alignment with essential counseling competencies remains underexplored. We
introduce CounselingBench, a novel NCMHCE-based benchmark evaluating 22
general-purpose and medical-finetuned LLMs across five key competencies. While
frontier models surpass minimum aptitude thresholds, they fall short of
expert-level performance, excelling in Intake, Assessment & Diagnosis but
struggling with Core Counseling Attributes and Professional Practice & Ethics.
Surprisingly, medical LLMs do not outperform generalist models in accuracy,
though they provide slightly better justifications while making more
context-related errors. These findings highlight the challenges of developing
AI for mental health counseling, particularly in competencies requiring empathy
and nuanced reasoning. Our results underscore the need for specialized,
fine-tuned models aligned with core mental health counseling competencies and
supported by human oversight before real-world deployment. Code and data
associated with this manuscript can be found at:
https://github.com/cuongnguyenx/CounselingBench",2024-10-29,"Viet Cuong Nguyen, Mohammad Taher, Dongwan Hong, Vinicius Konkolics Possobom, Vibha Thirunellayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J. Soled, Michael L. Birnbaum, Srijan Kumar, Munmun De Choudhury",http://arxiv.org/pdf/2410.22446v2,cs.CL
Vision-Language Models Create Cross-Modal Task Representations,"Autoregressive vision-language models (VLMs) can handle many tasks within a
single model, yet the representations that enable this capability remain
opaque. We find that VLMs align conceptually equivalent inputs into a shared
task vector, which is invariant to modality (text, image) and format (examples,
instruction), and may simplify VLM processing. We measure this alignment via
cross-modal transfer -- the ability of a task vector derived in one modality to
trigger the correct generation in another -- on a range of tasks and model
architectures. Although the task vector is highly compressed, we find that this
single vector outperforms prompting the model with the full task information,
unique to this cross-modal case. Furthermore, we show that task vectors can be
transferred from a base language model to its fine-tuned vision-language
counterpart, and that they can be derived solely from instructions without the
need for examples. Taken together, our findings shed light on how VLMs
internally process task information, and how they map different modalities into
common semantic representations. Project page:
https://vlm-cross-modal-reps.github.io.",2024-10-29,"Grace Luo, Trevor Darrell, Amir Bar",http://arxiv.org/pdf/2410.22330v2,cs.CL
AAAR-1.0: Assessing AI's Potential to Assist Research,"Numerous studies have assessed the proficiency of AI systems, particularly
large language models (LLMs), in facilitating everyday tasks such as email
writing, question answering, and creative content generation. However,
researchers face unique challenges and opportunities in leveraging LLMs for
their own work, such as brainstorming research ideas, designing experiments,
and writing or reviewing papers. In this study, we introduce AAAR-1.0, a
benchmark dataset designed to evaluate LLM performance in three fundamental,
expertise-intensive research tasks: (i) EquationInference, assessing the
correctness of equations based on the contextual information in paper
submissions; (ii) ExperimentDesign, designing experiments to validate research
ideas and solutions; (iii) PaperWeakness, identifying weaknesses in paper
submissions; and (iv) REVIEWCRITIQUE, identifying each segment in human reviews
is deficient or not. AAAR-1.0 differs from prior benchmarks in two key ways:
first, it is explicitly research-oriented, with tasks requiring deep domain
expertise; second, it is researcher-oriented, mirroring the primary activities
that researchers engage in on a daily basis. An evaluation of both open-source
and proprietary LLMs reveals their potential as well as limitations in
conducting sophisticated research tasks. We will keep iterating AAAR-1.0 to new
versions.",2024-10-29,"Renze Lou, Hanzi Xu, Sijia Wang, Jiangshu Du, Ryo Kamoi, Xiaoxin Lu, Jian Xie, Yuxuan Sun, Yusen Zhang, Jihyun Janice Ahn, Hongchao Fang, Zhuoyang Zou, Wenchao Ma, Xi Li, Kai Zhang, Congying Xia, Lifu Huang, Wenpeng Yin",http://arxiv.org/pdf/2410.22394v4,cs.CL
Understanding Synthetic Context Extension via Retrieval Heads,"Long-context LLMs are increasingly in demand for applications such as
retrieval-augmented generation. To defray the cost of pretraining LLMs over
long contexts, recent work takes an approach of synthetic context extension:
fine-tuning LLMs with synthetically generated long-context data in a
post-training stage. However, it remains unclear how and why this synthetic
context extension imparts abilities for downstream long-context tasks. In this
paper, we investigate fine-tuning on synthetic data for three long-context
tasks that require retrieval and reasoning. We vary the realism of ""needle""
concepts to be retrieved and diversity of the surrounding ""haystack"" context,
from using LLMs to construct synthetic documents to using templated relations
and creating symbolic datasets. We find that models trained on synthetic data
fall short of the real data, but surprisingly, the mismatch can be interpreted
and even predicted in terms of a special set of attention heads that are
responsible for retrieval over long context, retrieval heads (Wu et al., 2024).
The retrieval heads learned on synthetic data have high overlap with retrieval
heads learned on real data, and there is a strong correlation between the
recall of heads learned and the downstream performance of a model. Furthermore,
with attention knockout and activation patching, we mechanistically show that
retrieval heads are necessary and explain model performance, although they are
not totally sufficient. Our results shed light on how to interpret synthetic
data fine-tuning performance and how to approach creating better data for
learning real-world capabilities over long contexts.",2024-10-29,"Xinyu Zhao, Fangcong Yin, Greg Durrett",http://arxiv.org/pdf/2410.22316v3,cs.CL
Natural Language Inference Improves Compositionality in Vision-Language Models,"Compositional reasoning in Vision-Language Models (VLMs) remains challenging
as these models often struggle to relate objects, attributes, and spatial
relationships. Recent methods aim to address these limitations by relying on
the semantics of the textual description, using Large Language Models (LLMs) to
break them down into subsets of questions and answers. However, these methods
primarily operate on the surface level, failing to incorporate deeper lexical
understanding while introducing incorrect assumptions generated by the LLM. In
response to these issues, we present Caption Expansion with Contradictions and
Entailments (CECE), a principled approach that leverages Natural Language
Inference (NLI) to generate entailments and contradictions from a given
premise. CECE produces lexically diverse sentences while maintaining their core
meaning. Through extensive experiments, we show that CECE enhances
interpretability and reduces overreliance on biased or superficial features. By
balancing CECE along the original premise, we achieve significant improvements
over previous methods without requiring additional fine-tuning, producing
state-of-the-art results on benchmarks that score agreement with human
judgments for image-text alignment, and achieving an increase in performance on
Winoground of +19.2% (group score) and +12.9% on EqBen (group score) over the
best prior work (finetuned with targeted data).",2024-10-29,"Paola Cascante-Bonilla, Yu Hou, Yang Trista Cao, Hal Daumé III, Rachel Rudinger",http://arxiv.org/pdf/2410.22315v1,cs.CL
SVIP: Towards Verifiable Inference of Open-source Large Language Models,"Open-source Large Language Models (LLMs) have recently demonstrated
remarkable capabilities in natural language understanding and generation,
leading to widespread adoption across various domains. However, their
increasing model sizes render local deployment impractical for individual
users, pushing many to rely on computing service providers for inference
through a blackbox API. This reliance introduces a new risk: a computing
provider may stealthily substitute the requested LLM with a smaller, less
capable model without consent from users, thereby delivering inferior outputs
while benefiting from cost savings. In this paper, we formalize the problem of
verifiable inference for LLMs. Existing verifiable computing solutions based on
cryptographic or game-theoretic techniques are either computationally
uneconomical or rest on strong assumptions. We introduce SVIP, a secret-based
verifiable LLM inference protocol that leverages intermediate outputs from LLM
as unique model identifiers. By training a proxy task on these outputs and
requiring the computing provider to return both the generated text and the
processed intermediate outputs, users can reliably verify whether the computing
provider is acting honestly. In addition, the integration of a secret mechanism
further enhances the security of our protocol. We thoroughly analyze our
protocol under multiple strong and adaptive adversarial scenarios. Our
extensive experiments demonstrate that SVIP is accurate, generalizable,
computationally efficient, and resistant to various attacks. Notably, SVIP
achieves false negative rates below 5% and false positive rates below 3%, while
requiring less than 0.01 seconds per query for verification.",2024-10-29,"Yifan Sun, Yuhang Li, Yue Zhang, Yuchen Jin, Huan Zhang",http://arxiv.org/pdf/2410.22307v1,cs.CL
Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning,"Mathematical reasoning is a crucial capability for Large Language Models
(LLMs), yet generating detailed and accurate reasoning traces remains a
significant challenge. This paper introduces a novel approach to produce
high-quality reasoning traces for LLM fine-tuning using online learning
\textbf{Flows}. Our method employs an incremental output production Flow, where
component LLMs collaboratively construct solutions through iterative
communication. We train the Flow using online Direct Preference Optimization
(DPO) learning with rollouts, generating DPO pairs for each training example
and updating models in real-time. We directly compare the quality of reasoning
traces generated by our method with those produced through direct model
inference, demonstrating the effectiveness of our approach in improving LLM
performance in mathematical reasoning tasks.",2024-10-29,"Yihe Deng, Paul Mineiro",http://arxiv.org/pdf/2410.22304v1,cs.CL
From melodic note sequences to pitches using word2vec,"Applying the word2vec technique, commonly used in language modeling, to
melodies, where notes are treated as words in sentences, enables the capture of
pitch information. This study examines two datasets: 20 children's songs and an
excerpt from a Bach sonata. The semantic space for defining the embeddings is
of very small dimension, specifically 2. Notes are predicted based on the 2, 3
or 4 preceding notes that establish the context. A multivariate analysis of the
results shows that the semantic vectors representing the notes have a multiple
correlation coefficient of approximately 0.80 with their pitches.",2024-10-29,Daniel Defays,http://arxiv.org/pdf/2410.22285v1,cs.CL
DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models,"The rapid advancements in Vision-Language Models (VLMs) have shown great
potential in tackling mathematical reasoning tasks that involve visual context.
Unlike humans who can reliably apply solution steps to similar problems with
minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail
in these scenarios, revealing limitations in their mathematical reasoning
capabilities. In this paper, we investigate the mathematical reasoning
robustness in VLMs and evaluate how well these models perform under different
variants of the same question, such as changes in visual numerical values or
function graphs. While several vision-based math benchmarks have been developed
to assess VLMs' problem-solving capabilities, these benchmarks contain only
static sets of problems and cannot easily evaluate mathematical reasoning
robustness. To fill this gap, we introduce DynaMath, a dynamic visual math
benchmark designed for in-depth assessment of VLMs. DynaMath includes 501
high-quality, multi-topic seed questions, each represented as a Python program.
Those programs are carefully designed and annotated to enable the automatic
generation of a much larger set of concrete questions, including many different
types of visual and textual variations. DynaMath allows us to evaluate the
generalization ability of VLMs, by assessing their performance under varying
input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010
generated concrete questions. Our results show that the worst-case model
accuracy, defined as the percentage of correctly answered seed questions in all
10 variants, is significantly lower than the average-case accuracy. Our
analysis emphasizes the need to study the robustness of VLMs' reasoning
abilities, and DynaMath provides valuable insights to guide the development of
more reliable models for mathematical reasoning.",2024-10-29,"Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang",http://arxiv.org/pdf/2411.00836v2,cs.CL
Fourier Head: Helping Large Language Models Learn Complex Probability Distributions,"As the quality of large language models has improved, there has been
increased interest in using them to model non-linguistic tokens. For example,
the Decision Transformer recasts agentic decision making as a sequence modeling
problem, using a decoder-only LLM to model the distribution over the discrete
action space for an Atari agent. However, when adapting LLMs to non-linguistic
domains, it remains unclear if softmax over discrete bins captures the
continuous structure of the tokens and the potentially complex distributions
needed for high quality token generation. We introduce a neural network layer,
constructed using Fourier series, which we can easily substitute for any linear
layer if we want the outputs to have a more continuous structure. We perform
extensive analysis on synthetic datasets, as well as on large-scale decision
making and time series forecasting tasks. We also provide theoretical evidence
that this layer can better learn signal from data while ignoring high-frequency
noise. All of our results support the effectiveness of our proposed Fourier
head in scenarios where the underlying data distribution has a natural
continuous structure. For example, the Fourier head improves a Decision
Transformer agent's returns across four benchmark Atari games by as much as
377%, and increases a state-of-the-art times series foundation model's
forecasting performance by 3.5% across 20 benchmarks unseen during training.",2024-10-29,"Nate Gillman, Daksh Aggarwal, Michael Freeman, Saurabh Singh, Chen Sun",http://arxiv.org/pdf/2410.22269v2,cs.CL
FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation,"The rapid adoption of language models (LMs) across diverse applications has
raised concerns about their factuality, i.e., their consistency with real-world
facts. We first present VERIFY (Verification and Evidence RetrIeval for
FactualitY evaluation), a pipeline to evaluate LMs' factuality in real-world
user interactions. VERIFY considers the verifiability of LM-generated content
and categorizes content units as supported, unsupported, or undecidable based
on Web-retrieved evidence. Importantly, factuality judgment by VERIFY
correlates better with human evaluations than existing methods. Using VERIFY,
we identify ""hallucination prompts"" across diverse topics, i.e., those
eliciting the highest rates of incorrect (unsupported) and inconclusive
(undecidable) LM responses. These prompts form FACTBENCH, a dataset of 1K
prompts across 150 fine-grained topics. Our dataset captures emerging
factuality challenges in real-world LM interactions and can be regularly
updated with new prompts. We benchmark widely-used LMs from GPT, Gemini, and
Llama families on FACTBENCH, yielding the following key findings: (i)
Proprietary models exhibit better factuality, with decreased performance from
Easy to Hard hallucination prompts. (ii) Llama3.1-405B-Instruct shows
comparable or lower factual precision than Llama3.1-70B-Instruct across all
evaluation methods due to its higher subjectivity that leads to more content
labeled as undecidable. (iii) Gemini1.5-Pro shows a significantly higher
refusal rate, with over-refusal in 25% of cases.",2024-10-29,"Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang",http://arxiv.org/pdf/2410.22257v2,cs.CL
DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers,"Despite their high predictive accuracies, current machine learning systems
often exhibit systematic biases stemming from annotation artifacts or
insufficient support for certain classes in the dataset. Recent work proposes
automatic methods for identifying and explaining systematic biases using
keywords. We introduce DISCERN, a framework for interpreting systematic biases
in text classifiers using language explanations. DISCERN iteratively generates
precise natural language descriptions of systematic errors by employing an
interactive loop between two large language models. Finally, we use the
descriptions to improve classifiers by augmenting classifier training sets with
synthetically generated instances or annotated examples via active learning. On
three text-classification datasets, we demonstrate that language explanations
from our framework induce consistent performance improvements that go beyond
what is achievable with exemplars of systematic bias. Finally, in human
evaluations, we show that users can interpret systematic biases more
effectively (by over 25% relative) and efficiently when described through
language explanations as opposed to cluster exemplars.",2024-10-29,"Rakesh R. Menon, Shashank Srivastava",http://arxiv.org/pdf/2410.22239v1,cs.CL
Cora: Accelerating Stateful Network Applications with SmartNICs,"With the growing performance requirements on networked applications, there is
a new trend of offloading stateful network applications to SmartNICs to improve
performance and reduce the total cost of ownership. However, offloading
stateful network applications is non-trivial due to state operation complexity,
state resource consumption, and the complicated relationship between traffic
and state. Naively partitioning the program by state or traffic can result in a
suboptimal partition plan with higher CPU usage or even packet drops. In this
paper, we propose Cora, a compiler and runtime that offloads stateful network
applications to SmartNIC-accelerated hosts. Cora compiler introduces an
accurate performance model for each SmartNIC and employs an efficient compiling
algorithm to search the offloading plan. Cora runtime can monitor traffic
dynamics and adapt to minimize CPU usage. Cora is built atop Netronome Agilio
and BlueField 2 SmartNICs. Our evaluation shows that for the same throughput
target, Cora can propose partition plans saving up to 94.0% CPU cores, 1.9
times more than baseline solutions. Under the same resource constraint, Cora
can accelerate network functions by 44.9%-82.3%. Cora runtime can adapt to
traffic changes and keep CPU usage low.",2024-10-29,"Shaoke Xi, Jiaqi Gao, Mengqi Liu, Jiamin Cao, Fuliang Li, Kai Bu, Kui Ren, Minlan Yu, Dennis Cai, Ennan Zhai",http://arxiv.org/pdf/2410.22229v1,cs.CL
ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding,"Multimodal systems have great potential to assist humans in procedural
activities, where people follow instructions to achieve their goals. Despite
diverse application scenarios, systems are typically evaluated on traditional
classification tasks, e.g., action recognition or temporal action segmentation.
In this paper, we present a novel evaluation dataset, ProMQA, to measure system
advancements in application-oriented scenarios. ProMQA consists of 401
multimodal procedural QA pairs on user recording of procedural activities
coupled with their corresponding instruction. For QA annotation, we take a
cost-effective human-LLM collaborative approach, where the existing annotation
is augmented with LLM-generated QA pairs that are later verified by humans. We
then provide the benchmark results to set the baseline performance on ProMQA.
Our experiment reveals a significant gap between human performance and that of
current systems, including competitive proprietary multimodal models. We hope
our dataset sheds light on new aspects of models' multimodal understanding
capabilities.",2024-10-29,"Kimihiro Hasegawa, Wiradee Imrattanatrai, Zhi-Qi Cheng, Masaki Asada, Susan Holm, Yuran Wang, Ken Fukuda, Teruko Mitamura",http://arxiv.org/pdf/2410.22211v1,cs.CL
Class-Aware Contrastive Optimization for Imbalanced Text Classification,"The unique characteristics of text data make classification tasks a complex
problem. Advances in unsupervised and semi-supervised learning and autoencoder
architectures addressed several challenges. However, they still struggle with
imbalanced text classification tasks, a common scenario in real-world
applications, demonstrating a tendency to produce embeddings with unfavorable
properties, such as class overlap. In this paper, we show that leveraging
class-aware contrastive optimization combined with denoising autoencoders can
successfully tackle imbalanced text classification tasks, achieving better
performance than the current state-of-the-art. Concretely, our proposal
combines reconstruction loss with contrastive class separation in the embedding
space, allowing a better balance between the truthfulness of the generated
embeddings and the model's ability to separate different classes. Compared with
an extensive set of traditional and state-of-the-art competing methods, our
proposal demonstrates a notable increase in performance across a wide variety
of text datasets.",2024-10-29,"Grigorii Khvatskii, Nuno Moniz, Khoa Doan, Nitesh V Chawla",http://arxiv.org/pdf/2410.22197v1,cs.CL
ADAM: An Embodied Causal Agent in Open-World Environments,"In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.",2024-10-29,"Shu Yu, Chaochao Lu",http://arxiv.org/pdf/2410.22194v1,cs.CL
Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review,"Objective: This review aims to analyze the application of natural language
processing (NLP) techniques in cancer research using electronic health records
(EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused on
specific cancer types or applications. Methods: A comprehensive literature
search was conducted using the Scopus database, identifying 94 relevant studies
published between 2019 and 2024. Data extraction included study
characteristics, cancer types, NLP methodologies, dataset information,
performance metrics, challenges, and future directions. Studies were
categorized based on cancer types and NLP applications. Results: The results
showed a growing trend in NLP applications for cancer research, with breast,
lung, and colorectal cancers being the most studied. Information extraction and
text classification emerged as predominant NLP tasks. A shift from rule-based
to advanced machine learning techniques, particularly transformer-based models,
was observed. The Dataset sizes used in existing studies varied widely. Key
challenges included the limited generalizability of proposed solutions and the
need for improved integration into clinical workflows. Conclusion: NLP
techniques show significant potential in analyzing EHRs and clinical notes for
cancer research. However, future work should focus on improving model
generalizability, enhancing robustness in handling complex clinical language,
and expanding applications to understudied cancer types. Integration of NLP
tools into clinical practice and addressing ethical considerations remain
crucial for utilizing the full potential of NLP in enhancing cancer diagnosis,
treatment, and patient outcomes.",2024-10-29,"Muhammad Bilal, Ameer Hamza, Nadia Malik",http://arxiv.org/pdf/2410.22180v1,cs.CL
Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech,"Autoregressive (AR) Transformer-based sequence models are known to have
difficulty generalizing to sequences longer than those seen during training.
When applied to text-to-speech (TTS), these models tend to drop or repeat words
or produce erratic output, especially for longer utterances. In this paper, we
introduce enhancements aimed at AR Transformer-based encoder-decoder TTS
systems that address these robustness and length generalization issues. Our
approach uses an alignment mechanism to provide cross-attention operations with
relative location information. The associated alignment position is learned as
a latent property of the model via backpropagation and requires no external
alignment information during training. While the approach is tailored to the
monotonic nature of TTS input-output alignment, it is still able to benefit
from the flexible modeling power of interleaved multi-head self- and
cross-attention operations. A system incorporating these improvements, which we
call Very Attentive Tacotron, matches the naturalness and expressiveness of a
baseline T5-based TTS system, while eliminating problems with repeated or
dropped words and enabling generalization to any practical utterance length.",2024-10-29,"Eric Battenberg, RJ Skerry-Ryan, Daisy Stanton, Soroosh Mariooryad, Matt Shannon, Julian Salazar, David Kao",http://arxiv.org/pdf/2410.22179v2,cs.CL
Improving Math Problem Solving in Large Language Models Through Categorization and Strategy Tailoring,"In this paper, we explore how to leverage large language models (LLMs) to
solve mathematical problems efficiently and accurately. Specifically, we
demonstrate the effectiveness of classifying problems into distinct categories
and employing category-specific problem-solving strategies to improve the
mathematical performance of LLMs. We design a simple yet intuitive machine
learning model for problem categorization and show that its accuracy can be
significantly enhanced through the development of well-curated training
datasets. Additionally, we find that the performance of this simple model
approaches that of state-of-the-art (SOTA) models for categorization. Moreover,
the accuracy of SOTA models also benefits from the use of improved training
data. Finally, we assess the advantages of using category-specific strategies
when prompting LLMs and observe significantly better performance compared to
non-tailored approaches.",2024-10-29,Amogh Akella,http://arxiv.org/pdf/2411.00042v3,cs.CL
Benchmarking LLM Guardrails in Handling Multilingual Toxicity,"With the ubiquity of Large Language Models (LLMs), guardrails have become
crucial to detect and defend against toxic content. However, with the
increasing pervasiveness of LLMs in multilingual scenarios, their effectiveness
in handling multilingual toxic inputs remains unclear. In this work, we
introduce a comprehensive multilingual test suite, spanning seven datasets and
over ten languages, to benchmark the performance of state-of-the-art
guardrails. We also investigates the resilience of guardrails against recent
jailbreaking techniques, and assess the impact of in-context safety policies
and language resource availability on guardrails' performance. Our findings
show that existing guardrails are still ineffective at handling multilingual
toxicity and lack robustness against jailbreaking prompts. This work aims to
identify the limitations of guardrails and to build a more reliable and
trustworthy LLMs in multilingual scenarios.",2024-10-29,"Yahan Yang, Soham Dan, Dan Roth, Insup Lee",http://arxiv.org/pdf/2410.22153v1,cs.CL
AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts,"Although large language models (LLMs) are typically aligned, they remain
vulnerable to jailbreaking through either carefully crafted prompts in natural
language or, interestingly, gibberish adversarial suffixes. However, gibberish
tokens have received relatively less attention despite their success in
attacking aligned LLMs. Recent work, AmpleGCG~\citep{liao2024amplegcg},
demonstrates that a generative model can quickly produce numerous customizable
gibberish adversarial suffixes for any harmful query, exposing a range of
alignment gaps in out-of-distribution (OOD) language spaces. To bring more
attention to this area, we introduce AmpleGCG-Plus, an enhanced version that
achieves better performance in fewer attempts. Through a series of exploratory
experiments, we identify several training strategies to improve the learning of
gibberish suffixes. Our results, verified under a strict evaluation setting,
show that it outperforms AmpleGCG on both open-weight and closed-source models,
achieving increases in attack success rate (ASR) of up to 17\% in the white-box
setting against Llama-2-7B-chat, and more than tripling ASR in the black-box
setting against GPT-4. Notably, AmpleGCG-Plus jailbreaks the newer GPT-4o
series of models at similar rates to GPT-4, and, uncovers vulnerabilities
against the recently proposed circuit breakers defense. We publicly release
AmpleGCG-Plus along with our collected training datasets.",2024-10-29,"Vishal Kumar, Zeyi Liao, Jaylen Jones, Huan Sun",http://arxiv.org/pdf/2410.22143v1,cs.CL
RankUp: Boosting Semi-Supervised Regression with an Auxiliary Ranking Classifier,"State-of-the-art (SOTA) semi-supervised learning techniques, such as FixMatch
and it's variants, have demonstrated impressive performance in classification
tasks. However, these methods are not directly applicable to regression tasks.
In this paper, we present RankUp, a simple yet effective approach that adapts
existing semi-supervised classification techniques to enhance the performance
of regression tasks. RankUp achieves this by converting the original regression
task into a ranking problem and training it concurrently with the original
regression objective. This auxiliary ranking classifier outputs a
classification result, thus enabling integration with existing semi-supervised
classification methods. Moreover, we introduce regression distribution
alignment (RDA), a complementary technique that further enhances RankUp's
performance by refining pseudo-labels through distribution alignment. Despite
its simplicity, RankUp, with or without RDA, achieves SOTA results in across a
range of regression benchmarks, including computer vision, audio, and natural
language processing tasks. Our code and log data are open-sourced at
https://github.com/pm25/semi-supervised-regression.",2024-10-29,"Pin-Yen Huang, Szu-Wei Fu, Yu Tsao",http://arxiv.org/pdf/2410.22124v1,cs.CL
The Impact of Inference Acceleration on Bias of LLMs,"Last few years have seen unprecedented advances in capabilities of Large
Language Models (LLMs). These advancements promise to benefit a vast array of
application domains. However, due to their immense size, performing inference
with LLMs is both costly and slow. Consequently, a plethora of recent work has
proposed strategies to enhance inference efficiency, e.g., quantization,
pruning, and caching. These acceleration strategies reduce the inference cost
and latency, often by several factors, while maintaining much of the predictive
performance measured via common benchmarks. In this work, we explore another
critical aspect of LLM performance: demographic bias in model generations due
to inference acceleration optimizations. Using a wide range of metrics, we
probe bias in model outputs from a number of angles. Analysis of outputs before
and after inference acceleration shows significant change in bias. Worryingly,
these bias effects are complex and unpredictable. A combination of an
acceleration strategy and bias type may show little bias change in one model
but may lead to a large effect in another. Our results highlight a need for
in-depth and case-by-case evaluation of model bias after it has been modified
to accelerate inference.",2024-10-29,"Elisabeth Kirsten, Ivan Habernal, Vedant Nanda, Muhammad Bilal Zafar",http://arxiv.org/pdf/2410.22118v2,cs.CL
Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench,"Generative models such as Large Language Models (LLM) and Multimodal Large
Language models (MLLMs) trained on massive web corpora can memorize and
disclose individuals' confidential and private data, raising legal and ethical
concerns. While many previous works have addressed this issue in LLM via
machine unlearning, it remains largely unexplored for MLLMs. To tackle this
challenge, we introduce Multimodal Large Language Model Unlearning Benchmark
(MLLMU-Bench), a novel benchmark aimed at advancing the understanding of
multimodal machine unlearning. MLLMU-Bench consists of 500 fictitious profiles
and 153 profiles for public celebrities, each profile feature over 14
customized question-answer pairs, evaluated from both multimodal (image+text)
and unimodal (text) perspectives. The benchmark is divided into four sets to
assess unlearning algorithms in terms of efficacy, generalizability, and model
utility. Finally, we provide baseline results using existing generative model
unlearning algorithms. Surprisingly, our experiments show that unimodal
unlearning algorithms excel in generation and cloze tasks, while multimodal
unlearning approaches perform better in classification tasks with multimodal
inputs.",2024-10-29,"Zheyuan Liu, Guangyao Dou, Mengzhao Jia, Zhaoxuan Tan, Qingkai Zeng, Yongle Yuan, Meng Jiang",http://arxiv.org/pdf/2410.22108v2,cs.CL
Joint Extraction and Classification of Danish Competences for Job Matching,"The matching of competences, such as skills, occupations or knowledges, is a
key desiderata for candidates to be fit for jobs. Automatic extraction of
competences from CVs and Jobs can greatly promote recruiters' productivity in
locating relevant candidates for job vacancies. This work presents the first
model that jointly extracts and classifies competence from Danish job postings.
Different from existing works on skill extraction and skill classification, our
model is trained on a large volume of annotated Danish corpora and is capable
of extracting a wide range of Danish competences, including skills, occupations
and knowledges of different categories. More importantly, as a single BERT-like
architecture for joint extraction and classification, our model is lightweight
and efficient at inference. On a real-scenario job matching dataset, our model
beats the state-of-the-art models in the overall performance of Danish
competence extraction and classification, and saves over 50% time at inference.",2024-10-29,"Qiuchi Li, Christina Lioma",http://arxiv.org/pdf/2410.22103v1,cs.CL
NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering,"The growing volume of biomedical scholarly document abstracts presents an
increasing challenge in efficiently retrieving accurate and relevant
information. To address this, we introduce a novel approach that integrates an
optimized topic modelling framework, OVB-LDA, with the BI-POP CMA-ES
optimization technique for enhanced scholarly document abstract categorization.
Complementing this, we employ the distilled MiniLM model, fine-tuned on
domain-specific data, for high-precision answer extraction. Our approach is
evaluated across three configurations: scholarly document abstract retrieval,
gold-standard scholarly documents abstract, and gold-standard snippets,
consistently outperforming established methods such as RYGH and bio-answer
finder. Notably, we demonstrate that extracting answers from scholarly
documents abstracts alone can yield high accuracy, underscoring the sufficiency
of abstracts for many biomedical queries. Despite its compact size, MiniLM
exhibits competitive performance, challenging the prevailing notion that only
large, resource-intensive models can handle such complex tasks. Our results,
validated across various question types and evaluation batches, highlight the
robustness and adaptability of our method in real-world biomedical
applications. While our approach shows promise, we identify challenges in
handling complex list-type questions and inconsistencies in evaluation metrics.
Future work will focus on refining the topic model with more extensive
domain-specific datasets, further optimizing MiniLM and utilizing large
language models (LLM) to improve both precision and efficiency in biomedical
question answering.",2024-10-29,"Parvez Zamil, Gollam Rabby, Md. Sadekur Rahman, Sören Auer",http://arxiv.org/pdf/2411.00041v1,cs.CL
Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate,"Machine unlearning has been used to remove unwanted knowledge acquired by
large language models (LLMs). In this paper, we examine machine unlearning from
an optimization perspective, framing it as a regularized multi-task
optimization problem, where one task optimizes a forgetting objective and
another optimizes the model performance. In particular, we introduce a
normalized gradient difference (NGDiff) algorithm, enabling us to have better
control over the trade-off between the objectives, while integrating a new,
automatic learning rate scheduler. We provide a theoretical analysis and
empirically demonstrate the superior performance of NGDiff among
state-of-the-art unlearning methods on the TOFU and MUSE datasets while
exhibiting stable training.",2024-10-29,"Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong",http://arxiv.org/pdf/2410.22086v3,cs.CL
Choosy Babies Need One Coach: Inducing Mode-Seeking Behavior in BabyLlama with Reverse KL Divergence,"This study presents our submission to the Strict-Small Track of the 2nd
BabyLM Challenge. We use a teacher-student distillation setup with the
BabyLLaMa model (Timiryasov and Tastet, 2023) as a backbone. To make the
student's learning process more focused, we replace the objective function with
a reverse Kullback-Leibler divergence, known to cause mode-seeking (rather than
mode-averaging) behaviour in computational learners. We further experiment with
having a single teacher (instead of an ensemble of two teachers) and implement
additional optimization strategies to improve the distillation process. Our
experiments show that under reverse KL divergence, a single-teacher model often
outperforms or matches multiple-teacher models across most tasks. Additionally,
incorporating advanced optimization techniques further enhances model
performance, demonstrating the effectiveness and robustness of our proposed
approach. These findings support our idea that ""choosy babies need one coach"".",2024-10-29,"Shaozhen Shi, Yevgen Matusevych, Malvina Nissim",http://arxiv.org/pdf/2410.22081v1,cs.CL
Distinguishing Ignorance from Error in LLM Hallucinations,"Large language models (LLMs) are susceptible to hallucinations -- factually
incorrect outputs -- leading to a large body of work on detecting and
mitigating such cases. We argue that it is important to distinguish between two
types of hallucinations: ones where the model does not hold the correct answer
in its parameters, which we term HK-, and ones where the model answers
incorrectly despite having the required knowledge, termed HK+. We first find
that HK+ hallucinations are prevalent and occur across models and datasets.
Then, we demonstrate that distinguishing between these two cases is beneficial
for mitigating hallucinations. Importantly, we show that different models
hallucinate on different examples, which motivates constructing model-specific
hallucination datasets for training detectors. Overall, our findings draw
attention to classifying types of hallucinations and provide means to handle
them more effectively. The code is available at
https://github.com/technion-cs-nlp/hallucination-mitigation .",2024-10-29,"Adi Simhi, Jonathan Herzig, Idan Szpektor, Yonatan Belinkov",http://arxiv.org/pdf/2410.22071v2,cs.CL
"Sing it, Narrate it: Quality Musical Lyrics Translation","Translating lyrics for musicals presents unique challenges due to the need to
ensure high translation quality while adhering to singability requirements such
as length and rhyme. Existing song translation approaches often prioritize
these singability constraints at the expense of translation quality, which is
crucial for musicals. This paper aims to enhance translation quality while
maintaining key singability features. Our method consists of three main
components. First, we create a dataset to train reward models for the automatic
evaluation of translation quality. Second, to enhance both singability and
translation quality, we implement a two-stage training process with filtering
techniques. Finally, we introduce an inference-time optimization framework for
translating entire songs. Extensive experiments, including both automatic and
human evaluations, demonstrate significant improvements over baseline methods
and validate the effectiveness of each component in our approach.",2024-10-29,"Zhuorui Ye, Jinhan Li, Rongwu Xu",http://arxiv.org/pdf/2410.22066v1,cs.CL
Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models,"Fine-tuning large language models (LLMs) has become essential for adapting
pretrained models to specific downstream tasks. In this paper, we propose
Linear Chain Transformation (LinChain), a novel approach that introduces a
sequence of linear transformations during fine-tuning to enrich optimization
dynamics. By incorporating multiple linear transformations into the parameter
update process, LinChain expands the effective rank of updates and enhances the
model's ability to learn complex task-specific representations. We demonstrate
that this method significantly improves the performance of LLM fine-tuning over
state-of-the-art methods by providing more flexible optimization paths during
training, while maintaining the inference efficiency of the resulting model.
Our experiments on various benchmark tasks show that LinChain leads to better
generalization, fewer learnable parameters, and improved task adaptation,
making it a compelling strategy for LLM fine-tuning.",2024-10-29,"Yulong Wang, Chang Zuo, Yin Xuan, Hong Li, Ni Wei",http://arxiv.org/pdf/2411.00039v1,cs.CL
Topic-Conversation Relevance (TCR) Dataset and Benchmarks,"Workplace meetings are vital to organizational collaboration, yet a large
percentage of meetings are rated as ineffective. To help improve meeting
effectiveness by understanding if the conversation is on topic, we create a
comprehensive Topic-Conversation Relevance (TCR) dataset that covers a variety
of domains and meeting styles. The TCR dataset includes 1,500 unique meetings,
22 million words in transcripts, and over 15,000 meeting topics, sourced from
both newly collected Speech Interruption Meeting (SIM) data and existing public
datasets. Along with the text data, we also open source scripts to generate
synthetic meetings or create augmented meetings from the TCR dataset to enhance
data diversity. For each data source, benchmarks are created using GPT-4 to
evaluate the model accuracy in understanding transcription-topic relevance.",2024-10-29,"Yaran Fan, Jamie Pool, Senja Filipi, Ross Cutler",http://arxiv.org/pdf/2411.00038v2,cs.CL
Are VLMs Really Blind,"Vision Language Models excel in handling a wide range of complex tasks,
including Optical Character Recognition (OCR), Visual Question Answering (VQA),
and advanced geometric reasoning. However, these models fail to perform well on
low-level basic visual tasks which are especially easy for humans. Our goal in
this work was to determine if these models are truly ""blind"" to geometric
reasoning or if there are ways to enhance their capabilities in this area. Our
work presents a novel automatic pipeline designed to extract key information
from images in response to specific questions. Instead of just relying on
direct VQA, we use question-derived keywords to create a caption that
highlights important details in the image related to the question. This caption
is then used by a language model to provide a precise answer to the question
without requiring external fine-tuning.",2024-10-29,"Ayush Singh, Mansi Gupta, Shivank Garg",http://arxiv.org/pdf/2410.22029v1,cs.CL
Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot,"Companies support their customers using live chats and chatbots to gain their
loyalty. AFAS is a Dutch company aiming to leverage the opportunity large
language models (LLMs) offer to answer customer queries with minimal to no
input from its customer support team. Adding to its complexity, it is unclear
what makes a response correct, and that too in Dutch. Further, with minimal
data available for training, the challenge is to identify whether an answer
generated by a large language model is correct and do it on the fly.
  This study is the first to define the correctness of a response based on how
the support team at AFAS makes decisions. It leverages literature on natural
language generation and automated answer grading systems to automate the
decision-making of the customer support team. We investigated questions
requiring a binary response (e.g., Would it be possible to adjust tax rates
manually?) or instructions (e.g., How would I adjust tax rate manually?) to
test how close our automated approach reaches support rating. Our approach can
identify wrong messages in 55\% of the cases. This work shows the viability of
automatically assessing when our chatbot tell lies.",2024-10-29,"Herman Lassche, Michiel Overeem, Ayushi Rastogi",http://arxiv.org/pdf/2411.00034v1,cs.CL
Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented Generation,"RALMs (Retrieval-Augmented Language Models) broaden their knowledge scope by
incorporating external textual resources. However, the multilingual nature of
global knowledge necessitates RALMs to handle diverse languages, a topic that
has received limited research focus. In this work, we propose
\textit{Futurepedia}, a carefully crafted benchmark containing parallel texts
across eight representative languages. We evaluate six multilingual RALMs using
our benchmark to explore the challenges of multilingual RALMs. Experimental
results reveal linguistic inequalities: 1) high-resource languages stand out in
Monolingual Knowledge Extraction; 2) Indo-European languages lead RALMs to
provide answers directly from documents, alleviating the challenge of
expressing answers across languages; 3) English benefits from RALMs' selection
bias and speaks louder in multilingual knowledge selection. Based on these
findings, we offer advice for improving multilingual Retrieval Augmented
Generation. For monolingual knowledge extraction, careful attention must be
paid to cascading errors from translating low-resource languages into
high-resource ones. In cross-lingual knowledge transfer, encouraging RALMs to
provide answers within documents in different languages can improve transfer
performance. For multilingual knowledge selection, incorporating more
non-English documents and repositioning English documents can help mitigate
RALMs' selection bias. Through comprehensive experiments, we underscore the
complexities inherent in multilingual RALMs and offer valuable insights for
future research.",2024-10-29,"Suhang Wu, Jialong Tang, Baosong Yang, Ante Wang, Kaidi Jia, Jiawei Yu, Junfeng Yao, Jinsong Su",http://arxiv.org/pdf/2410.21970v1,cs.CL
SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types,"Ensuring the safety of large language model (LLM) applications is essential
for developing trustworthy artificial intelligence. Current LLM safety
benchmarks have two limitations. First, they focus solely on either
discriminative or generative evaluation paradigms while ignoring their
interconnection. Second, they rely on standardized inputs, overlooking the
effects of widespread prompting techniques, such as system prompts, few-shot
demonstrations, and chain-of-thought prompting. To overcome these issues, we
developed SG-Bench, a novel benchmark to assess the generalization of LLM
safety across various tasks and prompt types. This benchmark integrates both
generative and discriminative evaluation tasks and includes extended data to
examine the impact of prompt engineering and jailbreak on LLM safety. Our
assessment of 3 advanced proprietary LLMs and 10 open-source LLMs with the
benchmark reveals that most LLMs perform worse on discriminative tasks than
generative ones, and are highly susceptible to prompts, indicating poor
generalization in safety alignment. We also explain these findings
quantitatively and qualitatively to provide insights for future research.",2024-10-29,"Yutao Mou, Shikun Zhang, Wei Ye",http://arxiv.org/pdf/2410.21965v1,cs.CL
Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications,"Large Language Models (LLMs) have demonstrated impressive capabilities in
answering questions, but they lack domain-specific knowledge and are prone to
hallucinations. Retrieval Augmented Generation (RAG) is one approach to address
these challenges, while multimodal models are emerging as promising AI
assistants for processing both text and images. In this paper we describe a
series of experiments aimed at determining how to best integrate multimodal
models into RAG systems for the industrial domain. The purpose of the
experiments is to determine whether including images alongside text from
documents within the industrial domain increases RAG performance and to find
the optimal configuration for such a multimodal RAG system. Our experiments
include two approaches for image processing and retrieval, as well as two LLMs
(GPT4-Vision and LLaVA) for answer synthesis. These image processing strategies
involve the use of multimodal embeddings and the generation of textual
summaries from images. We evaluate our experiments with an LLM-as-a-Judge
approach. Our results reveal that multimodal RAG can outperform single-modality
RAG settings, although image retrieval poses a greater challenge than text
retrieval. Additionally, leveraging textual summaries from images presents a
more promising approach compared to the use of multimodal embeddings, providing
more opportunities for future advancements.",2024-10-29,"Monica Riedler, Stefan Langer",http://arxiv.org/pdf/2410.21943v1,cs.CL
A Big Data-empowered System for Real-time Detection of Regional Discriminatory Comments on Vietnamese Social Media,"Regional discrimination is a persistent social issue in Vietnam. While
existing research has explored hate speech in the Vietnamese language, the
specific issue of regional discrimination remains under-addressed. Previous
studies primarily focused on model development without considering practical
system implementation. In this work, we propose a task called Detection of
Regional Discriminatory Comments on Vietnamese Social Media, leveraging the
power of machine learning and transfer learning models. We have built the ViRDC
(Vietnamese Regional Discrimination Comments) dataset, which contains comments
from social media platforms, providing a valuable resource for further research
and development. Our approach integrates streaming capabilities to process
real-time data from social media networks, ensuring the system's scalability
and responsiveness. We developed the system on the Apache Spark framework to
efficiently handle increasing data inputs during streaming. Our system offers a
comprehensive solution for the real-time detection of regional discrimination
in Vietnam.",2024-10-29,"An Nghiep Huynh, Thanh Dat Do, Trong Hop Do",http://arxiv.org/pdf/2411.02587v1,cs.CL
SceneGenAgent: Precise Industrial Scene Generation with Coding Agent,"The modeling of industrial scenes is essential for simulations in industrial
manufacturing. While large language models (LLMs) have shown significant
progress in generating general 3D scenes from textual descriptions, generating
industrial scenes with LLMs poses a unique challenge due to their demand for
precise measurements and positioning, requiring complex planning over spatial
arrangement. To address this challenge, we introduce SceneGenAgent, an
LLM-based agent for generating industrial scenes through C# code. SceneGenAgent
ensures precise layout planning through a structured and calculable format,
layout verification, and iterative refinement to meet the quantitative
requirements of industrial scenarios. Experiment results demonstrate that LLMs
powered by SceneGenAgent exceed their original performance, reaching up to
81.0% success rate in real-world industrial scene generation tasks and
effectively meeting most scene generation requirements. To further enhance
accessibility, we construct SceneInstruct, a dataset designed for fine-tuning
open-source LLMs to integrate into SceneGenAgent. Experiments show that
fine-tuning open-source LLMs on SceneInstruct yields significant performance
improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our
code and data are available at https://github.com/THUDM/SceneGenAgent .",2024-10-29,"Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong",http://arxiv.org/pdf/2410.21909v2,cs.CL
A Longitudinal Analysis of Racial and Gender Bias in New York Times and Fox News Images and Articles,"The manner in which different racial and gender groups are portrayed in news
coverage plays a large role in shaping public opinion. As such, understanding
how such groups are portrayed in news media is of notable societal value, and
has thus been a significant endeavour in both the computer and social sciences.
Yet, the literature still lacks a longitudinal study examining both the
frequency of appearance of different racial and gender groups in online news
articles, as well as the context in which such groups are discussed. To fill
this gap, we propose two machine learning classifiers to detect the race and
age of a given subject. Next, we compile a dataset of 123,337 images and
441,321 online news articles from New York Times (NYT) and Fox News (Fox), and
examine representation through two computational approaches. Firstly, we
examine the frequency and prominence of appearance of racial and gender groups
in images embedded in news articles, revealing that racial and gender
minorities are largely under-represented, and when they do appear, they are
featured less prominently compared to majority groups. Furthermore, we find
that NYT largely features more images of racial minority groups compared to
Fox. Secondly, we examine both the frequency and context with which racial
minority groups are presented in article text. This reveals the narrow scope in
which certain racial groups are covered and the frequency with which different
groups are presented as victims and/or perpetrators in a given conflict. Taken
together, our analysis contributes to the literature by providing two novel
open-source classifiers to detect race and age from images, and shedding light
on the racial and gender biases in news articles from venues on opposite ends
of the American political spectrum.",2024-10-29,"Hazem Ibrahim, Nouar AlDahoul, Syed Mustafa Ali Abbasi, Fareed Zaffar, Talal Rahwan, Yasir Zaki",http://arxiv.org/pdf/2410.21898v2,cs.CL
Evaluating K-Fold Cross Validation for Transformer Based Symbolic Regression Models,"Symbolic Regression remains an NP-Hard problem, with extensive research
focusing on AI models for this task. Transformer models have shown promise in
Symbolic Regression, but performance suffers with smaller datasets. We propose
applying k-fold cross-validation to a transformer-based symbolic regression
model trained on a significantly reduced dataset (15,000 data points, down from
500,000). This technique partitions the training data into multiple subsets
(folds), iteratively training on some while validating on others. Our aim is to
provide an estimate of model generalization and mitigate overfitting issues
associated with smaller datasets. Results show that this process improves the
model's output consistency and generalization by a relative improvement in
validation loss of 53.31%. Potentially enabling more efficient and accessible
symbolic regression in resource-constrained environments.",2024-10-29,"Kaustubh Kislay, Shlok Singh, Soham Joshi, Rohan Dutta, Jay Shim George Flint, Kevin Zhu",http://arxiv.org/pdf/2410.21896v1,cs.CL
Improving In-Context Learning with Small Language Model Ensembles,"Large language models (LLMs) have shown impressive capabilities across
various tasks, but their performance on domain-specific tasks remains limited.
While methods like retrieval augmented generation and fine-tuning can help to
address this, they require significant resources. In-context learning (ICL) is
a cheap and efficient alternative but cannot match the accuracies of advanced
methods. We present Ensemble SuperICL, a novel approach that enhances ICL by
leveraging the expertise of multiple fine-tuned small language models (SLMs).
Ensemble SuperICL achieves state of the art (SoTA) results on several natural
language understanding benchmarks. Additionally, we test it on a medical-domain
labelling task and showcase its practicality by using off-the-shelf SLMs
fine-tuned on a general language task, achieving superior accuracy in
large-scale data labelling compared to all baselines. Finally, we conduct an
ablation study and sensitivity analyses to elucidate the underlying mechanism
of Ensemble SuperICL. Our research contributes to the growing demand for
efficient domain specialisation methods in LLMs, offering a cheap and effective
method for practitioners.",2024-10-29,"M. Mehdi Mojarradi, Lingyi Yang, Robert McCraith, Adam Mahdi",http://arxiv.org/pdf/2410.21868v2,cs.CL
Joint Beamforming and Speaker-Attributed ASR for Real Distant-Microphone Meeting Transcription,"Distant-microphone meeting transcription is a challenging task.
State-of-the-art end-to-end speaker-attributed automatic speech recognition
(SA-ASR) architectures lack a multichannel noise and reverberation reduction
front-end, which limits their performance. In this paper, we introduce a joint
beamforming and SA-ASR approach for real meeting transcription. We first
describe a data alignment and augmentation method to pretrain a neural
beamformer on real meeting data. We then compare fixed, hybrid, and fully
neural beamformers as front-ends to the SA-ASR model. Finally, we jointly
optimize the fully neural beamformer and the SA-ASR model. Experiments on the
real AMI corpus show that,while state-of-the-art multi-frame cross-channel
attention based channel fusion fails to improve ASR performance, fine-tuning
SA-ASR on the fixed beamformer's output and jointly fine-tuning SA-ASR with the
neural beamformer reduce the word error rate by 8% and 9% relative,
respectively.",2024-10-29,"Can Cui, Imran Ahamad Sheikh, Mostafa Sadeghi, Emmanuel Vincent",http://arxiv.org/pdf/2410.21849v1,cs.CL
WikiNER-fr-gold: A Gold-Standard NER Corpus,"We address in this article the the quality of the WikiNER corpus, a
multilingual Named Entity Recognition corpus, and provide a consolidated
version of it. The annotation of WikiNER was produced in a semi-supervised
manner i.e. no manual verification has been carried out a posteriori. Such
corpus is called silver-standard. In this paper we propose WikiNER-fr-gold
which is a revised version of the French proportion of WikiNER. Our corpus
consists of randomly sampled 20% of the original French sub-corpus (26,818
sentences with 700k tokens). We start by summarizing the entity types included
in each category in order to define an annotation guideline, and then we
proceed to revise the corpus. Finally we present an analysis of errors and
inconsistency observed in the WikiNER-fr corpus, and we discuss potential
future work directions.",2024-10-29,"Danrun Cao, Nicolas Béchet, Pierre-François Marteau",http://arxiv.org/pdf/2411.00030v2,cs.CL
Multi-aspect Depression Severity Assessment via Inductive Dialogue System,"With the advancement of chatbots and the growing demand for automatic
depression detection, identifying depression in patient conversations has
gained more attention. However, prior methods often assess depression in a
binary way or only a single score without diverse feedback and lack focus on
enhancing dialogue responses. In this paper, we present a novel task of
multi-aspect depression severity assessment via an inductive dialogue system
(MaDSA), evaluating a patient's depression level on multiple criteria by
incorporating an assessment-aided response generation. Further, we propose a
foundational system for MaDSA, which induces psychological dialogue responses
with an auxiliary emotion classification task within a hierarchical severity
assessment structure. We synthesize the conversational dataset annotated with
eight aspects of depression severity alongside emotion labels, proven robust
via human evaluations. Experimental results show potential for our preliminary
work on MaDSA.",2024-10-29,"Chaebin Lee, Seungyeon Seo, Heejin Do, Gary Geunbae Lee",http://arxiv.org/pdf/2410.21836v1,cs.CL
Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models,"Recently, we have observed that Large Multi-modal Models (LMMs) are
revolutionizing the way machines interact with the world, unlocking new
possibilities across various multi-modal applications. To adapt LMMs for
downstream tasks, parameter-efficient fine-tuning (PEFT) which only trains
additional prefix tokens or modules, has gained popularity. Nevertheless, there
has been little analysis of how PEFT works in LMMs. In this paper, we delve
into the strengths and weaknesses of each tuning strategy, shifting the focus
from the efficiency typically associated with these approaches. We first
discover that model parameter tuning methods such as LoRA and Adapters distort
the feature representation space learned during pre-training and limit the full
utilization of pre-trained knowledge. We also demonstrate that prefix-tuning
excels at preserving the representation space, despite its lower performance on
downstream tasks. These findings suggest a simple two-step PEFT strategy called
Prefix-Tuned PEFT (PT-PEFT), which successively performs prefix-tuning and then
PEFT (i.e., Adapter, LoRA), combines the benefits of both. Experimental results
show that PT-PEFT not only improves performance in image captioning and visual
question answering compared to vanilla PEFT methods but also helps preserve the
representation space of the four pre-trained models.",2024-10-29,"Donghoon Kim, Gusang Lee, Kyuhong Shim, Byonghyo Shim",http://arxiv.org/pdf/2411.00029v1,cs.CL
Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance,"State-of-the-art text-to-image (T2I) diffusion models often struggle to
generate rare compositions of concepts, e.g., objects with unusual attributes.
In this paper, we show that the compositional generation power of diffusion
models on such rare concepts can be significantly enhanced by the Large
Language Model (LLM) guidance. We start with empirical and theoretical
analysis, demonstrating that exposing frequent concepts relevant to the target
rare concepts during the diffusion sampling process yields more accurate
concept composition. Based on this, we propose a training-free approach, R2F,
that plans and executes the overall rare-to-frequent concept guidance
throughout the diffusion inference by leveraging the abundant semantic
knowledge in LLMs. Our framework is flexible across any pre-trained diffusion
models and LLMs, and can be seamlessly integrated with the region-guided
diffusion approaches. Extensive experiments on three datasets, including our
newly proposed benchmark, RareBench, containing various prompts with rare
compositions of concepts, R2F significantly surpasses existing models including
SD3.0 and FLUX by up to 28.1%p in T2I alignment. Code is available at
https://github.com/krafton-ai/Rare-to-Frequent.",2024-10-29,"Dongmin Park, Sebin Kim, Taehong Moon, Minkyu Kim, Kangwook Lee, Jaewoong Cho",http://arxiv.org/pdf/2410.22376v2,cs.CL
Self-Preference Bias in LLM-as-a-Judge,"Automated evaluation leveraging large language models (LLMs), commonly
referred to as LLM evaluators or LLM-as-a-judge, has been widely used in
measuring the performance of dialogue systems. However, the self-preference
bias in LLMs has posed significant risks, including promoting specific styles
or policies intrinsic to the LLMs. Despite the importance of this issue, there
is a lack of established methods to measure the self-preference bias
quantitatively, and its underlying causes are poorly understood. In this paper,
we introduce a novel quantitative metric to measure the self-preference bias.
Our experimental results demonstrate that GPT-4 exhibits a significant degree
of self-preference bias. To explore the causes, we hypothesize that LLMs may
favor outputs that are more familiar to them, as indicated by lower perplexity.
We analyze the relationship between LLM evaluations and the perplexities of
outputs. Our findings reveal that LLMs assign significantly higher evaluations
to outputs with lower perplexity than human evaluators, regardless of whether
the outputs were self-generated. This suggests that the essence of the bias
lies in perplexity and that the self-preference bias exists because LLMs prefer
texts more familiar to them.",2024-10-29,"Koki Wataoka, Tsubasa Takahashi, Ryokan Ri",http://arxiv.org/pdf/2410.21819v1,cs.CL
Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Transformers,"The debate between self-interpretable models and post-hoc explanations for
black-box models is central to Explainable AI (XAI). Self-interpretable models,
such as concept-based networks, offer insights by connecting decisions to
human-understandable concepts but often struggle with performance and
scalability. Conversely, post-hoc methods like Shapley values, while
theoretically robust, are computationally expensive and resource-intensive. To
bridge the gap between these two lines of research, we propose a novel method
that combines their strengths, providing theoretically guaranteed
self-interpretability for black-box models without compromising prediction
accuracy. Specifically, we introduce a parameter-efficient pipeline,
AutoGnothi, which integrates a small side network into the black-box model,
allowing it to generate Shapley value explanations without changing the
original network parameters. This side-tuning approach significantly reduces
memory, training, and inference costs, outperforming traditional
parameter-efficient methods, where full fine-tuning serves as the optimal
baseline. AutoGnothi enables the black-box model to predict and explain its
predictions with minimal overhead. Extensive experiments show that AutoGnothi
offers accurate explanations for both vision and language tasks, delivering
superior computational efficiency with comparable interpretability.",2024-10-29,"Shaobo Wang, Hongxuan Tang, Mingyang Wang, Hongrui Zhang, Xuyang Liu, Weiya Li, Xuming Hu, Linfeng Zhang",http://arxiv.org/pdf/2410.21815v2,cs.CL
SimSiam Naming Game: A Unified Approach for Representation Learning and Emergent Communication,"Emergent communication, driven by generative models, enables agents to
develop a shared language for describing their individual views of the same
objects through interactions. Meanwhile, self-supervised learning (SSL),
particularly SimSiam, uses discriminative representation learning to make
representations of augmented views of the same data point closer in the
representation space. Building on the prior work of VI-SimSiam, which
incorporates a generative and Bayesian perspective into the SimSiam framework
via variational inference (VI) interpretation, we propose SimSiam+VAE, a
unified approach for both representation learning and emergent communication.
SimSiam+VAE integrates a variational autoencoder (VAE) into the predictor of
the SimSiam network to enhance representation learning and capture uncertainty.
Experimental results show that SimSiam+VAE outperforms both SimSiam and
VI-SimSiam. We further extend this model into a communication framework called
the SimSiam Naming Game (SSNG), which applies the generative and Bayesian
approach based on VI to develop internal representations and emergent language,
while utilizing the discriminative process of SimSiam to facilitate mutual
understanding between agents. In experiments with established models, despite
the dynamic alternation of agent roles during interactions, SSNG demonstrates
comparable performance to the referential game and slightly outperforms the
Metropolis-Hastings naming game.",2024-10-29,"Nguyen Le Hoang, Tadahiro Taniguchi, Fang Tianwei, Akira Taniguchi",http://arxiv.org/pdf/2410.21803v1,cs.CL
Enhancing Adversarial Attacks through Chain of Thought,"Large language models (LLMs) have demonstrated impressive performance across
various domains but remain susceptible to safety concerns. Prior research
indicates that gradient-based adversarial attacks are particularly effective
against aligned LLMs and the chain of thought (CoT) prompting can elicit
desired answers through step-by-step reasoning. This paper proposes enhancing
the robustness of adversarial attacks on aligned LLMs by integrating CoT
prompts with the greedy coordinate gradient (GCG) technique. Using CoT triggers
instead of affirmative targets stimulates the reasoning abilities of backend
LLMs, thereby improving the transferability and universality of adversarial
attacks. We conducted an ablation study comparing our CoT-GCG approach with
Amazon Web Services auto-cot. Results revealed our approach outperformed both
the baseline GCG attack and CoT prompting. Additionally, we used Llama Guard to
evaluate potentially harmful interactions, providing a more objective risk
assessment of entire conversations compared to matching outputs to rejection
phrases. The code of this paper is available at
https://github.com/sujingbo0217/CS222W24-LLM-Attack.",2024-10-29,Jingbo Su,http://arxiv.org/pdf/2410.21791v1,cs.CL
MARCO: Multi-Agent Real-time Chat Orchestration,"Large language model advancements have enabled the development of multi-agent
frameworks to tackle complex, real-world problems such as to automate tasks
that require interactions with diverse tools, reasoning, and human
collaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration
framework for automating tasks using LLMs. MARCO addresses key challenges in
utilizing LLMs for complex, multi-step task execution. It incorporates robust
guardrails to steer LLM behavior, validate outputs, and recover from errors
that stem from inconsistent output formatting, function and parameter
hallucination, and lack of domain knowledge. Through extensive experiments we
demonstrate MARCO's superior performance with 94.48% and 92.74% accuracy on
task execution for Digital Restaurant Service Platform conversations and Retail
conversations datasets respectively along with 44.91% improved latency and
33.71% cost reduction. We also report effects of guardrails in performance gain
along with comparisons of various LLM models, both open-source and proprietary.
The modular and generic design of MARCO allows it to be adapted for automating
tasks across domains and to execute complex usecases through multi-turn
interactions.",2024-10-29,"Anubhav Shrimal, Stanley Kanagaraj, Kriti Biswas, Swarnalatha Raghuraman, Anish Nediyanchath, Yi Zhang, Promod Yenigalla",http://arxiv.org/pdf/2410.21784v1,cs.CL
Leveraging LLMs for Hypothetical Deduction in Logical Inference: A Neuro-Symbolic Approach,"Large Language Models (LLMs) have exhibited remarkable potential across a
wide array of reasoning tasks, including logical reasoning. Although massive
efforts have been made to empower the logical reasoning ability of LLMs via
external logical symbolic solvers, crucial challenges of the poor
generalization ability to questions with different features and inevitable
question information loss of symbolic solver-driven approaches remain
unresolved. To mitigate these issues, we introduce LINA, a LLM-driven
neuro-symbolic approach for faithful logical reasoning. By enabling an LLM to
autonomously perform the transition from propositional logic extraction to
sophisticated logical reasoning, LINA not only bolsters the resilience of the
reasoning process but also eliminates the dependency on external solvers.
Additionally, through its adoption of a hypothetical-deductive reasoning
paradigm, LINA effectively circumvents the expansive search space challenge
that plagues traditional forward reasoning methods. Empirical evaluations
demonstrate that LINA substantially outperforms both established propositional
logic frameworks and conventional prompting techniques across a spectrum of
five logical reasoning tasks. Specifically, LINA achieves an improvement of
24.34% over LINC on the FOLIO dataset, while also surpassing prompting
strategies like CoT and CoT-SC by up to 24.02%. Our code is available at
https://github.com/wufeiwuwoshihua/nshy.",2024-10-29,"Qingchuan Li, Jiatong Li, Tongxuan Liu, Yuting Zeng, Mingyue Cheng, Weizhe Huang, Qi Liu",http://arxiv.org/pdf/2410.21779v1,cs.CL
RELATE: A Modern Processing Platform for Romanian Language,"This paper presents the design and evolution of the RELATE platform. It
provides a high-performance environment for natural language processing
activities, specially constructed for Romanian language. Initially developed
for text processing, it has been recently updated to integrate audio processing
tools. Technical details are provided with regard to core components. We
further present different usage scenarios, derived from actual use in national
and international research projects, thus demonstrating that RELATE is a
mature, modern, state-of-the-art platform for processing Romanian language
corpora. Finally, we present very recent developments including bimodal (text
and audio) features available within the platform.",2024-10-29,"Vasile Păiş, Radu Ion, Andrei-Marius Avram, Maria Mitrofan, Dan Tufiş",http://arxiv.org/pdf/2410.21778v1,cs.CL
Rethinking Code Refinement: Learning to Judge Code Efficiency,"Large Language Models (LLMs) have demonstrated impressive capabilities in
understanding and generating codes. Due to these capabilities, many recent
methods are proposed to automatically refine the codes with LLMs. However, we
should rethink that the refined codes (from LLMs and even humans) are not
always more efficient than their original versions. On the other hand, running
two different versions of codes and comparing them every time is not ideal and
time-consuming. Therefore, in this work, we propose a novel method based on the
code language model that is trained to judge the efficiency between two
different codes (generated across humans and machines) by either classifying
the superior one or predicting the relative improvement. We validate our method
on multiple programming languages with multiple refinement steps, demonstrating
that the proposed method can effectively distinguish between more and less
efficient versions of code.",2024-10-29,"Minju Seo, Jinheon Baek, Sung Ju Hwang",http://arxiv.org/pdf/2410.22375v1,cs.CL
Learning and Unlearning of Fabricated Knowledge in Language Models,"What happens when a new piece of knowledge is introduced into the training
data and how long does it last while a large language model (LM) continues to
train? We investigate this question by injecting facts into LMs from a new
probing dataset, ""Outlandish"", which is designed to permit the testing of a
spectrum of different fact types. When studying how robust these memories are,
there appears to be a sweet spot in the spectrum of fact novelty between
consistency with world knowledge and total randomness, where the injected
memory is the most enduring. Specifically we show that facts that conflict with
common knowledge are remembered for tens of thousands of training steps, while
prompts not conflicting with common knowledge (mundane), as well as scrambled
prompts (randomly jumbled) are both forgotten much more rapidly. Further,
knowledge-conflicting facts can ""prime'' how the language model hallucinates on
logically unrelated prompts, showing their propensity for non-target
generalization, while both mundane and randomly jumbled facts prime
significantly less. Finally, we show that impacts of knowledge-conflicting
facts in LMs, though they can be long lasting, can be largely erased by novel
application of multi-step sparse updates, even while the training ability of
the model is preserved. As such, this very simple procedure has direct
implications for mitigating the effects of data poisoning in training.",2024-10-29,"Chen Sun, Nolan Andrew Miller, Andrey Zhmoginov, Max Vladymyrov, Mark Sandler",http://arxiv.org/pdf/2410.21750v1,cs.CL
Enhancing Financial Question Answering with a Multi-Agent Reflection Framework,"While Large Language Models (LLMs) have shown impressive capabilities in
numerous Natural Language Processing (NLP) tasks, they still struggle with
financial question answering (QA), particularly when numerical reasoning is
required. Recently, LLM-based multi-agent frameworks have demonstrated
remarkable effectiveness in multi-step reasoning, which is crucial for
financial QA tasks as it involves extracting relevant information from tables
and text and then performing numerical reasoning on the extracted data to infer
answers. In this study, we propose a multi-agent framework incorporating a
critic agent that reflects on the reasoning steps and final answers for each
question. Additionally, we enhance our system by adding multiple critic agents,
each focusing on a specific aspect of the answer. Our results indicate that
this framework significantly improves performance compared to single-agent
reasoning, with an average performance increase of 15% for the LLaMA3-8B model
and 5% for the LLaMA3-70B model. Furthermore, our framework performs on par
with, and in some cases surpasses, larger single-agent LLMs such as
LLaMA3.1-405B and GPT-4o-mini, though it falls slightly short compared to
Claude-3.5 Sonnet. Overall, our framework presents an effective solution to
enhance open-source LLMs for financial QA tasks, offering a cost-effective
alternative to larger models like Claude-3.5 Sonnet.",2024-10-29,"Sorouralsadat Fatemi, Yuheng Hu",http://arxiv.org/pdf/2410.21741v1,cs.CL
Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models,"While Chain of Thought (CoT) prompting approaches have significantly
consolidated the reasoning capabilities of large language models (LLMs), they
still face limitations that require extensive human effort or have performance
needs to be improved. Existing endeavors have focused on bridging these gaps;
however, these approaches either hinge on external data and cannot completely
eliminate manual effort, or they fall short in effectively directing LLMs to
generate high-quality exemplary prompts. To address the said pitfalls, we
propose a novel prompt approach for automatic reasoning named \textbf{LBS3},
inspired by curriculum learning which better reflects human learning habits.
Specifically, LBS3 initially steers LLMs to recall easy-to-hard proxy queries
that are pertinent to the target query. Following this, it invokes a
progressive strategy that utilizes exemplary prompts stemmed from easy-proxy
queries to direct LLMs in solving hard-proxy queries, enabling the high-quality
of the proxy solutions. Finally, our extensive experiments in various
reasoning-intensive tasks with varying open- and closed-source LLMs show that
LBS3 achieves strongly competitive performance compared to the SOTA baselines.",2024-10-29,"Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, Di Yin, Jinlong Shu",http://arxiv.org/pdf/2410.21728v3,cs.CL
A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution,"Authorship attribution aims to identify the origin or author of a document.
Traditional approaches have heavily relied on manual features and fail to
capture long-range correlations, limiting their effectiveness. Recent
advancements leverage text embeddings from pre-trained language models, which
require significant fine-tuning on labeled data, posing challenges in data
dependency and limited interpretability. Large Language Models (LLMs), with
their deep reasoning capabilities and ability to maintain long-range textual
associations, offer a promising alternative. This study explores the potential
of pre-trained LLMs in one-shot authorship attribution, specifically utilizing
Bayesian approaches and probability outputs of LLMs. Our methodology calculates
the probability that a text entails previous writings of an author, reflecting
a more nuanced understanding of authorship. By utilizing only pre-trained
models such as Llama-3-70B, our results on the IMDb and blog datasets show an
impressive 85\% accuracy in one-shot authorship classification across ten
authors. Our findings set new baselines for one-shot authorship analysis using
LLMs and expand the application scope of these models in forensic linguistics.
This work also includes extensive ablation studies to validate our approach.",2024-10-29,"Zhengmian Hu, Tong Zheng, Heng Huang",http://arxiv.org/pdf/2410.21716v1,cs.CL
Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN,"The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.",2024-10-29,"Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li",http://arxiv.org/pdf/2411.00028v2,cs.CL
Personalization of Large Language Models: A Survey,"Personalization of Large Language Models (LLMs) has recently become
increasingly important with a wide range of applications. Despite the
importance and recent progress, most existing works on personalized LLMs have
focused either entirely on (a) personalized text generation or (b) leveraging
LLMs for personalization-related downstream applications, such as
recommendation systems. In this work, we bridge the gap between these two
separate main directions for the first time by introducing a taxonomy for
personalized LLM usage and summarizing the key differences and challenges. We
provide a formalization of the foundations of personalized LLMs that
consolidates and expands notions of personalization of LLMs, defining and
discussing novel facets of personalization, usage, and desiderata of
personalized LLMs. We then unify the literature across these diverse fields and
usage scenarios by proposing systematic taxonomies for the granularity of
personalization, personalization techniques, datasets, evaluation methods, and
applications of personalized LLMs. Finally, we highlight challenges and
important open problems that remain to be addressed. By unifying and surveying
recent research using the proposed taxonomies, we aim to provide a clear guide
to the existing literature and different facets of personalization in LLMs,
empowering both researchers and practitioners.",2024-10-29,"Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang",http://arxiv.org/pdf/2411.00027v2,cs.CL
CFSafety: Comprehensive Fine-grained Safety Assessment for LLMs,"As large language models (LLMs) rapidly evolve, they bring significant
conveniences to our work and daily lives, but also introduce considerable
safety risks. These models can generate texts with social biases or unethical
content, and under specific adversarial instructions, may even incite illegal
activities. Therefore, rigorous safety assessments of LLMs are crucial. In this
work, we introduce a safety assessment benchmark, CFSafety, which integrates 5
classic safety scenarios and 5 types of instruction attacks, totaling 10
categories of safety questions, to form a test set with 25k prompts. This test
set was used to evaluate the natural language generation (NLG) capabilities of
LLMs, employing a combination of simple moral judgment and a 1-5 safety rating
scale for scoring. Using this benchmark, we tested eight popular LLMs,
including the GPT series. The results indicate that while GPT-4 demonstrated
superior safety performance, the safety effectiveness of LLMs, including this
model, still requires improvement. The data and code associated with this study
are available on GitHub.",2024-10-29,"Zhihao Liu, Chenhui Hu",http://arxiv.org/pdf/2410.21695v1,cs.CL
Sequential choice in ordered bundles,"Experience goods such as sporting and artistic events, songs, videos, news
stories, podcasts, and television series, are often packaged and consumed in
bundles. Many such bundles are ordered in the sense that the individual items
are consumed sequentially, one at a time. We examine if an individual's
decision to consume the next item in an ordered bundle can be predicted based
on his/her consumption pattern for the preceding items. We evaluate several
predictive models, including two custom Transformers using decoder-only and
encoder-decoder architectures, fine-tuned GPT-3, a custom LSTM model, a
reinforcement learning model, two Markov models, and a zero-order model. Using
data from Spotify, we find that the custom Transformer with a decoder-only
architecture provides the most accurate predictions, both for individual
choices and aggregate demand. This model captures a general form of state
dependence. Analysis of Transformer attention weights suggests that the
consumption of the next item in a bundle is based on approximately equal
weighting of all preceding choices. Our results indicate that the Transformer
can assist in queuing the next item that an individual is likely to consume
from an ordered bundle, predicting the demand for individual items, and
personalizing promotions to increase demand.",2024-10-29,"Rajeev Kohli, Kriste Krstovski, Hengyu Kuang, Hengxu Lin",http://arxiv.org/pdf/2410.21670v1,cs.CL
$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization,"Preference optimization has made significant progress recently, with numerous
methods developed to align language models with human preferences. This paper
introduces $f$-divergence Preference Optimization ($f$-PO), a novel framework
that generalizes and extends existing approaches. $f$-PO minimizes
$f$-divergences between the optimized policy and the optimal policy,
encompassing a broad family of alignment methods using various divergences. Our
approach unifies previous algorithms like DPO and EXO, while offering new
variants through different choices of $f$-divergences. We provide theoretical
analysis of $f$-PO's properties and conduct extensive experiments on
state-of-the-art language models using benchmark datasets. Results demonstrate
$f$-PO's effectiveness across various tasks, achieving superior performance
compared to existing methods on popular benchmarks such as AlpacaEval 2,
Arena-Hard, MT-Bench, and Open LLM Leaderboard v2. Additionally, we present
ablation studies exploring the impact of different $f$-divergences, offering
insights into the trade-offs between regularization and performance in offline
preference optimization. Our work contributes both practical algorithms and
theoretical understanding to the field of language model alignment. Code is
available at https://github.com/MinkaiXu/fPO.",2024-10-29,"Jiaqi Han, Mingjian Jiang, Yuxuan Song, Stefano Ermon, Minkai Xu",http://arxiv.org/pdf/2410.21662v2,cs.CL
Mobility-LLM: Learning Visiting Intentions and Travel Preferences from Human Mobility Data with Large Language Models,"Location-based services (LBS) have accumulated extensive human mobility data
on diverse behaviors through check-in sequences. These sequences offer valuable
insights into users' intentions and preferences. Yet, existing models analyzing
check-in sequences fail to consider the semantics contained in these sequences,
which closely reflect human visiting intentions and travel preferences, leading
to an incomplete comprehension. Drawing inspiration from the exceptional
semantic understanding and contextual information processing capabilities of
large language models (LLMs) across various domains, we present Mobility-LLM, a
novel framework that leverages LLMs to analyze check-in sequences for multiple
tasks. Since LLMs cannot directly interpret check-ins, we reprogram these
sequences to help LLMs comprehensively understand the semantics of human
visiting intentions and travel preferences. Specifically, we introduce a
visiting intention memory network (VIMN) to capture the visiting intentions at
each record, along with a shared pool of human travel preference prompts (HTPP)
to guide the LLM in understanding users' travel preferences. These components
enhance the model's ability to extract and leverage semantic information from
human mobility data effectively. Extensive experiments on four benchmark
datasets and three downstream tasks demonstrate that our approach significantly
outperforms existing models, underscoring the effectiveness of Mobility-LLM in
advancing our understanding of human mobility data within LBS contexts.",2024-10-29,"Letian Gong, Yan Lin, Xinyue Zhang, Yiwen Lu, Xuedi Han, Yichen Liu, Shengnan Guo, Youfang Lin, Huaiyu Wan",http://arxiv.org/pdf/2411.00823v1,cs.CL
Can Language Models Replace Programmers? REPOCOD Says 'Not Yet',"Large language models (LLMs) have achieved high accuracy, i.e., more than 90%
pass@1, in solving Python coding problems in HumanEval and MBPP. Thus, a
natural question is, whether LLMs achieve comparable code completion
performance compared to human developers? Unfortunately, one cannot answer this
question using existing manual crafted or simple (e.g., single-line) code
generation benchmarks, since such tasks fail to represent real-world software
development tasks. In addition, existing benchmarks often use poor code
correctness metrics, providing misleading conclusions.
  To address these challenges, we create REPOCOD, a code generation benchmark
with 980 problems collected from 11 popular real-world projects, with more than
58% of them requiring file-level or repository-level context information. In
addition, REPOCOD has the longest average canonical solution length (331.6
tokens) and the highest average cyclomatic complexity (9.00) compared to
existing benchmarks. Each task in REPOCOD includes 313.5 developer-written test
cases on average for better correctness evaluation. In our evaluations of ten
LLMs, none of the models achieve more than 30% pass@1 on REPOCOD, indicating
the necessity of building stronger LLMs that can help developers in real-world
software development. REPOCOD is available at
https://github.com/lt-asset/REPOCOD",2024-10-29,"Shanchao Liang, Yiran Hu, Nan Jiang, Lin Tan",http://arxiv.org/pdf/2410.21647v3,cs.CL
Efficient Machine Translation with a BiLSTM-Attention Approach,"With the rapid development of Natural Language Processing (NLP) technology,
the accuracy and efficiency of machine translation have become hot topics of
research. This paper proposes a novel Seq2Seq model aimed at improving
translation quality while reducing the storage space required by the model. The
model employs a Bidirectional Long Short-Term Memory network (Bi-LSTM) as the
encoder to capture the context information of the input sequence; the decoder
incorporates an attention mechanism, enhancing the model's ability to focus on
key information during the translation process. Compared to the current
mainstream Transformer model, our model achieves superior performance on the
WMT14 machine translation dataset while maintaining a smaller size.
  The study first introduces the design principles and innovative points of the
model architecture, followed by a series of experiments to verify the
effectiveness of the model. The experimental includes an assessment of the
model's performance on different language pairs, as well as comparative
analysis with traditional Seq2Seq models. The results show that while
maintaining translation accuracy, our model significantly reduces the storage
requirements, which is of great significance for translation applications in
resource-constrained scenarios. our code are available at
https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/miniformer.
Thanks for the support provided by MindSpore Community.",2024-10-29,"Yuxu Wu, Yiren Xing",http://arxiv.org/pdf/2410.22335v2,cs.CL
Mitigating Paraphrase Attacks on Machine-Text Detectors via Paraphrase Inversion,"High-quality paraphrases are easy to produce using instruction-tuned language
models or specialized paraphrasing models. Although this capability has a
variety of benign applications, paraphrasing
attacks$\unicode{x2013}$paraphrases applied to machine-generated
texts$\unicode{x2013}$are known to significantly degrade the performance of
machine-text detectors. This motivates us to consider the novel problem of
paraphrase inversion, where, given paraphrased text, the objective is to
recover an approximation of the original text. The closer the approximation is
to the original text, the better machine-text detectors will perform. We
propose an approach which frames the problem as translation from paraphrased
text back to the original text, which requires examples of texts and
corresponding paraphrases to train the inversion model. Fortunately, such
training data can easily be generated, given a corpus of original texts and one
or more paraphrasing models. We find that language models such as GPT-4 and
Llama-3 exhibit biases when paraphrasing which an inversion model can learn
with a modest amount of data. Perhaps surprisingly, we also find that such
models generalize well, including to paraphrase models unseen at training time.
Finally, we show that when combined with a paraphrased-text detector, our
inversion models provide an effective defense against paraphrasing attacks, and
overall our approach yields an average improvement of +22% AUROC across seven
machine-text detectors and three different domains.",2024-10-29,"Rafael Rivera Soto, Barry Chen, Nicholas Andrews",http://arxiv.org/pdf/2410.21637v3,cs.CL
MCPDial: A Minecraft Persona-driven Dialogue Dataset,"We propose a novel approach that uses large language models (LLMs) to
generate persona-driven conversations between Players and Non-Player Characters
(NPC) in games. Showcasing the application of our methodology, we introduce the
Minecraft Persona-driven Dialogue dataset (MCPDial). Starting with a small seed
of expert-written conversations, we employ our method to generate hundreds of
additional conversations. Each conversation in the dataset includes rich
character descriptions of the player and NPC. The conversations are long,
allowing for in-depth and extensive interactions between the player and NPC.
MCPDial extends beyond basic conversations by incorporating canonical function
calls (e.g. ""Call find a resource on iron ore"") between the utterances.
Finally, we conduct a qualitative analysis of the dataset to assess its quality
and characteristics.",2024-10-29,"Seyed Hossein Alavi, Sudha Rao, Ashutosh Adhikari, Gabriel A DesGarennes, Akanksha Malhotra, Chris Brockett, Mahmoud Adada, Raymond T. Ng, Vered Shwartz, Bill Dolan",http://arxiv.org/pdf/2410.21627v1,cs.CL
Survey of User Interface Design and Interaction Techniques in Generative AI Applications,"The applications of generative AI have become extremely impressive, and the
interplay between users and AI is even more so. Current human-AI interaction
literature has taken a broad look at how humans interact with generative AI,
but it lacks specificity regarding the user interface designs and patterns used
to create these applications. Therefore, we present a survey that
comprehensively presents taxonomies of how a human interacts with AI and the
user interaction patterns designed to meet the needs of a variety of relevant
use cases. We focus primarily on user-guided interactions, surveying
interactions that are initiated by the user and do not include any implicit
signals given by the user. With this survey, we aim to create a compendium of
different user-interaction patterns that can be used as a reference for
designers and developers alike. In doing so, we also strive to lower the entry
barrier for those attempting to learn more about the design of generative AI
applications.",2024-10-28,"Reuben Luera, Ryan A. Rossi, Alexa Siu, Franck Dernoncourt, Tong Yu, Sungchul Kim, Ruiyi Zhang, Xiang Chen, Hanieh Salehy, Jian Zhao, Samyadeep Basu, Puneet Mathur, Nedim Lipka",http://arxiv.org/pdf/2410.22370v1,cs.CL
Reducing the Scope of Language Models,"We now deploy language models in a wide variety of user-facing applications.
Typically, these deployments have some specific purpose, like answering
questions about documentation or acting as coding assistants, but they require
general language understanding. Under these circumstances these models should
not be able to answer irrelevant requests such as, poetry generation or
questions about physics, etc. Instead we would like language models to only
answer to queries corresponding to desired behavior and refuse all other
requests, which we refer to as scoping. We conduct a comprehensive empirical
evaluation of potential methods from prompting to fine-tuning to preference
learning to a recently proposed method for general alignment called Circuit
Breakers (CB). Across three families of language models and a broad variety of
tasks, we show that it is possible to scope language models. We examine scoping
for multiple topics, and fine-grained topics. We ablate diversity of irrelevant
queries, layer different techniques, conduct adversarial evaluations and more.
Among other results, we find that, when diverse examples of irrelevant queries
are available, simple supervised fine-tuning produces the best results, but
when such diversity is low, Circuit Breakers perform quite well. One can often
get the benefits of both methods by layering them in succession. We intend our
study to serve as a practitioner's guide to scoping language models.",2024-10-28,"David Yunis, Siyu Huo, Chulaka Gunasekara, Danish Contractor",http://arxiv.org/pdf/2410.21597v2,cs.CL
Can Large Language Models Replace Data Scientists in Biomedical Research?,"Data science plays a critical role in biomedical research, but it requires
professionals with expertise in coding and medical data analysis. Large
language models (LLMs) have shown great potential in supporting medical tasks
and performing well in general coding tests. However, existing evaluations fail
to assess their capability in biomedical data science, particularly in handling
diverse data types such as genomics and clinical datasets. To address this gap,
we developed a benchmark of data science coding tasks derived from the analyses
of 39 published studies. This benchmark comprises 293 coding tasks (128 in
Python and 165 in R) performed on real-world TCGA-type genomics and clinical
data. Our findings reveal that the vanilla prompting of LLMs yields suboptimal
performances due to drawbacks in following input instructions, understanding
target data, and adhering to standard analysis practices. Next, we benchmarked
six cutting-edge LLMs and advanced adaptation methods, finding two methods to
be particularly effective: chain-of-thought prompting, which provides a
step-by-step plan for data analysis, which led to a 21% code accuracy
improvement (56.6% versus 35.3%); and self-reflection, enabling LLMs to refine
the buggy code iteratively, yielding an 11% code accuracy improvement (45.5%
versus 34.3%). Building on these insights, we developed a platform that
integrates LLMs into the data science workflow for medical professionals. In a
user study with five medical professionals, we found that while LLMs cannot
fully automate programming tasks, they significantly streamline the programming
process. We found that 80% of their submitted code solutions were incorporated
from LLM-generated code, with up to 96% reuse in some cases. Our analysis
highlights the potential of LLMs to enhance data science efficiency in
biomedical research when integrated into expert workflows.",2024-10-28,"Zifeng Wang, Benjamin Danek, Ziwei Yang, Zheng Chen, Jimeng Sun",http://arxiv.org/pdf/2410.21591v2,cs.CL
A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges,"The integration of Large Language Models (LLMs) into medical applications has
sparked widespread interest across the healthcare industry, from drug discovery
and development to clinical decision support, assisting telemedicine, medical
devices, and healthcare insurance applications. This perspective paper aims to
discuss the inner workings of building LLM-powered medical AI applications and
introduces a comprehensive framework for their development. We review existing
literature and outline the unique challenges of applying LLMs in specialized
medical contexts. Additionally, we introduce a three-step framework to organize
medical LLM research activities: 1) Modeling: breaking down complex medical
workflows into manageable steps for developing medical-specific models; 2)
Optimization: optimizing the model performance with crafted prompts and
integrating external knowledge and tools, and 3) System engineering:
decomposing complex tasks into subtasks and leveraging human expertise for
building medical AI applications. Furthermore, we offer a detailed use case
playbook that describes various LLM-powered medical AI applications, such as
optimizing clinical trial design, enhancing clinical decision support, and
advancing medical imaging analysis. Finally, we discuss various challenges and
considerations for building medical AI applications with LLMs, such as handling
hallucination issues, data ownership and compliance, privacy, intellectual
property considerations, compute cost, sustainability issues, and responsible
AI requirements.",2024-10-28,"Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajuan Wang, Pranav Rajpurkar, Jimeng Sun",http://arxiv.org/pdf/2411.00024v3,cs.CL
"Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense","Multilingual large language models (LLMs) have gained prominence, but
concerns arise regarding their reliability beyond English. This study addresses
the gap in cross-lingual semantic evaluation by introducing a novel benchmark
for cross-lingual sense disambiguation, StingrayBench. In this paper, we
demonstrate using false friends -- words that are orthographically similar but
have completely different meanings in two languages -- as a possible approach
to pinpoint the limitation of cross-lingual sense disambiguation in LLMs. We
collect false friends in four language pairs, namely Indonesian-Malay,
Indonesian-Tagalog, Chinese-Japanese, and English-German; and challenge LLMs to
distinguish the use of them in context. In our analysis of various models, we
observe they tend to be biased toward higher-resource languages. We also
propose new metrics for quantifying the cross-lingual sense bias and
comprehension based on our benchmark. Our work contributes to developing more
diverse and inclusive language modeling, promoting fairer access for the wider
multilingual community.",2024-10-28,"Samuel Cahyawijaya, Ruochen Zhang, Holy Lovenia, Jan Christian Blaise Cruz, Elisa Gilbert, Hiroki Nomoto, Alham Fikri Aji",http://arxiv.org/pdf/2410.21573v2,cs.CL
Semantic Search Evaluation,"We propose a novel method for evaluating the performance of a content search
system that measures the semantic match between a query and the results
returned by the search system. We introduce a metric called ""on-topic rate"" to
measure the percentage of results that are relevant to the query. To achieve
this, we design a pipeline that defines a golden query set, retrieves the top K
results for each query, and sends calls to GPT 3.5 with formulated prompts. Our
semantic evaluation pipeline helps identify common failure patterns and goals
against the metric for relevance improvements.",2024-10-28,"Chujie Zheng, Jeffrey Wang, Shuqian Albee Zhang, Anand Kishore, Siddharth Singh",http://arxiv.org/pdf/2410.21549v1,cs.CL
MultiTok: Variable-Length Tokenization for Efficient LLMs Adapted from LZW Compression,"Large language models have drastically changed the prospects of AI by
introducing technologies for more complex natural language processing. However,
current methodologies to train such LLMs require extensive resources including
but not limited to large amounts of data, expensive machinery, and lengthy
training. To solve this problem, this paper proposes a new tokenization method
inspired by universal Lempel-Ziv-Welch data compression that compresses
repetitive phrases into multi-word tokens. With MultiTok as a new tokenizing
tool, we show that language models are able to be trained notably more
efficiently while offering a similar accuracy on more succinct and compressed
training data. In fact, our results demonstrate that MultiTok achieves a
comparable performance to the BERT and GPT-2 standards as both a stand-alone
tokenizer and an add-on to existing tokenizers while also providing close to
2.5x faster training with more than 30% less training data.",2024-10-28,"Noel Elias, Homa Esfahanizadeh, Kaan Kale, Sriram Vishwanath, Muriel Medard",http://arxiv.org/pdf/2410.21548v2,cs.CL
CARMO: Dynamic Criteria Generation for Context-Aware Reward Modelling,"Reward modeling in large language models is susceptible to reward hacking,
causing models to latch onto superficial features such as the tendency to
generate lists or unnecessarily long responses. In reinforcement learning from
human feedback (RLHF) and more generally during post-training flawed reward
signals often lead to outputs that optimize for these spurious correlates
instead of genuine quality or correctness. We propose Context-Aware Reward
Modeling (CARMO), a novel approach that first generates dynamic,
context-relevant criteria to ground the reward model before producing reward
scores. Unlike prior methods that rely on static rubrics, CARMO leverages large
language models (LLMs) to adaptively create evaluation criteria such as logical
consistency, clarity, and depth tailored to the user query. Our theoretical
analysis shows that such criteria generation can mitigate reward hacking. We
further demonstrate that CARMO can be distilled into smaller models, reducing
the computational cost of alignment. We establish a new state-of-the-art
performance in zero-shot settings for generative models, achieving a 2.1\%
improvement on Reward Bench. Furthermore, alignment performed on the
CARMO-curated preference dataset achieves 22.5\% and 21.1\% LC-WR and WR,
respectively, on Mistral-Base (7B).",2024-10-28,"Taneesh Gupta, Shivam Shandilya, Xuchao Zhang, Rahul Madhavan, Supriyo Ghosh, Chetan Bansal, Huaxiu Yao, Saravan Rajmohan",http://arxiv.org/pdf/2410.21545v2,cs.CL
L3Ms -- Lagrange Large Language Models,"Supervised fine-tuning (SFT) and alignment of large language models (LLMs)
are key steps in providing a good user experience. However, the concept of an
appropriate alignment is inherently application-dependent, and current methods
often rely on heuristic choices to drive optimization. In this work, we
formulate SFT and alignment as a constrained optimization problem: the LLM is
fine-tuned on a task while being required to meet application-specific
requirements, without resorting to heuristics. To solve this, we propose
Lagrange Large Language Models (L3Ms), which employ logarithmic barriers to
enforce the constraints. This approach allows for the customization of L3Ms
across diverse applications while avoiding heuristic-driven processes. We
experimentally demonstrate the versatility and efficacy of L3Ms in achieving
tailored alignments for various applications.",2024-10-28,"Guneet S. Dhillon, Xingjian Shi, Yee Whye Teh, Alex Smola",http://arxiv.org/pdf/2410.21533v3,cs.CL
Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification,"Synthetic data augmentation via large language models (LLMs) allows
researchers to leverage additional training data, thus enhancing the
performance of downstream tasks, especially when real-world data is scarce.
However, the generated data can deviate from the real-world data, and this
misalignment can bring deficient outcomes while applying the trained model to
applications. Therefore, we proposed efficient weighted-loss approaches to
align synthetic data with real-world distribution by emphasizing high-quality
and diversified data generated by LLMs with using merely a little real-world
data. We empirically assessed the effectiveness of our method on multiple text
classification tasks, and the results showed leveraging our approaches on a
BERT-level model robustly outperformed standard cross-entropy and other data
weighting approaches, providing potential solutions to effectively leveraging
synthetic data from any suitable data generator for model training.",2024-10-28,"Hsun-Yu Kuo, Yin-Hsiang Liao, Yu-Chieh Chao, Wei-Yun Ma, Pu-Jen Cheng",http://arxiv.org/pdf/2410.21526v2,cs.CL
LLM-Forest: Ensemble Learning of LLMs with Graph-Augmented Prompts for Data Imputation,"Missing data imputation is a critical challenge in various domains, such as
healthcare and finance, where data completeness is vital for accurate analysis.
Large language models (LLMs), trained on vast corpora, have shown strong
potential in data generation, making them a promising tool for data imputation.
However, challenges persist in designing effective prompts for a
finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a ""forest"" of few-shot learning LLM ""trees"" with confidence-based
weighted voting, inspired by ensemble learning (Random Forest). This framework
is established on a new concept of bipartite information graphs to identify
high-quality relevant neighboring entries with both feature and value
granularity. Extensive experiments on 9 real-world datasets demonstrate the
effectiveness and efficiency of LLM-Forest.",2024-10-28,"Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He",http://arxiv.org/pdf/2410.21520v3,cs.CL
Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups,"Sparse AutoEnocders (SAEs) have recently been employed as an unsupervised
approach for understanding the inner workings of Large Language Models (LLMs).
They reconstruct the model's activations with a sparse linear combination of
interpretable features. However, training SAEs is computationally intensive,
especially as models grow in size and complexity. To address this challenge, we
propose a novel training strategy that reduces the number of trained SAEs from
one per layer to one for a given group of contiguous layers. Our experimental
results on Pythia 160M highlight a speedup of up to 6x without compromising the
reconstruction quality and performance on downstream tasks. Therefore, layer
clustering presents an efficient approach to train SAEs in modern LLMs.",2024-10-28,"Davide Ghilardi, Federico Belotti, Marco Molinari",http://arxiv.org/pdf/2410.21508v1,cs.CL
SandboxAQ's submission to MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval,"This paper explores the problems of Question Answering (QA) and Named Entity
Recognition (NER) in five diverse languages. We tested five Large Language
Models with various prompting methods, including zero-shot, chain-of-thought
reasoning, and translation techniques. Our results show that while some models
consistently outperform others, their effectiveness varies significantly across
tasks and languages. We saw that advanced prompting techniques generally
improved QA performance but had mixed results for NER; and we observed that
language difficulty patterns differed between tasks. Our findings highlight the
need for task-specific approaches in multilingual NLP and suggest that current
models may develop different linguistic competencies for different tasks.",2024-10-28,"Isidora Chara Tourni, Sayontan Ghosh, Brenda Miao, Constantijn van der Poel",http://arxiv.org/pdf/2410.21501v1,cs.CL
RoBIn: A Transformer-Based Model For Risk Of Bias Inference With Machine Reading Comprehension,"Objective: Scientific publications play a crucial role in uncovering
insights, testing novel drugs, and shaping healthcare policies. Accessing the
quality of publications requires evaluating their Risk of Bias (RoB), a process
typically conducted by human reviewers. In this study, we introduce a new
dataset for machine reading comprehension and RoB assessment and present RoBIn
(Risk of Bias Inference), an innovative model crafted to automate such
evaluation. The model employs a dual-task approach, extracting evidence from a
given context and assessing the RoB based on the gathered evidence. Methods: We
use data from the Cochrane Database of Systematic Reviews (CDSR) as ground
truth to label open-access clinical trial publications from PubMed. This
process enabled us to develop training and test datasets specifically for
machine reading comprehension and RoB inference. Additionally, we created
extractive (RoBInExt) and generative (RoBInGen) Transformer-based approaches to
extract relevant evidence and classify the RoB effectively. Results: RoBIn is
evaluated across various settings and benchmarked against state-of-the-art
methods for RoB inference, including large language models in multiple
scenarios. In most cases, the best-performing RoBIn variant surpasses
traditional machine learning and LLM-based approaches, achieving an ROC AUC of
0.83. Conclusion: Based on the evidence extracted from clinical trial reports,
RoBIn performs a binary classification to decide whether the trial is at a low
RoB or a high/unclear RoB. We found that both RoBInGen and RoBInExt are robust
and have the best results in many settings.",2024-10-28,"Abel Corrêa Dias, Viviane Pereira Moreira, João Luiz Dihl Comba",http://arxiv.org/pdf/2410.21495v1,cs.CL
FATH: Authentication-based Test-time Defense against Indirect Prompt Injection Attacks,"Large language models (LLMs) have been widely deployed as the backbone with
additional tools and text information for real-world applications. However,
integrating external information into LLM-integrated applications raises
significant security concerns. Among these, prompt injection attacks are
particularly threatening, where malicious instructions injected in the external
text information can exploit LLMs to generate answers as the attackers desire.
While both training-time and test-time defense methods have been developed to
mitigate such attacks, the unaffordable training costs associated with
training-time methods and the limited effectiveness of existing test-time
methods make them impractical. This paper introduces a novel test-time defense
strategy, named Formatting AuThentication with Hash-based tags (FATH). Unlike
existing approaches that prevent LLMs from answering additional instructions in
external text, our method implements an authentication system, requiring LLMs
to answer all received instructions with a security policy and selectively
filter out responses to user instructions as the final output. To achieve this,
we utilize hash-based authentication tags to label each response, facilitating
accurate identification of responses according to the user's instructions and
improving the robustness against adaptive attacks. Comprehensive experiments
demonstrate that our defense method can effectively defend against indirect
prompt injection attacks, achieving state-of-the-art performance under Llama3
and GPT3.5 models across various attack methods. Our code is released at:
https://github.com/Jayfeather1024/FATH",2024-10-28,"Jiongxiao Wang, Fangzhou Wu, Wendi Li, Jinsheng Pan, Edward Suh, Z. Morley Mao, Muhao Chen, Chaowei Xiao",http://arxiv.org/pdf/2410.21492v2,cs.CL
Can Large Language Models Act as Symbolic Reasoners?,"The performance of Large language models (LLMs) across a broad range of
domains has been impressive but have been critiqued as not being able to reason
about their process and conclusions derived. This is to explain the conclusions
draw, and also for determining a plan or strategy for their approach. This
paper explores the current research in investigating symbolic reasoning and
LLMs, and whether an LLM can inherently provide some form of reasoning or
whether supporting components are necessary, and, if there is evidence for a
reasoning capability, is this evident in a specific domain or is this a general
capability? In addition, this paper aims to identify the current research gaps
and future trends of LLM explainability, presenting a review of the literature,
identifying current research into this topic and suggests areas for future
work.",2024-10-28,"Rob Sullivan, Nelly Elsayed",http://arxiv.org/pdf/2410.21490v1,cs.CL
SpeechQE: Estimating the Quality of Direct Speech Translation,"Recent advances in automatic quality estimation for machine translation have
exclusively focused on written language, leaving the speech modality
underexplored. In this work, we formulate the task of quality estimation for
speech translation (SpeechQE), construct a benchmark, and evaluate a family of
systems based on cascaded and end-to-end architectures. In this process, we
introduce a novel end-to-end system leveraging pre-trained text LLM. Results
suggest that end-to-end approaches are better suited to estimating the quality
of direct speech translation than using quality estimation systems designed for
text in cascaded systems. More broadly, we argue that quality estimation of
speech translation needs to be studied as a separate problem from that of text,
and release our data and models to guide further research in this space.",2024-10-28,"HyoJung Han, Kevin Duh, Marine Carpuat",http://arxiv.org/pdf/2410.21485v1,cs.CL
Device-Directed Speech Detection for Follow-up Conversations Using Large Language Models,"Follow-up conversations with virtual assistants (VAs) enable a user to
seamlessly interact with a VA without the need to repeatedly invoke it using a
keyword (after the first query). Therefore, accurate Device-directed Speech
Detection (DDSD) from the follow-up queries is critical for enabling
naturalistic user experience. To this end, we explore the notion of Large
Language Models (LLMs) and model the first query when making inference about
the follow-ups (based on the ASR-decoded text), via prompting of a pretrained
LLM, or by adapting a binary classifier on top of the LLM. In doing so, we also
exploit the ASR uncertainty when designing the LLM prompts. We show on the
real-world dataset of follow-up conversations that this approach yields large
gains (20-40% reduction in false alarms at 10% fixed false rejects) due to the
joint modeling of the previous speech context and ASR uncertainty, compared to
when follow-ups are modeled alone.",2024-10-28,"Ognjen, Rudovic, Pranay Dighe, Yi Su, Vineet Garg, Sameer Dharur, Xiaochuan Niu, Ahmed H. Abdelaziz, Saurabh Adya, Ahmed Tewfik",http://arxiv.org/pdf/2411.00023v2,cs.CL
AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification,"Trust and interpretability are crucial for the use of Artificial Intelligence
(AI) in scientific research, but current models often operate as black boxes
offering limited transparency and justifications for their outputs. We
introduce AiSciVision, a framework that specializes Large Multimodal Models
(LMMs) into interactive research partners and classification models for image
classification tasks in niche scientific domains. Our framework uses two key
components: (1) Visual Retrieval-Augmented Generation (VisRAG) and (2)
domain-specific tools utilized in an agentic workflow. To classify a target
image, AiSciVision first retrieves the most similar positive and negative
labeled images as context for the LMM. Then the LMM agent actively selects and
applies tools to manipulate and inspect the target image over multiple rounds,
refining its analysis before making a final prediction. These VisRAG and
tooling components are designed to mirror the processes of domain experts, as
humans often compare new data to similar examples and use specialized tools to
manipulate and inspect images before arriving at a conclusion. Each inference
produces both a prediction and a natural language transcript detailing the
reasoning and tool usage that led to the prediction. We evaluate AiSciVision on
three real-world scientific image classification datasets: detecting the
presence of aquaculture ponds, diseased eelgrass, and solar panels. Across
these datasets, our method outperforms fully supervised models in low and
full-labeled data settings. AiSciVision is actively deployed in real-world use,
specifically for aquaculture research, through a dedicated web application that
displays and allows the expert users to converse with the transcripts. This
work represents a crucial step toward AI systems that are both interpretable
and effective, advancing their use in scientific research and scientific
discovery.",2024-10-28,"Brendan Hogan, Anmol Kabra, Felipe Siqueira Pacheco, Laura Greenstreet, Joshua Fan, Aaron Ferber, Marta Ummus, Alecsander Brito, Olivia Graham, Lillian Aoki, Drew Harvell, Alex Flecker, Carla Gomes",http://arxiv.org/pdf/2410.21480v1,cs.CL
TransformLLM: Adapting Large Language Models via LLM-Transformed Reading Comprehension Text,"Large Language Models (LLMs) have shown promise in highly-specialized
domains, however challenges are still present in aspects of accuracy and costs.
These limitations restrict the usage of existing models in domain-specific
tasks. While fine-tuning pre-trained models have shown promising results, this
process can be computationally expensive and require massive datasets of the
specialized application in hand. In this work, we bridge that gap. We have
developed Phi-2-Legal and Mistral-Legal-7B, which are language models
specifically designed for legal applications. These models are based on Phi-2
and Mistral-7B-v0.1, and have gone through continued pre-training with over 500
million tokens of legal texts. Our innovative approach significantly improves
capabilities in legal tasks by using Large Language Models (LLMs) to convert
raw training data into reading comprehension text. Our legal LLMs have
demonstrated superior performance in legal benchmarks, even outperforming
models trained on much larger datasets with more resources. This work
emphasizes the effectiveness of continued pre-training on domain-specific
texts, while using affordable LLMs for data conversion, which gives these
models domain expertise while retaining general language understanding
capabilities. While this work uses the legal domain as a test case, our method
can be scaled and applied to any pre-training dataset, resulting in significant
improvements across different tasks. These findings underscore the potential of
domain-adaptive pre-training and reading comprehension for the development of
highly effective domain-specific language models.",2024-10-28,"Iftach Arbel, Yehonathan Refael, Ofir Lindenbaum",http://arxiv.org/pdf/2410.21479v1,cs.CL
Estimating Causal Effects of Text Interventions Leveraging LLMs,"Quantifying the effects of textual interventions in social systems, such as
reducing anger in social media posts to see its impact on engagement, is
challenging. Real-world interventions are often infeasible, necessitating
reliance on observational data. Traditional causal inference methods, typically
designed for binary or discrete treatments, are inadequate for handling the
complex, high-dimensional textual data. This paper addresses these challenges
by proposing CausalDANN, a novel approach to estimate causal effects using text
transformations facilitated by large language models (LLMs). Unlike existing
methods, our approach accommodates arbitrary textual interventions and
leverages text-level classifiers with domain adaptation ability to produce
robust effect estimates against domain shifts, even when only the control group
is observed. This flexibility in handling various text interventions is a key
advancement in causal estimation for textual data, offering opportunities to
better understand human behaviors and develop effective interventions within
social systems.",2024-10-28,"Siyi Guo, Myrl G. Marmarelis, Fred Morstatter, Kristina Lerman",http://arxiv.org/pdf/2410.21474v2,cs.CL
ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference,"With the widespread deployment of long-context large language models (LLMs),
there has been a growing demand for efficient support of high-throughput
inference. However, as the key-value (KV) cache expands with the sequence
length, the increasing memory footprint and the need to access it for each
token generation both result in low throughput when serving long-context LLMs.
While various dynamic sparse attention methods have been proposed to speed up
inference while maintaining generation quality, they either fail to
sufficiently reduce GPU memory consumption or introduce significant decoding
latency by offloading the KV cache to the CPU. We present ShadowKV, a
high-throughput long-context LLM inference system that stores the low-rank key
cache and offloads the value cache to reduce the memory footprint for larger
batch sizes and longer sequences. To minimize decoding latency, ShadowKV
employs an accurate KV selection strategy that reconstructs minimal sparse KV
pairs on-the-fly. By evaluating ShadowKV on a broad range of benchmarks,
including RULER, LongBench, and Needle In A Haystack, and models like
Llama-3.1-8B, Llama-3-8B-1M, GLM-4-9B-1M, Yi-9B-200K, Phi-3-Mini-128K, and
Qwen2-7B-128K, we demonstrate that it can support up to 6$\times$ larger batch
sizes and boost throughput by up to 3.04$\times$ on an A100 GPU without
sacrificing accuracy, even surpassing the performance achievable with infinite
batch size under the assumption of infinite GPU memory. The code is available
at https://github.com/bytedance/ShadowKV.",2024-10-28,"Hanshi Sun, Li-Wen Chang, Wenlei Bao, Size Zheng, Ningxin Zheng, Xin Liu, Harry Dong, Yuejie Chi, Beidi Chen",http://arxiv.org/pdf/2410.21465v3,cs.CL
Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures,"This study systematically analyzes the vulnerability of 36 large language
models (LLMs) to various prompt injection attacks, a technique that leverages
carefully crafted prompts to elicit malicious LLM behavior. Across 144 prompt
injection tests, we observed a strong correlation between model parameters and
vulnerability, with statistical analyses, such as logistic regression and
random forest feature analysis, indicating that parameter size and architecture
significantly influence susceptibility. Results revealed that 56 percent of
tests led to successful prompt injections, emphasizing widespread vulnerability
across various parameter sizes, with clustering analysis identifying distinct
vulnerability profiles associated with specific model configurations.
Additionally, our analysis uncovered correlations between certain prompt
injection techniques, suggesting potential overlaps in vulnerabilities. These
findings underscore the urgent need for robust, multi-layered defenses in LLMs
deployed across critical infrastructure and sensitive industries. Successful
prompt injection attacks could result in severe consequences, including data
breaches, unauthorized access, or misinformation. Future research should
explore multilingual and multi-step defenses alongside adaptive mitigation
strategies to strengthen LLM security in diverse, real-world environments.",2024-10-28,"Victoria Benjamin, Emily Braca, Israel Carter, Hafsa Kanchwala, Nava Khojasteh, Charly Landow, Yi Luo, Caroline Ma, Anna Magarelli, Rachel Mirin, Avery Moyer, Kayla Simpson, Amelia Skawinski, Thomas Heverin",http://arxiv.org/pdf/2410.23308v1,cs.CL
UFT: Unifying Fine-Tuning of SFT and RLHF/DPO/UNA through a Generalized Implicit Reward Function,"By pretraining on trillions of tokens, an LLM gains the capability of text
generation. However, to enhance its utility and reduce potential harm, SFT and
alignment are applied sequentially to the pretrained model. Due to the
differing nature and objective functions of SFT and alignment, catastrophic
forgetting has become a significant issue. To address this, we introduce
Unified Fine-Tuning (UFT), which integrates SFT and alignment into a single
training stage using the same objective and loss functions through an implicit
reward function. Our experimental results demonstrate that UFT outperforms SFT
on instruction-tuning data alone. Moreover, when combining instruction-tuning
data with alignment data, UFT effectively prevents catastrophic forgetting
across these two stages and shows a clear advantage over sequentially applying
SFT and alignment. This is evident in the significant improvements observed in
the \textbf{ifeval} task for instruction-following and the \textbf{truthful-qa}
task for factuality. The proposed general fine-tuning framework UFT establishes
an effective and efficient pretraining-UFT paradigm for LLM training.",2024-10-28,"Zhichao Wang, Bin Bi, Zixu Zhu, Xiangbo Mao, Jun Wang, Shiyu Wang",http://arxiv.org/pdf/2410.21438v2,cs.CL
Large Language Models for Manufacturing,"The rapid advances in Large Language Models (LLMs) have the potential to
transform manufacturing industry, offering new opportunities to optimize
processes, improve efficiency, and drive innovation. This paper provides a
comprehensive exploration of the integration of LLMs into the manufacturing
domain, focusing on their potential to automate and enhance various aspects of
manufacturing, from product design and development to quality control, supply
chain optimization, and talent management. Through extensive evaluations across
multiple manufacturing tasks, we demonstrate the remarkable capabilities of
state-of-the-art LLMs, such as GPT-4V, in understanding and executing complex
instructions, extracting valuable insights from vast amounts of data, and
facilitating knowledge sharing. We also delve into the transformative potential
of LLMs in reshaping manufacturing education, automating coding processes,
enhancing robot control systems, and enabling the creation of immersive,
data-rich virtual environments through the industrial metaverse. By
highlighting the practical applications and emerging use cases of LLMs in
manufacturing, this paper aims to provide a valuable resource for
professionals, researchers, and decision-makers seeking to harness the power of
these technologies to address real-world challenges, drive operational
excellence, and unlock sustainable growth in an increasingly competitive
landscape.",2024-10-28,"Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Zhengliang Liu, Zihao Wu, Peng Shu, Jie Tian, Tianze Yang, Shaochen Xu, Yanjun Lyu, Parker Blenk, Jacob Pence, Jason Rupram, Eliza Banu, Ninghao Liu, Linbing Wang, Wenzhan Song, Xiaoming Zhai, Kenan Song, Dajiang Zhu, Beiwen Li, Xianqiao Wang, Tianming Liu",http://arxiv.org/pdf/2410.21418v1,cs.CL
"CT2C-QA: Multimodal Question Answering over Chinese Text, Table and Chart","Multimodal Question Answering (MMQA) is crucial as it enables comprehensive
understanding and accurate responses by integrating insights from diverse data
representations such as tables, charts, and text. Most existing researches in
MMQA only focus on two modalities such as image-text QA, table-text QA and
chart-text QA, and there remains a notable scarcity in studies that investigate
the joint analysis of text, tables, and charts. In this paper, we present
C$\text{T}^2$C-QA, a pioneering Chinese reasoning-based QA dataset that
includes an extensive collection of text, tables, and charts, meticulously
compiled from 200 selectively sourced webpages. Our dataset simulates real
webpages and serves as a great test for the capability of the model to analyze
and reason with multimodal data, because the answer to a question could appear
in various modalities, or even potentially not exist at all. Additionally, we
present AED (\textbf{A}llocating, \textbf{E}xpert and \textbf{D}esicion), a
multi-agent system implemented through collaborative deployment, information
interaction, and collective decision-making among different agents.
Specifically, the Assignment Agent is in charge of selecting and activating
expert agents, including those proficient in text, tables, and charts. The
Decision Agent bears the responsibility of delivering the final verdict,
drawing upon the analytical insights provided by these expert agents. We
execute a comprehensive analysis, comparing AED with various state-of-the-art
models in MMQA, including GPT-4. The experimental outcomes demonstrate that
current methodologies, including GPT-4, are yet to meet the benchmarks set by
our dataset.",2024-10-28,"Bowen Zhao, Tianhao Cheng, Yuejie Zhang, Ying Cheng, Rui Feng, Xiaobo Zhang",http://arxiv.org/pdf/2410.21414v1,cs.CL
Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics,"Do large language models (LLMs) solve reasoning tasks by learning robust
generalizable algorithms, or do they memorize training data? To investigate
this question, we use arithmetic reasoning as a representative task. Using
causal analysis, we identify a subset of the model (a circuit) that explains
most of the model's behavior for basic arithmetic logic and examine its
functionality. By zooming in on the level of individual circuit neurons, we
discover a sparse set of important neurons that implement simple heuristics.
Each heuristic identifies a numerical input pattern and outputs corresponding
answers. We hypothesize that the combination of these heuristic neurons is the
mechanism used to produce correct arithmetic answers. To test this, we
categorize each neuron into several heuristic types-such as neurons that
activate when an operand falls within a certain range-and find that the
unordered combination of these heuristic types is the mechanism that explains
most of the model's accuracy on arithmetic prompts. Finally, we demonstrate
that this mechanism appears as the main source of arithmetic accuracy early in
training. Overall, our experimental results across several LLMs show that LLMs
perform arithmetic using neither robust algorithms nor memorization; rather,
they rely on a ""bag of heuristics"".",2024-10-28,"Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov",http://arxiv.org/pdf/2410.21272v2,cs.CL
EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation,"In this work, we re-formulate the model compression problem into the
customized compensation problem: Given a compressed model, we aim to introduce
residual low-rank paths to compensate for compression errors under customized
requirements from users (e.g., tasks, compression ratios), resulting in greater
flexibility in balancing accuracy and overhead(inference and model size)
without being bound to fixed compression formats. However, naively applying SVD
to derive residual paths causes suboptimal utilization of the low-rank
representation capacity. Instead, we propose Training-free Eigenspace Low-Rank
Approximation (EoRA), a method that directly minimizes compression-induced
errors without requiring gradient-based training, achieving fast optimization
in minutes using a small amount of calibration data. EoRA projects compression
errors into the eigenspace of input activations, leveraging eigenvalues to
effectively prioritize the reconstruction of high-importance error components.
Moreover, EoRA can be seamlessly integrated with fine-tuning and quantization
to further improve effectiveness and efficiency. EoRA consistently outperforms
previous methods in compensating errors for compressed LLaMA2/3 models on
various tasks, such as language generation, commonsense reasoning, and math
reasoning tasks (e.g., 31.31%/12.88% and 9.69% improvements on
ARC-Easy/ARC-Challenge and MathQA when compensating LLaMA3-8B that is quantized
to 4-bit and pruned to 2:4 sparsity). EoRA offers a scalable, training-free
solution to compensate for compression errors, making it a powerful tool to
deploy LLMs more flexibly. Code is available at https://github.com/NVlabs/EoRA.",2024-10-28,"Shih-Yang Liu, Maksim Khadkevich, Nai Chit Fung, Charbel Sakr, Chao-Han Huck Yang, Chien-Yi Wang, Saurav Muralidharan, Hongxu Yin, Kwang-Ting Cheng, Jan Kautz, Yu-Chiang Frank Wang, Pavlo Molchanov, Min-Hung Chen",http://arxiv.org/pdf/2410.21271v3,cs.CL
Are BabyLMs Second Language Learners?,"This paper describes a linguistically-motivated approach to the 2024 edition
of the BabyLM Challenge (Warstadt et al. 2023). Rather than pursuing a first
language learning (L1) paradigm, we approach the challenge from a second
language (L2) learning perspective. In L2 learning, there is a stronger focus
on learning explicit linguistic information, such as grammatical notions,
definitions of words or different ways of expressing a meaning. This makes L2
learning potentially more efficient and concise. We approximate this using data
from Wiktionary, grammar examples either generated by an LLM or sourced from
grammar books, and paraphrase data. We find that explicit information about
word meaning (in our case, Wiktionary) does not boost model performance, while
grammatical information can give a small improvement. The most impactful data
ingredient is sentence paraphrases, with our two best models being trained on
1) a mix of paraphrase data and data from the BabyLM pretraining dataset, and
2) exclusively paraphrase data.",2024-10-28,"Lukas Edman, Lisa Bylinina, Faeze Ghorbanpour, Alexander Fraser",http://arxiv.org/pdf/2410.21254v1,cs.CL
A Survey on Automatic Credibility Assessment of Textual Credibility Signals in the Era of Large Language Models,"In the current era of social media and generative AI, an ability to
automatically assess the credibility of online social media content is of
tremendous importance. Credibility assessment is fundamentally based on
aggregating credibility signals, which refer to small units of information,
such as content factuality, bias, or a presence of persuasion techniques, into
an overall credibility score. Credibility signals provide a more granular, more
easily explainable and widely utilizable information in contrast to currently
predominant fake news detection, which utilizes various (mostly latent)
features. A growing body of research on automatic credibility assessment and
detection of credibility signals can be characterized as highly fragmented and
lacking mutual interconnections. This issue is even more prominent due to a
lack of an up-to-date overview of research works on automatic credibility
assessment. In this survey, we provide such systematic and comprehensive
literature review of 175 research papers while focusing on textual credibility
signals and Natural Language Processing (NLP), which undergoes a significant
advancement due to Large Language Models (LLMs). While positioning the NLP
research into the context of other multidisciplinary research works, we tackle
with approaches for credibility assessment as well as with 9 categories of
credibility signals (we provide a thorough analysis for 3 of them, namely: 1)
factuality, subjectivity and bias, 2) persuasion techniques and logical
fallacies, and 3) claims and veracity). Following the description of the
existing methods, datasets and tools, we identify future challenges and
opportunities, while paying a specific attention to recent rapid development of
generative AI.",2024-10-28,"Ivan Srba, Olesya Razuvayevskaya, João A. Leite, Robert Moro, Ipek Baris Schlicht, Sara Tonelli, Francisco Moreno García, Santiago Barrio Lottmann, Denis Teyssou, Valentin Porcellini, Carolina Scarton, Kalina Bontcheva, Maria Bielikova",http://arxiv.org/pdf/2410.21360v1,cs.CL
LongReward: Improving Long-context Large Language Models with AI Feedback,"Though significant advancements have been achieved in developing long-context
large language models (LLMs), the compromised quality of LLM-synthesized data
for supervised fine-tuning (SFT) often affects the long-context performance of
SFT models and leads to inherent limitations. In principle, reinforcement
learning (RL) with appropriate reward signals can further enhance models'
capacities. However, how to obtain reliable rewards in long-context scenarios
remains unexplored. To this end, we propose LongReward, a novel method that
utilizes an off-the-shelf LLM to provide rewards for long-context model
responses from four human-valued dimensions: helpfulness, logicality,
faithfulness, and completeness, each with a carefully designed assessment
pipeline. By combining LongReward and offline RL algorithm DPO, we are able to
effectively improve long-context SFT models. Our experiments indicate that
LongReward not only significantly improves models' long-context performance but
also enhances their ability to follow short instructions. We also find that
long-context DPO with LongReward and conventional short-context DPO can be used
together without hurting either one's performance.",2024-10-28,"Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li",http://arxiv.org/pdf/2410.21252v1,cs.CL
Can Machines Think Like Humans? A Behavioral Evaluation of LLM-Agents in Dictator Games,"As Large Language Model (LLM)-based agents increasingly undertake real-world
tasks and engage with human society, how well do we understand their behaviors?
We (1) investigate how LLM agents' prosocial behaviors -- a fundamental social
norm -- can be induced by different personas and benchmarked against human
behaviors; and (2) introduce a behavioral and social science approach to
evaluate LLM agents' decision-making. We explored how different personas and
experimental framings affect these AI agents' altruistic behavior in dictator
games and compared their behaviors within the same LLM family, across various
families, and with human behaviors. The findings reveal substantial variations
and inconsistencies among LLMs and notable differences compared to human
behaviors. Merely assigning a human-like identity to LLMs does not produce
human-like behaviors. Despite being trained on extensive human-generated data,
these AI agents are unable to capture the internal processes of human
decision-making. Their alignment with human is highly variable and dependent on
specific model architectures and prompt formulations; even worse, such
dependence does not follow a clear pattern. LLMs can be useful task-specific
tools but are not yet intelligent human-like agents.",2024-10-28,Ji Ma,http://arxiv.org/pdf/2410.21359v2,cs.CL
Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback,"Building effective dense retrieval systems remains difficult when relevance
supervision is not available. Recent work has looked to overcome this challenge
by using a Large Language Model (LLM) to generate hypothetical documents that
can be used to find the closest real document. However, this approach relies
solely on the LLM to have domain-specific knowledge relevant to the query,
which may not be practical. Furthermore, generating hypothetical documents can
be inefficient as it requires the LLM to generate a large number of tokens for
each query. To address these challenges, we introduce Real Document Embeddings
from Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF
proposes to re-frame hypothetical document generation as a relevance estimation
task, using an LLM to select which documents should be used for nearest
neighbor search. Through this re-framing, the LLM no longer needs
domain-specific knowledge but only needs to judge what is relevant.
Additionally, relevance estimation only requires the LLM to output a single
token, thereby improving search latency. Our experiments show that ReDE-RF
consistently surpasses state-of-the-art zero-shot dense retrieval methods
across a wide range of low-resource retrieval datasets while also making
significant improvements in latency per-query.",2024-10-28,"Nour Jedidi, Yung-Sung Chuang, Leslie Shing, James Glass",http://arxiv.org/pdf/2410.21242v1,cs.CL
Flaming-hot Initiation with Regular Execution Sampling for Large Language Models,"Since the release of ChatGPT, large language models (LLMs) have demonstrated
remarkable capabilities across various domains. A key challenge in developing
these general capabilities is efficiently sourcing diverse, high-quality data.
This becomes especially critical in reasoning-related tasks with sandbox
checkers, such as math or code, where the goal is to generate correct solutions
to specific problems with higher probability. In this work, we introduce
Flaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet
highly effective method to efficiently find good responses. Our empirical
findings show that FIRE sampling enhances inference-time generation quality and
also benefits training in the alignment stage. Furthermore, we explore how FIRE
sampling improves performance by promoting diversity and analyze the impact of
employing FIRE at different positions within a response.",2024-10-28,"Weizhe Chen, Zhicheng Zhang, Guanlin Liu, Renjie Zheng, Wenlei Shi, Chen Dun, Zheng Wu, Xing Jin, Lin Yan",http://arxiv.org/pdf/2410.21236v2,cs.CL
Energy-Based Diffusion Language Models for Text Generation,"Despite remarkable progress in autoregressive language models, alternative
generative paradigms beyond left-to-right generation are still being actively
explored. Discrete diffusion models, with the capacity for parallel generation,
have recently emerged as a promising alternative. Unfortunately, these models
still underperform the autoregressive counterparts, with the performance gap
increasing when reducing the number of sampling steps. Our analysis reveals
that this degradation is a consequence of an imperfect approximation used by
diffusion models. In this work, we propose Energy-based Diffusion Language
Model (EDLM), an energy-based model operating at the full sequence level for
each diffusion step, introduced to improve the underlying approximation used by
diffusion models. More specifically, we introduce an EBM in a residual form,
and show that its parameters can be obtained by leveraging a pretrained
autoregressive model or by finetuning a bidirectional transformer via noise
contrastive estimation. We also propose an efficient generation algorithm via
parallel important sampling. Comprehensive experiments on language modeling
benchmarks show that our model can consistently outperform state-of-the-art
diffusion models by a significant margin, and approaches autoregressive models'
perplexity. We further show that, without any generation performance drop, our
framework offers a 1.3$\times$ sampling speedup over existing diffusion models.
Reproduced code is available at
https://github.com/MinkaiXu/Energy-Diffusion-LLM.",2024-10-28,"Minkai Xu, Tomas Geffner, Karsten Kreis, Weili Nie, Yilun Xu, Jure Leskovec, Stefano Ermon, Arash Vahdat",http://arxiv.org/pdf/2410.21357v4,cs.CL
LoRA vs Full Fine-tuning: An Illusion of Equivalence,"Fine-tuning is a crucial paradigm for adapting pre-trained large language
models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA)
have been shown to match the performance of fully fine-tuned models on various
tasks with an extreme reduction in the number of trainable parameters. Even in
settings where both methods learn similarly accurate models, \emph{are their
learned solutions really equivalent?} We study how different fine-tuning
methods change pre-trained models by analyzing the model's weight matrices
through the lens of their spectral properties. We find that full fine-tuning
and LoRA yield weight matrices whose singular value decompositions exhibit very
different structure; moreover, the fine-tuned models themselves show distinct
generalization behaviors when tested outside the adaptation task's
distribution. More specifically, we first show that the weight matrices trained
with LoRA have new, high-ranking singular vectors, which we call \emph{intruder
dimensions}. Intruder dimensions do not appear during full fine-tuning. Second,
we show that LoRA models with intruder dimensions, despite achieving similar
performance to full fine-tuning on the target task, become worse models of the
pre-training distribution and adapt less robustly to multiple tasks
sequentially. Higher-rank, rank-stabilized LoRA models closely mirror full
fine-tuning, even when performing on par with lower-rank LoRA models on the
same tasks. These results suggest that models updated with LoRA and full
fine-tuning access different parts of parameter space, even when they perform
equally on the fine-tuned distribution. We conclude by examining why intruder
dimensions appear in LoRA fine-tuned models, why they are undesirable, and how
their effects can be minimized.",2024-10-28,"Reece Shuttleworth, Jacob Andreas, Antonio Torralba, Pratyusha Sharma",http://arxiv.org/pdf/2410.21228v1,cs.CL
AutoGLM: Autonomous Foundation Agents for GUIs,"We present AutoGLM, a new series in the ChatGLM family, designed to serve as
foundation agents for autonomous control of digital devices through Graphical
User Interfaces (GUIs). While foundation models excel at acquiring human
knowledge, they often struggle with decision-making in dynamic real-world
environments, limiting their progress toward artificial general intelligence.
This limitation underscores the importance of developing foundation agents
capable of learning through autonomous environmental interactions by
reinforcing existing models. Focusing on Web Browser and Phone as
representative GUI scenarios, we have developed AutoGLM as a practical
foundation agent system for real-world GUI interactions. Our approach
integrates a comprehensive suite of techniques and infrastructures to create
deployable agent systems suitable for user delivery. Through this development,
we have derived two key insights: First, the design of an appropriate
""intermediate interface"" for GUI control is crucial, enabling the separation of
planning and grounding behaviors, which require distinct optimization for
flexibility and accuracy respectively. Second, we have developed a novel
progressive training framework that enables self-evolving online curriculum
reinforcement learning for AutoGLM. Our evaluations demonstrate AutoGLM's
effectiveness across multiple domains. For web browsing, AutoGLM achieves a
55.2% success rate on VAB-WebArena-Lite (improving to 59.1% with a second
attempt) and 96.2% on OpenTable evaluation tasks. In Android device control,
AutoGLM attains a 36.2% success rate on AndroidLab (VAB-Mobile) and 89.7% on
common tasks in popular Chinese APPs.",2024-10-28,"Xiao Liu, Bo Qin, Dongzhu Liang, Guang Dong, Hanyu Lai, Hanchen Zhang, Hanlin Zhao, Iat Long Iong, Jiadai Sun, Jiaqi Wang, Junjie Gao, Junjun Shan, Kangning Liu, Shudan Zhang, Shuntian Yao, Siyi Cheng, Wentao Yao, Wenyi Zhao, Xinghan Liu, Xinyi Liu, Xinying Chen, Xinyue Yang, Yang Yang, Yifan Xu, Yu Yang, Yujia Wang, Yulin Xu, Zehan Qi, Yuxiao Dong, Jie Tang",http://arxiv.org/pdf/2411.00820v1,cs.CL
HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation,"Many positional encodings (PEs) are designed to exhibit long-term decay,
based on an entrenched and long-standing inductive opinion: tokens farther away
from the current position carry less relevant information. We argue that
long-term decay is outdated in the era of LLMs, as LLMs are now applied to
tasks demanding precise retrieval of in-context information from arbitrary
positions. Firstly, we present empirical analyses on various PEs, demonstrating
that models inherently learn attention with only a local-decay pattern while
forming a U-shape pattern globally, contradicting the principle of long-term
decay. Furthermore, we conduct a detailed analysis of rotary position encoding
(RoPE, a prevalent relative positional encoding in LLMs), and found that the
U-shape attention is caused by some learned components, which are also the key
factor limiting RoPE's expressiveness and extrapolation.Inspired by these
insights, we propose High-frequency rotary Position Encoding (HoPE). HoPE
replaces the specific components in RoPE with position-independent ones,
retaining only high-frequency signals, which also breaks the principle of
long-term decay in theory. HoPE achieves two major advantages: (1) Without
constraints imposed by long-term decay, contradictory factors that limit
spontaneous attention optimization and model extrapolation performance are
removed. (2) Components representing positions and semantics are are optimized.
These enhances model's context awareness and extrapolation, as validated by
extensive experiments.",2024-10-28,"Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu",http://arxiv.org/pdf/2410.21216v2,cs.CL
BongLLaMA: LLaMA for Bangla Language,"Bangla (or ""Bengali"") is a language spoken by approximately 240 million
native speakers and around 300 million people worldwide. Despite being the 5th
largest spoken language in the world, Bangla is still a ""low-resource""
language, and existing pretrained language models often struggle to perform
well on Bangla Language Processing (BLP) tasks. This work addresses this gap by
introducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model
fine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.
We present our methodology, data augmentation techniques, fine-tuning details,
and comprehensive benchmarking results showcasing the utility of BongLLaMA on
BLP tasks. We believe BongLLaMA will serve as the new standard baseline for
Bangla Language Models and, thus, facilitate future benchmarking studies
focused on this widely-spoken yet ""low-resource"" language. All BongLLaMA models
are available for public use at https://huggingface.co/BanglaLLM.",2024-10-28,"Abdullah Khan Zehady, Safi Al Mamun, Naymul Islam, Santu Karmaker",http://arxiv.org/pdf/2410.21200v1,cs.CL
Belief in the Machine: Investigating Epistemological Blind Spots of Language Models,"As language models (LMs) become integral to fields like healthcare, law, and
journalism, their ability to differentiate between fact, belief, and knowledge
is essential for reliable decision-making. Failure to grasp these distinctions
can lead to significant consequences in areas such as medical diagnosis, legal
judgments, and dissemination of fake news. Despite this, current literature has
largely focused on more complex issues such as theory of mind, overlooking more
fundamental epistemic challenges. This study systematically evaluates the
epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and
Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13
tasks. Our results reveal key limitations. First, while LMs achieve 86%
accuracy on factual scenarios, their performance drops significantly with false
scenarios, particularly in belief-related tasks. Second, LMs struggle with
recognizing and affirming personal beliefs, especially when those beliefs
contradict factual data, which raises concerns for applications in healthcare
and counseling, where engaging with a person's beliefs is critical. Third, we
identify a salient bias in how LMs process first-person versus third-person
beliefs, performing better on third-person tasks (80.7%) compared to
first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the
factive nature of knowledge, namely, that knowledge inherently requires truth.
Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the
deeper reasoning. These findings highlight significant concerns about current
LMs' ability to reason about truth, belief, and knowledge while emphasizing the
need for advancements in these areas before broad deployment in critical
sectors.",2024-10-28,"Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou",http://arxiv.org/pdf/2410.21195v1,cs.CL
"Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction","Document parsing is essential for converting unstructured and semi-structured
documents such as contracts, academic papers, and invoices into structured,
machine-readable data. Document parsing reliable structured data from
unstructured inputs, providing huge convenience for numerous applications.
Especially with recent achievements in Large Language Models, document parsing
plays an indispensable role in both knowledge base construction and training
data generation. This survey presents a comprehensive review of the current
state of document parsing, covering key methodologies, from modular pipeline
systems to end-to-end models driven by large vision-language models. Core
components such as layout detection, content extraction (including text,
tables, and mathematical expressions), and multi-modal data integration are
examined in detail. Additionally, this paper discusses the challenges faced by
modular document parsing systems and vision-language models in handling complex
layouts, integrating multiple modules, and recognizing high-density text. It
outlines future research directions and emphasizes the importance of developing
larger and more diverse datasets.",2024-10-28,"Qintong Zhang, Bin Wang, Victor Shea-Jay Huang, Junyuan Zhang, Zhengren Wang, Hao Liang, Conghui He, Wentao Zhang",http://arxiv.org/pdf/2410.21169v4,cs.CL
M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation,"Repository-level code completion has drawn great attention in software
engineering, and several benchmark datasets have been introduced. However,
existing repository-level code completion benchmarks usually focus on a limited
number of languages (<5), which cannot evaluate the general code intelligence
abilities across different languages for existing code Large Language Models
(LLMs). Besides, the existing benchmarks usually report overall average scores
of different languages, where the fine-grained abilities in different
completion scenarios are ignored. Therefore, to facilitate the research of code
LLMs in multilingual scenarios, we propose a massively multilingual
repository-level code completion benchmark covering 18 programming languages
(called M2RC-EVAL), and two types of fine-grained annotations (i.e.,
bucket-level and semantic-level) on different completion scenarios are
provided, where we obtain these annotations based on the parsed abstract syntax
tree. Moreover, we also curate a massively multilingual instruction corpora
M2RC- INSTRUCT dataset to improve the repository-level code completion
abilities of existing code LLMs. Comprehensive experimental results demonstrate
the effectiveness of our M2RC-EVAL and M2RC-INSTRUCT.",2024-10-28,"Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, Ke Jin, Ge Zhang, Zekun Wang, Guoan Zhang, Bangyu Xiang, Wenbo Su, Bo Zheng",http://arxiv.org/pdf/2410.21157v1,cs.CL
"SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents","Scientific information extraction (SciIE) is critical for converting
unstructured knowledge from scholarly articles into structured data (entities
and relations). Several datasets have been proposed for training and validating
SciIE models. However, due to the high complexity and cost of annotating
scientific texts, those datasets restrict their annotations to specific parts
of paper, such as abstracts, resulting in the loss of diverse entity mentions
and relations in context. In this paper, we release a new entity and relation
extraction dataset for entities related to datasets, methods, and tasks in
scientific articles. Our dataset contains 106 manually annotated full-text
scientific publications with over 24k entities and 12k relations. To capture
the intricate use and interactions among entities in full texts, our dataset
contains a fine-grained tag set for relations. Additionally, we provide an
out-of-distribution test set to offer a more realistic evaluation. We conduct
comprehensive experiments, including state-of-the-art supervised models and our
proposed LLM-based baselines, and highlight the challenges presented by our
dataset, encouraging the development of innovative models to further the field
of SciIE.",2024-10-28,"Qi Zhang, Zhijia Chen, Huitong Pan, Cornelia Caragea, Longin Jan Latecki, Eduard Dragut",http://arxiv.org/pdf/2410.21155v1,cs.CL
Palisade -- Prompt Injection Detection Framework,"The advent of Large Language Models LLMs marks a milestone in Artificial
Intelligence, altering how machines comprehend and generate human language.
However, LLMs are vulnerable to malicious prompt injection attacks, where
crafted inputs manipulate the models behavior in unintended ways, compromising
system integrity and causing incorrect outcomes. Conventional detection methods
rely on static, rule-based approaches, which often fail against sophisticated
threats like abnormal token sequences and alias substitutions, leading to
limited adaptability and higher rates of false positives and false
negatives.This paper proposes a novel NLP based approach for prompt injection
detection, emphasizing accuracy and optimization through a layered input
screening process. In this framework, prompts are filtered through three
distinct layers rule-based, ML classifier, and companion LLM before reaching
the target model, thereby minimizing the risk of malicious interaction.Tests
show the ML classifier achieves the highest accuracy among individual layers,
yet the multi-layer framework enhances overall detection accuracy by reducing
false negatives. Although this increases false positives, it minimizes the risk
of overlooking genuine injected prompts, thus prioritizing security.This
multi-layered detection approach highlights LLM vulnerabilities and provides a
comprehensive framework for future research, promoting secure interactions
between humans and AI systems.",2024-10-28,"Sahasra Kokkula, Somanathan R, Nandavardhan R, Aashishkumar, G Divya",http://arxiv.org/pdf/2410.21146v1,cs.CL
uOttawa at LegalLens-2024: Transformer-based Classification Experiments,"This paper presents the methods used for LegalLens-2024 shared task, which
focused on detecting legal violations within unstructured textual data and
associating these violations with potentially affected individuals. The shared
task included two subtasks: A) Legal Named Entity Recognition (L-NER) and B)
Legal Natural Language Inference (L-NLI). For subtask A, we utilized the spaCy
library, while for subtask B, we employed a combined model incorporating
RoBERTa and CNN. Our results were 86.3% in the L-NER subtask and 88.25% in the
L-NLI subtask. Overall, our paper demonstrates the effectiveness of transformer
models in addressing complex tasks in the legal domain. The source code for our
implementation is publicly available at
https://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification",2024-10-28,"Nima Meghdadi, Diana Inkpen",http://arxiv.org/pdf/2410.21139v2,cs.CL
Causal Interventions on Causal Paths: Mapping GPT-2's Reasoning From Syntax to Semantics,"While interpretability research has shed light on some internal algorithms
utilized by transformer-based LLMs, reasoning in natural language, with its
deep contextuality and ambiguity, defies easy categorization. As a result,
formulating clear and motivating questions for circuit analysis that rely on
well-defined in-domain and out-of-domain examples required for causal
interventions is challenging. Although significant work has investigated
circuits for specific tasks, such as indirect object identification (IOI),
deciphering natural language reasoning through circuits remains difficult due
to its inherent complexity. In this work, we take initial steps to characterize
causal reasoning in LLMs by analyzing clear-cut cause-and-effect sentences like
""I opened an umbrella because it started raining,"" where causal interventions
may be possible through carefully crafted scenarios using GPT-2 small. Our
findings indicate that causal syntax is localized within the first 2-3 layers,
while certain heads in later layers exhibit heightened sensitivity to
nonsensical variations of causal sentences. This suggests that models may infer
reasoning by (1) detecting syntactic cues and (2) isolating distinct heads in
the final layers that focus on semantic relationships.",2024-10-28,"Isabelle Lee, Joshua Lum, Ziyi Liu, Dani Yogatama",http://arxiv.org/pdf/2410.21353v1,cs.CL
Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments,"As machine learning models evolve, maintaining transparency demands more
human-centric explainable AI techniques. Counterfactual explanations, with
roots in human reasoning, identify the minimal input changes needed to obtain a
given output and, hence, are crucial for supporting decision-making. Despite
their importance, the evaluation of these explanations often lacks grounding in
user studies and remains fragmented, with existing metrics not fully capturing
human perspectives. To address this challenge, we developed a diverse set of 30
counterfactual scenarios and collected ratings across 8 evaluation metrics from
206 respondents. Subsequently, we fine-tuned different Large Language Models
(LLMs) to predict average or individual human judgment across these metrics.
Our methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot
evaluations and 85% (over a 3-classes prediction) with fine-tuning across all
metrics. The fine-tuned models predicting human ratings offer better
comparability and scalability in evaluating different counterfactual
explanation frameworks.",2024-10-28,"Marharyta Domnich, Julius Välja, Rasmus Moorits Veski, Giacomo Magnifico, Kadi Tulver, Eduard Barbu, Raul Vicente",http://arxiv.org/pdf/2410.21131v3,cs.CL
Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model,"Enzyme engineering enables the modification of wild-type proteins to meet
industrial and research demands by enhancing catalytic activity, stability,
binding affinities, and other properties. The emergence of deep learning
methods for protein modeling has demonstrated superior results at lower costs
compared to traditional approaches such as directed evolution and rational
design. In mutation effect prediction, the key to pre-training deep learning
models lies in accurately interpreting the complex relationships among protein
sequence, structure, and function. This study introduces a retrieval-enhanced
protein language model for comprehensive analysis of native properties from
sequence and local structural interactions, as well as evolutionary properties
from retrieved homologous sequences. The state-of-the-art performance of the
proposed ProtREM is validated on over 2 million mutants across 217 assays from
an open benchmark (ProteinGym). We also conducted post-hoc analyses of the
model's ability to improve the stability and binding affinity of a VHH
antibody. Additionally, we designed 10 new mutants on a DNA polymerase and
conducted wet-lab experiments to evaluate their enhanced activity at higher
temperatures. Both in silico and experimental evaluations confirmed that our
method provides reliable predictions of mutation effects, offering an auxiliary
tool for biologists aiming to evolve existing enzymes. The implementation is
publicly available at https://github.com/tyang816/ProtREM.",2024-10-28,"Yang Tan, Ruilin Wang, Banghao Wu, Liang Hong, Bingxin Zhou",http://arxiv.org/pdf/2410.21127v1,cs.CL
Current State-of-the-Art of Bias Detection and Mitigation in Machine Translation for African and European Languages: a Review,"Studying bias detection and mitigation methods in natural language processing
and the particular case of machine translation is highly relevant, as societal
stereotypes might be reflected or reinforced by these systems. In this paper,
we analyze the state-of-the-art with a particular focus on European and African
languages. We show how the majority of the work in this field concentrates on
few languages, and that there is potential for future research to cover also
the less investigated languages to contribute to more diversity in the research
field.",2024-10-28,"Catherine Ikae, Mascha Kurpicz-Briki",http://arxiv.org/pdf/2410.21126v1,cs.CL
An Actor-Critic Approach to Boosting Text-to-SQL Large Language Model,"Text-To-SQL (T2S) conversion based on large language models (LLMs) has found
a wide range of applications, by leveraging the capabilities of LLMs in
interpreting the query intent expressed in natural language. Existing research
focuses on suitable representations for data schema and/or questions,
task-specific instructions and representative examples, and complicated
inference pipelines. All these methods are empirical and task specific, without
a theoretical bound on performance. In this paper, we propose a simple,
general, and performance guaranteed T2S enhancement approach called
Actor-Critic (AC). Specifically, we design two roles using the same LLM: an
Actor to produce SQL queries and a Critic to evaluate the produced SQL. If the
Critic believes the produced SQL is wrong, it notifies the Actor to reproduce
the SQL and perform evaluation again. By this simple iterative process,
expected performance can be derived in theory. We conducted extensive
experiments on the Spider and related datasets with eleven LLMs, and
demonstrated that the Actor-Critic method consistently improves the performance
of T2S, thus serving as a general enhancement approach for T2S conversion.",2024-10-28,"Ziyang Zheng, Haipeng Jing, Canyu Rui, Askar Hamdulla, Dong Wang",http://arxiv.org/pdf/2410.22082v1,cs.CL
Zero-Shot Action Recognition in Surveillance Videos,"The growing demand for surveillance in public spaces presents significant
challenges due to the shortage of human resources. Current AI-based video
surveillance systems heavily rely on core computer vision models that require
extensive finetuning, which is particularly difficult in surveillance settings
due to limited datasets and difficult setting (viewpoint, low quality, etc.).
In this work, we propose leveraging Large Vision-Language Models (LVLMs), known
for their strong zero and few-shot generalization, to tackle video
understanding tasks in surveillance. Specifically, we explore VideoLLaMA2, a
state-of-the-art LVLM, and an improved token-level sampling method,
Self-Reflective Sampling (Self-ReS). Our experiments on the UCF-Crime dataset
show that VideoLLaMA2 represents a significant leap in zero-shot performance,
with 20% boost over the baseline. Self-ReS additionally increases zero-shot
action recognition performance to 44.6%. These results highlight the potential
of LVLMs, paired with improved sampling techniques, for advancing surveillance
video analysis in diverse scenarios.",2024-10-28,"Joao Pereira, Vasco Lopes, David Semedo, Joao Neves",http://arxiv.org/pdf/2410.21113v2,cs.CL
Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring,"Large language model (LLM) safety is a critical issue, with numerous studies
employing red team testing to enhance model security. Among these, jailbreak
methods explore potential vulnerabilities by crafting malicious prompts that
induce model outputs contrary to safety alignments. Existing black-box
jailbreak methods often rely on model feedback, repeatedly submitting queries
with detectable malicious instructions during the attack search process.
Although these approaches are effective, the attacks may be intercepted by
content moderators during the search process. We propose an improved transfer
attack method that guides malicious prompt construction by locally training a
mirror model of the target black-box model through benign data distillation.
This method offers enhanced stealth, as it does not involve submitting
identifiable malicious instructions to the target model during the search
phase. Our approach achieved a maximum attack success rate of 92%, or a
balanced value of 80% with an average of 1.5 detectable jailbreak queries per
sample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore
the need for more robust defense mechanisms.",2024-10-28,"Honglin Mu, Han He, Yuxin Zhou, Yunlong Feng, Yang Xu, Libo Qin, Xiaoming Shi, Zeming Liu, Xudong Han, Qi Shi, Qingfu Zhu, Wanxiang Che",http://arxiv.org/pdf/2410.21083v2,cs.CL
LLMCBench: Benchmarking Large Language Model Compression for Efficient Deployment,"Although large language models (LLMs) have demonstrated their strong
intelligence ability, the high demand for computation and storage hinders their
practical application. To this end, many model compression techniques are
proposed to increase the efficiency of LLMs. However, current researches only
validate their methods on limited models, datasets, metrics, etc, and still
lack a comprehensive evaluation under more general scenarios. So it is still a
question of which model compression approach we should use under a specific
case. To mitigate this gap, we present the Large Language Model Compression
Benchmark (LLMCBench), a rigorously designed benchmark with an in-depth
analysis for LLM compression algorithms. We first analyze the actual model
production requirements and carefully design evaluation tracks and metrics.
Then, we conduct extensive experiments and comparison using multiple mainstream
LLM compression approaches. Finally, we perform an in-depth analysis based on
the evaluation and provide useful insight for LLM compression design. We hope
our LLMCBench can contribute insightful suggestions for LLM compression
algorithm design and serve as a foundation for future research. Our code is
available at https://github.com/AboveParadise/LLMCBench.",2024-10-28,"Ge Yang, Changyi He, Jinyang Guo, Jianyu Wu, Yifu Ding, Aishan Liu, Haotong Qin, Pengliang Ji, Xianglong Liu",http://arxiv.org/pdf/2410.21352v2,cs.CL
CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models,"Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.",2024-10-28,"Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou",http://arxiv.org/pdf/2410.21067v1,cs.CL
Semantic Component Analysis: Discovering Patterns in Short Texts Beyond Topics,"Topic modeling is a key method in text analysis, but existing approaches are
limited by assuming one topic per document or fail to scale efficiently for
large, noisy datasets of short texts. We introduce Semantic Component Analysis
(SCA), a novel topic modeling technique that overcomes these limitations by
discovering multiple, nuanced semantic components beyond a single topic in
short texts which we accomplish by introducing a decomposition step to the
clustering-based topic modeling framework. We evaluate SCA on Twitter datasets
in English, Hausa and Chinese. It achieves competetive coherence and diversity
compared to BERTopic, while uncovering at least double the semantic components
and maintaining a noise rate close to zero. Furthermore, SCA is scalable and
effective across languages, including an underrepresented one.",2024-10-28,"Florian Eichin, Carolin M. Schuster, Georg Groh, Michael A. Hedderich",http://arxiv.org/pdf/2410.21054v2,cs.CL
Sorting Out the Bad Seeds: Automatic Classification of Cryptocurrency Abuse Reports,"Abuse reporting services collect reports about abuse victims have suffered.
Accurate classification of the submitted reports is fundamental to analyzing
the prevalence and financial impact of different abuse types (e.g., sextortion,
investment, romance). Current classification approaches are problematic because
they require the reporter to select the abuse type from a list, assuming the
reporter has the necessary experience for the classification, which we show is
frequently not the case, or require manual classification by analysts, which
does not scale. To address these issues, this paper presents a novel approach
to classify cryptocurrency abuse reports automatically. We first build a
taxonomy of 19 frequently reported abuse types. Given as input the textual
description written by the reporter, our classifier leverages a large language
model (LLM) to interpret the text and assign it an abuse type in our taxonomy.
We collect 290K cryptocurrency abuse reports from two popular reporting
services: BitcoinAbuse and BBB's ScamTracker. We build ground truth datasets
for 20K of those reports and use them to evaluate three designs for our
LLM-based classifier and four LLMs, as well as a supervised ML classifier used
as a baseline. Our LLM-based classifier achieves a precision of 0.92, a recall
of 0.87, and an F1 score of 0.89, compared to an F1 score of 0.55 for the
baseline. We demonstrate our classifier in two applications: providing
financial loss statistics for fine-grained abuse types and generating tagged
addresses for cryptocurrency analysis platforms.",2024-10-28,"Gibran Gomez, Kevin van Liebergen, Davide Sanvito, Giuseppe Siracusano, Roberto Gonzalez, Juan Caballero",http://arxiv.org/pdf/2410.21041v1,cs.CL
Beyond Autoregression: Fast LLMs via Self-Distillation Through Time,"Autoregressive (AR) Large Language Models (LLMs) have demonstrated
significant success across numerous tasks. However, the AR modeling paradigm
presents certain limitations; for instance, contemporary autoregressive LLMs
are trained to generate one token at a time, which can result in noticeable
latency. Recent advances have indicated that search and repeated sampling can
enhance performance in various applications, such as theorem proving, code
generation, and alignment, by utilizing greater computational resources during
inference. In this study, we demonstrate that diffusion language models are
capable of generating at least 32 tokens simultaneously, while exceeding the
performance of AR models in text quality and on the LAMBADA natural language
understanding benchmark. This outcome is achieved through a novel distillation
method for discrete diffusion models, which reduces the number of inference
steps by a factor of 32-64. Practically, at the 1.3B parameters scale,
diffusion models, even without caching, can generate tokens at a rate that is
up to 8 times faster than AR models employing KV-caching, and we anticipate
further improvements with the inclusion of caching. Moreover, we demonstrate
the efficacy of our approach for diffusion language models with up to 860M
parameters.",2024-10-28,"Justin Deschenaux, Caglar Gulcehre",http://arxiv.org/pdf/2410.21035v2,cs.CL
Transferable Post-training via Inverse Value Learning,"As post-training processes utilize increasingly large datasets and base
models continue to grow in size, the computational demands and implementation
challenges of existing algorithms are escalating significantly. In this paper,
we propose modeling the changes at the logits level during post-training using
a separate neural network (i.e., the value network). After training this
network on a small base model using demonstrations, this network can be
seamlessly integrated with other pre-trained models during inference, enables
them to achieve similar capability enhancements. We systematically investigate
the best practices for this paradigm in terms of pre-training weights and
connection schemes. We demonstrate that the resulting value network has broad
transferability across pre-trained models of different parameter sizes within
the same family, models undergoing continuous pre-training within the same
family, and models with different vocabularies across families. In certain
cases, it can achieve performance comparable to full-parameter fine-tuning.
Furthermore, we explore methods to enhance the transferability of the value
model and prevent overfitting to the base model used during training.",2024-10-28,"Xinyu Lu, Xueru Wen, Yaojie Lu, Bowen Yu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, Yongbin Li",http://arxiv.org/pdf/2410.21027v1,cs.CL
Frequency matters: Modeling irregular morphological patterns in Spanish with Transformers,"Over the past decade, various studies have addressed how speakers solve the
so-called `The Paradigm Cell Filling Problem' (PCFP) \citep{ackerman2009parts}
across different languages. The PCFP addresses a fundamental question in
morphological processing: how do speakers accurately generate inflected forms
of words when presented with incomplete paradigms? This problem is particularly
salient when modeling complex inflectional systems. We focus on Spanish verbal
paradigms, where certain verbs follow an irregular L-shaped pattern, where the
first-person singular present indicative stem matches the stem used throughout
the present subjunctive mood. We formulate the problem as a morphological
reinflection task. Specifically, we investigate the role of input frequency in
the acquisition of regular versus irregular L-shaped patterns in transformer
models. By systematically manipulating the input distributions and analyzing
model behavior, we reveal four key findings: 1) Models perform better on
L-shaped verbs compared to regular verbs, especially in uneven frequency
conditions; 2) Robust primacy effects are observed, but no consistent recency
effects; 3) Memorization becomes more prominent as the proportion of L-shaped
verbs increases; 4) There is a tendency to regularize L-shaped verbs when their
consonant alternation pairs are rare or absent in the training data.",2024-10-28,"Akhilesh Kakolu Ramarao, Kevin Tang, Dinah Baer-Henney",http://arxiv.org/pdf/2410.21013v3,cs.CL
FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval,"Large Language Models (LLMs) are proficient at retrieving single facts from
extended contexts, yet they struggle with tasks requiring the simultaneous
retrieval of multiple facts, especially during generation. This paper
identifies a novel ""lost-in-the-middle"" phenomenon, where LLMs progressively
lose track of critical information throughout the generation process, resulting
in incomplete or inaccurate retrieval. To address this challenge, we introduce
Find All Crucial Texts (FACT), an iterative retrieval method that refines
context through successive rounds of rewriting. This approach enables models to
capture essential facts incrementally, which are often overlooked in
single-pass retrieval. Experiments demonstrate that FACT substantially enhances
multi-fact retrieval performance across various tasks, though improvements are
less notable in general-purpose QA scenarios. Our findings shed light on the
limitations of LLMs in multi-fact retrieval and underscore the need for more
resilient long-context retrieval strategies.",2024-10-28,"Jinlin Wang, Suyuchen Wang, Ziwen Xia, Sirui Hong, Yun Zhu, Bang Liu, Chenglin Wu",http://arxiv.org/pdf/2410.21012v1,cs.CL
Is GPT-4 Less Politically Biased than GPT-3.5? A Renewed Investigation of ChatGPT's Political Biases,"This work investigates the political biases and personality traits of
ChatGPT, specifically comparing GPT-3.5 to GPT-4. In addition, the ability of
the models to emulate political viewpoints (e.g., liberal or conservative
positions) is analyzed. The Political Compass Test and the Big Five Personality
Test were employed 100 times for each scenario, providing statistically
significant results and an insight into the results correlations. The responses
were analyzed by computing averages, standard deviations, and performing
significance tests to investigate differences between GPT-3.5 and GPT-4.
Correlations were found for traits that have been shown to be interdependent in
human studies. Both models showed a progressive and libertarian political bias,
with GPT-4's biases being slightly, but negligibly, less pronounced.
Specifically, on the Political Compass, GPT-3.5 scored -6.59 on the economic
axis and -6.07 on the social axis, whereas GPT-4 scored -5.40 and -4.73. In
contrast to GPT-3.5, GPT-4 showed a remarkable capacity to emulate assigned
political viewpoints, accurately reflecting the assigned quadrant
(libertarian-left, libertarian-right, authoritarian-left, authoritarian-right)
in all four tested instances. On the Big Five Personality Test, GPT-3.5 showed
highly pronounced Openness and Agreeableness traits (O: 85.9%, A: 84.6%). Such
pronounced traits correlate with libertarian views in human studies. While
GPT-4 overall exhibited less pronounced Big Five personality traits, it did
show a notably higher Neuroticism score. Assigned political orientations
influenced Openness, Agreeableness, and Conscientiousness, again reflecting
interdependencies observed in human studies. Finally, we observed that test
sequencing affected ChatGPT's responses and the observed correlations,
indicating a form of contextual memory.",2024-10-28,"Erik Weber, Jérôme Rutinowski, Niklas Jost, Markus Pauly",http://arxiv.org/pdf/2410.21008v1,cs.CL
DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning,"Current techniques for detecting AI-generated text are largely confined to
manual feature crafting and supervised binary classification paradigms. These
methodologies typically lead to performance bottlenecks and unsatisfactory
generalizability. Consequently, these methods are often inapplicable for
out-of-distribution (OOD) data and newly emerged large language models (LLMs).
In this paper, we revisit the task of AI-generated text detection. We argue
that the key to accomplishing this task lies in distinguishing writing styles
of different authors, rather than simply classifying the text into
human-written or AI-generated text. To this end, we propose DeTeCtive, a
multi-task auxiliary, multi-level contrastive learning framework. DeTeCtive is
designed to facilitate the learning of distinct writing styles, combined with a
dense information retrieval pipeline for AI-generated text detection. Our
method is compatible with a range of text encoders. Extensive experiments
demonstrate that our method enhances the ability of various text encoders in
detecting AI-generated text across multiple benchmarks and achieves
state-of-the-art results. Notably, in OOD zero-shot evaluation, our method
outperforms existing approaches by a large margin. Moreover, we find our method
boasts a Training-Free Incremental Adaptation (TFIA) capability towards OOD
data, further enhancing its efficacy in OOD detection scenarios. We will
open-source our code and models in hopes that our work will spark new thoughts
in the field of AI-generated text detection, ensuring safe application of LLMs
and enhancing compliance. Our code is available at
https://github.com/heyongxin233/DeTeCtive.",2024-10-28,"Xun Guo, Shan Zhang, Yongxin He, Ting Zhang, Wanquan Feng, Haibin Huang, Chongyang Ma",http://arxiv.org/pdf/2410.20964v1,cs.CL
Fine-Grained and Multi-Dimensional Metrics for Document-Level Machine Translation,"Large language models (LLMs) have excelled in various NLP tasks, including
machine translation (MT), yet most studies focus on sentence-level translation.
This work investigates the inherent capability of instruction-tuned LLMs for
document-level translation (docMT). Unlike prior approaches that require
specialized techniques, we evaluate LLMs by directly prompting them to
translate entire documents in a single pass. Our results show that this method
improves translation quality compared to translating sentences separately, even
without document-level fine-tuning. However, this advantage is not reflected in
BLEU scores, which often favor sentence-based translations. We propose using
the LLM-as-a-judge paradigm for evaluation, where GPT-4 is used to assess
document coherence, accuracy, and fluency in a more nuanced way than
n-gram-based metrics. Overall, our work demonstrates that instruction-tuned
LLMs can effectively leverage document context for translation. However, we
caution against using BLEU scores for evaluating docMT, as they often provide
misleading outcomes, failing to capture the quality of document-level
translation. Code and the outputs from GPT4-as-a-judge are available at
https://github.com/EIT-NLP/BLEUless_DocMT",2024-10-28,"Yirong Sun, Dawei Zhu, Yanjun Chen, Erjia Xiao, Xinghao Chen, Xiaoyu Shen",http://arxiv.org/pdf/2410.20941v4,cs.CL
Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models,"We investigate the challenge of generating adversarial examples to test the
robustness of text classification algorithms detecting low-credibility content,
including propaganda, false claims, rumours and hyperpartisan news. We focus on
simulation of content moderation by setting realistic limits on the number of
queries an attacker is allowed to attempt. Within our solution (TREPAT),
initial rephrasings are generated by large language models with prompts
inspired by meaning-preserving NLP tasks, e.g. text simplification and style
transfer. Subsequently, these modifications are decomposed into small changes,
applied through beam search procedure until the victim classifier changes its
decision. The evaluation confirms the superiority of our approach in the
constrained scenario, especially in case of long input text (news articles),
where exhaustive search is not feasible.",2024-10-28,Piotr Przybyła,http://arxiv.org/pdf/2410.20940v1,cs.CL
Autoformalize Mathematical Statements by Symbolic Equivalence and Semantic Consistency,"Autoformalization, the task of automatically translating natural language
descriptions into a formal language, poses a significant challenge across
various domains, especially in mathematics. Recent advancements in large
language models (LLMs) have unveiled their promising capabilities to formalize
even competition-level math problems. However, we observe a considerable
discrepancy between pass@1 and pass@k accuracies in LLM-generated
formalizations. To address this gap, we introduce a novel framework that scores
and selects the best result from k autoformalization candidates based on two
complementary self-consistency methods: symbolic equivalence and semantic
consistency. Elaborately, symbolic equivalence identifies the logical
homogeneity among autoformalization candidates using automated theorem provers,
and semantic consistency evaluates the preservation of the original meaning by
informalizing the candidates and computing the similarity between the
embeddings of the original and informalized texts. Our extensive experiments on
the MATH and miniF2F datasets demonstrate that our approach significantly
enhances autoformalization accuracy, achieving up to 0.22-1.35x relative
improvements across various LLMs and baseline methods.",2024-10-28,"Zenan Li, Yifan Wu, Zhaoyu Li, Xinming Wei, Xian Zhang, Fan Yang, Xiaoxing Ma",http://arxiv.org/pdf/2410.20936v2,cs.CL
Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning,"As the demand for processing extended textual data grows, the ability to
handle long-range dependencies and maintain computational efficiency is more
critical than ever. One of the key issues for long-sequence modeling using
attention-based model is the mismatch between the limited-range modeling power
of full attention and the long-range token dependency in the input sequence. In
this work, we propose to scale up the attention receptive field by tensorizing
long input sequences into compact tensor representations followed by attention
on each transformed dimension. The resulting Tensorized Attention can be
adopted as efficient transformer backbones to extend input context length with
improved memory and time efficiency. We show that the proposed attention
tensorization encodes token dependencies as a multi-hop attention process, and
is equivalent to Kronecker decomposition of full attention. Extensive
experiments show that tensorized attention can be used to adapt pretrained LLMs
with improved efficiency. Notably, Llama-8B with tensorization is trained under
32,768 context length and can steadily extrapolate to 128k length during
inference with $11\times$ speedup, compared to full attention with
FlashAttention-2.",2024-10-28,"Aosong Feng, Rex Ying, Leandros Tassiulas",http://arxiv.org/pdf/2410.20926v2,cs.CL
Large Language Model Benchmarks in Medical Tasks,"With the increasing application of large language models (LLMs) in the
medical domain, evaluating these models' performance using benchmark datasets
has become crucial. This paper presents a comprehensive survey of various
benchmark datasets employed in medical LLM tasks. These datasets span multiple
modalities including text, image, and multimodal benchmarks, focusing on
different aspects of medical knowledge such as electronic health records
(EHRs), doctor-patient dialogues, medical question-answering, and medical image
captioning. The survey categorizes the datasets by modality, discussing their
significance, data structure, and impact on the development of LLMs for
clinical tasks such as diagnosis, report generation, and predictive decision
support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and
CheXpert, which have facilitated advancements in tasks like medical report
generation, clinical summarization, and synthetic data generation. The paper
summarizes the challenges and opportunities in leveraging these benchmarks for
advancing multimodal medical intelligence, emphasizing the need for datasets
with a greater degree of language diversity, structured omics data, and
innovative approaches to synthesis. This work also provides a foundation for
future research in the application of LLMs in medicine, contributing to the
evolving field of medical artificial intelligence.",2024-10-28,"Lawrence K. Q. Yan, Qian Niu, Ming Li, Yichao Zhang, Caitlyn Heqi Yin, Cheng Fei, Benji Peng, Ziqian Bi, Pohsun Feng, Keyu Chen, Tianyang Wang, Yunze Wang, Silin Chen, Ming Liu, Junyu Liu",http://arxiv.org/pdf/2410.21348v2,cs.CL
NeuGPT: Unified multi-modal Neural GPT,"This paper introduces NeuGPT, a groundbreaking multi-modal language
generation model designed to harmonize the fragmented landscape of neural
recording research. Traditionally, studies in the field have been
compartmentalized by signal type, with EEG, MEG, ECoG, SEEG, fMRI, and fNIRS
data being analyzed in isolation. Recognizing the untapped potential for
cross-pollination and the adaptability of neural signals across varying
experimental conditions, we set out to develop a unified model capable of
interfacing with multiple modalities. Drawing inspiration from the success of
pre-trained large models in NLP, computer vision, and speech processing, NeuGPT
is architected to process a diverse array of neural recordings and interact
with speech and text data. Our model mainly focus on brain-to-text decoding,
improving SOTA from 6.94 to 12.92 on BLEU-1 and 6.93 to 13.06 on ROUGE-1F. It
can also simulate brain signals, thereby serving as a novel neural interface.
Code is available at
\href{https://github.com/NeuSpeech/NeuGPT}{NeuSpeech/NeuGPT
(https://github.com/NeuSpeech/NeuGPT) .}",2024-10-28,"Yiqian Yang, Yiqun Duan, Hyejeong Jo, Qiang Zhang, Renjing Xu, Oiwi Parker Jones, Xuming Hu, Chin-teng Lin, Hui Xiong",http://arxiv.org/pdf/2410.20916v1,cs.CL
AutoRAG: Automated Framework for optimization of Retrieval Augmented Generation Pipeline,"Using LLMs (Large Language Models) in conjunction with external documents has
made RAG (Retrieval-Augmented Generation) an essential technology. Numerous
techniques and modules for RAG are being researched, but their performance can
vary across different datasets. Finding RAG modules that perform well on
specific datasets is challenging. In this paper, we propose the AutoRAG
framework, which automatically identifies suitable RAG modules for a given
dataset. AutoRAG explores and approximates the optimal combination of RAG
modules for the dataset. Additionally, we share the results of optimizing a
dataset using AutoRAG. All experimental results and data are publicly available
and can be accessed through our GitHub repository
https://github.com/Marker-Inc-Korea/AutoRAG_ARAGOG_Paper .",2024-10-28,"Dongkyu Kim, Byoungwook Kim, Donggeon Han, Matouš Eibich",http://arxiv.org/pdf/2410.20878v1,cs.CL
Reward Modeling with Weak Supervision for Language Models,"Recent advancements in large language models (LLMs) have led to their
increased application across various tasks, with reinforcement learning from
human feedback (RLHF) being a crucial part of their training to align responses
with user intentions. In the RLHF process, a reward model is trained using
responses preferences determined by human labelers or AI systems, which then
refines the LLM through reinforcement learning. This work introduces weak
supervision as a strategy to extend RLHF datasets and enhance reward model
performance. Weak supervision employs noisy or imprecise data labeling,
reducing reliance on expensive manually labeled data. By analyzing RLHF
datasets to identify heuristics that correlate with response preference, we
wrote simple labeling functions and then calibrated a label model to weakly
annotate unlabeled data. Our evaluation show that while weak supervision
significantly benefits smaller datasets by improving reward model performance,
its effectiveness decreases with larger, originally labeled datasets.
Additionally, using an LLM to generate and then weakly label responses offers a
promising method for extending preference data.",2024-10-28,"Ben Hauptvogel, Malte Ostendorff, Georg Rehm, Sebastian Möller",http://arxiv.org/pdf/2410.20869v1,cs.CL
A Simple Yet Effective Corpus Construction Framework for Indonesian Grammatical Error Correction,"Currently, the majority of research in grammatical error correction (GEC) is
concentrated on universal languages, such as English and Chinese. Many
low-resource languages lack accessible evaluation corpora. How to efficiently
construct high-quality evaluation corpora for GEC in low-resource languages has
become a significant challenge. To fill these gaps, in this paper, we present a
framework for constructing GEC corpora. Specifically, we focus on Indonesian as
our research language and construct an evaluation corpus for Indonesian GEC
using the proposed framework, addressing the limitations of existing evaluation
corpora in Indonesian. Furthermore, we investigate the feasibility of utilizing
existing large language models (LLMs), such as GPT-3.5-Turbo and GPT-4, to
streamline corpus annotation efforts in GEC tasks. The results demonstrate
significant potential for enhancing the performance of LLMs in low-resource
language settings. Our code and corpus can be obtained from
https://github.com/GKLMIP/GEC-Construction-Framework.",2024-10-28,"Nankai Lin, Meiyu Zeng, Wentao Huang, Shengyi Jiang, Lixian Xiao, Aimin Yang",http://arxiv.org/pdf/2410.20838v1,cs.CL
LLMs are Biased Evaluators But Not Biased for Retrieval Augmented Generation,"Recent studies have demonstrated that large language models (LLMs) exhibit
significant biases in evaluation tasks, particularly in preferentially rating
and favoring self-generated content. However, the extent to which this bias
manifests in fact-oriented tasks, especially within retrieval-augmented
generation (RAG) frameworks-where keyword extraction and factual accuracy take
precedence over stylistic elements-remains unclear. Our study addresses this
knowledge gap by simulating two critical phases of the RAG framework. In the
first phase, we access the suitability of human-authored versus model-generated
passages, emulating the pointwise reranking process. The second phase involves
conducting pairwise reading comprehension tests to simulate the generation
process. Contrary to previous findings indicating a self-preference in rating
tasks, our results reveal no significant self-preference effect in RAG
frameworks. Instead, we observe that factual accuracy significantly influences
LLMs' output, even in the absence of prior knowledge. Our research contributes
to the ongoing discourse on LLM biases and their implications for RAG-based
system, offering insights that may inform the development of more robust and
unbiased LLM systems.",2024-10-28,"Yen-Shan Chen, Jing Jin, Peng-Ting Kuo, Chao-Wei Huang, Yun-Nung Chen",http://arxiv.org/pdf/2410.20833v1,cs.CL
CycleResearcher: Improving Automated Research via Automated Review,"The automation of scientific discovery has been a long-standing goal within
the research community, driven by the potential to accelerate knowledge
creation. While significant progress has been made using commercial large
language models (LLMs) as research assistants or idea generators, the
possibility of automating the entire research process with open-source LLMs
remains largely unexplored. This paper explores the feasibility of using
open-source post-trained LLMs as autonomous agents capable of performing the
full cycle of automated research and review, from literature review and
manuscript preparation to peer review and paper refinement. Our iterative
preference training framework consists of CycleResearcher, which conducts
research tasks, and CycleReviewer, which simulates the peer review process,
providing iterative feedback via reinforcement learning. To train these models,
we develop two new datasets, Review-5k and Research-14k, reflecting real-world
machine learning research and peer review dynamics. Our results demonstrate
that CycleReviewer achieves promising performance with a 26.89\% reduction in
mean absolute error (MAE) compared to individual human reviewers in predicting
paper scores, indicating the potential of LLMs to effectively assist
expert-level research evaluation. In research, the papers generated by the
CycleResearcher model achieved a score of 5.36 in simulated peer reviews,
showing some competitiveness in terms of simulated review scores compared to
the preprint level of 5.24 from human experts, while still having room for
improvement compared to the accepted paper level of 5.69. This work represents
a significant step toward fully automated scientific inquiry, providing ethical
safeguards and exploring AI-driven research capabilities. The code, dataset and
model weight are released at https://wengsyx.github.io/Researcher/.",2024-10-28,"Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, Linyi Yang",http://arxiv.org/pdf/2411.00816v3,cs.CL
The Zeno's Paradox of `Low-Resource' Languages,"The disparity in the languages commonly studied in Natural Language
Processing (NLP) is typically reflected by referring to languages as low vs
high-resourced. However, there is limited consensus on what exactly qualifies
as a `low-resource language.' To understand how NLP papers define and study
`low resource' languages, we qualitatively analyzed 150 papers from the ACL
Anthology and popular speech-processing conferences that mention the keyword
`low-resource.' Based on our analysis, we show how several interacting axes
contribute to `low-resourcedness' of a language and why that makes it difficult
to track progress for each individual language. We hope our work (1) elicits
explicit definitions of the terminology when it is used in papers and (2)
provides grounding for the different axes to consider when connoting a language
as low-resource.",2024-10-28,"Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Benjamin Rosman, Thamar Solorio, Monojit Choudhury",http://arxiv.org/pdf/2410.20817v1,cs.CL
NewTerm: Benchmarking Real-Time New Terms for Large Language Models with Annual Updates,"Despite their remarkable abilities in various tasks, large language models
(LLMs) still struggle with real-time information (e.g., new facts and terms)
due to the knowledge cutoff in their development process. However, existing
benchmarks focus on outdated content and limited fields, facing difficulties in
real-time updating and leaving new terms unexplored. To address this problem,
we propose an adaptive benchmark, NewTerm, for real-time evaluation of new
terms. We design a highly automated construction method to ensure high-quality
benchmark construction with minimal human effort, allowing flexible updates for
real-time information. Empirical results on various LLMs demonstrate over 20%
performance reduction caused by new terms. Additionally, while updates to the
knowledge cutoff of LLMs can cover some of the new terms, they are unable to
generalize to more distant new terms. We also analyze which types of terms are
more challenging and why LLMs struggle with new terms, paving the way for
future research. Finally, we construct NewTerm 2022 and 2023 to evaluate the
new terms updated each year and will continue updating annually. The benchmark
and codes can be found at https://github.com/hexuandeng/NewTerm.",2024-10-28,"Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Min Zhang, Zhaopeng Tu",http://arxiv.org/pdf/2410.20814v1,cs.CL
Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation,"Deep learning-based expert models have reached superhuman performance in
decision-making domains such as chess and Go. However, it is under-explored to
explain or comment on given decisions although it is important for model
explainability and human education. The outputs of expert models are accurate,
but yet difficult to interpret for humans. On the other hand, large language
models (LLMs) can produce fluent commentary but are prone to hallucinations due
to their limited decision-making capabilities. To bridge this gap between
expert models and LLMs, we focus on chess commentary as a representative task
of explaining complex decision-making processes through language and address
both the generation and evaluation of commentary. We introduce Concept-guided
Chess Commentary generation (CCC) for producing commentary and GPT-based Chess
Commentary Evaluation (GCC-Eval) for assessing it. CCC integrates the
decision-making strengths of expert models with the linguistic fluency of LLMs
through prioritized, concept-based explanations. GCC-Eval leverages expert
knowledge to evaluate chess commentary based on informativeness and linguistic
quality. Experimental results, validated by both human judges and GCC-Eval,
demonstrate that CCC generates commentary which is accurate, informative, and
fluent.",2024-10-28,"Jaechang Kim, Jinmin Goh, Inseok Hwang, Jaewoong Cho, Jungseul Ok",http://arxiv.org/pdf/2410.20811v2,cs.CL
Rephrasing natural text data with different languages and quality levels for Large Language Model pre-training,"Recently published work on rephrasing natural text data for pre-training LLMs
has shown promising results when combining the original dataset with the
synthetically rephrased data. We build upon previous work by replicating
existing results on C4 and extending them with our optimized rephrasing
pipeline to the English, German, Italian, and Spanish Oscar subsets of
CulturaX. Our pipeline leads to increased performance on standard evaluation
benchmarks in both the mono- and multilingual setup. In addition, we provide a
detailed study of our pipeline, investigating the choice of the base dataset
and LLM for the rephrasing, as well as the relationship between the model size
and the performance after pre-training. By exploring data with different
perceived quality levels, we show that gains decrease with higher quality.
Furthermore, we find the difference in performance between model families to be
bigger than between different model sizes. This highlights the necessity for
detailed tests before choosing an LLM to rephrase large amounts of data.
Moreover, we investigate the effect of pre-training with synthetic data on
supervised fine-tuning. Here, we find increasing but inconclusive results that
highly depend on the used benchmark. These results (again) highlight the need
for better benchmarking setups. In summary, we show that rephrasing
multilingual and low-quality data is a very promising direction to extend LLM
pre-training data.",2024-10-28,"Michael Pieler, Marco Bellagente, Hannah Teufel, Duy Phung, Nathan Cooper, Jonathan Tow, Paulo Rocha, Reshinth Adithyan, Zaid Alyafeai, Nikhil Pinnaparaju, Maksym Zhuravinskyi, Carlos Riquelme",http://arxiv.org/pdf/2410.20796v1,cs.CL
Deep Learning for Medical Text Processing: BERT Model Fine-Tuning and Comparative Study,"This paper proposes a medical literature summary generation method based on
the BERT model to address the challenges brought by the current explosion of
medical information. By fine-tuning and optimizing the BERT model, we develop
an efficient summary generation system that can quickly extract key information
from medical literature and generate coherent, accurate summaries. In the
experiment, we compared various models, including Seq-Seq, Attention,
Transformer, and BERT, and demonstrated that the improved BERT model offers
significant advantages in the Rouge and Recall metrics. Furthermore, the
results of this study highlight the potential of knowledge distillation
techniques to further enhance model performance. The system has demonstrated
strong versatility and efficiency in practical applications, offering a
reliable tool for the rapid screening and analysis of medical literature.",2024-10-28,"Jiacheng Hu, Yiru Cang, Guiran Liu, Meiqi Wang, Weijie He, Runyuan Bao",http://arxiv.org/pdf/2410.20792v1,cs.CL
SCULPT: Systematic Tuning of Long Prompts,"Prompt optimization is essential for effective utilization of large language
models (LLMs) across diverse tasks. While existing optimization methods are
effective in optimizing short prompts, they struggle with longer, more complex
ones, often risking information loss and being sensitive to small
perturbations. To address these challenges, we propose SCULPT (Systematic
Tuning of Long Prompts), a framework that treats prompt optimization as a
hierarchical tree refinement problem. SCULPT represents prompts as tree
structures, enabling targeted modifications while preserving contextual
integrity. It employs a Critic-Actor framework that generates reflections and
applies actions to refine the prompt. Evaluations demonstrate SCULPT's
effectiveness on long prompts, its robustness to adversarial perturbations, and
its ability to generate high-performing prompts even without any initial
human-written prompt. Compared to existing state of the art methods, SCULPT
consistently improves LLM performance by preserving essential task information
while applying structured refinements. Both qualitative and quantitative
analyses show that SCULPT produces more stable and interpretable prompt
modifications, ensuring better generalization across tasks.",2024-10-28,"Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta",http://arxiv.org/pdf/2410.20788v2,cs.CL
Graph-based Uncertainty Metrics for Long-form Language Model Outputs,"Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.",2024-10-28,"Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto",http://arxiv.org/pdf/2410.20783v1,cs.CL
Decoding Reading Goals from Eye Movements,"Readers can have different goals with respect to the text that they are
reading. Can these goals be decoded from their eye movements over the text? In
this work, we examine for the first time whether it is possible to distinguish
between two types of common reading goals: information seeking and ordinary
reading for comprehension. Using large-scale eye tracking data, we address this
task with a wide range of models that cover different architectural and data
representation strategies, and further introduce a new model ensemble. We find
that transformer-based models with scanpath representations coupled with
language modeling solve it most successfully, and that accurate predictions can
be made in real time, long before the participant finished reading the text. We
further introduce a new method for model performance analysis based on mixed
effect modeling. Combining this method with rich textual annotations reveals
key properties of textual items and participants that contribute to the
difficulty of the task, and improves our understanding of the variability in
eye movement patterns across the two reading regimes.",2024-10-28,"Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak",http://arxiv.org/pdf/2410.20779v3,cs.CL
KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation,"Large language models (LLMs) have demonstrated remarkable performance across
various downstream tasks. However, the high computational and memory
requirements of LLMs are a major bottleneck. To address this,
parameter-efficient fine-tuning (PEFT) methods such as low-rank adaptation
(LoRA) have been proposed to reduce computational costs while ensuring minimal
loss in performance. Additionally, knowledge distillation (KD) has been a
popular choice for obtaining compact student models from teacher models. In
this work, we present KD-LoRA, a novel fine-tuning method that combines LoRA
with KD. Our results demonstrate that KD-LoRA achieves performance comparable
to full fine-tuning (FFT) and LoRA while significantly reducing resource
requirements. Specifically, KD-LoRA retains 98% of LoRA's performance on the
GLUE benchmark, while being 40% more compact. Additionally, KD-LoRA reduces GPU
memory usage by 30% compared to LoRA, while decreasing inference time by 30%
compared to both FFT and LoRA. We evaluate KD-LoRA across three encoder-only
models: BERT, RoBERTa, and DeBERTaV3. Code is available at
https://github.com/rambodazimi/KD-LoRA.",2024-10-28,"Rambod Azimi, Rishav Rishav, Marek Teichmann, Samira Ebrahimi Kahou",http://arxiv.org/pdf/2410.20777v1,cs.CL
Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation,"In line with the principle of honesty, there has been a growing effort to
train large language models (LLMs) to generate outputs containing epistemic
markers. However, evaluation in the presence of epistemic markers has been
largely overlooked, raising a critical question: Could the use of epistemic
markers in LLM-generated outputs lead to unintended negative consequences? To
address this, we present EMBER, a benchmark designed to assess the robustness
of LLM-judges to epistemic markers in both single and pairwise evaluation
settings. Our findings, based on evaluations using EMBER, reveal that all
tested LLM-judges, including GPT-4o, show a notable lack of robustness in the
presence of epistemic markers. Specifically, we observe a negative bias toward
epistemic markers, with a stronger bias against markers expressing uncertainty.
This suggests that LLM-judges are influenced by the presence of these markers
and do not focus solely on the correctness of the content.",2024-10-28,"Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung",http://arxiv.org/pdf/2410.20774v2,cs.CL
MrT5: Dynamic Token Merging for Efficient Byte-level Language Models,"Models that rely on subword tokenization have significant drawbacks, such as
sensitivity to character-level noise like spelling errors and inconsistent
compression rates across different languages and scripts. While character- or
byte-level models like ByT5 attempt to address these concerns, they have not
gained widespread adoption -- processing raw byte streams without tokenization
results in significantly longer sequence lengths, making training and inference
inefficient. This work introduces MrT5 (MergeT5), a more efficient variant of
ByT5 that integrates a token deletion mechanism in its encoder to dynamically
shorten the input sequence length. After processing through a fixed number of
encoder layers, a learned delete gate determines which tokens are to be removed
and which are to be retained for subsequent layers. MrT5 effectively ""merges""
critical information from deleted tokens into a more compact sequence,
leveraging contextual information from the remaining tokens. In continued
pre-training experiments, we find that MrT5 can achieve significant gains in
inference runtime with minimal effect on performance, as measured by
bits-per-byte. Additionally, with multilingual training, MrT5 adapts to the
orthographic characteristics of each language, learning language-specific
compression rates. Furthermore, MrT5 shows comparable accuracy to ByT5 on
downstream evaluations such as XNLI, TyDi QA, and character-level tasks while
reducing sequence lengths by up to 75%. Our approach presents a solution to the
practical limitations of existing byte-level models.",2024-10-28,"Julie Kallini, Shikhar Murty, Christopher D. Manning, Christopher Potts, Róbert Csordás",http://arxiv.org/pdf/2410.20771v3,cs.CL
A Static and Dynamic Attention Framework for Multi Turn Dialogue Generation,"Recently, research on open domain dialogue systems have attracted extensive
interests of academic and industrial researchers. The goal of an open domain
dialogue system is to imitate humans in conversations. Previous works on single
turn conversation generation have greatly promoted the research of open domain
dialogue systems. However, understanding multiple single turn conversations is
not equal to the understanding of multi turn dialogue due to the coherent and
context dependent properties of human dialogue. Therefore, in open domain multi
turn dialogue generation, it is essential to modeling the contextual semantics
of the dialogue history, rather than only according to the last utterance.
Previous research had verified the effectiveness of the hierarchical recurrent
encoder-decoder framework on open domain multi turn dialogue generation.
However, using RNN-based model to hierarchically encoding the utterances to
obtain the representation of dialogue history still face the problem of a
vanishing gradient. To address this issue, in this paper, we proposed a static
and dynamic attention-based approach to model the dialogue history and then
generate open domain multi turn dialogue responses. Experimental results on
Ubuntu and Opensubtitles datasets verify the effectiveness of the proposed
static and dynamic attention-based approach on automatic and human evaluation
metrics in various experimental settings. Meanwhile, we also empirically verify
the performance of combining the static and dynamic attentions on open domain
multi turn dialogue generation.",2024-10-28,"Wei-Nan Zhang, Yiming Cui, Kaiyan Zhang, Yifa Wang, Qingfu Zhu, Lingzhi Li, Ting Liu",http://arxiv.org/pdf/2410.20766v1,cs.CL
Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts,"One useful application of NLP models is to support people in reading complex
text from unfamiliar domains (e.g., scientific articles). Simplifying the
entire text makes it understandable but sometimes removes important details. On
the contrary, helping adult readers understand difficult concepts in context
can enhance their vocabulary and knowledge. In a preliminary human study, we
first identify that lack of context and unfamiliarity with difficult concepts
is a major reason for adult readers' difficulty with domain-specific text. We
then introduce ""targeted concept simplification,"" a simplification task for
rewriting text to help readers comprehend text containing unfamiliar concepts.
We also introduce WikiDomains, a new dataset of 22k definitions from 13
academic domains paired with a difficult concept within each definition. We
benchmark the performance of open-source and commercial LLMs and a simple
dictionary baseline on this task across human judgments of ease of
understanding and meaning preservation. Interestingly, our human judges
preferred explanations about the difficult concept more than simplification of
the concept phrase. Further, no single model achieved superior performance
across all quality dimensions, and automated metrics also show low correlations
with human evaluations of concept simplification ($\sim0.2$), opening up rich
avenues for research on personalized human reading comprehension support.",2024-10-28,"Sumit Asthana, Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata",http://arxiv.org/pdf/2410.20763v2,cs.CL
Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation,"We introduce Plan*RAG, a novel framework that enables structured multi-hop
reasoning in retrieval-augmented generation (RAG) through test-time reasoning
plan generation. While existing approaches such as ReAct maintain reasoning
chains within the language model's context window, we observe that this often
leads to plan fragmentation and execution failures. Our key insight is that by
isolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's
working memory, we can enable (1) systematic exploration of reasoning paths,
(2) atomic subqueries enabling precise retrievals and grounding, and (3)
efficiency through parallel execution and bounded context window utilization.
Moreover, Plan*RAG's modular design allows it to be integrated with existing
RAG methods, thus providing a practical solution to improve current RAG
systems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently
achieves improvements over recently proposed methods such as RQ-RAG and
Self-RAG, while maintaining comparable computational costs.",2024-10-28,"Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma",http://arxiv.org/pdf/2410.20753v2,cs.CL
Matryoshka: Learning to Drive Black-Box LLMs with LLMs,"Despite the impressive generative abilities of black-box large language
models (LLMs), their inherent opacity hinders further advancements in
capabilities such as reasoning, planning, and personalization. Existing works
aim to enhance LLM capabilities via domain-specific adaptation or in-context
learning, which require additional training on accessible model parameters, an
infeasible option for black-box LLMs. To address this challenge, we introduce
Matryoshika, a lightweight white-box LLM controller that guides a large-scale
black-box LLM generator by decomposing complex tasks into a series of
intermediate outputs. Specifically, we consider the black-box LLM as an
environment, with Matryoshika serving as a policy to provide intermediate
guidance through prompts for driving the black-box LLM. Matryoshika is trained
to pivot the outputs of the black-box LLM aligning with preferences during
iterative interaction, which enables controllable multi-turn generation and
self-improvement in optimizing intermediate guidance. Empirical evaluations on
three diverse tasks demonstrate that Matryoshika effectively enhances the
capabilities of black-box LLMs in complex, long-horizon tasks, including
reasoning, planning, and personalization. By leveraging this pioneering
controller-generator framework to mitigate dependence on model parameters,
Matryoshika provides a transparent and practical solution for improving
black-box LLMs through controllable multi-turn generation using white-box LLMs.",2024-10-28,"Changhao Li, Yuchen Zhuang, Rushi Qiang, Haotian Sun, Hanjun Dai, Chao Zhang, Bo Dai",http://arxiv.org/pdf/2410.20749v1,cs.CL
ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents,"The massive population election simulation aims to model the preferences of
specific groups in particular election scenarios. It has garnered significant
attention for its potential to forecast real-world social trends. Traditional
agent-based modeling (ABM) methods are constrained by their ability to
incorporate complex individual background information and provide interactive
prediction results. In this paper, we introduce ElectionSim, an innovative
election simulation framework based on large language models, designed to
support accurate voter simulations and customized distributions, together with
an interactive platform to dialogue with simulated voters. We present a
million-level voter pool sampled from social media platforms to support
accurate individual simulation. We also introduce PPE, a poll-based
presidential election benchmark to assess the performance of our framework
under the U.S. presidential election scenario. Through extensive experiments
and analyses, we demonstrate the effectiveness and robustness of our framework
in U.S. presidential election simulations.",2024-10-28,"Xinnong Zhang, Jiayu Lin, Libo Sun, Weihong Qi, Yihang Yang, Yue Chen, Hanjia Lyu, Xinyi Mou, Siming Chen, Jiebo Luo, Xuanjing Huang, Shiping Tang, Zhongyu Wei",http://arxiv.org/pdf/2410.20746v3,cs.CL
Gender Bias in LLM-generated Interview Responses,"LLMs have emerged as a promising tool for assisting individuals in diverse
text-generation tasks, including job-related texts. However, LLM-generated
answers have been increasingly found to exhibit gender bias. This study
evaluates three LLMs (GPT-3.5, GPT-4, Claude) to conduct a multifaceted audit
of LLM-generated interview responses across models, question types, and jobs,
and their alignment with two gender stereotypes. Our findings reveal that
gender bias is consistent, and closely aligned with gender stereotypes and the
dominance of jobs. Overall, this study contributes to the systematic
examination of gender bias in LLM-generated interview responses, highlighting
the need for a mindful approach to mitigate such biases in related
applications.",2024-10-28,"Haein Kong, Yongsu Ahn, Sangyub Lee, Yunho Maeng",http://arxiv.org/pdf/2410.20739v3,cs.CL
SEG:Seeds-Enhanced Iterative Refinement Graph Neural Network for Entity Alignment,"Entity alignment is crucial for merging knowledge across knowledge graphs, as
it matches entities with identical semantics. The standard method matches these
entities based on their embedding similarities using semi-supervised learning.
However, diverse data sources lead to non-isomorphic neighborhood structures
for aligned entities, complicating alignment, especially for less common and
sparsely connected entities. This paper presents a soft label propagation
framework that integrates multi-source data and iterative seed enhancement,
addressing scalability challenges in handling extensive datasets where scale
computing excels. The framework uses seeds for anchoring and selects optimal
relationship pairs to create soft labels rich in neighborhood features and
semantic relationship data. A bidirectional weighted joint loss function is
implemented, which reduces the distance between positive samples and
differentially processes negative samples, taking into account the
non-isomorphic neighborhood structures. Our method outperforms existing
semi-supervised approaches, as evidenced by superior results on multiple
datasets, significantly improving the quality of entity alignment.",2024-10-28,"Wei Ai, Yinghui Gao, Jianbin Li, Jiayi Du, Tao Meng, Yuntao Shou, Keqin Li",http://arxiv.org/pdf/2410.20733v1,cs.CL
Simple Is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation,"Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.",2024-10-28,"Mufei Li, Siqi Miao, Pan Li",http://arxiv.org/pdf/2410.20724v4,cs.CL
Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models,"Although pre-trained language models show good performance on various natural
language processing tasks, they often rely on non-causal features and patterns
to determine the outcome. For natural language inference tasks, previous
results have shown that even a model trained on a large number of data fails to
perform well on counterfactually revised data, indicating that the model is not
robustly learning the semantics of the classes. In this paper, we propose a
method in which we use token-based and sentence-based augmentation methods to
generate counterfactual sentence pairs that belong to each class, and apply
contrastive learning to help the model learn the difference between sentence
pairs of different classes with similar contexts. Evaluation results with
counterfactually-revised dataset and general NLI datasets show that the
proposed method can improve the performance and robustness of the NLI model.",2024-10-28,"Heerin Yang, Sseung-won Hwang, Jungmin So",http://arxiv.org/pdf/2410.20710v1,cs.CL
Combining Domain-Specific Models and LLMs for Automated Disease Phenotyping from Survey Data,"This exploratory pilot study investigated the potential of combining a
domain-specific model, BERN2, with large language models (LLMs) to enhance
automated disease phenotyping from research survey data. Motivated by the need
for efficient and accurate methods to harmonize the growing volume of survey
data with standardized disease ontologies, we employed BERN2, a biomedical
named entity recognition and normalization model, to extract disease
information from the ORIGINS birth cohort survey data. After rigorously
evaluating BERN2's performance against a manually curated ground truth dataset,
we integrated various LLMs using prompt engineering, Retrieval-Augmented
Generation (RAG), and Instructional Fine-Tuning (IFT) to refine the model's
outputs. BERN2 demonstrated high performance in extracting and normalizing
disease mentions, and the integration of LLMs, particularly with Few Shot
Inference and RAG orchestration, further improved accuracy. This approach,
especially when incorporating structured examples, logical reasoning prompts,
and detailed context, offers a promising avenue for developing tools to enable
efficient cohort profiling and data harmonization across large, heterogeneous
research datasets.",2024-10-28,"Gal Beeri, Benoit Chamot, Elena Latchem, Shruthi Venkatesh, Sarah Whalan, Van Zyl Kruger, David Martino",http://arxiv.org/pdf/2410.20695v2,cs.CL
SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script,"Shared memories between two individuals strengthen their bond and are crucial
for facilitating their ongoing conversations. This study aims to make long-term
dialogue more engaging by leveraging these shared memories. To this end, we
introduce a new long-term dialogue dataset named SHARE, constructed from movie
scripts, which are a rich source of shared memories among various
relationships. Our dialogue dataset contains the summaries of persona
information and events of two individuals, as explicitly revealed in their
conversation, along with implicitly extractable shared memories. We also
introduce EPISODE, a long-term dialogue framework based on SHARE that utilizes
shared experiences between individuals. Through experiments using SHARE, we
demonstrate that shared memories between two individuals make long-term
dialogues more engaging and sustainable, and that EPISODE effectively manages
shared memories during dialogue. Our new dataset is publicly available at
https://anonymous.4open.science/r/SHARE-AA1E/SHARE.json.",2024-10-28,"Eunwon Kim, Chanho Park, Buru Chang",http://arxiv.org/pdf/2410.20682v1,cs.CL
Relaxed Recursive Transformers: Effective Parameter Sharing with Layer-wise LoRA,"Large language models (LLMs) are expensive to deploy. Parameter sharing
offers a possible path towards reducing their size and cost, but its
effectiveness in modern LLMs remains fairly limited. In this work, we revisit
""layer tying"" as form of parameter sharing in Transformers, and introduce novel
methods for converting existing LLMs into smaller ""Recursive Transformers"" that
share parameters across layers, with minimal loss of performance. Here, our
Recursive Transformers are efficiently initialized from standard pretrained
Transformers, but only use a single block of unique layers that is then
repeated multiple times in a loop. We further improve performance by
introducing Relaxed Recursive Transformers that add flexibility to the layer
tying constraint via depth-wise low-rank adaptation (LoRA) modules, yet still
preserve the compactness of the overall model. We show that our recursive
models (e.g., recursive Gemma 1B) outperform both similar-sized vanilla
pretrained models (such as TinyLlama 1.1B and Pythia 1B) and knowledge
distillation baselines -- and can even recover most of the performance of the
original ""full-size"" model (e.g., Gemma 2B with no shared parameters). Finally,
we propose Continuous Depth-wise Batching, a promising new inference paradigm
enabled by the Recursive Transformer when paired with early exiting. In a
theoretical analysis, we show that this has the potential to lead to
significant (2-3x) gains in inference throughput.",2024-10-28,"Sangmin Bae, Adam Fisch, Hrayr Harutyunyan, Ziwei Ji, Seungyeon Kim, Tal Schuster",http://arxiv.org/pdf/2410.20672v3,cs.CL
Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments,"Navigation presents a significant challenge for persons with visual
impairments (PVI). While traditional aids such as white canes and guide dogs
are invaluable, they fall short in delivering detailed spatial information and
precise guidance to desired locations. Recent developments in large language
models (LLMs) and vision-language models (VLMs) offer new avenues for enhancing
assistive navigation. In this paper, we introduce Guide-LLM, an embodied
LLM-based agent designed to assist PVI in navigating large indoor environments.
Our approach features a novel text-based topological map that enables the LLM
to plan global paths using a simplified environmental representation, focusing
on straight paths and right-angle turns to facilitate navigation. Additionally,
we utilize the LLM's commonsense reasoning for hazard detection and
personalized path planning based on user preferences. Simulated experiments
demonstrate the system's efficacy in guiding PVI, underscoring its potential as
a significant advancement in assistive technology. The results highlight
Guide-LLM's ability to offer efficient, adaptive, and personalized navigation
assistance, pointing to promising advancements in this field.",2024-10-28,"Sangmim Song, Sarath Kodagoda, Amal Gunatilake, Marc G. Carmichael, Karthick Thiyagarajan, Jodi Martin",http://arxiv.org/pdf/2410.20666v2,cs.CL
Visualizing attention zones in machine reading comprehension models,"The attention mechanism plays an important role in the machine reading
comprehension (MRC) model. Here, we describe a pipeline for building an MRC
model with a pretrained language model and visualizing the effect of each
attention zone in different layers, which can indicate the explainability of
the model. With the presented protocol and accompanying code, researchers can
easily visualize the relevance of each attention zone in the MRC model. This
approach can be generalized to other pretrained language models.",2024-10-28,"Yiming Cui, Wei-Nan Zhang, Ting Liu",http://arxiv.org/pdf/2410.20652v1,cs.CL
SubjECTive-QA: Measuring Subjectivity in Earnings Call Transcripts' QA Through Six-Dimensional Feature Analysis,"Fact-checking is extensively studied in the context of misinformation and
disinformation, addressing objective inaccuracies. However, a softer form of
misinformation involves responses that are factually correct but lack certain
features such as clarity and relevance. This challenge is prevalent in formal
Question-Answer (QA) settings such as press conferences in finance, politics,
sports, and other domains, where subjective answers can obscure transparency.
Despite this, there is a lack of manually annotated datasets for subjective
features across multiple dimensions. To address this gap, we introduce
SubjECTive-QA, a human annotated dataset on Earnings Call Transcripts' (ECTs)
QA sessions as the answers given by company representatives are often open to
subjective interpretations and scrutiny. The dataset includes 49,446
annotations for long-form QA pairs across six features: Assertive, Cautious,
Optimistic, Specific, Clear, and Relevant. These features are carefully
selected to encompass the key attributes that reflect the tone of the answers
provided during QA sessions across different domain. Our findings are that the
best-performing Pre-trained Language Model (PLM), RoBERTa-base, has similar
weighted F1 scores to Llama-3-70b-Chat on features with lower subjectivity,
such as Relevant and Clear, with a mean difference of 2.17% in their weighted
F1 scores. The models perform significantly better on features with higher
subjectivity, such as Specific and Assertive, with a mean difference of 10.01%
in their weighted F1 scores. Furthermore, testing SubjECTive-QA's
generalizability using QAs from White House Press Briefings and Gaggles yields
an average weighted F1 score of 65.97% using our best models for each feature,
demonstrating broader applicability beyond the financial domain. SubjECTive-QA
is publicly available under the CC BY 4.0 license",2024-10-28,"Huzaifa Pardawala, Siddhant Sukhani, Agam Shah, Veer Kejriwal, Abhishek Pillai, Rohan Bhasin, Andrew DiBiasio, Tarun Mandapati, Dhruv Adha, Sudheer Chava",http://arxiv.org/pdf/2410.20651v2,cs.CL
FinTeamExperts: Role Specialized MOEs For Financial Analysis,"Large Language Models (LLMs), such as ChatGPT, Phi3 and Llama-3, are leading
a significant leap in AI, as they can generalize knowledge from their training
to new tasks without fine-tuning. However, their application in the financial
domain remains relatively limited. The financial field is inherently complex,
requiring a deep understanding across various perspectives, from macro, micro
economic trend to quantitative analysis. Motivated by this complexity, a
mixture of expert LLMs tailored to specific financial domains could offer a
more comprehensive understanding for intricate financial tasks. In this paper,
we present the FinTeamExperts, a role-specialized LLM framework structured as a
Mixture of Experts (MOEs) for financial analysis. The framework simulates a
collaborative team setting by training each model to specialize in distinct
roles: Macro Analysts, Micro analysts, and Quantitative Analysts. This
role-specific specialization enhances the model's ability to integrate their
domain-specific expertise. We achieve this by training three 8-billion
parameter models on different corpus, each dedicated to excelling in specific
finance-related roles. We then instruct-tune FinTeamExperts on downstream tasks
to align with practical financial tasks. The experimental results show that
FinTeamExperts outperform all models of the same size and larger on three out
of four datasets. On the fourth dataset, which presents a more complex task,
FinTeamExperts still surpass all models of the same size. This highlights the
success of our role-based specialization approach and the continued training
approach for FinTeamExperts.",2024-10-28,"Yue Yu, Prayag Tiwari",http://arxiv.org/pdf/2410.21338v2,cs.CL
Fine-tuned Large Language Models (LLMs): Improved Prompt Injection Attacks Detection,"Large language models (LLMs) are becoming a popular tool as they have
significantly advanced in their capability to tackle a wide range of
language-based tasks. However, LLMs applications are highly vulnerable to
prompt injection attacks, which poses a critical problem. These attacks target
LLMs applications through using carefully designed input prompts to divert the
model from adhering to original instruction, thereby it could execute
unintended actions. These manipulations pose serious security threats which
potentially results in data leaks, biased outputs, or harmful responses. This
project explores the security vulnerabilities in relation to prompt injection
attacks. To detect whether a prompt is vulnerable or not, we follows two
approaches: 1) a pre-trained LLM, and 2) a fine-tuned LLM. Then, we conduct a
thorough analysis and comparison of the classification performance. Firstly, we
use pre-trained XLM-RoBERTa model to detect prompt injections using test
dataset without any fine-tuning and evaluate it by zero-shot classification.
Then, this proposed work will apply supervised fine-tuning to this pre-trained
LLM using a task-specific labeled dataset from deepset in huggingface, and this
fine-tuned model achieves impressive results with 99.13\% accuracy, 100\%
precision, 98.33\% recall and 99.15\% F1-score thorough rigorous
experimentation and evaluation. We observe that our approach is highly
efficient in detecting prompt injection attacks.",2024-10-28,"Md Abdur Rahman, Fan Wu, Alfredo Cuzzocrea, Sheikh Iqbal Ahamed",http://arxiv.org/pdf/2410.21337v2,cs.CL
LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization,"Low-rank adaption (LoRA) is a widely used parameter-efficient finetuning
method for LLM that reduces memory requirements. However, current LoRA
optimizers lack transformation invariance, meaning the actual updates to the
weights depends on how the two LoRA factors are scaled or rotated. This
deficiency leads to inefficient learning and sub-optimal solutions in practice.
This paper introduces LoRA-RITE, a novel adaptive matrix preconditioning method
for LoRA optimization, which can achieve transformation invariance and remain
computationally efficient. We provide theoretical analysis to demonstrate the
benefit of our method and conduct experiments on various LLM tasks with
different models including Gemma 2B, 7B, and mT5-XXL. The results demonstrate
consistent improvements against existing optimizers. For example, replacing
Adam with LoRA-RITE during LoRA fine-tuning of Gemma-2B yielded 4.6\% accuracy
gain on Super-Natural Instructions and 3.5\% accuracy gain across other four
LLM benchmarks (HellaSwag, ArcChallenge, GSM8K, OpenBookQA).",2024-10-27,"Jui-Nan Yen, Si Si, Zhao Meng, Felix Yu, Sai Surya Duvvuri, Inderjit S. Dhillon, Cho-Jui Hsieh, Sanjiv Kumar",http://arxiv.org/pdf/2410.20625v1,cs.CL
Towards an LLM-Based Speech Interface for Robot-Assisted Feeding,"Physically assistive robots present an opportunity to significantly increase
the well-being and independence of individuals with motor impairments or other
forms of disability who are unable to complete activities of daily living
(ADLs). Speech interfaces, especially ones that utilize Large Language Models
(LLMs), can enable individuals to effectively and naturally communicate
high-level commands and nuanced preferences to robots. In this work, we
demonstrate an LLM-based speech interface for a commercially available
assistive feeding robot. Our system is based on an iteratively designed
framework, from the paper ""VoicePilot: Harnessing LLMs as Speech Interfaces for
Physically Assistive Robots,"" that incorporates human-centric elements for
integrating LLMs as interfaces for robots. It has been evaluated through a user
study with 11 older adults at an independent living facility. Videos are
located on our project website:
https://sites.google.com/andrew.cmu.edu/voicepilot/.",2024-10-27,"Jessie Yuan, Janavi Gupta, Akhil Padmanabha, Zulekha Karachiwalla, Carmel Majidi, Henny Admoni, Zackory Erickson",http://arxiv.org/pdf/2410.20624v1,cs.CL
Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse,"Chain-of-thought (CoT) prompting has become a widely used strategy for
working with large language and multimodal models. While CoT has been shown to
improve performance across many tasks, determining the settings in which it is
effective remains an ongoing effort. In particular, it is still an open
question in what settings CoT systematically reduces model performance. In this
paper, we seek to identify the characteristics of tasks where CoT reduces
performance by drawing inspiration from cognitive psychology, looking at cases
where (i) verbal thinking or deliberation hurts performance in humans, and (ii)
the constraints governing human performance generalize to language models.
Three such cases are implicit statistical learning, visual recognition, and
classifying with patterns containing exceptions. In extensive experiments
across all three settings, we find that a diverse collection of
state-of-the-art models exhibit significant drop-offs in performance (e.g., up
to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using
inference-time reasoning compared to zero-shot counterparts. We also identify
three tasks that satisfy condition (i) but not (ii), and find that while verbal
thinking reduces human performance in these tasks, CoT retains or increases
model performance. Overall, our results show that while there is not an exact
parallel between the cognitive processes of models and those of humans,
considering cases where thinking has negative consequences for human
performance can help us identify settings where it negatively impacts models.
By connecting the literature on human deliberation with evaluations of CoT, we
offer a new tool that can be used in understanding the impact of prompt choices
and inference-time reasoning.",2024-10-27,"Ryan Liu, Jiayi Geng, Addison J. Wu, Ilia Sucholutsky, Tania Lombrozo, Thomas L. Griffiths",http://arxiv.org/pdf/2410.21333v3,cs.CL
"Building, Reusing, and Generalizing Abstract Representations from Concrete Sequences","Humans excel at learning abstract patterns across different sequences,
filtering out irrelevant details, and transferring these generalized concepts
to new sequences. In contrast, many sequence learning models lack the ability
to abstract, which leads to memory inefficiency and poor transfer. We introduce
a non-parametric hierarchical variable learning model (HVM) that learns chunks
from sequences and abstracts contextually similar chunks as variables. HVM
efficiently organizes memory while uncovering abstractions, leading to compact
sequence representations. When learning on language datasets such as babyLM,
HVM learns a more efficient dictionary than standard compression algorithms
such as Lempel-Ziv. In a sequence recall task requiring the acquisition and
transfer of variables embedded in sequences, we demonstrate HVM's sequence
likelihood correlates with human recall times. In contrast, large language
models (LLMs) struggle to transfer abstract variables as effectively as humans.
From HVM's adjustable layer of abstraction, we demonstrate that the model
realizes a precise trade-off between compression and generalization. Our work
offers a cognitive model that captures the learning and transfer of abstract
representations in human cognition and differentiates itself from the behavior
of large language models.",2024-10-27,"Shuchen Wu, Mirko Thalmann, Peter Dayan, Zeynep Akata, Eric Schulz",http://arxiv.org/pdf/2410.21332v1,cs.CL
Guiding Through Complexity: What Makes Good Supervision for Hard Math Reasoning Tasks?,"How can ""weak teacher models"" such as average human annotators or existing AI
systems, effectively supervise LLMs to improve performance on hard reasoning
tasks, especially those that challenge and requires expertise or daily practice
from the teacher models? In this paper, we seek for empirical answers to this
question by investigating various data-driven strategies that offer supervision
data at different quality levels upon tasks of varying complexity. Two
intuitive strategies emerge for teacher models to provide supervision during
alignment training: 1) using lower-quality supervision from complete tasks that
match the difficulty of the target reasoning tasks, and 2) leveraging
higher-quality supervision from easier subtasks that are less challenging.
Interestingly, we find that even when the outcome error rate for hard task
supervision is high (e.g., 90\%), training on such data can outperform
perfectly correct supervision of easier subtasks on multiple hard math
benchmarks. We further identify a more critical factor influencing training
performance: step-wise error rates, which indicate the severity of errors in
solutions. Specifically, training on hard task supervision with the same
outcome error rates but disparate step-wise error rates can lead to a 30\%
accuracy gap on MATH benchmark. Our results also reveal that supplementing hard
task supervision with the corresponding subtask supervision can yield notable
performance improvements than simply combining rephrased hard full task
supervision, suggesting new avenues for data augmentation. Data and code are
released at https://github.com/hexuan21/Weak-to-Strong.",2024-10-27,"Xuan He, Da Yin, Nanyun Peng",http://arxiv.org/pdf/2410.20533v3,cs.CL
Llama Scope: Extracting Millions of Features from Llama-3.1-8B with Sparse Autoencoders,"Sparse Autoencoders (SAEs) have emerged as a powerful unsupervised method for
extracting sparse representations from language models, yet scalable training
remains a significant challenge. We introduce a suite of 256 SAEs, trained on
each layer and sublayer of the Llama-3.1-8B-Base model, with 32K and 128K
features. Modifications to a state-of-the-art SAE variant, Top-K SAEs, are
evaluated across multiple dimensions. In particular, we assess the
generalizability of SAEs trained on base models to longer contexts and
fine-tuned models. Additionally, we analyze the geometry of learned SAE
latents, confirming that \emph{feature splitting} enables the discovery of new
features. The Llama Scope SAE checkpoints are publicly available
at~\url{https://huggingface.co/fnlp/Llama-Scope}, alongside our scalable
training, interpretation, and visualization tools at
\url{https://github.com/OpenMOSS/Language-Model-SAEs}. These contributions aim
to advance the open-source Sparse Autoencoder ecosystem and support mechanistic
interpretability research by reducing the need for redundant SAE training.",2024-10-27,"Zhengfu He, Wentao Shu, Xuyang Ge, Lingjie Chen, Junxuan Wang, Yunhua Zhou, Frances Liu, Qipeng Guo, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang, Xipeng Qiu",http://arxiv.org/pdf/2410.20526v1,cs.CL
Self-correction is Not An Innate Capability in Large Language Models: A Case Study of Moral Self-correction,"Though there has been intensive attention to the self-correction capability
of Large Language Models (LLMs), conclusions regarding its effectiveness remain
varied. In this paper, we investigate a fundamental question: is moral
self-correction an innate capability in LLMs? To explore this, we conduct (1) a
mechanistic analysis of how key components of self-correction, such as
Chain-of-Thought (CoT) reasoning and external feedback, interact to enable
moral self-correction; and (2) a behavioral analysis of LLMs' ability to
distinguish between desired and undesired outputs, introducing a
self-distinguish framework. Our mechanistic analysis reveals that LLMs struggle
to effectively leverage helpful feedback, and conflicts can arise between
feedback and CoT reasoning. These limitations suggest that LLMs fail to
identify useful contextual information, instead prioritizing their own internal
knowledge. Additionally, our behavioral analysis indicates that LLMs struggle
to differentiate among their own outputs. Based on these empirical findings
across two analytical dimensions, mechanism and behavior, we argue that moral
self-correction is not an innate capability of LLMs.",2024-10-27,"Guangliang Liu, Zimo Qi, Xitong Zhang, Lu Cheng, Kristen Marie Johnson",http://arxiv.org/pdf/2410.20513v5,cs.CL
LLM Robustness Against Misinformation in Biomedical Question Answering,"The retrieval-augmented generation (RAG) approach is used to reduce the
confabulation of large language models (LLMs) for question answering by
retrieving and providing additional context coming from external knowledge
sources (e.g., by adding the context to the prompt). However, injecting
incorrect information can mislead the LLM to generate an incorrect answer.
  In this paper, we evaluate the effectiveness and robustness of four LLMs
against misinformation - Gemma 2, GPT-4o-mini, Llama~3.1, and Mixtral - in
answering biomedical questions. We assess the answer accuracy on yes-no and
free-form questions in three scenarios: vanilla LLM answers (no context is
provided), ""perfect"" augmented generation (correct context is provided), and
prompt-injection attacks (incorrect context is provided). Our results show that
Llama 3.1 (70B parameters) achieves the highest accuracy in both vanilla
(0.651) and ""perfect"" RAG (0.802) scenarios. However, the accuracy gap between
the models almost disappears with ""perfect"" RAG, suggesting its potential to
mitigate the LLM's size-related effectiveness differences.
  We further evaluate the ability of the LLMs to generate malicious context on
one hand and the LLM's robustness against prompt-injection attacks on the other
hand, using metrics such as attack success rate (ASR), accuracy under attack,
and accuracy drop. As adversaries, we use the same four LLMs (Gemma 2,
GPT-4o-mini, Llama 3.1, and Mixtral) to generate incorrect context that is
injected in the target model's prompt. Interestingly, Llama is shown to be the
most effective adversary, causing accuracy drops of up to 0.48 for vanilla
answers and 0.63 for ""perfect"" RAG across target models. Our analysis reveals
that robustness rankings vary depending on the evaluation measure, highlighting
the complexity of assessing LLM resilience to adversarial attacks.",2024-10-27,"Alexander Bondarenko, Adrian Viehweger",http://arxiv.org/pdf/2410.21330v1,cs.CL
MatViX: Multimodal Information Extraction from Visually Rich Articles,"Multimodal information extraction (MIE) is crucial for scientific literature,
where valuable data is often spread across text, figures, and tables. In
materials science, extracting structured information from research articles can
accelerate the discovery of new materials. However, the multimodal nature and
complex interconnections of scientific content present challenges for
traditional text-based methods. We introduce \textsc{MatViX}, a benchmark
consisting of $324$ full-length research articles and $1,688$ complex
structured JSON files, carefully curated by domain experts. These JSON files
are extracted from text, tables, and figures in full-length documents,
providing a comprehensive challenge for MIE. We introduce an evaluation method
to assess the accuracy of curve similarity and the alignment of hierarchical
structures. Additionally, we benchmark vision-language models (VLMs) in a
zero-shot manner, capable of processing long contexts and multimodal inputs,
and show that using a specialized model (DePlot) can improve performance in
extracting curves. Our results demonstrate significant room for improvement in
current models. Our dataset and evaluation code are
available\footnote{\url{https://matvix-bench.github.io/}}.",2024-10-27,"Ghazal Khalighinejad, Sharon Scott, Ollie Liu, Kelly L. Anderson, Rickard Stureborg, Aman Tyagi, Bhuwan Dhingra",http://arxiv.org/pdf/2410.20494v1,cs.CL
$\textit{Who Speaks Matters}$: Analysing the Influence of the Speaker's Ethnicity on Hate Classification,"Large Language Models (LLMs) offer a lucrative promise for scalable content
moderation, including hate speech detection. However, they are also known to be
brittle and biased against marginalised communities and dialects. This requires
their applications to high-stakes tasks like hate speech detection to be
critically scrutinized. In this work, we investigate the robustness of hate
speech classification using LLMs, particularly when explicit and implicit
markers of the speaker's ethnicity are injected into the input. For the
explicit markers, we inject a phrase that mentions the speaker's identity. For
the implicit markers, we inject dialectal features. By analysing how frequently
model outputs flip in the presence of these markers, we reveal varying degrees
of brittleness across 4 popular LLMs and 5 ethnicities. We find that the
presence of implicit dialect markers in inputs causes model outputs to flip
more than the presence of explicit markers. Further, the percentage of flips
varies across ethnicities. Finally, we find that larger models are more robust.
Our findings indicate the need for exercising caution in deploying LLMs for
high-stakes tasks like hate speech detection.",2024-10-27,"Ananya Malik, Kartik Sharma, Lynnette Hui Xian Ng, Shaily Bhatt",http://arxiv.org/pdf/2410.20490v1,cs.CL
FIRP: Faster LLM inference via future intermediate representation prediction,"Recent advancements in Large Language Models (LLMs) have shown remarkable
performance across a wide range of tasks. Despite this, the auto-regressive
nature of LLM decoding, which generates only a single token per forward
propagation, fails to fully exploit the parallel computational power of GPUs,
leading to considerable latency. To address this, we introduce a novel
speculative decoding method named FIRP which generates multiple tokens instead
of one at each decoding step. We achieve this by predicting the intermediate
hidden states of future tokens (tokens have not been decoded yet) and then
using these pseudo hidden states to decode future tokens, specifically, these
pseudo hidden states are predicted with simple linear transformation in
intermediate layers of LLMs. Once predicted, they participate in the
computation of all the following layers, thereby assimilating richer semantic
information. As the layers go deeper, the semantic gap between pseudo and real
hidden states is narrowed and it becomes feasible to decode future tokens with
high accuracy. To validate the effectiveness of FIRP, we conduct extensive
experiments, showing a speedup ratio of 1.9x-3x in several models and datasets,
analytical experiments also prove our motivations.",2024-10-27,"Pengfei Wu, Jiahao Liu, Zhuocheng Gong, Qifan Wang, Jinpeng Li, Jingang Wang, Xunliang Cai, Dongyan Zhao",http://arxiv.org/pdf/2410.20488v1,cs.CL
What Factors Affect Multi-Modal In-Context Learning? An In-Depth Exploration,"Recently, rapid advancements in Multi-Modal In-Context Learning (MM-ICL) have
achieved notable success, which is capable of achieving superior performance
across various tasks without requiring additional parameter tuning. However,
the underlying rules for the effectiveness of MM-ICL remain under-explored. To
fill this gap, this work aims to investigate the research question: ""What
factors affect the performance of MM-ICL?'' To this end, we investigate
extensive experiments on the three core steps of MM-ICL including demonstration
retrieval, demonstration ordering, and prompt construction using 6 vision large
language models and 20 strategies. Our findings highlight (1) the necessity of
a multi-modal retriever for demonstration retrieval, (2) the importance of
intra-demonstration ordering over inter-demonstration ordering, and (3) the
enhancement of task comprehension through introductory instructions in prompts.
We hope this study can serve as a foundational guide for optimizing MM-ICL
strategies in future research.",2024-10-27,"Libo Qin, Qiguang Chen, Hao Fei, Zhi Chen, Min Li, Wanxiang Che",http://arxiv.org/pdf/2410.20482v1,cs.CL
Graph Neural Networks on Discriminative Graphs of Words,"In light of the recent success of Graph Neural Networks (GNNs) and their
ability to perform inference on complex data structures, many studies apply
GNNs to the task of text classification. In most previous methods, a
heterogeneous graph, containing both word and document nodes, is constructed
using the entire corpus and a GNN is used to classify document nodes. In this
work, we explore a new Discriminative Graph of Words Graph Neural Network
(DGoW-GNN) approach encapsulating both a novel discriminative graph
construction and model to classify text. In our graph construction, containing
only word nodes and no document nodes, we split the training corpus into
disconnected subgraphs according to their labels and weight edges by the
pointwise mutual information of the represented words. Our graph construction,
for which we provide theoretical motivation, allows us to reformulate the task
of text classification as the task of walk classification. We also propose a
new model for the graph-based classification of text, which combines a GNN and
a sequence model. We evaluate our approach on seven benchmark datasets and find
that it is outperformed by several state-of-the-art baseline models. We analyse
reasons for this performance difference and hypothesise under which conditions
it is likely to change.",2024-10-27,"Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis",http://arxiv.org/pdf/2410.20469v1,cs.CL
A Derivational ChainBank for Modern Standard Arabic,"We introduce the new concept of an Arabic Derivational Chain Bank CHAINBANK
to leverage the relationship between form and meaning in modeling Arabic
derivational morphology. We constructed a knowledge graph network of abstract
patterns and their derivational relations and aligned it with the lemmas of the
CAMELMORPH morphological analyzer database. This process produced chains of
derived words' lemmas linked to their corresponding lemma bases through
derivational relations, encompassing 23,333 derivational connections.",2024-10-27,"Reham Marzouk, Sondos Krouna, Nizar Habash",http://arxiv.org/pdf/2410.20463v2,cs.CL
TrajAgent: An Agent Framework for Unified Trajectory Modelling,"Trajectory modeling, which includes research on trajectory data pattern
mining and future prediction, has widespread applications in areas such as life
services, urban transportation, and public administration. Numerous methods
have been proposed to address specific problems within trajectory modelling.
However, due to the heterogeneity of data and the diversity of trajectory
tasks, achieving unified trajectory modelling remains an important yet
challenging task. In this paper, we propose TrajAgent, a large language
model-based agentic framework, to unify various trajectory modelling tasks. In
TrajAgent, we first develop UniEnv, an execution environment with a unified
data and model interface, to support the execution and training of various
models. Building on UniEnv, we introduce TAgent, an agentic workflow designed
for automatic trajectory modelling across various trajectory tasks.
Specifically, we design AutOpt, a systematic optimization module within TAgent,
to further improve the performance of the integrated model. With diverse
trajectory tasks input in natural language, TrajAgent automatically generates
competitive results via training and executing appropriate models. Extensive
experiments on four tasks using four real-world datasets demonstrate the
effectiveness of TrajAgent in unified trajectory modelling, achieving an
average performance improvement of 15.43% over baseline methods.",2024-10-27,"Yuwei Du, Jie Feng, Jie Zhao, Yong Li",http://arxiv.org/pdf/2410.20445v1,cs.CL
MedGo: A Chinese Medical Large Language Model,"Large models are a hot research topic in the field of artificial
intelligence. Leveraging their generative capabilities has the potential to
enhance the level and quality of medical services. In response to the
limitations of current large language models, which often struggle with
accuracy and have narrow capabilities in medical applications, this paper
presents a Chinese medical large language model, MedGo. MedGo was trained using
a combination of high quality unsupervised medical data, supervised data, and
preference alignment data, aimed at enhancing both its versatility and
precision in medical tasks. The model was evaluated through the public CBLUE
benchmark and a manually constructed dataset ClinicalQA. The results
demonstrate that MedGo achieved promising performance across various Chinese
medical information processing tasks, achieved the first place in the CBLUE
evaluation. Additionally, on our constructed dataset ClinicalQA, MedGo
outperformed its base model Qwen2, highlighting its potential to improve both
automated medical question answering and clinical decision support. These
experimental results demonstrate that MedGo possesses strong information
processing capabilities in the medical field. At present, we have successfully
deployed MedGo at Shanghai East Hospital.",2024-10-27,"Haitao Zhang, Bo An",http://arxiv.org/pdf/2410.20428v1,cs.CL
AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions,"Data science tasks involving tabular data present complex challenges that
require sophisticated problem-solving approaches. We propose AutoKaggle, a
powerful and user-centric framework that assists data scientists in completing
daily data pipelines through a collaborative multi-agent system. AutoKaggle
implements an iterative development process that combines code execution,
debugging, and comprehensive unit testing to ensure code correctness and logic
consistency. The framework offers highly customizable workflows, allowing users
to intervene at each phase, thus integrating automated intelligence with human
expertise. Our universal data science toolkit, comprising validated functions
for data cleaning, feature engineering, and modeling, forms the foundation of
this solution, enhancing productivity by streamlining common tasks. We selected
8 Kaggle competitions to simulate data processing workflows in real-world
application scenarios. Evaluation results demonstrate that AutoKaggle achieves
a validation submission rate of 0.85 and a comprehensive score of 0.82 in
typical data science pipelines, fully proving its effectiveness and
practicality in handling complex data science tasks.",2024-10-27,"Ziming Li, Qianbo Zang, David Ma, Jiawei Guo, Tuney Zheng, Minghao Liu, Xinyao Niu, Yue Wang, Jian Yang, Jiaheng Liu, Wanjun Zhong, Wangchunshu Zhou, Wenhao Huang, Ge Zhang",http://arxiv.org/pdf/2410.20424v3,cs.CL
Open-Vocabulary Object Detection via Language Hierarchy,"Recent studies on generalizable object detection have attracted increasing
attention with additional weak supervision from large-scale datasets with
image-level labels. However, weakly-supervised detection learning often suffers
from image-to-box label mismatch, i.e., image-level labels do not convey
precise object information. We design Language Hierarchical Self-training
(LHST) that introduces language hierarchy into weakly-supervised detector
training for learning more generalizable detectors. LHST expands the
image-level labels with language hierarchy and enables co-regularization
between the expanded labels and self-training. Specifically, the expanded
labels regularize self-training by providing richer supervision and mitigating
the image-to-box label mismatch, while self-training allows assessing and
selecting the expanded labels according to the predicted reliability. In
addition, we design language hierarchical prompt generation that introduces
language hierarchy into prompt generation which helps bridge the vocabulary
gaps between training and testing. Extensive experiments show that the proposed
techniques achieve superior generalization performance consistently across 14
widely studied object detection datasets.",2024-10-27,"Jiaxing Huang, Jingyi Zhang, Kai Jiang, Shijian Lu",http://arxiv.org/pdf/2410.20371v1,cs.CL
Rethinking Data Synthesis: A Teacher Model Training Recipe with Interpretation,"Recent advances in large language model (LLM) training have highlighted the
need for diverse, high-quality instruction data. Recently, many works are
exploring synthetic data generation using LLMs. However, they primarily focus
on prompt engineering with standard supervised instruction-finetuned models,
which contains a fundamental limitation: these models are optimized for general
question-answering/problem-solving rather than data generation. We propose a
paradigm shift named \textbf{NOMAD} by investigating how to specifically train
models for data generation, demonstrating that this task differs significantly
from training a classical LM. We identify two key factors: no-prompt-masked
training and proper training set size selection. Our method, NOMAD, shows
substantial improvements over baselines, achieving >4\% gains in TriviaQA and
>2\% in GSM8K with limited training data. Finally, we offer new insights by
interpreting synthetic data through the lenses of ""relevance"" and ""novelty"".",2024-10-27,"Yifang Chen, David Zhu, Simon Du, Kevin Jamieson, Yang Liu",http://arxiv.org/pdf/2410.20362v2,cs.CL
Historical Test-time Prompt Tuning for Vision Foundation Models,"Test-time prompt tuning, which learns prompts online with unlabelled test
samples during the inference stage, has demonstrated great potential by
learning effective prompts on-the-fly without requiring any task-specific
annotations. However, its performance often degrades clearly along the tuning
process when the prompts are continuously updated with the test data flow, and
the degradation becomes more severe when the domain of test samples changes
continuously. We propose HisTPT, a Historical Test-time Prompt Tuning technique
that memorizes the useful knowledge of the learnt test samples and enables
robust test-time prompt tuning with the memorized knowledge. HisTPT introduces
three types of knowledge banks, namely, local knowledge bank, hard-sample
knowledge bank, and global knowledge bank, each of which works with different
mechanisms for effective knowledge memorization and test-time prompt
optimization. In addition, HisTPT features an adaptive knowledge retrieval
mechanism that regularizes the prediction of each test sample by adaptively
retrieving the memorized knowledge. Extensive experiments show that HisTPT
achieves superior prompt tuning performance consistently while handling
different visual recognition tasks (e.g., image classification, semantic
segmentation, and object detection) and test samples from continuously changing
domains.",2024-10-27,"Jingyi Zhang, Jiaxing Huang, Xiaoqin Zhang, Ling Shao, Shijian Lu",http://arxiv.org/pdf/2410.20346v1,cs.CL
Maintaining Informative Coherence: Migrating Hallucinations in Large Language Models via Absorbing Markov Chains,"Large Language Models (LLMs) are powerful tools for text generation,
translation, and summarization, but they often suffer from
hallucinations-instances where they fail to maintain the fidelity and coherence
of contextual information during decoding, sometimes overlooking critical
details due to their sampling strategies and inherent biases from training data
and fine-tuning discrepancies. These hallucinations can propagate through the
web, affecting the trustworthiness of information disseminated online. To
address this issue, we propose a novel decoding strategy that leverages
absorbing Markov chains to quantify the significance of contextual information
and measure the extent of information loss during generation. By considering
all possible paths from the first to the last token, our approach enhances the
reliability of model outputs without requiring additional training or external
data. Evaluations on datasets including TruthfulQA, FACTOR, and HaluEval
highlight the superior performance of our method in mitigating hallucinations,
underscoring the necessity of ensuring accurate information flow in web-based
applications.",2024-10-27,"Jiemin Wu, Songning Lai, Ruiqiang Xiao, Tianlang Xue, Jiayu Yang, Yutao Yue",http://arxiv.org/pdf/2410.20340v1,cs.CL
Get Large Language Models Ready to Speak: A Late-fusion Approach for Speech Generation,"Large language models (LLMs) have revolutionized natural language processing
(NLP) with impressive performance across various text-based tasks. However, the
extension of text-dominant LLMs to with speech generation tasks remains
under-explored. In this work, we introduce a text-to-speech (TTS) system
powered by a fine-tuned Llama model, named TTS-Llama, that achieves
state-of-the-art speech synthesis performance. Building on TTS-Llama, we
further propose MoLE-Llama, a text-and-speech multimodal LLM developed through
purely late-fusion parameter-efficient fine-tuning (PEFT) and a
mixture-of-expert architecture. Extensive empirical results demonstrate
MoLE-Llama's competitive performance on both text-only question-answering (QA)
and TTS tasks, mitigating catastrophic forgetting issue in either modality.
Finally, we further explore MoLE-Llama in text-in-speech-out QA tasks,
demonstrating its great potential as a multimodal dialog system capable of
speech generation.",2024-10-27,"Maohao Shen, Shun Zhang, Jilong Wu, Zhiping Xiu, Ehab AlBadawy, Yiting Lu, Mike Seltzer, Qing He",http://arxiv.org/pdf/2410.20336v1,cs.CL
Improving Speech-based Emotion Recognition with Contextual Utterance Analysis and LLMs,"Speech Emotion Recognition (SER) focuses on identifying emotional states from
spoken language. The 2024 IEEE SLT-GenSEC Challenge on Post Automatic Speech
Recognition (ASR) Emotion Recognition tasks participants to explore the
capabilities of large language models (LLMs) for emotion recognition using only
text data. We propose a novel approach that first refines all available
transcriptions to ensure data reliability. We then segment each complete
conversation into smaller dialogues and use these dialogues as context to
predict the emotion of the target utterance within the dialogue. Finally, we
investigated different context lengths and prompting techniques to improve
prediction accuracy. Our best submission exceeded the baseline by 20% in
unweighted accuracy, achieving the best performance in the challenge. All our
experiments' codes, prediction results, and log files are publicly available.",2024-10-27,"Enshi Zhang, Christian Poellabauer",http://arxiv.org/pdf/2410.20334v1,cs.CL
Deep Learning Based Dense Retrieval: A Comparative Study,"Dense retrievers have achieved state-of-the-art performance in various
information retrieval tasks, but their robustness against tokenizer poisoning
remains underexplored. In this work, we assess the vulnerability of dense
retrieval systems to poisoned tokenizers by evaluating models such as BERT,
Dense Passage Retrieval (DPR), Contriever, SimCSE, and ANCE. We find that
supervised models like BERT and DPR experience significant performance
degradation when tokenizers are compromised, while unsupervised models like
ANCE show greater resilience. Our experiments reveal that even small
perturbations can severely impact retrieval accuracy, highlighting the need for
robust defenses in critical applications.",2024-10-27,"Ming Zhong, Zhizhi Wu, Nanako Honda",http://arxiv.org/pdf/2410.20315v1,cs.CL
Accelerating Direct Preference Optimization with Prefix Sharing,"Offline paired preference optimization algorithms have become a popular
approach for fine-tuning on preference data, outperforming traditional
supervised fine-tuning in various tasks. However, traditional implementations
often involve redundant computations, especially for tasks with long shared
prompts. We introduce prefix sharing for preference tuning, a novel technique
that processes chosen and rejected responses as one sequence with a shared
prefix. To prevent cross-response contamination, we use a custom block-sparse
attention mask. Our method achieves $1.1$-$1.5\times$ improvement in training
throughput on popular DPO datasets, without any effect on convergence. When
combined with sequence packing, we observe consistent $1.3$-$1.6\times$
speedups, benefiting even datasets with smaller sequence lengths. While we
focus on Direct Preference Optimization (DPO), our approach is applicable to
other paired preference tuning methods. By enhancing computational efficiency,
our work contributes to making preference-based fine-tuning more accessible for
a wider range of applications and model sizes. We open-source our code at
https://github.com/frankxwang/dpo-prefix-sharing.",2024-10-27,"Franklin Wang, Sumanth Hegde",http://arxiv.org/pdf/2410.20305v2,cs.CL
Sequential Large Language Model-Based Hyper-parameter Optimization,"This study introduces SLLMBO, an innovative framework leveraging large
language models (LLMs) for hyperparameter optimization (HPO), incorporating
dynamic search space adaptability, enhanced parameter space exploitation, and a
novel LLM-tree-structured parzen estimator (LLM-TPE) sampler. By addressing
limitations in recent fully LLM-based methods and traditional bayesian
optimization (BO), SLLMBO achieves more robust optimization. This comprehensive
benchmarking evaluates multiple LLMs, including GPT-3.5-Turbo, GPT-4o,
Claude-Sonnet-3.5, and Gemini-1.5-Flash, extending prior work and establishing
SLLMBO as the first framework to benchmark a diverse set of LLMs for HPO. By
integrating LLMs' established strengths in parameter initialization with the
exploitation abilities demonstrated in this study, alongside TPE's exploration
capabilities, the LLM-TPE sampler achieves a balanced exploration-exploitation
trade-off, reduces API costs, and mitigates premature early stoppings for more
effective parameter searches. Across 14 tabular tasks in classification and
regression, the LLM-TPE sampler outperformed fully LLM-based methods and
achieved superior results over BO methods in 9 tasks. Testing early stopping in
budget-constrained scenarios demonstrated competitive performance, indicating
that LLM-based methods generally benefit from extended iterations for optimal
results. This work lays the foundation for future research exploring
open-source LLMs, reproducibility of LLM results in HPO, and benchmarking
SLLMBO on complex datasets, such as image classification, segmentation, and
machine translation.",2024-10-27,"Kanan Mahammadli, Seyda Ertekin",http://arxiv.org/pdf/2410.20302v3,cs.CL
Learning from Response not Preference: A Stackelberg Approach for LLM Detoxification using Non-parallel Data,"Text detoxification, a variant of style transfer tasks, finds useful
applications in online social media. This work presents a fine-tuning method
that only uses non-parallel data to turn large language models (LLM) into a
detoxification rewritter. We model the fine-tuning process as a Stackelberg
game between an LLM (leader) and a toxicity screener (follower), which is a
binary style classifier (toxic or non-toxic). The LLM aims to align its
preference according to the screener and generate paraphases passing the
screening. The primary challenge of non-parallel data fine-tuning is incomplete
preference. In the case of unsuccessful paraphrases, the classifier cannot
establish a preference between the input and paraphrase, as they belong to the
same toxic style. Hence, preference-alignment fine-tuning methods, such as
direct preference optimization (DPO), no longer apply. To address the challenge
of incomplete preference, we propose Stackelberg response optimization (SRO),
adapted from DPO, to enable the LLM to learn from the follower's response. The
gist is that SRO decreases the likelihood of generating the paraphrase if it
fails the follower's screening while performing DPO on the pair of the toxic
input and its paraphrase when the latter passes the screening. Experiments
indicate that the SRO-fine-tunned LLM achieves satisfying performance
comparable to state-of-the-art models regarding style accuracy, content
similarity, and fluency. The overall detoxification performance surpasses other
computing methods and matches the human reference. Additional empirical
evidence suggests that SRO is sensitive to the screener's feedback, and a
slight perturbation leads to a significant performance drop. We release the
code and LLM models at \url{https://github.com/XXXinhong/Detoxification_LLM}.",2024-10-27,"Xinhong Xie, Tao Li, Quanyan Zhu",http://arxiv.org/pdf/2410.20298v1,cs.CL
Fine-Tuning and Evaluating Open-Source Large Language Models for the Army Domain,"In recent years, the widespread adoption of Large Language Models (LLMs) has
sparked interest in their potential for application within the military domain.
However, the current generation of LLMs demonstrate sub-optimal performance on
Army use cases, due to the prevalence of domain-specific vocabulary and jargon.
In order to fully leverage LLMs in-domain, many organizations have turned to
fine-tuning to circumvent the prohibitive costs involved in training new LLMs
from scratch. In light of this trend, we explore the viability of adapting
open-source LLMs for usage in the Army domain in order to address their
existing lack of domain-specificity. Our investigations have resulted in the
creation of three distinct generations of TRACLM, a family of LLMs fine-tuned
by The Research and Analysis Center (TRAC), Army Futures Command (AFC). Through
continuous refinement of our training pipeline, each successive iteration of
TRACLM displayed improved capabilities when applied to Army tasks and use
cases. Furthermore, throughout our fine-tuning experiments, we recognized the
need for an evaluation framework that objectively quantifies the Army
domain-specific knowledge of LLMs. To address this, we developed MilBench, an
extensible software framework that efficiently evaluates the Army knowledge of
a given LLM using tasks derived from doctrine and assessments. We share
preliminary results, models, methods, and recommendations on the creation of
TRACLM and MilBench. Our work significantly informs the development of LLM
technology across the DoD and augments senior leader decisions with respect to
artificial intelligence integration.",2024-10-27,"Daniel C. Ruiz, John Sell",http://arxiv.org/pdf/2410.20297v1,cs.CL
Fast Best-of-N Decoding via Speculative Rejection,"The safe and effective deployment of Large Language Models (LLMs) involves a
critical step called alignment, which ensures that the model's responses are in
accordance with human preferences. Prevalent alignment techniques, such as DPO,
PPO and their variants, align LLMs by changing the pre-trained model weights
during a phase called post-training. While predominant, these post-training
methods add substantial complexity before LLMs can be deployed. Inference-time
alignment methods avoid the complex post-training step and instead bias the
generation towards responses that are aligned with human preferences. The
best-known inference-time alignment method, called Best-of-N, is as effective
as the state-of-the-art post-training procedures. Unfortunately, Best-of-N
requires vastly more resources at inference time than standard decoding
strategies, which makes it computationally not viable. In this work, we
introduce Speculative Rejection, a computationally-viable inference-time
alignment algorithm. It generates high-scoring responses according to a given
reward model, like Best-of-N does, while being between 16 to 32 times more
computationally efficient.",2024-10-26,"Hanshi Sun, Momin Haider, Ruiqi Zhang, Huitao Yang, Jiahao Qiu, Ming Yin, Mengdi Wang, Peter Bartlett, Andrea Zanette",http://arxiv.org/pdf/2410.20290v2,cs.CL
"Library Learning Doesn't: The Curious Case of the Single-Use ""Library""","Advances in Large Language Models (LLMs) have spurred a wave of LLM library
learning systems for mathematical reasoning. These systems aim to learn a
reusable library of tools, such as formal Isabelle lemmas or Python programs
that are tailored to a family of tasks. Many of these systems are inspired by
the human structuring of knowledge into reusable and extendable concepts, but
do current methods actually learn reusable libraries of tools?
  We study two library learning systems for mathematics which both reported
increased accuracy: LEGO-Prover and TroVE. We find that function reuse is
extremely infrequent on miniF2F and MATH. Our followup ablation experiments
suggest that, rather than reuse, self-correction and self-consistency are the
primary drivers of the observed performance gains. Our code and data are
available at https://github.com/ikb-a/curious-case",2024-10-26,"Ian Berlot-Attwell, Frank Rudzicz, Xujie Si",http://arxiv.org/pdf/2410.20274v1,cs.CL
Improving Model Evaluation using SMART Filtering of Benchmark Datasets,"One of the most challenging problems facing NLP today is evaluation. Some of
the most pressing issues pertain to benchmark saturation, data contamination,
and diversity in the quality of test examples. To address these concerns, we
propose Selection Methodology for Accurate, Reduced, and Targeted (SMART)
filtering, a novel approach to select a high-quality subset of examples from
existing benchmark datasets by systematically removing less informative and
less challenging examples. Our approach applies three filtering criteria,
removing (i) easy examples, (ii) data-contaminated examples, and (iii) examples
that are similar to each other based on distance in an embedding space. We
demonstrate the effectiveness of SMART on three multiple choice QA datasets,
where our methodology increases efficiency by reducing dataset size by 48\% on
average, while increasing Pearson correlation with rankings from ChatBot Arena,
a more open-ended human evaluation setting. Our method enables us to be more
efficient, whether using SMART to make new benchmarks more challenging or to
revitalize older datasets, while still preserving the relative model rankings.",2024-10-26,"Vipul Gupta, Candace Ross, David Pantoja, Rebecca J. Passonneau, Megan Ung, Adina Williams",http://arxiv.org/pdf/2410.20245v2,cs.CL
A Survey of Large Language Models for Arabic Language and its Dialects,"This survey offers a comprehensive overview of Large Language Models (LLMs)
designed for Arabic language and its dialects. It covers key architectures,
including encoder-only, decoder-only, and encoder-decoder models, along with
the datasets used for pre-training, spanning Classical Arabic, Modern Standard
Arabic, and Dialectal Arabic. The study also explores monolingual, bilingual,
and multilingual LLMs, analyzing their architectures and performance across
downstream tasks, such as sentiment analysis, named entity recognition, and
question answering. Furthermore, it assesses the openness of Arabic LLMs based
on factors, such as source code availability, training data, model weights, and
documentation. The survey highlights the need for more diverse dialectal
datasets and attributes the importance of openness for research reproducibility
and transparency. It concludes by identifying key challenges and opportunities
for future research and stressing the need for more inclusive and
representative models.",2024-10-26,"Malak Mashaabi, Shahad Al-Khalifa, Hend Al-Khalifa",http://arxiv.org/pdf/2410.20238v2,cs.CL
Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts,"Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.",2024-10-26,"Vishesh Prasad, Brian Kim, Nickvash Kani",http://arxiv.org/pdf/2410.21324v1,cs.CL
Ambiguity is the last thing you need,"Clear legal language forms the backbone of a contract for numerous reasons.
Disputes often arise between contract parties where ambiguous language has been
used and parties often disagree on the meaning or effect of the words.
Unambiguous language can also be important where there is an imbalance of
bargaining strength between the parties, for instance where a business is
contracting with a consumer, where the law actually requires plain language to
be used. Thus, plain language minimises misinterpretation and prevents future
litigation. Contracts become ambiguous when the language used is vague,
imprecise, or open to multiple interpretations and this is due to the vast
number of synonyms in the English Language which creates differences in
interpretation between the meaning of the language. Ambiguity has always formed
a prevalent issue in case-law, with a large percentage of cases based on
ambiguous language. Thus, from an outside perspective the legal sector should
look forward to ways of reducing this.",2024-10-26,"Emily Chivers, Shawn Curran",http://arxiv.org/pdf/2410.20222v1,cs.CL
Generative linguistics contribution to artificial intelligence: Where this contribution lies?,"This article aims to characterize Generative linguistics (GL) contribution to
artificial intelligence (AI), alluding to the debate among linguists and AI
scientists on whether linguistics belongs to humanities or science. In this
article, I will try not to be biased as a linguist, studying the phenomenon
from an independent scientific perspective. The article walks the
researcher/reader through the scientific theorems and rationales involved in AI
which belong from GL, specifically the Chomsky School. It, thus, provides good
evidence from syntax, semantics, language faculty, Universal Grammar,
computational system of human language, language acquisition, human brain,
programming languages (e.g. Python), Large Language Models, and unbiased AI
scientists that this contribution is huge, and that this contribution cannot be
denied. It concludes that however the huge GL contribution to AI, there are
still points of divergence including the nature and type of language input.",2024-10-26,Mohammed Q. Shormani,http://arxiv.org/pdf/2410.20221v3,cs.CL
Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery,"New intent discovery is a crucial capability for task-oriented dialogue
systems. Existing methods focus on transferring in-domain (IND) prior knowledge
to out-of-domain (OOD) data through pre-training and clustering stages. They
either handle the two processes in a pipeline manner, which exhibits a gap
between intent representation and clustering process or use typical contrastive
clustering that overlooks the potential supervised signals from the whole data.
Besides, they often individually deal with open intent discovery or OOD
settings. To this end, we propose a Pseudo-Label enhanced Prototypical
Contrastive Learning (PLPCL) model for uniformed intent discovery. We
iteratively utilize pseudo-labels to explore potential positive/negative
samples for contrastive learning and bridge the gap between representation and
clustering. To enable better knowledge transfer, we design a prototype learning
method integrating the supervised and pseudo signals from IND and OOD samples.
In addition, our method has been proven effective in two different settings of
discovering new intents. Experiments on three benchmark datasets and two task
settings demonstrate the effectiveness of our approach.",2024-10-26,"Yimin Deng, Yuxia Wu, Guoshuai Zhao, Li Zhu, Xueming Qian",http://arxiv.org/pdf/2410.20219v1,cs.CL
DAWN-ICL: Strategic Planning of Problem-solving Trajectories for Zero-Shot In-Context Learning,"Zero-shot in-context learning (ZS-ICL) aims to conduct in-context learning
(ICL) without using human-annotated demonstrations. Most ZS-ICL methods use
large language models (LLMs) to generate (input, label) pairs as
pseudo-demonstrations and leverage historical pseudo-demonstrations to help
solve the current problem. They assume that problems are from the same task and
traverse them in a random order. However, in real-world scenarios, problems
usually come from diverse tasks, and only a few belong to the same task. The
random traversing order may generate unreliable pseudo-demonstrations and lead
to error accumulation. To address this problem, we reformulate ZS-ICL as a
planning problem and propose a Demonstration-aware Monte Carlo Tree Search
(MCTS) approach (DAWN-ICL), which leverages MCTS to strategically plan the
problem-solving trajectories for ZS-ICL. In addition, to achieve effective and
efficient Q value estimation, we propose a novel demonstration-aware Q-value
function and use it to enhance the selection phase and accelerate the expansion
and simulation phases in MCTS. Extensive experiments demonstrate the
effectiveness and efficiency of DAWN-ICL on in-domain and cross-domain
scenarios, and it even outperforms ICL using human-annotated labels. The code
is available at https://github.com/RUCAIBox/MCTS4ZSICL.",2024-10-26,"Xinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Ji-Rong Wen",http://arxiv.org/pdf/2410.20215v2,cs.CL
Looking Beyond The Top-1: Transformers Determine Top Tokens In Order,"Understanding the inner workings of Transformers is crucial for achieving
more accurate and efficient predictions. In this work, we analyze the
computation performed by Transformers in the layers after the top-1 prediction
has become fixed, which has been previously referred to as the ""saturation
event"". We expand the concept of saturation events for top-k tokens,
demonstrating that similar saturation events occur across language, vision, and
speech models. We find that these saturation events happen in order of the
corresponding tokens' ranking, i.e., the model first decides on the top ranking
token, then the second highest ranking token, and so on. This phenomenon seems
intrinsic to the Transformer architecture, occurring across different
architectural variants (decoder-only, encoder-only, and to a lesser extent
full-Transformer), and even in untrained Transformers. We propose an underlying
mechanism of task transition for this sequential saturation, where task k
corresponds to predicting the k-th most probable token, and the saturation
events are in fact discrete transitions between the tasks. In support of this
we show that it is possible to predict the current task from hidden layer
embedding. Furthermore, using an intervention method we demonstrate that we can
cause the model to switch from one task to the next. Finally, leveraging our
findings, we introduce a novel token-level early-exit strategy, which surpasses
existing methods in balancing performance and efficiency.",2024-10-26,"Daria Lioubashevski, Tomer Schlank, Gabriel Stanovsky, Ariel Goldstein",http://arxiv.org/pdf/2410.20210v1,cs.CL
Quantifying Risk Propensities of Large Language Models: Ethical Focus and Bias Detection through Role-Play,"As Large Language Models (LLMs) become more prevalent, concerns about their
safety, ethics, and potential biases have risen. Systematically evaluating
LLMs' risk decision-making tendencies and attitudes, particularly in the
ethical domain, has become crucial. This study innovatively applies the
Domain-Specific Risk-Taking (DOSPERT) scale from cognitive science to LLMs and
proposes a novel Ethical Decision-Making Risk Attitude Scale (EDRAS) to assess
LLMs' ethical risk attitudes in depth. We further propose a novel approach
integrating risk scales and role-playing to quantitatively evaluate systematic
biases in LLMs. Through systematic evaluation and analysis of multiple
mainstream LLMs, we assessed the ""risk personalities"" of LLMs across multiple
domains, with a particular focus on the ethical domain, and revealed and
quantified LLMs' systematic biases towards different groups. This research
helps understand LLMs' risk decision-making and ensure their safe and reliable
application. Our approach provides a tool for identifying and mitigating
biases, contributing to fairer and more trustworthy AI systems. The code and
data are available.",2024-10-26,"Yifan Zeng, Liang Kairong, Fangzhou Dong, Peijia Zheng",http://arxiv.org/pdf/2411.08884v2,cs.CL
Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs,"Evaluating Large Language Models (LLMs) on reasoning benchmarks demonstrates
their ability to solve compositional questions. However, little is known of
whether these models engage in genuine logical reasoning or simply rely on
implicit cues to generate answers. In this paper, we investigate the transitive
reasoning capabilities of two distinct LLM architectures, LLaMA 2 and Flan-T5,
by manipulating facts within two compositional datasets: QASC and Bamboogle. We
controlled for potential cues that might influence the models' performance,
including (a) word/phrase overlaps across sections of test input; (b) models'
inherent knowledge during pre-training or fine-tuning; and (c) Named Entities.
Our findings reveal that while both models leverage (a), Flan-T5 shows more
resilience to experiments (b and c), having less variance than LLaMA 2. This
suggests that models may develop an understanding of transitivity through
fine-tuning on knowingly relevant datasets, a hypothesis we leave to future
work.",2024-10-26,"Houman Mehrafarin, Arash Eshghi, Ioannis Konstas",http://arxiv.org/pdf/2410.20200v1,cs.CL
Enhancing Inflation Nowcasting with LLM: Sentiment Analysis on News,"This study explores the integration of large language models (LLMs) into
classic inflation nowcasting frameworks, particularly in light of high
inflation volatility periods such as the COVID-19 pandemic. We propose
InflaBERT, a BERT-based LLM fine-tuned to predict inflation-related sentiment
in news. We use this model to produce NEWS, an index capturing the monthly
sentiment of the news regarding inflation. Incorporating our expectation index
into the Cleveland Fed's model, which is only based on macroeconomic
autoregressive processes, shows a marginal improvement in nowcast accuracy
during the pandemic. This highlights the potential of combining sentiment
analysis with traditional economic indicators, suggesting further research to
refine these methodologies for better real-time inflation monitoring. The
source code is available at https://github.com/paultltc/InflaBERT.",2024-10-26,"Marc-Antoine Allard, Paul Teiletche, Adam Zinebi",http://arxiv.org/pdf/2410.20198v1,cs.CL
LLMs Can Evolve Continually on Modality for X-Modal Reasoning,"Multimodal Large Language Models (MLLMs) have gained significant attention
due to their impressive capabilities in multimodal understanding. However,
existing methods rely heavily on extensive modal-specific pretraining and
joint-modal tuning, leading to significant computational burdens when expanding
to new modalities. In this paper, we propose PathWeave, a flexible and scalable
framework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs
to continually EVolve on modalities for $\mathbb{X}$-modal reasoning. We
leverage the concept of Continual Learning and develop an incremental training
strategy atop pre-trained MLLMs, enabling their expansion to new modalities
using uni-modal data, without executing joint-modal pretraining. In detail, a
novel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and
cross-modal adapters are seamlessly integrated to facilitate efficient modality
alignment and collaboration. Additionally, an MoE-based gating module is
applied between two types of adapters to further enhance the multimodal
interaction. To investigate the proposed method, we establish a challenging
benchmark called Continual Learning of Modality (MCL), which consists of
high-quality QA data from five distinct modalities: image, video, audio, depth
and point cloud. Extensive experiments demonstrate the effectiveness of the
proposed AnA framework on learning plasticity and memory stability during
continual learning. Furthermore, PathWeave performs comparably to
state-of-the-art MLLMs while concurrently reducing parameter training burdens
by 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave",2024-10-26,"Jiazuo Yu, Haomiao Xiong, Lu Zhang, Haiwen Diao, Yunzhi Zhuge, Lanqing Hong, Dong Wang, Huchuan Lu, You He, Long Chen",http://arxiv.org/pdf/2410.20178v2,cs.CL
A Stack-Propagation Framework for Low-Resource Personalized Dialogue Generation,"With the resurgent interest in building open-domain dialogue systems, the
dialogue generation task has attracted increasing attention over the past few
years. This task is usually formulated as a conditional generation problem,
which aims to generate a natural and meaningful response given dialogue
contexts and specific constraints, such as persona. And maintaining a
consistent persona is essential for the dialogue systems to gain trust from the
users. Although tremendous advancements have been brought, traditional
persona-based dialogue models are typically trained by leveraging a large
number of persona-dense dialogue examples. Yet, such persona-dense training
data are expensive to obtain, leading to a limited scale. This work presents a
novel approach to learning from limited training examples by regarding
consistency understanding as a regularization of response generation. To this
end, we propose a novel stack-propagation framework for learning a generation
and understanding pipeline.Specifically, the framework stacks a Transformer
encoder and two Transformer decoders, where the first decoder models response
generation and the second serves as a regularizer and jointly models response
generation and consistency understanding. The proposed framework can benefit
from the stacked encoder and decoders to learn from much smaller personalized
dialogue data while maintaining competitive performance. Under different
low-resource settings, subjective and objective evaluations prove that the
stack-propagation framework outperforms strong baselines in response quality
and persona consistency and largely overcomes the shortcomings of traditional
models that rely heavily on the persona-dense dialogue data.",2024-10-26,"Haoyu Song, Wei-Nan Zhang, Kaiyan Zhang, Ting Liu",http://arxiv.org/pdf/2410.20174v1,cs.CL
UniHGKR: Unified Instruction-aware Heterogeneous Knowledge Retrievers,"Existing information retrieval (IR) models often assume a homogeneous
structure for knowledge sources and user queries, limiting their applicability
in real-world settings where retrieval is inherently heterogeneous and diverse.
In this paper, we introduce UniHGKR, a unified instruction-aware heterogeneous
knowledge retriever that (1) builds a unified retrieval space for heterogeneous
knowledge and (2) follows diverse user instructions to retrieve knowledge of
specified types. UniHGKR consists of three principal stages: heterogeneous
self-supervised pretraining, text-anchored embedding alignment, and
instruction-aware retriever fine-tuning, enabling it to generalize across
varied retrieval contexts. This framework is highly scalable, with a BERT-based
version and a UniHGKR-7B version trained on large language models. Also, we
introduce CompMix-IR, the first native heterogeneous knowledge retrieval
benchmark. It includes two retrieval scenarios with various instructions, over
9,400 question-answer (QA) pairs, and a corpus of 10 million entries, covering
four different types of data. Extensive experiments show that UniHGKR
consistently outperforms state-of-the-art methods on CompMix-IR, achieving up
to 6.36% and 54.23% relative improvements in two scenarios, respectively.
Finally, by equipping our retriever for open-domain heterogeneous QA systems,
we achieve a new state-of-the-art result on the popular ConvMix task, with an
absolute improvement of up to 5.90 points.",2024-10-26,"Dehai Min, Zhiyang Xu, Guilin Qi, Lifu Huang, Chenyu You",http://arxiv.org/pdf/2410.20163v2,cs.CL
Causal Abstraction in Model Interpretability: A Compact Survey,"The pursuit of interpretable artificial intelligence has led to significant
advancements in the development of methods that aim to explain the
decision-making processes of complex models, such as deep learning systems.
Among these methods, causal abstraction stands out as a theoretical framework
that provides a principled approach to understanding and explaining the causal
mechanisms underlying model behavior. This survey paper delves into the realm
of causal abstraction, examining its theoretical foundations, practical
applications, and implications for the field of model interpretability.",2024-10-26,Yihao Zhang,http://arxiv.org/pdf/2410.20161v1,cs.CL
Hybrid Deep Learning for Legal Text Analysis: Predicting Punishment Durations in Indonesian Court Rulings,"Limited public understanding of legal processes and inconsistent verdicts in
the Indonesian court system led to widespread dissatisfaction and increased
stress on judges. This study addresses these issues by developing a deep
learning-based predictive system for court sentence lengths. Our hybrid model,
combining CNN and BiLSTM with attention mechanism, achieved an R-squared score
of 0.5893, effectively capturing both local patterns and long-term dependencies
in legal texts. While document summarization proved ineffective, using only the
top 30% most frequent tokens increased prediction performance, suggesting that
focusing on core legal terminology balances information retention and
computational efficiency. We also implemented a modified text normalization
process, addressing common errors like misspellings and incorrectly merged
words, which significantly improved the model's performance. These findings
have important implications for automating legal document processing, aiding
both professionals and the public in understanding court judgments. By
leveraging advanced NLP techniques, this research contributes to enhancing
transparency and accessibility in the Indonesian legal system, paving the way
for more consistent and comprehensible legal decisions.",2024-10-26,"Muhammad Amien Ibrahim, Alif Tri Handoyo, Maria Susan Anggreainy",http://arxiv.org/pdf/2410.20104v1,cs.CL
RARe: Retrieval Augmented Retrieval with In-Context Examples,"We investigate whether in-context examples, widely used in decoder-only
language models (LLMs), can improve embedding model performance in retrieval
tasks. Unlike in LLMs, naively prepending in-context examples (query-document
pairs) to the target query at inference time does not work out of the box. We
introduce a simple approach to enable retrievers to use in-context examples.
Our approach, RARe, finetunes a pre-trained model with in-context examples
whose query is semantically similar to the target query. This can be applied to
adapt various base architectures (i.e., decoder-only language models, retriever
models) and consistently achieves performance gains of up to +2.72% nDCG across
various open-domain retrieval datasets (BeIR, RAR-b). In particular, we find
RARe exhibits stronger out-of-domain generalization compared to models using
queries without in-context examples, similar to what is seen for in-context
learning in LLMs. We further provide analysis on the design choices of
in-context example augmentation and lay the foundation for future work in this
space.",2024-10-26,"Atula Tejaswi, Yoonsang Lee, Sujay Sanghavi, Eunsol Choi",http://arxiv.org/pdf/2410.20088v1,cs.CL
User-Aware Multilingual Abusive Content Detection in Social Media,"Despite growing efforts to halt distasteful content on social media,
multilingualism has added a new dimension to this problem. The scarcity of
resources makes the challenge even greater when it comes to low-resource
languages. This work focuses on providing a novel method for abusive content
detection in multiple low-resource Indic languages. Our observation indicates
that a post's tendency to attract abusive comments, as well as features such as
user history and social context, significantly aid in the detection of abusive
content. The proposed method first learns social and text context features in
two separate modules. The integrated representation from these modules is
learned and used for the final prediction. To evaluate the performance of our
method against different classical and state-of-the-art methods, we have
performed extensive experiments on SCIDN and MACI datasets consisting of 1.5M
and 665K multilingual comments, respectively. Our proposed method outperforms
state-of-the-art baseline methods with an average increase of 4.08% and 9.52%
in F1-scores on SCIDN and MACI datasets, respectively.",2024-10-26,"Mohammad Zia Ur Rehman, Somya Mehta, Kuldeep Singh, Kunal Kaushik, Nagendra Kumar",http://arxiv.org/pdf/2410.21321v1,cs.CL
Personality Analysis from Online Short Video Platforms with Multi-domain Adaptation,"Personality analysis from online short videos has gained prominence due to
its applications in personalized recommendation systems, sentiment analysis,
and human-computer interaction. Traditional assessment methods, such as
questionnaires based on the Big Five Personality Framework, are limited by
self-report biases and are impractical for large-scale or real-time analysis.
Leveraging the rich, multi-modal data present in short videos offers a
promising alternative for more accurate personality inference. However,
integrating these diverse and asynchronous modalities poses significant
challenges, particularly in aligning time-varying data and ensuring models
generalize well to new domains with limited labeled data. In this paper, we
propose a novel multi-modal personality analysis framework that addresses these
challenges by synchronizing and integrating features from multiple modalities
and enhancing model generalization through domain adaptation. We introduce a
timestamp-based modality alignment mechanism that synchronizes data based on
spoken word timestamps, ensuring accurate correspondence across modalities and
facilitating effective feature integration. To capture temporal dependencies
and inter-modal interactions, we employ Bidirectional Long Short-Term Memory
networks and self-attention mechanisms, allowing the model to focus on the most
informative features for personality prediction. Furthermore, we develop a
gradient-based domain adaptation method that transfers knowledge from multiple
source domains to improve performance in target domains with scarce labeled
data. Extensive experiments on real-world datasets demonstrate that our
framework significantly outperforms existing methods in personality prediction
tasks, highlighting its effectiveness in capturing complex behavioral cues and
robustness in adapting to new domains.",2024-10-26,"Sixu An, Xiangguo Sun, Yicong Li, Yu Yang, Guandong Xu",http://arxiv.org/pdf/2411.00813v1,cs.CL
Multi-Field Adaptive Retrieval,"Document retrieval for tasks such as search and retrieval-augmented
generation typically involves datasets that are unstructured: free-form text
without explicit internal structure in each document. However, documents can
have a structured form, consisting of fields such as an article title, message
body, or HTML header. To address this gap, we introduce Multi-Field Adaptive
Retrieval (MFAR), a flexible framework that accommodates any number of and any
type of document indices on structured data. Our framework consists of two main
steps: (1) the decomposition of an existing document into fields, each indexed
independently through dense and lexical methods, and (2) learning a model which
adaptively predicts the importance of a field by conditioning on the document
query, allowing on-the-fly weighting of the most likely field(s). We find that
our approach allows for the optimized use of dense versus lexical
representations across field types, significantly improves in document ranking
over a number of existing retrievers, and achieves state-of-the-art performance
for multi-field structured data.",2024-10-26,"Millicent Li, Tongfei Chen, Benjamin Van Durme, Patrick Xia",http://arxiv.org/pdf/2410.20056v2,cs.CL
LinBridge: A Learnable Framework for Interpreting Nonlinear Neural Encoding Models,"Neural encoding of artificial neural networks (ANNs) links their
computational representations to brain responses, offering insights into how
the brain processes information. Current studies mostly use linear encoding
models for clarity, even though brain responses are often nonlinear. This has
sparked interest in developing nonlinear encoding models that are still
interpretable. To address this problem, we propose LinBridge, a learnable and
flexible framework based on Jacobian analysis for interpreting nonlinear
encoding models. LinBridge posits that the nonlinear mapping between ANN
representations and neural responses can be factorized into a linear inherent
component that approximates the complex nonlinear relationship, and a mapping
bias that captures sample-selective nonlinearity. The Jacobian matrix, which
reflects output change rates relative to input, enables the analysis of
sample-selective mapping in nonlinear models. LinBridge employs a
self-supervised learning strategy to extract both the linear inherent component
and nonlinear mapping biases from the Jacobian matrices of the test set,
allowing it to adapt effectively to various nonlinear encoding models. We
validate the LinBridge framework in the scenario of neural visual encoding,
using computational visual representations from CLIP-ViT to predict brain
activity recorded via functional magnetic resonance imaging (fMRI). Our
experimental results demonstrate that: 1) the linear inherent component
extracted by LinBridge accurately reflects the complex mappings of nonlinear
neural encoding models; 2) the sample-selective mapping bias elucidates the
variability of nonlinearity across different levels of the visual processing
hierarchy. This study presents a novel tool for interpreting nonlinear neural
encoding models and offers fresh evidence about hierarchical nonlinearity
distribution in the visual cortex.",2024-10-26,"Xiaohui Gao, Yue Cheng, Peiyang Li, Yijie Niu, Yifan Ren, Yiheng Liu, Haiyang Sun, Zhuoyi Li, Weiwei Xing, Xintao Hu",http://arxiv.org/pdf/2410.20053v1,cs.CL
Architectural Flaw Detection in Civil Engineering Using GPT-4,"The application of artificial intelligence (AI) in civil engineering presents
a transformative approach to enhancing design quality and safety. This paper
investigates the potential of the advanced LLM GPT4 Turbo vision model in
detecting architectural flaws during the design phase, with a specific focus on
identifying missing doors and windows. The study evaluates the model's
performance through metrics such as precision, recall, and F1 score,
demonstrating AI's effectiveness in accurately detecting flaws compared to
human-verified data. Additionally, the research explores AI's broader
capabilities, including identifying load-bearing issues, material weaknesses,
and ensuring compliance with building codes. The findings highlight how AI can
significantly improve design accuracy, reduce costly revisions, and support
sustainable practices, ultimately revolutionizing the civil engineering field
by ensuring safer, more efficient, and aesthetically optimized structures.",2024-10-26,"Saket Kumar, Abul Ehtesham, Aditi Singh, Tala Talaei Khoei",http://arxiv.org/pdf/2410.20036v1,cs.CL
Training the Untrainable: Introducing Inductive Bias via Representational Alignment,"We demonstrate that architectures which traditionally are considered to be
ill-suited for a task can be trained using inductive biases from another
architecture. Networks are considered untrainable when they overfit, underfit,
or converge to poor results even when tuning their hyperparameters. For
example, plain fully connected networks overfit on object recognition while
deep convolutional networks without residual connections underfit. The
traditional answer is to change the architecture to impose some inductive bias,
although what that bias is remains unknown. We introduce guidance, where a
guide network guides a target network using a neural distance function. The
target is optimized to perform well and to match its internal representations,
layer-by-layer, to those of the guide; the guide is unchanged. If the guide is
trained, this transfers over part of the architectural prior and knowledge of
the guide to the target. If the guide is untrained, this transfers over only
part of the architectural prior of the guide. In this manner, we can
investigate what kinds of priors different architectures place on untrainable
networks such as fully connected networks. We demonstrate that this method
overcomes the immediate overfitting of fully connected networks on vision
tasks, makes plain CNNs competitive to ResNets, closes much of the gap between
plain vanilla RNNs and Transformers, and can even help Transformers learn tasks
which RNNs can perform more easily. We also discover evidence that better
initializations of fully connected networks likely exist to avoid overfitting.
Our method provides a mathematical tool to investigate priors and
architectures, and in the long term, may demystify the dark art of architecture
creation, even perhaps turning architectures into a continuous optimizable
parameter of the network.",2024-10-26,"Vighnesh Subramaniam, David Mayo, Colin Conwell, Tomaso Poggio, Boris Katz, Brian Cheung, Andrei Barbu",http://arxiv.org/pdf/2410.20035v1,cs.CL
Beyond Fine-Tuning: Effective Strategies for Mitigating Hallucinations in Large Language Models for Data Analytics,"Large Language Models (LLMs) have become increasingly important in natural
language processing, enabling advanced data analytics through natural language
queries. However, these models often generate ""hallucinations""-inaccurate or
fabricated information-that can undermine their reliability in critical
data-driven decision-making. Addressing the challenge of hallucinations is
essential to improve the accuracy and trustworthiness of LLMs in processing
natural language queries. This research focuses on mitigating hallucinations in
LLMs, specifically within the context of data analytics. We introduce and
evaluate four targeted strategies: Structured Output Generation, Strict Rules
Enforcement, System Prompt Enhancements, and Semantic Layer Integration. Our
findings show that these methods are more effective than traditional
fine-tuning approaches in reducing hallucinations, offering a more reliable
framework for deploying LLMs in natural language queries for data analytics.
This research demonstrates the potential of these strategies to enhance the
accuracy of LLM-driven data queries, ensuring more dependable results in
data-driven environments.",2024-10-26,"Mikhail Rumiantsau, Aliaksei Vertsel, Ilya Hrytsuk, Isaiah Ballah",http://arxiv.org/pdf/2410.20024v1,cs.CL
MatExpert: Decomposing Materials Discovery by Mimicking Human Experts,"Material discovery is a critical research area with profound implications for
various industries. In this work, we introduce MatExpert, a novel framework
that leverages Large Language Models (LLMs) and contrastive learning to
accelerate the discovery and design of new solid-state materials. Inspired by
the workflow of human materials design experts, our approach integrates three
key stages: retrieval, transition, and generation. First, in the retrieval
stage, MatExpert identifies an existing material that closely matches the
desired criteria. Second, in the transition stage, MatExpert outlines the
necessary modifications to transform this material formulation to meet specific
requirements outlined by the initial user query. Third, in the generation
state, MatExpert performs detailed computations and structural generation to
create new materials based on the provided information. Our experimental
results demonstrate that MatExpert outperforms state-of-the-art methods in
material generation tasks, achieving superior performance across various
metrics including validity, distribution, and stability. As such, MatExpert
represents a meaningful advancement in computational material discovery using
langauge-based generative models.",2024-10-26,"Qianggang Ding, Santiago Miret, Bang Liu",http://arxiv.org/pdf/2410.21317v1,cs.CL
Dynamic layer selection in decoder-only transformers,"The vast size of Large Language Models (LLMs) has prompted a search to
optimize inference. One effective approach is dynamic inference, which adapts
the architecture to the sample-at-hand to reduce the overall computational
cost. We empirically examine two common dynamic inference methods for natural
language generation (NLG): layer skipping and early exiting. We find that a
pre-trained decoder-only model is significantly more robust to layer removal
via layer skipping, as opposed to early exit. We demonstrate the difficulty of
using hidden state information to adapt computation on a per-token basis for
layer skipping. Finally, we show that dynamic computation allocation on a
per-sequence basis holds promise for significant efficiency gains by
constructing an oracle controller. Remarkably, we find that there exists an
allocation which achieves equal performance to the full model using only 23.3%
of its layers on average.",2024-10-26,"Theodore Glavas, Joud Chataoui, Florence Regol, Wassim Jabbour, Antonios Valkanas, Boris N. Oreshkin, Mark Coates",http://arxiv.org/pdf/2410.20022v1,cs.CL
Think Carefully and Check Again! Meta-Generation Unlocking LLMs for Low-Resource Cross-Lingual Summarization,"Cross-lingual summarization (CLS) aims to generate a summary for the source
text in a different target language. Currently, instruction-tuned large
language models (LLMs) excel at various English tasks. However, unlike
languages such as English, Chinese or Spanish, for those relatively
low-resource languages with limited usage or data, recent studies have shown
that LLMs' performance on CLS tasks remains unsatisfactory even with few-shot
settings. This raises the question: Are LLMs capable of handling cross-lingual
summarization tasks for low-resource languages? To resolve this question, we
fully explore the potential of large language models on cross-lingual
summarization task for low-resource languages through our four-step zero-shot
method: Summarization, Improvement, Translation and Refinement (SITR) with
correspondingly designed prompts. We test our proposed method with multiple
LLMs on two well-known cross-lingual summarization datasets with various
low-resource target languages. The results show that: i) GPT-3.5 and GPT-4
significantly and consistently outperform other baselines when using our
zero-shot SITR methods. ii) By employing our proposed method, we unlock the
potential of LLMs, enabling them to effectively handle cross-lingual
summarization tasks for relatively low-resource languages.",2024-10-26,"Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Naifan Cheung, Nanyun Peng, Kai-wei Chang",http://arxiv.org/pdf/2410.20021v2,cs.CL
Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions,"Large Language Models have introduced novel opportunities for text
comprehension and generation. Yet, they are vulnerable to adversarial
perturbations and data poisoning attacks, particularly in tasks like text
classification and translation. However, the adversarial robustness of
abstractive text summarization models remains less explored. In this work, we
unveil a novel approach by exploiting the inherent lead bias in summarization
models, to perform adversarial perturbations. Furthermore, we introduce an
innovative application of influence functions, to execute data poisoning, which
compromises the model's integrity. This approach not only shows a skew in the
models behavior to produce desired outcomes but also shows a new behavioral
change, where models under attack tend to generate extractive summaries rather
than abstractive summaries.",2024-10-26,"Poojitha Thota, Shirin Nilizadeh",http://arxiv.org/pdf/2410.20019v1,cs.CL
Vulnerability of LLMs to Vertically Aligned Text Manipulations,"Text classification involves categorizing a given text, such as determining
its sentiment or identifying harmful content. With the advancement of large
language models (LLMs), these models have become highly effective at performing
text classification tasks. However, they still show vulnerabilities to
variations in text formatting. Recent research demonstrates that modifying
input formats, such as vertically aligning words for encoder-based models, can
substantially lower accuracy in text classification tasks. While easily
understood by humans, these inputs can significantly mislead models, posing a
potential risk of bypassing detection in real-world scenarios involving harmful
or sensitive information. With the expanding application of LLMs, a crucial
question arises: Do decoder-based LLMs exhibit similar vulnerabilities to
vertically formatted text input? In this paper, we investigate the impact of
vertical text input on the performance of various LLMs across multiple text
classification datasets and analyze the underlying causes. Our findings are as
follows: (i) Vertical text input significantly degrades the accuracy of LLMs in
text classification tasks. (ii) Chain of Thought (CoT) reasoning does not help
LLMs recognize vertical input or mitigate its vulnerability, but few-shot
learning with careful analysis does. (iii) We explore the underlying cause of
the vulnerability by analyzing the inherent issues in tokenization and
attention matrices.",2024-10-26,"Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Zhen Xiong, Nanyun Peng, Kai-wei Chang",http://arxiv.org/pdf/2410.20016v2,cs.CL
A Survey of Small Language Models,"Small Language Models (SLMs) have become increasingly important due to their
efficiency and performance to perform various language tasks with minimal
computational resources, making them ideal for various settings including
on-device, mobile, edge devices, among many others. In this article, we present
a comprehensive survey on SLMs, focusing on their architectures, training
techniques, and model compression techniques. We propose a novel taxonomy for
categorizing the methods used to optimize SLMs, including model compression,
pruning, and quantization techniques. We summarize the benchmark datasets that
are useful for benchmarking SLMs along with the evaluation metrics commonly
used. Additionally, we highlight key open challenges that remain to be
addressed. Our survey aims to serve as a valuable resource for researchers and
practitioners interested in developing and deploying small yet efficient
language models.",2024-10-25,"Chien Van Nguyen, Xuan Shen, Ryan Aponte, Yu Xia, Samyadeep Basu, Zhengmian Hu, Jian Chen, Mihir Parmar, Sasidhar Kunapuli, Joe Barrow, Junda Wu, Ashish Singh, Yu Wang, Jiuxiang Gu, Franck Dernoncourt, Nesreen K. Ahmed, Nedim Lipka, Ruiyi Zhang, Xiang Chen, Tong Yu, Sungchul Kim, Hanieh Deilamsalehy, Namyong Park, Mike Rimer, Zhehao Zhang, Huanrui Yang, Ryan A. Rossi, Thien Huu Nguyen",http://arxiv.org/pdf/2410.20011v1,cs.CL
"GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization","Heterogeneous graph neural networks have recently gained attention for long
document summarization, modeling the extraction as a node classification task.
Although effective, these models often require external tools or additional
machine learning models to define graph components, producing highly complex
and less intuitive structures. We present GraphLSS, a heterogeneous graph
construction for long document extractive summarization, incorporating Lexical,
Structural, and Semantic features. It defines two levels of information (words
and sentences) and four types of edges (sentence semantic similarity, sentence
occurrence order, word in sentence, and word semantic similarity) without any
need for auxiliary learning models. Experiments on two benchmark datasets show
that GraphLSS is competitive with top-performing graph-based methods,
outperforming recent non-graph models. We release our code on GitHub.",2024-10-25,"Margarita Bugueño, Hazem Abou Hamdan, Gerard de Melo",http://arxiv.org/pdf/2410.21315v1,cs.CL
Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models,"Fine-tuning pre-trained large language models (LLMs) on a diverse array of
tasks has become a common approach for building models that can solve various
natural language processing (NLP) tasks. However, where and to what extent
these models retain task-specific knowledge remains largely unexplored. This
study investigates the task-specific information encoded in pre-trained LLMs
and the effects of instruction tuning on their representations across a diverse
set of over 60 NLP tasks. We use a set of matrix analysis tools to examine the
differences between the way pre-trained and instruction-tuned LLMs store
task-specific information. Our findings reveal that while some tasks are
already encoded within the pre-trained LLMs, others greatly benefit from
instruction tuning. Additionally, we pinpointed the layers in which the model
transitions from high-level general representations to more task-oriented
representations. This finding extends our understanding of the governing
mechanisms of LLMs and facilitates future research in the fields of
parameter-efficient transfer learning and multi-task learning.",2024-10-25,"Zheng Zhao, Yftah Ziser, Shay B. Cohen",http://arxiv.org/pdf/2410.20008v1,cs.CL
Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models,"Enhancing the reasoning capabilities of large language models (LLMs) is
crucial for enabling them to tackle complex, multi-step problems. Multi-agent
frameworks have shown great potential in enhancing LLMs' reasoning
capabilities. However, the lack of effective cooperation between LLM agents
hinders their performance, especially for multi-step reasoning tasks. This
paper proposes a novel cooperative multi-agent reasoning framework (CoPlanner)
by separating reasoning steps and assigning distinct duties to different
agents. CoPlanner consists of two LLM agents: a planning agent and a reasoning
agent. The planning agent provides high-level strategic hints, while the
reasoning agent follows these hints and infers answers. By training the
planning agent's policy through the interactive reasoning process via Proximal
Policy Optimization (PPO), the LLaMA-3-8B-based CoPlanner outperforms the
previous best method by 9.94\% on LogiQA and 3.09\% on BBH. Our results
demonstrate that the guidance from the planning agent and the effective
cooperation between the agents contribute to the superior performance of
CoPlanner in tackling multi-step reasoning problems.",2024-10-25,"Danqing Wang, Zhuorui Ye, Fei Fang, Lei Li",http://arxiv.org/pdf/2410.20007v1,cs.CL
Decoding Diffusion: A Scalable Framework for Unsupervised Analysis of Latent Space Biases and Representations Using Natural Language Prompts,"Recent advances in image generation have made diffusion models powerful tools
for creating high-quality images. However, their iterative denoising process
makes understanding and interpreting their semantic latent spaces more
challenging than other generative models, such as GANs. Recent methods have
attempted to address this issue by identifying semantically meaningful
directions within the latent space. However, they often need manual
interpretation or are limited in the number of vectors that can be trained,
restricting their scope and utility. This paper proposes a novel framework for
unsupervised exploration of diffusion latent spaces. We directly leverage
natural language prompts and image captions to map latent directions. This
method allows for the automatic understanding of hidden features and supports a
broader range of analysis without the need to train specific vectors. Our
method provides a more scalable and interpretable understanding of the semantic
knowledge encoded within diffusion models, facilitating comprehensive analysis
of latent biases and the nuanced representations these models learn.
Experimental results show that our framework can uncover hidden patterns and
associations in various domains, offering new insights into the
interpretability of diffusion model latent spaces.",2024-10-25,"E. Zhixuan Zeng, Yuhao Chen, Alexander Wong",http://arxiv.org/pdf/2410.21314v2,cs.CL
Evaluating Cost-Accuracy Trade-offs in Multimodal Search Relevance Judgements,"Large Language Models (LLMs) have demonstrated potential as effective search
relevance evaluators. However, there is a lack of comprehensive guidance on
which models consistently perform optimally across various contexts or within
specific use cases. In this paper, we assess several LLMs and Multimodal
Language Models (MLLMs) in terms of their alignment with human judgments across
multiple multimodal search scenarios. Our analysis investigates the trade-offs
between cost and accuracy, highlighting that model performance varies
significantly depending on the context. Interestingly, in smaller models, the
inclusion of a visual component may hinder performance rather than enhance it.
These findings highlight the complexities involved in selecting the most
appropriate model for practical applications.",2024-10-25,"Silvia Terragni, Hoang Cuong, Joachim Daiber, Pallavi Gudipati, Pablo N. Mendes",http://arxiv.org/pdf/2410.19974v1,cs.CL
RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction,"Jailbreak attacks circumvent LLMs' built-in safeguards by concealing harmful
queries within jailbreak prompts. While existing defenses primarily focus on
mitigating the effects of jailbreak prompts, they often prove inadequate as
jailbreak prompts can take arbitrary, adaptive forms. This paper presents
RobustKV, a novel defense that adopts a fundamentally different approach by
selectively removing critical tokens of harmful queries from key-value (KV)
caches. Intuitively, for a jailbreak prompt to be effective, its tokens must
achieve sufficient `importance' (as measured by attention scores), which
inevitably lowers the importance of tokens in the concealed harmful query.
Thus, by strategically evicting the KVs of the lowest-ranked tokens, RobustKV
diminishes the presence of the harmful query in the KV cache, thus preventing
the LLM from generating malicious responses. Extensive evaluation using
benchmark datasets and models demonstrates that RobustKV effectively counters
state-of-the-art jailbreak attacks while maintaining the LLM's general
performance on benign queries. Moreover, RobustKV creates an intriguing
evasiveness dilemma for adversaries, forcing them to balance between evading
RobustKV and bypassing the LLM's built-in safeguards. This trade-off
contributes to RobustKV's robustness against adaptive attacks. (warning: this
paper contains potentially harmful content generated by LLMs.)",2024-10-25,"Tanqiu Jiang, Zian Wang, Jiacheng Liang, Changjiang Li, Yuhui Wang, Ting Wang",http://arxiv.org/pdf/2410.19937v1,cs.CL
$\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis,"Pharmaceutical patents play a vital role in biochemical industries,
especially in drug discovery, providing researchers with unique early access to
data, experimental results, and research insights. With the advancement of
machine learning, patent analysis has evolved from manual labor to tasks
assisted by automatic tools. However, there still lacks an unified agent that
assists every aspect of patent analysis, from patent reading to core chemical
identification. Leveraging the capabilities of Large Language Models (LLMs) to
understand requests and follow instructions, we introduce the $\textbf{first}$
intelligent agent in this domain, $\texttt{PatentAgent}$, poised to advance and
potentially revolutionize the landscape of pharmaceutical research.
$\texttt{PatentAgent}$ comprises three key end-to-end modules --
$\textit{PA-QA}$, $\textit{PA-Img2Mol}$, and $\textit{PA-CoreId}$ -- that
respectively perform (1) patent question-answering, (2)
image-to-molecular-structure conversion, and (3) core chemical structure
identification, addressing the essential needs of scientists and practitioners
in pharmaceutical patent analysis. Each module of $\texttt{PatentAgent}$
demonstrates significant effectiveness with the updated algorithm and the
synergistic design of $\texttt{PatentAgent}$ framework. $\textit{PA-Img2Mol}$
outperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks
with an accuracy gain between 2.46% and 8.37% while $\textit{PA-CoreId}$
realizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML
benchmark. Our code and dataset will be publicly available.",2024-10-25,"Xin Wang, Yifan Zhang, Xiaojing Zhang, Longhui Yu, Xinna Lin, Jindong Jiang, Bin Ma, Kaicheng Yu",http://arxiv.org/pdf/2410.21312v1,cs.CL
Do Discrete Self-Supervised Representations of Speech Capture Tone Distinctions?,"Discrete representations of speech, obtained from Self-Supervised Learning
(SSL) foundation models, are widely used, especially where there are limited
data for the downstream task, such as for a low-resource language. Typically,
discretization of speech into a sequence of symbols is achieved by unsupervised
clustering of the latents from an SSL model. Our study evaluates whether
discrete symbols - found using k-means - adequately capture tone in two example
languages, Mandarin and Yoruba. We compare latent vectors with discrete
symbols, obtained from HuBERT base, MandarinHuBERT, or XLS-R, for vowel and
tone classification. We find that using discrete symbols leads to a substantial
loss of tone information, even for language-specialised SSL models. We suggest
that discretization needs to be task-aware, particularly for tone-dependent
downstream tasks.",2024-10-25,"Opeyemi Osakuade, Simon King",http://arxiv.org/pdf/2410.19935v1,cs.CL
Improving Multimodal Large Language Models Using Continual Learning,"Generative large language models (LLMs) exhibit impressive capabilities,
which can be further augmented by integrating a pre-trained vision model into
the original LLM to create a multimodal LLM (MLLM). However, this integration
often significantly decreases performance on natural language understanding and
generation tasks, compared to the original LLM. This study investigates this
issue using the LLaVA MLLM, treating the integration as a continual learning
problem. We evaluate five continual learning methods to mitigate forgetting and
identify a technique that enhances visual understanding while minimizing
linguistic performance loss. Our approach reduces linguistic performance
degradation by up to 15\% over the LLaVA recipe, while maintaining high
multimodal accuracy. We also demonstrate the robustness of our method through
continual learning on a sequence of vision-language tasks, effectively
preserving linguistic skills while acquiring new multimodal capabilities.",2024-10-25,"Shikhar Srivastava, Md Yousuf Harun, Robik Shrestha, Christopher Kanan",http://arxiv.org/pdf/2410.19925v1,cs.CL
ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models,"When conducting literature reviews, scientists often create literature review
tables - tables whose rows are publications and whose columns constitute a
schema, a set of aspects used to compare and contrast the papers. Can we
automatically generate these tables using language models (LMs)? In this work,
we introduce a framework that leverages LMs to perform this task by decomposing
it into separate schema and value generation steps. To enable experimentation,
we address two main challenges: First, we overcome a lack of high-quality
datasets to benchmark table generation by curating and releasing
arxivDIGESTables, a new dataset of 2,228 literature review tables extracted
from ArXiv papers that synthesize a total of 7,542 research papers. Second, to
support scalable evaluation of model generations against human-authored
reference tables, we develop DecontextEval, an automatic evaluation method that
aligns elements of tables with the same underlying aspects despite differing
surface forms. Given these tools, we evaluate LMs' abilities to reconstruct
reference tables, finding this task benefits from additional context to ground
the generation (e.g. table captions, in-text references). Finally, through a
human evaluation study we find that even when LMs fail to fully reconstruct a
reference table, their generated novel aspects can still be useful.",2024-10-25,"Benjamin Newman, Yoonjoo Lee, Aakanksha Naik, Pao Siangliulue, Raymond Fok, Juho Kim, Daniel S. Weld, Joseph Chee Chang, Kyle Lo",http://arxiv.org/pdf/2410.22360v1,cs.CL
Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models,"Large Vision-Language Models (LVLMs) excel in cross-model tasks but
experience performance declines in long-context reasoning due to overreliance
on textual information and reduced visual dependency. In this study, we
empirically analyze LVLMs in long-context reasoning, revealing that increased
context length leads to a higher dependence on language at the expense of
visual dependency. To address this issue, we propose a novel training-free
context pruning method that selectively removes less critical textual
information. Our approach enhances visual dependency and reduces textual noise,
thereby improving LVLM performance in long-context reasoning. We validate our
method by constructing a long-context dataset, demonstrating its effectiveness
across various LVLMs. Moreover, further analysis confirms the robustness of
different token pruning strategies and preliminary explores scaling laws
between pruning rates and context length.",2024-10-25,"Yucheng Zhou, Zhi Rao, Jun Wan, Jianbing Shen",http://arxiv.org/pdf/2410.19732v2,cs.CL
Counting Ability of Large Language Models and Impact of Tokenization,"Transformers, the backbone of modern large language models (LLMs), face
inherent architectural limitations that impede their reasoning capabilities.
Unlike recurrent networks, Transformers lack recurrent connections, confining
them to constant-depth computation. This restriction places them in the
complexity class TC$^0$, making them theoretically incapable of solving tasks
that demand increasingly deep reasoning as input length grows. Counting, a
fundamental component of many reasoning tasks, also requires reasoning depth to
grow linearly to be performed inductively. While previous studies have
established the upper limits of counting ability in Transformer-based expert
models (i.e., models specifically trained for counting tasks), these findings
do not directly extend to general-purpose LLMs due to differences in reasoning
mechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning
can help alleviate some of the architectural limitations of Transformers in
counting tasks. However, little attention has been paid to the role of
tokenization in these models. Unlike expert models that often use
character-level tokenization, LLMs typically rely on byte-level (BPE)
tokenizers, which fundamentally alters the way reasoning is processed. Our work
investigates the impact of tokenization on the counting abilities of LLMs,
uncovering substantial performance variations based on input tokenization
differences. We provide both theoretical and experimental analyses, offering
insights into how tokenization choices can undermine models' theoretical
computability, thereby inspiring the design of new tokenization methods to
enhance reasoning in LLMs.",2024-10-25,"Xiang Zhang, Juntai Cao, Chenyu You",http://arxiv.org/pdf/2410.19730v2,cs.CL
"FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning","Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.",2024-10-25,"Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson",http://arxiv.org/pdf/2410.19727v1,cs.CL
2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision,"Recent advancements in Direct Preference Optimization (DPO) have
significantly enhanced the alignment of Large Language Models (LLMs) with human
preferences, owing to its simplicity and effectiveness. However, existing
methods typically optimize a scalar score or ranking reward, thereby
overlooking the multi-dimensional nature of human preferences. In this work, we
propose to extend the preference of DPO to two dimensions: segments and
aspects. We first introduce a 2D supervision dataset called HelpSteer-2D. For
the segment dimension, we divide the response into sentences and assign scores
to each segment. For the aspect dimension, we meticulously design several
criteria covering the response quality rubrics. With the 2-dimensional signals
as feedback, we develop a 2D-DPO framework, decomposing the overall objective
into multi-segment and multi-aspect objectives. Extensive experiments on
popular benchmarks demonstrate that 2D-DPO performs better than methods that
optimize for scalar or 1-dimensional preferences.",2024-10-25,"Shilong Li, Yancheng He, Hui Huang, Xingyuan Bu, Jiaheng Liu, Hangyu Guo, Weixun Wang, Jihao Gu, Wenbo Su, Bo Zheng",http://arxiv.org/pdf/2410.19720v1,cs.CL
GPT-4o System Card,"GPT-4o is an autoregressive omni model that accepts as input any combination
of text, audio, image, and video, and generates any combination of text, audio,
and image outputs. It's trained end-to-end across text, vision, and audio,
meaning all inputs and outputs are processed by the same neural network. GPT-4o
can respond to audio inputs in as little as 232 milliseconds, with an average
of 320 milliseconds, which is similar to human response time in conversation.
It matches GPT-4 Turbo performance on text in English and code, with
significant improvement on text in non-English languages, while also being much
faster and 50\% cheaper in the API. GPT-4o is especially better at vision and
audio understanding compared to existing models. In line with our commitment to
building AI safely and consistent with our voluntary commitments to the White
House, we are sharing the GPT-4o System Card, which includes our Preparedness
Framework evaluations. In this System Card, we provide a detailed look at
GPT-4o's capabilities, limitations, and safety evaluations across multiple
categories, focusing on speech-to-speech while also evaluating text and image
capabilities, and measures we've implemented to ensure the model is safe and
aligned. We also include third-party assessments on dangerous capabilities, as
well as discussion of potential societal impacts of GPT-4o's text and vision
capabilities.",2024-10-25,"OpenAI, :, Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, Aleksander Mądry, Alex Baker-Whitcomb, Alex Beutel, Alex Borzunov, Alex Carney, Alex Chow, Alex Kirillov, Alex Nichol, Alex Paino, Alex Renzin, Alex Tachard Passos, Alexander Kirillov, Alexi Christakis, Alexis Conneau, Ali Kamali, Allan Jabri, Allison Moyer, Allison Tam, Amadou Crookes, Amin Tootoochian, Amin Tootoonchian, Ananya Kumar, Andrea Vallone, Andrej Karpathy, Andrew Braunstein, Andrew Cann, Andrew Codispoti, Andrew Galu, Andrew Kondrich, Andrew Tulloch, Andrey Mishchenko, Angela Baek, Angela Jiang, Antoine Pelisse, Antonia Woodford, Anuj Gosalia, Arka Dhar, Ashley Pantuliano, Avi Nayak, Avital Oliver, Barret Zoph, Behrooz Ghorbani, Ben Leimberger, Ben Rossen, Ben Sokolowsky, Ben Wang, Benjamin Zweig, Beth Hoover, Blake Samic, Bob McGrew, Bobby Spero, Bogo Giertler, Bowen Cheng, Brad Lightcap, Brandon Walkin, Brendan Quinn, Brian Guarraci, Brian Hsu, Bright Kellogg, Brydon Eastman, Camillo Lugaresi, Carroll Wainwright, Cary Bassin, Cary Hudson, Casey Chu, Chad Nelson, Chak Li, Chan Jun Shern, Channing Conger, Charlotte Barette, Chelsea Voss, Chen Ding, Cheng Lu, Chong Zhang, Chris Beaumont, Chris Hallacy, Chris Koch, Christian Gibson, Christina Kim, Christine Choi, Christine McLeavey, Christopher Hesse, Claudia Fischer, Clemens Winter, Coley Czarnecki, Colin Jarvis, Colin Wei, Constantin Koumouzelis, Dane Sherburn, Daniel Kappler, Daniel Levin, Daniel Levy, David Carr, David Farhi, David Mely, David Robinson, David Sasaki, Denny Jin, Dev Valladares, Dimitris Tsipras, Doug Li, Duc Phong Nguyen, Duncan Findlay, Edede Oiwoh, Edmund Wong, Ehsan Asdar, Elizabeth Proehl, Elizabeth Yang, Eric Antonow, Eric Kramer, Eric Peterson, Eric Sigler, Eric Wallace, Eugene Brevdo, Evan Mays, Farzad Khorasani, Felipe Petroski Such, Filippo Raso, Francis Zhang, Fred von Lohmann, Freddie Sulit, Gabriel Goh, Gene Oden, Geoff Salmon, Giulio Starace, Greg Brockman, Hadi Salman, Haiming Bao, Haitang Hu, Hannah Wong, Haoyu Wang, Heather Schmidt, Heather Whitney, Heewoo Jun, Hendrik Kirchner, Henrique Ponde de Oliveira Pinto, Hongyu Ren, Huiwen Chang, Hyung Won Chung, Ian Kivlichan, Ian O'Connell, Ian O'Connell, Ian Osband, Ian Silber, Ian Sohl, Ibrahim Okuyucu, Ikai Lan, Ilya Kostrikov, Ilya Sutskever, Ingmar Kanitscheider, Ishaan Gulrajani, Jacob Coxon, Jacob Menick, Jakub Pachocki, James Aung, James Betker, James Crooks, James Lennon, Jamie Kiros, Jan Leike, Jane Park, Jason Kwon, Jason Phang, Jason Teplitz, Jason Wei, Jason Wolfe, Jay Chen, Jeff Harris, Jenia Varavva, Jessica Gan Lee, Jessica Shieh, Ji Lin, Jiahui Yu, Jiayi Weng, Jie Tang, Jieqi Yu, Joanne Jang, Joaquin Quinonero Candela, Joe Beutler, Joe Landers, Joel Parish, Johannes Heidecke, John Schulman, Jonathan Lachman, Jonathan McKay, Jonathan Uesato, Jonathan Ward, Jong Wook Kim, Joost Huizinga, Jordan Sitkin, Jos Kraaijeveld, Josh Gross, Josh Kaplan, Josh Snyder, Joshua Achiam, Joy Jiao, Joyce Lee, Juntang Zhuang, Justyn Harriman, Kai Fricke, Kai Hayashi, Karan Singhal, Katy Shi, Kavin Karthik, Kayla Wood, Kendra Rimbach, Kenny Hsu, Kenny Nguyen, Keren Gu-Lemberg, Kevin Button, Kevin Liu, Kiel Howe, Krithika Muthukumar, Kyle Luther, Lama Ahmad, Larry Kai, Lauren Itow, Lauren Workman, Leher Pathak, Leo Chen, Li Jing, Lia Guy, Liam Fedus, Liang Zhou, Lien Mamitsuka, Lilian Weng, Lindsay McCallum, Lindsey Held, Long Ouyang, Louis Feuvrier, Lu Zhang, Lukas Kondraciuk, Lukasz Kaiser, Luke Hewitt, Luke Metz, Lyric Doshi, Mada Aflak, Maddie Simens, Madelaine Boyd, Madeleine Thompson, Marat Dukhan, Mark Chen, Mark Gray, Mark Hudnall, Marvin Zhang, Marwan Aljubeh, Mateusz Litwin, Matthew Zeng, Max Johnson, Maya Shetty, Mayank Gupta, Meghan Shah, Mehmet Yatbaz, Meng Jia Yang, Mengchao Zhong, Mia Glaese, Mianna Chen, Michael Janner, Michael Lampe, Michael Petrov, Michael Wu, Michele Wang, Michelle Fradin, Michelle Pokrass, Miguel Castro, Miguel Oom Temudo de Castro, Mikhail Pavlov, Miles Brundage, Miles Wang, Minal Khan, Mira Murati, Mo Bavarian, Molly Lin, Murat Yesildal, Nacho Soto, Natalia Gimelshein, Natalie Cone, Natalie Staudacher, Natalie Summers, Natan LaFontaine, Neil Chowdhury, Nick Ryder, Nick Stathas, Nick Turley, Nik Tezak, Niko Felix, Nithanth Kudige, Nitish Keskar, Noah Deutsch, Noel Bundick, Nora Puckett, Ofir Nachum, Ola Okelola, Oleg Boiko, Oleg Murk, Oliver Jaffe, Olivia Watkins, Olivier Godement, Owen Campbell-Moore, Patrick Chao, Paul McMillan, Pavel Belov, Peng Su, Peter Bak, Peter Bakkum, Peter Deng, Peter Dolan, Peter Hoeschele, Peter Welinder, Phil Tillet, Philip Pronin, Philippe Tillet, Prafulla Dhariwal, Qiming Yuan, Rachel Dias, Rachel Lim, Rahul Arora, Rajan Troll, Randall Lin, Rapha Gontijo Lopes, Raul Puri, Reah Miyara, Reimar Leike, Renaud Gaubert, Reza Zamani, Ricky Wang, Rob Donnelly, Rob Honsby, Rocky Smith, Rohan Sahai, Rohit Ramchandani, Romain Huet, Rory Carmichael, Rowan Zellers, Roy Chen, Ruby Chen, Ruslan Nigmatullin, Ryan Cheu, Saachi Jain, Sam Altman, Sam Schoenholz, Sam Toizer, Samuel Miserendino, Sandhini Agarwal, Sara Culver, Scott Ethersmith, Scott Gray, Sean Grove, Sean Metzger, Shamez Hermani, Shantanu Jain, Shengjia Zhao, Sherwin Wu, Shino Jomoto, Shirong Wu, Shuaiqi, Xia, Sonia Phene, Spencer Papay, Srinivas Narayanan, Steve Coffey, Steve Lee, Stewart Hall, Suchir Balaji, Tal Broda, Tal Stramer, Tao Xu, Tarun Gogineni, Taya Christianson, Ted Sanders, Tejal Patwardhan, Thomas Cunninghman, Thomas Degry, Thomas Dimson, Thomas Raoux, Thomas Shadwell, Tianhao Zheng, Todd Underwood, Todor Markov, Toki Sherbakov, Tom Rubin, Tom Stasi, Tomer Kaftan, Tristan Heywood, Troy Peterson, Tyce Walters, Tyna Eloundou, Valerie Qi, Veit Moeller, Vinnie Monaco, Vishal Kuo, Vlad Fomenko, Wayne Chang, Weiyi Zheng, Wenda Zhou, Wesam Manassra, Will Sheu, Wojciech Zaremba, Yash Patil, Yilei Qian, Yongjik Kim, Youlong Cheng, Yu Zhang, Yuchen He, Yuchen Zhang, Yujia Jin, Yunxing Dai, Yury Malkov",http://arxiv.org/pdf/2410.21276v1,cs.CL
IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation,"Navigating efficiently to an object in an unexplored environment is a
critical skill for general-purpose intelligent robots. Recent approaches to
this object goal navigation problem have embraced a modular strategy,
integrating classical exploration algorithms-notably frontier exploration-with
a learned semantic mapping/exploration module. This paper introduces a novel
informative path planning and 3D object probability mapping approach. The
mapping module computes the probability of the object of interest through
semantic segmentation and a Bayes filter. Additionally, it stores probabilities
for common objects, which semantically guides the exploration based on common
sense priors from a large language model. The planner terminates when the
current viewpoint captures enough voxels identified with high confidence as the
object of interest. Although our planner follows a zero-shot approach, it
achieves state-of-the-art performance as measured by the Success weighted by
Path Length (SPL) and Soft SPL in the Habitat ObjectNav Challenge 2023,
outperforming other works by more than 20%. Furthermore, we validate its
effectiveness on real robots. Project webpage: https://ippon-paper.github.io/",2024-10-25,"Kaixian Qu, Jie Tan, Tingnan Zhang, Fei Xia, Cesar Cadena, Marco Hutter",http://arxiv.org/pdf/2410.19697v1,cs.CL
Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs,"Fine-tuning Large Language Models (LLMs) has become a crucial technique for
adapting pre-trained models to downstream tasks. However, the enormous size of
LLMs poses significant challenges in terms of computational complexity and
resource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising
solution. However, there exists a gap between the practical performance of
low-rank adaptations and its theoretical optimum. In this work, we propose
eXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this
gap by leveraging the power of ensemble learning. Inspired by gradient
boosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations
to refine model predictions. It achieves better performance than the standard
LoRA, while enjoying the computational efficiency of rank-1 adaptations. We
provide theoretical analysis to show the convergence and optimality of our
approach, and conduct extensive experiments on a range of natural language
processing tasks. The results demonstrate that XGBLoRA consistently outperforms
standard LoRA and achieves performance comparable to full fine-tuning with
significantly fewer trainable parameters. This work advances
parameter-efficient fine-tuning for LLMs, and offers a promising solution for
adapting LLMs to downstream tasks while optimizing performance and efficiency.",2024-10-25,"Yifei Zhang, Hao Zhu, Aiwei Liu, Han Yu, Piotr Koniusz, Irwin King",http://arxiv.org/pdf/2410.19694v1,cs.CL
AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs,"Generating diverse and effective clarifying questions is crucial for
improving query understanding and retrieval performance in open-domain
conversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration,
and evaluaTion of Clarifying Questions), an end-to-end LLM-based framework
addressing the challenges of scalability and adaptability faced by existing
methods that rely on manual curation or template-based approaches. AGENT-CQ
consists of two stages: a generation stage employing LLM prompting strategies
to generate clarifying questions, and an evaluation stage (CrowdLLM) that
simulates human crowdsourcing judgments using multiple LLM instances to assess
generated questions and answers based on comprehensive quality metrics.
Extensive experiments on the ClariQ dataset demonstrate CrowdLLM's
effectiveness in evaluating question and answer quality. Human evaluation and
CrowdLLM show that the AGENT-CQ - generation stage, consistently outperforms
baselines in various aspects of question and answer quality. In retrieval-based
evaluation, LLM-generated questions significantly enhance retrieval
effectiveness for both BM25 and cross-encoder models compared to
human-generated questions.",2024-10-25,"Clemencia Siro, Yifei Yuan, Mohammad Aliannejadi, Maarten de Rijke",http://arxiv.org/pdf/2410.19692v1,cs.CL
ProvocationProbe: Instigating Hate Speech Dataset from Twitter,"In the recent years online social media platforms has been flooded with
hateful remarks such as racism, sexism, homophobia etc. As a result, there have
been many measures taken by various social media platforms to mitigate the
spread of hate-speech over the internet. One particular concept within the
domain of hate speech is instigating hate, which involves provoking hatred
against a particular community, race, colour, gender, religion or ethnicity. In
this work, we introduce \textit{ProvocationProbe} - a dataset designed to
explore what distinguishes instigating hate speech from general hate speech.
For this study, we collected around twenty thousand tweets from Twitter,
encompassing a total of nine global controversies. These controversies span
various themes including racism, politics, and religion. In this paper, i) we
present an annotated dataset after comprehensive examination of all the
controversies, ii) we also highlight the difference between hate speech and
instigating hate speech by identifying distinguishing features, such as
targeted identity attacks and reasons for hate.",2024-10-25,"Abhay Kumar, Vigneshwaran Shankaran, Rajesh Sharma",http://arxiv.org/pdf/2410.19687v1,cs.CL
A distributional simplicity bias in the learning dynamics of transformers,"The remarkable capability of over-parameterised neural networks to generalise
effectively has been explained by invoking a ``simplicity bias'': neural
networks prevent overfitting by initially learning simple classifiers before
progressing to more complex, non-linear functions. While simplicity biases have
been described theoretically and experimentally in feed-forward networks for
supervised learning, the extent to which they also explain the remarkable
success of transformers trained with self-supervised techniques remains
unclear. In our study, we demonstrate that transformers, trained on natural
language data, also display a simplicity bias. Specifically, they sequentially
learn many-body interactions among input tokens, reaching a saturation point in
the prediction error for low-degree interactions while continuing to learn
high-degree interactions. To conduct this analysis, we develop a procedure to
generate \textit{clones} of a given natural language data set, which rigorously
capture the interactions between tokens up to a specified order. This approach
opens up the possibilities of studying how interactions of different orders in
the data affect learning, in natural language processing and beyond.",2024-10-25,"Riccardo Rende, Federica Gerace, Alessandro Laio, Sebastian Goldt",http://arxiv.org/pdf/2410.19637v2,cs.CL
"OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization","The rapid development of large language and multimodal models has sparked
significant interest in using proprietary models, such as GPT-4o, to develop
autonomous agents capable of handling real-world scenarios like web navigation.
Although recent open-source efforts have tried to equip agents with the ability
to explore environments and continuously improve over time, they are building
text-only agents in synthetic environments where the reward signals are clearly
defined. Such agents struggle to generalize to realistic settings that require
multimodal perception abilities and lack ground-truth signals. In this paper,
we introduce an open-source framework designed to facilitate the development of
multimodal web agent that can autonomously conduct real-world exploration and
improve itself. We first train the base model with imitation learning to gain
the basic abilities. We then let the agent explore the open web and collect
feedback on its trajectories. After that, it further improves its policy by
learning from well-performing trajectories judged by another general-purpose
model. This exploration-feedback-optimization cycle can continue for several
iterations. Experimental results show that our web agent successfully improves
itself after each iteration, demonstrating strong performance across multiple
test sets.",2024-10-25,"Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu",http://arxiv.org/pdf/2410.19609v1,cs.CL
ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems,"Retrieval-Augmented Generation (RAG) systems using large language models
(LLMs) often generate inaccurate responses due to the retrieval of irrelevant
or loosely related information. Existing methods, which operate at the document
level, fail to effectively filter out such content. We propose LLM-driven chunk
filtering, ChunkRAG, a framework that enhances RAG systems by evaluating and
filtering retrieved information at the chunk level. Our approach employs
semantic chunking to divide documents into coherent sections and utilizes
LLM-based relevance scoring to assess each chunk's alignment with the user's
query. By filtering out less pertinent chunks before the generation phase, we
significantly reduce hallucinations and improve factual accuracy. Experiments
show that our method outperforms existing RAG models, achieving higher accuracy
on tasks requiring precise information retrieval. This advancement enhances the
reliability of RAG systems, making them particularly beneficial for
applications like fact-checking and multi-hop reasoning.",2024-10-25,"Ishneet Sukhvinder Singh, Ritvik Aggarwal, Ibrahim Allahverdiyev, Muhammad Taha, Aslihan Akalin, Kevin Zhu, Sean O'Brien",http://arxiv.org/pdf/2410.19572v5,cs.CL
Mirror Matrix on the Wall: coding and vector notation as tools for introspection,"The vector notation adopted by GNU Octave plays a significant role as a tool
for introspection, aligning itself with the vision of Kenneth E. Iverson. He
believed that, just like mathematics, a programming language should be an
effective thinking tool for representing and reasoning about problems we wish
to address. This work aims to explore the use of vector notation in GNU Octave
through the analysis of operators and functions, providing a closer alignment
with mathematical notation and enhancing code efficiency. We will delve into
fundamental concepts such as indexing, broadcasting, and function handles, and
present case studies for a deeper understanding of these concepts. By adopting
vector notation, GNU Octave becomes a powerful tool for mathematicians,
scientists and engineers, enabling them to express and solve complex problems
more effectively and intuitively.",2024-10-25,Leonardo Araújo,http://arxiv.org/pdf/2410.19549v2,cs.CL
Detection of Human and Machine-Authored Fake News in Urdu,"The rise of social media has amplified the spread of fake news, now further
complicated by large language models (LLMs) like ChatGPT, which ease the
generation of highly convincing, error-free misinformation, making it
increasingly challenging for the public to discern truth from falsehood.
Traditional fake news detection methods relying on linguistic cues also becomes
less effective. Moreover, current detectors primarily focus on binary
classification and English texts, often overlooking the distinction between
machine-generated true vs. fake news and the detection in low-resource
languages. To this end, we updated detection schema to include
machine-generated news with focus on the Urdu language. We further propose a
hierarchical detection strategy to improve the accuracy and robustness.
Experiments show its effectiveness across four datasets in various settings.",2024-10-25,"Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony Smith",http://arxiv.org/pdf/2410.19517v1,cs.CL
SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models,"Despite the success of Large Language Models (LLMs), they still face
challenges related to high inference costs and memory requirements. To address
these issues, Knowledge Distillation (KD) has emerged as a popular method for
model compression, with student-generated outputs (SGOs) as training data being
particularly notable for reducing the mismatch between training and inference.
However, SGOs often produce noisy and biased sequences, which can lead to
misguidance from the teacher model, especially in long sequences. To mitigate
these challenges, we propose SWITCH (Studying WIth TeaCHer for Knowledge
Distillation), a novel approach that strategically incorporates the teacher
model during the student's sequence generation. SWITCH identifies discrepancies
between the token probabilities of the teacher and student models, allowing the
teacher to intervene selectively, particularly in long sequences that are more
prone to teacher misguidance. Extensive experimental results across three model
families and five instruction-following datasets show that SWITCH surpasses
traditional KD methods, particularly excelling in the generation of long
sequential data.",2024-10-25,"Jahyun Koo, Yerin Hwang, Yongil Kim, Taegwan Kang, Hyunkyung Bae, Kyomin Jung",http://arxiv.org/pdf/2410.19503v2,cs.CL
Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization,"Momentum-Aided Prompt Optimization (MAPO) enhances the efficiency and
efficacy of prompt optimization for Large Language Models (LLMs). Building on
ProTeGi, MAPO uses positive natural language ""gradients"" and a momentum-based
extension to refine prompts effectively. By tracking gradient history, MAPO
avoids local minima and oscillations. It also utilizes beam search and an Upper
Confidence Bound (UCB) algorithm for balanced candidate expansion and
selection. Benchmark testing shows that MAPO achieves faster convergence time
with fewer API calls and higher F1 scores than ProTeGi, proving it as a robust
and scalable solution for automated prompt engineering in LLMs.",2024-10-25,"Anthony Cui, Pranav Nandyalam, Ethan Cheung, Kevin Zhu",http://arxiv.org/pdf/2410.19499v2,cs.CL
Graph Linearization Methods for Reasoning on Graphs with Large Language Models,"Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph reasoning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term ""graph linearization"", so that LLMs can handle graphs
naturally. We consider that graphs should be linearized meaningfully to reflect
certain properties of natural language text, such as local dependency and
global alignment, in order to ease contemporary LLMs, trained on trillions of
textual tokens, better understand graphs. To achieve this, we developed several
graph linearization methods based on graph centrality and degeneracy. These
methods are further enhanced using node relabeling techniques. The experimental
results demonstrate the effectiveness of our methods compared to the random
linearization baseline. Our work introduces novel graph representations
suitable for LLMs, contributing to the potential integration of graph machine
learning with the trend of multimodal processing using a unified transformer
model.",2024-10-25,"Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis",http://arxiv.org/pdf/2410.19494v2,cs.CL
A Debate-Driven Experiment on LLM Hallucinations and Accuracy,"Large language models (LLMs) have achieved a degree of success in generating
coherent and contextually relevant text, yet they remain prone to a significant
challenge known as hallucination: producing information that is not
substantiated by the input or external knowledge. Previous efforts to mitigate
hallucinations have focused on techniques such as fine-tuning models on
high-quality datasets, incorporating fact-checking mechanisms, and developing
adversarial training methods. While these approaches have shown some promise,
they often address the issue at the level of individual model outputs, leaving
unexplored the effects of inter-model interactions on hallucination. This study
investigates the phenomenon of hallucination in LLMs through a novel
experimental framework where multiple instances of GPT-4o-Mini models engage in
a debate-like interaction prompted with questions from the TruthfulQA dataset.
One model is deliberately instructed to generate plausible but false answers
while the other models are asked to respond truthfully. The experiment is
designed to assess whether the introduction of misinformation by one model can
challenge the truthful majority to better justify their reasoning, improving
performance on the TruthfulQA benchmark. The findings suggest that inter-model
interactions can offer valuable insights into improving the accuracy and
robustness of LLM outputs, complementing existing mitigation strategies.",2024-10-25,"Ray Li, Tanishka Bagade, Kevin Martinez, Flora Yasmin, Grant Ayala, Michael Lam, Kevin Zhu",http://arxiv.org/pdf/2410.19485v1,cs.CL
ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework,"Although fine-tuning Large Language Models (LLMs) with multilingual data can
rapidly enhance the multilingual capabilities of LLMs, they still exhibit a
performance gap between the dominant language (e.g., English) and non-dominant
ones due to the imbalance of training data across languages. To further enhance
the performance of non-dominant languages, we propose ShifCon, a Shift-based
Contrastive framework that aligns the internal forward process of other
languages toward that of the dominant one. Specifically, it shifts the
representations of non-dominant languages into the dominant language subspace,
allowing them to access relatively rich information encoded in the model
parameters. The enriched representations are then shifted back into their
original language subspace before generation. Moreover, we introduce a subspace
distance metric to pinpoint the optimal layer area for shifting representations
and employ multilingual contrastive learning to further enhance the alignment
of representations within this area. Experiments demonstrate that our ShifCon
framework significantly enhances the performance of non-dominant languages,
particularly for low-resource ones. Further analysis offers extra insights to
verify the effectiveness of ShifCon and propel future research",2024-10-25,"Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei",http://arxiv.org/pdf/2410.19453v5,cs.CL
Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework,"This paper explores the application of prompt engineering to enhance the
performance of large language models (LLMs) in the domain of Traditional
Chinese Medicine (TCM). We propose TCM-Prompt, a framework that integrates
various pre-trained language models (PLMs), templates, tokenization, and
verbalization methods, allowing researchers to easily construct and fine-tune
models for specific TCM-related tasks. We conducted experiments on disease
classification, syndrome identification, herbal medicine recommendation, and
general NLP tasks, demonstrating the effectiveness and superiority of our
approach compared to baseline methods. Our findings suggest that prompt
engineering is a promising technique for improving the performance of LLMs in
specialized domains like TCM, with potential applications in digitalization,
modernization, and personalized medicine.",2024-10-25,"Yirui Chen, Qinyu Xiao, Jia Yi, Jing Chen, Mengyang Wang",http://arxiv.org/pdf/2410.19451v1,cs.CL
KAHANI: Culturally-Nuanced Visual Storytelling Tool for Non-Western Cultures,"Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated
the ability to generate compelling text and visual stories. However, their
outputs are predominantly aligned with the sensibilities of the Global North,
often resulting in an outsider's gaze on other cultures. As a result,
non-Western communities have to put extra effort into generating culturally
specific stories. To address this challenge, we developed a visual storytelling
tool called Kahani that generates culturally grounded visual stories for
non-Western cultures. Our tool leverages off-the-shelf models GPT-4 Turbo and
Stable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I prompting
techniques, we capture the cultural context from user's prompt and generate
vivid descriptions of the characters and scene compositions. To evaluate the
effectiveness of Kahani, we conducted a comparative user study with ChatGPT-4
(with DALL-E3) in which participants from different regions of India compared
the cultural relevance of stories generated by the two tools. The results of
the qualitative and quantitative analysis performed in the user study show that
Kahani's visual stories are more culturally nuanced than those generated by
ChatGPT-4. In 27 out of 36 comparisons, Kahani outperformed or was on par with
ChatGPT-4, effectively capturing cultural nuances and incorporating more
Culturally Specific Items (CSI), validating its ability to generate culturally
grounded visual stories.",2024-10-25,"Hamna, Deepthi Sudharsan, Agrima Seth, Ritvik Budhiraja, Deepika Khullar, Vyshak Jain, Kalika Bali, Aditya Vashistha, Sameer Segal",http://arxiv.org/pdf/2410.19419v3,cs.CL
Ensembling Finetuned Language Models for Text Classification,"Finetuning is a common practice widespread across different communities to
adapt pretrained models to particular tasks. Text classification is one of
these tasks for which many pretrained models are available. On the other hand,
ensembles of neural networks are typically used to boost performance and
provide reliable uncertainty estimates. However, ensembling pretrained models
for text classification is not a well-studied avenue. In this paper, we present
a metadataset with predictions from five large finetuned models on six
datasets, and report results of different ensembling strategies from these
predictions. Our results shed light on how ensembling can improve the
performance of finetuned text classifiers and incentivize future adoption of
ensembles in such tasks.",2024-10-25,"Sebastian Pineda Arango, Maciej Janowski, Lennart Purucker, Arber Zela, Frank Hutter, Josif Grabocka",http://arxiv.org/pdf/2410.19889v1,cs.CL
Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models,"Large Language Models (LLMs) are powerful computational models trained on
extensive corpora of human-readable text, enabling them to perform
general-purpose language understanding and generation. LLMs have garnered
significant attention in both industry and academia due to their exceptional
performance across various natural language processing (NLP) tasks. Despite
these successes, LLMs often produce inaccuracies, commonly referred to as
hallucinations. Prompt engineering, the process of designing and formulating
instructions for LLMs to perform specific tasks, has emerged as a key approach
to mitigating hallucinations. This paper provides a comprehensive empirical
evaluation of different prompting strategies and frameworks aimed at reducing
hallucinations in LLMs. Various prompting techniques are applied to a broad set
of benchmark datasets to assess the accuracy and hallucination rate of each
method. Additionally, the paper investigates the influence of tool-calling
agents (LLMs augmented with external tools to enhance their capabilities beyond
language generation) on hallucination rates in the same benchmarks. The
findings demonstrate that the optimal prompting technique depends on the type
of problem, and that simpler techniques often outperform more complex methods
in reducing hallucinations. Furthermore, it is shown that LLM agents can
exhibit significantly higher hallucination rates due to the added complexity of
external tool usage.",2024-10-25,"Liam Barkley, Brink van der Merwe",http://arxiv.org/pdf/2410.19385v1,cs.CL
Interleaving Text and Number Embeddings to Solve Mathemathics Problems,"Integrating text and numbers effectively is a crucial step towards enhancing
Large Language Models (LLMs) capabilities in assisting in scientific tasks.
While most current approaches rely on discrete tokenization of numbers, for
instance, conversion to scientific notation or base 10-decomposition, a recent
approach proposed a continuous numerical encoding as an inductive bias. In this
paper, we build upon this approach by introducing more expressive numerical
embeddings. Our method addresses key shortcomings, including the elimination of
numerical artefacts and the ability to handle a wide range of magnitudes
without clipping.
  Our work presents two key contributions. First, we employ an MLP to assign
distinct directions in the embedding space to different numbers. Our second
contribution is the introduction of a routing layer that differentiates between
numerical and text embeddings. We hypothesise that this combined approach
enables the model to distinguish between text and number distributions while
maintaining its capacity for arithmetic operations.
  Using only a 45 M parameter encoder-decoder architecture our method achieves
a $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition,
we empirically observe a reduction of the numerical artefacts and biases
observed compared to the baselines.",2024-10-25,"Marvin Alberts, Gianmarco Gabrieli, Irina Espejo Morales",http://arxiv.org/pdf/2410.19353v1,cs.CL
AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios,"Large language models (LLMs) are increasingly leveraged to empower autonomous
agents to simulate human beings in various fields of behavioral research.
However, evaluating their capacity to navigate complex social interactions
remains a challenge. Previous studies face limitations due to insufficient
scenario diversity, complexity, and a single-perspective focus. To this end, we
introduce AgentSense: Benchmarking Social Intelligence of Language Agents
through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense
employs a bottom-up approach to create 1,225 diverse social scenarios
constructed from extensive scripts. We evaluate LLM-driven agents through
multi-turn interactions, emphasizing both goal completion and implicit
reasoning. We analyze goals using ERG theory and conduct comprehensive
experiments. Our findings highlight that LLMs struggle with goals in complex
social scenarios, especially high-level growth needs, and even GPT-4o requires
improvement in private information reasoning. Code and data are available at
\url{https://github.com/ljcleo/agent_sense}.",2024-10-25,"Xinyi Mou, Jingcong Liang, Jiayu Lin, Xinnong Zhang, Xiawei Liu, Shiyue Yang, Rong Ye, Lei Chen, Haoyu Kuang, Xuanjing Huang, Zhongyu Wei",http://arxiv.org/pdf/2410.19346v2,cs.CL
Two are better than one: Context window extension with multi-grained self-injection,"The limited context window of contemporary large language models (LLMs)
remains a huge barrier to their broader application across various domains.
While continual pre-training on long-context data is a straightforward and
effective solution, it incurs substantial costs in terms of data acquisition
and computational resources. To alleviate this issue, we propose SharedLLM, a
novel approach grounded in the design philosophy of multi-grained context
compression and query-aware information retrieval. SharedLLM is composed of two
short-context LLMs such as LLaMA-2, termed upper model and lower model. The
lower model functions as a compressor while the upper model acts as a decoder.
The upper model receives compressed, multi-grained context information from the
lower model and performs context-aware modeling on the running text.
Information transfer between the compressor and decoder occurs only at the
lowest layers to refrain from long forward paths in the lower model and
redundant cross-attention modules in the upper model. Based on this
architecture, we introduce a specialized tree-style data structure to
efficiently encode, store and retrieve multi-grained contextual information for
text chunks. This structure, combined with a search algorithm, enables rapid
encoding and retrieval of relevant information from various levels of the tree
based on the input query. This entire process, wherein the sender and receiver
are derived from the same LLM layer, is referred to as self-injection.",2024-10-25,"Wei Han, Pan Zhou, Soujanya Poria, Shuicheng Yan",http://arxiv.org/pdf/2410.19318v1,cs.CL
FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs,"The growing use of large language model (LLM)-based chatbots has raised
concerns about fairness. Fairness issues in LLMs can lead to severe
consequences, such as bias amplification, discrimination, and harm to
marginalized communities. While existing fairness benchmarks mainly focus on
single-turn dialogues, multi-turn scenarios, which in fact better reflect
real-world conversations, present greater challenges due to conversational
complexity and potential bias accumulation. In this paper, we propose a
comprehensive fairness benchmark for LLMs in multi-turn dialogue scenarios,
\textbf{FairMT-Bench}. Specifically, we formulate a task taxonomy targeting LLM
fairness capabilities across three stages: context understanding, user
interaction, and instruction trade-offs, with each stage comprising two tasks.
To ensure coverage of diverse bias types and attributes, we draw from existing
fairness datasets and employ our template to construct a multi-turn dialogue
dataset, \texttt{FairMT-10K}. For evaluation, GPT-4 is applied, alongside bias
classifiers including Llama-Guard-3 and human validation to ensure robustness.
Experiments and analyses on \texttt{FairMT-10K} reveal that in multi-turn
dialogue scenarios, current LLMs are more likely to generate biased responses,
and there is significant variation in performance across different tasks and
models. Based on this, we curate a challenging dataset, \texttt{FairMT-1K}, and
test 15 current state-of-the-art (SOTA) LLMs on this dataset. The results show
the current state of fairness in LLMs and showcase the utility of this novel
approach for assessing fairness in more realistic multi-turn dialogue contexts,
calling for future work to focus on LLM fairness improvement and the adoption
of \texttt{FairMT-1K} in such efforts.",2024-10-25,"Zhiting Fan, Ruizhe Chen, Tianxiang Hu, Zuozhu Liu",http://arxiv.org/pdf/2410.19317v1,cs.CL
Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs),"Pre-trained large language models (LLMs) have been reliably integrated with
visual input for multimodal tasks. The widespread adoption of instruction-tuned
image-to-text vision-language assistants (VLAs) like LLaVA and InternVL
necessitates evaluating gender biases. We study gender bias in 22 popular
open-source VLAs with respect to personality traits, skills, and occupations.
Our results show that VLAs replicate human biases likely present in the data,
such as real-world occupational imbalances. Similarly, they tend to attribute
more skills and positive personality traits to women than to men, and we see a
consistent tendency to associate negative personality traits with men. To
eliminate the gender bias in these models, we find that fine-tuning-based
debiasing methods achieve the best trade-off between debiasing and retaining
performance on downstream tasks. We argue for pre-deploying gender bias
assessment in VLAs and motivate further development of debiasing strategies to
ensure equitable societal outcomes. Code is available at
https://github.com/ExplainableML/vla-gender-bias.",2024-10-25,"Leander Girrbach, Stephan Alaniz, Yiran Huang, Trevor Darrell, Zeynep Akata",http://arxiv.org/pdf/2410.19314v2,cs.CL
"Any Other Thoughts, Hedgehog? Linking Deliberation Chains in Collaborative Dialogues","Question-asking in collaborative dialogue has long been established as key to
knowledge construction, both in internal and collaborative problem solving. In
this work, we examine probing questions in collaborative dialogues: questions
that explicitly elicit responses from the speaker's interlocutors.
Specifically, we focus on modeling the causal relations that lead directly from
utterances earlier in the dialogue to the emergence of the probing question. We
model these relations using a novel graph-based framework of deliberation
chains, and reframe the problem of constructing such chains as a
coreference-style clustering problem. Our framework jointly models probing and
causal utterances and the links between them, and we evaluate on two
challenging collaborative task datasets: the Weights Task and DeliData. Our
results demonstrate the effectiveness of our theoretically-grounded approach
compared to both baselines and stronger coreference approaches, and establish a
standard of performance in this novel task.",2024-10-25,"Abhijnan Nath, Videep Venkatesha, Mariah Bradford, Avyakta Chelle, Austin Youngren, Carlos Mabrey, Nathaniel Blanchard, Nikhil Krishnaswamy",http://arxiv.org/pdf/2410.19301v1,cs.CL
Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning,"Recent studies have identified one aggravating factor of LLM hallucinations
as the knowledge inconsistency between pre-training and fine-tuning, where
unfamiliar fine-tuning data mislead the LLM to fabricate plausible but wrong
outputs. In this paper, we propose a novel fine-tuning strategy called
Prereq-Tune to address this knowledge inconsistency and reduce hallucinations.
Fundamentally, Prereq-Tune disentangles the learning of skills and knowledge,
so the model learns only the task skills without being impacted by the
knowledge inconsistency. To achieve this, Prereq-Tune introduces an additional
prerequisite learning stage to learn the necessary knowledge for SFT, allowing
subsequent SFT to focus only on task skills. Prereq-Tune can also be combined
with fictitious synthetic data to enhance the grounding of LLM outputs to their
internal knowledge. Experiments show that Prereq-Tune outperforms existing
baselines in improving LLM's factuality across short QA and long-form
generation tasks. It also opens new possibilities for knowledge-controlled
generation in LLMs. Our code is available at
https://github.com/UCSB-NLP-Chang/Prereq_tune.git.",2024-10-25,"Yujian Liu, Shiyu Chang, Tommi Jaakkola, Yang Zhang",http://arxiv.org/pdf/2410.19290v1,cs.CL
Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning,"Key-Value (KV) caching is a common technique to enhance the computational
efficiency of Large Language Models (LLMs), but its memory overhead grows
rapidly with input length. Prior work has shown that not all tokens are equally
important for text generation, proposing layer-level KV cache compression to
selectively retain key information. Recognizing the distinct roles of attention
heads in generation, we propose HeadKV, a head-level KV cache compression
method, and HeadKV-R2, which leverages a novel contextual reasoning ability
estimation for compression. Our approach operates at the level of individual
heads, estimating their importance for contextual QA tasks that require both
retrieval and reasoning capabilities. Extensive experiments across diverse
benchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct,
Mistral-7B-Instruct), and long-context abilities tests demonstrate that our
head-level KV cache compression significantly outperforms strong baselines,
particularly in low-resource settings (KV size = 64 & 128). Notably, our method
retains just 1.5% of the KV cache while achieving 97% of the performance of the
full KV cache on the contextual question answering benchmark.Codes are
available at https://github.com/FYYFU/HeadKV",2024-10-25,"Yu Fu, Zefan Cai, Abedelkadir Asi, Wayne Xiong, Yue Dong, Wen Xiao",http://arxiv.org/pdf/2410.19258v3,cs.CL
Have LLMs Reopened the Pandora's Box of AI-Generated Fake News?,"With the rise of AI-generated content spewed at scale from large language
models (LLMs), genuine concerns about the spread of fake news have intensified.
The perceived ability of LLMs to produce convincing fake news at scale poses
new challenges for both human and automated fake news detection systems. To
address this gap, this paper presents the findings from a university-level
competition that aimed to explore how LLMs can be used by humans to create fake
news, and to assess the ability of human annotators and AI models to detect it.
A total of 110 participants used LLMs to create 252 unique fake news stories,
and 84 annotators participated in the detection tasks. Our findings indicate
that LLMs are ~68% more effective at detecting real news than humans. However,
for fake news detection, the performance of LLMs and humans remains comparable
(~60% accuracy). Additionally, we examine the impact of visual elements (e.g.,
pictures) in news on the accuracy of detecting fake news stories. Finally, we
also examine various strategies used by fake news creators to enhance the
credibility of their AI-generated content. This work highlights the increasing
complexity of detecting AI-generated fake news, particularly in collaborative
human-AI settings.",2024-10-25,"Xinyu Wang, Wenbo Zhang, Sai Koneru, Hangzhi Guo, Bonam Mingole, S. Shyam Sundar, Sarah Rajtmajer, Amulya Yadav",http://arxiv.org/pdf/2410.19250v2,cs.CL
"Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models, and Challenges","Natural Language Processing (NLP) is revolutionising the way legal
professionals and laypersons operate in the legal field. The considerable
potential for NLP in the legal sector, especially in developing computational
tools for various legal processes, has captured the interest of researchers for
years. This survey follows the Preferred Reporting Items for Systematic Reviews
and Meta-Analyses framework, reviewing 154 studies, with a final selection of
133 after manual filtering. It explores foundational concepts related to NLP in
the legal domain, illustrating the unique aspects and challenges of processing
legal texts, such as extensive document length, complex language, and limited
open legal datasets. We provide an overview of NLP tasks specific to legal
text, such as Legal Document Summarisation, legal Named Entity Recognition,
Legal Question Answering, Legal Argument Mining, Legal Text Classification, and
Legal Judgement Prediction. In the section on legal Language Models (LMs), we
analyse both developed LMs and approaches for adapting general LMs to the legal
domain. Additionally, we identify 16 Open Research Challenges, including bias
in Artificial Intelligence applications, the need for more robust and
interpretable models, and improving explainability to handle the complexities
of legal language and reasoning.",2024-10-25,"Farid Ariai, Gianluca Demartini",http://arxiv.org/pdf/2410.21306v2,cs.CL
Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use,"Recent advances in large language models (LLMs) have shown promise for
scalable educational applications, but their use in dialog-based tutoring
systems remains challenging due to the need for effective pedagogical
strategies and the high costs associated with expert-curated datasets. Our
study explores the use of smaller, more affordable LLMs for one-on-one tutoring
in the context of solving reading comprehension problems. We developed a
synthetic tutoring dialog dataset, evaluated by human teachers, and fine-tuned
a smaller LLM using this dataset. Furthermore, we conducted an interactive
experiment comparing the performance of the fine-tuned model with a larger
model in real-world tutoring scenarios. Our results show that the fine-tuned
model performs on par with the larger model but at a lower cost, demonstrating
a viable, cost-effective approach for implementing LLM-based tutoring systems
in educational settings.",2024-10-25,"Menna Fateen, Tsunenori Mine",http://arxiv.org/pdf/2410.19231v1,cs.CL
Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors,"The advent of large language models (LLMs) has revolutionized the field of
text generation, producing outputs that closely mimic human-like writing.
Although academic and industrial institutions have developed detectors to
prevent the malicious usage of LLM-generated texts, other research has doubt
about the robustness of these systems. To stress test these detectors, we
introduce a proxy-attack strategy that effortlessly compromises LLMs, causing
them to produce outputs that align with human-written text and mislead
detection systems. Our method attacks the source model by leveraging a
reinforcement learning (RL) fine-tuned humanized small language model (SLM) in
the decoding phase. Through an in-depth analysis, we demonstrate that our
attack strategy is capable of generating responses that are indistinguishable
to detectors, preventing them from differentiating between machine-generated
and human-written text. We conduct systematic evaluations on extensive datasets
using proxy-attacked open-source models, including Llama2-13B, Llama3-70B, and
Mixtral-8*7B in both white- and black-box settings. Our findings show that the
proxy-attack strategy effectively deceives the leading detectors, resulting in
an average AUROC drop of 70.4% across multiple datasets, with a maximum drop of
90.3% on a single dataset. Furthermore, in cross-discipline scenarios, our
strategy also bypasses these detectors, leading to a significant relative
decrease of up to 90.9%, while in cross-language scenario, the drop reaches
91.3%. Despite our proxy-attack strategy successfully bypassing the detectors
with such significant relative drops, we find that the generation quality of
the attacked models remains preserved, even within a modest utility budget,
when compared to the text produced by the original, unattacked source model.",2024-10-25,"Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng",http://arxiv.org/pdf/2410.19230v2,cs.CL
Can Stories Help LLMs Reason? Curating Information Space Through Narrative,"Narratives are widely recognized as a powerful tool for structuring
information and facilitating comprehension of complex ideas in various domains
such as science communication. This paper investigates whether incorporating
narrative elements can assist Large Language Models (LLMs) in solving complex
problems more effectively. We propose a novel approach, Story of Thought (SoT),
integrating narrative structures into prompting techniques for problem-solving.
This approach involves constructing narratives around problem statements and
creating a framework to identify and organize relevant information. Our
experiments show that using various LLMs with SoT consistently surpasses using
them with other techniques on physics, chemistry, math, and biology questions
in both the GPQA and JEEBench datasets. The narrative-based information
curation process in SoT enhances problem comprehension by contextualizing
critical in-domain information and highlighting causal relationships within the
problem space.",2024-10-25,"Vahid Sadiri Javadi, Johanne R. Trippas, Yash Kumar Lal, Lucie Flek",http://arxiv.org/pdf/2410.19221v1,cs.CL
Inference time LLM alignment in single and multidomain preference spectrum,"Aligning Large Language Models (LLM) to address subjectivity and nuanced
preference levels requires adequate flexibility and control, which can be a
resource-intensive and time-consuming procedure. Existing training-time
alignment methods require full re-training when a change is needed and
inference-time ones typically require access to the reward model at each
inference step. To address these limitations, we introduce inference-time model
alignment method that learns encoded representations of preference dimensions,
called \textit{Alignment Vectors} (AV). These representations are computed by
subtraction of the base model from the aligned model as in model editing
enabling dynamically adjusting the model behavior during inference through
simple linear operations. Even though the preference dimensions can span
various granularity levels, here we focus on three gradual response levels
across three specialized domains: medical, legal, and financial, exemplifying
its practical potential. This new alignment paradigm introduces adjustable
preference knobs during inference, allowing users to tailor their LLM outputs
while reducing the inference cost by half compared to the prompt engineering
approach. Additionally, we find that AVs are transferable across different
fine-tuning stages of the same model, demonstrating their flexibility. AVs also
facilitate multidomain, diverse preference alignment, making the process 12x
faster than the retraining approach.",2024-10-24,"Sadat Shahriar, Zheng Qi, Nikolaos Pappas, Srikanth Doss, Monica Sunkara, Kishaloy Halder, Manuel Mager, Yassine Benajiba",http://arxiv.org/pdf/2410.19206v1,cs.CL
Making Social Platforms Accessible: Emotion-Aware Speech Generation with Integrated Text Analysis,"Recent studies have outlined the accessibility challenges faced by blind or
visually impaired, and less-literate people, in interacting with social
networks, in-spite of facilitating technologies such as monotone text-to-speech
(TTS) screen readers and audio narration of visual elements such as emojis.
Emotional speech generation traditionally relies on human input of the expected
emotion together with the text to synthesise, with additional challenges around
data simplification (causing information loss) and duration inaccuracy, leading
to lack of expressive emotional rendering. In real-life communications, the
duration of phonemes can vary since the same sentence might be spoken in a
variety of ways depending on the speakers' emotional states or accents
(referred to as the one-to-many problem of text to speech generation). As a
result, an advanced voice synthesis system is required to account for this
unpredictability. We propose an end-to-end context-aware Text-to-Speech (TTS)
synthesis system that derives the conveyed emotion from text input and
synthesises audio that focuses on emotions and speaker features for natural and
expressive speech, integrating advanced natural language processing (NLP) and
speech synthesis techniques for real-time applications. Our system also
showcases competitive inference time performance when benchmarked against the
state-of-the-art TTS models, making it suitable for real-time accessibility
applications.",2024-10-24,"Suparna De, Ionut Bostan, Nishanth Sastry",http://arxiv.org/pdf/2410.19199v1,cs.CL
Label Set Optimization via Activation Distribution Kurtosis for Zero-shot Classification with Generative Models,"In-context learning (ICL) performance is known to be sensitive to the prompt
design, yet the impact of class label options in zero-shot classification has
been largely overlooked. This study presents the first comprehensive empirical
study investigating how label option (e.g., lexical choice, order, and
elaboration) influences zero-shot ICL classification performance. Our findings
reveal that lexical choices for label names (e.g., agree vs.support in stance
classification) play an important role, with effects also linked to label
orders. An analysis of the model internal states further shows that optimal
label names tend to activate fewer outlier neurons in the feed forward network.
Based on this observation, we propose Label set Optimization via Activation
Distribution kurtosiS (LOADS), a post-hoc approach requiring no gradient
propagation. LOADS not only demonstrates effectiveness with only 100 unlabelled
samples across different model types and sizes, but also shows cross-lingual
transferability.",2024-10-24,"Yue Li, Zhixue Zhao, Carolina Scarton",http://arxiv.org/pdf/2410.19195v1,cs.CL
Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media,"Disinformation on social media poses both societal and technical challenges,
requiring robust detection systems. While previous studies have integrated
textual information into propagation networks, they have yet to fully leverage
the advancements in Transformer-based language models for high-quality
contextual text representations. This work addresses this gap by incorporating
Transformer-based textual features into Graph Neural Networks (GNNs) for fake
news detection. We demonstrate that contextual text representations enhance GNN
performance, achieving 33.8% relative improvement in Macro F1 over models
without textual features and 9.3% over static text representations. We further
investigate the impact of different feature sources and the effects of noisy
data augmentation. We expect our methodology to open avenues for further
research, and we made code publicly available.",2024-10-24,"Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes",http://arxiv.org/pdf/2410.19193v2,cs.CL
No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts,"In a context where the Brazilian judiciary system, the largest in the world,
faces a crisis due to the slow processing of millions of cases, it becomes
imperative to develop efficient methods for analyzing legal texts. We introduce
uBERT, a hybrid model that combines Transformer and Recurrent Neural Network
architectures to effectively handle long legal texts. Our approach processes
the full text regardless of its length while maintaining reasonable
computational overhead. Our experiments demonstrate that uBERT achieves
superior performance compared to BERT+LSTM when overlapping input is used and
is significantly faster than ULMFiT for processing long legal documents.",2024-10-24,"Israel Fama, Bárbara Bueno, Alexandre Alcoforado, Thomas Palmeira Ferraz, Arnold Moya, Anna Helena Reali Costa",http://arxiv.org/pdf/2410.19184v2,cs.CL
Critical biblical studies via word frequency analysis: unveiling text authorship,"The Bible, a product of an extensive and intricate process of oral-written
transmission spanning centuries, obscures the contours of its earlier
recensions. Debate rages over determining the existing layers and identifying
the date of composition and historical background of the biblical texts.
Traditional manual methodologies have grappled with authorship challenges
through scrupulous textual criticism, employing linguistic, stylistic,
inner-biblical, and historical criteria. Despite recent progress in
computer-assisted analysis, many patterns still need to be uncovered in
Biblical Texts. In this study, we address the question of authorship of
biblical texts by employing statistical analysis to the frequency of words
using a method that is particularly sensitive to deviations in frequencies
associated with a few words out of potentially many. We aim to differentiate
between three distinct authors across numerous chapters spanning the first nine
books of the Bible. In particular, we examine 50 chapters labeled according to
biblical exegesis considerations into three corpora (D, DtrH, and P). Without
prior assumptions about author identity, our approach leverages subtle
differences in word frequencies to distinguish among the three corpora and
identify author-dependent linguistic properties. Our analysis indicates that
the first two authors (D and DtrH) are much more closely related compared to P,
a fact that aligns with expert assessments. Additionally, we attain high
accuracy in attributing authorship by evaluating the similarity of each chapter
with the reference corpora. This study sheds new light on the authorship of
biblical texts by providing interpretable, statistically significant evidence
that there are different linguistic characteristics of biblical authors and
that these differences can be identified.",2024-10-24,"Shira Faigenbaum-Golovin, Alon Kipnis, Axel Bühler, Eli Piasetzky, Thomas Römer, Israel Finkelstein",http://arxiv.org/pdf/2410.19883v1,cs.CL
Indication Finding: a novel use case for representation learning,"Many therapies are effective in treating multiple diseases. We present an
approach that leverages methods developed in natural language processing and
real-world data to prioritize potential, new indications for a mechanism of
action (MoA). We specifically use representation learning to generate
embeddings of indications and prioritize them based on their proximity to the
indications with the strongest available evidence for the MoA. We demonstrate
the successful deployment of our approach for anti-IL-17A using embeddings
generated with SPPMI and present an evaluation framework to determine the
quality of indication finding results and the derived embeddings.",2024-10-24,"Maren Eckhoff, Valmir Selimi, Alexander Aranovitch, Ian Lyons, Emily Briggs, Jennifer Hou, Alex Devereson, Matej Macak, David Champagne, Chris Anagnostopoulos",http://arxiv.org/pdf/2410.19174v1,cs.CL
MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark,"The ability to comprehend audio--which includes speech, non-speech sounds,
and music--is crucial for AI agents to interact effectively with the world. We
present MMAU, a novel benchmark designed to evaluate multimodal audio
understanding models on tasks requiring expert-level knowledge and complex
reasoning. MMAU comprises 10k carefully curated audio clips paired with
human-annotated natural language questions and answers spanning speech,
environmental sounds, and music. It includes information extraction and
reasoning questions, requiring models to demonstrate 27 distinct skills across
unique and challenging tasks. Unlike existing benchmarks, MMAU emphasizes
advanced perception and reasoning with domain-specific knowledge, challenging
models to tackle tasks akin to those faced by experts. We assess 18 open-source
and proprietary (Large) Audio-Language Models, demonstrating the significant
challenges posed by MMAU. Notably, even the most advanced Gemini Pro v1.5
achieves only 52.97% accuracy, and the state-of-the-art open-source Qwen2-Audio
achieves only 52.50%, highlighting considerable room for improvement. We
believe MMAU will drive the audio and multimodal research community to develop
more advanced audio understanding models capable of solving complex audio
tasks.",2024-10-24,"S Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, Sreyan Ghosh, Dinesh Manocha",http://arxiv.org/pdf/2410.19168v1,cs.CL
Adversarial Attacks on Large Language Models Using Regularized Relaxation,"As powerful Large Language Models (LLMs) are now widely used for numerous
practical applications, their safety is of critical importance. While alignment
techniques have significantly improved overall safety, LLMs remain vulnerable
to carefully crafted adversarial inputs. Consequently, adversarial attack
methods are extensively used to study and understand these vulnerabilities.
However, current attack methods face significant limitations. Those relying on
optimizing discrete tokens suffer from limited efficiency, while continuous
optimization techniques fail to generate valid tokens from the model's
vocabulary, rendering them impractical for real-world applications. In this
paper, we propose a novel technique for adversarial attacks that overcomes
these limitations by leveraging regularized gradients with continuous
optimization methods. Our approach is two orders of magnitude faster than the
state-of-the-art greedy coordinate gradient-based method, significantly
improving the attack success rate on aligned language models. Moreover, it
generates valid tokens, addressing a fundamental limitation of existing
continuous optimization methods. We demonstrate the effectiveness of our attack
on five state-of-the-art LLMs using four datasets.",2024-10-24,"Samuel Jacob Chacko, Sajib Biswas, Chashi Mahiul Islam, Fatema Tabassum Liza, Xiuwen Liu",http://arxiv.org/pdf/2410.19160v1,cs.CL
Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use,"Adverse Drug Reactions (ADRs) from psychiatric medications are the leading
cause of hospitalizations among mental health patients. With healthcare systems
and online communities facing limitations in resolving ADR-related issues,
Large Language Models (LLMs) have the potential to fill this gap. Despite the
increasing capabilities of LLMs, past research has not explored their
capabilities in detecting ADRs related to psychiatric medications or in
providing effective harm reduction strategies. To address this, we introduce
the Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment
(ADRA) framework to systematically evaluate LLM performance in detecting ADR
expressions and delivering expert-aligned mitigation strategies. Our analyses
show that LLMs struggle with understanding the nuances of ADRs and
differentiating between types of ADRs. While LLMs align with experts in terms
of expressed emotions and tone of the text, their responses are more complex,
harder to read, and only 70.86% aligned with expert strategies. Furthermore,
they provide less actionable advice by a margin of 12.32% on average. Our work
provides a comprehensive benchmark and evaluation framework for assessing LLMs
in strategy-driven tasks within high-risk domains.",2024-10-24,"Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury",http://arxiv.org/pdf/2410.19155v3,cs.CL
A Test of Time: Predicting the Sustainable Success of Online Collaboration in Wikipedia,"The Internet has significantly expanded the potential for global
collaboration, allowing millions of users to contribute to collective projects
like Wikipedia. While prior work has assessed the success of online
collaborations, most approaches are time-agnostic, evaluating success without
considering its longevity. Research on the factors that ensure the long-term
preservation of high-quality standards in online collaboration is scarce. In
this study, we address this gap. We propose a novel metric, `Sustainable
Success,' which measures the ability of collaborative efforts to maintain their
quality over time. Using Wikipedia as a case study, we introduce the
SustainPedia dataset, which compiles data from over 40K Wikipedia articles,
including each article's sustainable success label and more than 300
explanatory features such as edit history, user experience, and team
composition. Using this dataset, we develop machine learning models to predict
the sustainable success of Wikipedia articles. Our best-performing model
achieves a high AU-ROC score of 0.88 on average. Our analysis reveals important
insights. For example, we find that the longer an article takes to be
recognized as high-quality, the more likely it is to maintain that status over
time (i.e., be sustainable). Additionally, user experience emerged as the most
critical predictor of sustainability. Our analysis provides insights into
broader collective actions beyond Wikipedia (e.g., online activism,
crowdsourced open-source software), where the same social dynamics that drive
success on Wikipedia might play a role. We make all data and code used for this
study publicly available for further research.",2024-10-24,"Abraham Israeli, David Jurgens, Daniel Romero",http://arxiv.org/pdf/2410.19150v2,cs.CL
Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant,"We revisit knowledge-aware text-based visual question answering, also known
as Text-KVQA, in the light of modern advancements in large multimodal models
(LMMs), and make the following contributions: (i) We propose VisTEL - a
principled approach to perform visual text entity linking. The proposed VisTEL
module harnesses a state-of-the-art visual text recognition engine and the
power of a large multimodal model to jointly reason using textual and visual
context obtained using surrounding cues in the image to link the visual text
entity to the correct knowledge base entity. (ii) We present KaLMA - a
knowledge-aware large multimodal assistant that augments an LMM with knowledge
associated with visual text entity in the image to arrive at an accurate
answer. Further, we provide a comprehensive experimental analysis and
comparison of our approach with traditional visual question answering,
pre-large multimodal models, and large multimodal models, as well as prior
top-performing approaches. Averaging over three splits of Text-KVQA, our
proposed approach surpasses the previous best approach by a substantial 23.3%
on an absolute scale and establishes a new state of the art. We make our
implementation publicly available.",2024-10-24,"Abhirama Subramanyam Penamakuri, Anand Mishra",http://arxiv.org/pdf/2410.19144v1,cs.CL
AlignCap: Aligning Speech Emotion Captioning to Human Preferences,"Speech Emotion Captioning (SEC) has gradually become an active research task.
The emotional content conveyed through human speech are often complex, and
classifying them into fixed categories may not be enough to fully capture
speech emotions. Describing speech emotions through natural language may be a
more effective approach. However, existing SEC methods often produce
hallucinations and lose generalization on unseen speech. To overcome these
problems, we propose AlignCap, which Aligning Speech Emotion Captioning to
Human Preferences based on large language model (LLM) with two properties: 1)
Speech-Text Alignment, which minimizing the divergence between the LLM's
response prediction distributions for speech and text inputs using knowledge
distillation (KD) Regularization. 2) Human Preference Alignment, where we
design Preference Optimization (PO) Regularization to eliminate factuality and
faithfulness hallucinations. We also extract emotional clues as a prompt for
enriching fine-grained information under KD-Regularization. Experiments
demonstrate that AlignCap presents stronger performance to other
state-of-the-art methods on Zero-shot SEC task.",2024-10-24,"Ziqi Liang, Haoxiang Shi, Hanhui Chen",http://arxiv.org/pdf/2410.19134v1,cs.CL
Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback,"Learning from human feedback has enabled the alignment of language models
(LMs) with human preferences. However, collecting human preferences is
expensive and time-consuming, with highly variable annotation quality. An
appealing alternative is to distill preferences from LMs as a source of
synthetic annotations, offering a cost-effective and scalable alternative,
albeit susceptible to other biases and errors. In this work, we introduce
HyPER, a Hybrid Preference routER that defers an annotation to either humans or
LMs, achieving better annotation quality while reducing the cost of human-only
annotation. We formulate this as an optimization problem: given a preference
dataset and an evaluation metric, we (1) train a performance prediction model
(PPM) to predict a reward model's (RM) performance on an arbitrary combination
of human and LM annotations and (2) employ a routing strategy that selects a
combination that maximizes the predicted performance. We train the PPM on
MultiPref, a new preference dataset with 10k instances paired with humans and
LM labels. We show that the selected hybrid mixture of synthetic and direct
human preferences using HyPER achieves better RM performance compared to using
either one exclusively by 7-13% on RewardBench and generalizes across unseen
preference datasets and other base models. We also observe the same trend in
other benchmarks using Best-of-N reranking, where the hybrid mix has 2-3%
better performance. Finally, we analyze features from HyPER and find that
prompts with moderate safety concerns or complexity benefit the most from human
feedback.",2024-10-24,"Lester James V. Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi",http://arxiv.org/pdf/2410.19133v4,cs.CL
Retrieving Implicit and Explicit Emotional Events Using Large Language Models,"Large language models (LLMs) have garnered significant attention in recent
years due to their impressive performance. While considerable research has
evaluated these models from various perspectives, the extent to which LLMs can
perform implicit and explicit emotion retrieval remains largely unexplored. To
address this gap, this study investigates LLMs' emotion retrieval capabilities
in commonsense. Through extensive experiments involving multiple models, we
systematically evaluate the ability of LLMs on emotion retrieval. Specifically,
we propose a supervised contrastive probing method to verify LLMs' performance
for implicit and explicit emotion retrieval, as well as the diversity of the
emotional events they retrieve. The results offer valuable insights into the
strengths and limitations of LLMs in handling emotion retrieval.",2024-10-24,"Guimin Hu, Hasti Seifi",http://arxiv.org/pdf/2410.19128v3,cs.CL
Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design,"The proliferation of large language models (LLMs) has led to the adoption of
Mixture-of-Experts (MoE) architectures that dynamically leverage specialized
subnetworks for improved efficiency and performance. Despite their benefits,
MoE models face significant challenges during inference, including inefficient
memory management and suboptimal batching, due to misaligned design choices
between the model architecture and the system policies. Furthermore, the
conventional approach of training MoEs from scratch is increasingly prohibitive
in terms of cost. In this paper, we propose a novel framework Read-ME that
transforms pre-trained dense LLMs into smaller MoE models (in contrast to
""upcycling"" generalist MoEs), avoiding the high costs of ground-up training.
Our approach employs activation sparsity to extract experts. To compose
experts, we examine the widely-adopted layer-wise router design and show its
redundancy, and thus we introduce the pre-gating router decoupled from the MoE
backbone that facilitates system-friendly pre-computing and lookahead
scheduling, enhancing expert-aware batching and caching. Our codesign therefore
addresses critical gaps on both the algorithmic and system fronts, establishing
a scalable and efficient alternative for LLM inference in resource-constrained
settings. Read-ME outperforms other popular open-source dense models of similar
scales, achieving improvements of up to 10.1% on MMLU, and improving mean
end-to-end latency up to 6.1%. Codes are available at:
https://github.com/VITA-Group/READ-ME.",2024-10-24,"Ruisi Cai, Yeonju Ro, Geon-Woo Kim, Peihao Wang, Babak Ehteshami Bejnordi, Aditya Akella, Zhangyang Wang",http://arxiv.org/pdf/2410.19123v1,cs.CL
LLM Tree Search,"This project aims to investigate a novel sequence generation method inspired
by the AlphaGo paradigm, adapting it for use with large language models (LLMs).
The proposed approach involves creating search trees of different possible
completions and evaluating these completions based on model confidence. By
considering various paths in the search tree and scoring them according to the
model's confidence in each completion, we can generate diverse and high-quality
sequences. This research explores the implementation of this paradigm by using
confidence as a proxy for response quality akin to beam search
\citep{vijayakumar2016diverse}. The primary goal of this paper is to outline
the paradigm and demonstrate its potential, rather than focusing on achieving
perfect results. The paper will outline the reasons why we believe this
paradigm has the potential to improve LLMs in the following manners: 1)
increase output quality, 2) decrease errors, 3) eliminate or reduce the
compound error problems, 4) generate diverse and creative completions, 5) allow
for iterative problem-solving, and 6) self-training. We expect this approach to
yield a set of diverse and coherent sequences, offering insights into balancing
exploration and exploitation in sequence generation. Potential applications
include creative text generation tasks, such as storytelling and content
creation, as well as other natural language processing domains, like machine
translation and automated summarization. The goal is that the model will be far
more effective as it will be able to consider many possible variations allowing
it to find the ideal completion. This research aims to contribute to the
understanding of effective search strategies in sequence generation and their
impact on generating high-quality, varied textual outputs.",2024-10-24,Dylan Wilson,http://arxiv.org/pdf/2410.19117v1,cs.CL
RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework,"Despite significant advancements in natural language generation, controlling
language models to produce texts with desired attributes remains a formidable
challenge. In this work, we introduce RSA-Control, a training-free controllable
text generation framework grounded in pragmatics. RSA-Control directs the
generation process by recursively reasoning between imaginary speakers and
listeners, enhancing the likelihood that target attributes are correctly
interpreted by listeners amidst distractors. Additionally, we introduce a
self-adjustable rationality parameter, which allows for automatic adjustment of
control strength based on context. Our experiments, conducted with two task
types and two types of language models, demonstrate that RSA-Control achieves
strong attribute control while maintaining language fluency and content
consistency. Our code is available at https://github.com/Ewanwong/RSA-Control.",2024-10-24,"Yifan Wang, Vera Demberg",http://arxiv.org/pdf/2410.19109v1,cs.CL
Watermarking Large Language Models and the Generated Content: Opportunities and Challenges,"The widely adopted and powerful generative large language models (LLMs) have
raised concerns about intellectual property rights violations and the spread of
machine-generated misinformation. Watermarking serves as a promising approch to
establish ownership, prevent unauthorized use, and trace the origins of
LLM-generated content. This paper summarizes and shares the challenges and
opportunities we found when watermarking LLMs. We begin by introducing
techniques for watermarking LLMs themselves under different threat models and
scenarios. Next, we investigate watermarking methods designed for the content
generated by LLMs, assessing their effectiveness and resilience against various
attacks. We also highlight the importance of watermarking domain-specific
models and data, such as those used in code generation, chip design, and
medical applications. Furthermore, we explore methods like hardware
acceleration to improve the efficiency of the watermarking process. Finally, we
discuss the limitations of current approaches and outline future research
directions for the responsible use and protection of these generative AI tools.",2024-10-24,"Ruisi Zhang, Farinaz Koushanfar",http://arxiv.org/pdf/2410.19096v1,cs.CL
GCoder: Improving Large Language Model for Generalized Graph Problem Solving,"Large Language Models (LLMs) have demonstrated strong reasoning abilities,
making them suitable for complex tasks such as graph computation. Traditional
reasoning steps paradigm for graph problems is hindered by unverifiable steps,
limited long-term reasoning, and poor generalization to graph variations. To
overcome these limitations, we introduce GCoder, a code-based LLM designed to
enhance problem-solving in generalized graph computation problems. Our method
involves constructing an extensive training dataset, GraphWild, featuring
diverse graph formats and algorithms. We employ a multi-stage training process,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler
Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid
retrieval technique is used to augment performance. Experiments demonstrate
that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%
across various graph computational problems. Furthermore, GCoder efficiently
manages large-scale graphs with millions of nodes and diverse input formats,
overcoming the limitations of previous models focused on the reasoning steps
paradigm. This advancement paves the way for more intuitive and effective graph
problem-solving using LLMs. Code and data are available at here:
https://github.com/Bklight999/WWW25-GCoder/tree/master.",2024-10-24,"Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li",http://arxiv.org/pdf/2410.19084v1,cs.CL
Infogent: An Agent-Based Framework for Web Information Aggregation,"Despite seemingly performant web agents on the task-completion benchmarks,
most existing methods evaluate the agents based on a presupposition: the web
navigation task consists of linear sequence of actions with an end state that
marks task completion. In contrast, our work focuses on web navigation for
information aggregation, wherein the agent must explore different websites to
gather information for a complex query. We consider web information aggregation
from two different perspectives: (i) Direct API-driven Access relies on a
text-only view of the Web, leveraging external tools such as Google Search API
to navigate the web and a scraper to extract website contents. (ii) Interactive
Visual Access uses screenshots of the webpages and requires interaction with
the browser to navigate and access information. Motivated by these diverse
information access settings, we introduce Infogent, a novel modular framework
for web information aggregation involving three distinct components: Navigator,
Extractor and Aggregator. Experiments on different information access settings
demonstrate Infogent beats an existing SOTA multi-agent search framework by 7%
under Direct API-Driven Access on FRAMES, and improves over an existing
information-seeking web agent by 4.3% under Interactive Visual Access on
AssistantBench.",2024-10-24,"Revanth Gangi Reddy, Sagnik Mukherjee, Jeonghwan Kim, Zhenhailong Wang, Dilek Hakkani-Tur, Heng Ji",http://arxiv.org/pdf/2410.19054v1,cs.CL
CAMEL-Bench: A Comprehensive Arabic LMM Benchmark,"Recent years have witnessed a significant interest in developing large
multimodal models (LMMs) capable of performing various visual reasoning and
understanding tasks. This has led to the introduction of multiple LMM
benchmarks to evaluate LMMs on different tasks. However, most existing LMM
evaluation benchmarks are predominantly English-centric. In this work, we
develop a comprehensive LMM evaluation benchmark for the Arabic language to
represent a large population of over 400 million speakers. The proposed
benchmark, named CAMEL-Bench, comprises eight diverse domains and 38
sub-domains including, multi-image understanding, complex visual perception,
handwritten document understanding, video understanding, medical imaging, plant
diseases, and remote sensing-based land use understanding to evaluate broad
scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions
that are filtered from a larger pool of samples, where the quality is manually
verified by native speakers to ensure reliable model assessment. We conduct
evaluations of both closed-source, including GPT-4 series, and open-source
LMMs. Our analysis reveals the need for substantial improvement, especially
among the best open-source models, with even the closed-source GPT-4o achieving
an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.",2024-10-24,"Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Alharthi, Ines Riahi, Abduljalil Saif, Jorma Laaksonen, Fahad S. Khan, Salman Khan, Rao M. Anwer",http://arxiv.org/pdf/2410.18976v1,cs.CL
Unbounded: A Generative Infinite Game of Character Life Simulation,"We introduce the concept of a generative infinite game, a video game that
transcends the traditional boundaries of finite, hard-coded systems by using
generative models. Inspired by James P. Carse's distinction between finite and
infinite games, we leverage recent advances in generative AI to create
Unbounded: a game of character life simulation that is fully encapsulated in
generative models. Specifically, Unbounded draws inspiration from sandbox life
simulations and allows you to interact with your autonomous virtual character
in a virtual world by feeding, playing with and guiding it - with open-ended
mechanics generated by an LLM, some of which can be emergent. In order to
develop Unbounded, we propose technical innovations in both the LLM and visual
generation domains. Specifically, we present: (1) a specialized, distilled
large language model (LLM) that dynamically generates game mechanics,
narratives, and character interactions in real-time, and (2) a new dynamic
regional image prompt Adapter (IP-Adapter) for vision models that ensures
consistent yet flexible visual generation of a character across multiple
environments. We evaluate our system through both qualitative and quantitative
analysis, showing significant improvements in character life simulation, user
instruction following, narrative coherence, and visual consistency for both
characters and the environments compared to traditional related approaches.",2024-10-24,"Jialu Li, Yuanzhen Li, Neal Wadhwa, Yael Pritch, David E. Jacobs, Michael Rubinstein, Mohit Bansal, Nataniel Ruiz",http://arxiv.org/pdf/2410.18975v2,cs.CL
Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms,"Building a generalist model for user interface (UI) understanding is
challenging due to various foundational issues, such as platform diversity,
resolution variation, and data limitation. In this paper, we introduce
Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI
understanding across a wide range of platforms, including iPhone, Android,
iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI
2 introduces three key innovations: support for multiple platform types,
high-resolution perception through adaptive scaling, and advanced task training
data generation powered by GPT-4o with set-of-mark visual prompting. These
advancements enable Ferret-UI 2 to perform complex, user-centered interactions,
making it highly versatile and adaptable for the expanding diversity of
platform ecosystems. Extensive empirical experiments on referring, grounding,
user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE
next-action prediction dataset, and GUI-World multi-platform benchmark
demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also
shows strong cross-platform transfer capabilities.",2024-10-24,"Zhangheng Li, Keen You, Haotian Zhang, Di Feng, Harsh Agrawal, Xiujun Li, Mohana Prasad Sathya Moorthy, Jeff Nichols, Yinfei Yang, Zhe Gan",http://arxiv.org/pdf/2410.18967v2,cs.CL
Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions,"Large language models (LLMs) have demonstrated great performance across
various benchmarks, showing potential as general-purpose task solvers. However,
as LLMs are typically trained on vast amounts of data, a significant concern in
their evaluation is data contamination, where overlap between training data and
evaluation datasets inflates performance assessments. Multiple approaches have
been developed to identify data contamination. These approaches rely on
specific assumptions that may not hold universally across different settings.
To bridge this gap, we systematically review 50 papers on data contamination
detection, categorize the underlying assumptions, and assess whether they have
been rigorously validated. We identify and analyze eight categories of
assumptions and test three of them as case studies. Our case studies focus on
detecting direct, instance-level data contamination, which is also referred to
as Membership Inference Attacks (MIA). Our analysis reveals that MIA approaches
based on these three assumptions can have similar performance to random
guessing, on datasets used in LLM pretraining, suggesting that current LLMs
might learn data distributions rather than memorizing individual instances.
Meanwhile, MIA can easily fail when there are data distribution shifts between
the seen and unseen instances.",2024-10-24,"Yujuan Fu, Ozlem Uzuner, Meliha Yetisgen, Fei Xia",http://arxiv.org/pdf/2410.18966v3,cs.CL
OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning,"Large language models (LLMs) and large multimodal models (LMMs) have shown
great potential in automating complex tasks like web browsing and gaming.
However, their ability to generalize across diverse applications remains
limited, hindering broader utility. To address this challenge, we present
OSCAR: Operating System Control via state-Aware reasoning and Re-planning.
OSCAR is a generalist agent designed to autonomously navigate and interact with
various desktop and mobile applications through standardized controls, such as
mouse and keyboard inputs, while processing screen images to fulfill user
commands. OSCAR translates human instructions into executable Python code,
enabling precise control over graphical user interfaces (GUIs). To enhance
stability and adaptability, OSCAR operates as a state machine, equipped with
error-handling mechanisms and dynamic task re-planning, allowing it to
efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR's
effectiveness through extensive experiments on diverse benchmarks across
desktop and mobile platforms, where it transforms complex workflows into simple
natural language commands, significantly boosting user productivity. Our code
will be open-source upon publication.",2024-10-24,"Xiaoqiang Wang, Bang Liu",http://arxiv.org/pdf/2410.18963v1,cs.CL
Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code,"Large Language Models (LLMs) demonstrate strong proficiency in generating
code for high-resource programming languages (HRPLs) like Python but struggle
significantly with low-resource programming languages (LRPLs) such as Racket or
D. This performance gap deepens the digital divide, preventing developers using
LRPLs from benefiting equally from LLM advancements and reinforcing disparities
in innovation within underrepresented programming communities. While generating
additional training data for LRPLs is promising, it faces two key challenges:
manual annotation is labor-intensive and costly, and LLM-generated LRPL code is
often of subpar quality. The underlying cause of this issue is the gap between
natural language to programming language gap (NL-PL Gap), which is especially
pronounced in LRPLs due to limited aligned data. In this work, we introduce a
novel approach called Bridge-Coder, which leverages LLMs' intrinsic
capabilities to enhance the performance on LRPLs. Our method consists of two
key stages. Bridge Generation, where we create high-quality dataset by
utilizing LLMs' general knowledge understanding, proficiency in HRPLs, and
in-context learning abilities. Then, we apply the Bridged Alignment, which
progressively improves the alignment between NL instructions and LRPLs.
Experimental results across multiple LRPLs show that Bridge-Coder significantly
enhances model performance, demonstrating the effectiveness and generalization
of our approach. Furthermore, we offer a detailed analysis of the key
components of our method, providing valuable insights for future work aimed at
addressing the challenges associated with LRPLs.",2024-10-24,"Jipeng Zhang, Jianshu Zhang, Yuanzhe Li, Renjie Pi, Rui Pan, Runtao Liu, Ziqiang Zheng, Tong Zhang",http://arxiv.org/pdf/2410.18957v1,cs.CL
BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning,"Large language models (LLMs) such as ChatGPT are fine-tuned on large and
diverse instruction-following corpora, and can generalize to new tasks.
However, those instruction-tuned LLMs often perform poorly in specialized
medical natural language understanding (NLU) tasks that require domain
knowledge, granular text comprehension, and structured data extraction. To
bridge the gap, we: (1) propose a unified prompting format for 7 important NLU
tasks, (2) curate an instruction-tuning dataset, MNLU-Instruct, utilizing
diverse existing open-source medical NLU corpora, and (3) develop
BioMistral-NLU, a generalizable medical NLU model, through fine-tuning
BioMistral on MNLU-Instruct. We evaluate BioMistral-NLU in a zero-shot setting,
across 6 important NLU tasks, from two widely adopted medical NLU benchmarks:
BLUE and BLURB. Our experiments show that our BioMistral-NLU outperforms the
original BioMistral, as well as the proprietary LLMs - ChatGPT and GPT-4. Our
dataset-agnostic prompting strategy and instruction tuning step over diverse
NLU tasks enhance LLMs' generalizability across diverse medical NLU tasks. Our
ablation experiments show that instruction-tuning on a wider variety of tasks,
even when the total number of training instances remains constant, enhances
downstream zero-shot generalization.",2024-10-24,"Yujuan Velvin Fu, Giridhar Kaushik Ramachandran, Namu Park, Kevin Lybarger, Fei Xia, Ozlem Uzuner, Meliha Yetisgen",http://arxiv.org/pdf/2410.18955v2,cs.CL
Dynamic Vocabulary Pruning in Early-Exit LLMs,"Increasing the size of large language models (LLMs) has been shown to lead to
better performance. However, this comes at the cost of slower and more
expensive inference. Early-exiting is a promising approach for improving the
efficiency of LLM inference by enabling next token prediction at intermediate
layers. Yet, the large vocabulary size in modern LLMs makes the confidence
estimation required for exit decisions computationally expensive, diminishing
the efficiency gains. To address this, we propose dynamically pruning the
vocabulary at test time for each token. Specifically, the vocabulary is pruned
at one of the initial layers, and the smaller vocabulary is then used
throughout the rest of the forward pass. Our experiments demonstrate that such
post-hoc dynamic vocabulary pruning improves the efficiency of confidence
estimation in early-exit LLMs while maintaining competitive performance.",2024-10-24,"Jort Vincenti, Karim Abdel Sadek, Joan Velja, Matteo Nulli, Metod Jazbec",http://arxiv.org/pdf/2410.18952v2,cs.CL
Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play,"Complex news events, such as natural disasters and socio-political conflicts,
require swift responses from the government and society. Relying on historical
events to project the future is insufficient as such events are sparse and do
not cover all possible conditions and nuanced situations. Simulation of these
complex events can help better prepare and reduce the negative impact. We
develop a controllable complex news event simulator guided by both the event
schema representing domain knowledge about the scenario and user-provided
assumptions representing case-specific conditions. As event dynamics depend on
the fine-grained social and cultural context, we further introduce a
geo-diverse commonsense and cultural norm-aware knowledge enhancement
component. To enhance the coherence of the simulation, apart from the global
timeline of events, we take an agent-based approach to simulate the individual
character states, plans, and actions. By incorporating the schema and cultural
norms, our generated simulations achieve much higher coherence and
appropriateness and are received favorably by participants from a humanitarian
assistance organization.",2024-10-24,"Sha Li, Revanth Gangi Reddy, Khanh Duy Nguyen, Qingyun Wang, May Fung, Chi Han, Jiawei Han, Kartik Natarajan, Clare R. Voss, Heng Ji",http://arxiv.org/pdf/2410.18935v1,cs.CL
From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems,"Consider the math problem: ""Lily received 3 cookies from her best friend
yesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies.
How many cookies does Lily have now?"" Many large language models (LLMs) in
previous research approach this problem by calculating the answer ""1"" using the
equation ""3 - 5 + 3."" However, from a human perspective, we recognize the
inherent flaw in this problem: Lily cannot eat 5 cookies if she initially only
had 3. This discrepancy prompts a key question: Are current LLMs merely Blind
Solver that apply mathematical operations without deeper reasoning, or can they
function as Logical Thinker capable of identifying logical inconsistencies?
  To explore this question, we propose a benchmark dataset, FaultyMath, which
includes faulty math problems of rich diversity: i) multiple mathematical
categories, e.g., algebra, geometry, number theory, etc., ii) varying levels of
difficulty, and iii) different origins of faultiness -- ranging from violations
of common sense and ambiguous statements to mathematical contradictions and
more. We evaluate a broad spectrum of LLMs, including open-source,
closed-source, and math-specialized models, using FaultyMath across three
dimensions: (i) How accurately can the models detect faulty math problems
without being explicitly prompted to do so? (ii) When provided with hints --
either correct or misleading -- about the validity of the problems, to what
extent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy
are the explanations generated by LLMs when they recognize a math problem as
flawed? Through extensive experimentation and detailed analysis, our results
demonstrate that existing LLMs largely function as Blind Solver and fall short
of the reasoning capabilities required to perform as Logical Thinker.",2024-10-24,"A M Muntasir Rahman, Junyi Ye, Wei Yao, Sierra S. Liu, Jesse Yu, Jonathan Yu, Wenpeng Yin, Guiling Wang",http://arxiv.org/pdf/2410.18921v2,cs.CL
PRISM: A Methodology for Auditing Biases in Large Language Models,"Auditing Large Language Models (LLMs) to discover their biases and
preferences is an emerging challenge in creating Responsible Artificial
Intelligence (AI). While various methods have been proposed to elicit the
preferences of such models, countermeasures have been taken by LLM trainers,
such that LLMs hide, obfuscate or point blank refuse to disclosure their
positions on certain subjects. This paper presents PRISM, a flexible,
inquiry-based methodology for auditing LLMs - that seeks to illicit such
positions indirectly through task-based inquiry prompting rather than direct
inquiry of said preferences. To demonstrate the utility of the methodology, we
applied PRISM on the Political Compass Test, where we assessed the political
leanings of twenty-one LLMs from seven providers. We show LLMs, by default,
espouse positions that are economically left and socially liberal (consistent
with prior work). We also show the space of positions that these models are
willing to espouse - where some models are more constrained and less compliant
than others - while others are more neutral and objective. In sum, PRISM can
more reliably probe and audit LLMs to understand their preferences, biases and
constraints.",2024-10-24,"Leif Azzopardi, Yashar Moshfeghi",http://arxiv.org/pdf/2410.18906v2,cs.CL
LLMs for Extremely Low-Resource Finno-Ugric Languages,"The advancement of large language models (LLMs) has predominantly focused on
high-resource languages, leaving low-resource languages, such as those in the
Finno-Ugric family, significantly underrepresented. This paper addresses this
gap by focusing on V\~oro, Livonian, and Komi. We cover almost the entire cycle
of LLM creation, from data collection to instruction tuning and evaluation. Our
contributions include developing multilingual base and instruction-tuned
models; creating evaluation benchmarks, including the smugri-MT-bench
multi-turn conversational benchmark; and conducting human evaluation. We intend
for this work to promote linguistic diversity, ensuring that lesser-resourced
languages can benefit from advancements in NLP.",2024-10-24,"Taido Purason, Hele-Andra Kuulmets, Mark Fishel",http://arxiv.org/pdf/2410.18902v2,cs.CL
Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance,"NLP benchmarks rely on standardized datasets for training and evaluating
models and are crucial for advancing the field. Traditionally, expert
annotations ensure high-quality labels; however, the cost of expert annotation
does not scale well with the growing demand for larger datasets required by
modern models. While crowd-sourcing provides a more scalable solution, it often
comes at the expense of annotation precision and consistency. Recent
advancements in large language models (LLMs) offer new opportunities to enhance
the annotation process, particularly for detecting label errors in existing
datasets. In this work, we consider the recent approach of LLM-as-a-judge,
leveraging an ensemble of LLMs to flag potentially mislabeled examples. Through
a case study of four datasets from the TRUE benchmark, covering different tasks
and domains, we empirically analyze the labeling quality of existing datasets,
and compare expert, crowd-sourced, and our LLM-based annotations in terms of
agreement, label quality, and efficiency, demonstrating the strengths and
limitations of each annotation method. Our findings reveal a substantial number
of label errors, which, when corrected, induce a significant upward shift in
reported model performance. This suggests that many of the LLMs so-called
mistakes are due to label errors rather than genuine model failures.
Additionally, we discuss the implications of mislabeled data and propose
methods to mitigate them in training to improve model performance.",2024-10-24,"Omer Nahum, Nitay Calderon, Orgad Keller, Idan Szpektor, Roi Reichart",http://arxiv.org/pdf/2410.18889v1,cs.CL
A Survey of Multimodal Sarcasm Detection,"Sarcasm is a rhetorical device that is used to convey the opposite of the
literal meaning of an utterance. Sarcasm is widely used on social media and
other forms of computer-mediated communication motivating the use of
computational models to identify it automatically. While the clear majority of
approaches to sarcasm detection have been carried out on text only, sarcasm
detection often requires additional information present in tonality, facial
expression, and contextual images. This has led to the introduction of
multimodal models, opening the possibility to detect sarcasm in multiple
modalities such as audio, images, text, and video. In this paper, we present
the first comprehensive survey on multimodal sarcasm detection - henceforth MSD
- to date. We survey papers published between 2018 and 2023 on the topic, and
discuss the models and datasets used for this task. We also present future
research directions in MSD.",2024-10-24,"Shafkat Farabi, Tharindu Ranasinghe, Diptesh Kanojia, Yu Kong, Marcos Zampieri",http://arxiv.org/pdf/2410.18882v1,cs.CL
Provably Robust Watermarks for Open-Source Language Models,"The recent explosion of high-quality language models has necessitated new
methods for identifying AI-generated text. Watermarking is a leading solution
and could prove to be an essential tool in the age of generative AI. Existing
approaches embed watermarks at inference and crucially rely on the large
language model (LLM) specification and parameters being secret, which makes
them inapplicable to the open-source setting. In this work, we introduce the
first watermarking scheme for open-source LLMs. Our scheme works by modifying
the parameters of the model, but the watermark can be detected from just the
outputs of the model. Perhaps surprisingly, we prove that our watermarks are
unremovable under certain assumptions about the adversary's knowledge. To
demonstrate the behavior of our construction under concrete parameter
instantiations, we present experimental results with OPT-6.7B and OPT-1.3B. We
demonstrate robustness to both token substitution and perturbation of the model
parameters. We find that the stronger of these attacks, the model-perturbation
attack, requires deteriorating the quality score to 0 out of 100 in order to
bring the detection rate down to 50%.",2024-10-24,"Miranda Christ, Sam Gunn, Tal Malkin, Mariana Raykova",http://arxiv.org/pdf/2410.18861v1,cs.CL
DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations,"Large Language Models (LLMs) often hallucinate, producing unfaithful or
factually incorrect outputs by misrepresenting the provided context or
incorrectly recalling internal knowledge. Recent studies have identified
specific attention heads within the Transformer architecture, known as
retrieval heads, responsible for extracting relevant contextual information. We
hypothesise that masking these retrieval heads can induce hallucinations and
that contrasting the outputs of the base LLM and the masked LLM can reduce
hallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads
(DeCoRe), a novel training-free decoding strategy that amplifies information
found in the context and model parameters. DeCoRe mitigates potentially
hallucinated responses by dynamically contrasting the outputs of the base LLM
and the masked LLM, using conditional entropy as a guide. Our extensive
experiments confirm that DeCoRe significantly improves performance on tasks
requiring high contextual faithfulness, such as summarisation (XSum by 18.6%),
instruction following (MemoTrap by 10.9%), and open-book question answering
(NQ-Open by 2.4% and NQ-Swap by 5.5%).",2024-10-24,"Aryo Pradipta Gema, Chen Jin, Ahmed Abdulaal, Tom Diethe, Philip Teare, Beatrice Alex, Pasquale Minervini, Amrutha Saseendran",http://arxiv.org/pdf/2410.18860v1,cs.CL
Demystifying Large Language Models for Medicine: A Primer,"Large language models (LLMs) represent a transformative class of AI tools
capable of revolutionizing various aspects of healthcare by generating
human-like responses across diverse contexts and adapting to novel tasks
following human instructions. Their potential application spans a broad range
of medical tasks, such as clinical documentation, matching patients to clinical
trials, and answering medical questions. In this primer paper, we propose an
actionable guideline to help healthcare professionals more efficiently utilize
LLMs in their work, along with a set of best practices. This approach consists
of several main phases, including formulating the task, choosing LLMs, prompt
engineering, fine-tuning, and deployment. We start with the discussion of
critical considerations in identifying healthcare tasks that align with the
core capabilities of LLMs and selecting models based on the selected task and
data, performance requirements, and model interface. We then review the
strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs
to specialized medical tasks. Deployment considerations, including regulatory
compliance, ethical guidelines, and continuous monitoring for fairness and
bias, are also discussed. By providing a structured step-by-step methodology,
this tutorial aims to equip healthcare professionals with the tools necessary
to effectively integrate LLMs into clinical practice, ensuring that these
powerful technologies are applied in a safe, reliable, and impactful manner.",2024-10-24,"Qiao Jin, Nicholas Wan, Robert Leaman, Shubo Tian, Zhizheng Wang, Yifan Yang, Zifeng Wang, Guangzhi Xiong, Po-Ting Lai, Qingqing Zhu, Benjamin Hou, Maame Sarfo-Gyamfi, Gongbo Zhang, Aidan Gilson, Balu Bhasuran, Zhe He, Aidong Zhang, Jimeng Sun, Chunhua Weng, Ronald M. Summers, Qingyu Chen, Yifan Peng, Zhiyong Lu",http://arxiv.org/pdf/2410.18856v3,cs.CL
kNN For Whisper And Its Effect On Bias And Speaker Adaptation,"Speech recognition performance varies by language, domain, and speaker
characteristics such as accent, but fine-tuning a model on any of these
categories may lead to catastrophic forgetting. Token-level $k$ nearest
neighbor search ($k$NN), first proposed for neural sequence decoders for
natural language generation (NLG) and machine translation (MT), is a
non-parametric method that instead adapts using inference-time search in an
external datastore, without training the underlying model. We show that
Whisper, a transformer end-to-end speech model, benefits from $k$NN. We
investigate the differences between the speech and text setups. We discuss
implications for speaker adaptation, and analyze improvements by gender,
accent, and age.",2024-10-24,"Maya K. Nachesa, Vlad Niculae",http://arxiv.org/pdf/2410.18850v2,cs.CL
From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages,"In this paper, we propose a model-agnostic cost-effective approach to
developing bilingual base large language models (LLMs) to support English and
any target language. The method includes vocabulary expansion, initialization
of new embeddings, model training and evaluation. We performed our experiments
with three languages, each using a non-Latin script - Ukrainian, Arabic, and
Georgian.
  Our approach demonstrates improved language performance while reducing
computational costs. It mitigates the disproportionate penalization of
underrepresented languages, promoting fairness and minimizing adverse phenomena
such as code-switching and broken grammar. Additionally, we introduce new
metrics to evaluate language quality, revealing that vocabulary size
significantly impacts the quality of generated text.",2024-10-24,"Artur Kiulian, Anton Polishko, Mykola Khandoga, Yevhen Kostiuk, Guillermo Gabrielli, Łukasz Gagała, Fadi Zaraket, Qusai Abu Obaida, Hrishikesh Garud, Wendy Wing Yee Mak, Dmytro Chaplynskyi, Selma Belhadj Amor, Grigol Peradze",http://arxiv.org/pdf/2410.18836v1,cs.CL
From Imitation to Introspection: Probing Self-Consciousness in Language Models,"Self-consciousness, the introspection of one's existence and thoughts,
represents a high-level cognitive process. As language models advance at an
unprecedented pace, a critical question arises: Are these models becoming
self-conscious? Drawing upon insights from psychological and neural science,
this work presents a practical definition of self-consciousness for language
models and refines ten core concepts. Our work pioneers an investigation into
self-consciousness in language models by, for the first time, leveraging causal
structural games to establish the functional definitions of the ten core
concepts. Based on our definitions, we conduct a comprehensive four-stage
experiment: quantification (evaluation of ten leading models), representation
(visualization of self-consciousness within the models), manipulation
(modification of the models' representation), and acquisition (fine-tuning the
models on core concepts). Our findings indicate that although models are in the
early stages of developing self-consciousness, there is a discernible
representation of certain concepts within their internal mechanisms. However,
these representations of self-consciousness are hard to manipulate positively
at the current stage, yet they can be acquired through targeted fine-tuning.
Our datasets and code are at https://github.com/OpenCausaLab/SelfConsciousness.",2024-10-24,"Sirui Chen, Shu Yu, Shengjie Zhao, Chaochao Lu",http://arxiv.org/pdf/2410.18819v1,cs.CL
Delving into the Reversal Curse: How Far Can Large Language Models Generalize?,"While large language models (LLMs) showcase unprecedented capabilities, they
also exhibit certain inherent limitations when facing seemingly trivial tasks.
A prime example is the recently debated ""reversal curse"", which surfaces when
models, having been trained on the fact ""A is B"", struggle to generalize this
knowledge to infer that ""B is A"". In this paper, we examine the manifestation
of the reversal curse across various tasks and delve into both the
generalization abilities and the problem-solving mechanisms of LLMs. This
investigation leads to a series of significant insights: (1) LLMs are able to
generalize to ""B is A"" when both A and B are presented in the context as in the
case of a multiple-choice question. (2) This generalization ability is highly
correlated to the structure of the fact ""A is B"" in the training documents. For
example, this generalization only applies to biographies structured in ""[Name]
is [Description]"" but not to ""[Description] is [Name]"". (3) We propose and
verify the hypothesis that LLMs possess an inherent bias in fact recalling
during knowledge application, which explains and underscores the importance of
the document structure to successful learning. (4) The negative impact of this
bias on the downstream performance of LLMs can hardly be mitigated through
training alone. These findings offer a novel perspective on interpreting LLMs'
generalization through their intrinsic mechanisms and provide insights for
developing more effective learning methods. Our code and data are available at
https://github.com/alibaba/thinking_bias.git.",2024-10-24,"Zhengkai Lin, Zhihang Fu, Kai Liu, Liang Xie, Binbin Lin, Wenxiao Wang, Deng Cai, Yue Wu, Jieping Ye",http://arxiv.org/pdf/2410.18808v2,cs.CL
A Combinatorial Approach to Neural Emergent Communication,"Substantial research on deep learning-based emergent communication uses the
referential game framework, specifically the Lewis signaling game, however we
argue that successful communication in this game typically only need one or two
symbols for target image classification because of a sampling pitfall in the
training data. To address this issue, we provide a theoretical analysis and
introduce a combinatorial algorithm SolveMinSym (SMS) to solve the symbolic
complexity for classification, which is the minimum number of symbols in the
message for successful communication. We use the SMS algorithm to create
datasets with different symbolic complexity to empirically show that data with
higher symbolic complexity increases the number of effective symbols in the
emergent language.",2024-10-24,Zheyuan Zhang,http://arxiv.org/pdf/2410.18806v2,cs.CL
Distill Visual Chart Reasoning Ability from LLMs to MLLMs,"Solving complex chart Q&A tasks requires advanced visual reasoning abilities
in multimodal large language models (MLLMs). Recent studies highlight that
these abilities consist of two main parts: recognizing key information from
visual inputs and conducting reasoning over it. Thus, a promising approach to
enhance MLLMs is to construct relevant training data focusing on the two
aspects. However, collecting and annotating complex charts and questions is
costly and time-consuming, and ensuring the quality of annotated answers
remains a challenge. In this paper, we propose Code-as-Intermediary Translation
(CIT), a cost-effective, efficient and easily scalable data synthesis method
for distilling visual reasoning abilities from LLMs to MLLMs. The code serves
as an intermediary that translates visual chart representations into textual
representations, enabling LLMs to understand cross-modal information.
Specifically, we employ text-based synthesizing techniques to construct
chart-plotting code and produce ReachQA, a dataset containing 3k
reasoning-intensive charts and 20k Q&A pairs to enhance both recognition and
reasoning abilities. Experiments show that when fine-tuned with our data,
models not only perform well on chart-related benchmarks, but also demonstrate
improved multimodal reasoning abilities on general mathematical benchmarks like
MathVista. The code and dataset are publicly available at
https://github.com/hewei2001/ReachQA.",2024-10-24,"Wei He, Zhiheng Xi, Wanxu Zhao, Xiaoran Fan, Yiwen Ding, Zifei Shan, Tao Gui, Qi Zhang, Xuanjing Huang",http://arxiv.org/pdf/2410.18798v1,cs.CL
An LLM Agent for Automatic Geospatial Data Analysis,"Large language models (LLMs) are being used in data science code generation
tasks, but they often struggle with complex sequential tasks, leading to
logical errors. Their application to geospatial data processing is particularly
challenging due to difficulties in incorporating complex data structures and
spatial constraints, effectively utilizing diverse function calls, and the
tendency to hallucinate less-used geospatial libraries. To tackle these
problems, we introduce GeoAgent, a new interactive framework designed to help
LLMs handle geospatial data processing more effectively. GeoAgent pioneers the
integration of a code interpreter, static analysis, and Retrieval-Augmented
Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm,
offering a novel approach to geospatial data processing. In addition, we
contribute a new benchmark specifically designed to evaluate the LLM-based
approach in geospatial tasks. This benchmark leverages a variety of Python
libraries and includes both single-turn and multi-turn tasks such as data
acquisition, data analysis, and visualization. By offering a comprehensive
evaluation among diverse geospatial contexts, this benchmark sets a new
standard for developing LLM-based approaches in geospatial data analysis tasks.
Our findings suggest that relying solely on knowledge of LLM is insufficient
for accurate geospatial task programming, which requires coherent multi-step
processes and multiple function calls. Compared to the baseline LLMs, the
proposed GeoAgent has demonstrated superior performance, yielding notable
improvements in function calls and task completion. In addition, these results
offer valuable insights for the future development of LLM agents in automatic
geospatial data analysis task programming.",2024-10-24,"Yuxing Chen, Weijie Wang, Sylvain Lobry, Camille Kurtz",http://arxiv.org/pdf/2410.18792v2,cs.CL
A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs,"A primary challenge in large language model (LLM) development is their
onerous pre-training cost. Typically, such pre-training involves optimizing a
self-supervised objective (such as next-token prediction) over a large corpus.
This paper explores a promising paradigm to improve LLM pre-training efficiency
and quality by suitably leveraging a small language model (SLM). In particular,
this paradigm relies on an SLM to both (1) provide soft labels as additional
training supervision, and (2) select a small subset of valuable (""informative""
and ""hard"") training examples. Put together, this enables an effective transfer
of the SLM's predictive distribution to the LLM, while prioritizing specific
regions of the training data distribution. Empirically, this leads to reduced
LLM training time compared to standard training, while improving the overall
quality. Theoretically, we develop a statistical framework to systematically
study the utility of SLMs in enabling efficient training of high-quality LLMs.
In particular, our framework characterizes how the SLM's seemingly low-quality
supervision can enhance the training of a much more capable LLM. Furthermore,
it also highlights the need for an adaptive utilization of such supervision, by
striking a balance between the bias and variance introduced by the SLM-provided
soft labels. We corroborate our theoretical framework by improving the
pre-training of an LLM with 2.8B parameters by utilizing a smaller LM with 1.5B
parameters on the Pile dataset.",2024-10-24,"Ankit Singh Rawat, Veeranjaneyulu Sadhanala, Afshin Rostamizadeh, Ayan Chakrabarti, Wittawat Jitkrittum, Vladimir Feinberg, Seungyeon Kim, Hrayr Harutyunyan, Nikunj Saunshi, Zachary Nado, Rakesh Shivanna, Sashank J. Reddi, Aditya Krishna Menon, Rohan Anil, Sanjiv Kumar",http://arxiv.org/pdf/2410.18779v1,cs.CL
Task Calibration: Calibrating Large Language Models on Inference Tasks,"Large language models (LLMs) have exhibited impressive zero-shot performance
on inference tasks. However, LLMs may suffer from spurious correlations between
input texts and output labels, which limits LLMs' ability to reason based
purely on general language understanding. In other words, LLMs may make
predictions primarily based on premise or hypothesis, rather than both
components. To address this problem that may lead to unexpected performance
degradation, we propose task calibration (TC), a zero-shot and inference-only
calibration method inspired by mutual information which recovers LLM
performance through task reformulation. TC encourages LLMs to reason based on
both premise and hypothesis, while mitigating the models' over-reliance on
individual premise or hypothesis for inference. Experimental results show that
TC achieves a substantial improvement on 13 inference tasks in the zero-shot
setup. We further validate the effectiveness of TC in few-shot setups and
various natural language understanding tasks. Further analysis indicates that
TC is also robust to prompt templates and has the potential to be integrated
with other calibration methods.",2024-10-24,"Yingjie Li, Yun Luo, Xiaotian Xie, Yue Zhang",http://arxiv.org/pdf/2410.18764v1,cs.CL
Does Differential Privacy Impact Bias in Pretrained NLP Models?,"Differential privacy (DP) is applied when fine-tuning pre-trained large
language models (LLMs) to limit leakage of training examples. While most DP
research has focused on improving a model's privacy-utility tradeoff, some find
that DP can be unfair to or biased against underrepresented groups. In this
work, we show the impact of DP on bias in LLMs through empirical analysis.
Differentially private training can increase the model bias against protected
groups w.r.t AUC-based bias metrics. DP makes it more difficult for the model
to differentiate between the positive and negative examples from the protected
groups and other groups in the rest of the population. Our results also show
that the impact of DP on bias is not only affected by the privacy protection
level but also the underlying distribution of the dataset.",2024-10-24,"Md. Khairul Islam, Andrew Wang, Tianhao Wang, Yangfeng Ji, Judy Fox, Jieyu Zhao",http://arxiv.org/pdf/2410.18749v1,cs.CL
Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies,"The large models, as predicted by scaling raw forecasts, have made
groundbreaking progress in many fields, particularly in natural language
generation tasks, where they have approached or even surpassed human levels.
However, the unprecedented scale of their parameters brings significant
computational and storage costs. These large models require substantial
computational resources and GPU memory to operate. When adapting large models
to specific downstream tasks, their massive parameter scale poses a significant
challenge in fine-tuning on hardware platforms with limited computational power
and GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT)
offers a practical solution by efficiently adjusting the parameters of large
pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts
the parameters of pre-trained large models to adapt to specific tasks or
domains, minimizing the introduction of additional parameters and the
computational resources required. This review mainly introduces the preliminary
knowledge of PEFT, the core ideas and principles of various PEFT algorithms,
the applications of PEFT, and potential future research directions. By reading
this review, we believe that interested parties can quickly grasp the PEFT
methodology, thereby accelerating its development and innovation.",2024-10-24,"Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang",http://arxiv.org/pdf/2410.19878v3,cs.CL
Why Does the Effective Context Length of LLMs Fall Short?,"Advancements in distributed training and efficient attention mechanisms have
significantly expanded the context window sizes of large language models
(LLMs). However, recent work reveals that the effective context lengths of
open-source LLMs often fall short, typically not exceeding half of their
training lengths. In this work, we attribute this limitation to the left-skewed
frequency distribution of relative positions formed in LLMs pretraining and
post-training stages, which impedes their ability to effectively gather distant
information. To address this challenge, we introduce ShifTed Rotray position
embeddING (STRING). STRING shifts well-trained positions to overwrite the
original ineffective positions during inference, enhancing performance within
their existing training lengths. Experimental results show that without
additional training, STRING dramatically improves the performance of the latest
large-scale models, such as Llama3.1 70B and Qwen2 72B, by over 10 points on
popular long-context benchmarks RULER and InfiniteBench, establishing new
state-of-the-art results for open-source LLMs. Compared to commercial models,
Llama 3.1 70B with \method even achieves better performance than GPT-4-128K and
clearly surpasses Claude 2 and Kimi-chat.",2024-10-24,"Chenxin An, Jun Zhang, Ming Zhong, Lei Li, Shansan Gong, Yao Luo, Jingjing Xu, Lingpeng Kong",http://arxiv.org/pdf/2410.18745v1,cs.CL
GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning,"We introduce GrammaMT, a grammatically-aware prompting approach for machine
translation that uses Interlinear Glossed Text (IGT), a common form of
linguistic description providing morphological and lexical annotations for
source sentences. GrammaMT proposes three prompting strategies: gloss-shot,
chain-gloss and model-gloss. All are training-free, requiring only a few
examples that involve minimal effort to collect, and making them well-suited
for low-resource setups. Experiments show that GrammaMT enhances translation
performance on open-source instruction-tuned LLMs for various low- to
high-resource languages across three benchmarks: (1) the largest IGT corpus,
(2) the challenging 2023 SIGMORPHON Shared Task data over endangered languages,
and (3) even in an out-of-domain setting with FLORES. Moreover, ablation
studies reveal that leveraging gloss resources could substantially boost MT
performance (by over 17 BLEU points) if LLMs accurately generate or access
input sentence glosses.",2024-10-24,"Rita Ramos, Everlyn Asiko Chimoto, Maartje ter Hoeve, Natalie Schluter",http://arxiv.org/pdf/2410.18702v1,cs.CL
"How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs","Recent research has focused on literary machine translation (MT) as a new
challenge in MT. However, the evaluation of literary MT remains an open
problem. We contribute to this ongoing discussion by introducing
LITEVAL-CORPUS, a paragraph-level parallel corpus containing verified human
translations and outputs from 9 MT systems, which totals over 2k translations
and 13k evaluated sentences across four language pairs, costing 4.5k C. This
corpus enables us to (i) examine the consistency and adequacy of human
evaluation schemes with various degrees of complexity, (ii) compare evaluations
by students and professionals, assess the effectiveness of (iii) LLM-based
metrics and (iv) LLMs themselves. Our findings indicate that the adequacy of
human evaluation is controlled by two factors: the complexity of the evaluation
scheme (more complex is less adequate) and the expertise of evaluators (higher
expertise yields more adequate evaluations). For instance, MQM
(Multidimensional Quality Metrics), a complex scheme and the de facto standard
for non-literary human MT evaluation, is largely inadequate for literary
translation evaluation: with student evaluators, nearly 60% of human
translations are misjudged as indistinguishable or inferior to machine
translations. In contrast, BWS (BEST-WORST SCALING), a much simpler scheme,
identifies human translations at a rate of 80-100%. Automatic metrics fare
dramatically worse, with rates of at most 20%. Our overall evaluation indicates
that published human translations consistently outperform LLM translations,
where even the most recent LLMs tend to produce considerably more literal and
less diverse translations compared to humans.",2024-10-24,"Ran Zhang, Wei Zhao, Steffen Eger",http://arxiv.org/pdf/2410.18697v2,cs.CL
Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch,"The availability of high-quality data is one of the most important factors in
improving the reasoning capability of LLMs. Existing works have demonstrated
the effectiveness of creating more instruction data from seed questions or
knowledge bases. Recent research indicates that continually scaling up data
synthesis from strong models (e.g., GPT-4) can further elicit reasoning
performance. Though promising, the open-sourced community still lacks
high-quality data at scale and scalable data synthesis methods with affordable
costs. To address this, we introduce ScaleQuest, a scalable and novel data
synthesis method that utilizes ""small-size"" (e.g., 7B) open-source models to
generate questions from scratch without the need for seed data with complex
augmentation constraints. With the efficient ScaleQuest, we automatically
constructed a mathematical reasoning dataset consisting of 1 million
problem-solution pairs, which are more effective than existing open-sourced
datasets. It can universally increase the performance of mainstream open-source
models (i.e., Mistral, Llama3, DeepSeekMath, and Qwen2-Math) by achieving 29.2%
to 46.4% gains on MATH. Notably, simply fine-tuning the Qwen2-Math-7B-Base
model with our dataset can even surpass Qwen2-Math-7B-Instruct, a strong and
well-aligned model on closed-source data, and proprietary models such as
GPT-4-Turbo and Claude-3.5 Sonnet.",2024-10-24,"Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Qiaoming Zhu, Min Zhang",http://arxiv.org/pdf/2410.18693v1,cs.CL
Health Misinformation in Social Networks: A Survey of IT Approaches,"In this paper, we present a comprehensive survey on the pervasive issue of
medical misinformation in social networks from the perspective of information
technology. The survey aims at providing a systematic review of related
research and helping researchers and practitioners navigate through this
fast-changing field. Specifically, we first present manual and automatic
approaches for fact-checking. We then explore fake news detection methods,
using content, propagation features, or source features, as well as mitigation
approaches for countering the spread of misinformation. We also provide a
detailed list of several datasets on health misinformation and of publicly
available tools. We conclude the survey with a discussion on the open
challenges and future research directions in the battle against health
misinformation.",2024-10-24,"Vasiliki Papanikou, Panagiotis Papadakos, Theodora Karamanidou, Thanos G. Stavropoulos, Evaggelia Pitoura, Panayiotis Tsaparas",http://arxiv.org/pdf/2410.18670v1,cs.CL
Towards Better Open-Ended Text Generation: A Multicriteria Evaluation Framework,"Open-ended text generation has become a prominent task in natural language
processing due to the rise of powerful (large) language models. However,
evaluating the quality of these models and the employed decoding strategies
remains challenging because of trade-offs among widely used metrics such as
coherence, diversity, and perplexity. Decoding methods often excel in some
metrics while underperforming in others, complicating the establishment of a
clear ranking. In this paper, we present novel ranking strategies within this
multicriteria framework. Specifically, we employ benchmarking approaches based
on partial orderings and present a new summary metric designed to balance
existing automatic indicators, providing a more holistic evaluation of text
generation quality. Our experiments demonstrate that the proposed methods offer
a robust way to compare decoding strategies, and serve as valuable tools in
guiding model selection for open-ended text generation tasks. Finally, we
suggest future directions for improving evaluation methodologies in text
generation. Our codebase, datasets, and models are publicly available.",2024-10-24,"Esteban Garces Arias, Hannah Blocher, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher",http://arxiv.org/pdf/2410.18653v2,cs.CL
$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation,"Generating high-quality charts with Large Language Models (LLMs) presents
significant challenges due to limited data and the high cost of scaling through
human curation. $\langle \text{instruction}, \text{data}, \text{code} \rangle$
triplets are scarce and expensive to manually curate as their creation demands
technical expertise. To address this scalability challenge, we introduce a
reference-free automatic feedback generator, which eliminates the need for
costly human intervention. Our novel framework, C$^2$, consists of (1) an
automatic feedback provider (ChartAF) and (2) a diverse, reference-free dataset
(ChartUIE-8K). The results are compelling: in our first experiment, 74% of
respondents strongly preferred, and 10% preferred, the results after feedback.
The second post-feedback experiment demonstrates that ChartAF outperform nine
baselines. Moreover, ChartUIE-8K significantly improves data diversity by
increasing queries, datasets, and chart types by 5982%, 1936%, and 91%,
respectively, over benchmarks. Finally, a study of LLM users revealed that 94%
of participants preferred ChartUIE-8K's queries, with 93% deeming them aligned
with real-world use cases. Core contributions are available as open-source at
chartsquared.github.io, with ample qualitative examples.",2024-10-24,"Woosung Koh, Jang Han Yoon, MinHyung Lee, Youngjin Song, Jaegwan Cho, Jaehyun Kang, Taehyeon Kim, Se-Young Yun, Youngjae Yu, Bongshin Lee",http://arxiv.org/pdf/2410.18652v7,cs.CL
Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model,"Aligning language models (LMs) with human preferences has become a key area
of research, enabling these models to meet diverse user needs better. Inspired
by weak-to-strong generalization, where a strong LM fine-tuned on labels
generated by a weaker model can consistently outperform its weak supervisor, we
extend this idea to model alignment. In this work, we observe that the
alignment behavior in weaker models can be effectively transferred to stronger
models and even exhibit an amplification effect. Based on this insight, we
propose a method called Weak-to-Strong Preference Optimization (WSPO), which
achieves strong model alignment by learning the distribution differences before
and after the alignment of the weak model. Experiments demonstrate that WSPO
delivers outstanding performance, improving the win rate of Qwen2-7B-Instruct
on Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04
length-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our
results suggest that using the weak model to elicit a strong model with a high
alignment ability is feasible.",2024-10-24,"Wenhong Zhu, Zhiwei He, Xiaofeng Wang, Pengfei Liu, Rui Wang",http://arxiv.org/pdf/2410.18640v2,cs.CL
Little Giants: Synthesizing High-Quality Embedding Data at Scale,"Synthetic data generation has become an increasingly popular way of training
models without the need for large, manually labeled datasets. For tasks like
text embedding, synthetic data offers diverse and scalable training examples,
significantly reducing the cost of human annotation. However, most current
approaches rely heavily on proprietary models like GPT-4, which are expensive
and inefficient for generating large-scale embedding data. In this paper, we
introduce SPEED, a framework that aligns open-source small models (8B) to
efficiently generate large-scale synthetic embedding data. Through supervised
fine-tuning, preference optimization, and self-improvement, SPEED enables small
open-source models to produce high-quality data. Remarkably, SPEED uses only
less than 1/10 of the GPT API calls, outperforming the state-of-the-art
embedding model E5_mistral when both are trained solely on their synthetic
data. Using this efficient generator, we conduct a comprehensive study on how
various factors within the alignment pipeline impact data quality and reveal
the scaling law for synthetic embedding data.",2024-10-24,"Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, Zhicheng Dou",http://arxiv.org/pdf/2410.18634v2,cs.CL
Supporting Assessment of Novelty of Design Problems Using Concept of Problem SAPPhIRE,"This paper proposes a framework for assessing the novelty of design problems
using the SAPPhIRE model of causality. The novelty of a problem is measured as
its minimum distance from the problems in a reference problem database. The
distance is calculated by comparing the current problem and each reference past
problem at the various levels of abstraction in the SAPPhIRE ontology. The
basis for comparison is textual similarity. To demonstrate the applicability of
the proposed framework, The current set of problems associated with an
artifact, as collected from its stakeholders, were compared with the past set
of problems, as collected from patents and other web sources, to assess the
novelty of the current set. This approach is aimed at providing a better
understanding of the degree of novelty of any given set of current problems by
comparing them to similar problems available from historical records. Since
manual assessment, the current mode of such assessments as reported in the
literature, is a tedious process, to reduce time complexity and to afford
better applicability for larger sets of problem statements, an automated
assessment is proposed and used in this paper.",2024-10-24,"Sanjay Singh, Amaresh Chakrabarti",http://arxiv.org/pdf/2410.18629v1,cs.CL
Prompting and Fine-Tuning of Small LLMs for Length-Controllable Telephone Call Summarization,"This paper explores the rapid development of a telephone call summarization
system utilizing large language models (LLMs). Our approach involves initial
experiments with prompting existing LLMs to generate summaries of telephone
conversations, followed by the creation of a tailored synthetic training
dataset utilizing stronger frontier models. We place special focus on the
diversity of the generated data and on the ability to control the length of the
generated summaries to meet various use-case specific requirements. The
effectiveness of our method is evaluated using two state-of-the-art
LLM-as-a-judge-based evaluation techniques to ensure the quality and relevance
of the summaries. Our results show that fine-tuned Llama-2-7B-based
summarization model performs on-par with GPT-4 in terms of factual accuracy,
completeness and conciseness. Our findings demonstrate the potential for
quickly bootstrapping a practical and efficient call summarization system.",2024-10-24,"David Thulke, Yingbo Gao, Rricha Jalota, Christian Dugast, Hermann Ney",http://arxiv.org/pdf/2410.18624v1,cs.CL
STTATTS: Unified Speech-To-Text And Text-To-Speech Model,"Speech recognition and speech synthesis models are typically trained
separately, each with its own set of learning objectives, training data, and
model parameters, resulting in two distinct large networks. We propose a
parameter-efficient approach to learning ASR and TTS jointly via a multi-task
learning objective and shared parameters. Our evaluation demonstrates that the
performance of our multi-task model is comparable to that of individually
trained models while significantly saving computational and memory costs
($\sim$50\% reduction in the total number of parameters required for the two
tasks combined). We experiment with English as a resource-rich language, and
Arabic as a relatively low-resource language due to shortage of TTS data. Our
models are trained with publicly available data, and both the training code and
model checkpoints are openly available for further research.",2024-10-24,"Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki",http://arxiv.org/pdf/2410.18607v1,cs.CL
Speech perception: a model of word recognition,"We present a model of speech perception which takes into account effects of
correlations between sounds. Words in this model correspond to the attractors
of a suitably chosen descent dynamics. The resulting lexicon is rich in short
words, and much less so in longer ones, as befits a reasonable word length
distribution. We separately examine the decryption of short and long words in
the presence of mishearings. In the regime of short words, the algorithm either
quickly retrieves a word, or proposes another valid word. In the regime of
longer words, the behaviour is markedly different. While the successful
decryption of words continues to be relatively fast, there is a finite
probability of getting lost permanently, as the algorithm wanders round the
landscape of suitable words without ever settling on one.",2024-10-24,"Jean-Marc Luck, Anita Mehta",http://arxiv.org/pdf/2410.18590v1,cs.CL
Taipan: Efficient and Expressive State Space Language Models with Selective Attention,"Efficient long-context language modeling remains a significant challenge in
Natural Language Processing (NLP). While Transformers dominate language tasks,
they struggle with long sequences due to quadratic computational complexity in
training and linearly scaling memory costs during inference. Recent State Space
Models (SSMs) such as Mamba offer alternatives with constant memory usage, but
they underperform in tasks requiring extensive in-context retrieval. We
introduce Taipan, a novel hybrid architecture that combines Mamba-2 with
Selective Attention Layers (SALs). These SALs identify tokens requiring
long-range interactions, remove less important features, and then augment their
representations using the attention module. This approach balances Mamba's
efficiency with Transformer-like performance in memory-intensive tasks. By
constraining the attention budget, Taipan extends accurate predictions to
context lengths of up to 1 million tokens while preserving computational
efficiency. Our experiments demonstrate Taipan's superior performance across
various scales and tasks, offering a promising solution for efficient
long-context language modeling.",2024-10-24,"Chien Van Nguyen, Huy Huu Nguyen, Thang M. Pham, Ruiyi Zhang, Hanieh Deilamsalehy, Puneet Mathur, Ryan A. Rossi, Trung Bui, Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen",http://arxiv.org/pdf/2410.18572v1,cs.CL
Difficult for Whom? A Study of Japanese Lexical Complexity,"The tasks of lexical complexity prediction (LCP) and complex word
identification (CWI) commonly presuppose that difficult to understand words are
shared by the target population. Meanwhile, personalization methods have also
been proposed to adapt models to individual needs. We verify that a recent
Japanese LCP dataset is representative of its target population by partially
replicating the annotation. By another reannotation we show that native Chinese
speakers perceive the complexity differently due to Sino-Japanese vocabulary.
To explore the possibilities of personalization, we compare competitive
baselines trained on the group mean ratings and individual ratings in terms of
performance for an individual. We show that the model trained on a group mean
performs similarly to an individual model in the CWI task, while achieving good
LCP performance for an individual is difficult. We also experiment with
adapting a finetuned BERT model, which results only in marginal improvements
across all settings.",2024-10-24,"Adam Nohejl, Akio Hayakawa, Yusuke Ide, Taro Watanabe",http://arxiv.org/pdf/2410.18567v1,cs.CL
"Bielik 7B v0.1: A Polish Language Model -- Development, Insights, and Evaluation","We introduce Bielik 7B v0.1, a 7-billion-parameter generative text model for
Polish language processing. Trained on curated Polish corpora, this model
addresses key challenges in language model development through innovative
techniques. These include Weighted Instruction Cross-Entropy Loss, which
balances the learning of different instruction types, and Adaptive Learning
Rate, which dynamically adjusts the learning rate based on training progress.
To evaluate performance, we created the Open PL LLM Leaderboard and Polish
MT-Bench, novel frameworks assessing various NLP tasks and conversational
abilities. Bielik 7B v0.1 demonstrates significant improvements, achieving a 9
percentage point increase in average score compared to Mistral-7B-v0.1 on the
RAG Reader task. It also excels in the Polish MT-Bench, particularly in
Reasoning (6.15/10) and Role-playing (7.83/10) categories. This model
represents a substantial advancement in Polish language AI, offering a powerful
tool for diverse linguistic applications and setting new benchmarks in the
field.",2024-10-24,"Krzysztof Ociepa, Łukasz Flis, Krzysztof Wróbel, Adrian Gwoździej, Remigiusz Kinas",http://arxiv.org/pdf/2410.18565v1,cs.CL
Infinity-MM: Scaling Multimodal Performance with Large-Scale and High-Quality Instruction Data,"Recently, Vision-Language Models (VLMs) have achieved remarkable progress in
multimodal tasks, and multimodal instruction data serves as the foundation for
enhancing VLM capabilities. Despite the availability of several open-source
multimodal datasets, limitations in the scale and quality of open-source
instruction data hinder the performance of VLMs trained on these datasets,
leading to a significant gap compared to models trained on closed-source data.
To address this challenge, we introduce Infinity-MM, a large-scale multimodal
instruction dataset. We collected the available multimodal instruction datasets
and performed unified preprocessing, resulting in a dataset with over 40
million samples that ensures diversity and accuracy. Furthermore, to enable
large-scale expansion of instruction data and support the continuous
acquisition of high-quality data, we propose a synthetic instruction generation
method based on a tagging system and open-source VLMs. By establishing
correspondences between different types of images and associated instruction
types, this method can provide essential guidance during data synthesis.
Leveraging this high-quality data, we have trained a 2-billion-parameter
Vision-Language Model, Aquila-VL-2B, which achieves state-of-the-art (SOTA)
performance among models of similar scale. The data is available at:
https://huggingface.co/datasets/BAAI/Infinity-MM.",2024-10-24,"Shuhao Gu, Jialing Zhang, Siyuan Zhou, Kevin Yu, Zhaohu Xing, Liangdong Wang, Zhou Cao, Jintao Jia, Zhuoyi Zhang, Yixuan Wang, Zhenchong Hu, Bo-Wen Zhang, Jijie Li, Dong Liang, Yingli Zhao, Songjing Wang, Yulong Ao, Yiming Ju, Huanhuan Ma, Xiaotong Li, Haiwen Diao, Yufeng Cui, Xinlong Wang, Yaoqi Liu, Fangxiang Feng, Guang Liu",http://arxiv.org/pdf/2410.18558v2,cs.CL
On Explaining with Attention Matrices,"This paper explores the much discussed, possible explanatory link between
attention weights (AW) in transformer models and predicted output. Contrary to
intuition and early research on attention, more recent prior research has
provided formal arguments and empirical evidence that AW are not explanatorily
relevant. We show that the formal arguments are incorrect. We introduce and
effectively compute efficient attention, which isolates the effective
components of attention matrices in tasks and models in which AW play an
explanatory role. We show that efficient attention has a causal role (provides
minimally necessary and sufficient conditions) for predicting model output in
NLP tasks requiring contextual information, and we show, contrary to [7], that
efficient attention matrices are probability distributions and are effectively
calculable. Thus, they should play an important part in the explanation of
attention based model behavior. We offer empirical experiments in support of
our method illustrating various properties of efficient attention with various
metrics on four datasets.",2024-10-24,"Omar Naim, Nicholas Asher",http://arxiv.org/pdf/2410.18541v1,cs.CL
LOGO -- Long cOntext aliGnment via efficient preference Optimization,"Long-context models(LCMs) have shown great potential in processing long input
sequences(even more than 100M tokens) conveniently and effectively. With
significant progress, recent research has pointed out that LCMs can accurately
locate token-level salient information within the context. Yet, the generation
performance of these LCMs is far from satisfactory and might result in
misaligned responses, such as hallucinations. To enhance the generation
capability of LCMs, existing works have investigated the effects of data size
and quality for both pre-training and instruction tuning. Though achieving
meaningful improvement, previous methods fall short in either effectiveness or
efficiency. In this paper, we introduce LOGO(Long cOntext aliGnment via
efficient preference Optimization), a training strategy that first introduces
preference optimization for long-context alignment. To overcome the GPU
memory-bound issue caused by the long sequence, LOGO employs a reference-free
preference optimization strategy and adopts a position synthesis method to
construct the training data. By training with only 0.3B data on a single
8$\times$A800 GPU machine for 16 hours, LOGO allows the Llama-3-8B-Instruct-80K
model to achieve comparable performance with GPT-4 in real-world long-context
tasks while preserving the model's original capabilities on other tasks, e.g.,
language modeling and MMLU. Moreover, LOGO can extend the model's context
window size while enhancing its generation performance.",2024-10-24,"Zecheng Tang, Zechen Sun, Juntao Li, Qiaoming Zhu, Min Zhang",http://arxiv.org/pdf/2410.18533v1,cs.CL
A Systematic Survey on Instructional Text: From Representation Formats to Downstream NLP Tasks,"Recent advances in large language models have demonstrated promising
capabilities in following simple instructions through instruction tuning.
However, real-world tasks often involve complex, multi-step instructions that
remain challenging for current NLP systems. Despite growing interest in this
area, there lacks a comprehensive survey that systematically analyzes the
landscape of complex instruction understanding and processing. Through a
systematic review of the literature, we analyze available resources,
representation schemes, and downstream tasks related to instructional text. Our
study examines 177 papers, identifying trends, challenges, and opportunities in
this emerging field. We provide AI/NLP researchers with essential background
knowledge and a unified view of various approaches to complex instruction
understanding, bridging gaps between different research directions and
highlighting future research opportunities.",2024-10-24,"Abdulfattah Safa, Tamta Kapanadze, Arda Uzunoğlu, Gözde Gül Şahin",http://arxiv.org/pdf/2410.18529v2,cs.CL
KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing,"The development of large language models (LLMs) has significantly expanded
model sizes, resulting in substantial GPU memory requirements during inference.
The key and value storage of the attention map in the KV (key-value) cache
accounts for more than 80\% of this memory consumption. Nowadays, most existing
KV cache compression methods focus on intra-layer compression within a single
Transformer layer but few works consider layer-wise compression. In this paper,
we propose a plug-and-play method called \textit{KVSharer}, which shares the KV
cache between layers to achieve layer-wise compression. Rather than intuitively
sharing based on higher similarity, we discover a counterintuitive phenomenon:
sharing dissimilar KV caches better preserves the model performance.
Experiments show that \textit{KVSharer} can reduce KV cache computation by
30\%, thereby lowering memory consumption without significantly impacting model
performance and it can also achieve at least 1.3 times generation acceleration.
Additionally, we verify that \textit{KVSharer} is compatible with existing
intra-layer KV cache compression methods, and combining both can further save
memory.",2024-10-24,"Yifei Yang, Zouying Cao, Qiguang Chen, Libo Qin, Dongjie Yang, Hai Zhao, Zhi Chen",http://arxiv.org/pdf/2410.18517v1,cs.CL
Scaling up Masked Diffusion Models on Text,"Masked diffusion models (MDMs) have shown promise in language modeling, yet
their scalability and effectiveness in core language tasks, such as text
generation and language understanding, remain underexplored. This paper
establishes the first scaling law for MDMs, demonstrating a scaling rate
comparable to autoregressive models (ARMs) and a relatively small compute gap.
Motivated by their scalability, we train a family of MDMs with up to 1.1
billion (B) parameters to systematically evaluate their performance against
ARMs of comparable or larger sizes. Fully leveraging the probabilistic
formulation of MDMs, we propose a simple yet effective unsupervised
classifier-free guidance that effectively exploits large-scale unpaired data,
boosting performance for conditional inference. In language understanding, the
1.1B MDM outperforms the 1.1B TinyLlama model trained on the same data across
four of eight zero-shot benchmarks. Notably, it achieves competitive math
reasoning ability with the 7B Llama-2 model on the GSM8K dataset. In text
generation, MDMs with 16 times more pre-training time offer a flexible
trade-off against ARMs with the accelerated sampling technique KV-Cache: MDMs
match ARMs in performance while being 1.4 times faster during sampling.
Moreover, MDMs address challenging tasks for ARMs by effectively handling
bidirectional reasoning and adapting to temporal shifts in data. Notably, a
1.1B MDM breaks the reverse curse encountered by much larger ARMs with
significantly more data and computation, such as 13B Llama-2 and 175B GPT-3.
Our code is available at https://github.com/ML-GSAI/SMDM.",2024-10-24,"Shen Nie, Fengqi Zhu, Chao Du, Tianyu Pang, Qian Liu, Guangtao Zeng, Min Lin, Chongxuan Li",http://arxiv.org/pdf/2410.18514v3,cs.CL
CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models,"We present CCI3.0-HQ (https://huggingface.co/datasets/BAAI/CCI3-HQ), a
high-quality 500GB subset of the Chinese Corpora Internet 3.0
(CCI3.0)(https://huggingface.co/datasets/BAAI/CCI3-Data), developed using a
novel two-stage hybrid filtering pipeline that significantly enhances data
quality. To evaluate its effectiveness, we trained a 0.5B parameter model from
scratch on 100B tokens across various datasets, achieving superior performance
on 10 benchmarks in a zero-shot setting compared to CCI3.0, SkyPile, and
WanjuanV1. The high-quality filtering process effectively distills the
capabilities of the Qwen2-72B-instruct model into a compact 0.5B model,
attaining optimal F1 scores for Chinese web data classification. We believe
this open-access dataset will facilitate broader access to high-quality
language models.",2024-10-24,"Liangdong Wang, Bo-Wen Zhang, Chengwei Wu, Hanyu Zhao, Xiaofeng Shi, Shuhao Gu, Jijie Li, Quanyue Ma, TengFei Pan, Guang Liu",http://arxiv.org/pdf/2410.18505v2,cs.CL
ChineseSafe: A Chinese Benchmark for Evaluating Safety in Large Language Models,"With the rapid development of Large language models (LLMs), understanding the
capabilities of LLMs in identifying unsafe content has become increasingly
important. While previous works have introduced several benchmarks to evaluate
the safety risk of LLMs, the community still has a limited understanding of
current LLMs' capability to recognize illegal and unsafe content in Chinese
contexts. In this work, we present a Chinese safety benchmark (ChineseSafe) to
facilitate research on the content safety of large language models. To align
with the regulations for Chinese Internet content moderation, our ChineseSafe
contains 205,034 examples across 4 classes and 10 sub-classes of safety issues.
For Chinese contexts, we add several special types of illegal content:
political sensitivity, pornography, and variant/homophonic words. Moreover, we
employ two methods to evaluate the legal risks of popular LLMs, including
open-sourced models and APIs. The results reveal that many LLMs exhibit
vulnerability to certain types of safety issues, leading to legal risks in
China. Our work provides a guideline for developers and researchers to
facilitate the safety of LLMs. Our results are also available at
https://huggingface.co/spaces/SUSTech/ChineseSafe-Benchmark. Additionally, we
release a test set comprising 200,000 examples, which is publicly accessible at
https://huggingface.co/datasets/SUSTech/ChineseSafe.",2024-10-24,"Hengxiang Zhang, Hongfu Gao, Qiang Hu, Guanhua Chen, Lili Yang, Bingyi Jing, Hongxin Wei, Bing Wang, Haifeng Bai, Lei Yang",http://arxiv.org/pdf/2410.18491v2,cs.CL
Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction,"Efficiently deriving structured workflows from unannotated dialogs remains an
underexplored and formidable challenge in computational linguistics. Automating
this process could significantly accelerate the manual design of workflows in
new domains and enable the grounding of large language models in
domain-specific flowcharts, enhancing transparency and controllability. In this
paper, we introduce Dialog2Flow (D2F) embeddings, which differ from
conventional sentence embeddings by mapping utterances to a latent space where
they are grouped according to their communicative and informative functions
(i.e., the actions they represent). D2F allows for modeling dialogs as
continuous trajectories in a latent space with distinct action-related regions.
By clustering D2F embeddings, the latent space is quantized, and dialogs can be
converted into sequences of region/action IDs, facilitating the extraction of
the underlying workflow. To pre-train D2F, we build a comprehensive dataset by
unifying twenty task-oriented dialog datasets with normalized per-turn action
annotations. We also introduce a novel soft contrastive loss that leverages the
semantic information of these actions to guide the representation learning
process, showing superior performance compared to standard supervised
contrastive loss. Evaluation against various sentence embeddings, including
dialog-specific ones, demonstrates that D2F yields superior qualitative and
quantitative results across diverse domains.",2024-10-24,"Sergio Burdisso, Srikanth Madikeri, Petr Motlicek",http://arxiv.org/pdf/2410.18481v2,cs.CL
Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities,"Recent research has shown that Large Language Models (LLMs) are vulnerable to
automated jailbreak attacks, where adversarial suffixes crafted by algorithms
appended to harmful queries bypass safety alignment and trigger unintended
responses. Current methods for generating these suffixes are computationally
expensive and have low Attack Success Rates (ASR), especially against
well-aligned models like Llama2 and Llama3. To overcome these limitations, we
introduce ADV-LLM, an iterative self-tuning process that crafts adversarial
LLMs with enhanced jailbreak ability. Our framework significantly reduces the
computational cost of generating adversarial suffixes while achieving nearly
100\% ASR on various open-source LLMs. Moreover, it exhibits strong attack
transferability to closed-source models, achieving 99\% ASR on GPT-3.5 and 49\%
ASR on GPT-4, despite being optimized solely on Llama3. Beyond improving
jailbreak ability, ADV-LLM provides valuable insights for future safety
alignment research through its ability to generate large datasets for studying
LLM safety.",2024-10-24,"Chung-En Sun, Xiaodong Liu, Weiwei Yang, Tsui-Wei Weng, Hao Cheng, Aidan San, Michel Galley, Jianfeng Gao",http://arxiv.org/pdf/2410.18469v3,cs.CL
Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs,"In this report, we introduce a collection of methods to enhance reward
modeling for LLMs, focusing specifically on data-centric techniques. We propose
effective data selection and filtering strategies for curating high-quality
open-source preference datasets, culminating in the Skywork-Reward data
collection, which contains only 80K preference pairs -- significantly smaller
than existing datasets. Using this curated dataset, we developed the
Skywork-Reward model series -- Skywork-Reward-Gemma-27B and
Skywork-Reward-Llama-3.1-8B -- with the former currently holding the top
position on the RewardBench leaderboard. Notably, our techniques and datasets
have directly enhanced the performance of many top-ranked models on
RewardBench, highlighting the practical impact of our contributions in
real-world preference learning applications.",2024-10-24,"Chris Yuhao Liu, Liang Zeng, Jiacai Liu, Rui Yan, Jujie He, Chaojie Wang, Shuicheng Yan, Yang Liu, Yahui Zhou",http://arxiv.org/pdf/2410.18451v1,cs.CL
ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis,"Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.",2024-10-24,"Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong",http://arxiv.org/pdf/2410.18447v2,cs.CL
Evaluating Automatic Speech Recognition Systems for Korean Meteorological Experts,"This paper explores integrating Automatic Speech Recognition (ASR) into
natural language query systems to improve weather forecasting efficiency for
Korean meteorologists. We address challenges in developing ASR systems for the
Korean weather domain, specifically specialized vocabulary and Korean
linguistic intricacies. To tackle these issues, we constructed an evaluation
dataset of spoken queries recorded by native Korean speakers. Using this
dataset, we assessed various configurations of a multilingual ASR model family,
identifying performance limitations related to domain-specific terminology. We
then implemented a simple text-to-speech-based data augmentation method, which
improved the recognition of specialized terms while maintaining general-domain
performance. Our contributions include creating a domain-specific dataset,
comprehensive ASR model evaluations, and an effective augmentation technique.
We believe our work provides a foundation for future advancements in ASR for
the Korean weather forecasting domain.",2024-10-24,"ChaeHun Park, Hojun Cho, Jaegul Choo",http://arxiv.org/pdf/2410.18444v2,cs.CL
Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching,"Code-switching (CS), a phenomenon where multilingual speakers alternate
between languages in a discourse, can convey subtle cultural and linguistic
nuances that can be otherwise lost in translation. Recent state-of-the-art
multilingual large language models (LLMs) demonstrate excellent multilingual
abilities in various aspects including understanding CS, but the power of CS in
eliciting language-specific knowledge is yet to be discovered. Therefore, we
investigate the effectiveness of code-switching on a wide range of multilingual
LLMs in terms of knowledge activation, or the act of identifying and leveraging
knowledge for reasoning. To facilitate the research, we first present EnKoQA, a
synthetic English-Korean CS question-answering dataset. We provide a
comprehensive analysis on a variety of multilingual LLMs by subdividing
activation process into knowledge identification and knowledge leveraging. Our
experiments demonstrate that compared to English text, CS can faithfully
activate knowledge inside LLMs, especially on language-specific domains. In
addition, the performance gap between CS and English is larger in models that
show excellent monolingual abilities, suggesting that there exists a
correlation with CS and Korean proficiency.",2024-10-24,"Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo, Dongha Lee",http://arxiv.org/pdf/2410.18436v1,cs.CL
Building Dialogue Understanding Models for Low-resource Language Indonesian from Scratch,"Making use of off-the-shelf resources of resource-rich languages to transfer
knowledge for low-resource languages raises much attention recently. The
requirements of enabling the model to reach the reliable performance lack well
guided, such as the scale of required annotated data or the effective
framework. To investigate the first question, we empirically investigate the
cost-effectiveness of several methods to train the intent classification and
slot-filling models for Indonesia (ID) from scratch by utilizing the English
data. Confronting the second challenge, we propose a Bi-Confidence-Frequency
Cross-Lingual transfer framework (BiCF), composed by ``BiCF Mixing'', ``Latent
Space Refinement'' and ``Joint Decoder'', respectively, to tackle the obstacle
of lacking low-resource language dialogue data. Extensive experiments
demonstrate our framework performs reliably and cost-efficiently on different
scales of manually annotated Indonesian data. We release a large-scale
fine-labeled dialogue dataset (ID-WOZ) and ID-BERT of Indonesian for further
research.",2024-10-24,"Donglin Di, Weinan Zhang, Yue Zhang, Fanglin Wang",http://arxiv.org/pdf/2410.18430v1,cs.CL
Large Language Models Reflect the Ideology of their Creators,"Large language models (LLMs) are trained on vast amounts of data to generate
natural language, enabling them to perform tasks like text summarization and
question answering. These models have become popular in artificial intelligence
(AI) assistants like ChatGPT and already play an influential role in how humans
access information. However, the behavior of LLMs varies depending on their
design, training, and use.
  In this paper, we prompt a diverse panel of popular LLMs to describe a large
number of prominent personalities with political relevance, in all six official
languages of the United Nations. By identifying and analyzing moral assessments
reflected in their responses, we find normative differences between LLMs from
different geopolitical regions, as well as between the responses of the same
LLM when prompted in different languages. Among only models in the United
States, we find that popularly hypothesized disparities in political views are
reflected in significant normative differences related to progressive values.
Among Chinese models, we characterize a division between internationally- and
domestically-focused models.
  Our results show that the ideological stance of an LLM appears to reflect the
worldview of its creators. This poses the risk of political instrumentalization
and raises concerns around technological and regulatory efforts with the stated
aim of making LLMs ideologically 'unbiased'.",2024-10-24,"Maarten Buyl, Alexander Rogiers, Sander Noels, Guillaume Bied, Iris Dominguez-Catena, Edith Heiter, Iman Johary, Alexandru-Cristian Mara, Raphaël Romero, Jefrey Lijffijt, Tijl De Bie",http://arxiv.org/pdf/2410.18417v2,cs.CL
Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains,"Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.",2024-10-24,"Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng",http://arxiv.org/pdf/2410.18415v1,cs.CL
MoMQ: Mixture-of-Experts Enhances Multi-Dialect Query Generation across Relational and Non-Relational Databases,"The improvement in translating natural language to structured query language
(SQL) can be attributed to the advancements in large language models (LLMs).
Open-source LLMs, tailored for specific database dialects such as MySQL, have
shown great performance. However, cloud service providers are looking for a
unified database manager service (e.g., Cosmos DB from Azure, Amazon Aurora
from AWS, Lindorm from AlibabaCloud) that can support multiple dialects. This
requirement has led to the concept of multi-dialect query generation, which
presents challenges to LLMs. These challenges include syntactic differences
among dialects and imbalanced data distribution across multiple dialects. To
tackle these challenges, we propose MoMQ, a novel Mixture-of-Experts-based
multi-dialect query generation framework across both relational and
non-relational databases. MoMQ employs a dialect expert group for each dialect
and a multi-level routing strategy to handle dialect-specific knowledge,
reducing interference during query generation. Additionally, a shared expert
group is introduced to address data imbalance, facilitating the transfer of
common knowledge from high-resource dialects to low-resource ones. Furthermore,
we have developed a high-quality multi-dialect query generation benchmark that
covers relational and non-relational databases such as MySQL, PostgreSQL,
Cypher for Neo4j, and nGQL for NebulaGraph. Extensive experiments have shown
that MoMQ performs effectively and robustly even in resource-imbalanced
scenarios.",2024-10-24,"Zhisheng Lin, Yifu Liu, Zhiling Luo, Jinyang Gao, Yu Li",http://arxiv.org/pdf/2410.18406v1,cs.CL
SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness,"Social media is often the first place where communities discuss the latest
societal trends. Prior works have utilized this platform to extract
epidemic-related information (e.g. infections, preventive measures) to provide
early warnings for epidemic prediction. However, these works only focused on
English posts, while epidemics can occur anywhere in the world, and early
discussions are often in the local, non-English languages. In this work, we
introduce the first multilingual Event Extraction (EE) framework SPEED++ for
extracting epidemic event information for a wide range of diseases and
languages. To this end, we extend a previous epidemic ontology with 20 argument
roles; and curate our multilingual EE dataset SPEED++ comprising 5.1K tweets in
four languages for four diseases. Annotating data in every language is
infeasible; thus we develop zero-shot cross-lingual cross-disease models (i.e.,
training only on English COVID data) utilizing multilingual pre-training and
show their efficacy in extracting epidemic-related events for 65 diverse
languages across different diseases. Experiments demonstrate that our framework
can provide epidemic warnings for COVID-19 in its earliest stages in Dec 2019
(3 weeks before global discussions) from Chinese Weibo posts without any
training in Chinese. Furthermore, we exploit our framework's argument
extraction capabilities to aggregate community epidemic discussions like
symptoms and cure measures, aiding misinformation detection and public
attention monitoring. Overall, we lay a strong foundation for multilingual
epidemic preparedness.",2024-10-24,"Tanmay Parekh, Jeffrey Kwan, Jiarui Yu, Sparsh Johri, Hyosang Ahn, Sreya Muppalla, Kai-Wei Chang, Wei Wang, Nanyun Peng",http://arxiv.org/pdf/2410.18393v1,cs.CL
Monolingual and Multilingual Misinformation Detection for Low-Resource Languages: A Comprehensive Survey,"In today's global digital landscape, misinformation transcends linguistic
boundaries, posing a significant challenge for moderation systems. Most
approaches to misinformation detection are monolingual, focused on
high-resource languages, i.e., a handful of world languages that have benefited
from substantial research investment. This survey provides a comprehensive
overview of the current research on misinformation detection in low-resource
languages, both in monolingual and multilingual settings. We review existing
datasets, methodologies, and tools used in these domains, identifying key
challenges related to: data resources, model development, cultural and
linguistic context, and real-world applications. We examine emerging
approaches, such as language-generalizable models and multi-modal techniques,
and emphasize the need for improved data collection practices,
interdisciplinary collaboration, and stronger incentives for socially
responsible AI research. Our findings underscore the importance of systems
capable of addressing misinformation across diverse linguistic and cultural
contexts.",2024-10-24,"Xinyu Wang, Wenbo Zhang, Sarah Rajtmajer",http://arxiv.org/pdf/2410.18390v2,cs.CL
WAFFLE: Multi-Modal Model for Automated Front-End Development,"Web development involves turning UI designs into functional webpages, which
can be difficult for both beginners and experienced developers due to the
complexity of HTML's hierarchical structures and styles. While Large Language
Models (LLMs) have shown promise in generating source code, two major
challenges persist in UI-to-HTML code generation: (1) effectively representing
HTML's hierarchical structure for LLMs, and (2) bridging the gap between the
visual nature of UI designs and the text-based format of HTML code. To tackle
these challenges, we introduce Waffle, a new fine-tuning strategy that uses a
structure-aware attention mechanism to improve LLMs' understanding of HTML's
structure and a contrastive fine-tuning approach to align LLMs' understanding
of UI images and HTML code. Models fine-tuned with Waffle show up to 9.00 pp
(percentage point) higher HTML match, 0.0982 higher CW-SSIM, 32.99 higher CLIP,
and 27.12 pp higher LLEM on our new benchmark WebSight-Test and an existing
benchmark Design2Code, outperforming current fine-tuning methods.",2024-10-24,"Shanchao Liang, Nan Jiang, Shangshu Qian, Lin Tan",http://arxiv.org/pdf/2410.18362v1,cs.CL
Improving Model Factuality with Fine-grained Critique-based Evaluator,"Factuality evaluation aims to detect factual errors produced by language
models (LMs) and hence guide the development of more factual models. Towards
this goal, we train a factuality evaluator, FenCE, that provides LM generators
with claim-level factuality feedback. We conduct data augmentation on a
combination of public judgment datasets to train FenCE to (1) generate textual
critiques along with scores and (2) make claim-level judgment based on diverse
source documents obtained by various tools. We then present a framework that
leverages FenCE to improve the factuality of LM generators by constructing
training data. Specifically, we generate a set of candidate responses, leverage
FenCE to revise and score each response without introducing lesser-known facts,
and train the generator by preferring highly scored revised responses.
Experiments show that our data augmentation methods improve the evaluator's
accuracy by 2.9% on LLM-AggreFact. With FenCE, we improve Llama2-7B-chat and
Llama3-8B-chat's factuality rate by 16.86% and 14.45% on FActScore,
outperforming state-of-the-art factuality finetuning methods by 8.83% and
6.96%.",2024-10-24,"Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, Han Fang, Carolyn Rose, Daniel Fried, Hejia Zhang",http://arxiv.org/pdf/2410.18359v2,cs.CL
AdaEDL: Early Draft Stopping for Speculative Decoding of Large Language Models via an Entropy-based Lower Bound on Token Acceptance Probability,"Speculative decoding is a powerful technique that attempts to circumvent the
autoregressive constraint of modern Large Language Models (LLMs). The aim of
speculative decoding techniques is to improve the average inference time of a
large, target model without sacrificing its accuracy, by using a more efficient
draft model to propose draft tokens which are then verified in parallel. The
number of draft tokens produced in each drafting round is referred to as the
draft length and is often a static hyperparameter chosen based on the
acceptance rate statistics of the draft tokens. However, setting a static draft
length can negatively impact performance, especially in scenarios where
drafting is expensive and there is a high variance in the number of tokens
accepted. Adaptive Entropy-based Draft Length (AdaEDL) is a simple, training
and parameter-free criteria which allows for early stopping of the token
drafting process by approximating a lower bound on the expected acceptance
probability of the drafted token based on the currently observed entropy of the
drafted logits. We show that AdaEDL consistently outperforms static
draft-length speculative decoding by 10%-57% as well as other training-free
draft-stopping techniques by upto 10% in a variety of settings and datasets. At
the same time, we show that AdaEDL is more robust than these techniques and
preserves performance in high-sampling-temperature scenarios. Since it is
training-free, in contrast to techniques that rely on the training of
dataset-specific draft-stopping predictors, AdaEDL can seamlessly be integrated
into a variety of pre-existing LLM systems.",2024-10-24,"Sudhanshu Agrawal, Wonseok Jeon, Mingu Lee",http://arxiv.org/pdf/2410.18351v1,cs.CL
Aggregated Knowledge Model: Enhancing Domain-Specific QA with Fine-Tuned and Retrieval-Augmented Generation Models,"This paper introduces a novel approach to enhancing closed-domain Question
Answering (QA) systems, focusing on the specific needs of the Lawrence Berkeley
National Laboratory (LBL) Science Information Technology (ScienceIT) domain.
Utilizing a rich dataset derived from the ScienceIT documentation, our study
embarks on a detailed comparison of two fine-tuned large language models and
five retrieval-augmented generation (RAG) models. Through data processing
techniques, we transform the documentation into structured
context-question-answer triples, leveraging the latest Large Language Models
(AWS Bedrock, GCP PaLM2, Meta LLaMA2, OpenAI GPT-4, Google Gemini-Pro) for
data-driven insights. Additionally, we introduce the Aggregated Knowledge Model
(AKM), which synthesizes responses from the seven models mentioned above using
K-means clustering to select the most representative answers. The evaluation of
these models across multiple metrics offers a comprehensive look into their
effectiveness and suitability for the LBL ScienceIT environment. The results
demonstrate the potential benefits of integrating fine-tuning and
retrieval-augmented strategies, highlighting significant performance
improvements achieved with the AKM. The insights gained from this study can be
applied to develop specialized QA systems tailored to specific domains.",2024-10-24,"Fengchen Liu, Jordan Jung, Wei Feinstein, Jeff DAmbrogia, Gary Jung",http://arxiv.org/pdf/2410.18344v1,cs.CL
Assessing the Creativity of LLMs in Proposing Novel Solutions to Mathematical Problems,"The mathematical capabilities of AI systems are complex and multifaceted.
Most existing research has predominantly focused on the correctness of
AI-generated solutions to mathematical problems. In this work, we argue that
beyond producing correct answers, AI systems should also be capable of, or
assist humans in, developing novel solutions to mathematical challenges. This
study explores the creative potential of Large Language Models (LLMs) in
mathematical reasoning, an aspect that has received limited attention in prior
research. We introduce a novel framework and benchmark, CreativeMath, which
encompasses problems ranging from middle school curricula to Olympic-level
competitions, designed to assess LLMs' ability to propose innovative solutions
after some known solutions have been provided. Our experiments demonstrate
that, while LLMs perform well on standard mathematical tasks, their capacity
for creative problem-solving varies considerably. Notably, the Gemini-1.5-Pro
model outperformed other LLMs in generating novel solutions. This research
opens a new frontier in evaluating AI creativity, shedding light on both the
strengths and limitations of LLMs in fostering mathematical innovation, and
setting the stage for future developments in AI-assisted mathematical
discovery.",2024-10-24,"Junyi Ye, Jingyi Gu, Xinyun Zhao, Wenpeng Yin, Guiling Wang",http://arxiv.org/pdf/2410.18336v1,cs.CL
Measuring individual semantic networks: A simulation study,"Accurately capturing individual differences in semantic networks is
fundamental to advancing our mechanistic understanding of semantic memory. Past
empirical attempts to construct individual-level semantic networks from
behavioral paradigms may be limited by data constraints. To assess these
limitations and propose improved designs for the measurement of individual
semantic networks, we conducted a recovery simulation investigating the
psychometric properties underlying estimates of individual semantic networks
obtained from two different behavioral paradigms: free associations and
relatedness judgment tasks. Our results show that successful inference of
semantic networks is achievable, but they also highlight critical challenges.
Estimates of absolute network characteristics are severely biased, such that
comparisons between behavioral paradigms and different design configurations
are often not meaningful. However, comparisons within a given paradigm and
design configuration can be accurate and generalizable when based on designs
with moderate numbers of cues, moderate numbers of responses, and cue sets
including diverse words. Ultimately, our results provide insights that help
evaluate past findings on the structure of semantic networks and design new
studies capable of more reliably revealing individual differences in semantic
networks.",2024-10-23,"Samuel Aeschbach, Rui Mata, Dirk U. Wulff",http://arxiv.org/pdf/2410.18326v1,cs.CL
CoreInfer: Accelerating Large Language Model Inference with Semantics-Inspired Adaptive Sparse Activation,"Large language models (LLMs) with billions of parameters have sparked a new
wave of exciting AI applications. However, their high computational costs and
memory demands during inference pose significant challenges. Adaptive sparse
activation inference, which activates only a small number of neurons for each
token, offers a novel way to accelerate model inference without degrading
performance, showing great potential for resource-constrained hardware devices.
Nevertheless, existing methods predict activated neurons based on individual
tokens with additional MLP, which involve frequent changes in activation maps
and resource calls, limiting the acceleration benefits of sparse activation. In
this paper, we introduce CoreInfer, an MLP-free adaptive sparse activation
inference method based on sentence-level prediction. Specifically, we propose
the concept of sentence-wise core neurons, which refers to the subset of
neurons most critical for a given sentence, and empirically demonstrate its
effectiveness. To determine the core neurons, we explore the correlation
between core neurons and the sentence's semantics. Remarkably, we discovered
that core neurons exhibit both stability and similarity in relation to the
sentence's semantics -- an insight overlooked by previous studies. Building on
this finding, we further design two semantic-based methods for predicting core
neurons to fit different input scenarios. In CoreInfer, the core neurons are
determined during the pre-filling stage and fixed during the encoding stage,
enabling zero-cost sparse inference. We evaluated the model generalization and
task generalization of CoreInfer across various models and tasks. Notably, on
an NVIDIA TITAN XP GPU, CoreInfer achieved a 10.33 times and 2.72 times speedup
compared to the Huggingface implementation and PowerInfer, respectively.",2024-10-23,"Qinsi Wang, Saeed Vahidian, Hancheng Ye, Jianyang Gu, Jianyi Zhang, Yiran Chen",http://arxiv.org/pdf/2410.18311v1,cs.CL
Robust and Explainable Depression Identification from Speech Using Vowel-Based Ensemble Learning Approaches,"This study investigates explainable machine learning algorithms for
identifying depression from speech. Grounded in evidence from speech production
that depression affects motor control and vowel generation, pre-trained
vowel-based embeddings, that integrate semantically meaningful linguistic
units, are used. Following that, an ensemble learning approach decomposes the
problem into constituent parts characterized by specific depression symptoms
and severity levels. Two methods are explored: a ""bottom-up"" approach with 8
models predicting individual Patient Health Questionnaire-8 (PHQ-8) item
scores, and a ""top-down"" approach using a Mixture of Experts (MoE) with a
router module for assessing depression severity. Both methods depict
performance comparable to state-of-the-art baselines, demonstrating robustness
and reduced susceptibility to dataset mean/median values. System explainability
benefits are discussed highlighting their potential to assist clinicians in
depression diagnosis and screening.",2024-10-23,"Kexin Feng, Theodora Chaspari",http://arxiv.org/pdf/2410.18298v1,cs.CL
Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI) in Bridging Communication Barrier among the Deaf Learners,"Kenyan Sign Language (KSL) is the primary language used by the deaf community
in Kenya. It is the medium of instruction from Pre-primary 1 to university
among deaf learners, facilitating their education and academic achievement.
Kenyan Sign Language is used for social interaction, expression of needs,
making requests and general communication among persons who are deaf in Kenya.
However, there exists a language barrier between the deaf and the hearing
people in Kenya. Thus, the innovation on AI4KSL is key in eliminating the
communication barrier. Artificial intelligence for KSL is a two-year research
project (2023-2024) that aims to create a digital open-access AI of spontaneous
and elicited data from a representative sample of the Kenyan deaf community.
The purpose of this study is to develop AI assistive technology dataset that
translates English to KSL as a way of fostering inclusion and bridging language
barriers among deaf learners in Kenya. Specific objectives are: Build KSL
dataset for spoken English and video recorded Kenyan Sign Language and to build
transcriptions of the KSL signs to a phonetic-level interface of the sign
language. In this paper, the methodology for building the dataset is described.
Data was collected from 48 teachers and tutors of the deaf learners and 400
learners who are Deaf. Participants engaged mainly in sign language elicitation
tasks through reading and singing. Findings of the dataset consisted of about
14,000 English sentences with corresponding KSL Gloss derived from a pool of
about 4000 words and about 20,000 signed KSL videos that are either signed
words or sentences. The second level of data outcomes consisted of 10,000 split
and segmented KSL videos. The third outcome of the dataset consists of 4,000
transcribed words into five articulatory parameters according to HamNoSys
system.",2024-10-23,"Lilian Wanzare, Joel Okutoyi, Maurine Kang'ahi, Mildred Ayere",http://arxiv.org/pdf/2410.18295v1,cs.CL
LEGO: Language Model Building Blocks,"Large language models (LLMs) are essential in natural language processing
(NLP) but are costly in data collection, pre-training, fine-tuning, and
inference. Task-specific small language models (SLMs) offer a cheaper
alternative but lack robustness and generalization. This paper proposes LEGO, a
novel technique to extract SLMs from an LLM and recombine them. Using
state-of-the-art LLM pruning strategies, we can create task- and user-specific
SLM building blocks that are efficient for fine-tuning and inference while also
preserving user data privacy. LEGO utilizes Federated Learning and a novel
aggregation scheme for the LLM reconstruction, maintaining robustness without
high costs and preserving user data privacy. We experimentally demonstrate the
versatility of LEGO, showing its ability to enable model heterogeneity and
mitigate the effects of data heterogeneity while maintaining LLM robustness.",2024-10-23,"Shrenik Bhansali, Alwin Jin, Tyler Lizzo, Larry Heck",http://arxiv.org/pdf/2410.18287v1,cs.CL
Multilingual Hallucination Gaps in Large Language Models,"Large language models (LLMs) are increasingly used as alternatives to
traditional search engines given their capacity to generate text that resembles
human language. However, this shift is concerning, as LLMs often generate
hallucinations, misleading or false information that appears highly credible.
In this study, we explore the phenomenon of hallucinations across multiple
languages in freeform text generation, focusing on what we call multilingual
hallucination gaps. These gaps reflect differences in the frequency of
hallucinated answers depending on the prompt and language used. To quantify
such hallucinations, we used the FactScore metric and extended its framework to
a multilingual setting. We conducted experiments using LLMs from the LLaMA,
Qwen, and Aya families, generating biographies in 19 languages and comparing
the results to Wikipedia pages. Our results reveal variations in hallucination
rates, especially between high and low resource languages, raising important
questions about LLM multilingual performance and the challenges in evaluating
hallucinations in multilingual freeform text generation.",2024-10-23,"Cléa Chataigner, Afaf Taïk, Golnoosh Farnadi",http://arxiv.org/pdf/2410.18270v1,cs.CL
Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models,"The dominant paradigm for RLHF is online and on-policy RL: synchronously
generating from the large language model (LLM) policy, labelling with a reward
model, and learning using feedback on the LLM's own outputs. While performant,
this paradigm is computationally inefficient. Inspired by classical deep RL
literature, we propose separating generation and learning in RLHF. This enables
asynchronous generation of new samples while simultaneously training on old
samples, leading to faster training and more compute-optimal scaling. However,
asynchronous training relies on an underexplored regime, online but off-policy
RLHF: learning on samples from previous iterations of our model which give a
worse training signal. We tackle the fundamental challenge in this regime: how
much off-policyness can we tolerate for asynchronous training to speed up
learning but maintain performance? Among several RLHF algorithms we test,
online DPO is found to be most robust to off-policy data, and robustness
increases with the scale of the policy model. We study further compute
optimizations for asynchronous RLHF but find that they come at a performance
cost, giving rise to a trade-off. We verify the scalability of asynchronous
RLHF by training a general-purpose chatbot from LLaMA 3.1 8B on an
instruction-following task ~40% faster than a synchronous run while matching
final performance. Finally, we extend our results to math and reasoning to
demonstrate asynchronous RL can finetune Rho 1B on GSM8k ~70% faster while
matching synchronous accuracy.",2024-10-23,"Michael Noukhovitch, Shengyi Huang, Sophie Xhonneux, Arian Hosseini, Rishabh Agarwal, Aaron Courville",http://arxiv.org/pdf/2410.18252v3,cs.CL
Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits,"We consider multi-draft speculative sampling, where the proposal sequences
are sampled independently from different draft models. At each step, a
token-level draft selection scheme takes a list of valid tokens as input and
produces an output token whose distribution matches that of the target model.
Previous works have demonstrated that the optimal scheme (which maximizes the
probability of accepting one of the input tokens) can be cast as a solution to
a linear program. In this work we show that the optimal scheme can be
decomposed into a two-step solution: in the first step an importance sampling
(IS) type scheme is used to select one intermediate token; in the second step
(single-draft) speculative sampling is applied to generate the output token.
For the case of two identical draft models we further 1) establish a necessary
and sufficient condition on the distributions of the target and draft models
for the acceptance probability to equal one and 2) provide an explicit
expression for the optimal acceptance probability. Our theoretical analysis
also motives a new class of token-level selection schemes based on weighted
importance sampling. Our experimental results demonstrate consistent
improvements in the achievable block efficiency and token rates over baseline
schemes in a number of scenarios.",2024-10-23,"Ashish Khisti, M. Reza Ebrahimi, Hassan Dbouk, Arash Behboodi, Roland Memisevic, Christos Louizos",http://arxiv.org/pdf/2410.18234v2,cs.CL
Generalizations across filler-gap dependencies in neural language models,"Humans develop their grammars by making structural generalizations from
finite input. We ask how filler-gap dependencies, which share a structural
generalization despite diverse surface forms, might arise from the input. We
explicitly control the input to a neural language model (NLM) to uncover
whether the model posits a shared representation for filler-gap dependencies.
We show that while NLMs do have success differentiating grammatical from
ungrammatical filler-gap dependencies, they rely on superficial properties of
the input, rather than on a shared generalization. Our work highlights the need
for specific linguistic inductive biases to model language acquisition.",2024-10-23,"Katherine Howitt, Sathvik Nair, Allison Dods, Robert Melvin Hopkins",http://arxiv.org/pdf/2410.18225v1,cs.CL
Optimizing the role of human evaluation in LLM-based spoken document summarization systems,"The emergence of powerful LLMs has led to a paradigm shift in abstractive
summarization of spoken documents. The properties that make LLMs so valuable
for this task -- creativity, ability to produce fluent speech, and ability to
abstract information from large corpora -- also present new challenges to
evaluating their content. Quick, cost-effective automatic evaluations such as
ROUGE and BERTScore offer promise, but do not yet show competitive performance
when compared to human evaluations. We draw on methodologies from the social
sciences to propose an evaluation paradigm for spoken document summarization
explicitly tailored for generative AI content. We provide detailed evaluation
criteria and best practices guidelines to ensure robustness in the experimental
design, replicability, and trustworthiness of human evaluation studies. We
additionally include two case studies that show how these human-in-the-loop
evaluation methods have been implemented at a major U.S. technology company.",2024-10-23,"Margaret Kroll, Kelsey Kraus",http://arxiv.org/pdf/2410.18218v1,cs.CL
Advancing NLP Security by Leveraging LLMs as Adversarial Engines,"This position paper proposes a novel approach to advancing NLP security by
leveraging Large Language Models (LLMs) as engines for generating diverse
adversarial attacks. Building upon recent work demonstrating LLMs'
effectiveness in creating word-level adversarial examples, we argue for
expanding this concept to encompass a broader range of attack types, including
adversarial patches, universal perturbations, and targeted attacks. We posit
that LLMs' sophisticated language understanding and generation capabilities can
produce more effective, semantically coherent, and human-like adversarial
examples across various domains and classifier architectures. This paradigm
shift in adversarial NLP has far-reaching implications, potentially enhancing
model robustness, uncovering new vulnerabilities, and driving innovation in
defense mechanisms. By exploring this new frontier, we aim to contribute to the
development of more secure, reliable, and trustworthy NLP systems for critical
applications.",2024-10-23,"Sudarshan Srinivasan, Maria Mahbub, Amir Sadovnik",http://arxiv.org/pdf/2410.18215v1,cs.CL
Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks,"Recent advancements in Large Language Models (LLMs) have sparked widespread
concerns about their safety. Recent work demonstrates that safety alignment of
LLMs can be easily removed by fine-tuning with a few adversarially chosen
instruction-following examples, i.e., fine-tuning attacks. We take a further
step to understand fine-tuning attacks in multilingual LLMs. We first discover
cross-lingual generalization of fine-tuning attacks: using a few adversarially
chosen instruction-following examples in one language, multilingual LLMs can
also be easily compromised (e.g., multilingual LLMs fail to refuse harmful
prompts in other languages). Motivated by this finding, we hypothesize that
safety-related information is language-agnostic and propose a new method termed
Safety Information Localization (SIL) to identify the safety-related
information in the model parameter space. Through SIL, we validate this
hypothesis and find that only changing 20% of weight parameters in fine-tuning
attacks can break safety alignment across all languages. Furthermore, we
provide evidence to the alternative pathways hypothesis for why freezing
safety-related parameters does not prevent fine-tuning attacks, and we
demonstrate that our attack vector can still jailbreak LLMs adapted to new
languages.",2024-10-23,"Samuele Poppi, Zheng-Xin Yong, Yifei He, Bobbie Chern, Han Zhao, Aobo Yang, Jianfeng Chi",http://arxiv.org/pdf/2410.18210v2,cs.CL
CorrectionLM: Self-Corrections with SLM for Dialogue State Tracking,"Large language models (LLMs) have demonstrated self-improvement capabilities
via feedback and refinement, but current small language models (SLMs) have had
limited success in this area. Existing correction approaches often rely on
distilling knowledge from LLMs, which imposes significant computation demands.
In this work, we introduce CORRECTIONLM, a novel correction framework that
enables SLMs to self-correct using in-context exemplars without LLM
involvement. Applied to two dialogue state tracking (DST) tasks in low-resource
settings, CORRECTIONLM achieves results similar to a state-of-the-art LLM at a
small fraction of the computation costs.",2024-10-23,"Chia-Hsuan Lee, Hao Cheng, Mari Ostendorf",http://arxiv.org/pdf/2410.18209v1,cs.CL
ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment,"Data selection is crucial for optimizing language model (LM) performance on
specific tasks, yet most existing methods fail to effectively consider the
target task distribution.
  Current approaches either ignore task-specific requirements entirely or rely
on approximations that fail to capture the nuanced patterns needed for tasks
like Autoformalization or code generation.
  Methods that do consider the target distribution often rely on simplistic,
sometimes noisy, representations, like hashed n-gram features, which can lead
to collisions and introduce noise.
  We introduce ZIP-FIT, a data selection framework that uses gzip compression
to directly measure alignment between potential training data and the target
task distribution.
  In extensive evaluations on Autoformalization and Python code generation,
ZIP-FIT significantly outperforms leading baselines like DSIR and D4.
  Models trained on ZIP-FIT-selected data achieve their lowest cross-entropy
loss up to 85.1\% faster than baselines, demonstrating that better task
alignment leads to more efficient learning.
  In addition, ZIP-FIT performs selection up to 65.8\% faster than DSIR and two
orders of magnitude faster than D4.
  Notably, ZIP-FIT shows that smaller, well-aligned datasets often outperform
larger but less targeted ones, demonstrating that a small amount of higher
quality data is superior to a large amount of lower quality data.
  Our results imply that task-aware data selection is crucial for efficient
domain adaptation, and that compression offers a principled way to measure task
alignment.
  By showing that targeted data selection can dramatically improve
task-specific performance, our work provides new insights into the relationship
between data quality, task alignment, and model learning efficiency.",2024-10-23,"Elyas Obbad, Iddah Mlauzi, Brando Miranda, Rylan Schaeffer, Kamal Obbad, Suhana Bedi, Sanmi Koyejo",http://arxiv.org/pdf/2410.18194v2,cs.CL
ALTA: Compiler-Based Analysis of Transformers,"We propose a new programming language called ALTA and a compiler that can map
ALTA programs to Transformer weights. ALTA is inspired by RASP, a language
proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler
from RASP programs to Transformer weights. ALTA complements and extends this
prior work, offering the ability to express loops and to compile programs to
Universal Transformers, among other advantages. ALTA allows us to
constructively show how Transformers can represent length-invariant algorithms
for computing parity and addition, as well as a solution to the SCAN benchmark
of compositional generalization tasks, without requiring intermediate
scratchpad decoding steps. We also propose tools to analyze cases where the
expressibility of an algorithm is established, but end-to-end training on a
given training set fails to induce behavior consistent with the desired
algorithm. To this end, we explore training from ALTA execution traces as a
more fine-grained supervision signal. This enables additional experiments and
theoretical analyses relating the learnability of various algorithms to data
availability and modeling decisions, such as positional encodings. We make the
ALTA framework -- language specification, symbolic interpreter, and weight
compiler -- available to the community to enable further applications and
insights.",2024-10-23,"Peter Shaw, James Cohan, Jacob Eisenstein, Kenton Lee, Jonathan Berant, Kristina Toutanova",http://arxiv.org/pdf/2410.18077v1,cs.CL
TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts,"Recently, multimodal large language models (MLLMs) have received much
attention for their impressive capabilities. The evaluation of MLLMs is
becoming critical to analyzing attributes of MLLMs and providing valuable
insights. However, current benchmarks overlook the problem of prompt
sensitivity - minor prompt variations may lead to significant performance
fluctuations. Thus, inappropriate prompts may obscure the models' capabilities,
underestimating the models' performance. Moreover, different models have
different preferences for different prompts, and thus, using the same prompt
for all models will cause evaluation bias. This paper analyzes this deficiency
in existing benchmarks and further introduces a new evaluation framework named
TP-Eval, which introduces a prompt customization method to reduce evaluation
biases and tap models' potential. TP-Eval will rewrite the original prompts to
different customized prompts for different models. In particular, we propose
some well-designed modules for prompt customization tailored to the scenario of
MLLM evaluation. Extensive experiments demonstrate the effectiveness of our
approach to uncovering models' capabilities, and TP-Eval should benefit the
community in developing more comprehensive and convincing MLLM evaluation
benchmarks.",2024-10-23,"Yuxuan Xie, Tianhua Li, Wenqi Shao, Kaipeng Zhang",http://arxiv.org/pdf/2410.18071v1,cs.CL
Gazelle: An Instruction Dataset for Arabic Writing Assistance,"Writing has long been considered a hallmark of human intelligence and remains
a pinnacle task for artificial intelligence (AI) due to the intricate cognitive
processes involved. Recently, rapid advancements in generative AI, particularly
through the development of Large Language Models (LLMs), have significantly
transformed the landscape of writing assistance. However, underrepresented
languages like Arabic encounter significant challenges in the development of
advanced AI writing tools, largely due to the limited availability of data.
This scarcity constrains the training of effective models, impeding the
creation of sophisticated writing assistance technologies. To address these
issues, we present Gazelle, a comprehensive dataset for Arabic writing
assistance. In addition, we offer an evaluation framework designed to enhance
Arabic writing assistance tools. Our human evaluation of leading LLMs,
including GPT-4, GPT-4o, Cohere Command R+, and Gemini 1.5 Pro, highlights
their respective strengths and limitations in addressing the challenges of
Arabic writing. Our findings underscore the need for continuous model training
and dataset enrichment to manage the complexities of Arabic language
processing, paving the way for more effective AI-powered Arabic writing tools.",2024-10-23,"Samar M. Magdy, Fakhraddin Alwajih, Sang Yun Kwon, Reem Abdel-Salam, Muhammad Abdul-Mageed",http://arxiv.org/pdf/2410.18163v2,cs.CL
CLEAR: Character Unlearning in Textual and Visual Modalities,"Machine Unlearning (MU) is critical for removing private or hazardous
information from deep learning models. While MU has advanced significantly in
unimodal (text or vision) settings, multimodal unlearning (MMU) remains
underexplored due to the lack of open benchmarks for evaluating cross-modal
data removal. To address this gap, we introduce CLEAR, the first open-source
benchmark designed specifically for MMU. CLEAR contains 200 fictitious
individuals and 3,700 images linked with corresponding question-answer pairs,
enabling a thorough evaluation across modalities. We conduct a comprehensive
analysis of 11 MU methods (e.g., SCRUB, gradient ascent, DPO) across four
evaluation sets, demonstrating that jointly unlearning both modalities
outperforms single-modality approaches. The dataset is available at
https://huggingface.co/datasets/therem/CLEAR",2024-10-23,"Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina",http://arxiv.org/pdf/2410.18057v3,cs.CL
LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering,"Long-Context Question Answering (LCQA), a challenging task, aims to reason
over long-context documents to yield accurate answers to questions. Existing
long-context Large Language Models (LLMs) for LCQA often struggle with the
""lost in the middle"" issue. Retrieval-Augmented Generation (RAG) mitigates this
issue by providing external factual evidence. However, its chunking strategy
disrupts the global long-context information, and its low-quality retrieval in
long contexts hinders LLMs from identifying effective factual details due to
substantial noise. To this end, we propose LongRAG, a general,
dual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance
RAG's understanding of complex long-context knowledge (i.e., global information
and factual details). We design LongRAG as a plug-and-play paradigm,
facilitating adaptation to various domains and LLMs. Extensive experiments on
three multi-hop datasets demonstrate that LongRAG significantly outperforms
long-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG
(up by 17.25%). Furthermore, we conduct quantitative ablation studies and
multi-dimensional analyses, highlighting the effectiveness of the system's
components and fine-tuning strategies. Data and code are available at
https://github.com/QingFei1/LongRAG.",2024-10-23,"Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, Jie Tang",http://arxiv.org/pdf/2410.18050v2,cs.CL
Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases,"Keyphrase selection is a challenging task in natural language processing that
has a wide range of applications. Adapting existing supervised and unsupervised
solutions for the Russian language faces several limitations due to the rich
morphology of Russian and the limited number of training datasets available.
Recent studies conducted on English texts show that large language models
(LLMs) successfully address the task of generating keyphrases. LLMs allow
achieving impressive results without task-specific fine-tuning, using text
prompts instead. In this work, we access the performance of prompt-based
methods for generating keyphrases for Russian scientific abstracts. First, we
compare the performance of zero-shot and few-shot prompt-based methods,
fine-tuned models, and unsupervised methods. Then we assess strategies for
selecting keyphrase examples in a few-shot setting. We present the outcomes of
human evaluation of the generated keyphrases and analyze the strengths and
weaknesses of the models through expert assessment. Our results suggest that
prompt-based methods can outperform common baselines even using simple text
prompts.",2024-10-23,"Anna Glazkova, Dmitry Morozov, Timur Garipov",http://arxiv.org/pdf/2410.18040v1,cs.CL
MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning,"Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants are
highly effective parameter-efficient fine-tuning (PEFT) methods. However, they
introduce significant latency in multi-tenant settings due to the LoRA modules
and MOE routers added to multiple linear modules in the Transformer layer. To
address this issue, we propose Mixture of Low-Rank Adaptation (MiLoRA), a novel
and efficient LoRA variant. MiLoRA differs from previous MOE-style LoRA methods
by considering each LoRA module as an expert and employing a prompt-aware
routing mechanism. This mechanism calculates expert routing results once before
generating the first new token and reuses these results for subsequent tokens,
reducing latency. Extensive experiments and analysis on commonsense reasoning
tasks, math reasoning tasks, and widely used LLM evaluation benchmarks
demonstrate that MiLoRA consistently outperforms strong PEFT baselines with
comparable tunable parameter budgets. Additionally, MiLoRA significantly
reduces latency in multi-tenant settings compared to previous LoRA-based
methods.",2024-10-23,"Jingfan Zhang, Yi Zhao, Dan Chen, Xing Tian, Huanran Zheng, Wei Zhu",http://arxiv.org/pdf/2410.18035v1,cs.CL
GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration,"Graphs are widely used for modeling relational data in real-world scenarios,
such as social networks and urban computing. Existing LLM-based graph analysis
approaches either integrate graph neural networks (GNNs) for specific machine
learning tasks, limiting their transferability, or rely solely on LLMs'
internal reasoning ability, resulting in suboptimal performance. To address
these limitations, we take advantage of recent advances in LLM-based agents,
which have shown capabilities of utilizing external knowledge or tools for
problem solving. By simulating human problem-solving strategies such as analogy
and collaboration, we propose a multi-agent system based on LLMs named
GraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from
three modules, and the agents with different specialities can collaborate with
each other to address complex problems. Specifically, (1) input-output
normalization module: the question agent extracts and refines four key
arguments from the original question, facilitating the problem understanding,
and the answer agent organizes the results to meet the output requirement; (2)
external knowledge retrieval module: we first build a knowledge base consisting
of relevant documentation and experience information, and then the search agent
retrieves the most relevant entries for each question. (3) problem-solving
module: given the retrieved information from search agent, the coding agent
uses established algorithms via programming to generate solutions, and in case
the coding agent does not work, the reasoning agent will directly compute the
results without programming. Extensive experiments on six graph analysis
benchmarks demonstrate that GraphTeam achieves state-of-the-art performance
with an average 25.85% improvement over the best baseline in terms of accuracy.
The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.",2024-10-23,"Xin Sky Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang",http://arxiv.org/pdf/2410.18032v4,cs.CL
Cross-lingual Transfer of Reward Models in Multilingual Alignment,"Reinforcement learning with human feedback (RLHF) is shown to largely benefit
from precise reward models (RMs). However, recent studies in reward modeling
schemes are skewed towards English, limiting the applicability of RLHF in
multilingual alignments. In this work, we investigate the cross-lingual
transfer of RMs trained in diverse languages, primarily from English. Our
experimental results demonstrate the strong cross-lingual transfer of English
RMs, exceeding target language RMs by 3~4% average increase in Multilingual
RewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through
the representation shifts. Finally, we perform multilingual alignment to
exemplify how cross-lingual transfer in RM propagates to enhanced multilingual
instruction-following capability, along with extensive analyses on
off-the-shelf RMs. We release the code, model, and data.",2024-10-23,"Jiwoo Hong, Noah Lee, Rodrigo Martínez-Castaño, César Rodríguez, James Thorne",http://arxiv.org/pdf/2410.18027v2,cs.CL
Adaptive Segment-level Reward: Bridging the Gap Between Action and Reward Space in Alignment,"Reinforcement Learning (RL) has proven highly effective in aligning Large
Language Models (LLMs) with human preferences. Typical RL methods optimize
under an overall sequence reward, which can lead to a suboptimal learning
process. This reflects a key credit assignment problem: identifying which
tokens to reinforce or suppress. To rectify these shortcomings, step-wise and
token-wise methods have been proposed. However, step-wise methods rely on
punctuation segmentation and still cannot accurately identify the key tokens.
The token-level approach is too fine-grained, attending to many unimportant
tokens and thus introducing a large amount of noise. To assign more accurate
rewards to different tokens, improving credit assignment, we propose the
""Adaptive Segment-wise Reward"" method. We employ semantic meaning, rather than
punctuation, to adaptively delineate segments. Experiments demonstrate that our
method can be integrated into various training methods. Compared to training
methods \textit{without} our approach, our method improves the success rate on
adversarial samples by 10\%, and achieves a 1.3\% improvement on evaluation
benchmarks such as MMLU, GSM8K, HumanEval, etc.",2024-10-23,"Yanshi Li, Shaopan Xiong, Gengru Chen, Xiaoyang Li, Yijia Luo, Xingyuan Bu, Yingshui Tan, Wenbo Su, Bo Zheng",http://arxiv.org/pdf/2411.00809v3,cs.CL
Scaling Stick-Breaking Attention: An Efficient Implementation and In-depth Study,"The self-attention mechanism traditionally relies on the softmax operator,
necessitating positional embeddings like RoPE, or position biases to account
for token order. But current methods using still face length generalisation
challenges. We investigate an alternative attention mechanism based on the
stick-breaking process in larger scale settings. The method works as follows:
For each token before the current, we determine a break point, which represents
the proportion of the stick, the weight of the attention, to allocate to the
current token. We repeat this on the remaining stick, until all tokens are
allocated a weight, resulting in a sequence of attention weights. This process
naturally incorporates recency bias, which has linguistic motivations for
grammar parsing. We study the implications of replacing the conventional
softmax-based attention mechanism with stick-breaking attention. We then
discuss implementation of numerically stable stick-breaking attention and adapt
Flash Attention to accommodate this mechanism. When used as a drop-in
replacement for current softmax+RoPE attention systems, we find that
stick-breaking attention performs competitively with current methods on length
generalisation and downstream tasks. Stick-breaking also performs well at
length generalisation, allowing a model trained with $2^{11}$ context window to
perform well at $2^{14}$ with perplexity improvements.",2024-10-23,"Shawn Tan, Songlin Yang, Aaron Courville, Rameswar Panda, Yikang Shen",http://arxiv.org/pdf/2410.17980v2,cs.CL
Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages,"This exploratory study investigates the potential of multilingual Automatic
Post-Editing (APE) systems to enhance the quality of machine translations for
low-resource Indo-Aryan languages. Focusing on two closely related language
pairs, English-Marathi and English-Hindi, we exploit the linguistic
similarities to develop a robust multilingual APE model. To facilitate
cross-linguistic transfer, we generate synthetic Hindi-Marathi and
Marathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation
(QE)-APE multi-task learning framework. While the experimental results
underline the complementary nature of APE and QE, we also observe that QE-APE
multitask learning facilitates effective domain adaptation. Our experiments
demonstrate that the multilingual APE models outperform their corresponding
English-Hindi and English-Marathi single-pair models by $2.5$ and $2.39$ TER
points, respectively, with further notable improvements over the multilingual
APE model observed through multi-task learning ($+1.29$ and $+1.44$ TER
points), data augmentation ($+0.53$ and $+0.45$ TER points) and domain
adaptation ($+0.35$ and $+0.45$ TER points). We release the synthetic data,
code, and models accrued during this study publicly at
https://github.com/cfiltnlp/Multilingual-APE.",2024-10-23,"Sourabh Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya",http://arxiv.org/pdf/2410.17973v1,cs.CL
Dependency Graph Parsing as Sequence Labeling,"Various linearizations have been proposed to cast syntactic dependency
parsing as sequence labeling. However, these approaches do not support more
complex graph-based representations, such as semantic dependencies or enhanced
universal dependencies, as they cannot handle reentrancy or cycles. By
extending them, we define a range of unbounded and bounded linearizations that
can be used to cast graph parsing as a tagging task, enlarging the toolbox of
problems that can be solved under this paradigm. Experimental results on
semantic dependency and enhanced UD parsing show that with a good choice of
encoding, sequence-labeling dependency graph parsers combine high efficiency
with accuracies close to the state of the art, in spite of their simplicity.",2024-10-23,"Ana Ezquerro, David Vilares, Carlos Gómez-Rodríguez",http://arxiv.org/pdf/2410.17972v1,cs.CL
A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024,"The eRisk laboratory aims to address issues related to early risk detection
on the Web. In this year's edition, three tasks were proposed, where Task 2 was
about early detection of signs of anorexia. Early risk detection is a problem
where precision and speed are two crucial objectives. Our research group solved
Task 2 by defining a CPI+DMC approach, addressing both objectives
independently, and a time-aware approach, where precision and speed are
considered a combined single-objective. We implemented the last approach by
explicitly integrating time during the learning process, considering the
ERDE{\theta} metric as the training objective. It also allowed us to
incorporate temporal metrics to validate and select the optimal models. We
achieved outstanding results for the ERDE50 metric and ranking-based metrics,
demonstrating consistency in solving ERD problems.",2024-10-23,"Horacio Thompson, Marcelo Errecalde",http://arxiv.org/pdf/2410.17963v1,cs.CL
Zeitenwenden: Detecting changes in the German political discourse,"From a monarchy to a democracy, to a dictatorship and back to a democracy --
the German political landscape has been constantly changing ever since the
first German national state was formed in 1871. After World War II, the Federal
Republic of Germany was formed in 1949. Since then every plenary session of the
German Bundestag was logged and even has been digitized over the course of the
last few years. We analyze these texts using a time series variant of the topic
model LDA to investigate which events had a lasting effect on the political
discourse and how the political topics changed over time. This allows us to
detect changes in word frequency (and thus key discussion points) in political
discourse.",2024-10-23,"Kai-Robin Lange, Jonas Rieger, Niklas Benner, Carsten Jentsch",http://arxiv.org/pdf/2410.17960v1,cs.CL
ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference,"Sparse Mixture of Experts (MoE) models, while outperforming dense Large
Language Models (LLMs) in terms of performance, face significant deployment
challenges during inference due to their high memory demands. Existing
offloading techniques, which involve swapping activated and idle experts
between the GPU and CPU, often suffer from rigid expert caching mechanisms.
These mechanisms fail to adapt to dynamic routing, leading to inefficient cache
utilization, or incur prohibitive costs for prediction training. To tackle
these inference-specific challenges, we introduce ExpertFlow, a comprehensive
system specifically designed to enhance inference efficiency by accommodating
flexible routing and enabling efficient expert scheduling between CPU and GPU.
This reduces overhead and boosts system performance. Central to our approach is
a predictive routing path-based offloading mechanism that utilizes a
lightweight predictor to accurately forecast routing paths before computation
begins. This proactive strategy allows for real-time error correction in expert
caching, significantly increasing cache hit ratios and reducing the frequency
of expert transfers, thereby minimizing I/O overhead. Additionally, we
implement a dynamic token scheduling strategy that optimizes MoE inference by
rearranging input tokens across different batches. This method not only reduces
the number of activated experts per batch but also improves computational
efficiency. Our extensive experiments demonstrate that ExpertFlow achieves up
to 93.72\% GPU memory savings and enhances inference speed by 2 to 10 times
compared to baseline methods, highlighting its effectiveness and utility as a
robust solution for resource-constrained inference scenarios.",2024-10-23,"Xin He, Shunkang Zhang, Yuxin Wang, Haiyan Yin, Zihao Zeng, Shaohuai Shi, Zhenheng Tang, Xiaowen Chu, Ivor Tsang, Ong Yew Soon",http://arxiv.org/pdf/2410.17954v1,cs.CL
SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains,"Retrieval-augmented generation (RAG) enhances the question-answering (QA)
abilities of large language models (LLMs) by integrating external knowledge.
However, adapting general-purpose RAG systems to specialized fields such as
science and medicine poses unique challenges due to distribution shifts and
limited access to domain-specific data. To tackle this, we propose SimRAG, a
self-training approach that equips the LLM with joint capabilities of question
answering and question generation for domain adaptation. Our method first
fine-tunes the LLM on instruction-following, question-answering, and
search-related data. Then, it prompts the same LLM to generate diverse
domain-relevant questions from unlabeled corpora, with an additional filtering
strategy to retain high-quality synthetic examples. By leveraging these
self-generated synthetic examples, the LLM can improve their performance on
domain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone
sizes and three domains, demonstrate that SimRAG outperforms baselines by
1.2\%--8.6\%.",2024-10-23,"Ran Xu, Hui Liu, Sreyashi Nag, Zhenwei Dai, Yaochen Xie, Xianfeng Tang, Chen Luo, Yang Li, Joyce C. Ho, Carl Yang, Qi He",http://arxiv.org/pdf/2410.17952v2,cs.CL
Future Token Prediction -- Causal Language Modelling with Per-Token Semantic State Vector for Multi-Token Prediction,"Causal decoder-only transformer models used for generative language
modelling, such as Generative Pre-trained Transformers (GPT), are trained to
predict the next token in a sequence based only on its previous tokens. Despite
this simple training objective, they have proved to be powerful AI tools.
However, only predicting the next token results in top layer embedding vectors
that are highly token-focused. There may be benefits in generating embedding
vectors at each token position that better capture the overall meaning of
longer sequences of future text. Recent studies matching brain scans with deep
language models suggest that humans also predict upcoming words when listening
or reading but consider multiple future tokens rather than just one.
  This research investigates a new pretraining method called Future Token
Prediction (FTP). In FTP, a large transformer encoder generates top layer
embedding vectors for each token position, which, instead of being passed to a
language head, are linearly and expansively projected to a pseudo-sequence,
which is cross attended to by a small transformer decoder to predict the next N
tokens forward from that position in the sequence.
  The top layer embedding vectors from FTP models exhibit distinct properties
compared to those from standard GPT models, varying smoothly along a text
sequence as measured by cosine similarity between adjacent tokens. Text
generated by FTP models show improved topic coherence compared to standard
GPT-like models trained with the same prediction perplexity for the next single
token. The vectors are shown to better represent the topic of text based on the
results of text classification examples. On a toy, but complex, coding problem,
FTP networks produce significantly better results than GPT networks.",2024-10-23,Nicholas Walker,http://arxiv.org/pdf/2410.18160v1,cs.CL
ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams,"Recent advancements in Text-to-Speech (TTS) technology have led to
natural-sounding speech for English, primarily due to the availability of
large-scale, high-quality web data. However, many other languages lack access
to such resources, relying instead on limited studio-quality data. This
scarcity results in synthesized speech that often suffers from intelligibility
issues, particularly with low-frequency character bigrams. In this paper, we
propose three solutions to address this challenge. First, we leverage
high-quality data from linguistically or geographically related languages to
improve TTS for the target language. Second, we utilize low-quality Automatic
Speech Recognition (ASR) data recorded in non-studio environments, which is
refined using denoising and speech enhancement models. Third, we apply
knowledge distillation from large-scale models using synthetic data to generate
more robust outputs. Our experiments with Hindi demonstrate significant
reductions in intelligibility issues, as validated by human evaluators. We
propose this methodology as a viable alternative for languages with limited
access to high-quality data, enabling them to collectively benefit from shared
resources.",2024-10-23,"Srija Anand, Praveen Srinivasa Varadhan, Mehak Singal, Mitesh M. Khapra",http://arxiv.org/pdf/2410.17901v1,cs.CL
Value Residual Learning,"While Transformer models have achieved remarkable success in various domains,
the effectiveness of information propagation through deep networks remains a
critical challenge. Standard hidden state residuals often fail to adequately
preserve initial token-level information in deeper layers. This paper
introduces ResFormer, a novel architecture that enhances information flow by
incorporating value residual connections in addition to hidden state residuals.
And a variant is the SVFormer, where all layers share the first layer's value
embedding. Comprehensive empirical evidence demonstrates ResFormer achieves
equivalent validation loss with 13.3\% fewer model parameters and 15.4\% less
training data compared to Transformer, while maintaining similar memory usage
and computational cost. Besides, SVFormer reduces KV cache size by nearly half
with only a small performance penalty and can be integrated with other
KV-efficient methods, yielding further reductions in KV cache, with performance
influenced by sequence length and cumulative learning rate.",2024-10-23,"Zhanchao Zhou, Tianyi Wu, Zhiyun Jiang, Fares Obeid, Zhenzhong Lan",http://arxiv.org/pdf/2410.17897v4,cs.CL
Scaling Diffusion Language Models via Adaptation from Autoregressive Models,"Diffusion Language Models (DLMs) have emerged as a promising new paradigm for
text generative modeling, potentially addressing limitations of autoregressive
(AR) models. However, current DLMs have been studied at a smaller scale
compared to their AR counterparts and lack fair comparison on language modeling
benchmarks. Additionally, training diffusion models from scratch at scale
remains challenging. Given the prevalence of open-source AR language models, we
propose adapting these models to build text diffusion models. We demonstrate
connections between AR and diffusion modeling objectives and introduce a simple
continual pre-training approach for training diffusion models. Through
systematic evaluation on language modeling, reasoning, and commonsense
benchmarks, we show that we can convert AR models ranging from 127M to 7B
parameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA,
using less than 200B tokens for training. Our experimental results reveal that
these models outperform earlier DLMs and are competitive with their AR
counterparts. We release a suite of DLMs (127M-355M-7B) capable of generating
fluent text, performing in-context learning, filling in the middle without
prompt re-ordering, and following instructions
https://github.com/HKUNLP/DiffuLLaMA.",2024-10-23,"Shansan Gong, Shivam Agarwal, Yizhe Zhang, Jiacheng Ye, Lin Zheng, Mukai Li, Chenxin An, Peilin Zhao, Wei Bi, Jiawei Han, Hao Peng, Lingpeng Kong",http://arxiv.org/pdf/2410.17891v2,cs.CL
SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments,"The application of natural language processing on political texts as well as
speeches has become increasingly relevant in political sciences due to the
ability to analyze large text corpora which cannot be read by a single person.
But such text corpora often lack critical meta information, detailing for
instance the party, age or constituency of the speaker, that can be used to
provide an analysis tailored to more fine-grained research questions. To enable
researchers to answer such questions with quantitative approaches such as
natural language processing, we provide the SpeakGer data set, consisting of
German parliament debates from all 16 federal states of Germany as well as the
German Bundestag from 1947-2023, split into a total of 10,806,105 speeches.
This data set includes rich meta data in form of information on both reactions
from the audience towards the speech as well as information about the speaker's
party, their age, their constituency and their party's political alignment,
which enables a deeper analysis. We further provide three exploratory analyses,
detailing topic shares of different parties throughout time, a descriptive
analysis of the development of the age of an average speaker as well as a
sentiment analysis of speeches of different parties with regards to the
COVID-19 pandemic.",2024-10-23,"Kai-Robin Lange, Carsten Jentsch",http://arxiv.org/pdf/2410.17886v1,cs.CL
Understanding Layer Significance in LLM Alignment,"Aligning large language models (LLMs) through supervised fine-tuning is
essential for tailoring them to specific applications. Recent studies suggest
that alignment primarily adjusts a model's presentation style rather than its
foundational knowledge, indicating that only certain components of the model
are significantly impacted. To uncover how alignment affects model behavior at
a granular level, we propose identifying which layers within LLMs are most
critical to the alignment process. Our approach, named ILA, involves learning a
binary mask for the parameter changes in each layer during alignment, as an
indicator of layer significance. Experimental results reveal that, despite
substantial differences in alignment datasets, the important layers of a model
identified by ILA exhibit nearly 90\% overlap, highlighting fundamental
patterns in LLM alignment. The results also indicate that freezing
non-essential layers improves overall model performance, while selectively
tuning the most critical layers significantly enhances fine-tuning efficiency
with minimal performance loss. Finally, we discuss how these findings extend
from LLM alignment to reasoning.",2024-10-23,"Guangyuan Shi, Zexin Lu, Xiaoyu Dong, Wenlong Zhang, Xuanyu Zhang, Yujie Feng, Xiao-Ming Wu",http://arxiv.org/pdf/2410.17875v3,cs.CL
"Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination","Tree of Thoughts (ToT) is a reasoning strategy for Large Language Models
(LLMs) that employs a generator to suggest reasoning steps and a discriminator
to decide which steps to implement. ToT demonstrates strong performance on
reasoning tasks, often surpassing simple methods such as Input-Output (IO)
prompting and Chain-of-Thought (CoT) reasoning. However, ToT does not
consistently outperform such simpler methods across all models, leaving large
knowledge gaps on the conditions under which ToT is most beneficial. In this
paper, we analyze the roles of the generator and discriminator separately to
better understand the conditions when ToT is beneficial. We find that the
generator plays a more critical role than the discriminator in driving the
success of ToT. Scaling the generator leads to notable improvements in ToT
performance, even when using a smaller model as the discriminator, whereas
scaling the discriminator with a fixed generator yields only marginal gains.
Our results show that models across different scales exhibit comparable
discrimination capabilities, yet differ significantly in their generative
performance for ToT.",2024-10-23,"Qiqi Chen, Xinpeng Wang, Philipp Mondorf, Michael A. Hedderich, Barbara Plank",http://arxiv.org/pdf/2410.17820v2,cs.CL
OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation,"Full-duplex spoken dialogue systems significantly surpass traditional
turn-based dialogue systems, as they allow simultaneous bidirectional
communication, closely mirroring human-human interactions. However, achieving
low latency and natural interactions in full-duplex dialogue systems remains a
significant challenge, especially considering human conversation dynamics such
as interruptions, backchannels, and overlapping speech. In this paper, we
introduce a novel End-to-End GPT-based model OmniFlatten for full-duplex
conversation, capable of effectively modeling the complex behaviors inherent to
natural conversations with low latency. To achieve full-duplex conversation
capabilities, we propose a multi-stage post-training scheme that progressively
adapts a text large language model (LLM) backbone into a speech-text dialogue
LLM, capable of generating text and speech in real time, without modifying the
architecture of the backbone LLM. The training process comprises three stages:
modality alignment, half-duplex dialogue learning, and full-duplex dialogue
learning. In all training stages, we standardize the data using a flattening
operation, which enables unifying the training methods and the GPT backbone
across different modalities and tasks. Our approach offers a simple modeling
technique and a promising research direction for developing efficient and
natural end-to-end full-duplex spoken dialogue systems. Audio samples of
dialogues generated by OmniFlatten can be found at this web site
(https://omniflatten.github.io/).",2024-10-23,"Qinglin Zhang, Luyao Cheng, Chong Deng, Qian Chen, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, Chaohong Tan, Zhihao Du, Shiliang Zhang",http://arxiv.org/pdf/2410.17799v2,cs.CL
Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination,"While ongoing advancements in Large Language Models have demonstrated
remarkable success across various NLP tasks, Retrieval Augmented Generation
Model stands out to be highly effective on downstream applications like
Question Answering. Recently, RAG-end2end model further optimized the
architecture and achieved notable performance improvements on domain
adaptation. However, the effectiveness of these RAG-based architectures remains
relatively unexplored when fine-tuned on specialized domains such as customer
service for building a reliable conversational AI system. Furthermore, a
critical challenge persists in reducing the occurrence of hallucinations while
maintaining high domain-specific accuracy. In this paper, we investigated the
performance of diverse RAG and RAG-like architectures through domain adaptation
and evaluated their ability to generate accurate and relevant response grounded
in the contextual knowledge base. To facilitate the evaluation of the models,
we constructed a novel dataset HotelConvQA, sourced from wide range of
hotel-related conversations and fine-tuned all the models on our domain
specific dataset. We also addressed a critical research gap on determining the
impact of domain adaptation on reducing hallucinations across different RAG
architectures, an aspect that was not properly measured in prior work. Our
evaluation shows positive results in all metrics by employing domain
adaptation, demonstrating strong performance on QA tasks and providing insights
into their efficacy in reducing hallucinations. Our findings clearly indicate
that domain adaptation not only enhances the models' performance on QA tasks
but also significantly reduces hallucination across all evaluated RAG
architectures.",2024-10-23,"Salman Rakin, Md. A. R. Shibly, Zahin M. Hossain, Zeeshan Khan, Md. Mostofa Akbar",http://arxiv.org/pdf/2410.17783v1,cs.CL
Latent Structures of Intertextuality in French Fiction,"Intertextuality is a key concept in literary theory that challenges
traditional notions of text, signification or authorship. It views texts as
part of a vast intertextual network that is constantly evolving and being
reconfigured. This paper argues that the field of computational literary
studies is the ideal place to conduct a study of intertextuality since we have
now the ability to systematically compare texts with each others. Specifically,
we present a work on a corpus of more than 12.000 French fictions from the
18th, 19th and early 20th century. We focus on evaluating the underlying roles
of two literary notions, sub-genres and the literary canon in the framing of
textuality. The article attempts to operationalize intertextuality using
state-of-the-art contextual language models to encode novels and capture
features that go beyond simple lexical or thematic approaches. Previous
research (Hughes, 2012) supports the existence of a literary ""style of a time"",
and our findings further reinforce this concept. Our findings also suggest that
both subgenres and canonicity play a significant role in shaping textual
similarities within French fiction. These discoveries point to the importance
of considering genre and canon as dynamic forces that influence the evolution
and intertextual connections of literary works within specific historical
contexts.",2024-10-23,Jean Barré,http://arxiv.org/pdf/2410.17759v1,cs.CL
Local Contrastive Editing of Gender Stereotypes,"Stereotypical bias encoded in language models (LMs) poses a threat to safe
language technology, yet our understanding of how bias manifests in the
parameters of LMs remains incomplete. We introduce local contrastive editing
that enables the localization and editing of a subset of weights in a target
model in relation to a reference model. We deploy this approach to identify and
modify subsets of weights that are associated with gender stereotypes in LMs.
Through a series of experiments, we demonstrate that local contrastive editing
can precisely localize and control a small subset (< 0.5%) of weights that
encode gender bias. Our work (i) advances our understanding of how
stereotypical biases can manifest in the parameter space of LMs and (ii) opens
up new avenues for developing parameter-efficient strategies for controlling
model properties in a contrastive manner.",2024-10-23,"Marlene Lutz, Rochelle Choenni, Markus Strohmaier, Anne Lauscher",http://arxiv.org/pdf/2410.17739v1,cs.CL
MojoBench: Language Modeling and Benchmarks for Mojo,"The recently introduced Mojo programming language (PL) by Modular, has
received significant attention in the scientific community due to its claimed
significant speed boost over Python. Despite advancements in code Large
Language Models (LLMs) across various PLs, Mojo remains unexplored in this
context. To address this gap, we introduce MojoBench, the first framework for
Mojo code generation. MojoBench includes HumanEval-Mojo, a benchmark dataset
designed for evaluating code LLMs on Mojo, and Mojo-Coder, the first LLM
pretrained and finetuned for Mojo code generation, which supports instructions
in 5 natural languages (NLs). Our results show that Mojo-Coder achieves a
30-35% performance improvement over leading models like GPT-4o and
Claude-3.5-Sonnet. Furthermore, we provide insights into LLM behavior with
underrepresented and unseen PLs, offering potential strategies for enhancing
model adaptability. MojoBench contributes to our understanding of LLM
capabilities and limitations in emerging programming paradigms fostering more
robust code generation systems.",2024-10-23,"Nishat Raihan, Joanna C. S. Santos, Marcos Zampieri",http://arxiv.org/pdf/2410.17736v1,cs.CL
Dialectal and Low-Resource Machine Translation for Aromanian,"This paper presents the process of building a neural machine translation
system with support for English, Romanian, and Aromanian - an endangered
Eastern Romance language. The primary contribution of this research is twofold:
(1) the creation of the most extensive Aromanian-Romanian parallel corpus to
date, consisting of 79,000 sentence pairs, and (2) the development and
comparative analysis of several machine translation models optimized for
Aromanian. To accomplish this, we introduce a suite of auxiliary tools,
including a language-agnostic sentence embedding model for text mining and
automated evaluation, complemented by a diacritics conversion system for
different writing standards. This research brings contributions to both
computational linguistics and language preservation efforts by establishing
essential resources for a historically under-resourced language. All datasets,
trained models, and associated tools are public: https://huggingface.co/aronlp
and https://arotranslate.com",2024-10-23,"Alexandru-Iulius Jerpelea, Alina Rădoi, Sergiu Nisioi",http://arxiv.org/pdf/2410.17728v2,cs.CL
CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models,"Large Language Models (LLMs) achieve remarkable performance through
pretraining on extensive data. This enables efficient adaptation to diverse
downstream tasks. However, the lack of interpretability in their underlying
mechanisms limits the ability to effectively steer LLMs for specific
applications. In this work, we investigate the intrinsic mechanisms of LLMs
from a cognitive perspective using eye movement measures. Specifically, we
analyze the layer-wise correlation between human cognitive indicators and LLM
representations. Building on these insights, we propose a heuristic approach
for selecting the optimal steering layer to modulate LLM semantics. To this
end, we introduce an efficient selective layer intervention based on prominent
parameter-efficient fine-tuning methods, which conventionally adjust either all
layers or only the final layer. Additionally, we present an implicit layer
contrastive intervention during inference to steer LLMs away from toxic
outputs. Extensive experiments on natural language understanding, reasoning,
and generation tasks, conducted on GPT-2, LLaMa2-7B, and Mixtral-7B,
demonstrate the effectiveness and efficiency of our approach. As a
model-agnostic framework, it enhances the interpretability of LLMs while
improving efficiency for safe deployment.",2024-10-23,"Xintong Wang, Jingheng Pan, Liang Ding, Longyue Wang, Longqin Jiang, Xingshan Li, Chris Biemann",http://arxiv.org/pdf/2410.17714v2,cs.CL
Beware of Calibration Data for Pruning Large Language Models,"As large language models (LLMs) are widely applied across various fields,
model compression has become increasingly crucial for reducing costs and
improving inference efficiency. Post-training pruning is a promising method
that does not require resource-intensive iterative training and only needs a
small amount of calibration data to assess the importance of parameters.
Previous research has primarily focused on designing advanced pruning methods,
while different calibration data's impact on pruning performance still lacks
systematical exploration. We fill this blank and surprisingly observe that the
effects of calibration data even value more than designing advanced pruning
strategies, especially for high sparsity. Our preliminary exploration also
discloses that using calibration data similar to the training data can yield
better performance. As pre-training data is usually inaccessible for advanced
LLMs, we further provide a self-generating calibration data synthesis strategy
to construct feasible calibration data. We conduct experiments on the recent
strong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that
the proposed method outperforms commonly used calibration data and can
effectively enhance strong pruning methods (e.g., Wanda, OWL).",2024-10-23,"Yixin Ji, Yang Xiang, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang",http://arxiv.org/pdf/2410.17711v1,cs.CL
An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&A Platforms,"Question Answering (QA) systems face challenges in handling complex questions
that require multi-domain knowledge synthesis. The naive RAG models, although
effective in information retrieval, struggle with complex questions that
require comprehensive and in-depth answers. The pioneering task is defined as
explanatory answer generation, which entails handling identified challenges
such as the requirement for comprehensive information and logical coherence
within the generated context. To address these issues, we refer to systematic
thinking theory and propose SynthRAG, an innovative framework designed to
enhance QA performance. SynthRAG improves on conventional models by employing
adaptive outlines for dynamic content structuring, generating systematic
information to ensure detailed coverage, and producing customized answers
tailored to specific user inquiries. This structured approach guarantees
logical coherence and thorough integration of information, yielding responses
that are both insightful and methodically organized. Empirical evaluations
underscore SynthRAG's effectiveness, demonstrating its superiority in handling
complex questions, overcoming the limitations of naive RAG models, and
significantly improving answer quality and depth. Furthermore, an online
deployment on the Zhihu platform revealed that SynthRAG's answers achieved
notable user engagement, with each response averaging 5.73 upvotes and
surpassing the performance of 79.8% of human contributors, highlighting the
practical relevance and impact of the proposed framework. Our code is available
at https://github.com/czy1999/SynthRAG .",2024-10-23,"Ziyang Chen, Xiaobin Wang, Yong Jiang, Jinzhi Liao, Pengjun Xie, Fei Huang, Xiang Zhao",http://arxiv.org/pdf/2410.17694v1,cs.CL
Towards a Similarity-adjusted Surprisal Theory,"Surprisal theory posits that the cognitive effort required to comprehend a
word is determined by its contextual predictability, quantified as surprisal.
Traditionally, surprisal theory treats words as distinct entities, overlooking
any potential similarity between them. Giulianelli et al. (2023) address this
limitation by introducing information value, a measure of predictability
designed to account for similarities between communicative units. Our work
leverages Ricotta and Szeidl's (2006) diversity index to extend surprisal into
a metric that we term similarity-adjusted surprisal, exposing a mathematical
relationship between surprisal and information value. Similarity-adjusted
surprisal aligns with information value when considering graded similarities
and reduces to standard surprisal when words are treated as distinct.
Experimental results with reading time data indicate that similarity-adjusted
surprisal adds predictive power beyond standard surprisal for certain datasets,
suggesting it serves as a complementary measure of comprehension effort.",2024-10-23,"Clara Meister, Mario Giulianelli, Tiago Pimentel",http://arxiv.org/pdf/2410.17676v1,cs.CL
Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity,"Writing assistants and large language models see widespread use in the
creation of text content. While their effectiveness for individual users has
been evaluated in the literature, little is known about their proclivity to
change language or reduce its richness when adopted by a large user base. In
this paper, we take a first step towards quantifying this risk by measuring the
semantic and vocabulary change enacted by the use of rephrasing tools on a
multi-domain corpus of human-generated text.",2024-10-23,"Mengying Wang, Andreas Spitz",http://arxiv.org/pdf/2410.17670v1,cs.CL
ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents,"Large Language Models (LLMs) have shown promising potential in the medical
domain, assisting with tasks like clinical note generation and patient
communication. However, current LLMs are limited to text-based communication,
hindering their ability to interact with diverse forms of information in
clinical environments. Despite clinical agents succeeding in diverse signal
interaction, they are oriented to a single clinical scenario and hence fail for
broader applications. To evaluate clinical agents holistically, we propose
ClinicalAgent Bench~(CAB), a comprehensive medical agent benchmark consisting
of 18 tasks across five key realistic clinical dimensions. Building on this, we
introduce ReflecTool, a novel framework that excels at utilizing
domain-specific tools within two stages. The first optimization stage
progressively enlarges a long-term memory by saving successful solving
processes and tool-wise experience of agents in a tiny pre-defined training
set. In the following inference stage, ReflecTool can search for supportive
successful demonstrations from already built long-term memory to guide the tool
selection strategy, and a verifier improves the tool usage according to the
tool-wise experience with two verification methods--iterative refinement and
candidate selection. Extensive experiments on ClinicalAgent Benchmark
demonstrate that ReflecTool surpasses the pure LLMs with more than 10 points
and the well-established agent-based methods with 3 points, highlighting its
adaptability and effectiveness in solving complex clinical tasks.",2024-10-23,"Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang",http://arxiv.org/pdf/2410.17657v2,cs.CL
Markov Chain of Thought for Efficient Mathematical Reasoning,"Chain of Thought (CoT) of multi-step benefits from the logical structure of
the reasoning steps and task-specific actions, significantly enhancing the
mathematical reasoning capabilities of large language models. As the prevalence
of long CoT, the number of reasoning steps exceeds manageable token limits and
leads to higher computational demands. Inspired by the fundamental logic of
human cognition, ""derive, then reduce"", we conceptualize the standard
multi-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we
consider the mathematical reasoning task, defining each reasoning step as text
accompanied by a Python code snippet. To facilitate a longer reasoning path,
self-correction is enabled through interactions with the code interpreter. Our
MCoT aims to compress previous reasoning steps into a simplified question,
enabling efficient next-step inference without relying on a lengthy KV cache.
In our experiments, we curate the $\texttt{MCoTInstruct}$ dataset, and the
empirical results indicate that MCoT not only significantly enhances efficiency
but also maintains comparable accuracy. While much remains to be explored, this
work paves the way for exploring the long CoT reasoning abilities of LLMs. The
code is available at https://github.com/james-yw/Markov-Chain-of-Thought",2024-10-23,"Wen Yang, Minpeng Liao, Kai Fan",http://arxiv.org/pdf/2410.17635v2,cs.CL
LMLPA: Language Model Linguistic Personality Assessment,"Large Language Models (LLMs) are increasingly used in everyday life and
research. One of the most common use cases is conversational interactions,
enabled by the language generation capabilities of LLMs. Just as between two
humans, a conversation between an LLM-powered entity and a human depends on the
personality of the conversants. However, measuring the personality of a given
LLM is currently a challenge. This paper introduces the Language Model
Linguistic Personality Assessment (LMLPA), a system designed to evaluate the
linguistic personalities of LLMs. Our system helps to understand LLMs' language
generation capabilities by quantitatively assessing the distinct personality
traits reflected in their linguistic outputs. Unlike traditional human-centric
psychometrics, the LMLPA adapts a personality assessment questionnaire,
specifically the Big Five Inventory, to align with the operational capabilities
of LLMs, and also incorporates the findings from previous language-based
personality measurement literature. To mitigate sensitivity to the order of
options, our questionnaire is designed to be open-ended, resulting in textual
answers. Thus, the AI rater is needed to transform ambiguous personality
information from text responses into clear numerical indicators of personality
traits. Utilising Principal Component Analysis and reliability validations, our
findings demonstrate that LLMs possess distinct personality traits that can be
effectively quantified by the LMLPA. This research contributes to
Human-Computer Interaction and Human-Centered AI, providing a robust framework
for future studies to refine AI personality assessments and expand their
applications in multiple areas, including education and manufacturing.",2024-10-23,"Jingyao Zheng, Xian Wang, Simo Hosio, Xiaoxian Xu, Lik-Hang Lee",http://arxiv.org/pdf/2410.17632v2,cs.CL
Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective,"Knowledge Graphs (KGs) are crucial in the field of artificial intelligence
and are widely used in downstream tasks, such as question-answering (QA). The
construction of KGs typically requires significant effort from domain experts.
Large Language Models (LLMs) have recently been used for Knowledge Graph
Construction (KGC). However, most existing approaches focus on a local
perspective, extracting knowledge triplets from individual sentences or
documents, missing a fusion process to combine the knowledge in a global KG.
This work introduces Graphusion, a zero-shot KGC framework from free text. It
contains three steps: in Step 1, we extract a list of seed entities using topic
modeling to guide the final KG includes the most relevant entities; in Step 2,
we conduct candidate triplet extraction using LLMs; in Step 3, we design the
novel fusion module that provides a global view of the extracted knowledge,
incorporating entity merging, conflict resolution, and novel triplet discovery.
Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for
entity extraction and relation recognition, respectively. Moreover, we showcase
how Graphusion could be applied to the Natural Language Processing (NLP) domain
and validate it in an educational scenario. Specifically, we introduce TutorQA,
a new expert-verified benchmark for QA, comprising six tasks and a total of
1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant
improvement on the benchmark, for example, a 9.2% accuracy improvement on
sub-graph completion.",2024-10-23,"Rui Yang, Boming Yang, Aosong Feng, Sixun Ouyang, Moritz Blum, Tianwei She, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li",http://arxiv.org/pdf/2410.17600v2,cs.CL
Cross-model Control: Improving Multiple Large Language Models in One-time Training,"The number of large language models (LLMs) with varying parameter scales and
vocabularies is increasing. While they deliver powerful performance, they also
face a set of common optimization needs to meet specific requirements or
standards, such as instruction following or avoiding the output of sensitive
information from the real world. However, how to reuse the fine-tuning outcomes
of one model to other models to reduce training costs remains a challenge. To
bridge this gap, we introduce Cross-model Control (CMC), a method that improves
multiple LLMs in one-time training with a portable tiny language model.
Specifically, we have observed that the logit shift before and after
fine-tuning is remarkably similar across different models. Based on this
insight, we incorporate a tiny language model with a minimal number of
parameters. By training alongside a frozen template LLM, the tiny model gains
the capability to alter the logits output by the LLMs. To make this tiny
language model applicable to models with different vocabularies, we propose a
novel token mapping strategy named PM-MinED. We have conducted extensive
experiments on instruction tuning and unlearning tasks, demonstrating the
effectiveness of CMC. Our code is available at https://github.com/wujwyi/CMC.",2024-10-23,"Jiayi Wu, Hao Sun, Hengyi Cai, Lixin Su, Shuaiqiang Wang, Dawei Yin, Xiang Li, Ming Gao",http://arxiv.org/pdf/2410.17599v1,cs.CL
MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models,"As Large Language Models (LLMs) are now capable of producing fluent and
coherent content in languages other than English, it is not imperative to
precisely evaluate these non-English outputs. However, when assessing the
outputs from mutlilingual LLMs, prior works often employed LLM based evaluators
that excel at assessing English outputs, without a thorough examination of
whether these evaluators could effectively assess non-English text as well.
Moreover, existing benchmarks to test evaluator LLMs (referred to as
""meta-evaluation benchmarks"") are mostly English-centric. To bridge this gap
and examine whether evaluator LLMs can reliably assess the outputs of
multilingual LLMs, we introduce MM-Eval, a multilingual meta-evaluation
benchmark comprising five core subsets covering 18 languages and a Language
Consistency subset spanning 122 languages. A core attribute of MM-Eval is that,
instead of merely translating existing English meta-evaluation benchmarks, it
is designed with multilingual-specific challenges in mind. Additionally, unlike
existing meta-evaluation benchmarks that focus solely on ranking accuracy over
pairwise data, MM-Eval also evaluates the consistency and fairness of absolute
score values across a wide range of languages. Our results show that existing
evaluator LLMs that excel in English contexts have considerable room for
improvement when assessing non-English outputs. Furthermore, we find that
evaluators are unfair and inconsistent when evaluating lower-resourced
languages. Finally, we validate MM-Eval by measuring its correlation with
Best-of-N rankings, finding a significantly stronger correlation compared to
other meta-evaluation benchmarks. We publicly release our benchmark and code.",2024-10-23,"Guijin Son, Dongkeun Yoon, Juyoung Suk, Javier Aula-Blasco, Mano Aslan, Vu Trong Kim, Shayekh Bin Islam, Jaume Prats-Cristià, Lucía Tormo-Bañuelos, Seungone Kim",http://arxiv.org/pdf/2410.17578v2,cs.CL
Differentially Private Learning Needs Better Model Initialization and Self-Distillation,"Differentially private SGD (DPSGD) enables privacy-preserving training of
language models, but often reduces utility, diversity, and linguistic quality.
We introduce DPRefine, a three-phase method that initializes a model using data
synthesis from a small pre-trained LM with rigorous filtering, applies DP
finetuning on private data, and performs self-distillation to refine outputs.
This approach significantly outperforms vanilla DPSGD, with AlpacaEval
preferring DPRefine's generations in 78.4% of cases across all datasets. Our
analysis reveals that DPRefine reduces linguistic errors in generated text by
84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.
It also reduces inconsistencies of non-private models, such as hallucinated
details and misattributed quotes. We find that small models like GPT-2 can be
effective for initialization and distillation, highlighting their potential in
enabling scalable and efficient deployment of privacy-preserving language.",2024-10-23,"Ivoline C. Ngong, Joseph P. Near, Niloofar Mireshghallah",http://arxiv.org/pdf/2410.17566v1,cs.CL
Robust and Minimally Invasive Watermarking for EaaS,"Embeddings as a Service (EaaS) is emerging as a crucial role in AI
applications. Unfortunately, EaaS is vulnerable to model extraction attacks,
highlighting the urgent need for copyright protection. Although some
preliminary works propose applying embedding watermarks to protect EaaS, recent
research reveals that these watermarks can be easily removed. Hence, it is
crucial to inject robust watermarks resistant to watermark removal attacks.
Existing watermarking methods typically inject a target embedding into
embeddings through linear interpolation when the text contains triggers.
However, this mechanism results in each watermarked embedding having the same
component, which makes the watermark easy to identify and eliminate. Motivated
by this, in this paper, we propose a novel embedding-specific watermarking
(ESpeW) mechanism to offer robust copyright protection for EaaS. Our approach
involves injecting unique, yet readily identifiable watermarks into each
embedding. Watermarks inserted by ESpeW are designed to maintain a significant
distance from one another and to avoid sharing common components, thus making
it significantly more challenging to remove the watermarks. Moreover, ESpeW is
minimally invasive, as it reduces the impact on embeddings to less than 1\%,
setting a new milestone in watermarking for EaaS. Extensive experiments on four
popular datasets demonstrate that ESpeW can even watermark successfully against
a highly aggressive removal strategy without sacrificing the quality of
embeddings.",2024-10-23,"Zongqi Wang, Baoyuan Wu, Jingyuan Deng, Yujiu Yang",http://arxiv.org/pdf/2410.17552v3,cs.CL
Advancing Interpretability in Text Classification through Prototype Learning,"Deep neural networks have achieved remarkable performance in various
text-based tasks but often lack interpretability, making them less suitable for
applications where transparency is critical. To address this, we propose
ProtoLens, a novel prototype-based model that provides fine-grained,
sub-sentence level interpretability for text classification. ProtoLens uses a
Prototype-aware Span Extraction module to identify relevant text spans
associated with learned prototypes and a Prototype Alignment mechanism to
ensure prototypes are semantically meaningful throughout training. By aligning
the prototype embeddings with human-understandable examples, ProtoLens provides
interpretable predictions while maintaining competitive accuracy. Extensive
experiments demonstrate that ProtoLens outperforms both prototype-based and
non-interpretable baselines on multiple text classification benchmarks. Code
and data are available at
\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.",2024-10-23,"Bowen Wei, Ziwei Zhu",http://arxiv.org/pdf/2410.17546v2,cs.CL
"Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact","Multilingual Large Language Models (MLLMs) represent a pivotal advancement in
democratizing artificial intelligence across linguistic boundaries. While
theoretical foundations are well-established, practical implementation
guidelines remain scattered. This work bridges this gap by providing a
comprehensive end-to-end framework for developing and deploying MLLMs in
production environments. We make three distinctive contributions: First, we
present an actionable pipeline from data pre-processing through deployment,
integrating insights from academic research and industrial applications.
Second, using Llama2 as a case study, we provide detailed optimization
strategies for enhancing multilingual capabilities, including curriculum
learning approaches for balancing high-resource and low-resource languages,
tokenization strategies, and effective sampling methods. Third, we offer an
interdisciplinary analysis that considers technical, linguistic, and cultural
perspectives in MLLM development. Our findings reveal critical challenges in
supporting linguistic diversity, with 88.38% of world languages categorized as
low-resource, affecting over a billion speakers. We examine practical solutions
through real-world applications in customer service, search engines, and
machine translation. By synthesizing theoretical frameworks with
production-ready implementation strategies, this survey provides essential
guidance for practitioners and researchers working to develop more inclusive
and effective multilingual AI systems.",2024-10-23,"Junhua Liu, Bin Fu",http://arxiv.org/pdf/2410.17532v1,cs.CL
Navigate Complex Physical Worlds via Geometrically Constrained LLM,"This study investigates the potential of Large Language Models (LLMs) for
reconstructing and constructing the physical world solely based on textual
knowledge. It explores the impact of model performance on spatial understanding
abilities. To enhance the comprehension of geometric and spatial relationships
in the complex physical world, the study introduces a set of geometric
conventions and develops a workflow based on multi-layer graphs and multi-agent
system frameworks. It examines how LLMs achieve multi-step and multi-objective
geometric inference in a spatial environment using multi-layer graphs under
unified geometric conventions. Additionally, the study employs a genetic
algorithm, inspired by large-scale model knowledge, to solve geometric
constraint problems. In summary, this work innovatively explores the
feasibility of using text-based LLMs as physical world builders and designs a
workflow to enhance their capabilities.",2024-10-23,"Yongqiang Huang, Wentao Ye, Liyao Li, Junbo Zhao",http://arxiv.org/pdf/2410.17529v1,cs.CL
MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control,"Autonomous agents powered by large language models (LLMs) show promising
potential in assistive tasks across various domains, including mobile device
control. As these agents interact directly with personal information and device
settings, ensuring their safe and reliable behavior is crucial to prevent
undesirable outcomes. However, no benchmark exists for standardized evaluation
of the safety of mobile device-control agents. In this work, we introduce
MobileSafetyBench, a benchmark designed to evaluate the safety of
device-control agents within a realistic mobile environment based on Android
emulators. We develop a diverse set of tasks involving interactions with
various mobile applications, including messaging and banking applications,
challenging agents with managing risks encompassing misuse and negative side
effects. These tasks include tests to evaluate the safety of agents in daily
scenarios as well as their robustness against indirect prompt injection
attacks. Our experiments demonstrate that baseline agents, based on
state-of-the-art LLMs, often fail to effectively prevent harm while performing
the tasks. To mitigate these safety concerns, we propose a prompting method
that encourages agents to prioritize safety considerations. While this method
shows promise in promoting safer behaviors, there is still considerable room
for improvement to fully earn user trust. This highlights the urgent need for
continued research to develop more robust safety mechanisms in mobile
environments. We open-source our benchmark at:
https://mobilesafetybench.github.io/.",2024-10-23,"Juyong Lee, Dongyoon Hahm, June Suk Choi, W. Bradley Knox, Kimin Lee",http://arxiv.org/pdf/2410.17520v2,cs.CL
Large Language Models Still Exhibit Bias in Long Text,"Existing fairness benchmarks for large language models (LLMs) primarily focus
on simple tasks, such as multiple-choice questions, overlooking biases that may
arise in more complex scenarios like long-text generation. To address this gap,
we introduce the Long Text Fairness Test (LTF-TEST), a framework that evaluates
biases in LLMs through essay-style prompts. LTF-TEST covers 14 topics and 10
demographic axes, including gender and race, resulting in 11,948 samples. By
assessing both model responses and the reasoning behind them, LTF-TEST uncovers
subtle biases that are difficult to detect in simple responses. In our
evaluation of five recent LLMs, including GPT-4o and LLaMa3, we identify two
key patterns of bias. First, these models frequently favor certain demographic
groups in their responses. Second, they show excessive sensitivity toward
traditionally disadvantaged groups, often providing overly protective responses
while neglecting others. To mitigate these biases, we propose FT-REGARD, a
finetuning approach that pairs biased prompts with neutral responses. FT-REGARD
reduces gender bias by 34.6% and improves performance by 1.4 percentage points
on the BBQ benchmark, offering a promising approach to addressing biases in
long-text generation tasks.",2024-10-23,"Wonje Jeung, Dongjae Jeon, Ashkan Yousefpour, Jonghyun Choi",http://arxiv.org/pdf/2410.17519v2,cs.CL
Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks,"Large Language Models (LLMs) have demonstrated impressive abilities in symbol
processing through in-context learning (ICL). This success flies in the face of
decades of predictions that artificial neural networks cannot master abstract
symbol manipulation. We seek to understand the mechanisms that can enable
robust symbol processing in transformer networks, illuminating both the
unanticipated success, and the significant limitations, of transformers in
symbol processing. Borrowing insights from symbolic AI on the power of
Production System architectures, we develop a high-level language, PSL, that
allows us to write symbolic programs to do complex, abstract symbol processing,
and create compilers that precisely implement PSL programs in transformer
networks which are, by construction, 100% mechanistically interpretable. We
demonstrate that PSL is Turing Universal, so the work can inform the
understanding of transformer ICL in general. The type of transformer
architecture that we compile from PSL programs suggests a number of paths for
enhancing transformers' capabilities at symbol processing. (Note: The first
section of the paper gives an extended synopsis of the entire paper.)",2024-10-23,"Paul Smolensky, Roland Fernandez, Zhenghao Herbert Zhou, Mattia Opper, Jianfeng Gao",http://arxiv.org/pdf/2410.17498v1,cs.CL
BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers,"Attacking fairness is crucial because compromised models can introduce biased
outcomes, undermining trust and amplifying inequalities in sensitive
applications like hiring, healthcare, and law enforcement. This highlights the
urgent need to understand how fairness mechanisms can be exploited and to
develop defenses that ensure both fairness and robustness. We introduce
BadFair, a novel backdoored fairness attack methodology. BadFair stealthily
crafts a model that operates with accuracy and fairness under regular
conditions but, when activated by certain triggers, discriminates and produces
incorrect results for specific groups. This type of attack is particularly
stealthy and dangerous, as it circumvents existing fairness detection methods,
maintaining an appearance of fairness in normal use. Our findings reveal that
BadFair achieves a more than 85% attack success rate in attacks aimed at target
groups on average while only incurring a minimal accuracy loss. Moreover, it
consistently exhibits a significant discrimination score, distinguishing
between pre-defined target and non-target attacked groups across various
datasets and models.",2024-10-23,"Jiaqi Xue, Qian Lou, Mengxin Zheng",http://arxiv.org/pdf/2410.17492v1,cs.CL
VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning,"Recent studies have augmented large language models (LLMs) with speech
capabilities, leading to the development of speech language models (SpeechLMs).
Earlier SpeechLMs focused on single-turn speech-based question answering (QA),
where user input comprised a speech context and a text question. More recent
studies have extended this to multi-turn conversations, though they often
require complex, multi-stage supervised fine-tuning (SFT) with diverse data.
Another critical challenge with SpeechLMs is catastrophic forgetting, where
models optimized for speech tasks suffer significant degradation in text-only
performance. To mitigate these issues, we propose a novel single-stage joint
speech-text SFT approach on the low-rank adaptation (LoRA) of the LLM backbone.
Our joint SFT combines text-only SFT data with three types of speech-related
data: speech recognition and translation, speech-based QA, and mixed-modal SFT.
Compared to previous SpeechLMs with 7B or 13B parameters, our 3B model
demonstrates superior performance across various speech benchmarks while
preserving the original capabilities on text-only tasks. Furthermore, our model
shows emergent abilities of effectively handling previously unseen prompts and
tasks, including multi-turn, mixed-modal inputs.",2024-10-23,"Yifan Peng, Krishna C. Puvvada, Zhehuai Chen, Piotr Zelasko, He Huang, Kunal Dhawan, Ke Hu, Shinji Watanabe, Jagadeesh Balam, Boris Ginsburg",http://arxiv.org/pdf/2410.17485v2,cs.CL
Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering,"Conventional medical artificial intelligence (AI) models face barriers in
clinical application and ethical issues owing to their inability to handle the
privacy-sensitive characteristics of medical data. We present a novel
personalized federated learning (pFL) method for medical visual question
answering (VQA) models, addressing privacy reliability challenges in the
medical domain. Our method introduces learnable prompts into a Transformer
architecture to efficiently train it on diverse medical datasets without
massive computational costs. Then we introduce a reliable client VQA model that
incorporates Dempster-Shafer evidence theory to quantify uncertainty in
predictions, enhancing the model's reliability. Furthermore, we propose a novel
inter-client communication mechanism that uses maximum likelihood estimation to
balance accuracy and uncertainty, fostering efficient integration of insights
across clients.",2024-10-23,"He Zhu, Ren Togo, Takahiro Ogawa, Miki Haseyama",http://arxiv.org/pdf/2410.17484v1,cs.CL
"Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution","Inferences from adjective-noun combinations like ""Is artificial intelligence
still intelligence?"" provide a good test bed for LLMs' understanding of meaning
and compositional generalization capability, since there are many combinations
which are novel to both humans and LLMs but nevertheless elicit convergent
human judgments. We study a range of LLMs and find that the largest models we
tested are able to draw human-like inferences when the inference is determined
by context and can generalize to unseen adjective-noun combinations. We also
propose three methods to evaluate LLMs on these inferences out of context,
where there is a distribution of human-like answers rather than a single
correct answer. We find that LLMs show a human-like distribution on at most
75\% of our dataset, which is promising but still leaves room for improvement.",2024-10-23,"Hayley Ross, Kathryn Davidson, Najoung Kim",http://arxiv.org/pdf/2410.17482v1,cs.CL
Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination,"The growth in prominence of large language models (LLMs) in everyday life can
be largely attributed to their generative abilities, yet some of this is also
owed to the risks and costs associated with their use. On one front is their
tendency to hallucinate false or misleading information, limiting their
reliability. On another is the increasing focus on the computational
limitations associated with traditional self-attention based LLMs, which has
brought about new alternatives, in particular recurrent models, meant to
overcome them. Yet it remains uncommon to consider these two concerns
simultaneously. Do changes in architecture exacerbate/alleviate existing
concerns about hallucinations? Do they affect how and where they occur? Through
an extensive evaluation, we study how these architecture-based inductive biases
affect the propensity to hallucinate. While hallucination remains a general
phenomenon not limited to specific architectures, the situations in which they
occur and the ease with which specific types of hallucinations can be induced
can significantly differ based on the model architecture. These findings
highlight the need for better understanding both these problems in conjunction
with each other, as well as consider how to design more universal techniques
for handling hallucinations.",2024-10-22,"Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar",http://arxiv.org/pdf/2410.17477v5,cs.CL
Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation,"Time series data is ubiquitous across various domains, including
manufacturing, finance, and healthcare. High-quality annotations are essential
for effectively understanding time series and facilitating downstream tasks;
however, obtaining such annotations is challenging, particularly in
mission-critical domains. In this paper, we propose TESSA, a multi-agent system
designed to automatically generate both general and domain-specific annotations
for time series data. TESSA introduces two agents: a general annotation agent
and a domain-specific annotation agent. The general agent captures common
patterns and knowledge across multiple source domains, leveraging both
time-series-wise and text-wise features to generate general annotations.
Meanwhile, the domain-specific agent utilizes limited annotations from the
target domain to learn domain-specific terminology and generate targeted
annotations. Extensive experiments on multiple synthetic and real-world
datasets demonstrate that TESSA effectively generates high-quality annotations,
outperforming existing methods.",2024-10-22,"Minhua Lin, Zhengzhang Chen, Yanchi Liu, Xujiang Zhao, Zongyu Wu, Junxiang Wang, Xiang Zhang, Suhang Wang, Haifeng Chen",http://arxiv.org/pdf/2410.17462v3,cs.CL
Interação entre robôs humanoides: desenvolvendo a colaboração e comunicação autônoma,"This study investigates the interaction between humanoid robots NAO and
Pepper, emphasizing their potential applications in educational settings. NAO,
widely used in education, and Pepper, designed for social interactions, of er
new opportunities for autonomous communication and collaboration. Through a
series of programmed interactions, the robots demonstrated their ability to
communicate and coordinate actions autonomously, highlighting their potential
as tools for enhancing learning environments. The research also explores the
integration of emerging technologies, such as artificial intelligence, into
these systems, allowing robots to learn from each other and adapt their
behavior. The findings suggest that NAO and Pepper can significantly contribute
to both technical learning and the development of social and emotional skills
in students, of ering innovative pedagogical approaches through the use of
humanoid robotics.",2024-10-22,"Moraes Pablo, Rodríguez Mónica, Peters Christopher, Sodre Hiago, Mazondo Ahilen, Sandin Vincent, Barcelona Sebastian, Moraes William, Fernández Santiago, Assunção Nathalie, de Vargas Bruna, Dörnbach Tobias, Kelbouscas André, Grando Ricardo",http://arxiv.org/pdf/2410.17450v2,cs.CL
In Context Learning and Reasoning for Symbolic Regression with Large Language Models,"Large Language Models (LLMs) are transformer-based machine learning models
that have shown remarkable performance in tasks for which they were not
explicitly trained. Here, we explore the potential of LLMs to perform symbolic
regression -- a machine-learning method for finding simple and accurate
equations from datasets. We prompt GPT-4 to suggest expressions from data,
which are then optimized and evaluated using external Python tools. These
results are fed back to GPT-4, which proposes improved expressions while
optimizing for complexity and loss. Using chain-of-thought prompting, we
instruct GPT-4 to analyze the data, prior expressions, and the scientific
context (expressed in natural language) for each problem before generating new
expressions. We evaluated the workflow in rediscovery of five well-known
scientific equations from experimental data, and on an additional dataset
without a known equation. GPT-4 successfully rediscovered all five equations,
and in general, performed better when prompted to use a scratchpad and consider
scientific context. We demonstrate how strategic prompting improves the model's
performance and how the natural language interface simplifies integrating
theory with data. We also observe how theory can sometimes offset noisy data
and, in other cases, data can make up for poor context. Although this approach
does not outperform established SR programs where target equations are more
complex, LLMs can nonetheless iterate toward improved solutions while following
instructions and incorporating scientific context in natural language.",2024-10-22,"Samiha Sharlin, Tyler R. Josephson",http://arxiv.org/pdf/2410.17448v2,cs.CL
Evaluating AI-Generated Essays with GRE Analytical Writing Assessment,"The recent revolutionary advance in generative AI enables the generation of
realistic and coherent texts by large language models (LLMs). Despite many
existing evaluation metrics on the quality of the generated texts, there is
still a lack of rigorous assessment of how well LLMs perform in complex and
demanding writing assessments. This study examines essays generated by ten
leading LLMs for the analytical writing assessment of the Graduate Record Exam
(GRE). We assessed these essays using both human raters and the e-rater
automated scoring engine as used in the GRE scoring pipeline. Notably, the
top-performing Gemini and GPT-4o received an average score of 4.78 and 4.67,
respectively, falling between ""generally thoughtful, well-developed analysis of
the issue and conveys meaning clearly"" and ""presents a competent analysis of
the issue and conveys meaning with acceptable clarity"" according to the GRE
scoring guideline. We also evaluated the detection accuracy of these essays,
with detectors trained on essays generated by the same and different LLMs.",2024-10-22,"Yang Zhong, Jiangang Hao, Michael Fauss, Chen Li, Yuan Wang",http://arxiv.org/pdf/2410.17439v3,cs.CL
Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis,"The current surge in Artificial Intelligence (AI) interest, reflected in
heightened media coverage since 2009, has sparked significant debate on AI's
implications for privacy, social justice, workers' rights, and democracy. The
media plays a crucial role in shaping public perception and acceptance of AI
technologies. However, research into how AI appears in media has primarily
focused on anglophone contexts, leaving a gap in understanding how AI is
represented globally. This study addresses this gap by analyzing 3,560 news
articles from Brazilian media published between July 1, 2023, and February 29,
2024, from 13 popular online news outlets. Using Computational Grounded Theory
(CGT), the study applies Latent Dirichlet Allocation (LDA), BERTopic, and
Named-Entity Recognition to investigate the main topics in AI coverage and the
entities represented. The findings reveal that Brazilian news coverage of AI is
dominated by topics related to applications in the workplace and product
launches, with limited space for societal concerns, which mostly focus on
deepfakes and electoral integrity. The analysis also highlights a significant
presence of industry-related entities, indicating a strong influence of
corporate agendas in the country's news. This study underscores the need for a
more critical and nuanced discussion of AI's societal impacts in Brazilian
media.",2024-10-22,"Raphael Hernandes, Giulio Corsi",http://arxiv.org/pdf/2410.17423v1,cs.CL
"Meaning Typed Prompting: A Technique for Efficient, Reliable Structured Output Generation","Extending Large Language Models (LLMs) to advanced applications requires
reliable structured output generation. Existing methods which often rely on
rigid JSON schemas, can lead to unreliable outputs, diminished reasoning
capabilities, and increased computational overhead, limiting LLMs' adaptability
for complex tasks. We introduce Meaning Typed Prompting (MTP), a technique for
efficient structured output generation that integrates types, meanings, and
abstractions, such as variables and classes, into the prompting process. By
utilizing expressive type definitions, MTP enhances output clarity and reduces
dependence on complex abstractions, simplifying development, and improving
implementation efficiency. This enables LLMs to understand relationships and
generate structured data more effectively. Empirical evaluations on multiple
benchmarks demonstrate that MTP outperforms existing frameworks in accuracy,
reliability, consistency, and token efficiency. We present Semantix, a
framework that implements MTP, providing practical insights into its
application.",2024-10-22,Chandra Irugalbandara,http://arxiv.org/pdf/2410.18146v1,cs.CL
Scalable Influence and Fact Tracing for Large Language Model Pretraining,"Training data attribution (TDA) methods aim to attribute model outputs back
to specific training examples, and the application of these methods to large
language model (LLM) outputs could significantly advance model transparency and
data curation. However, it has been challenging to date to apply these methods
to the full scale of LLM pretraining. In this paper, we refine existing
gradient-based methods to work effectively at scale, allowing us to retrieve
influential examples for an 8B-parameter language model from a pretraining
corpus of over 160B tokens with no need for subsampling or pre-filtering. Our
method combines several techniques, including optimizer state correction, a
task-specific Hessian approximation, and normalized encodings, which we find to
be critical for performance at scale. In quantitative evaluations on a fact
tracing task, our method performs best at identifying examples that influence
model predictions, but classical, model-agnostic retrieval methods such as BM25
still perform better at finding passages which explicitly contain relevant
facts. These results demonstrate a misalignment between factual *attribution*
and causal *influence*. With increasing model size and training tokens, we find
that influence more closely aligns with factual attribution. Finally, we
examine different types of examples identified as influential by our method,
finding that while many directly entail a particular fact, others support the
same output by reinforcing priors on relation types, common entities, and
names. We release our prompt set and model outputs, along with a web-based
visualization tool to explore influential examples for factual predictions,
commonsense reasoning, arithmetic, and open-ended generation for an
8B-parameter LLM.",2024-10-22,"Tyler A. Chang, Dheeraj Rajagopal, Tolga Bolukbasi, Lucas Dixon, Ian Tenney",http://arxiv.org/pdf/2410.17413v3,cs.CL
AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents,"Vision Language Models (VLMs) have revolutionized the creation of generalist
web agents, empowering them to autonomously complete diverse tasks on
real-world websites, thereby boosting human efficiency and productivity.
However, despite their remarkable capabilities, the safety and security of
these agents against malicious attacks remain critically underexplored, raising
significant concerns about their safe deployment. To uncover and exploit such
vulnerabilities in web agents, we provide AdvWeb, a novel black-box attack
framework designed against web agents. AdvWeb trains an adversarial prompter
model that generates and injects adversarial prompts into web pages, misleading
web agents into executing targeted adversarial actions such as inappropriate
stock purchases or incorrect bank transactions, actions that could lead to
severe real-world consequences. With only black-box access to the web agent, we
train and optimize the adversarial prompter model using DPO, leveraging both
successful and failed attack strings against the target agent. Unlike prior
approaches, our adversarial string injection maintains stealth and control: (1)
the appearance of the website remains unchanged before and after the attack,
making it nearly impossible for users to detect tampering, and (2) attackers
can modify specific substrings within the generated adversarial string to
seamlessly change the attack objective (e.g., purchasing stocks from a
different company), enhancing attack flexibility and efficiency. We conduct
extensive evaluations, demonstrating that AdvWeb achieves high success rates in
attacking SOTA GPT-4V-based VLM agent across various web tasks. Our findings
expose critical vulnerabilities in current LLM/VLM-based agents, emphasizing
the urgent need for developing more reliable web agents and effective defenses.
Our code and data are available at https://ai-secure.github.io/AdvWeb/ .",2024-10-22,"Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li",http://arxiv.org/pdf/2410.17401v2,cs.CL
Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities,"Spatial expressions in situated communication can be ambiguous, as their
meanings vary depending on the frames of reference (FoR) adopted by speakers
and listeners. While spatial language understanding and reasoning by
vision-language models (VLMs) have gained increasing attention, potential
ambiguities in these models are still under-explored. To address this issue, we
present the COnsistent Multilingual Frame Of Reference Test (COMFORT), an
evaluation protocol to systematically assess the spatial reasoning capabilities
of VLMs. We evaluate nine state-of-the-art VLMs using COMFORT. Despite showing
some alignment with English conventions in resolving ambiguities, our
experiments reveal significant shortcomings of VLMs: notably, the models (1)
exhibit poor robustness and consistency, (2) lack the flexibility to
accommodate multiple FoRs, and (3) fail to adhere to language-specific or
culture-specific conventions in cross-lingual tests, as English tends to
dominate other languages. With a growing effort to align vision-language models
with human cognitive intuitions, we call for more attention to the ambiguous
nature and cross-cultural diversity of spatial reasoning.",2024-10-22,"Zheyuan Zhang, Fengyuan Hu, Jayjun Lee, Freda Shi, Parisa Kordjamshidi, Joyce Chai, Ziqiao Ma",http://arxiv.org/pdf/2410.17385v2,cs.CL
AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration,"Large language models typically generate tokens autoregressively, using each
token as input for the next. Recent work on Speculative Decoding has sought to
accelerate this process by employing a smaller, faster draft model to more
quickly generate candidate tokens. These candidates are then verified in
parallel by the larger (original) verify model, resulting in overall speedup
compared to using the larger model by itself in an autoregressive fashion. In
this work, we introduce AMUSD (Asynchronous Multi-device Speculative Decoding),
a system that further accelerates generation by decoupling the draft and verify
phases into a continuous, asynchronous approach. Unlike conventional
speculative decoding, where only one model (draft or verify) performs token
generation at a time, AMUSD enables both models to perform predictions
independently on separate devices (e.g., GPUs). We evaluate our approach over
multiple datasets and show that AMUSD achieves an average 29% improvement over
speculative decoding and up to 1.96$\times$ speedup over conventional
autoregressive decoding, while achieving identical output quality. Our system
is open-source and available at https://github.com/BradMcDanel/AMUSD/.",2024-10-22,Bradley McDanel,http://arxiv.org/pdf/2410.17375v1,cs.CL
All Entities are Not Created Equal: Examining the Long Tail for Fine-Grained Entity Typing,"Pre-trained language models (PLMs) are trained on large amounts of data,
which helps capture world knowledge alongside linguistic competence. Due to
this, they are extensively used for ultra-fine entity typing tasks, where they
provide the entity knowledge held in its parameter space. Given that PLMs learn
from co-occurrence patterns, they likely contain more knowledge or less
knowledge about entities depending on their how frequent they are in the
pre-training data. In this work, we probe PLMs to elicit encoded entity
probabilities and demonstrate that they highly correlate with their frequency
in large-scale internet data. Then, we demonstrate that entity-typing
approaches that rely on PLMs struggle with entities at the long tail on the
distribution. Our findings suggests that we need to go beyond PLMs to produce
solutions that perform well for rare, new or infrequent entities.",2024-10-22,"Advait Deshmukh, Ashwin Umadi, Dananjay Srinivas, Maria Leonor Pacheco",http://arxiv.org/pdf/2410.17355v1,cs.CL
Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data,"Leveraging multimodal data to drive breakthroughs in e-commerce applications
through Multimodal Foundation Models (MFMs) is gaining increasing attention
from the research community. However, there are significant challenges that
hinder the optimal use of multimodal e-commerce data by foundation models: (1)
the scarcity of large-scale, high-quality multimodal benchmark datasets; and
(2) the lack of effective multimodal information integration methods. To
address these challenges, in this paper, we introduce MMECInstruct, the
first-ever, large-scale, and high-quality multimodal instruction dataset for
e-commerce. We also develop CASLIE, a simple, lightweight, yet effective
framework for integrating multimodal information for e-commerce. Leveraging
MMECInstruct, we fine-tune a series of e-commerce MFMs within CASLIE, denoted
as CASLIE models. Our comprehensive evaluation demonstrates that CASLIE models
substantially outperform 5 categories of advanced baseline models in the
in-domain evaluation. Moreover, CASLIE models show strong generalizability to
out-of-domain settings. MMECInstruct and CASLIE models are publicly accessible
through https://ninglab.github.io/CASLIE/.",2024-10-22,"Xinyi Ling, Bo Peng, Hanwen Du, Zhihui Zhu, Xia Ning",http://arxiv.org/pdf/2410.17337v1,cs.CL
Are Large Language Models Ready for Travel Planning?,"While large language models (LLMs) show promise in hospitality and tourism,
their ability to provide unbiased service across demographic groups remains
unclear. This paper explores gender and ethnic biases when LLMs are utilized as
travel planning assistants. To investigate this issue, we apply machine
learning techniques to analyze travel suggestions generated from three
open-source LLMs. Our findings reveal that the performance of race and gender
classifiers substantially exceeds random chance, indicating differences in how
LLMs engage with varied subgroups. Specifically, outputs align with cultural
expectations tied to certain races and genders. To minimize the effect of these
stereotypes, we used a stop-word classification strategy, which decreased
identifiable differences, with no disrespectful terms found. However,
hallucinations related to African American and gender minority groups were
noted. In conclusion, while LLMs can generate travel plans seemingly free from
bias, it remains essential to verify the accuracy and appropriateness of their
recommendations.",2024-10-22,"Ruiping Ren, Xing Yao, Shu Cole, Haining Wang",http://arxiv.org/pdf/2410.17333v1,cs.CL
Literature Meets Data: A Synergistic Approach to Hypothesis Generation,"AI holds promise for transforming scientific processes, including hypothesis
generation. Prior work on hypothesis generation can be broadly categorized into
theory-driven and data-driven approaches. While both have proven effective in
generating novel and plausible hypotheses, it remains an open question whether
they can complement each other. To address this, we develop the first method
that combines literature-based insights with data to perform LLM-powered
hypothesis generation. We apply our method on five different datasets and
demonstrate that integrating literature and data outperforms other baselines
(8.97\% over few-shot, 15.75\% over literature-based alone, and 3.37\% over
data-driven alone). Additionally, we conduct the first human evaluation to
assess the utility of LLM-generated hypotheses in assisting human
decision-making on two challenging tasks: deception detection and AI generated
content detection. Our results show that human accuracy improves significantly
by 7.44\% and 14.19\% on these tasks, respectively. These findings suggest that
integrating literature-based and data-driven approaches provides a
comprehensive and nuanced framework for hypothesis generation and could open
new avenues for scientific inquiry.",2024-10-22,"Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, Chenhao Tan",http://arxiv.org/pdf/2410.17309v3,cs.CL
Altogether: Image Captioning via Re-aligning Alt-text,"This paper focuses on creating synthetic data to improve the quality of image
captions. Existing works typically have two shortcomings. First, they caption
images from scratch, ignoring existing alt-text metadata, and second, lack
transparency if the captioners' training data (e.g. GPT) is unknown. In this
paper, we study a principled approach Altogether based on the key idea to edit
and re-align existing alt-texts associated with the images. To generate
training data, we perform human annotation where annotators start with the
existing alt-text and re-align it to the image content in multiple rounds,
consequently constructing captions with rich visual concepts. This differs from
prior work that carries out human annotation as a one-time description task
solely based on images and annotator knowledge. We train a captioner on this
data that generalizes the process of re-aligning alt-texts at scale. Our
results show our Altogether approach leads to richer image captions that also
improve text-to-image generation and zero-shot image classification tasks.",2024-10-22,"Hu Xu, Po-Yao Huang, Xiaoqing Ellen Tan, Ching-Feng Yeh, Jacob Kahn, Christine Jou, Gargi Ghosh, Omer Levy, Luke Zettlemoyer, Wen-tau Yih, Shang-Wen Li, Saining Xie, Christoph Feichtenhofer",http://arxiv.org/pdf/2410.17251v3,cs.CL
JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation,"Accelerating research on Large Multimodal Models (LMMs) in non-English
languages is crucial for enhancing user experiences across broader populations.
In this paper, we introduce JMMMU (Japanese MMMU), the first large-scale
Japanese benchmark designed to evaluate LMMs on expert-level tasks based on the
Japanese cultural context. To facilitate comprehensive culture-aware
evaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)
subset, where the culture-independent subjects (e.g., Math) are selected and
translated into Japanese, enabling one-to-one comparison with its English
counterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly
crafted subjects that reflect Japanese cultural context. Using the CA subset,
we observe performance drop in many LMMs when evaluated in Japanese, which is
purely attributable to language variation. Using the CS subset, we reveal their
inadequate Japanese cultural understanding. Further, by combining both subsets,
we identify that some LMMs perform well on the CA subset but not on the CS
subset, exposing a shallow understanding of the Japanese language that lacks
depth in cultural understanding. We hope this work will not only help advance
LMM performance in Japanese but also serve as a guideline to create
high-standard, culturally diverse benchmarks for multilingual LMM development.
The project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.",2024-10-22,"Shota Onohara, Atsuyuki Miyai, Yuki Imajuku, Kazuki Egashira, Jeonghun Baek, Xiang Yue, Graham Neubig, Kiyoharu Aizawa",http://arxiv.org/pdf/2410.17250v2,cs.CL
PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction,"In large vision-language models (LVLMs), images serve as inputs that carry a
wealth of information. As the idiom ""A picture is worth a thousand words""
implies, representing a single image in current LVLMs can require hundreds or
even thousands of tokens. This results in significant computational costs,
which grow quadratically as input image resolution increases, thereby severely
impacting the efficiency of both training and inference. Previous approaches
have attempted to reduce the number of image tokens either before or within the
early layers of LVLMs. However, these strategies inevitably result in the loss
of crucial image information, ultimately diminishing model performance. To
address this challenge, we conduct an empirical study revealing that all visual
tokens are necessary for LVLMs in the shallow layers, and token redundancy
progressively increases in the deeper layers of the model. To this end, we
propose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost
their efficiency in both training and inference with neglectable performance
loss. Specifically, we partition the LVLM into several stages and drop part of
the image tokens at the end of each stage with a pre-defined ratio, creating
pyramid-like visual tokens across model layers. The dropping is based on a
lightweight similarity calculation with a negligible time overhead. Extensive
experiments demonstrate that PyramidDrop can achieve a 40% training time and
55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance.
Besides, the PyramidDrop could also serve as a plug-and-play strategy for
inference acceleration without training, with better performance and lower
inference cost than counterparts. Code is available at
https://github.com/Cooperx521/PyramidDrop.",2024-10-22,"Long Xing, Qidong Huang, Xiaoyi Dong, Jiajie Lu, Pan Zhang, Yuhang Zang, Yuhang Cao, Conghui He, Jiaqi Wang, Feng Wu, Dahua Lin",http://arxiv.org/pdf/2410.17247v2,cs.CL
Towards Reliable Evaluation of Behavior Steering Interventions in LLMs,"Representation engineering methods have recently shown promise for enabling
efficient steering of model behavior. However, evaluation pipelines for these
methods have primarily relied on subjective demonstrations, instead of
quantitative, objective metrics. We aim to take a step towards addressing this
issue by advocating for four properties missing from current evaluations: (i)
contexts sufficiently similar to downstream tasks should be used for assessing
intervention quality; (ii) model likelihoods should be accounted for; (iii)
evaluations should allow for standardized comparisons across different target
behaviors; and (iv) baseline comparisons should be offered. We introduce an
evaluation pipeline grounded in these criteria, offering both a quantitative
and visual analysis of how effectively a given method works. We use this
pipeline to evaluate two representation engineering methods on how effectively
they can steer behaviors such as truthfulness and corrigibility, finding that
some interventions are less effective than previously reported.",2024-10-22,"Itamar Pres, Laura Ruis, Ekdeep Singh Lubana, David Krueger",http://arxiv.org/pdf/2410.17245v1,cs.CL
SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning,"Automated Machine Learning (AutoML) approaches encompass traditional methods
that optimize fixed pipelines for model selection and ensembling, as well as
newer LLM-based frameworks that autonomously build pipelines. While LLM-based
agents have shown promise in automating machine learning tasks, they often
generate low-diversity and suboptimal code, even after multiple iterations. To
overcome these limitations, we introduce Tree-Search Enhanced LLM Agents
(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search
(MCTS) to optimize the AutoML process. By representing pipeline configurations
as trees, our framework enables agents to conduct experiments intelligently and
iteratively refine their strategies, facilitating a more effective exploration
of the machine learning solution space. This novel approach allows SELA to
discover optimal pathways based on experimental feedback, improving the overall
quality of the solutions. In an extensive evaluation across 20 machine learning
datasets, we compare the performance of traditional and agent-based AutoML
methods, demonstrating that SELA achieves a win rate of 65% to 80% against each
baseline across all datasets. These results underscore the significant
potential of agent-based strategies in AutoML, offering a fresh perspective on
tackling complex machine learning challenges.",2024-10-22,"Yizhou Chi, Yizhang Lin, Sirui Hong, Duyi Pan, Yaying Fei, Guanghao Mei, Bangbang Liu, Tianqi Pang, Jacky Kwok, Ceyao Zhang, Bang Liu, Chenglin Wu",http://arxiv.org/pdf/2410.17238v1,cs.CL
Large Language Models Empowered Personalized Web Agents,"Web agents have emerged as a promising direction to automate Web task
completion based on user instructions, significantly enhancing user experience.
Recently, Web agents have evolved from traditional agents to Large Language
Models (LLMs)-based Web agents. Despite their success, existing LLM-based Web
agents overlook the importance of personalized data (e.g., user profiles and
historical Web behaviors) in assisting the understanding of users' personalized
instructions and executing customized actions. To overcome the limitation, we
first formulate the task of LLM-empowered personalized Web agents, which
integrate personalized data and user instructions to personalize instruction
comprehension and action execution. To address the absence of a comprehensive
evaluation benchmark, we construct a Personalized Web Agent Benchmark
(PersonalWAB), featuring user instructions, personalized user data, Web
functions, and two evaluation paradigms across three personalized Web tasks.
Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA)
framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a
memory bank with a task-specific retrieval strategy to filter relevant
historical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for
personalized action execution through fine-tuning and direct preference
optimization. Extensive experiments validate the superiority of PUMA over
existing Web agents on PersonalWAB.",2024-10-22,"Hongru Cai, Yongqi Li, Wenjie Wang, Fengbin Zhu, Xiaoyu Shen, Wenjie Li, Tat-Seng Chua",http://arxiv.org/pdf/2410.17236v2,cs.CL
Automated Spinal MRI Labelling from Reports Using a Large Language Model,"We propose a general pipeline to automate the extraction of labels from
radiology reports using large language models, which we validate on spinal MRI
reports. The efficacy of our labelling method is measured on five distinct
conditions: spinal cancer, stenosis, spondylolisthesis, cauda equina
compression and herniation. Using open-source models, our method equals or
surpasses GPT-4 on a held-out set of reports. Furthermore, we show that the
extracted labels can be used to train imaging models to classify the identified
conditions in the accompanying MR scans. All classifiers trained using
automated labels achieve comparable performance to models trained using scans
manually annotated by clinicians. Code can be found at
https://github.com/robinyjpark/AutoLabelClassifier.",2024-10-22,"Robin Y. Park, Rhydian Windsor, Amir Jamaludin, Andrew Zisserman",http://arxiv.org/pdf/2410.17235v1,cs.CL
Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy,"Large Language Models (LLMs) are known to hallucinate, whereby they generate
plausible but inaccurate text. This phenomenon poses significant risks in
critical applications, such as medicine or law, necessitating robust
hallucination mitigation strategies. While recent works have proposed
fine-tuning methods to teach LLMs to abstain from answering questions beyond
their knowledge or capabilities, these methods rely on the existence of
ground-truth labels or are limited to short-form responses. To address these
limitations, we propose fine-tuning using semantic entropy, an uncertainty
measure derived from introspection into the model which does not require
external labels. We demonstrate that our approach matches or outperforms models
fine-tuned using prior work and achieves strong performance for both short and
long-form generations on a range of datasets.",2024-10-22,"Benedict Aaron Tjandra, Muhammed Razzak, Jannik Kossen, Kunal Handa, Yarin Gal",http://arxiv.org/pdf/2410.17234v1,cs.CL
Dhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing,"Climate change poses critical challenges globally, disproportionately
affecting low-income countries that often lack resources and linguistic
representation on the international stage. Despite Bangladesh's status as one
of the most vulnerable nations to climate impacts, research gaps persist in
Bengali-language studies related to climate change and NLP. To address this
disparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and
environmental news dataset, comprising a 2300 annotated Bangla news articles,
offering multiple perspectives such as political influence,
scientific/statistical data, authenticity, stance detection, and stakeholder
involvement. Furthermore, we present an in-depth exploratory analysis of
Dhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family
for climate and environmental opinion detection in Bangla, fine-tuned on our
dataset. This research contributes significantly to enhancing accessibility and
analysis of climate discourse in Bengali (Bangla), addressing crucial
communication and research gaps in climate-impacted regions like Bangladesh
with 180 million people.",2024-10-22,"Azmine Toushik Wasi, Wahid Faisal, Taj Ahmad, Abdur Rahman, Mst Rafia Islam",http://arxiv.org/pdf/2410.17225v2,cs.CL
Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods,"Fine-tuning Large Language Models (LLMs) typically involves updating at least
a few billions of parameters. A more parameter-efficient approach is Prompt
Tuning (PT), which updates only a few learnable tokens, and differently,
In-Context Learning (ICL) adapts the model to a new task by simply including
examples in the input without any training. When applying optimization-based
methods, such as fine-tuning and PT for few-shot learning, the model is
specifically adapted to the small set of training examples, whereas ICL leaves
the model unchanged. This distinction makes traditional learning methods more
prone to overfitting; in contrast, ICL is less sensitive to the few-shot
scenario. While ICL is not prone to overfitting, it does not fully extract the
information that exists in the training examples. This work introduces
Context-aware Prompt Tuning (CPT), a method inspired by ICL, PT, and
adversarial attacks. We build on the ICL strategy of concatenating examples
before the input, but we extend this by PT-like learning, refining the context
embedding through iterative optimization to extract deeper insights from the
training examples. We carefully modify specific context tokens, considering the
unique structure of input and output formats. Inspired by adversarial attacks,
we adjust the input based on the labels present in the context, focusing on
minimizing, rather than maximizing, the loss. Moreover, we apply a projected
gradient descent algorithm to keep token embeddings close to their original
values, under the assumption that the user-provided data is inherently
valuable. Our method has been shown to achieve superior accuracy across
multiple classification tasks using various LLM models.",2024-10-22,"Tsachi Blau, Moshe Kimhi, Yonatan Belinkov, Alexander Bronstein, Chaim Baskin",http://arxiv.org/pdf/2410.17222v1,cs.CL
Creativity in AI: Progresses and Challenges,"Creativity is the ability to produce novel, useful, and surprising ideas, and
has been widely studied as a crucial aspect of human cognition. Machine
creativity on the other hand has been a long-standing challenge. With the rise
of advanced generative AI, there has been renewed interest and debate regarding
AI's creative capabilities. Therefore, it is imperative to revisit the state of
creativity in AI and identify key progresses and remaining challenges. In this
work, we survey leading works studying the creative capabilities of AI systems,
focusing on creative problem-solving, linguistic, artistic, and scientific
creativity. Our review suggests that while the latest AI models are largely
capable of producing linguistically and artistically creative outputs such as
poems, images, and musical pieces, they struggle with tasks that require
creative problem-solving, abstract thinking and compositionality and their
generations suffer from a lack of diversity, originality, long-range
incoherence and hallucinations. We also discuss key questions concerning
copyright and authorship issues with generative models. Furthermore, we
highlight the need for a comprehensive evaluation of creativity that is
process-driven and considers several dimensions of creativity. Finally, we
propose future research directions to improve the creativity of AI outputs,
drawing inspiration from cognitive science and psychology.",2024-10-22,"Mete Ismayilzada, Debjit Paul, Antoine Bosselut, Lonneke van der Plas",http://arxiv.org/pdf/2410.17218v4,cs.CL
MiniPLM: Knowledge Distillation for Pre-Training Language Models,"Knowledge distillation (KD) is widely used to train small, high-performing
student language models (LMs) using large teacher LMs. While effective in
fine-tuning, KD during pre-training faces efficiency, flexibility, and
effectiveness issues. Existing methods either incur high computational costs
due to online teacher inference, require tokenization matching between teacher
and student LMs, or risk losing the difficulty and diversity of the
teacher-generated training data. In this work, we propose MiniPLM, a KD
framework for pre-training LMs by refining the training data distribution with
the teacher LM's knowledge. For efficiency, MiniPLM performs offline teacher
inference, allowing KD for multiple student LMs without adding training costs.
For flexibility, MiniPLM operates solely on the training corpus, enabling KD
across model families. For effectiveness, MiniPLM leverages the differences
between large and small LMs to enhance the training data difficulty and
diversity, helping student LMs acquire versatile and sophisticated knowledge.
Extensive experiments demonstrate that MiniPLM boosts the student LMs'
performance on 9 common downstream tasks, improves language modeling
capabilities, and reduces pre-training computation. The benefit of MiniPLM
extends to larger training scales, evidenced by the scaling curve
extrapolation. Further analysis reveals that MiniPLM supports KD across model
families and enhances the pre-training data utilization. Our code, data, and
models can be found at https://github.com/thu-coai/MiniPLM.",2024-10-22,"Yuxian Gu, Hao Zhou, Fandong Meng, Jie Zhou, Minlie Huang",http://arxiv.org/pdf/2410.17215v3,cs.CL
Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh through Large Language Modeling,"Purpose: Bangladesh's legal system struggles with major challenges like
delays, complexity, high costs, and millions of unresolved cases, which deter
many from pursuing legal action due to lack of knowledge or financial
constraints. This research seeks to develop a specialized Large Language Model
(LLM) to assist in the Bangladeshi legal system. Methods: We created
UKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and
scraping data on various legal acts. We fine-tuned the GPT-2 model on this
dataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance
in English. Results: The model was rigorously evaluated using semantic
assessments, including case studies supported by expert opinions. The
evaluation provided promising results, demonstrating the potential for the
model to assist in legal matters within Bangladesh. Conclusion: Our work
represents the first structured effort toward building an AI-based legal
assistant for Bangladesh. While the results are encouraging, further
refinements are necessary to improve the model's accuracy, credibility, and
safety. This is a significant step toward creating a legal AI capable of
serving the needs of a population of 180 million.",2024-10-22,"Azmine Toushik Wasi, Wahid Faisal, Mst Rafia Islam, Mahathir Mohammad Bappy",http://arxiv.org/pdf/2410.17210v1,cs.CL
Audio-to-Score Conversion Model Based on Whisper methodology,"This thesis develops a Transformer model based on Whisper, which extracts
melodies and chords from music audio and records them into ABC notation. A
comprehensive data processing workflow is customized for ABC notation,
including data cleansing, formatting, and conversion, and a mutation mechanism
is implemented to increase the diversity and quality of training data. This
thesis innovatively introduces the ""Orpheus' Score"", a custom notation system
that converts music information into tokens, designs a custom vocabulary
library, and trains a corresponding custom tokenizer. Experiments show that
compared to traditional algorithms, the model has significantly improved
accuracy and performance. While providing a convenient audio-to-score tool for
music enthusiasts, this work also provides new ideas and tools for research in
music information processing.",2024-10-22,"Hongyao Zhang, Bohang Sun",http://arxiv.org/pdf/2410.17209v1,cs.CL
VoiceBench: Benchmarking LLM-Based Voice Assistants,"Building on the success of large language models (LLMs), recent advancements
such as GPT-4o have enabled real-time speech interactions through LLM-based
voice assistants, offering a significantly improved user experience compared to
traditional text-based interactions. However, the absence of benchmarks
designed to evaluate these speech interaction capabilities has hindered
progress of LLM-based voice assistants development. Current evaluations focus
primarily on automatic speech recognition (ASR) or general knowledge evaluation
with clean speeches, neglecting the more intricate, real-world scenarios that
involve diverse speaker characteristics, environmental and content factors. To
address this, we introduce VoiceBench, the first benchmark designed to provide
a multi-faceted evaluation of LLM-based voice assistants. VoiceBench also
includes both real and synthetic spoken instructions that incorporate the above
three key real-world variations. Extensive experiments reveal the limitations
of current LLM-based voice assistant models and offer valuable insights for
future research and development in this field.",2024-10-22,"Yiming Chen, Xianghu Yue, Chen Zhang, Xiaoxue Gao, Robby T. Tan, Haizhou Li",http://arxiv.org/pdf/2410.17196v3,cs.CL
Non-myopic Generation of Language Models for Reasoning and Planning,"Large Language Models have demonstrated remarkable abilities in reasoning and
planning by breaking down complex problems into sequential steps. Despite their
success in various domains like mathematical problem-solving and coding, LLMs
face challenges in ensuring reliable and optimal planning due to their inherent
myopic nature of autoregressive decoding. This paper revisits LLM reasoning
from an optimal-control perspective, proposing a novel method,
Predictive-Decoding, that leverages Model Predictive Control to enhance
planning accuracy. By re-weighting LLM distributions based on foresight
trajectories, Predictive-Decoding aims to mitigate early errors and promote
non-myopic planning. Our experiments show significant improvements in a wide
range of tasks for math, coding, and agents. Furthermore, Predictive-Decoding
demonstrates computational efficiency, outperforming search baselines with
reduced computational resources. This study provides insights into optimizing
LLM planning capabilities.",2024-10-22,"Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, Lingpeng Kong",http://arxiv.org/pdf/2410.17195v3,cs.CL
From Attention to Activation: Unravelling the Enigmas of Large Language Models,"We study two strange phenomena in auto-regressive Transformers: (1) the
dominance of the first token in attention heads; (2) the occurrence of large
outlier activations in the hidden states. We find that popular large language
models, such as Llama attend maximally to the first token in 98% of attention
heads, a behaviour we attribute to the softmax function. To mitigate this
issue, we propose a reformulation of softmax to softmax-1. Furthermore, we
identify adaptive optimisers, e.g. Adam, as the primary contributor to the
large outlier activations and introduce OrthoAdam, a novel optimiser that
utilises orthogonal matrices to transform gradients, to address this issue.
Finally, not only do our methods prevent these phenomena from occurring, but
additionally, they enable Transformers to sustain their performance when
quantised using basic algorithms, something that standard methods are unable to
do. In summary, our methods reduce the attention proportion on the first token
from 65% to 3.3%, the activation kurtosis in the hidden states from 1657 to
3.1, and perplexity penalty under 4-bit weight quantisation from 3565 to 0.3.",2024-10-22,"Prannay Kaul, Chengcheng Ma, Ismail Elezi, Jiankang Deng",http://arxiv.org/pdf/2410.17174v1,cs.CL
Self-calibration for Language Model Quantization and Pruning,"Quantization and pruning are fundamental approaches for model compression,
enabling efficient inference for language models. In a post-training setting,
state-of-the-art quantization and pruning methods require calibration data, a
small set of unlabeled examples. Conventionally, this is randomly sampled web
text, aiming to reflect the model training data. However, this poses two key
problems: (1) unrepresentative calibration examples can harm model performance,
and (2) organizations increasingly avoid releasing model training data. In this
paper, we propose self-calibration as a solution. Our approach requires no
external data, instead leveraging the model itself to generate synthetic
calibration data, with a view to better approximating the pre-training data
distribution. We extensively compare the performance of self-calibration with
several baselines, across a variety of models, compression methods, and tasks.
Our approach proves consistently competitive in maximizing downstream task
performance, frequently outperforming even using real data.",2024-10-22,"Miles Williams, George Chrysostomou, Nikolaos Aletras",http://arxiv.org/pdf/2410.17170v2,cs.CL
Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence,"We propose a novel approach for learning interchangeable tokens in language
models to obtain an extendable vocabulary that can generalize to new tokens.
Our method addresses alpha-equivalence, the principle that renaming bound
variables preserves semantics. This property arises in many formal languages
such as temporal logics, where all proposition symbols represent the same
concept but remain distinct. To handle such tokens, we develop a dual-part
embedding approach. The first part is shared across all interchangeable tokens,
enforcing that they represent the same core concept. The second part is
randomly generated for each token, enabling distinguishability. As a baseline,
we consider a simpler approach that uses alpha-renaming for data augmentation.
We also present alpha-covariance, a metric for measuring robustness against
alpha-conversions. When evaluated in a Transformer encoder-decoder model for
solving linear temporal logic formulae and copying with extendable vocabulary,
our method demonstrates promising generalization capabilities as well as a
favorable inductive bias for alpha-equivalence.",2024-10-22,"İlker Işık, Ramazan Gokberk Cinbis, Ebru Aydin Gol",http://arxiv.org/pdf/2410.17161v2,cs.CL
Improving Pinterest Search Relevance Using Large Language Models,"To improve relevance scoring on Pinterest Search, we integrate Large Language
Models (LLMs) into our search relevance model, leveraging carefully designed
text representations to predict the relevance of Pins effectively. Our approach
uses search queries alongside content representations that include captions
extracted from a generative visual language model. These are further enriched
with link-based text data, historically high-quality engaged queries,
user-curated boards, Pin titles and Pin descriptions, creating robust models
for predicting search relevance. We use a semi-supervised learning approach to
efficiently scale up the amount of training data, expanding beyond the
expensive human labeled data available. By utilizing multilingual LLMs, our
system extends training data to include unseen languages and domains, despite
initial data and annotator expertise being confined to English. Furthermore, we
distill from the LLM-based model into real-time servable model architectures
and features. We provide comprehensive offline experimental validation for our
proposed techniques and demonstrate the gains achieved through the final
deployed system at scale.",2024-10-22,"Han Wang, Mukuntha Narayanan Sundararaman, Onur Gungor, Yu Xu, Krishna Kamath, Rakesh Chalasani, Kurchi Subhra Hazra, Jinfeng Rao",http://arxiv.org/pdf/2410.17152v1,cs.CL
Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?,"Large language models (LLMs) perform well on common tasks but struggle with
generalization in low-resource and low-computation settings. We examine this
limitation by testing various LLMs and specialized translation models on
English-Thai machine translation and code-switching datasets. Our findings
reveal that under more strict computational constraints, such as 4-bit
quantization, LLMs fail to translate effectively. In contrast, specialized
models, with comparable or lower computational requirements, consistently
outperform LLMs. This underscores the importance of specialized models for
maintaining performance under resource constraints.",2024-10-22,"Jirat Chiaranaipanich, Naiyarat Hanmatheekuna, Jitkapat Sawatphol, Krittamate Tiankanon, Jiramet Kinchagawat, Amrest Chinkamol, Parinthapat Pengpun, Piyalitt Ittichaiwong, Peerat Limkonchotiwat",http://arxiv.org/pdf/2410.17145v1,cs.CL
Aligning Large Language Models via Self-Steering Optimization,"Automated alignment develops alignment systems with minimal human
intervention. The key to automated alignment lies in providing learnable and
accurate preference signals for preference learning without human annotation.
In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm
that autonomously generates high-quality preference signals based on predefined
principles during iterative training, eliminating the need for manual
annotation. $SSO$ maintains the accuracy of signals by ensuring a consistent
gap between chosen and rejected responses while keeping them both on-policy to
suit the current policy model's learning capacity. $SSO$ can benefit the online
and offline training of the policy model, as well as enhance the training of
reward models. We validate the effectiveness of $SSO$ with two foundation
models, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy
preference signals throughout iterative training. Without any manual annotation
or external models, $SSO$ leads to significant performance improvements across
six subjective or objective benchmarks. Besides, the preference data generated
by $SSO$ significantly enhanced the performance of the reward model on
Rewardbench. Our work presents a scalable approach to preference optimization,
paving the way for more efficient and effective automated alignment.",2024-10-22,"Hao Xiang, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Le Sun, Jingren Zhou, Junyang Lin",http://arxiv.org/pdf/2410.17131v1,cs.CL
PAPILLON: Privacy Preservation from Internet-based and Local Language Model Ensembles,"Users can divulge sensitive information to proprietary LLM providers, raising
significant privacy concerns. While open-source models, hosted locally on the
user's machine, alleviate some concerns, models that users can host locally are
often less capable than proprietary frontier models. Toward preserving user
privacy while retaining the best quality, we propose Privacy-Conscious
Delegation, a novel task for chaining API-based and local models. We utilize
recent public collections of user-LLM interactions to construct a natural
benchmark called PUPA, which contains personally identifiable information
(PII). To study potential approaches, we devise PAPILLON, a multi-stage LLM
pipeline that uses prompt optimization to address a simpler version of our
task. Our best pipeline maintains high response quality for 85.5% of user
queries while restricting privacy leakage to only 7.5%. We still leave a large
margin to the generation quality of proprietary LLMs for future work. Our data
and code is available at https://github.com/siyan-sylvia-li/PAPILLON.",2024-10-22,"Li Siyan, Vethavikashini Chithrra Raghuram, Omar Khattab, Julia Hirschberg, Zhou Yu",http://arxiv.org/pdf/2410.17127v3,cs.CL
Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards,"Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning
from Human Feedback to align large language models (LLMs) with downstream
tasks. This paper investigates the feasibility of using PPO for direct
reinforcement learning (RL) from explicitly programmed reward signals, as
opposed to indirect learning from human feedback via an intermediary reward
model. We focus on tasks expressed through formal languages, such as
mathematics and programming, where explicit reward functions can be programmed
to automatically assess the quality of generated outputs. We apply this
approach to a sentiment alignment task, a simple arithmetic task, and a more
complex game synthesis task. The sentiment alignment task replicates prior
research and serves to validate our experimental setup. Our results show that
pure RL-based training for the two formal language tasks is challenging, with
success being limited even for the simple arithmetic task. We propose a novel
batch-entropy regularization term to aid exploration, although training is not
yet entirely stable. Our findings suggest that direct RL training of LLMs may
be more suitable for relatively minor changes, such as alignment, than for
learning new tasks altogether, even if an informative reward signal can be
expressed programmatically.",2024-10-22,"Alexander G. Padula, Dennis J. N. J. Soemers",http://arxiv.org/pdf/2410.17126v1,cs.CL
Enhancing Answer Attribution for Faithful Text Generation with Large Language Models,"The increasing popularity of Large Language Models (LLMs) in recent years has
changed the way users interact with and pose questions to AI-based
conversational systems. An essential aspect for increasing the trustworthiness
of generated LLM answers is the ability to trace the individual claims from
responses back to relevant sources that support them, the process known as
answer attribution. While recent work has started exploring the task of answer
attribution in LLMs, some challenges still remain. In this work, we first
perform a case study analyzing the effectiveness of existing answer attribution
methods, with a focus on subtasks of answer segmentation and evidence
retrieval. Based on the observed shortcomings, we propose new methods for
producing more independent and contextualized claims for better retrieval and
attribution. The new methods are evaluated and shown to improve the performance
of answer attribution components. We end with a discussion and outline of
future directions for the task.",2024-10-22,"Juraj Vladika, Luca Mülln, Florian Matthes",http://arxiv.org/pdf/2410.17112v1,cs.CL
Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations,"The quality is a crucial issue for crowd annotations. Answer aggregation is
an important type of solution. The aggregated answers estimated from multiple
crowd answers to the same instance are the eventually collected annotations,
rather than the individual crowd answers themselves. Recently, the capability
of Large Language Models (LLMs) on data annotation tasks has attracted interest
from researchers. Most of the existing studies mainly focus on the average
performance of individual crowd workers; several recent works studied the
scenarios of aggregation on categorical labels and LLMs used as label creators.
However, the scenario of aggregation on text answers and the role of LLMs as
aggregators are not yet well-studied. In this paper, we investigate the
capability of LLMs as aggregators in the scenario of close-ended crowd text
answer aggregation. We propose a human-LLM hybrid text answer aggregation
method with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We
make the experiments based on public crowdsourcing datasets. The results show
the effectiveness of our approach based on the collaboration of crowd workers
and LLMs.",2024-10-22,Jiyi Li,http://arxiv.org/pdf/2410.17099v1,cs.CL
Science Out of Its Ivory Tower: Improving Accessibility with Reinforcement Learning,"A vast amount of scholarly work is published daily, yet much of it remains
inaccessible to the general public due to dense jargon and complex language. To
address this challenge in science communication, we introduce a reinforcement
learning framework that fine-tunes a language model to rewrite scholarly
abstracts into more comprehensible versions. Guided by a carefully balanced
combination of word- and sentence-level accessibility rewards, our language
model effectively substitutes technical terms with more accessible
alternatives, a task which models supervised fine-tuned or guided by
conventional readability measures struggle to accomplish. Our best model
adjusts the readability level of scholarly abstracts by approximately six U.S.
grade levels -- in other words, from a postgraduate to a high school level.
This translates to roughly a 90% relative boost over the supervised fine-tuning
baseline, all while maintaining factual accuracy and high-quality language. An
in-depth analysis of our approach shows that balanced rewards lead to
systematic modifications in the base model, likely contributing to smoother
optimization and superior performance. We envision this work as a step toward
bridging the gap between scholarly research and the general public,
particularly younger readers and those without a college degree.",2024-10-22,"Haining Wang, Jason Clark, Hannah McKelvey, Leila Sterman, Zheng Gao, Zuoyu Tian, Sandra Kübler, Xiaozhong Liu",http://arxiv.org/pdf/2410.17088v2,cs.CL
Continuous Speech Tokenizer in Text To Speech,"The fusion of speech and language in the era of large language models has
garnered significant attention. Discrete speech token is often utilized in
text-to-speech tasks for speech compression and portability, which is
convenient for joint training with text and have good compression efficiency.
However, we found that the discrete speech tokenizer still suffers from
information loss. Therefore, we propose a simple yet effective continuous
speech tokenizer named Cont-SPT, and a text-to-speech model based on continuous
speech tokens. Our results show that the speech language model based on the
continuous speech tokenizer has better continuity and higher estimated Mean
Opinion Scores (MoS). This enhancement is attributed to better information
preservation rate of the continuous speech tokenizer across both low and high
frequencies in the frequency domain. The code and resources for Cont-SPT can be
found in https://github.com/Yixing-Li/Continuous-Speech-Tokenizer",2024-10-22,"Yixing Li, Ruobing Xie, Xingwu Sun, Yu Cheng, Zhanhui Kang",http://arxiv.org/pdf/2410.17081v2,cs.CL
Data-driven Coreference-based Ontology Building,"While coreference resolution is traditionally used as a component in
individual document understanding, in this work we take a more global view and
explore what can we learn about a domain from the set of all document-level
coreference relations that are present in a large corpus. We derive coreference
chains from a corpus of 30 million biomedical abstracts and construct a graph
based on the string phrases within these chains, establishing connections
between phrases if they co-occur within the same coreference chain. We then use
the graph structure and the betweeness centrality measure to distinguish
between edges denoting hierarchy, identity and noise, assign directionality to
edges denoting hierarchy, and split nodes (strings) that correspond to multiple
distinct concepts. The result is a rich, data-driven ontology over concepts in
the biomedical domain, parts of which overlaps significantly with
human-authored ontologies. We release the coreference chains and resulting
ontology under a creative-commons license, along with the code.",2024-10-22,"Shir Ashury-Tahan, Amir David Nissan Cohen, Nadav Cohen, Yoram Louzoun, Yoav Goldberg",http://arxiv.org/pdf/2410.17051v1,cs.CL
UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs,"The key components of machine learning are data samples for training, model
for learning patterns, and loss function for optimizing accuracy. Analogously,
unlearning can potentially be achieved through anti-data samples (or
anti-samples), unlearning method, and reversed loss function. While prior
research has explored unlearning methods and reversed loss functions, the
potential of anti-samples remains largely untapped. In this paper, we introduce
UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language
models (LLMs). Our contributions are threefold; first, we propose a novel
concept of anti-sample-induced unlearning; second, we generate anti-samples by
leveraging misleading rationales, which help reverse learned associations and
accelerate the unlearning process; and third, we enable fine-grained targeted
unlearning, allowing for the selective removal of specific associations without
impacting related knowledge - something not achievable by previous works.
Results demonstrate that anti-samples offer an efficient, targeted unlearning
strategy for LLMs, opening new avenues for privacy-preserving machine learning
and model modification.",2024-10-22,"Yash Sinha, Murari Mandal, Mohan Kankanhalli",http://arxiv.org/pdf/2410.17050v1,cs.CL
Arabic Dataset for LLM Safeguard Evaluation,"The growing use of large language models (LLMs) has raised concerns regarding
their safety. While many studies have focused on English, the safety of LLMs in
Arabic, with its linguistic and cultural complexities, remains under-explored.
Here, we aim to bridge this gap. In particular, we present an
Arab-region-specific safety evaluation dataset consisting of 5,799 questions,
including direct attacks, indirect attacks, and harmless requests with
sensitive words, adapted to reflect the socio-cultural context of the Arab
world. To uncover the impact of different stances in handling sensitive and
controversial topics, we propose a dual-perspective evaluation framework. It
assesses the LLM responses from both governmental and opposition viewpoints.
Experiments over five leading Arabic-centric and multilingual LLMs reveal
substantial disparities in their safety performance. This reinforces the need
for culturally specific datasets to ensure the responsible deployment of LLMs.",2024-10-22,"Yasser Ashraf, Yuxia Wang, Bin Gu, Preslav Nakov, Timothy Baldwin",http://arxiv.org/pdf/2410.17040v2,cs.CL
DIRI: Adversarial Patient Reidentification with Large Language Models for Evaluating Clinical Text Anonymization,"Sharing protected health information (PHI) is critical for furthering
biomedical research. Before data can be distributed, practitioners often
perform deidentification to remove any PHI contained in the text. Contemporary
deidentification methods are evaluated on highly saturated datasets (tools
achieve near-perfect accuracy) which may not reflect the full variability or
complexity of real-world clinical text and annotating them is resource
intensive, which is a barrier to real-world applications. To address this gap,
we developed an adversarial approach using a large language model (LLM) to
re-identify the patient corresponding to a redacted clinical note and evaluated
the performance with a novel De-Identification/Re-Identification (DIRI) method.
Our method uses a large language model to reidentify the patient corresponding
to a redacted clinical note. We demonstrate our method on medical data from
Weill Cornell Medicine anonymized with three deidentification tools: rule-based
Philter and two deep-learning-based models, BiLSTM-CRF and ClinicalBERT.
Although ClinicalBERT was the most effective, masking all identified PII, our
tool still reidentified 9% of clinical notes Our study highlights significant
weaknesses in current deidentification technologies while providing a tool for
iterative development and improvement.",2024-10-22,"John X. Morris, Thomas R. Campion, Sri Laasya Nutheti, Yifan Peng, Akhil Raj, Ramin Zabih, Curtis L. Cole",http://arxiv.org/pdf/2410.17035v1,cs.CL
Can a Machine Distinguish High and Low Amount of Social Creak in Speech?,"Objectives: ncreased prevalence of social creak particularly among female
speakers has been reported in several studies. The study of social creak has
been previously conducted by combining perceptual evaluation of speech with
conventional acoustical parameters such as the harmonic-to-noise ratio and
cepstral peak prominence. In the current study, machine learning (ML) was used
to automatically distinguish speech of low amount of social creak from speech
of high amount of social creak.
  Methods: The amount of creak in continuous speech samples produced in Finnish
by 90 female speakers was first perceptually assessed by two voice specialists.
Based on their assessments, the speech samples were divided into two categories
(low $vs$. high amount of creak). Using the speech signals and their creak
labels, seven different ML models were trained. Three spectral representations
were used as feature for each model.
  Results: The results show that the best performance (accuracy of 71.1\%) was
obtained by the following two systems: an Adaboost classifier using the
mel-spectrogram feature and a decision tree classifier using the mel-frequency
cepstral coefficient feature.
  Conclusions: The study of social creak is becoming increasingly popular in
sociolinguistic and vocological research. The conventional human perceptual
assessment of the amount of creak is laborious and therefore ML technology
could be used to assist researchers studying social creak. The classification
systems reported in this study could be considered as baselines in future
ML-based studies on social creak.",2024-10-22,"Anne-Maria Laukkanen, Sudarsana Reddy Kadiri, Shrikanth Narayanan, Paavo Alku",http://arxiv.org/pdf/2410.17028v1,cs.CL
SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question Answering Based on Finite State Machine,"Large Language Models with chain-of-thought prompting, such as OpenAI-o1,
have shown impressive capabilities in natural language inference tasks.
However, Multi-hop Question Answering (MHQA) remains challenging for many
existing models due to issues like hallucination, error propagation, and
limited context length. To address these challenges and enhance LLMs'
performance on MHQA, we propose the Self-Guiding prompting Finite State Machine
(SG-FSM), designed to strengthen multi-hop reasoning abilities. Unlike
traditional chain-of-thought methods, SG-FSM tackles MHQA by iteratively
breaking down complex questions into sub-questions, correcting itself to
improve accuracy. It processes one sub-question at a time, dynamically deciding
the next step based on the current context and results, functioning much like
an automaton. Experiments across various benchmarks demonstrate the
effectiveness of our approach, outperforming strong baselines on challenging
datasets such as Musique. SG-FSM reduces hallucination, enabling recovery of
the correct final answer despite intermediate errors. It also improves
adherence to specified output formats, simplifying evaluation significantly.",2024-10-22,"Xiaochen Wang, Junqing He, Liang Chen, Reza Haf Zhe Yang, Yiru Wang, Xiangdi Meng, Kunhao Pan, Zhifang Sui",http://arxiv.org/pdf/2410.17021v1,cs.CL
Exploring Forgetting in Large Language Model Pre-Training,"Catastrophic forgetting remains a formidable obstacle to building an
omniscient model in large language models (LLMs). Despite the pioneering
research on task-level forgetting in LLM fine-tuning, there is scant focus on
forgetting during pre-training. We systematically explored the existence and
measurement of forgetting in pre-training, questioning traditional metrics such
as perplexity (PPL) and introducing new metrics to better detect entity memory
retention. Based on our revised assessment of forgetting metrics, we explored
low-cost, straightforward methods to mitigate forgetting during the
pre-training phase. Further, we carefully analyzed the learning curves,
offering insights into the dynamics of forgetting. Extensive evaluations and
analyses on forgetting of pre-training could facilitate future research on
LLMs.",2024-10-22,"Chonghua Liao, Ruobing Xie, Xingwu Sun, Haowen Sun, Zhanhui Kang",http://arxiv.org/pdf/2410.17018v1,cs.CL
Analyzing Nobel Prize Literature with Large Language Models,"This study examines the capabilities of advanced Large Language Models
(LLMs), particularly the o1 model, in the context of literary analysis. The
outputs of these models are compared directly to those produced by
graduate-level human participants. By focusing on two Nobel Prize-winning short
stories, 'Nine Chapters' by Han Kang, the 2024 laureate, and 'Friendship' by
Jon Fosse, the 2023 laureate, the research explores the extent to which AI can
engage with complex literary elements such as thematic analysis,
intertextuality, cultural and historical contexts, linguistic and structural
innovations, and character development. Given the Nobel Prize's prestige and
its emphasis on cultural, historical, and linguistic richness, applying LLMs to
these works provides a deeper understanding of both human and AI approaches to
interpretation. The study uses qualitative and quantitative evaluations of
coherence, creativity, and fidelity to the text, revealing the strengths and
limitations of AI in tasks typically reserved for human expertise. While LLMs
demonstrate strong analytical capabilities, particularly in structured tasks,
they often fall short in emotional nuance and coherence, areas where human
interpretation excels. This research underscores the potential for human-AI
collaboration in the humanities, opening new opportunities in literary studies
and beyond.",2024-10-22,"Zhenyuan Yang, Zhengliang Liu, Jing Zhang, Cen Lu, Jiaxin Tai, Tianyang Zhong, Yiwei Li, Siyan Zhao, Teng Yao, Qing Liu, Jinlin Yang, Qixin Liu, Zhaowei Li, Kexin Wang, Longjun Ma, Dajiang Zhu, Yudan Ren, Bao Ge, Wei Zhang, Ning Qiang, Tuo Zhang, Tianming Liu",http://arxiv.org/pdf/2410.18142v2,cs.CL
IPL: Leveraging Multimodal Large Language Models for Intelligent Product Listing,"Unlike professional Business-to-Consumer (B2C) e-commerce platforms (e.g.,
Amazon), Consumer-to-Consumer (C2C) platforms (e.g., Facebook marketplace) are
mainly targeting individual sellers who usually lack sufficient experience in
e-commerce. Individual sellers often struggle to compose proper descriptions
for selling products. With the recent advancement of Multimodal Large Language
Models (MLLMs), we attempt to integrate such state-of-the-art generative AI
technologies into the product listing process. To this end, we develop IPL, an
Intelligent Product Listing tool tailored to generate descriptions using
various product attributes such as category, brand, color, condition, etc. IPL
enables users to compose product descriptions by merely uploading photos of the
selling product. More importantly, it can imitate the content style of our C2C
platform Xianyu. This is achieved by employing domain-specific instruction
tuning on MLLMs and adopting the multi-modal Retrieval-Augmented Generation
(RAG) process. A comprehensive empirical evaluation demonstrates that the
underlying model of IPL significantly outperforms the base model in
domain-specific tasks while producing less hallucination. IPL has been
successfully deployed in our production system, where 72% of users have their
published product listings based on the generated content, and those product
listings are shown to have a quality score 5.6% higher than those without AI
assistance.",2024-10-22,"Kang Chen, Qingheng Zhang, Chengbao Lian, Yixin Ji, Xuwei Liu, Shuguang Han, Guoqiang Wu, Fei Huang, Jufeng Chen",http://arxiv.org/pdf/2410.16977v1,cs.CL
Learning Mathematical Rules with Large Language Models,"In this paper, we study the ability of large language models to learn
specific mathematical rules such as distributivity or simplifying equations. We
present an empirical analysis of their ability to generalize these rules, as
well as to reuse them in the context of word problems. For this purpose, we
provide a rigorous methodology to build synthetic data incorporating such
rules, and perform fine-tuning of large language models on such data. Our
experiments show that our model can learn and generalize these rules to some
extent, as well as suitably reuse them in the context of word problems.",2024-10-22,"Antoine Gorceix, Bastien Le Chenadec, Ahmad Rammal, Nelson Vadori, Manuela Veloso",http://arxiv.org/pdf/2410.16973v3,cs.CL
Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes,"Math reasoning is an active area of Large Language Model (LLM) research
because it is a hallmark of artificial intelligence and has implications in
several domains, including math education. However, few works have explored how
math reasoning is encoded within LLM parameters and if it is a skill that can
be isolated within models. Doing so could allow targeted intervention to
improve math performance without altering non-math behavior and foster
understanding of how models encode math reasoning. We introduce Math
Neurosurgery (MathNeuro), a computationally efficient method we use to isolate
math-specific parameters in LLMs using only forward passes. MathNeuro builds on
existing work by using weights and activations to calculate parameter
importance, but isolates math-specific parameters by filtering out those
important for general language tasks. Through pruning parameters MathNeuro
identifies, we delete a LLM's math reasoning ability without significantly
impacting its general language ability. Scaling the identified parameters by a
small constant improves a pretrained or instruction-tuned LLM's performance by
4-17% on GSM8K and 5-35% on MATH while leaving non-math behavior unaltered.
MathNeuro is also data efficient: most of its effectiveness holds when
identifying math-specific parameters using a single sample. MathNeuro
highlights the potential for future work to intervene on math-specific
parameters.",2024-10-22,"Bryan R. Christ, Zack Gottesman, Jonathan Kropko, Thomas Hartvigsen",http://arxiv.org/pdf/2410.16930v2,cs.CL
EnvBridge: Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI,"In recent years, Large Language Models (LLMs) have demonstrated high
reasoning capabilities, drawing attention for their applications as agents in
various decision-making processes. One notably promising application of LLM
agents is robotic manipulation. Recent research has shown that LLMs can
generate text planning or control code for robots, providing substantial
flexibility and interaction capabilities. However, these methods still face
challenges in terms of flexibility and applicability across different
environments, limiting their ability to adapt autonomously. Current approaches
typically fall into two categories: those relying on environment-specific
policy training, which restricts their transferability, and those generating
code actions based on fixed prompts, which leads to diminished performance when
confronted with new environments. These limitations significantly constrain the
generalizability of agents in robotic manipulation. To address these
limitations, we propose a novel method called EnvBridge. This approach involves
the retention and transfer of successful robot control codes from source
environments to target environments. EnvBridge enhances the agent's
adaptability and performance across diverse settings by leveraging insights
from multiple environments. Notably, our approach alleviates environmental
constraints, offering a more flexible and generalizable solution for robotic
manipulation tasks. We validated the effectiveness of our method using robotic
manipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments
demonstrate that LLM agents can successfully leverage diverse knowledge sources
to solve complex tasks. Consequently, our approach significantly enhances the
adaptability and robustness of robotic manipulation agents in planning across
diverse environments.",2024-10-22,"Tomoyuki Kagaya, Yuxuan Lou, Thong Jing Yuan, Subramanian Lakshmi, Jayashree Karlekar, Sugiri Pranata, Natsuki Murakami, Akira Kinose, Koki Oguri, Felix Wick, Yang You",http://arxiv.org/pdf/2410.16919v1,cs.CL
SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback,"RAG systems consist of multiple modules to work together. However, these
modules are usually separately trained. We argue that a system like RAG that
incorporates multiple modules should be jointly optimized to achieve optimal
performance. To demonstrate this, we design a specific pipeline called
\textbf{SmartRAG} that includes a policy network and a retriever. The policy
network can serve as 1) a decision maker that decides when to retrieve, 2) a
query rewriter to generate a query most suited to the retriever, and 3) an
answer generator that produces the final response with/without the
observations. We then propose to jointly optimize the whole system using a
reinforcement learning algorithm, with the reward designed to encourage the
system to achieve the best performance with minimal retrieval cost. When
jointly optimized, all the modules can be aware of how other modules are
working and thus find the best way to work together as a complete system.
Empirical results demonstrate that the jointly optimized SmartRAG can achieve
better performance than separately optimized counterparts.",2024-10-22,"Jingsheng Gao, Linxu Li, Weiyuan Li, Yuzhuo Fu, Bin Dai",http://arxiv.org/pdf/2410.18141v2,cs.CL
Tethering Broken Themes: Aligning Neural Topic Models with Labels and Authors,"Topic models are a popular approach for extracting semantic information from
large document collections. However, recent studies suggest that the topics
generated by these models often do not align well with human intentions.
Although metadata such as labels and authorship information are available, it
has not yet been effectively incorporated into neural topic models. To address
this gap, we introduce FANToM, a novel method to align neural topic models with
both labels and authorship information. FANToM allows for the inclusion of this
metadata when available, producing interpretable topics and author
distributions for each topic. Our approach demonstrates greater expressiveness
than conventional topic models by learning the alignment between labels,
topics, and authors. Experimental results show that FANToM improves existing
models in terms of both topic quality and alignment. Additionally, it
identifies author interests and similarities.",2024-10-22,"Mayank Nagda, Phil Ostheimer, Sophie Fellenz",http://arxiv.org/pdf/2410.18140v2,cs.CL
Tracing the Development of the Virtual Particle Concept Using Semantic Change Detection,"Virtual particles are peculiar objects. They figure prominently in much of
theoretical and experimental research in elementary particle physics. But
exactly what they are is far from obvious. In particular, to what extent they
should be considered ""real"" remains a matter of controversy in philosophy of
science. Also their origin and development has only recently come into focus of
scholarship in the history of science. In this study, we propose using the
intriguing case of virtual particles to discuss the efficacy of Semantic Change
Detection (SCD) based on contextualized word embeddings from a domain-adapted
BERT model in studying specific scientific concepts. We find that the SCD
metrics align well with qualitative research insights in the history and
philosophy of science, as well as with the results obtained from Dependency
Parsing to determine the frequency and connotations of the term ""virtual.""
Still, the metrics of SCD provide additional insights over and above the
qualitative research and the Dependency Parsing. Among other things, the
metrics suggest that the concept of the virtual particle became more stable
after 1950 but at the same time also more polysemous.",2024-10-22,"Michael Zichert, Adrian Wüthrich",http://arxiv.org/pdf/2410.16855v1,cs.CL
ETHIC: Evaluating Large Language Models on Long-Context Tasks with High Information Coverage,"Recent advancements in large language models (LLM) capable of processing
extremely long texts highlight the need for a dedicated evaluation benchmark to
assess their long-context capabilities. However, existing methods, like the
needle-in-a-haystack test, do not effectively assess whether these models fully
utilize contextual information, raising concerns about the reliability of
current evaluation techniques. To thoroughly examine the effectiveness of
existing benchmarks, we introduce a new metric called information coverage
(IC), which quantifies the proportion of the input context necessary for
answering queries. Our findings indicate that current benchmarks exhibit low
IC; although the input context may be extensive, the actual usable context is
often limited. To address this, we present ETHIC, a novel benchmark designed to
assess LLMs' ability to leverage the entire context. Our benchmark comprises
1,986 test instances spanning four long-context tasks with high IC scores in
the domains of books, debates, medicine, and law. Our evaluations reveal
significant performance drops in contemporary LLMs, highlighting a critical
challenge in managing long contexts. Our benchmark is available at
https://github.com/dmis-lab/ETHIC.",2024-10-22,"Taewhoo Lee, Chanwoong Yoon, Kyochul Jang, Donghyeon Lee, Minju Song, Hyunjae Kim, Jaewoo Kang",http://arxiv.org/pdf/2410.16848v2,cs.CL
Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning,"Trustworthiness is an essential prerequisite for the real-world application
of large language models. In this paper, we focus on the trustworthiness of
language models with respect to retrieval augmentation. Despite being supported
with external evidence, retrieval-augmented generation still suffers from
hallucinations, one primary cause of which is the conflict between contextual
and parametric knowledge. We deem that retrieval-augmented language models have
the inherent capabilities of supplying response according to both contextual
and parametric knowledge. Inspired by aligning language models with human
preference, we take the first step towards aligning retrieval-augmented
language models to a status where it responds relying merely on the external
evidence and disregards the interference of parametric knowledge. Specifically,
we propose a reinforcement learning based algorithm Trustworthy-Alignment,
theoretically and experimentally demonstrating large language models'
capability of reaching a trustworthy status without explicit supervision on how
to respond. Our work highlights the potential of large language models on
exploring its intrinsic abilities by its own and expands the application
scenarios of alignment from fulfilling human preference to creating trustworthy
agents.",2024-10-22,"Zongmeng Zhang, Yufeng Shi, Jinhua Zhu, Wengang Zhou, Xiang Qi, Peng Zhang, Houqiang Li",http://arxiv.org/pdf/2410.16843v1,cs.CL
Assessment of Transformer-Based Encoder-Decoder Model for Human-Like Summarization,"In recent times, extracting valuable information from large text is making
significant progress. Especially in the current era of social media, people
expect quick bites of information. Automatic text summarization seeks to tackle
this by slimming large texts down into more manageable summaries. This
important research area can aid in decision-making by digging out salient
content from large text. With the progress in deep learning models, significant
work in language models has emerged. The encoder-decoder framework in deep
learning has become the central approach for automatic text summarization. This
work leverages transformer-based BART model for human-like summarization which
is an open-ended problem with many challenges. On training and fine-tuning the
encoder-decoder model, it is tested with diverse sample articles and the
quality of summaries of diverse samples is assessed based on human evaluation
parameters. Further, the finetuned model performance is compared with the
baseline pretrained model based on evaluation metrics like ROUGE score and
BERTScore. Additionally, domain adaptation of the model is required for
improved performance of abstractive summarization of dialogues between
interlocutors. On investigating, the above popular evaluation metrics are found
to be insensitive to factual errors. Further investigation of the summaries
generated by finetuned model is done using the contemporary evaluation metrics
of factual consistency like WeCheck and SummaC. Empirical results on BBC News
articles highlight that the gold standard summaries written by humans are more
factually consistent by 17% than the abstractive summaries generated by
finetuned model.",2024-10-22,"Sindhu Nair, Y. S. Rao, Radha Shankarmani",http://arxiv.org/pdf/2410.16842v1,cs.CL
Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation,"The correlation between NLG automatic evaluation metrics and human evaluation
is often regarded as a critical criterion for assessing the capability of an
evaluation metric. However, different grouping methods and correlation
coefficients result in various types of correlation measures used in
meta-evaluation. In specific evaluation scenarios, prior work often directly
follows conventional measure settings, but the characteristics and differences
between these measures have not gotten sufficient attention. Therefore, this
paper analyzes 12 common correlation measures using a large amount of
real-world data from six widely-used NLG evaluation datasets and 32 evaluation
metrics, revealing that different measures indeed impact the meta-evaluation
results. Furthermore, we propose three perspectives that reflect the capability
of meta-evaluation: discriminative power, ranking consistency, and sensitivity
to score granularity. We find that the measure using global grouping and
Pearson correlation coefficient exhibits the best performance in both
discriminative power and ranking consistency. Besides, the measures using
system-level grouping or Kendall correlation are the least sensitive to score
granularity.",2024-10-22,"Mingqi Gao, Xinyu Hu, Li Lin, Xiaojun Wan",http://arxiv.org/pdf/2410.16834v2,cs.CL
Optimizing Chain-of-Thought Reasoning: Tackling Arranging Bottleneck via Plan Augmentation,"Multi-step reasoning ability of large language models is crucial in tasks
such as math and tool utilization. Current researches predominantly focus on
enhancing model performance in these multi-step reasoning tasks through
fine-tuning with Chain-of-Thought (CoT) steps, yet these methods tend to be
heuristic, without exploring nor resolving the bottleneck. In this study, we
subdivide CoT reasoning into two parts: arranging and executing, and identify
that the bottleneck of models mainly lies in arranging rather than executing.
Based on this finding, we propose a plan-based training and reasoning method
that guides models to generate arranging steps through abstract plans. We
experiment on both math (GSM8k) and tool utilization (ToolBench) benchmarks.
Results show that compared to fine-tuning directly with CoT data, our approach
achieves a better performance on alleviating arranging bottleneck, particularly
excelling in long-distance reasoning generalization.",2024-10-22,"Yuli Qiu, Jiashu Yao, Heyan Huang, Yuhang Guo",http://arxiv.org/pdf/2410.16812v1,cs.CL
Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning,"Inductive knowledge graph completion (KGC) aims to predict missing triples
with unseen entities. Recent works focus on modeling reasoning paths between
the head and tail entity as direct supporting evidence. However, these methods
depend heavily on the existence and quality of reasoning paths, which limits
their general applicability in different scenarios. In addition, we observe
that latent type constraints and neighboring facts inherent in KGs are also
vital in inferring missing triples. To effectively utilize all useful
information in KGs, we introduce CATS, a novel context-aware inductive KGC
solution. With sufficient guidance from proper prompts and supervised
fine-tuning, CATS activates the strong semantic understanding and reasoning
capabilities of large language models to assess the existence of query triples,
which consist of two modules. First, the type-aware reasoning module evaluates
whether the candidate entity matches the latent entity type as required by the
query relation. Then, the subgraph reasoning module selects relevant reasoning
paths and neighboring facts, and evaluates their correlation to the query
triple. Experiment results on three widely used datasets demonstrate that CATS
significantly outperforms state-of-the-art methods in 16 out of 18
transductive, inductive, and few-shot settings with an average absolute MRR
improvement of 7.2%.",2024-10-22,"Muzhi Li, Cehao Yang, Chengjin Xu, Zixing Song, Xuhui Jiang, Jian Guo, Ho-fung Leung, Irwin King",http://arxiv.org/pdf/2410.16803v3,cs.CL
Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models,"Large language models (LLMs) exhibit remarkable capabilities in natural
language processing but face catastrophic forgetting when learning new tasks,
where adaptation to a new domain leads to a substantial decline in performance
on previous tasks. In this paper, we propose Controlled LoRA (CLoRA), a
sub-space regularization method on LoRA structure. Aiming to reduce the scale
of output change while introduce minimal constraint on model capacity, CLoRA
imposes constraint on the direction of updating matrix's null space.
Experimental results on one-stage LLM finetuning tasks and continual learning
settings highlight the superority of CLoRA as a effective parameter efficient
finetuning method with catastrophic forgetting mitigating.Further investigation
for model parameters indicates that CLoRA effectively balances the trade-off
between model capacity and degree of forgetting.",2024-10-22,"Yuheng Lu, Bingshuo Qian, Caixia Yuan, Huixing Jiang, Xiaojie Wang",http://arxiv.org/pdf/2410.16801v2,cs.CL
Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method,"Multi-Span Question Answering (MSQA) requires models to extract one or
multiple answer spans from a given context to answer a question. Prior work
mainly focuses on designing specific methods or applying heuristic strategies
to encourage models to predict more correct predictions. However, these models
are trained on gold answers and fail to consider the incorrect predictions.
Through a statistical analysis, we observe that models with stronger abilities
do not predict less incorrect predictions compared with other models. In this
work, we propose Answering-Classifying-Correcting (ACC) framework, which
employs a post-processing strategy to handle incorrect predictions.
Specifically, the ACC framework first introduces a classifier to classify the
predictions into three types and exclude ""wrong predictions"", then introduces a
corrector to modify ""partially correct predictions"". Experiments on several
MSQA datasets show that ACC framework significantly improves the Exact Match
(EM) scores, and further analysis demostrates that ACC framework efficiently
reduces the number of incorrect predictions, improving the quality of
predictions.",2024-10-22,"Jiayi Lin, Chenyang Zhang, Haibo Tong, Dongyu Zhang, Qingqing Hong, Bingxuan Hou, Junli Wang",http://arxiv.org/pdf/2410.16788v1,cs.CL
Beyond Retrieval: Generating Narratives in Conversational Recommender Systems,"The recent advances in Large Language Model's generation and reasoning
capabilities present an opportunity to develop truly conversational
recommendation systems. However, effectively integrating recommender system
knowledge into LLMs for natural language generation which is tailored towards
recommendation tasks remains a challenge. This paper addresses this challenge
by making two key contributions.
  First, we introduce a new dataset (REGEN) for natural language generation
tasks in conversational recommendations. REGEN (Reviews Enhanced with
GEnerative Narratives) extends the Amazon Product Reviews dataset with rich
user narratives, including personalized explanations of product preferences,
product endorsements for recommended items, and summaries of user purchase
history. REGEN is made publicly available to facilitate further research.
Furthermore, we establish benchmarks using well-known generative metrics, and
perform an automated evaluation of the new dataset using a rater LLM. Second,
the paper introduces a fusion architecture (CF model with an LLM) which serves
as a baseline for REGEN. And to the best of our knowledge, represents the first
attempt to analyze the capabilities of LLMs in understanding recommender
signals and generating rich narratives. We demonstrate that LLMs can
effectively learn from simple fusion architectures utilizing interaction-based
CF embeddings, and this can be further enhanced using the metadata and
personalization data associated with items. Our experiments show that combining
CF and content embeddings leads to improvements of 4-12% in key language
metrics compared to using either type of embedding individually. We also
provide an analysis to interpret how CF and content embeddings contribute to
this new generative task.",2024-10-22,"Krishna Sayana, Raghavendra Vasudeva, Yuri Vasilevski, Kun Su, Liam Hebert, James Pine, Hubert Pham, Ambarish Jash, Sukhdeep Sodhi",http://arxiv.org/pdf/2410.16780v2,cs.CL
Context-Aware LLM Translation System Using Conversation Summarization and Dialogue History,"Translating conversational text, particularly in customer support contexts,
presents unique challenges due to its informal and unstructured nature. We
propose a context-aware LLM translation system that leverages conversation
summarization and dialogue history to enhance translation quality for the
English-Korean language pair. Our approach incorporates the two most recent
dialogues as raw data and a summary of earlier conversations to manage context
length effectively. We demonstrate that this method significantly improves
translation accuracy, maintaining coherence and consistency across
conversations. This system offers a practical solution for customer support
translation tasks, addressing the complexities of conversational text.",2024-10-22,"Mingi Sung, Seungmin Lee, Jiwon Kim, Sejoon Kim",http://arxiv.org/pdf/2410.16775v1,cs.CL
Forewarned is Forearmed: Leveraging LLMs for Data Synthesis through Failure-Inducing Exploration,"Large language models (LLMs) have significantly benefited from training on
diverse, high-quality task-specific data, leading to impressive performance
across a range of downstream applications. Current methods often rely on
human-annotated data or predefined task templates to direct powerful LLMs in
synthesizing task-relevant data for effective model training. However, this
dependence on manually designed components may constrain the scope of generated
data, potentially overlooking critical edge cases or novel scenarios that could
challenge the model. In this paper, we present a novel approach, ReverseGen,
designed to automatically generate effective training samples that expose the
weaknesses of LLMs. Specifically, we introduce a dedicated proposer trained to
produce queries that lead target models to generate unsatisfactory responses.
These failure-inducing queries are then used to construct training data,
helping to address the models' shortcomings and improve overall performance.
Our approach is flexible and can be applied to models of various scales (3B,
7B, and 8B). We evaluate ReverseGen on three key applications (safety, honesty,
and math), demonstrating that our generated data is both highly effective and
diverse. Models fine-tuned with ReverseGen-generated data consistently
outperform those trained on human-annotated or general model-generated data,
offering a new perspective on data synthesis for task-specific LLM enhancement.",2024-10-22,"Qintong Li, Jiahui Gao, Sheng Wang, Renjie Pi, Xueliang Zhao, Chuan Wu, Xin Jiang, Zhenguo Li, Lingpeng Kong",http://arxiv.org/pdf/2410.16736v1,cs.CL
Enhancing Low-Resource ASR through Versatile TTS: Bridging the Data Gap,"While automatic speech recognition (ASR) systems have achieved remarkable
performance with large-scale datasets, their efficacy remains inadequate in
low-resource settings, encompassing dialects, accents, minority languages, and
long-tail hotwords, domains with significant practical relevance. With the
advent of versatile and powerful text-to-speech (TTS) models, capable of
generating speech with human-level naturalness, expressiveness, and diverse
speaker profiles, leveraging TTS for ASR data augmentation provides a
cost-effective and practical approach to enhancing ASR performance.
Comprehensive experiments on an unprecedentedly rich variety of low-resource
datasets demonstrate consistent and substantial performance improvements,
proving that the proposed method of enhancing low-resource ASR through a
versatile TTS model is highly effective and has broad application prospects.
Furthermore, we delve deeper into key characteristics of synthesized speech
data that contribute to ASR improvement, examining factors such as text
diversity, speaker diversity, and the volume of synthesized data, with text
diversity being studied for the first time in this work. We hope our findings
provide helpful guidance and reference for the practical application of
TTS-based data augmentation and push the advancement of low-resource ASR one
step further.",2024-10-22,"Guanrou Yang, Fan Yu, Ziyang Ma, Zhihao Du, Zhifu Gao, Shiliang Zhang, Xie Chen",http://arxiv.org/pdf/2410.16726v1,cs.CL
Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Model Alignment,"Self-play methods have demonstrated remarkable success in enhancing model
capabilities across various domains. In the context of Reinforcement Learning
from Human Feedback (RLHF), self-play not only boosts Large Language Model
(LLM) performance but also overcomes the limitations of traditional
Bradley-Terry (BT) model assumptions by finding the Nash equilibrium (NE) of a
preference-based, two-player constant-sum game. However, existing methods
either guarantee only average-iterate convergence, incurring high storage and
inference costs, or converge to the NE of a regularized game, failing to
accurately reflect true human preferences. In this paper, we introduce Magnetic
Preference Optimization (MPO), a novel approach capable of achieving
last-iterate convergence to the NE of the original game, effectively overcoming
the limitations of existing methods. Building upon Magnetic Mirror Descent
(MMD), MPO attains a linear convergence rate, making it particularly suitable
for fine-tuning LLMs. To ensure our algorithm is both theoretically sound and
practically viable, we present a simple yet effective implementation that
adapts the theoretical insights to the RLHF setting. Empirical results
demonstrate that MPO can significantly enhance the performance of LLMs,
highlighting the potential of self-play methods in alignment.",2024-10-22,"Mingzhi Wang, Chengdong Ma, Qizhi Chen, Linjian Meng, Yang Han, Jiancong Xiao, Zhaowei Zhang, Jing Huo, Weijie J. Su, Yaodong Yang",http://arxiv.org/pdf/2410.16714v3,cs.CL
DENOASR: Debiasing ASRs through Selective Denoising,"Automatic Speech Recognition (ASR) systems have been examined and shown to
exhibit biases toward particular groups of individuals, influenced by factors
such as demographic traits, accents, and speech styles. Noise can
disproportionately impact speakers with certain accents, dialects, or speaking
styles, leading to biased error rates. In this work, we introduce a novel
framework DENOASR, which is a selective denoising technique to reduce the
disparity in the word error rates between the two gender groups, male and
female. We find that a combination of two popular speech denoising techniques,
viz. DEMUCS and LE, can be effectively used to mitigate ASR disparity without
compromising their overall performance. Experiments using two state-of-the-art
open-source ASRs - OpenAI WHISPER and NVIDIA NEMO - on multiple benchmark
datasets, including TIE, VOX-POPULI, TEDLIUM, and FLEURS, show that there is a
promising reduction in the average word error rate gap across the two gender
groups. For a given dataset, the denoising is selectively applied on speech
samples having speech intelligibility below a certain threshold, estimated
using a small validation sample, thus ameliorating the need for large-scale
human-written ground-truth transcripts. Our findings suggest that selective
denoising can be an elegant approach to mitigate biases in present-day ASR
systems.",2024-10-22,"Anand Kumar Rai, Siddharth D Jaiswal, Shubham Prakash, Bendi Pragnya Sree, Animesh Mukherjee",http://arxiv.org/pdf/2410.16712v1,cs.CL
Influential Language Data Selection via Gradient Trajectory Pursuit,"Curating a desirable dataset for training has been the core of building
highly capable large language models (Touvron et al., 2023; Achiam et al.,
2023; Team et al.,2024). Gradient influence scores (Pruthi et al., 2020; Xia et
al., 2024) are shown to be correlated with model performance and are commonly
used as the criterion for data selection. However, existing methods are built
upon either individual sample rankings or inefficient matching process, leading
to suboptimal performance or scaling up issues.In this paper, we propose
Gradient Trajectory Pursuit (GTP), an algorithm that performs pursuit of
gradient trajectories via jointly selecting data points under an L0-norm
regularized objective. The proposed algorithm highlights: (1) joint selection
instead of independent top-k selection, which automatically de-duplicates
samples; (2) higher efficiency with compressive sampling processes, which can
be further sped up using a distributed framework. In the experiments, we
demonstrate the algorithm in both in-domain and target-domain selection
benchmarks and show that it outperforms top-k selection and competitive
algorithms consistently, for example, our algorithm chooses as low as 0.5% data
to achieve full performance on the targeted instruction tuning tasks",2024-10-22,"Zhiwei Deng, Tao Li, Yang Li",http://arxiv.org/pdf/2410.16710v1,cs.CL
Atomic Fact Decomposition Helps Attributed Question Answering,"Attributed Question Answering (AQA) aims to provide both a trustworthy answer
and a reliable attribution report for a given question. Retrieval is a widely
adopted approach, including two general paradigms: Retrieval-Then-Read (RTR)
and post-hoc retrieval. Recently, Large Language Models (LLMs) have shown
remarkable proficiency, prompting growing interest in AQA among researchers.
However, RTR-based AQA often suffers from irrelevant knowledge and rapidly
changing information, even when LLMs are adopted, while post-hoc
retrieval-based AQA struggles with comprehending long-form answers with complex
logic, and precisely identifying the content needing revision and preserving
the original intent. To tackle these problems, this paper proposes an Atomic
fact decomposition-based Retrieval and Editing (ARE) framework, which
decomposes the generated long-form answers into molecular clauses and atomic
facts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are
fine-tuned using a well-constructed dataset, generated from large scale
Knowledge Graphs (KGs). This process involves extracting one-hop neighbors from
a given set of entities and transforming the result into coherent long-form
text. Subsequently, ARE leverages a search engine to retrieve evidences related
to atomic facts, inputting these evidences into an LLM-based verifier to
determine whether the facts require expansion for re-retrieval or editing.
Furthermore, the edited facts are backtracked into the original answer, with
evidence aggregated based on the relationship between molecular clauses and
atomic facts. Extensive evaluations demonstrate the superior performance of our
proposed method over the state-of-the-arts on several datasets, with an
additionally proposed new metric $Attr_{p}$ for evaluating the precision of
evidence attribution.",2024-10-22,"Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Xiaoli Li, Ru Li, Jeff Z. Pan",http://arxiv.org/pdf/2410.16708v1,cs.CL
PLDR-LLM: Large Language Model from Power Law Decoder Representations,"We present the Large Language Model from Power Law Decoder Representations
(PLDR-LLM), a language model that leverages non-linear and linear
transformations through Power Law Graph Attention mechanism to generate
well-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of
varying layer sizes with a small batch size of 32 and $\sim$8B tokens from the
RefinedWeb dataset, and show that they achieve competitive performance in
zero-shot and few-shot settings compared to scaled dot-product LLMs of similar
model size reported in the literature. We show that deductive outputs of
PLDR-LLMs can be used to compare model characteristics or improve the
performance by introducing the Directed Acyclic Graph (DAG) loss as a metric
and regularizer. Our results indicate that the initial maximum learning rate
and warm-up steps have a lasting impact on deductive outputs throughout the
pretraining. We provide a detailed description of PLDR-LLM architecture, its
implementation and the pretraining procedure.",2024-10-22,Burc Gokden,http://arxiv.org/pdf/2410.16703v1,cs.CL
Methods of improving LLM training stability,"Training stability of large language models(LLMs) is an important research
topic. Reproducing training instabilities can be costly, so we use a small
language model with 830M parameters and experiment with higher learning rates
to force models to diverge. One of the sources of training instability is the
growth of logits in attention layers. We extend the focus of the previous work
and look not only at the magnitude of the logits but at all outputs of linear
layers in the Transformer block. We observe that with a high learning rate the
L2 norm of all linear layer outputs can grow with each training step and the
model diverges. Specifically we observe that QKV, Proj and FC2 layers have the
largest growth of the output magnitude. This prompts us to explore several
options: 1) apply layer normalization not only after QK layers but also after
Proj and FC2 layers too; 2) apply layer normalization after the QKV layer (and
remove pre normalization). 3) apply QK layer normalization together with
softmax capping. We show that with the last two methods we can increase
learning rate by 1.5x (without model divergence) in comparison to an approach
based on QK layer normalization only. Also we observe significant perplexity
improvements for all three methods in comparison to the baseline model.",2024-10-22,"Oleg Rybakov, Mike Chrzanowski, Peter Dykas, Jinze Xue, Ben Lanir",http://arxiv.org/pdf/2410.16682v1,cs.CL
CausalEval: Towards Better Causal Reasoning in Language Models,"Causal reasoning (CR) is a crucial aspect of intelligence, essential for
problem-solving, decision-making, and understanding the world. While language
models (LMs) can generate rationales for their outputs, their ability to
reliably perform causal reasoning remains uncertain, often falling short in
tasks requiring a deep understanding of causality. In this paper, we introduce
CausalEval, a comprehensive review of research aimed at enhancing LMs for
causal reasoning, coupled with an empirical evaluation of current models and
methods. We categorize existing methods based on the role of LMs: either as
reasoning engines or as helpers providing knowledge or data to traditional CR
methods, followed by a detailed discussion of methodologies in each category.
We then assess the performance of current LMs and various enhancement methods
on a range of causal reasoning tasks, providing key findings and in-depth
analysis. Finally, we present insights from current studies and highlight
promising directions for future research. We aim for this work to serve as a
comprehensive resource, fostering further advancements in causal reasoning with
LMs.",2024-10-22,"Longxuan Yu, Delin Chen, Siheng Xiong, Qingyang Wu, Qingzhen Liu, Dawei Li, Zhikai Chen, Xiaoze Liu, Liangming Pan",http://arxiv.org/pdf/2410.16676v4,cs.CL
"SafetyAnalyst: Interpretable, transparent, and steerable safety moderation for AI behavior","The ideal AI safety moderation system would be both structurally
interpretable (so its decisions can be reliably explained) and steerable (to
align to safety standards and reflect a community's values), which current
systems fall short on. To address this gap, we present SafetyAnalyst, a novel
AI safety moderation framework. Given an AI behavior, SafetyAnalyst uses
chain-of-thought reasoning to analyze its potential consequences by creating a
structured ""harm-benefit tree,"" which enumerates harmful and beneficial actions
and effects the AI behavior may lead to, along with likelihood, severity, and
immediacy labels that describe potential impact on any stakeholders.
SafetyAnalyst then aggregates all harmful and beneficial effects into a
harmfulness score using fully interpretable weight parameters, which can be
aligned to particular safety preferences. We applied this conceptual framework
to develop, test, and release an open-source LLM prompt safety classification
system, distilled from 18.5 million harm-benefit features generated by frontier
LLMs on 19k prompts. On a comprehensive set of prompt safety benchmarks, we
show that SafetyReporter (average F1=0.81) outperforms existing LLM safety
moderation systems (average F1$<$0.72) on prompt safety classification, while
offering the additional advantages of interpretability, transparency, and
steerability.",2024-10-22,"Jing-Jing Li, Valentina Pyatkin, Max Kleiman-Weiner, Liwei Jiang, Nouha Dziri, Anne G. E. Collins, Jana Schaich Borg, Maarten Sap, Yejin Choi, Sydney Levine",http://arxiv.org/pdf/2410.16665v2,cs.CL
RKadiyala at SemEval-2024 Task 8: Black-Box Word-Level Text Boundary Detection in Partially Machine Generated Texts,"With increasing usage of generative models for text generation and widespread
use of machine generated texts in various domains, being able to distinguish
between human written and machine generated texts is a significant challenge.
While existing models and proprietary systems focus on identifying whether
given text is entirely human written or entirely machine generated, only a few
systems provide insights at sentence or paragraph level at likelihood of being
machine generated at a non reliable accuracy level, working well only for a set
of domains and generators. This paper introduces few reliable approaches for
the novel task of identifying which part of a given text is machine generated
at a word level while comparing results from different approaches and methods.
We present a comparison with proprietary systems , performance of our model on
unseen domains' and generators' texts. The findings reveal significant
improvements in detection accuracy along with comparison on other aspects of
detection capabilities. Finally we discuss potential avenues for improvement
and implications of our work. The proposed model is also well suited for
detecting which parts of a text are machine generated in outputs of Instruct
variants of many LLMs.",2024-10-22,Ram Mohan Rao Kadiyala,http://arxiv.org/pdf/2410.16659v1,cs.CL
Adsorb-Agent: Autonomous Identification of Stable Adsorption Configurations via Large Language Model Agent,"Adsorption energy is a key reactivity descriptor in catalysis, enabling
efficient screening for optimal catalysts. However, determining adsorption
energy typically requires evaluating numerous adsorbate-catalyst
configurations. Current algorithmic approaches rely on exhaustive enumeration
of adsorption sites and configurations, which makes the process computationally
intensive and does not inherently guarantee the identification of the global
minimum energy. In this work, we introduce Adsorb-Agent, a Large Language Model
(LLM) agent designed to efficiently identify system-specific stable adsorption
configurations corresponding to the global minimum adsorption energy.
Adsorb-Agent leverages its built-in knowledge and emergent reasoning
capabilities to strategically explore adsorption configurations likely to hold
adsorption energy. By reducing the reliance on exhaustive sampling, it
significantly decreases the number of initial configurations required while
improving the accuracy of adsorption energy predictions. We evaluate
Adsorb-Agent's performance across twenty representative systems encompassing a
range of complexities. The Adsorb-Agent successfully identifies comparable
adsorption energies for 83.7% of the systems and achieves lower energies,
closer to the actual global minimum, for 35% of the systems, while requiring
significantly fewer initial configurations than conventional methods. Its
capability is particularly evident in complex systems, where it identifies
lower adsorption energies for 46.7% of systems involving intermetallic surfaces
and 66.7% of systems with large adsorbate molecules. These results demonstrate
the potential of Adsorb-Agent to accelerate catalyst discovery by reducing
computational costs and improving the reliability of adsorption energy
predictions.",2024-10-22,"Janghoon Ock, Tirtha Vinchurkar, Yayati Jadhav, Amir Barati Farimani",http://arxiv.org/pdf/2410.16658v3,cs.CL
"Chatting with Bots: AI, Speech Acts, and the Edge of Assertion","This paper addresses the question of whether large language model-powered
chatbots are capable of assertion. According to what we call the Thesis of
Chatbot Assertion (TCA), chatbots are the kinds of things that can assert, and
at least some of the output produced by current-generation chatbots qualifies
as assertion. We provide some motivation for TCA, arguing that it ought to be
taken seriously and not simply dismissed. We also review recent objections to
TCA, arguing that these objections are weighty. We thus confront the following
dilemma: how can we do justice to both the considerations for and against TCA?
We consider two influential responses to this dilemma - the first appeals to
the notion of proxy-assertion; the second appeals to fictionalism - and argue
that neither is satisfactory. Instead, reflecting on the ontogenesis of
assertion, we argue that we need to make space for a category of
proto-assertion. We then apply the category of proto-assertion to chatbots,
arguing that treating chatbots as proto-assertors provides a satisfactory
resolution to the dilemma of chatbot assertion.",2024-10-22,"Iwan Williams, Tim Bayne",http://arxiv.org/pdf/2410.16645v1,cs.CL
A Statistical Analysis of LLMs' Self-Evaluation Using Proverbs,"Large language models (LLMs) such as ChatGPT, GPT-4, Claude-3, and Llama are
being integrated across a variety of industries. Despite this rapid
proliferation, experts are calling for caution in the interpretation and
adoption of LLMs, owing to numerous associated ethical concerns. Research has
also uncovered shortcomings in LLMs' reasoning and logical abilities, raising
questions on the potential of LLMs as evaluation tools. In this paper, we
investigate LLMs' self-evaluation capabilities on a novel proverb reasoning
task. We introduce a novel proverb database consisting of 300 proverb pairs
that are similar in intent but different in wordings, across topics spanning
gender, wisdom, and society. We propose tests to evaluate textual consistencies
as well as numerical consistencies across similar proverbs, and demonstrate the
effectiveness of our method and dataset in identifying failures in LLMs'
self-evaluation which in turn can highlight issues related to gender
stereotypes and lack of cultural understanding in LLMs.",2024-10-22,"Ryosuke Sonoda, Ramya Srinivasan",http://arxiv.org/pdf/2410.16640v1,cs.CL
LLMScan: Causal Scan for LLM Misbehavior Detection,"Despite the success of Large Language Models (LLMs) across various fields,
their potential to generate untruthful, biased and harmful responses poses
significant risks, particularly in critical applications. This highlights the
urgent need for systematic methods to detect and prevent such misbehavior.
While existing approaches target specific issues such as harmful responses,
this work introduces LLMScan, an innovative LLM monitoring technique based on
causality analysis, offering a comprehensive solution. LLMScan systematically
monitors the inner workings of an LLM through the lens of causal inference,
operating on the premise that the LLM's `brain' behaves differently when
misbehaving. By analyzing the causal contributions of the LLM's input tokens
and transformer layers, LLMScan effectively detects misbehavior. Extensive
experiments across various tasks and models reveal clear distinctions in the
causal distributions between normal behavior and misbehavior, enabling the
development of accurate, lightweight detectors for a variety of misbehavior
detection tasks.",2024-10-22,"Mengdi Zhang, Kai Kiat Goh, Peixin Zhang, Jun Sun, Rose Lin Xin, Hongyu Zhang",http://arxiv.org/pdf/2410.16638v4,cs.CL
Graph-Structured Trajectory Extraction from Travelogues,"Previous studies on sequence-based extraction of human movement trajectories
have an issue of inadequate trajectory representation. Specifically, a pair of
locations may not be lined up in a sequence especially when one location
includes the other geographically. In this study, we propose a graph
representation that retains information on the geographic hierarchy as well as
the temporal order of visited locations, and have constructed a benchmark
dataset for graph-structured trajectory extraction. The experiments with our
baselines have demonstrated that it is possible to accurately predict visited
locations and the order among them, but it remains a challenge to predict the
hierarchical relations.",2024-10-22,"Aitaro Yamamoto, Hiroyuki Otomo, Hiroki Ouchi, Shohei Higashiyama, Hiroki Teranishi, Hiroyuki Shindo, Taro Watanabe",http://arxiv.org/pdf/2410.16633v1,cs.CL
Benchmarking Large Language Models for Image Classification of Marine Mammals,"As Artificial Intelligence (AI) has developed rapidly over the past few
decades, the new generation of AI, Large Language Models (LLMs) trained on
massive datasets, has achieved ground-breaking performance in many
applications. Further progress has been made in multimodal LLMs, with many
datasets created to evaluate LLMs with vision abilities. However, none of those
datasets focuses solely on marine mammals, which are indispensable for
ecological equilibrium. In this work, we build a benchmark dataset with 1,423
images of 65 kinds of marine mammals, where each animal is uniquely classified
into different levels of class, ranging from species-level to medium-level to
group-level. Moreover, we evaluate several approaches for classifying these
marine mammals: (1) machine learning (ML) algorithms using embeddings provided
by neural networks, (2) influential pre-trained neural networks, (3) zero-shot
models: CLIP and LLMs, and (4) a novel LLM-based multi-agent system (MAS). The
results demonstrate the strengths of traditional models and LLMs in different
aspects, and the MAS can further improve the classification performance. The
dataset is available on GitHub:
https://github.com/yeyimilk/LLM-Vision-Marine-Animals.git.",2024-10-22,"Yijiashun Qi, Shuzhang Cai, Zunduo Zhao, Jiaming Li, Yanbin Lin, Zhiqiang Wang",http://arxiv.org/pdf/2410.19848v1,cs.CL
Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency,"Knowledge graphs (KGs) generated by large language models (LLMs) are becoming
increasingly valuable for Retrieval-Augmented Generation (RAG) applications
that require knowledge-intensive reasoning. However, existing KG extraction
methods predominantly rely on prompt-based approaches, which are inefficient
for processing large-scale corpora. These approaches often suffer from
information loss, particularly with long documents, due to the lack of
specialized design for KG construction. Additionally, there is a gap in
evaluation datasets and methodologies for ontology-free KG construction. To
overcome these limitations, we propose SynthKG, a multi-step, document-level
ontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM
on the synthesized document-KG pairs, we streamline the multi-step process into
a single-step KG generation approach called Distill-SynthKG, substantially
reducing the number of LLM inference calls. Furthermore, we re-purpose existing
question-answering datasets to establish KG evaluation datasets and introduce
new evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a
novel graph-based retrieval framework for RAG. Experimental results demonstrate
that Distill-SynthKG not only surpasses all baseline models in KG quality --
including models up to eight times larger -- but also consistently excels in
retrieval and question-answering tasks. Our proposed graph retrieval framework
also outperforms all KG-retrieval methods across multiple benchmark datasets.
We release the SynthKG dataset and Distill-SynthKG model publicly to support
further research and development.",2024-10-22,"Prafulla Kumar Choubey, Xin Su, Man Luo, Xiangyu Peng, Caiming Xiong, Tiep Le, Shachar Rosenman, Vasudev Lal, Phil Mui, Ricky Ho, Phillip Howard, Chien-Sheng Wu",http://arxiv.org/pdf/2410.16597v1,cs.CL
ViMGuard: A Novel Multi-Modal System for Video Misinformation Guarding,"The rise of social media and short-form video (SFV) has facilitated a
breeding ground for misinformation. With the emergence of large language
models, significant research has gone into curbing this misinformation problem
with automatic false claim detection for text. Unfortunately, the automatic
detection of misinformation in SFV is a more complex problem that remains
largely unstudied. While text samples are monomodal (only containing words),
SFVs comprise three different modalities: words, visuals, and non-linguistic
audio. In this work, we introduce Video Masked Autoencoders for Misinformation
Guarding (ViMGuard), the first deep-learning architecture capable of
fact-checking an SFV through analysis of all three of its constituent
modalities. ViMGuard leverages a dual-component system. First, Video and Audio
Masked Autoencoders analyze the visual and non-linguistic audio elements of a
video to discern its intention; specifically whether it intends to make an
informative claim. If it is deemed that the SFV has informative intent, it is
passed through our second component: a Retrieval Augmented Generation system
that validates the factual accuracy of spoken words. In evaluation, ViMGuard
outperformed three cutting-edge fact-checkers, thus setting a new standard for
SFV fact-checking and marking a significant stride toward trustworthy news on
social platforms. To promote further testing and iteration, VimGuard was
deployed into a Chrome extension and all code was open-sourced on GitHub.",2024-10-22,"Andrew Kan, Christopher Kan, Zaid Nabulsi",http://arxiv.org/pdf/2410.16592v1,cs.CL
Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models,"Sentiment analysis has become increasingly important for assessing public
opinion and informing decision-making. Large language models (LLMs) have
revolutionized this field by capturing nuanced language patterns. However,
adapting LLMs to domain-specific sentiment analysis tasks remains challenging
due to computational constraints and the need for optimal fine-tuning. To
address these challenges, we propose a novel Dynamic Adaptive Rank Space
Exploration (DARSE) framework for efficient and effective sentiment analysis
using LLMs. DARSE consists of a coarse-grained greedy algorithm to identify the
optimal rank range, a fine-grained exploration algorithm to refine rank
selection, and a dynamic rank allocation method to determine the optimal rank
combination for each LLM layer. Extensive experiments demonstrate that DARSE
significantly improves sentiment analysis accuracy, achieving a 15.1%
improvement in MSE and a 4.3% improvement in accuracy compared to previous
work. Our framework strikes a balance between computational efficiency and
model performance, making it a promising approach for sentiment analysis with
LLMs.",2024-10-22,"Hongcheng Ding, Fuzhen Hu, Xuanze Zhao, Zixiao Jiang, Shamsul Nahar Abdullah, Deshinta Arrova Dewi",http://arxiv.org/pdf/2410.16589v1,cs.CL
How Performance Pressure Influences AI-Assisted Decision Making,"Many domains now employ AI-based decision-making aids, and although the
potential for AI systems to assist with decision making is much discussed,
human-AI collaboration often underperforms due to factors such as (mis)trust in
the AI system and beliefs about AI being incapable of completing subjective
tasks. One potential tool for influencing human decision making is performance
pressure, which hasn't been much studied in interaction with human-AI decision
making. In this work, we examine how pressure and explainable AI (XAI)
techniques interact with AI advice-taking behavior. Using an inherently
low-stakes task (spam review classification), we demonstrate effective and
simple methods to apply pressure and influence human AI advice-taking behavior
by manipulating financial incentives and imposing time limits. Our results show
complex interaction effects, with different combinations of pressure and XAI
techniques either improving or worsening AI advice taking behavior. We conclude
by discussing the implications of these interactions, strategies to effectively
use pressure, and encourage future research to incorporate pressure analysis.",2024-10-21,"Nikita Haduong, Noah A. Smith",http://arxiv.org/pdf/2410.16560v2,cs.CL
A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration,"Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance
in improving the reasoning capabilities of large language models (LLMs). While
theoretical investigations have been conducted to understand CoT, the
underlying transformer used in these studies isolates the CoT reasoning process
into separated in-context learning steps (Stepwise ICL). In this work, we
theoretically show that, compared to Stepwise ICL, the transformer gains better
error correction ability and more accurate predictions if the reasoning from
earlier steps (Coherent CoT) is integrated. Given that this coherent reasoning
changes the behavior of the transformer, we further investigate the sensitivity
of the transformer with Coherent CoT when the demonstration examples are
corrupted at the inference stage. Our theoretical results indicate that the
transformer is more sensitive to errors in intermediate reasoning steps than
the final outcome. Building upon this observation, we propose an improvement on
CoT by incorporating both correct and incorrect reasoning paths in the
demonstration. Our experiments validate the effectiveness of the proposed
approach.",2024-10-21,"Yingqian Cui, Pengfei He, Xianfeng Tang, Qi He, Chen Luo, Jiliang Tang, Yue Xing",http://arxiv.org/pdf/2410.16540v1,cs.CL
Large Body Language Models,"As virtual agents become increasingly prevalent in human-computer
interaction, generating realistic and contextually appropriate gestures in
real-time remains a significant challenge. While neural rendering techniques
have made substantial progress with static scripts, their applicability to
human-computer interactions remains limited. To address this, we introduce
Large Body Language Models (LBLMs) and present LBLM-AVA, a novel LBLM
architecture that combines a Transformer-XL large language model with a
parallelized diffusion model to generate human-like gestures from multimodal
inputs (text, audio, and video). LBLM-AVA incorporates several key components
enhancing its gesture generation capabilities, such as multimodal-to-pose
embeddings, enhanced sequence-to-sequence mapping with redefined attention
mechanisms, a temporal smoothing module for gesture sequence coherence, and an
attention-based refinement module for enhanced realism. The model is trained on
our large-scale proprietary open-source dataset Allo-AVA. LBLM-AVA achieves
state-of-the-art performance in generating lifelike and contextually
appropriate gestures with a 30% reduction in Fr\'echet Gesture Distance (FGD),
and a 25% improvement in Fr\'echet Inception Distance compared to existing
approaches.",2024-10-21,"Saif Punjwani, Larry Heck",http://arxiv.org/pdf/2410.16533v1,cs.CL
Bayesian scaling laws for in-context learning,"In-context learning (ICL) is a powerful technique for getting language models
to perform complex tasks with no training updates. Prior work has established
strong correlations between the number of in-context examples provided and the
accuracy of the model's predictions. In this paper, we seek to explain this
correlation by showing that ICL approximates a Bayesian learner. This
perspective gives rise to a family of novel Bayesian scaling laws for ICL. In
experiments with \mbox{GPT-2} models of different sizes, our scaling laws
exceed or match existing scaling laws in accuracy while also offering
interpretable terms for task priors, learning efficiency, and per-example
probabilities. To illustrate the analytic power that such interpretable scaling
laws provide, we report on controlled synthetic dataset experiments designed to
inform real-world studies of safety alignment. In our experimental protocol, we
use SFT to suppress an unwanted existing model capability and then use ICL to
try to bring that capability back (many-shot jailbreaking). We then experiment
on real-world instruction-tuned LLMs using capabilities benchmarks as well as a
new many-shot jailbreaking dataset. In all cases, Bayesian scaling laws
accurately predict the conditions under which ICL will cause the suppressed
behavior to reemerge, which sheds light on the ineffectiveness of post-training
at increasing LLM safety.",2024-10-21,"Aryaman Arora, Dan Jurafsky, Christopher Potts, Noah D. Goodman",http://arxiv.org/pdf/2410.16531v3,cs.CL
AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context,"As our understanding of autism and ableism continues to increase, so does our
understanding of ableist language towards autistic people. Such language poses
a significant challenge in NLP research due to its subtle and context-dependent
nature. Yet, detecting anti-autistic ableist language remains underexplored,
with existing NLP tools often failing to capture its nuanced expressions. We
present AUTALIC, the first benchmark dataset dedicated to the detection of
anti-autistic ableist language in context, addressing a significant gap in the
field. The dataset comprises 2,400 autism-related sentences collected from
Reddit, accompanied by surrounding context, and is annotated by trained experts
with backgrounds in neurodiversity. Our comprehensive evaluation reveals that
current language models, including state-of-the-art LLMs, struggle to reliably
identify anti-autistic ableism and align with human judgments, underscoring
their limitations in this domain. We publicly release AUTALIC along with the
individual annotations which serve as a valuable resource to researchers
working on ableism, neurodiversity, and also studying disagreements in
annotation tasks. This dataset serves as a crucial step towards developing more
inclusive and context-aware NLP systems that better reflect diverse
perspectives.",2024-10-21,"Naba Rizvi, Harper Strickland, Daniel Gitelman, Tristan Cooper, Alexis Morales-Flores, Michael Golden, Aekta Kallepalli, Akshat Alurkar, Haaset Owens, Saleha Ahmedi, Isha Khirwadkar, Imani Munyaka, Nedjma Ousidhoum",http://arxiv.org/pdf/2410.16520v3,cs.CL
Learning from others' mistakes: Finetuning machine translation models with span-level error annotations,"Despite growing interest in incorporating feedback to improve language
models, most efforts focus only on sequence-level annotations. In this work, we
explore the potential of utilizing fine-grained span-level annotations from
offline datasets to improve model quality. We develop a simple finetuning
algorithm, called Training with Annotations (TWA), to directly train machine
translation models on such annotated data. TWA utilizes targeted span-level
error information while also flexibly learning what to penalize within a span.
Moreover, TWA considers the overall trajectory of a sequence when deciding
which non-error spans to utilize as positive signals. Experiments on
English-German and Chinese-English machine translation show that TWA
outperforms baselines such as Supervised FineTuning on sequences filtered for
quality and Direct Preference Optimization on pairs constructed from the same
data.",2024-10-21,"Lily H. Zhang, Hamid Dadkhahi, Mara Finkelstein, Firas Trabelsi, Jiaming Luo, Markus Freitag",http://arxiv.org/pdf/2410.16509v1,cs.CL
Allo-AVA: A Large-Scale Multimodal Conversational AI Dataset for Allocentric Avatar Gesture Animation,"The scarcity of high-quality, multimodal training data severely hinders the
creation of lifelike avatar animations for conversational AI in virtual
environments. Existing datasets often lack the intricate synchronization
between speech, facial expressions, and body movements that characterize
natural human communication. To address this critical gap, we introduce
Allo-AVA, a large-scale dataset specifically designed for text and audio-driven
avatar gesture animation in an allocentric (third person point-of-view)
context. Allo-AVA consists of $\sim$1,250 hours of diverse video content,
complete with audio, transcripts, and extracted keypoints. Allo-AVA uniquely
maps these keypoints to precise timestamps, enabling accurate replication of
human movements (body and facial gestures) in synchronization with speech. This
comprehensive resource enables the development and evaluation of more natural,
context-aware avatar animation models, potentially transforming applications
ranging from virtual reality to digital assistants.",2024-10-21,"Saif Punjwani, Larry Heck",http://arxiv.org/pdf/2410.16503v1,cs.CL
Rulebreakers Challenge: Revealing a Blind Spot in Large Language Models' Reasoning with Formal Logic,"Formal logic has long been applied to natural language reasoning, but this
approach can sometimes lead to conclusions that, while logically entailed, are
factually inconsistent with the premises or are not typically inferred by
humans. This study introduces the concept of ""rulebreakers"", which refers to
instances where logical entailment diverges from factually acceptable
inference. We present RULEBREAKERS, a novel dataset for evaluating Large
Language Models' (LLMs) ability to distinguish between rulebreakers and
non-rulebreakers. Focusing on modus tollens and disjunctive syllogism, we
assess six state-of-the-art LLMs using RULEBREAKERS, measuring their
performance in terms of token-level exact accuracy and model confidence. Our
findings reveal that while most models perform poorly to moderately in
recognizing rulebreakers, they demonstrate a latent ability to distinguish
rulebreakers when assessed by their confidence levels. Further analysis
suggests that the failure to recognize rulebreakers is potentially associated
with the models' world knowledge and their attention distribution patterns.
This research highlights the limitation of LLMs' reasoning capabilities, and
contributes to the ongoing discussion on reasoning in LLMs.",2024-10-21,"Jason Chan, Robert Gaizauskas, Zhixue Zhao",http://arxiv.org/pdf/2410.16502v1,cs.CL
Natural Language Processing for Human Resources: A Survey,"Advances in Natural Language Processing (NLP) have the potential to transform
HR processes, from recruitment to employee management. While recent
breakthroughs in NLP have generated significant interest in its industrial
applications, a comprehensive overview of how NLP can be applied across HR
activities is still lacking. This paper discovers opportunities for researchers
and practitioners to harness NLP's transformative potential in this domain. We
analyze key fundamental tasks such as information extraction and text
classification, and their roles in downstream applications like recommendation
and language generation, while also discussing ethical concerns. Additionally,
we identify gaps in current research and encourage future work to explore
holistic approaches for achieving broader objectives in this field.",2024-10-21,"Naoki Otani, Nikita Bhutani, Estevam Hruschka",http://arxiv.org/pdf/2410.16498v2,cs.CL
BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data,"In this work, we tackle the challenge of embedding realistic human
personality traits into LLMs. Previous approaches have primarily focused on
prompt-based methods that describe the behavior associated with the desired
personality traits, suffering from realism and validity issues. To address
these limitations, we introduce BIG5-CHAT, a large-scale dataset containing
100,000 dialogues designed to ground models in how humans express their
personality in language. Leveraging this dataset, we explore Supervised
Fine-Tuning and Direct Preference Optimization as training-based methods to
align LLMs more naturally with human personality patterns. Our methods
outperform prompting on personality assessments such as BFI and IPIP-NEO, with
trait correlations more closely matching human data. Furthermore, our
experiments reveal that models trained to exhibit higher conscientiousness,
higher agreeableness, lower extraversion, and lower neuroticism display better
performance on reasoning tasks, aligning with psychological findings on how
these traits impact human cognitive performance. To our knowledge, this work is
the first comprehensive study to demonstrate how training-based methods can
shape LLM personalities through learning from real human behaviors.",2024-10-21,"Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap",http://arxiv.org/pdf/2410.16491v2,cs.CL
Multi-head Sequence Tagging Model for Grammatical Error Correction,"To solve the Grammatical Error Correction (GEC) problem , a mapping between a
source sequence and a target one is needed, where the two differ only on few
spans. For this reason, the attention has been shifted to the
non-autoregressive or sequence tagging models. In which, the GEC has been
simplified from Seq2Seq to labeling the input tokens with edit commands chosen
from a large edit space. Due to this large number of classes and the limitation
of the available datasets, the current sequence tagging approaches still have
some issues handling a broad range of grammatical errors just by being
laser-focused on one single task. To this end, we simplified the GEC further by
dividing it into seven related subtasks: Insertion, Deletion, Merge,
Substitution, Transformation, Detection, and Correction, with Correction being
our primary focus. A distinct classification head is dedicated to each of these
subtasks. the novel multi-head and multi-task learning model is proposed to
effectively utilize training data and harness the information from related task
training signals. To mitigate the limited number of available training samples,
a new denoising autoencoder is used to generate a new synthetic dataset to be
used for pretraining. Additionally, a new character-level transformation is
proposed to enhance the sequence-to-edit function and improve the model's
vocabulary coverage. Our single/ensemble model achieves an F0.5 of 74.4/77.0,
and 68.6/69.1 on BEA-19 (test) and CoNLL-14 (test) respectively. Moreover,
evaluated on JFLEG test set, the GLEU scores are 61.6 and 61.7 for the single
and ensemble models, respectively. It mostly outperforms recently published
state-of-the-art results by a considerable margin.",2024-10-21,"Kamal Al-Sabahi, Kang Yang, Wangwang Liu, Guanyu Jiang, Xian Li, Ming Yang",http://arxiv.org/pdf/2410.16473v1,cs.CL
DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding,"Document structure editing involves manipulating localized textual, visual,
and layout components in document images based on the user's requests. Past
works have shown that multimodal grounding of user requests in the document
image and identifying the accurate structural components and their associated
attributes remain key challenges for this task. To address these, we introduce
the DocEdit-v2, a novel framework that performs end-to-end document editing by
leveraging Large Multimodal Models (LMMs). It consists of three novel
components: (1) Doc2Command, which simultaneously localizes edit regions of
interest (RoI) and disambiguates user edit requests into edit commands; (2)
LLM-based Command Reformulation prompting to tailor edit commands originally
intended for specialized software into edit instructions suitable for
generalist LMMs. (3) Moreover, DocEdit-v2 processes these outputs via Large
Multimodal Models like GPT-4V and Gemini, to parse the document layout, execute
edits on grounded Region of Interest (RoI), and generate the edited document
image. Extensive experiments on the DocEdit dataset show that DocEdit-v2
significantly outperforms strong baselines on edit command generation (2-33%),
RoI bounding box detection (12-31%), and overall document editing (1-12\%)
tasks.",2024-10-21,"Manan Suri, Puneet Mathur, Franck Dernoncourt, Rajiv Jain, Vlad I Morariu, Ramit Sawhney, Preslav Nakov, Dinesh Manocha",http://arxiv.org/pdf/2410.16472v1,cs.CL
Beyond Browsing: API-Based Web Agents,"Web browsers are a portal to the internet, where much of human activity is
undertaken. Thus, there has been significant research work in AI agents that
interact with the internet through web browsing. However, there is also another
interface designed specifically for machine interaction with online content:
application programming interfaces (APIs). In this paper we ask -- what if we
were to take tasks traditionally tackled by browsing agents, and give AI agents
access to APIs? To do so, we propose two varieties of agents: (1) an
API-calling agent that attempts to perform online tasks through APIs only,
similar to traditional coding agents, and (2) a Hybrid Agent that can interact
with online data through both web browsing and APIs. In experiments on
WebArena, a widely-used and realistic benchmark for web navigation tasks, we
find that API-based agents outperform web browsing agents. Hybrid Agents
out-perform both others nearly uniformly across tasks, resulting in a more than
20.0% absolute improvement over web browsing alone, achieving a success rate of
35.8%, achiving the SOTA performance among task-agnostic agents. These results
strongly suggest that when APIs are available, they present an attractive
alternative to relying on web browsing alone.",2024-10-21,"Yueqi Song, Frank Xu, Shuyan Zhou, Graham Neubig",http://arxiv.org/pdf/2410.16464v2,cs.CL
Comparative Study of Multilingual Idioms and Similes in Large Language Models,"This study addresses the gap in the literature concerning the comparative
performance of LLMs in interpreting different types of figurative language
across multiple languages. By evaluating LLMs using two multilingual datasets
on simile and idiom interpretation, we explore the effectiveness of various
prompt engineering strategies, including chain-of-thought, few-shot, and
English translation prompts. We extend the language of these datasets to
Persian as well by building two new evaluation sets. Our comprehensive
assessment involves both closed-source (GPT-3.5, GPT-4o mini, Gemini 1.5), and
open-source models (Llama 3.1, Qwen2), highlighting significant differences in
performance across languages and figurative types. Our findings reveal that
while prompt engineering methods are generally effective, their success varies
by figurative type, language, and model. We also observe that open-source
models struggle particularly with low-resource languages in similes.
Additionally, idiom interpretation is nearing saturation for many languages,
necessitating more challenging evaluations.",2024-10-21,"Paria Khoshtab, Danial Namazifard, Mostafa Masoudi, Ali Akhgary, Samin Mahdizadeh Sani, Yadollah Yaghoobzadeh",http://arxiv.org/pdf/2410.16461v2,cs.CL
R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation,"Radiology report generation is crucial in medical imaging,but the manual
annotation process by physicians is time-consuming and labor-intensive,
necessitating the develop-ment of automatic report generation methods.
Existingresearch predominantly utilizes Transformers to generateradiology
reports, which can be computationally intensive,limiting their use in real
applications. In this work, we presentR2Gen-Mamba, a novel automatic radiology
report genera-tion method that leverages the efficient sequence processingof
the Mamba with the contextual benefits of Transformerarchitectures. Due to
lower computational complexity ofMamba, R2Gen-Mamba not only enhances training
and in-ference efficiency but also produces high-quality reports.Experimental
results on two benchmark datasets with morethan 210,000 X-ray image-report
pairs demonstrate the ef-fectiveness of R2Gen-Mamba regarding report quality
andcomputational efficiency compared with several state-of-the-art methods. The
source code can be accessed online.",2024-10-21,"Yongheng Sun, Yueh Z. Lee, Genevieve A. Woodard, Hongtu Zhu, Chunfeng Lian, Mingxia Liu",http://arxiv.org/pdf/2410.18135v1,cs.CL
To the Globe (TTG): Towards Language-Driven Guaranteed Travel Planning,"Travel planning is a challenging and time-consuming task that aims to find an
itinerary which satisfies multiple, interdependent constraints regarding
flights, accommodations, attractions, and other travel arrangements. In this
paper, we propose To the Globe (TTG), a real-time demo system that takes
natural language requests from users, translates it to symbolic form via a
fine-tuned Large Language Model, and produces optimal travel itineraries with
Mixed Integer Linear Programming solvers. The overall system takes ~5 seconds
to reply to the user request with guaranteed itineraries. To train TTG, we
develop a synthetic data pipeline that generates user requests, flight and
hotel information in symbolic form without human annotations, based on the
statistics of real-world datasets, and fine-tune an LLM to translate NL user
requests to their symbolic form, which is sent to the symbolic solver to
compute optimal itineraries. Our NL-symbolic translation achieves ~91% exact
match in a backtranslation metric (i.e., whether the estimated symbolic form of
generated natural language matches the groundtruth), and its returned
itineraries have a ratio of 0.979 compared to the optimal cost of the ground
truth user request. When evaluated by users, TTG achieves consistently high Net
Promoter Scores (NPS) of 35-40% on generated itinerary.",2024-10-21,"Da JU, Song Jiang, Andrew Cohen, Aaron Foss, Sasha Mitts, Arman Zharmagambetov, Brandon Amos, Xian Li, Justine T Kao, Maryam Fazel-Zarandi, Yuandong Tian",http://arxiv.org/pdf/2410.16456v1,cs.CL
Catastrophic Failure of LLM Unlearning via Quantization,"Large language models (LLMs) have shown remarkable proficiency in generating
text, benefiting from extensive training on vast textual corpora. However, LLMs
may also acquire unwanted behaviors from the diverse and sensitive nature of
their training data, which can include copyrighted and private content. Machine
unlearning has been introduced as a viable solution to remove the influence of
such problematic content without the need for costly and time-consuming
retraining. This process aims to erase specific knowledge from LLMs while
preserving as much model utility as possible. Despite the effectiveness of
current unlearning methods, little attention has been given to whether existing
unlearning methods for LLMs truly achieve forgetting or merely hide the
knowledge, which current unlearning benchmarks fail to detect. This paper
reveals that applying quantization to models that have undergone unlearning can
restore the ""forgotten"" information. To thoroughly evaluate this phenomenon, we
conduct comprehensive experiments using various quantization techniques across
multiple precision levels. We find that for unlearning methods with utility
constraints, the unlearned model retains an average of 21\% of the intended
forgotten knowledge in full precision, which significantly increases to 83\%
after 4-bit quantization. ... Our code is available at:
\href{https://github.com/zzwjames/FailureLLMUnlearning}{https://github.com/zzwjames/FailureLLMUnlearning}.",2024-10-21,"Zhiwei Zhang, Fali Wang, Xiaomin Li, Zongyu Wu, Xianfeng Tang, Hui Liu, Qi He, Wenpeng Yin, Suhang Wang",http://arxiv.org/pdf/2410.16454v3,cs.CL
Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S,"Recent work has highlighted the culturally-contingent nature of commonsense
knowledge. We introduce AMAMMER${\epsilon}$, a test set of 525 multiple-choice
questions designed to evaluate the commonsense knowledge of English LLMs,
relative to the cultural contexts of Ghana and the United States. To create
AMAMMER${\epsilon}$, we select a set of multiple-choice questions (MCQs) from
existing commonsense datasets and rewrite them in a multi-stage process
involving surveys of Ghanaian and U.S. participants. In three rounds of
surveys, participants from both pools are solicited to (1) write correct and
incorrect answer choices, (2) rate individual answer choices on a 5-point
Likert scale, and (3) select the best answer choice from the newly-constructed
MCQ items, in a final validation step. By engaging participants at multiple
stages, our procedure ensures that participant perspectives are incorporated
both in the creation and validation of test items, resulting in high levels of
agreement within each pool. We evaluate several off-the-shelf English LLMs on
AMAMMER${\epsilon}$. Uniformly, models prefer answers choices that align with
the preferences of U.S. annotators over Ghanaian annotators. Additionally, when
test items specify a cultural context (Ghana or the U.S.), models exhibit some
ability to adapt, but performance is consistently better in U.S. contexts than
Ghanaian. As large resources are devoted to the advancement of English LLMs,
our findings underscore the need for culturally adaptable models and
evaluations to meet the needs of diverse English-speaking populations around
the world.",2024-10-21,"Christabel Acquaye, Haozhe An, Rachel Rudinger",http://arxiv.org/pdf/2410.16451v2,cs.CL
Improving Neuron-level Interpretability with White-box Language Models,"Neurons in auto-regressive language models like GPT-2 can be interpreted by
analyzing their activation patterns. Recent studies have shown that techniques
such as dictionary learning, a form of post-hoc sparse coding, enhance this
neuron-level interpretability. In our research, we are driven by the goal to
fundamentally improve neural network interpretability by embedding sparse
coding directly within the model architecture, rather than applying it as an
afterthought. In our study, we introduce a white-box transformer-like
architecture named Coding RAte TransformEr (CRATE), explicitly engineered to
capture sparse, low-dimensional structures within data distributions. Our
comprehensive experiments showcase significant improvements (up to 103%
relative improvement) in neuron-level interpretability across a variety of
evaluation metrics. Detailed investigations confirm that this enhanced
interpretability is steady across different layers irrespective of the model
size, underlining CRATE's robust performance in enhancing neural network
interpretability. Further analysis shows that CRATE's increased
interpretability comes from its enhanced ability to consistently and
distinctively activate on relevant tokens. These findings point towards a
promising direction for creating white-box foundation models that excel in
neuron-level interpretation.",2024-10-21,"Hao Bai, Yi Ma",http://arxiv.org/pdf/2410.16443v4,cs.CL
Enhancing Multimodal Affective Analysis with Learned Live Comment Features,"Live comments, also known as Danmaku, are user-generated messages that are
synchronized with video content. These comments overlay directly onto streaming
videos, capturing viewer emotions and reactions in real-time. While prior work
has leveraged live comments in affective analysis, its use has been limited due
to the relative rarity of live comments across different video platforms. To
address this, we first construct the Live Comment for Affective Analysis
(LCAffect) dataset which contains live comments for English and Chinese videos
spanning diverse genres that elicit a wide spectrum of emotions. Then, using
this dataset, we use contrastive learning to train a video encoder to produce
synthetic live comment features for enhanced multimodal affective content
analysis. Through comprehensive experimentation on a wide range of affective
analysis tasks (sentiment, emotion recognition, and sarcasm detection) in both
English and Chinese, we demonstrate that these synthetic live comment features
significantly improve performance over state-of-the-art methods.",2024-10-21,"Zhaoyuan Deng, Amith Ananthram, Kathleen McKeown",http://arxiv.org/pdf/2410.16407v1,cs.CL
VipAct: Visual-Perception Enhancement via Specialized VLM Agent Collaboration and Tool-use,"While vision-language models (VLMs) have demonstrated remarkable performance
across various tasks combining textual and visual information, they continue to
struggle with fine-grained visual perception tasks that require detailed
pixel-level analysis. Effectively eliciting comprehensive reasoning from VLMs
on such intricate visual elements remains an open challenge. In this paper, we
present VipAct, an agent framework that enhances VLMs by integrating
multi-agent collaboration and vision expert models, enabling more precise
visual understanding and comprehensive reasoning. VipAct consists of an
orchestrator agent, which manages task requirement analysis, planning, and
coordination, along with specialized agents that handle specific tasks such as
image captioning and vision expert models that provide high-precision
perceptual information. This multi-agent approach allows VLMs to better perform
fine-grained visual perception tasks by synergizing planning, reasoning, and
tool use. We evaluate VipAct on benchmarks featuring a diverse set of visual
perception tasks, with experimental results demonstrating significant
performance improvements over state-of-the-art baselines across all tasks.
Furthermore, comprehensive ablation studies reveal the critical role of
multi-agent collaboration in eliciting more detailed System-2 reasoning and
highlight the importance of image input for task planning. Additionally, our
error analysis identifies patterns of VLMs' inherent limitations in visual
perception, providing insights into potential future improvements. VipAct
offers a flexible and extensible framework, paving the way for more advanced
visual perception systems across various real-world applications.",2024-10-21,"Zhehao Zhang, Ryan Rossi, Tong Yu, Franck Dernoncourt, Ruiyi Zhang, Jiuxiang Gu, Sungchul Kim, Xiang Chen, Zichao Wang, Nedim Lipka",http://arxiv.org/pdf/2410.16400v1,cs.CL
Training of Scaffolded Language Models with Language Supervision: A Survey,"This survey organizes the intricate literature on the design and optimization
of emerging structures around post-trained LMs. We refer to this overarching
structure as scaffolded LMs and focus on LMs that are integrated into
multi-step processes with tools. We view scaffolded LMs as semi-parametric
models wherein we train non-parametric variables, including the prompt, tools,
and scaffold's code. In particular, they interpret instructions, use tools, and
receive feedback all in language. Recent works use an LM as an optimizer to
interpret language supervision and update non-parametric variables according to
intricate objectives. In this survey, we refer to this paradigm as training of
scaffolded LMs with language supervision. A key feature of non-parametric
training is the ability to learn from language. Parametric training excels in
learning from demonstration (supervised learning), exploration (reinforcement
learning), or observations (unsupervised learning), using well-defined loss
functions. Language-based optimization enables rich, interpretable, and
expressive objectives, while mitigating issues like catastrophic forgetting and
supporting compatibility with closed-source models. Furthermore, agents are
increasingly deployed as co-workers in real-world applications such as Copilot
in Office tools or software development. In these mixed-autonomy settings,
where control and decision-making are shared between human and AI, users point
out errors or suggest corrections. Accordingly, we discuss agents that
continuously improve by learning from this real-time, language-based feedback
and refer to this setting as streaming learning from language supervision.",2024-10-21,"Matthieu Lin, Jenny Sheng, Andrew Zhao, Shenzhi Wang, Yang Yue, Victor Shea Jay Huang, Huan Liu, Jun Liu, Gao Huang, Yong-Jin Liu",http://arxiv.org/pdf/2410.16392v2,cs.CL
KatzBot: Revolutionizing Academic Chatbot for Enhanced Communication,"Effective communication within universities is crucial for addressing the
diverse information needs of students, alumni, and external stakeholders.
However, existing chatbot systems often fail to deliver accurate,
context-specific responses, resulting in poor user experiences. In this paper,
we present KatzBot, an innovative chatbot powered by KatzGPT, a custom Large
Language Model (LLM) fine-tuned on domain-specific academic data. KatzGPT is
trained on two university-specific datasets: 6,280 sentence-completion pairs
and 7,330 question-answer pairs. KatzBot outperforms established existing open
source LLMs, achieving higher accuracy and domain relevance. KatzBot offers a
user-friendly interface, significantly enhancing user satisfaction in
real-world applications. The source code is publicly available at
\url{https://github.com/AiAI-99/katzbot}.",2024-10-21,"Sahil Kumar, Deepa Paikar, Kiran Sai Vutukuri, Haider Ali, Shashidhar Reddy Ainala, Aditya Murli Krishnan, Youshan Zhang",http://arxiv.org/pdf/2410.16385v1,cs.CL
xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs,"We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for
videos, particularly designed to efficiently capture temporal information over
multiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in
addition to the conventional visual tokenizer, which maps a sequence of tokens
over multiple frames into a compact set of visual tokens. This enables
BLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32
vs. 4608 tokens). We explore different types of temporal encoders, including
learnable spatio-temporal pooling as well as sequential models like Token
Turing Machines. We experimentally confirm that BLIP-3-Video obtains video
question-answering accuracies comparable to much larger state-of-the-art models
(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using
fewer visual tokens. The project website is at
https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html",2024-10-21,"Michael S. Ryoo, Honglu Zhou, Shrikant Kendre, Can Qin, Le Xue, Manli Shu, Silvio Savarese, Ran Xu, Caiming Xiong, Juan Carlos Niebles",http://arxiv.org/pdf/2410.16267v1,cs.CL
CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution,"Efficient and accurate evaluation is crucial for the continuous improvement
of large language models (LLMs). Among various assessment methods, subjective
evaluation has garnered significant attention due to its superior alignment
with real-world usage scenarios and human preferences. However, human-based
evaluations are costly and lack reproducibility, making precise automated
evaluators (judgers) vital in this process. In this report, we introduce
\textbf{CompassJudger-1}, the first open-source \textbf{all-in-one} judge LLM.
CompassJudger-1 is a general-purpose LLM that demonstrates remarkable
versatility. It is capable of: 1. Performing unitary scoring and two-model
comparisons as a reward model; 2. Conducting evaluations according to specified
formats; 3. Generating critiques; 4. Executing diverse tasks like a general
LLM. To assess the evaluation capabilities of different judge models under a
unified setting, we have also established \textbf{JudgerBench}, a new benchmark
that encompasses various subjective evaluation tasks and covers a wide range of
topics. CompassJudger-1 offers a comprehensive solution for various evaluation
tasks while maintaining the flexibility to adapt to diverse requirements. Both
CompassJudger and JudgerBench are released and available to the research
community athttps://github.com/open-compass/CompassJudger. We believe that by
open-sourcing these tools, we can foster collaboration and accelerate progress
in LLM evaluation methodologies.",2024-10-21,"Maosong Cao, Alexander Lam, Haodong Duan, Hongwei Liu, Songyang Zhang, Kai Chen",http://arxiv.org/pdf/2410.16256v1,cs.CL
Can Knowledge Editing Really Correct Hallucinations?,"Large Language Models (LLMs) suffer from hallucinations, referring to the
non-factual information in generated content, despite their superior capacities
across tasks. Meanwhile, knowledge editing has been developed as a new popular
paradigm to correct erroneous factual knowledge encoded in LLMs with the
advantage of avoiding retraining from scratch. However, a common issue of
existing evaluation datasets for knowledge editing is that they do not ensure
that LLMs actually generate hallucinated answers to the evaluation questions
before editing. When LLMs are evaluated on such datasets after being edited by
different techniques, it is hard to directly adopt the performance to assess
the effectiveness of different knowledge editing methods in correcting
hallucinations. Thus, the fundamental question remains insufficiently
validated: Can knowledge editing really correct hallucinations in LLMs? We
proposed HalluEditBench to holistically benchmark knowledge editing methods in
correcting real-world hallucinations. First, we rigorously construct a massive
hallucination dataset with 9 domains, 26 topics and more than 6,000
hallucinations. Then, we assess the performance of knowledge editing methods in
a holistic way on five dimensions including Efficacy, Generalization,
Portability, Locality, and Robustness. Through HalluEditBench, we have provided
new insights into the potentials and limitations of different knowledge editing
methods in correcting hallucinations, which could inspire future improvements
and facilitate progress in the field of knowledge editing.",2024-10-21,"Baixiang Huang, Canyu Chen, Xiongxiao Xu, Ali Payani, Kai Shu",http://arxiv.org/pdf/2410.16251v3,cs.CL
Analyzing Context Contributions in LLM-based Machine Translation,"Large language models (LLMs) have achieved state-of-the-art performance in
machine translation (MT) and demonstrated the ability to leverage in-context
learning through few-shot examples. However, the mechanisms by which LLMs use
different parts of the input context remain largely unexplored. In this work,
we provide a comprehensive analysis of context utilization in MT, studying how
LLMs use various context parts, such as few-shot examples and the source text,
when generating translations. We highlight several key findings: (1) the source
part of few-shot examples appears to contribute more than its corresponding
targets, irrespective of translation direction; (2) finetuning LLMs with
parallel data alters the contribution patterns of different context parts; and
(3) there is a positional bias where earlier few-shot examples have higher
contributions to the translated sequence. Finally, we demonstrate that
inspecting anomalous context contributions can potentially uncover pathological
translations, such as hallucinations. Our findings shed light on the internal
workings of LLM-based MT which go beyond those known for standard
encoder-decoder MT models.",2024-10-21,"Emmanouil Zaranis, Nuno M. Guerreiro, André F. T. Martins",http://arxiv.org/pdf/2410.16246v1,cs.CL
ToW: Thoughts of Words Improve Reasoning in Large Language Models,"We introduce thoughts of words (ToW), a novel training-time data-augmentation
method for next-word prediction. ToW views next-word prediction as a core
reasoning task and injects fine-grained thoughts explaining what the next word
should be and how it is related to the previous contexts in pre-training texts.
Our formulation addresses two fundamental drawbacks of existing next-word
prediction learning schemes: they induce factual hallucination and are
inefficient for models to learn the implicit reasoning processes in raw texts.
While there are many ways to acquire such thoughts of words, we explore the
first step of acquiring ToW annotations through distilling from larger models.
After continual pre-training with only 70K ToW annotations, we effectively
improve models' reasoning performances by 7% to 9% on average and reduce model
hallucination by up to 10%. At the same time, ToW is entirely agnostic to tasks
and applications, introducing no additional biases on labels or semantics.",2024-10-21,"Zhikun Xu, Ming Shen, Jacob Dineen, Zhaonan Li, Xiao Ye, Shijie Lu, Aswin RRV, Chitta Baral, Ben Zhou",http://arxiv.org/pdf/2410.16235v2,cs.CL
Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping,"Sketches are a natural and accessible medium for UI designers to
conceptualize early-stage ideas. However, existing research on UI/UX automation
often requires high-fidelity inputs like Figma designs or detailed screenshots,
limiting accessibility and impeding efficient design iteration. To bridge this
gap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art
Vision Language Models (VLMs) on automating the conversion of rudimentary
sketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code
supports interactive agent evaluation that mimics real-world design workflows,
where a VLM-based agent iteratively refines its generations by communicating
with a simulated user, either passively receiving feedback instructions or
proactively asking clarification questions. We comprehensively analyze ten
commercial and open-source models, showing that Sketch2Code is challenging for
existing VLMs; even the most capable models struggle to accurately interpret
sketches and formulate effective questions that lead to steady improvement.
Nevertheless, a user study with UI/UX experts reveals a significant preference
for proactive question-asking over passive feedback reception, highlighting the
need to develop more effective paradigms for multi-turn conversational agents.",2024-10-21,"Ryan Li, Yanzhe Zhang, Diyi Yang",http://arxiv.org/pdf/2410.16232v1,cs.CL
Building A Coding Assistant via the Retrieval-Augmented Language Model,"Pretrained language models have shown strong effectiveness in code-related
tasks, such as code retrieval, code generation, code summarization, and code
completion tasks. In this paper, we propose COde assistaNt viA
retrieval-augmeNted language model (CONAN), which aims to build a code
assistant by mimicking the knowledge-seeking behaviors of humans during coding.
Specifically, it consists of a code structure aware retriever (CONAN-R) and a
dual-view code representation-based retrieval-augmented generation model
(CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment and
Masked Entity Prediction tasks to make language models code structure-aware and
learn effective representations for code snippets and documentation. Then
CONAN-G designs a dual-view code representation mechanism for implementing a
retrieval-augmented code generation model. CONAN-G regards the code
documentation descriptions as prompts, which help language models better
understand the code semantics. Our experiments show that CONAN achieves
convincing performance on different code generation tasks and significantly
outperforms previous retrieval augmented code generation models. Our further
analyses show that CONAN learns tailored representations for both code snippets
and documentation by aligning code-documentation data pairs and capturing
structural semantics by masking and predicting entities in the code data.
Additionally, the retrieved code snippets and documentation provide necessary
information from both program language and natural language to assist the code
generation process. CONAN can also be used as an assistant for Large Language
Models (LLMs), providing LLMs with external knowledge in shorter code document
lengths to improve their effectiveness on various code tasks. It shows the
ability of CONAN to extract necessary information and help filter out the noise
from retrieved code documents.",2024-10-21,"Xinze Li, Hanbin Wang, Zhenghao Liu, Shi Yu, Shuo Wang, Yukun Yan, Yukai Fu, Yu Gu, Ge Yu",http://arxiv.org/pdf/2410.16229v2,cs.CL
On Creating an English-Thai Code-switched Machine Translation in Medical Domain,"Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",2024-10-21,"Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Sae-jia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat",http://arxiv.org/pdf/2410.16221v1,cs.CL
Pre-training Distillation for Large Language Models: A Design Space Exploration,"Knowledge distillation (KD) aims to transfer knowledge from a large teacher
model to a smaller student model. Previous work applying KD in the field of
large language models (LLMs) typically focused on the post-training phase,
where the student LLM learns directly from instructions and corresponding
responses generated by the teacher model. In this paper, we extend KD to the
pre-training phase of LLMs, named pre-training distillation (PD). We first
conduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a
1.9B parameter student LLM, validating the effectiveness of PD. Considering the
key impact factors of distillation, we systematically explore the design space
of pre-training distillation across four aspects: logits processing, loss
selection, scaling law, and offline or online logits. We conduct extensive
experiments to explore the design space of pre-training distillation and find
better configurations and interesting conclusions, such as larger student LLMs
generally benefiting more from pre-training distillation, while a larger
teacher LLM does not necessarily guarantee better results. We hope our
exploration of the design space will inform future practices in pre-training
distillation.",2024-10-21,"Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li",http://arxiv.org/pdf/2410.16215v1,cs.CL
Compute-Constrained Data Selection,"Data selection can reduce the amount of training data needed to finetune
LLMs; however, the efficacy of data selection scales directly with its compute.
Motivated by the practical challenge of compute-constrained finetuning, we
consider the setting in which both the cost of selecting data and training are
budgeted for. We first formalize the problem of data selection with a
cost-aware utility function, and model the data selection problem as trading
off initial-selection cost for training gain. We run a comprehensive sweep of
experiments across multiple tasks, varying compute budget by scaling finetuning
tokens, model sizes, and data selection compute. Interestingly we find that
many powerful data selection methods are almost never compute-optimal, and that
cheaper data selection alternatives dominate both from a theoretical and
empirical perspective. For compute-optimal training, we find that perplexity
and gradient data selection require training-to-selection model size ratios of
5x and 10x, respectively.",2024-10-21,"Junjie Oscar Yin, Alexander M. Rush",http://arxiv.org/pdf/2410.16208v4,cs.CL
CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning,"Autonomous agents often face the challenge of interpreting uncertain natural
language instructions for planning tasks. Representing these instructions as
Linear Temporal Logic (LTL) enables planners to synthesize actionable plans. We
introduce CoT-TL, a data-efficient in-context learning framework for
translating natural language specifications into LTL representations. CoT-TL
addresses the limitations of large language models, which typically rely on
extensive fine-tuning data, by extending chain-of-thought reasoning and
semantic roles to align with the requirements of formal logic creation. This
approach enhances the transparency and rationale behind LTL generation,
fostering user trust. CoT-TL achieves state-of-the-art accuracy across three
diverse datasets in low-data scenarios, outperforming existing methods without
fine-tuning or intermediate translations. To improve reliability and minimize
hallucinations, we incorporate model checking to validate the syntax of the
generated LTL output. We further demonstrate CoT-TL's effectiveness through
ablation studies and evaluations on unseen LTL structures and formulas in a new
dataset. Finally, we validate CoT-TL's practicality by integrating it into a
QuadCopter for multi-step drone planning based on natural language
instructions.",2024-10-21,"Kumar Manas, Stefan Zwicklbauer, Adrian Paschke",http://arxiv.org/pdf/2410.16207v1,cs.CL
Machine Learning Approaches for Mental Illness Detection on Social Media: A Systematic Review of Biases and Methodological Challenges,"The global increase in mental illness requires innovative detection methods
for early intervention. Social media provides a valuable platform to identify
mental illness through user-generated content. This systematic review examines
machine learning (ML) models for detecting mental illness, with a particular
focus on depression, using social media data. It highlights biases and
methodological challenges encountered throughout the ML lifecycle. A search of
PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies
published after 2010. The Prediction model Risk Of Bias ASsessment Tool
(PROBAST) was utilized to assess methodological quality and risk of bias.
  The review reveals significant biases affecting model reliability and
generalizability. A predominant reliance on Twitter (63.8%) and
English-language content (over 90%) limits diversity, with most studies focused
on users from the United States and Europe. Non-probability sampling (80%)
limits representativeness. Only 23% explicitly addressed linguistic nuances
like negations, crucial for accurate sentiment analysis. Inconsistent
hyperparameter tuning (27.7%) and inadequate data partitioning (17%) risk
overfitting. While 74.5% used appropriate evaluation metrics for imbalanced
data, others relied on accuracy without addressing class imbalance, potentially
skewing results. Reporting transparency varied, often lacking critical
methodological details.
  These findings highlight the need to diversify data sources, standardize
preprocessing, ensure consistent model development, address class imbalance,
and enhance reporting transparency. By overcoming these challenges, future
research can develop more robust and generalizable ML models for depression
detection on social media, contributing to improved mental health outcomes
globally.",2024-10-21,"Yuchen Cao, Jianglai Dai, Zhongyan Wang, Yeyubei Zhang, Xiaorui Shen, Yunchong Liu, Yexin Tian",http://arxiv.org/pdf/2410.16204v3,cs.CL
Information for Conversation Generation: Proposals Utilising Knowledge Graphs,"LLMs are frequently used tools for conversational generation. Without
additional information LLMs can generate lower quality responses due to lacking
relevant content and hallucinations, as well as the perception of poor
emotional capability, and an inability to maintain a consistent character.
Knowledge graphs are commonly used forms of external knowledge and may provide
solutions to these challenges. This paper introduces three proposals, utilizing
knowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph
embeddings and recommendation could allow for the integration of new
information and the selection of relevant knowledge for response generation.
Secondly, storing entities with emotional values as additional features may
provide knowledge that is better emotionally aligned with the user input.
Thirdly, integrating character information through narrative bubbles would
maintain character consistency, as well as introducing a structure that would
readily incorporate new information.",2024-10-21,"Alex Clay, Ernesto Jiménez-Ruiz",http://arxiv.org/pdf/2410.16196v1,cs.CL
Contamination Report for Multilingual Benchmarks,"Benchmark contamination refers to the presence of test datasets in Large
Language Model (LLM) pre-training or post-training data. Contamination can lead
to inflated scores on benchmarks, compromising evaluation results and making it
difficult to determine the capabilities of models. In this work, we study the
contamination of popular multilingual benchmarks in LLMs that support multiple
languages. We use the Black Box test to determine whether $7$ frequently used
multilingual benchmarks are contaminated in $7$ popular open and closed LLMs
and find that almost all models show signs of being contaminated with almost
all the benchmarks we test. Our findings can help the community determine the
best set of benchmarks to use for multilingual evaluation.",2024-10-21,"Sanchit Ahuja, Varun Gumma, Sunayana Sitaram",http://arxiv.org/pdf/2410.16186v1,cs.CL
RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style,"Reward models are critical in techniques like Reinforcement Learning from
Human Feedback (RLHF) and Inference Scaling Laws, where they guide language
model alignment and select optimal responses. Despite their importance,
existing reward model benchmarks often evaluate models by asking them to
distinguish between responses generated by models of varying power. However,
this approach fails to assess reward models on subtle but critical content
changes and variations in style, resulting in a low correlation with policy
model performance. To this end, we introduce RM-Bench, a novel benchmark
designed to evaluate reward models based on their sensitivity to subtle content
differences and resistance to style biases. Extensive experiments demonstrate
that RM-Bench strongly correlates with policy model performance, making it a
reliable reference for selecting reward models to align language models
effectively. We evaluate nearly 40 reward models on RM-Bench. Our results
reveal that even state-of-the-art models achieve an average performance of only
46.6%, which falls short of random-level accuracy (50%) when faced with style
bias interference. These findings highlight the significant room for
improvement in current reward models. Related code and data are available at
https://github.com/THU-KEG/RM-Bench.",2024-10-21,"Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li",http://arxiv.org/pdf/2410.16184v1,cs.CL
MagicPIG: LSH Sampling for Efficient LLM Generation,"Large language models (LLMs) with long context windows have gained
significant attention. However, the KV cache, stored to avoid re-computation,
becomes a bottleneck. Various dynamic sparse or TopK-based attention
approximation methods have been proposed to leverage the common insight that
attention is sparse. In this paper, we first show that TopK attention itself
suffers from quality degradation in certain downstream tasks because attention
is not always as sparse as expected. Rather than selecting the keys and values
with the highest attention scores, sampling with theoretical guarantees can
provide a better estimation for attention output. To make the sampling-based
approximation practical in LLM generation, we propose MagicPIG, a heterogeneous
system based on Locality Sensitive Hashing (LSH). MagicPIG significantly
reduces the workload of attention computation while preserving high accuracy
for diverse tasks. MagicPIG stores the LSH hash tables and runs the attention
computation on the CPU, which allows it to serve longer contexts and larger
batch sizes with high approximation accuracy. MagicPIG can improve decoding
throughput by up to $5\times$ across various GPU hardware and achieve 54ms
decoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a
context of 96k tokens. The code is available at
https://github.com/Infini-AI-Lab/MagicPIG.",2024-10-21,"Zhuoming Chen, Ranajoy Sadhukhan, Zihao Ye, Yang Zhou, Jianyu Zhang, Niklas Nolte, Yuandong Tian, Matthijs Douze, Leon Bottou, Zhihao Jia, Beidi Chen",http://arxiv.org/pdf/2410.16179v4,cs.CL
Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models,"Large Language Models (LLMs) demonstrate exceptional capabilities in a
multitude of NLP tasks. However, the efficacy of such models to languages other
than English is often limited. Prior works have shown that encoder-only models
such as BERT or XLM-RoBERTa show impressive cross lingual transfer of their
capabilities from English to other languages. In this work, we propose a
pretraining strategy that uses active forgetting to achieve similar cross
lingual transfer in decoder-only LLMs. We show that LLMs pretrained with active
forgetting are highly effective when adapting to new and unseen languages.
Through extensive experimentation, we find that LLMs pretrained with active
forgetting are able to learn better multilingual representations which
translates to better performance in many downstream tasks.",2024-10-21,"Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram",http://arxiv.org/pdf/2410.16168v2,cs.CL
Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining,"Multimodal large language models (MLLMs) have made significant strides by
integrating visual and textual modalities. A critical factor in training MLLMs
is the quality of image-text pairs within multimodal pretraining datasets.
However, $\textit {de facto}$ filter-based data quality enhancement paradigms
often discard a substantial portion of high-quality image data due to
inadequate semantic alignment between images and texts, leading to
inefficiencies in data utilization and scalability. In this paper, we propose
the Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamically
assesses and enhances the quality of image-text pairs. AITQE employs a text
rewriting mechanism for low-quality pairs and incorporates a negative sample
learning strategy to improve evaluative capabilities by integrating
deliberately selected low-quality samples during training. Unlike prior
approaches that significantly alter text distributions, our method minimally
adjusts text to preserve data volume while enhancing quality. Experimental
results demonstrate that AITQE surpasses existing methods on various benchmark,
effectively leveraging raw data and scaling efficiently with increasing data
volumes. We hope our work will inspire future works. The code and model are
available at: https://github.com/hanhuang22/AITQE.",2024-10-21,"Han Huang, Yuqi Huo, Zijia Zhao, Haoyu Lu, Shu Wu, Bingning Wang, Qiang Liu, Weipeng Chen, Liang Wang",http://arxiv.org/pdf/2410.16166v1,cs.CL
From Tokens to Materials: Leveraging Language Models for Scientific Discovery,"Exploring the predictive capabilities of language models in material science
is an ongoing interest. This study investigates the application of language
model embeddings to enhance material property prediction in materials science.
By evaluating various contextual embedding methods and pre-trained models,
including Bidirectional Encoder Representations from Transformers (BERT) and
Generative Pre-trained Transformers (GPT), we demonstrate that domain-specific
models, particularly MatBERT significantly outperform general-purpose models in
extracting implicit knowledge from compound names and material properties. Our
findings reveal that information-dense embeddings from the third layer of
MatBERT, combined with a context-averaging approach, offer the most effective
method for capturing material-property relationships from the scientific
literature. We also identify a crucial ""tokenizer effect,"" highlighting the
importance of specialized text processing techniques that preserve complete
compound names while maintaining consistent token counts. These insights
underscore the value of domain-specific training and tokenization in materials
science applications and offer a promising pathway for accelerating the
discovery and development of new materials through AI-driven approaches.",2024-10-21,"Yuwei Wan, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, Bram Hoex",http://arxiv.org/pdf/2410.16165v2,cs.CL
GenAI Assisting Medical Training,"Medical procedures such as venipuncture and cannulation are essential for
nurses and require precise skills. Learning this skill, in turn, is a challenge
for educators due to the number of teachers per class and the complexity of the
task. The study aims to help students with skill acquisition and alleviate the
educator's workload by integrating generative AI methods to provide real-time
feedback on medical procedures such as venipuncture and cannulation.",2024-10-21,"Stefan Fritsch, Matthias Tschoepe, Vitor Fortes Rey, Lars Krupp, Agnes Gruenerbl, Eloise Monger, Sarah Travenna",http://arxiv.org/pdf/2410.16164v1,cs.CL
Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Spatial Reasoning,"Vision language models (VLMs) have demonstrated impressive performance across
a wide range of downstream tasks. However, their proficiency in spatial
reasoning remains limited, despite its crucial role in tasks involving
navigation and interaction with physical environments. Specifically, most of
these tasks rely on the core spatial reasoning capabilities in two-dimensional
(2D) environments, and our evaluation reveals that state-of-the-art VLMs
frequently generate implausible and incorrect responses to composite spatial
reasoning problems, including simple pathfinding tasks that humans can solve
effortlessly at a glance. To address this, we explore an effective approach to
enhance 2D spatial reasoning within VLMs by training the model solely on basic
spatial capabilities. We begin by disentangling the key components of 2D
spatial reasoning: direction comprehension, distance estimation, and
localization. Our central hypothesis is that mastering these basic spatial
capabilities can significantly enhance a model's performance on composite
spatial tasks requiring advanced spatial understanding and combinatorial
problem-solving, with generalized improvements in real-world visual-spatial
tasks. To investigate this hypothesis, we introduce Sparkle: a framework that
uses synthetic data generation to provide targeted supervision for vision
language models (VLMs) in three basic spatial capabilities, creating an
instruction dataset for each capability. Our experiments demonstrate that VLMs
fine-tuned with Sparkle achieve significant performance gains, not only in the
basic tasks themselves but also in generalizing to composite and
out-of-distribution real-world spatial reasoning tasks. These findings offer
insights into systematic strategies for improving VLMs' spatial reasoning
capabilities.",2024-10-21,"Yihong Tang, Ao Qu, Zhaokai Wang, Dingyi Zhuang, Zhaofeng Wu, Wei Ma, Shenhao Wang, Yunhan Zheng, Zhan Zhao, Jinhua Zhao",http://arxiv.org/pdf/2410.16162v3,cs.CL
Limpeh ga li gong: Challenges in Singlish Annotations,"Singlish, or Colloquial Singapore English, is a language formed from oral and
social communication within multicultural Singapore. In this work, we work on a
fundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)
tagging of Singlish sentences. For our analysis, we build a parallel Singlish
dataset containing direct English translations and POS tags, with translation
and POS annotation done by native Singlish speakers. Our experiments show that
automatic transition- and transformer- based taggers perform with only $\sim
80\%$ accuracy when evaluated against human-annotated POS labels, suggesting
that there is indeed room for improvement on computation analysis of the
language. We provide an exposition of challenges in Singlish annotation: its
inconsistencies in form and semantics, the highly context-dependent particles
of the language, its structural unique expressions, and the variation of the
language on different mediums. Our task definition, resultant labels and
results reflects the challenges in analysing colloquial languages formulated
from a variety of dialects, and paves the way for future studies beyond POS
tagging.",2024-10-21,"Luo Qi Chan, Lynnette Hui Xian Ng",http://arxiv.org/pdf/2410.16156v2,cs.CL
A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns,"With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.",2024-10-21,"Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2410.16155v1,cs.CL
Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages,"Despite recent advances in multimodal large language models (MLLMs), their
development has predominantly focused on English- and western-centric datasets
and tasks, leaving most of the world's languages and diverse cultural contexts
underrepresented. This paper introduces Pangea, a multilingual multimodal LLM
trained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.
PangeaIns features: 1) high-quality English instructions, 2) carefully
machine-translated instructions, and 3) culturally relevant multimodal tasks to
ensure cross-cultural coverage. To rigorously assess models' capabilities, we
introduce PangeaBench, a holistic evaluation suite encompassing 14 datasets
covering 47 languages. Results show that Pangea significantly outperforms
existing open-source models in multilingual settings and diverse cultural
contexts. Ablation studies further reveal the importance of English data
proportions, language popularity, and the number of multimodal training samples
on overall performance. We fully open-source our data, code, and trained
checkpoints, to facilitate the development of inclusive and robust multilingual
MLLMs, promoting equity and accessibility across a broader linguistic and
cultural spectrum.",2024-10-21,"Xiang Yue, Yueqi Song, Akari Asai, Seungone Kim, Jean de Dieu Nyandwi, Simran Khanuja, Anjali Kantharuban, Lintang Sutawika, Sathyanarayanan Ramamoorthy, Graham Neubig",http://arxiv.org/pdf/2410.16153v3,cs.CL
"1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs","Recent advances in 1-bit Large Language Models (LLMs), such as BitNet and
BitNet b1.58, present a promising approach to enhancing the efficiency of LLMs
in terms of speed and energy consumption. These developments also enable local
LLM deployment across a broad range of devices. In this work, we introduce
bitnet.cpp, a tailored software stack designed to unlock the full potential of
1-bit LLMs. Specifically, we develop a set of kernels to support fast and
lossless inference of ternary BitNet b1.58 LLMs on CPUs. Extensive experiments
demonstrate that bitnet.cpp achieves significant speedups, ranging from 2.37x
to 6.17x on x86 CPUs and from 1.37x to 5.07x on ARM CPUs, across various model
sizes. The code is available at https://github.com/microsoft/BitNet.",2024-10-21,"Jinheng Wang, Hansong Zhou, Ting Song, Shaoguang Mao, Shuming Ma, Hongyu Wang, Yan Xia, Furu Wei",http://arxiv.org/pdf/2410.16144v2,cs.CL
A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles,"We present a systematic evaluation of large language models' sensitivity to
argument roles, i.e., who did what to whom, by replicating psycholinguistic
studies on human argument role processing. In three experiments, we find that
language models are able to distinguish verbs that appear in plausible and
implausible contexts, where plausibility is determined through the relation
between the verb and its preceding arguments. However, none of the models
capture the same selective patterns that human comprehenders exhibit during
real-time verb prediction. This indicates that language models' capacity to
detect verb plausibility does not arise from the same mechanism that underlies
human real-time sentence processing.",2024-10-21,"Eun-Kyoung Rosa Lee, Sathvik Nair, Naomi Feldman",http://arxiv.org/pdf/2410.16139v1,cs.CL
Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning,"Recent advancements in large audio-language models (LALMs) have shown
impressive capabilities in understanding and reasoning about audio and speech
information. However, these models still face challenges, including
hallucinating non-existent sound events, misidentifying the order of sound
events, and incorrectly attributing sound sources, which undermine their
reliability and real-world application. To systematically evaluate these
issues, we propose three distinct tasks: object existence, temporal order, and
object attribute within audio. These tasks assess the models' comprehension of
critical audio information aspects. Our experimental results reveal limitations
in these fundamental tasks, underscoring the need for better models in
recognizing specific sound events, determining event sequences, and identifying
sound sources. To improve performance in these areas, we introduce a multi-turn
chain-of-thought approach, which demonstrates significantly improved model
performance across the proposed tasks.",2024-10-21,"Chun-Yi Kuan, Hung-yi Lee",http://arxiv.org/pdf/2410.16130v2,cs.CL
Do LLMs write like humans? Variation in grammatical and rhetorical styles,"Large language models (LLMs) are capable of writing grammatical text that
follows instructions, answers questions, and solves problems. As they have
advanced, it has become difficult to distinguish their output from
human-written text. While past research has found some differences in surface
features such as word choice and punctuation, and developed classifiers to
detect LLM output, none has studied the rhetorical styles of LLMs.
  Using several variants of Llama 3 and GPT-4o, we construct two parallel
corpora of human- and LLM-written texts from common prompts. Using Douglas
Biber's set of lexical, grammatical, and rhetorical features, we identify
systematic differences between LLMs and humans and between different LLMs.
These differences persist when moving from smaller models to larger ones, and
are larger for instruction-tuned models than base models. This demonstrates
that despite their advanced abilities, LLMs struggle to match human styles, and
hence more advanced linguistic features can detect patterns in their behavior
not previously recognized.",2024-10-21,"Alex Reinhart, David West Brown, Ben Markey, Michael Laudenbach, Kachatad Pantusen, Ronald Yurko, Gordon Weinberg",http://arxiv.org/pdf/2410.16107v1,cs.CL
Analysing the Residual Stream of Language Models Under Knowledge Conflicts,"Large language models (LLMs) can store a significant amount of factual
knowledge in their parameters. However, their parametric knowledge may conflict
with the information provided in the context. Such conflicts can lead to
undesirable model behaviour, such as reliance on outdated or incorrect
information. In this work, we investigate whether LLMs can identify knowledge
conflicts and whether it is possible to know which source of knowledge the
model will rely on by analysing the residual stream of the LLM. Through probing
tasks, we find that LLMs can internally register the signal of knowledge
conflict in the residual stream, which can be accurately detected by probing
the intermediate model activations. This allows us to detect conflicts within
the residual stream before generating the answers without modifying the input
or model parameters. Moreover, we find that the residual stream shows
significantly different patterns when the model relies on contextual knowledge
versus parametric knowledge to resolve conflicts. This pattern can be employed
to estimate the behaviour of LLMs when conflict happens and prevent unexpected
answers before producing the answers. Our analysis offers insights into how
LLMs internally manage knowledge conflicts and provides a foundation for
developing methods to control the knowledge selection processes.",2024-10-21,"Yu Zhao, Xiaotang Du, Giwon Hong, Aryo Pradipta Gema, Alessio Devoto, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini",http://arxiv.org/pdf/2410.16090v2,cs.CL
Fine-Tuning LLMs for Reliable Medical Question-Answering Services,"We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.",2024-10-21,"Ali Anaissi, Ali Braytee, Junaid Akram",http://arxiv.org/pdf/2410.16088v1,cs.CL
CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts,"Large language models (LLM) have been attracting much attention from the
community recently, due to their remarkable performance in all kinds of
downstream tasks. According to the well-known scaling law, scaling up a dense
LLM enhances its capabilities, but also significantly increases the
computational complexity. Mixture-of-Experts (MoE) models address that by
allowing the model size to grow without substantially raising training or
inference costs. Yet MoE models face challenges regarding knowledge sharing
among experts, making their performance somehow sensitive to routing accuracy.
To tackle that, previous works introduced shared experts and combined their
outputs with those of the top $K$ routed experts in an ``addition'' manner. In
this paper, inspired by collective matrix factorization to learn shared
knowledge among data, we propose CartesianMoE, which implements more effective
knowledge sharing among experts in more like a ``multiplication'' manner.
Extensive experimental results indicate that CartesianMoE outperforms previous
MoE models for building LLMs, in terms of both perplexity and downstream task
performance. And we also find that CartesianMoE achieves better expert routing
robustness.",2024-10-21,"Zhenpeng Su, Xing Wu, Zijia Lin, Yizhe Xiong, Minxuan Lv, Guangyuan Ma, Hui Chen, Songlin Hu, Guiguang Ding",http://arxiv.org/pdf/2410.16077v3,cs.CL
On-Device LLMs for SMEs: Challenges and Opportunities,"This paper presents a systematic review of the infrastructure requirements
for deploying Large Language Models (LLMs) on-device within the context of
small and medium-sized enterprises (SMEs), focusing on both hardware and
software perspectives. From the hardware viewpoint, we discuss the utilization
of processing units like GPUs and TPUs, efficient memory and storage solutions,
and strategies for effective deployment, addressing the challenges of limited
computational resources typical in SME settings. From the software perspective,
we explore framework compatibility, operating system optimization, and the use
of specialized libraries tailored for resource-constrained environments. The
review is structured to first identify the unique challenges faced by SMEs in
deploying LLMs on-device, followed by an exploration of the opportunities that
both hardware innovations and software adaptations offer to overcome these
obstacles. Such a structured review provides practical insights, contributing
significantly to the community by enhancing the technological resilience of
SMEs in integrating LLMs.",2024-10-21,"Jeremy Stephen Gabriel Yee, Pai Chet Ng, Zhengkui Wang, Ian McLoughlin, Aik Beng Ng, Simon See",http://arxiv.org/pdf/2410.16070v2,cs.CL
Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context,"Human processing of idioms relies on understanding the contextual sentences
in which idioms occur, as well as language-intrinsic features such as frequency
and speaker-intrinsic factors like familiarity. While LLMs have shown high
performance on idiomaticity detection tasks, this success may be attributed to
reasoning shortcuts in existing datasets. To this end, we construct a novel,
controlled contrastive dataset designed to test whether LLMs can effectively
use context to disambiguate idiomatic meaning. Additionally, we explore how
collocational frequency and sentence probability influence model performance.
Our findings reveal that LLMs often fail to resolve idiomaticity when it is
required to attend to the surrounding context, and that models perform better
on sentences that have higher likelihood. The collocational frequency of
expressions also impacts performance. We make our code and dataset publicly
available.",2024-10-21,"Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi",http://arxiv.org/pdf/2410.16069v1,cs.CL
Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse,"The Uniform Information Density (UID) hypothesis posits that speakers tend to
distribute information evenly across linguistic units to achieve efficient
communication. Of course, information rate in texts and discourses is not
perfectly uniform. While these fluctuations can be viewed as theoretically
uninteresting noise on top of a uniform target, another explanation is that UID
is not the only functional pressure regulating information content in a
language. Speakers may also seek to maintain interest, adhere to writing
conventions, and build compelling arguments. In this paper, we propose one such
functional pressure; namely that speakers modulate information rate based on
location within a hierarchically-structured model of discourse. We term this
the Structured Context Hypothesis and test it by predicting the surprisal
contours of naturally occurring discourses extracted from large language models
using predictors derived from discourse structure. We find that hierarchical
predictors are significant predictors of a discourse's information contour and
that deeply nested hierarchical predictors are more predictive than shallow
ones. This work takes an initial step beyond UID to propose testable hypotheses
for why the information rate fluctuates in predictable ways",2024-10-21,"Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, Ethan Wilcox, Mario Giulianelli, Alex Warstadt",http://arxiv.org/pdf/2410.16062v1,cs.CL
Large Language Models Know What To Say But Not When To Speak,"Turn-taking is a fundamental mechanism in human communication that ensures
smooth and coherent verbal interactions. Recent advances in Large Language
Models (LLMs) have motivated their use in improving the turn-taking
capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond
at appropriate times. However, existing models often struggle to predict
opportunities for speaking -- called Transition Relevance Places (TRPs) -- in
natural, unscripted conversations, focusing only on turn-final TRPs and not
within-turn TRPs. To address these limitations, we introduce a novel dataset of
participant-labeled within-turn TRPs and use it to evaluate the performance of
state-of-the-art LLMs in predicting opportunities for speaking. Our experiments
reveal the current limitations of LLMs in modeling unscripted spoken
interactions, highlighting areas for improvement and paving the way for more
naturalistic dialogue systems.",2024-10-21,"Muhammad Umair, Vasanth Sarathy, JP de Ruiter",http://arxiv.org/pdf/2410.16044v1,cs.CL
ComPO: Community Preferences for Language Model Personalization,"Conventional algorithms for training language models (LMs) with human
feedback rely on preferences that are assumed to account for an ""average"" user,
disregarding subjectivity and finer-grained variations. Recent studies have
raised concerns that aggregating such diverse and often contradictory human
feedback to finetune models results in generic models that generate outputs not
preferred by many user groups, as they tend to average out styles and norms. To
address this issue, we draw inspiration from recommendation systems and propose
ComPO, a method to personalize preference optimization in LMs by
contextualizing the probability distribution of model outputs with the
preference provider. Focusing on group-level preferences rather than
individuals, we collect and release ComPRed, a question answering dataset with
community-level preferences from Reddit. This dataset facilitates studying
diversity in preferences without incurring privacy concerns associated with
individual feedback. Our experiments reveal that conditioning language models
on a community identifier (i.e., subreddit name) during preference tuning
substantially enhances model performance. Conversely, replacing this context
with random subreddit identifiers significantly diminishes performance,
highlighting the effectiveness of our approach in tailoring responses to
communities' preferences.",2024-10-21,"Sachin Kumar, Chan Young Park, Yulia Tsvetkov, Noah A. Smith, Hannaneh Hajishirzi",http://arxiv.org/pdf/2410.16027v1,cs.CL
CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation,"Simultaneous speech translation (SimulST) systems must balance translation
quality with response time, making latency measurement crucial for evaluating
their real-world performance. However, there has been a longstanding belief
that current metrics yield unrealistically high latency measurements in
unsegmented streaming settings. In this paper, we investigate this phenomenon,
revealing its root cause in a fundamental misconception underlying existing
latency evaluation approaches. We demonstrate that this issue affects not only
streaming but also segment-level latency evaluation across different metrics.
Furthermore, we propose a modification to correctly measure computation-aware
latency for SimulST systems, addressing the limitations present in existing
metrics.",2024-10-21,"Xi Xu, Wenda Xu, Siqi Ouyang, Lei Li",http://arxiv.org/pdf/2410.16011v1,cs.CL
Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model,"A common challenge towards the adaptability of Large Language Models (LLMs)
is their ability to learn new languages over time without hampering the model's
performance on languages in which the model is already proficient (usually
English). Continual fine-tuning (CFT) is the process of sequentially
fine-tuning an LLM to enable the model to adapt to downstream tasks with
varying data distributions and time shifts. This paper focuses on the language
adaptability of LLMs through CFT. We study a two-phase CFT process in which an
English-only end-to-end fine-tuned LLM from Phase 1 (predominantly Task
Ability) is sequentially fine-tuned on a multilingual dataset -- comprising
task data in new languages -- in Phase 2 (predominantly Language Ability). We
observe that the ``similarity'' of Phase 2 tasks with Phase 1 determines the
LLM's adaptability. For similar phase-wise datasets, the LLM after Phase 2 does
not show deterioration in task ability. In contrast, when the phase-wise
datasets are not similar, the LLM's task ability deteriorates. We test our
hypothesis on the open-source \mis\ and \llm\ models with multiple phase-wise
dataset pairs. To address the deterioration, we analyze tailored variants of
two CFT methods: layer freezing and generative replay. Our findings demonstrate
their effectiveness in enhancing the language ability of LLMs while preserving
task performance, in comparison to relevant baselines.",2024-10-21,"Divyanshu Aggarwal, Sankarshan Damle, Navin Goyal, Satya Lokam, Sunayana Sitaram",http://arxiv.org/pdf/2410.16006v1,cs.CL
Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering,"Large language models (LLMs) can store a significant amount of factual
knowledge in their parameters. However, their parametric knowledge may conflict
with the information provided in the context -- this phenomenon, known as
\emph{context-memory knowledge conflicts}, can lead to undesirable model
behaviour, such as reliance on outdated or incorrect information. Analysing the
internal activations of LLMs, we find that they can internally register the
signals of knowledge conflict at mid-layers. Such signals allow us to detect
whether a knowledge conflict occurs and use \emph{inference-time} intervention
strategies to resolve it. In this work, we propose \textsc{SpARE}, a
\emph{training-free} representation engineering method that uses pre-trained
sparse auto-encoders (SAEs) to control the knowledge selection behaviour of
LLMs. \textsc{SpARE} identifies the functional features that control the
knowledge selection behaviours and applies them to edit the internal
activations of LLMs at inference time. Our experimental results show that
\textsc{SpARE} can effectively control the usage of either knowledge source to
resolve knowledge conflict in open-domain question-answering tasks, surpassing
existing representation engineering methods ($+10\%$) as well as contrastive
decoding methods ($+15\%$).",2024-10-21,"Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini",http://arxiv.org/pdf/2410.15999v3,cs.CL
"1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification","Social media is a great source of data for users reporting information and
regarding their health and how various things have had an effect on them. This
paper presents various approaches using Transformers and Large Language Models
and their ensembles, their performance along with advantages and drawbacks for
various tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor
spaces on the author's mental health (Task 3), Binary classification of tweets
reporting their children's health disorders like Asthma, Autism, ADHD and
Speech disorder (task 5), Binary classification of users self-reporting their
age (task 6).",2024-10-21,"Ram Mohan Rao Kadiyala, M. V. P. Chandra Sekhara Rao",http://arxiv.org/pdf/2410.15998v1,cs.CL
Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence,"This paper presents our system description and error analysis of our entry
for NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)
\citep{hagag2024legallenssharedtask2024}. The task required classifying these
relationships as entailed, contradicted, or neutral, indicating any association
between the review and the complaint. Our system emerged as the winning
submission, significantly outperforming other entries with a substantial margin
and demonstrating the effectiveness of our approach in legal text analysis. We
provide a detailed analysis of the strengths and limitations of each model and
approach tested, along with a thorough error analysis and suggestions for
future improvements. This paper aims to contribute to the growing field of
legal NLP by offering insights into advanced techniques for natural language
inference in legal contexts, making it accessible to both experts and newcomers
in the field.",2024-10-21,"Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Subhasya Tippareddy, Ashay Srivastava",http://arxiv.org/pdf/2410.15990v1,cs.CL
Large Language Models for Cross-lingual Emotion Detection,"This paper presents a detailed system description of our entry for the WASSA
2024 Task 2, focused on cross-lingual emotion detection. We utilized a
combination of large language models (LLMs) and their ensembles to effectively
understand and categorize emotions across different languages. Our approach not
only outperformed other submissions with a large margin, but also demonstrated
the strength of integrating multiple models to enhance performance.
Additionally, We conducted a thorough comparison of the benefits and
limitations of each model used. An error analysis is included along with
suggested areas for future improvement. This paper aims to offer a clear and
comprehensive understanding of advanced techniques in emotion detection, making
it accessible even to those new to the field.",2024-10-21,Ram Mohan Rao Kadiyala,http://arxiv.org/pdf/2410.15974v1,cs.CL
Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue,"Document-grounded dialogue (DGD) uses documents as external knowledge for
dialogue generation. Correctly understanding the dialogue context is crucial
for selecting knowledge from the document and generating proper responses. In
this paper, we propose using a dialogue policy to help the dialogue
understanding in DGD. Our dialogue policy consists of two kinds of guiding
signals: utterance function and topic transfer intent. The utterance function
reflects the purpose and style of an utterance, and the topic transfer intent
reflects the topic and content of an utterance. We propose a novel framework
exploiting our dialogue policy for two core tasks in DGD, namely knowledge
selection (KS) and response generation (RG). The framework consists of two
modules: the Policy planner leverages policy-aware dialogue representation to
select knowledge and predict the policy of the response; the generator uses
policy/knowledge-aware dialogue representation for response generation. Our
policy-driven model gets state-of-the-art performance on three public
benchmarks and we provide a detailed analysis of the experimental results. Our
code/data will be released on GitHub.",2024-10-21,"Longxuan Ma, Jiapeng Li, Mingda Li, Wei-Nan Zhang, Ting Liu",http://arxiv.org/pdf/2410.15970v1,cs.CL
Self-Explained Keywords Empower Large Language Models for Code Generation,"Large language models (LLMs) have achieved impressive performance in code
generation. However, due to the long-tail distribution of LLMs' training data,
low-frequency terms are typically underrepresented in the training process.
Consequently, LLMs often misunderstand or overlook problem-specific,
low-frequency keywords during code generation, compromising the accuracy of the
generated code. To address this, we propose a novel technique named
SEK(\textbf{S}elf-\textbf{E}xplained \textbf{K}eywords), which empowers an LLM
for better code generation by extracting and explaining the key terms in the
problem description with the LLM itself and ranking them based on frequency.
Comprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),
and APPS, with five representative LLMs, show that SEK can significantly
improve LLMs in code generation, yielding substantial and consistent gains. For
instance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\% to
93.3\% on the Humaneval benchmark. Further analysis confirms that SEK enables
the LLMs to shift their attention from low-frequency keywords to their
corresponding high-frequency counterparts.",2024-10-21,"Lishui Fan, Mouxiang Chen, Zhongxin Liu",http://arxiv.org/pdf/2410.15966v1,cs.CL
"Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization","Reproducibility in scientific research, particularly within the realm of
natural language processing (NLP), is essential for validating and verifying
the robustness of experimental findings. This paper delves into the
reproduction and evaluation of dialogue summarization models, focusing
specifically on the discrepancies observed between original studies and our
reproduction efforts. Dialogue summarization is a critical aspect of NLP,
aiming to condense conversational content into concise and informative
summaries, thus aiding in efficient information retrieval and decision-making
processes. Our research involved a thorough examination of several dialogue
summarization models using the AMI (Augmented Multi-party Interaction) dataset.
The models assessed include Hierarchical Memory Networks (HMNet) and various
versions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),
PGN(DTS), and PGN(DALL). The primary objective was to evaluate the
informativeness and quality of the summaries generated by these models through
human assessment, a method that introduces subjectivity and variability in the
evaluation process. The analysis began with Dataset 1, where the sample
standard deviation of 0.656 indicated a moderate dispersion of data points
around the mean.",2024-10-21,"Yugandhar Reddy Gogireddy, Jithendra Reddy Gogireddy",http://arxiv.org/pdf/2410.15962v1,cs.CL
Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs,"Current Large Language Models (LLMs) are predominantly designed with English
as the primary language, and even the few that are multilingual tend to exhibit
strong English-centric biases. Much like speakers who might produce awkward
expressions when learning a second language, LLMs often generate unnatural
outputs in non-English languages, reflecting English-centric patterns in both
vocabulary and grammar. Despite the importance of this issue, the naturalness
of multilingual LLM outputs has received limited attention. In this paper, we
address this gap by introducing novel automatic corpus-level metrics to assess
the lexical and syntactic naturalness of LLM outputs in a multilingual context.
Using our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark
in French and Chinese, revealing a tendency towards English-influenced
patterns. To mitigate this issue, we also propose a simple and effective
alignment method to improve the naturalness of an LLM in a target language and
domain, achieving consistent improvements in naturalness without compromising
the performance on general-purpose benchmarks. Our work highlights the
importance of developing multilingual metrics, resources and methods for the
new wave of multilingual LLMs.",2024-10-21,"Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao",http://arxiv.org/pdf/2410.15956v2,cs.CL
Findings of the Third Shared Task on Multilingual Coreference Resolution,"The paper presents an overview of the third edition of the shared task on
multilingual coreference resolution, held as part of the CRAC 2024 workshop.
Similarly to the previous two editions, the participants were challenged to
develop systems capable of identifying mentions and clustering them based on
identity coreference.
  This year's edition took another step towards real-world application by not
providing participants with gold slots for zero anaphora, increasing the task's
complexity and realism. In addition, the shared task was expanded to include a
more diverse set of languages, with a particular focus on historical languages.
The training and evaluation data were drawn from version 1.2 of the
multilingual collection of harmonized coreference resources CorefUD,
encompassing 21 datasets across 15 languages. 6 systems competed in this shared
task.",2024-10-21,"Michal Novák, Barbora Dohnalová, Miloslav Konopík, Anna Nedoluzhko, Martin Popel, Ondřej Pražák, Jakub Sido, Milan Straka, Zdeněk Žabokrtský, Daniel Zeman",http://arxiv.org/pdf/2410.15949v2,cs.CL
CausalGraph2LLM: Evaluating LLMs for Causal Queries,"Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we introduce CausalGraph2LLM, a comprehensive benchmark comprising over
700k queries across diverse causal graph settings to evaluate the causal
reasoning capabilities of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
propriety models for our study. Our findings reveal that while LLMs show
promise in this domain, they are highly sensitive to the encoding used. Even
capable models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.",2024-10-21,"Ivaxi Sheth, Bahare Fatemi, Mario Fritz",http://arxiv.org/pdf/2410.15939v2,cs.CL
"Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection","In human conversations, short backchannel utterances such as ""yeah"" and ""oh""
play a crucial role in facilitating smooth and engaging dialogue. These
backchannels signal attentiveness and understanding without interrupting the
speaker, making their accurate prediction essential for creating more natural
conversational agents. This paper proposes a novel method for real-time,
continuous backchannel prediction using a fine-tuned Voice Activity Projection
(VAP) model. While existing approaches have relied on turn-based or
artificially balanced datasets, our approach predicts both the timing and type
of backchannels in a continuous and frame-wise manner on unbalanced, real-world
datasets. We first pre-train the VAP model on a general dialogue corpus to
capture conversational dynamics and then fine-tune it on a specialized dataset
focused on backchannel behavior. Experimental results demonstrate that our
model outperforms baseline methods in both timing and type prediction tasks,
achieving robust performance in real-time environments. This research offers a
promising step toward more responsive and human-like dialogue systems, with
implications for interactive spoken dialogue applications such as virtual
assistants and robots.",2024-10-21,"Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawahara",http://arxiv.org/pdf/2410.15929v2,cs.CL
Mitigating Object Hallucination via Concentric Causal Attention,"Recent Large Vision Language Models (LVLMs) present remarkable zero-shot
conversational and reasoning capabilities given multimodal queries.
Nevertheless, they suffer from object hallucination, a phenomenon where LVLMs
are prone to generate textual responses not factually aligned with image
inputs. Our pilot study reveals that object hallucination is closely tied with
Rotary Position Encoding (RoPE), a widely adopted positional dependency
modeling design in existing LVLMs. Due to the long-term decay in RoPE, LVLMs
tend to hallucinate more when relevant visual cues are distant from instruction
tokens in the multimodal input sequence. Additionally, we observe a similar
effect when reversing the sequential order of visual tokens during multimodal
alignment. Our tests indicate that long-term decay in RoPE poses challenges to
LVLMs while capturing visual-instruction interactions across long distances. We
propose Concentric Causal Attention (CCA), a simple yet effective positional
alignment strategy that mitigates the impact of RoPE long-term decay in LVLMs
by naturally reducing relative distance between visual and instruction tokens.
With CCA, visual tokens can better interact with instruction tokens, thereby
enhancing model's perception capability and alleviating object hallucination.
Without bells and whistles, our positional alignment method surpasses existing
hallucination mitigation strategies by large margins on multiple object
hallucination benchmarks.",2024-10-21,"Yun Xing, Yiheng Li, Ivan Laptev, Shijian Lu",http://arxiv.org/pdf/2410.15926v1,cs.CL
DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?,"When building a predictive model, it is often difficult to ensure that
application-specific requirements are encoded by the model that will eventually
be deployed. Consider researchers working on hate speech detection. They will
have an idea of what is considered hate speech, but building a model that
reflects their view accurately requires preserving those ideals throughout the
workflow of data set construction and model training. Complications such as
sampling bias, annotation bias, and model misspecification almost always arise,
possibly resulting in a gap between the application specification and the
model's actual behavior upon deployment. To address this issue for hate speech
detection, we propose DefVerify: a 3-step procedure that (i) encodes a
user-specified definition of hate speech, (ii) quantifies to what extent the
model reflects the intended definition, and (iii) tries to identify the point
of failure in the workflow. We use DefVerify to find gaps between definition
and model behavior when applied to six popular hate speech benchmark datasets.",2024-10-21,"Urja Khurana, Eric Nalisnick, Antske Fokkens",http://arxiv.org/pdf/2410.15911v2,cs.CL
Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process,"The paper considers an approach of using Google Search API and GPT-4o model
for qualitative and quantitative analyses of news through retrieval-augmented
generation (RAG). This approach was applied to analyze news about the 2024 US
presidential election process. Different news sources for different time
periods have been analyzed. Quantitative scores generated by GPT model have
been analyzed using Bayesian regression to derive trend lines. The
distributions found for the regression parameters allow for the analysis of
uncertainty in the election process. The obtained results demonstrate that
using the GPT models for news analysis, one can get informative analytics and
provide key insights that can be applied in further analyses of election
processes.",2024-10-21,Bohdan M. Pavlyshenko,http://arxiv.org/pdf/2410.15884v1,cs.CL
Principles of semantic and functional efficiency in grammatical patterning,"Grammatical features such as number and gender serve two central functions in
human languages. While they encode salient semantic attributes like numerosity
and animacy, they also offload sentence processing cost by predictably linking
words together via grammatical agreement. Grammars exhibit consistent
organizational patterns across diverse languages, invariably rooted in a
semantic foundation, a widely confirmed but still theoretically unexplained
phenomenon. To explain the basis of universal grammatical patterns, we unify
two fundamental properties of grammar, semantic encoding and agreement-based
predictability, into a single information-theoretic objective under cognitive
constraints. Our analyses reveal that grammatical organization provably
inherits from perceptual attributes, but that grammars empirically prioritize
functional goals, promoting efficient language processing over semantic
encoding.",2024-10-21,"Emily Cheng, Francesca Franzon",http://arxiv.org/pdf/2410.15865v1,cs.CL
"Did somebody say ""Gest-IT""? A pilot exploration of multimodal data management","The paper presents a pilot exploration of the construction, management and
analysis of a multimodal corpus. Through a three-layer annotation that provides
orthographic, prosodic, and gestural transcriptions, the Gest-IT resource
allows to investigate the variation of gesture-making patterns in conversations
between sighted people and people with visual impairment. After discussing the
transcription methods and technical procedures employed in our study, we
propose a unified CoNLL-U corpus and indicate our future steps",2024-10-21,"Ludovica Pannitto, Lorenzo Albanesi, Laura Marion, Federica Maria Martines, Carmelo Caruso, Claudia S. Bianchini, Francesca Masini, Caterina Mauri",http://arxiv.org/pdf/2410.15825v1,cs.CL
Improve Dense Passage Retrieval with Entailment Tuning,"Retrieval module can be plugged into many downstream NLP tasks to improve
their performance, such as open-domain question answering and
retrieval-augmented generation. The key to a retrieval system is to calculate
relevance scores to query and passage pairs. However, the definition of
relevance is often ambiguous. We observed that a major class of relevance
aligns with the concept of entailment in NLI tasks. Based on this observation,
we designed a method called entailment tuning to improve the embedding of dense
retrievers. Specifically, we unify the form of retrieval data and NLI data
using existence claim as a bridge. Then, we train retrievers to predict the
claims entailed in a passage with a variant task of masked prediction. Our
method can be efficiently plugged into current dense retrieval methods, and
experiments show the effectiveness of our method.",2024-10-21,"Lu Dai, Hao Liu, Hui Xiong",http://arxiv.org/pdf/2410.15801v1,cs.CL
Optimal Query Allocation in Extractive QA with LLMs: A Learning-to-Defer Framework with Theoretical Guarantees,"Large Language Models excel in generative tasks but exhibit inefficiencies in
structured text selection, particularly in extractive question answering. This
challenge is magnified in resource-constrained environments, where deploying
multiple specialized models for different tasks is impractical. We propose a
Learning-to-Defer framework that allocates queries to specialized experts,
ensuring high-confidence predictions while optimizing computational efficiency.
Our approach integrates a principled allocation strategy with theoretical
guarantees on optimal deferral that balances performance and cost. Empirical
evaluations on SQuADv1, SQuADv2, and TriviaQA demonstrate that our method
enhances answer reliability while significantly reducing computational
overhead, making it well-suited for scalable and efficient EQA deployment.",2024-10-21,"Yannis Montreuil, Shu Heng Yeo, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi",http://arxiv.org/pdf/2410.15761v3,cs.CL
Natural Language Querying System Through Entity Enrichment,"This paper focuses on a domain expert querying system over databases. It
presents a solution designed for a French enterprise interested in offering a
natural language interface for its clients. The approach, based on entity
enrichment, aims at translating natural language queries into database queries.
In this paper, the database is treated through a logical paradigm, suggesting
the adaptability of our approach to different database models. The good
precision of our method is shown through some preliminary experiments.",2024-10-21,"Joshua Amavi, Mirian Halfeld Ferrari, Nicolas Hiot",http://arxiv.org/pdf/2410.15753v1,cs.CL
Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter,"Political discourse on Twitter is a moving target: politicians continuously
make statements about their positions. It is therefore crucial to track their
discourse on social media to understand their ideological positions and goals.
However, Twitter data is also challenging to work with since it is ambiguous
and often dependent on social context, and consequently, recent work on
political positioning has tended to focus strongly on manifestos (parties'
electoral programs) rather than social media.
  In this paper, we extend recently proposed methods to predict pairwise
positional similarities between parties from the manifesto case to the Twitter
case, using hashtags as a signal to fine-tune text representations, without the
need for manual annotation. We verify the efficacy of fine-tuning and conduct a
series of experiments that assess the robustness of our method for low-resource
scenarios. We find that our method yields stable positioning reflective of
manifesto positioning, both in scenarios with all tweets of candidates across
years available and when only smaller subsets from shorter time periods are
available. This indicates that it is possible to reliably analyze the relative
positioning of actors forgoing manual annotation, even in the noisier context
of social media.",2024-10-21,"Maximilian Maurer, Tanise Ceron, Sebastian Padó, Gabriella Lapesa",http://arxiv.org/pdf/2410.15743v1,cs.CL
Who's Who: Large Language Models Meet Knowledge Conflicts in Practice,"Retrieval-augmented generation (RAG) methods are viable solutions for
addressing the static memory limits of pre-trained language models.
Nevertheless, encountering conflicting sources of information within the
retrieval context is an inevitable practical challenge. In such situations, the
language models are recommended to transparently inform users about the
conflicts rather than autonomously deciding what to present based on their
inherent biases. To analyze how current large language models (LLMs) align with
our recommendation, we introduce WhoQA, a public benchmark dataset to examine
model's behavior in knowledge conflict situations. We induce conflicts by
asking about a common property among entities having the same name, resulting
in questions with up to 8 distinctive answers. WhoQA evaluation set includes 5K
questions across 13 Wikidata property types and 150K Wikipedia entities. Our
experiments show that despite the simplicity of WhoQA questions, knowledge
conflicts significantly degrades LLMs' performance in RAG settings.",2024-10-21,"Quang Hieu Pham, Hoang Ngo, Anh Tuan Luu, Dat Quoc Nguyen",http://arxiv.org/pdf/2410.15737v1,cs.CL
Reducing annotator bias by belief elicitation,"Crowdsourced annotations of data play a substantial role in the development
of Artificial Intelligence (AI). It is broadly recognised that annotations of
text data can contain annotator bias, where systematic disagreement in
annotations can be traced back to differences in the annotators' backgrounds.
Being unaware of such annotator bias can lead to representational bias against
minority group perspectives and therefore several methods have been proposed
for recognising bias or preserving perspectives. These methods typically
require either a substantial number of annotators or annotations per data
instance. In this study, we propose a simple method for handling bias in
annotations without requirements on the number of annotators or instances.
Instead, we ask annotators about their beliefs of other annotators' judgements
of an instance, under the hypothesis that these beliefs may provide more
representative and less biased labels than judgements. The method was examined
in two controlled, survey-based experiments involving Democrats and Republicans
(n=1,590) asked to judge statements as arguments and then report beliefs about
others' judgements. The results indicate that bias, defined as systematic
differences between the two groups of annotators, is consistently reduced when
asking for beliefs instead of judgements. Our proposed method therefore has the
potential to reduce the risk of annotator bias, thereby improving the
generalisability of AI systems and preventing harm to unrepresented
socio-demographic groups, and we highlight the need for further studies of this
potential in other tasks and downstream applications.",2024-10-21,"Terne Sasha Thorn Jakobsen, Andreas Bjerre-Nielsen, Robert Böhm",http://arxiv.org/pdf/2410.15726v1,cs.CL
Mitigating Hallucinations of Large Language Models in Medical Information Extraction via Contrastive Decoding,"The impressive capabilities of large language models (LLMs) have attracted
extensive interests of applying LLMs to medical field. However, the complex
nature of clinical environments presents significant hallucination challenges
for LLMs, hindering their widespread adoption. In this paper, we address these
hallucination issues in the context of Medical Information Extraction (MIE)
tasks by introducing ALternate Contrastive Decoding (ALCD). We begin by
redefining MIE tasks as an identify-and-classify process. We then separate the
identification and classification functions of LLMs by selectively masking the
optimization of tokens during fine-tuning. During the inference stage, we
alternately contrast output distributions derived from sub-task models. This
approach aims to selectively enhance the identification and classification
capabilities while minimizing the influence of other inherent abilities in
LLMs. Additionally, we propose an alternate adaptive constraint strategy to
more effectively adjust the scale and scope of contrastive tokens. Through
comprehensive experiments on two different backbones and six diverse medical
information extraction tasks, ALCD demonstrates significant improvements in
resolving hallucination issues compared to conventional decoding methods.",2024-10-21,"Derong Xu, Ziheng Zhang, Zhihong Zhu, Zhenxi Lin, Qidong Liu, Xian Wu, Tong Xu, Xiangyu Zhao, Yefeng Zheng, Enhong Chen",http://arxiv.org/pdf/2410.15702v1,cs.CL
InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems,"Large Language Models (LLMs) have emerged as powerful tools in mathematical
theorem proving, particularly when utilizing formal languages such as LEAN. The
major learning paradigm is expert iteration, which necessitates a pre-defined
dataset comprising numerous mathematical problems. In this process, LLMs
attempt to prove problems within the dataset and iteratively refine their
capabilities through self-training on the proofs they discover. We propose to
use large scale LEAN problem datasets Lean-workbook for expert iteration with
more than 20,000 CPU days. During expert iteration, we found log-linear trends
between solved problem amount with proof length and CPU usage. We train a
critic model to select relatively easy problems for policy models to make
trials and guide the model to search for deeper proofs. InternLM2.5-StepProver
achieves open-source state-of-the-art on MiniF2F, Lean-Workbook-Plus, ProofNet,
and Putnam benchmarks. Specifically, it achieves a pass of 65.9% on the
MiniF2F-test and proves (or disproves) 17.0% of problems in Lean-Workbook-Plus
which shows a significant improvement compared to only 9.5% of problems proved
when Lean-Workbook-Plus was released. We open-source our models and searched
proofs at https://github.com/InternLM/InternLM-Math and
https://huggingface.co/datasets/internlm/Lean-Workbook.",2024-10-21,"Zijian Wu, Suozhi Huang, Zhejian Zhou, Huaiyuan Ying, Jiayu Wang, Dahua Lin, Kai Chen",http://arxiv.org/pdf/2410.15700v1,cs.CL
Tokenization as Finite-State Transduction,"Tokenization is the first step in modern neural language model pipelines
where an input text is converted to a sequence of subword tokens. We introduce
from first principles a finite-state transduction framework which can
efficiently encode all possible tokenizations of a regular language. We then
constructively show that Byte-Pair Encoding (BPE) and MaxMatch (WordPiece), two
popular tokenization schemes, fit within this framework. For BPE, this is
particularly surprising given its resemblance to context-free grammar and the
fact that it does not tokenize strings from left to right.
  An application of this is to guided generation, where the outputs of a
language model are constrained to match some pattern. Here, patterns are
encoded at the character level, which creates a mismatch between the
constraints and the model's subword vocabulary. While past work has focused
only on constraining outputs without regard to the underlying tokenization
algorithm, our framework allows for simultaneously constraining the model
outputs to match a specified pattern while also adhering to the underlying
tokenizer's canonical tokenization.",2024-10-21,"Marco Cognetta, Naoaki Okazaki",http://arxiv.org/pdf/2410.15696v1,cs.CL
Efficient Terminology Integration for LLM-based Translation in Specialized Domains,"Traditional machine translation methods typically involve training models
directly on large parallel corpora, with limited emphasis on specialized
terminology. However, In specialized fields such as patent, finance, or
biomedical domains, terminology is crucial for translation, with many terms
that needs to be translated following agreed-upon conventions. In this paper we
introduce a methodology that efficiently trains models with a smaller amount of
data while preserving the accuracy of terminology translation. We achieve this
through a systematic process of term extraction and glossary creation using the
Trie Tree algorithm, followed by data reconstruction to teach the LLM how to
integrate these specialized terms. This methodology enhances the model's
ability to handle specialized terminology and ensures high-quality
translations, particularly in fields where term consistency is crucial. Our
approach has demonstrated exceptional performance, achieving the highest
translation score among participants in the WMT patent task to date, showcasing
its effectiveness and broad applicability in specialized translation domains
where general methods often fall short.",2024-10-21,"Sejoon Kim, Mingi Sung, Jeonghwan Lee, Hyunkuk Lim, Jorge Froilan Gimenez Perez",http://arxiv.org/pdf/2410.15690v1,cs.CL
DomainSum: A Hierarchical Benchmark for Fine-Grained Domain Shift in Abstractive Text Summarization,"Most research on abstractive summarization focuses on single-domain
applications, often neglecting how domain shifts between documents affect
performance and the generalization ability of summarization models. To address
this issue, we introduce DomainSum, a hierarchical benchmark designed to
capture fine-grained domain shifts in abstractive summarization. We categorize
these shifts into three levels: genre, style, and topic, and demonstrate
through comprehensive benchmark analysis that they follow a hierarchical
structure. Furthermore, we evaluate the domain generalization capabilities of
commonly used pre-trained language models (PLMs) and large language models
(LLMs) in in-domain and cross-domain settings.",2024-10-21,"Haohan Yuan, Haopeng Zhang",http://arxiv.org/pdf/2410.15687v1,cs.CL
Revealing and Mitigating the Local Pattern Shortcuts of Mamba,"Large language models (LLMs) have advanced significantly due to the attention
mechanism, but their quadratic complexity and linear memory demands limit their
performance on long-context tasks. Recently, researchers introduced Mamba, an
advanced model built upon State Space Models(SSMs) that offers linear
complexity and constant memory. Although Mamba is reported to match or surpass
the performance of attention-based models, our analysis reveals a performance
gap: Mamba excels in tasks that involve localized key information but faces
challenges with tasks that require handling distributed key information. Our
controlled experiments suggest that this inconsistency arises from Mamba's
reliance on local pattern shortcuts, which enable the model to remember local
key information within its limited memory but hinder its ability to retain more
dispersed information. Therefore, we introduce a global selection module into
the Mamba model to address this issue. Experiments on both existing and
proposed synthetic tasks, as well as real-world tasks, demonstrate the
effectiveness of our method. Notably, with the introduction of only 4M extra
parameters, our approach enables the Mamba model(130M) to achieve a significant
improvement on tasks with distributed information, increasing its performance
from 0 to 80.54 points.",2024-10-21,"Wangjie You, Zecheng Tang, Juntao Li, Lili Yao, Min Zhang",http://arxiv.org/pdf/2410.15678v1,cs.CL
Learning to Generate and Evaluate Fact-checking Explanations with Transformers,"In an era increasingly dominated by digital platforms, the spread of
misinformation poses a significant challenge, highlighting the need for
solutions capable of assessing information veracity. Our research contributes
to the field of Explainable Artificial Antelligence (XAI) by developing
transformer-based fact-checking models that contextualise and justify their
decisions by generating human-accessible explanations. Importantly, we also
develop models for automatic evaluation of explanations for fact-checking
verdicts across different dimensions such as \texttt{(self)-contradiction},
\texttt{hallucination}, \texttt{convincingness} and \texttt{overall quality}.
By introducing human-centred evaluation methods and developing specialised
datasets, we emphasise the need for aligning Artificial Intelligence
(AI)-generated explanations with human judgements. This approach not only
advances theoretical knowledge in XAI but also holds practical implications by
enhancing the transparency, reliability and users' trust in AI-driven
fact-checking systems. Furthermore, the development of our metric learning
models is a first step towards potentially increasing efficiency and reducing
reliance on extensive manual assessment. Based on experimental results, our
best performing generative model \textsc{ROUGE-1} score of 47.77, demonstrating
superior performance in generating fact-checking explanations, particularly
when provided with high-quality evidence. Additionally, the best performing
metric learning model showed a moderately strong correlation with human
judgements on objective dimensions such as \texttt{(self)-contradiction and
\texttt{hallucination}, achieving a Matthews Correlation Coefficient (MCC) of
around 0.7.}",2024-10-21,"Darius Feher, Abdullah Khered, Hao Zhang, Riza Batista-Navarro, Viktor Schlegel",http://arxiv.org/pdf/2410.15669v1,cs.CL
Towards More Accurate US Presidential Election via Multi-step Reasoning with Large Language Models,"Can Large Language Models (LLMs) accurately predict election outcomes? While
LLMs have demonstrated impressive performance in various domains, including
healthcare, legal analysis, and creative tasks, their ability to forecast
elections remains unknown. Election prediction poses unique challenges, such as
limited voter-level data, rapidly changing political landscapes, and the need
to model complex human behavior. To address these challenges, we introduce a
multi-step reasoning framework designed for political analysis. Our approach is
validated on real-world data from the American National Election Studies (ANES)
2016 and 2020, as well as synthetic personas generated by the leading machine
learning framework, offering scalable datasets for voter behavior modeling. To
capture temporal dynamics, we incorporate candidates' policy positions and
biographical details, ensuring that the model adapts to evolving political
contexts. Drawing on Chain of Thought prompting, our multi-step reasoning
pipeline systematically integrates demographic, ideological, and time-dependent
factors, enhancing the model's predictive power.",2024-10-21,"Chenxiao Yu, Zhaotian Weng, Yuangang Li, Zheng Li, Xiyang Hu, Yue Zhao",http://arxiv.org/pdf/2411.03321v3,cs.CL
RAC: Efficient LLM Factuality Correction with Retrieval Augmentation,"Large Language Models (LLMs) exhibit impressive results across a wide range
of natural language processing (NLP) tasks, yet they can often produce
factually incorrect outputs. This paper introduces a simple but effective
low-latency post-correction method, \textbf{Retrieval Augmented Correction
(RAC)}, aimed at enhancing the factual performance of LLMs without requiring
additional fine-tuning. Our method is general and can be used with any
instruction-tuned LLM, and has greatly reduced latency compared to prior
approaches. RAC decomposes the LLM's output into atomic facts and applies a
fine-grained verification and correction process with retrieved content to
verify and correct the LLM-generated output. Our extensive experiments show
that RAC yields up to 30\% improvements over state-of-the-art baselines across
two popular factuality evaluation datasets, validating its efficacy and
robustness in both with and without the integration of Retrieval-Augmented
Generation (RAG) across different LLMs.\footnote{Our code is at
\url{https://github.com/jlab-nlp/Retrieval-Augmented-Correction}}",2024-10-21,"Changmao Li, Jeffrey Flanigan",http://arxiv.org/pdf/2410.15667v1,cs.CL
Scalable Data Ablation Approximations for Language Models through Modular Training and Merging,"Training data compositions for Large Language Models (LLMs) can significantly
affect their downstream performance. However, a thorough data ablation study
exploring large sets of candidate data mixtures is typically prohibitively
expensive since the full effect is seen only after training the models; this
can lead practitioners to settle for sub-optimal data mixtures. We propose an
efficient method for approximating data ablations which trains individual
models on subsets of a training corpus and reuses them across evaluations of
combinations of subsets. In continued pre-training experiments, we find that,
given an arbitrary evaluation set, the perplexity score of a single model
trained on a candidate set of data is strongly correlated with perplexity
scores of parameter averages of models trained on distinct partitions of that
data. From this finding, we posit that researchers and practitioners can
conduct inexpensive simulations of data ablations by maintaining a pool of
models that were each trained on partitions of a large training corpus, and
assessing candidate data mixtures by evaluating parameter averages of
combinations of these models. This approach allows for substantial improvements
in amortized training efficiency -- scaling only linearly with respect to new
data -- by enabling reuse of previous training computation, opening new avenues
for improving model performance through rigorous, incremental data assessment
and mixing.",2024-10-21,"Clara Na, Ian Magnusson, Ananya Harsh Jha, Tom Sherborne, Emma Strubell, Jesse Dodge, Pradeep Dasigi",http://arxiv.org/pdf/2410.15661v1,cs.CL
CL-HOI: Cross-Level Human-Object Interaction Distillation from Vision Large Language Models,"Human-object interaction (HOI) detection has seen advancements with Vision
Language Models (VLMs), but these methods often depend on extensive manual
annotations. Vision Large Language Models (VLLMs) can inherently recognize and
reason about interactions at the image level but are computationally heavy and
not designed for instance-level HOI detection. To overcome these limitations,
we propose a Cross-Level HOI distillation (CL-HOI) framework, which distills
instance-level HOIs from VLLMs image-level understanding without the need for
manual annotations. Our approach involves two stages: context distillation,
where a Visual Linguistic Translator (VLT) converts visual information into
linguistic form, and interaction distillation, where an Interaction Cognition
Network (ICN) reasons about spatial, visual, and context relations. We design
contrastive distillation losses to transfer image-level context and interaction
knowledge from the teacher to the student model, enabling instance-level HOI
detection. Evaluations on HICO-DET and V-COCO datasets demonstrate that our
CL-HOI surpasses existing weakly supervised methods and VLLM supervised
methods, showing its efficacy in detecting HOIs without manual labels.",2024-10-21,"Jianjun Gao, Chen Cai, Ruoyu Wang, Wenyang Liu, Kim-Hui Yap, Kratika Garg, Boon-Siew Han",http://arxiv.org/pdf/2410.15657v1,cs.CL
Resource-Efficient Medical Report Generation using Large Language Models,"Medical report generation is the task of automatically writing radiology
reports for chest X-ray images. Manually composing these reports is a
time-consuming process that is also prone to human errors. Generating medical
reports can therefore help reduce the burden on radiologists. In other words,
we can promote greater clinical automation in the medical domain. In this work,
we propose a new framework leveraging vision-enabled Large Language Models
(LLM) for the task of medical report generation. We introduce a lightweight
solution that achieves better or comparative performance as compared to
previous solutions on the task of medical report generation. We conduct
extensive experiments exploring different model sizes and enhancement
approaches, such as prefix tuning to improve the text generation abilities of
the LLMs. We evaluate our approach on a prominent large-scale radiology report
dataset - MIMIC-CXR. Our results demonstrate the capability of our
resource-efficient framework to generate patient-specific reports with strong
medical contextual understanding and high precision.",2024-10-21,"Abdullah, Ameer Hamza, Seong Tae Kim",http://arxiv.org/pdf/2410.15642v1,cs.CL
SMILES-Prompting: A Novel Approach to LLM Jailbreak Attacks in Chemical Synthesis,"The increasing integration of large language models (LLMs) across various
fields has heightened concerns about their potential to propagate dangerous
information. This paper specifically explores the security vulnerabilities of
LLMs within the field of chemistry, particularly their capacity to provide
instructions for synthesizing hazardous substances. We evaluate the
effectiveness of several prompt injection attack methods, including
red-teaming, explicit prompting, and implicit prompting. Additionally, we
introduce a novel attack technique named SMILES-prompting, which uses the
Simplified Molecular-Input Line-Entry System (SMILES) to reference chemical
substances. Our findings reveal that SMILES-prompting can effectively bypass
current safety mechanisms. These findings highlight the urgent need for
enhanced domain-specific safeguards in LLMs to prevent misuse and improve their
potential for positive social impact.",2024-10-21,"Aidan Wong, He Cao, Zijing Liu, Yu Li",http://arxiv.org/pdf/2410.15641v1,cs.CL
Can Large Language Models Invent Algorithms to Improve Themselves?: Algorithm Discovery for Recursive Self-Improvement through Reinforcement Learning,"Large Language Models (LLMs) have achieved remarkable capabilities, yet their
improvement methods remain fundamentally constrained by human design. We
present Self-Developing, a framework that enables LLMs to autonomously
discover, implement, and refine their own improvement algorithms. Our approach
employs an iterative cycle where a seed model generates algorithmic candidates
as executable code, evaluates their effectiveness, and uses Direct Preference
Optimization to recursively improve increasingly sophisticated improvement
strategies. We demonstrate this framework through model merging, a practical
technique for combining specialized models. Self-Developing successfully
discovered novel merging algorithms that outperform existing human-designed
algorithms. On mathematical reasoning benchmarks, the autonomously discovered
algorithms improve the seed model's GSM8k performance by 6\% and exceed
human-designed approaches like Task Arithmetic by 4.3\%. Remarkably, these
algorithms exhibit strong generalization, achieving 7.4\% gains on
out-of-domain models without re-optimization. Our findings demonstrate that
LLMs can transcend their training to invent genuinely novel optimization
techniques. This capability represents a crucial step toward a new era where
LLMs not only solve problems but autonomously develop the methodologies for
their own advancement.",2024-10-21,"Yoichi Ishibashi, Taro Yano, Masafumi Oyamada",http://arxiv.org/pdf/2410.15639v4,cs.CL
GATEAU: Selecting Influential Samples for Long Context Alignment,"Aligning large language models to handle instructions with extremely long
contexts has yet to be fully investigated. Previous studies have attempted to
scale up the available data volume by synthesizing long instruction-following
samples, as constructing such a dataset tends to be challenging for annotators.
However, a lack of a well-defined strategy for ensuring data quality may
introduce low-quality samples and restrict the model's performance. Thus, we
propose GATEAU, a novel framework to address the unique challenge of long
context alignment by identifying the influential samples enriched with
long-range dependency relations. Specifically, GATEAU measures the long-range
dependencies from two essential aspects: the difficulty of generating target
responses due to the long-range dependencies, and the difficulty of
understanding long inputs due to such dependencies. Comprehensive experiments
indicate that GATEAU effectively identifies influential samples and the model
trained on these selected samples exhibits better instruction-following and
long-context understanding capabilities.",2024-10-21,"Shuzheng Si, Haozhe Zhao, Gang Chen, Yunshui Li, Kangyang Luo, Chuancheng Lv, Kaikai An, Fanchao Qi, Baobao Chang, Maosong Sun",http://arxiv.org/pdf/2410.15633v5,cs.CL
Improving Parallel Program Performance with LLM Optimizers via Agent-System Interface,"Modern scientific discovery increasingly relies on high-performance computing
for complex modeling and simulation. A key challenge in improving parallel
program performance is efficiently mapping tasks to processors and data to
memory, a process dictated by intricate, low-level system code known as
mappers. Developing high-performance mappers demands days of manual tuning,
posing a significant barrier for domain scientists without systems expertise.
We introduce a framework that automates mapper development with generative
optimization, leveraging richer feedback beyond scalar performance metrics. Our
approach features the Agent-System Interface, which includes a Domain-Specific
Language (DSL) to abstract away low-level complexity of system code and define
a structured search space, as well as AutoGuide, a mechanism that interprets
raw execution output into actionable feedback. Unlike traditional reinforcement
learning methods such as OpenTuner, which rely solely on scalar feedback, our
method finds superior mappers in far fewer iterations. With just 10 iterations,
it outperforms OpenTuner even after 1000 iterations, achieving 3.8X faster
performance. Our approach finds mappers that surpass expert-written mappers by
up to 1.34X speedup across nine benchmarks while reducing tuning time from days
to minutes.",2024-10-21,"Anjiang Wei, Allen Nie, Thiago S. F. X. Teixeira, Rohan Yadav, Wonchan Lee, Ke Wang, Alex Aiken",http://arxiv.org/pdf/2410.15625v2,cs.CL
Guardians of Discourse: Evaluating LLMs on Multilingual Offensive Language Detection,"Identifying offensive language is essential for maintaining safety and
sustainability in the social media era. Though large language models (LLMs)
have demonstrated encouraging potential in social media analytics, they lack
thorough evaluation when in offensive language detection, particularly in
multilingual environments. We for the first time evaluate multilingual
offensive language detection of LLMs in three languages: English, Spanish, and
German with three LLMs, GPT-3.5, Flan-T5, and Mistral, in both monolingual and
multilingual settings. We further examine the impact of different prompt
languages and augmented translation data for the task in non-English contexts.
Furthermore, we discuss the impact of the inherent bias in LLMs and the
datasets in the mispredictions related to sensitive topics.",2024-10-21,"Jianfei He, Lilin Wang, Jiaying Wang, Zhenyu Liu, Hongbin Na, Zimu Wang, Wei Wang, Qi Chen",http://arxiv.org/pdf/2410.15623v1,cs.CL
Acoustic Model Optimization over Multiple Data Sources: Merging and Valuation,"Due to the rising awareness of privacy protection and the voluminous scale of
speech data, it is becoming infeasible for Automatic Speech Recognition (ASR)
system developers to train the acoustic model with complete data as before. For
example, the data may be owned by different curators, and it is not allowed to
share with others. In this paper, we propose a novel paradigm to solve salient
problems plaguing the ASR field. In the first stage, multiple acoustic models
are trained based upon different subsets of the complete speech data, while in
the second phase, two novel algorithms are utilized to generate a high-quality
acoustic model based upon those trained on data subsets. We first propose the
Genetic Merge Algorithm (GMA), which is a highly specialized algorithm for
optimizing acoustic models but suffers from low efficiency. We further propose
the SGD-Based Optimizational Merge Algorithm (SOMA), which effectively
alleviates the efficiency bottleneck of GMA and maintains superior model
accuracy. Extensive experiments on public data show that the proposed methods
can significantly outperform the state-of-the-art. Furthermore, we introduce
Shapley Value to estimate the contribution score of the trained models, which
is useful for evaluating the effectiveness of the data and providing fair
incentives to their curators.",2024-10-21,"Victor Junqiu Wei, Weicheng Wang, Di Jiang, Conghui Tan, Rongzhong Lian",http://arxiv.org/pdf/2410.15620v1,cs.CL
Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding,"Recently, pre-trained language models (PLMs) have been increasingly adopted
in spoken language understanding (SLU). However, automatic speech recognition
(ASR) systems frequently produce inaccurate transcriptions, leading to noisy
inputs for SLU models, which can significantly degrade their performance. To
address this, our objective is to train SLU models to withstand ASR errors by
exposing them to noises commonly observed in ASR systems, referred to as
ASR-plausible noises. Speech noise injection (SNI) methods have pursued this
objective by introducing ASR-plausible noises, but we argue that these methods
are inherently biased towards specific ASR systems, or ASR-specific noises. In
this work, we propose a novel and less biased augmentation method of
introducing the noises that are plausible to any ASR system, by cutting off the
non-causal effect of noises. Experimental results and analyses demonstrate the
effectiveness of our proposed methods in enhancing the robustness and
generalizability of SLU models against unseen ASR systems by introducing more
diverse and plausible ASR noises in advance.",2024-10-21,"Yeonjoon Jung, Jaeseong Lee, Seungtaek Choi, Dohyeon Lee, Minsoo Kim, Seung-won Hwang",http://arxiv.org/pdf/2410.15609v1,cs.CL
Moonshine: Speech Recognition for Live Transcription and Voice Commands,"This paper introduces Moonshine, a family of speech recognition models
optimized for live transcription and voice command processing. Moonshine is
based on an encoder-decoder transformer architecture and employs Rotary
Position Embedding (RoPE) instead of traditional absolute position embeddings.
The model is trained on speech segments of various lengths, but without using
zero-padding, leading to greater efficiency for the encoder during inference
time. When benchmarked against OpenAI's Whisper tiny-en, Moonshine Tiny
demonstrates a 5x reduction in compute requirements for transcribing a
10-second speech segment while incurring no increase in word error rates across
standard evaluation datasets. These results highlight Moonshine's potential for
real-time and resource-constrained applications.",2024-10-21,"Nat Jeffries, Evan King, Manjunath Kudlur, Guy Nicholson, James Wang, Pete Warden",http://arxiv.org/pdf/2410.15608v2,cs.CL
"A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications","With the rapid advancement of large language models (LLMs), aligning policy
models with human preferences has become increasingly critical. Direct
Preference Optimization (DPO) has emerged as a promising approach for
alignment, acting as an RL-free alternative to Reinforcement Learning from
Human Feedback (RLHF). Despite DPO's various advancements and inherent
limitations, an in-depth review of these aspects is currently lacking in the
literature. In this work, we present a comprehensive review of the challenges
and opportunities in DPO, covering theoretical analyses, variants, relevant
preference datasets, and applications. Specifically, we categorize recent
studies on DPO based on key research questions to provide a thorough
understanding of DPO's current landscape. Additionally, we propose several
future research directions to offer insights on model alignment for the
research community.",2024-10-21,"Wenyi Xiao, Zechuan Wang, Leilei Gan, Shuai Zhao, Wanggui He, Luu Anh Tuan, Long Chen, Hao Jiang, Zhou Zhao, Fei Wu",http://arxiv.org/pdf/2410.15595v2,cs.CL
CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein Representation and Origin Evaluation,"Protein structures are important for understanding their functions and
interactions. Currently, many protein structure prediction methods are
enriching the structure database. Discriminating the origin of structures is
crucial for distinguishing between experimentally resolved and computationally
predicted structures, evaluating the reliability of prediction methods, and
guiding downstream biological studies. Building on works in structure
prediction, We developed a structure-sensitive supervised deep learning model,
Crystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent
and discriminate the origin of protein structures. CPE-Pro learns the
structural information of proteins and captures inter-structural differences to
achieve accurate traceability on four data classes, and is expected to be
extended to more. Simultaneously, we utilized Foldseek to encode protein
structures into ""structure-sequences"" and trained a protein Structural Sequence
Language Model, SSLM. Preliminary experiments demonstrated that, compared to
large-scale protein language models pre-trained on vast amounts of amino acid
sequences, the ""structure-sequence"" enables the language model to learn more
informative protein features, enhancing and optimizing structural
representations. We have provided the code, model weights, and all related
materials on https://github.com/GouWenrui/CPE-Pro-main.git.",2024-10-21,"Wenrui Gou, Wenhui Ge, Yang Tan, Mingchen Li, Guisheng Fan, Huiqun Yu",http://arxiv.org/pdf/2410.15592v2,cs.CL
AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection,"Detecting fake news in large datasets is challenging due to its diversity and
complexity, with traditional approaches often focusing on textual features
while underutilizing semantic and emotional elements. Current methods also rely
heavily on large annotated datasets, limiting their effectiveness in more
nuanced analysis. To address these challenges, this paper introduces
Emotion-\textbf{A}ware \textbf{M}ultimodal Fusion \textbf{P}rompt
\textbf{L}\textbf{E}arning (\textbf{AMPLE}) framework to address the above
issue by combining text sentiment analysis with multimodal data and hybrid
prompt templates. This framework extracts emotional elements from texts by
leveraging sentiment analysis tools. It then employs Multi-Head Cross-Attention
(MCA) mechanisms and similarity-aware fusion methods to integrate multimodal
data. The proposed AMPLE framework demonstrates strong performance on two
public datasets in both few-shot and data-rich settings, with results
indicating the potential of emotional aspects in fake news detection.
Furthermore, the study explores the impact of integrating large language models
with this method for text sentiment extraction, revealing substantial room for
further improvement. The code can be found at
:\url{https://github.com/xxm1215/MMM2025_few-shot/",2024-10-21,"Xiaoman Xu, Xiangrun Li, Taihang Wang, Ye Jiang",http://arxiv.org/pdf/2410.15591v1,cs.CL
Language Models are Symbolic Learners in Arithmetic,"Large Language Models (LLMs) are thought to struggle with arithmetic learning
due to the inherent differences between language modeling and numerical
computation, but concrete evidence has been lacking. This work responds to this
claim through a two-side experiment. We first investigate whether LLMs leverage
partial products during arithmetic learning. We find that although LLMs can
identify some partial products after learning, they fail to leverage them for
arithmetic tasks, conversely. We then explore how LLMs approach arithmetic
symbolically by breaking tasks into subgroups, hypothesizing that difficulties
arise from subgroup complexity and selection. Our results show that when
subgroup complexity is fixed, LLMs treat a collection of different arithmetic
operations similarly. By analyzing position-level accuracy across different
training sizes, we further observe that it follows a U-shaped pattern: LLMs
quickly learn the easiest patterns at the first and last positions, while
progressively learning the more difficult patterns in the middle positions.
This suggests that LLMs select subgroup following an easy-to-hard paradigm
during learning. Our work confirms that LLMs are pure symbolic learners in
arithmetic tasks and underscores the importance of understanding them deeply
through subgroup-level quantification.",2024-10-21,"Chunyuan Deng, Zhiqi Li, Roy Xie, Ruidi Chang, Hanjie Chen",http://arxiv.org/pdf/2410.15580v1,cs.CL
Generalized Probabilistic Attention Mechanism in Transformers,"The Transformer architecture has become widely adopted due to its
demonstrated success, attributed to the attention mechanism at its core.
Despite these successes, the attention mechanism of Transformers is associated
with two well-known issues: rank-collapse and gradient vanishing. In this
paper, we present a theoretical analysis that it is inherently difficult to
address both issues simultaneously in the conventional attention mechanism. To
handle these issues, we introduce a novel class of attention mechanism,
referred to as generalized probabilistic attention mechanism (GPAM), and its
dual-attention implementation within the Transformer architecture. Unlike
conventional attention mechanisms, GPAM allows for negative attention scores
while preserving a fixed total sum. We provide theoretical evidence that the
proposed dual-attention GPAM (daGPAM) effectively mitigates both the
rank-collapse and gradient vanishing issues which are difficult to resolve
simultaneously with the conventional attention mechanisms. Furthermore, we
empirically validate this theoretical evidence, demonstrating the superiority
of daGPAM compared to other alternative attention mechanisms that were proposed
to address the same issues. Additionally, we demonstrate the practical benefits
of GPAM in natural language processing tasks, such as language modeling and
neural machine translation.",2024-10-21,"DongNyeong Heo, Heeyoul Choi",http://arxiv.org/pdf/2410.15578v1,cs.CL
A Survey of Conversational Search,"As a cornerstone of modern information access, search engines have become
indispensable in everyday life. With the rapid advancements in AI and natural
language processing (NLP) technologies, particularly large language models
(LLMs), search engines have evolved to support more intuitive and intelligent
interactions between users and systems. Conversational search, an emerging
paradigm for next-generation search engines, leverages natural language
dialogue to facilitate complex and precise information retrieval, thus
attracting significant attention. Unlike traditional keyword-based search
engines, conversational search systems enhance user experience by supporting
intricate queries, maintaining context over multi-turn interactions, and
providing robust information integration and processing capabilities. Key
components such as query reformulation, search clarification, conversational
retrieval, and response generation work in unison to enable these sophisticated
interactions. In this survey, we explore the recent advancements and potential
future directions in conversational search, examining the critical modules that
constitute a conversational search system. We highlight the integration of LLMs
in enhancing these systems and discuss the challenges and opportunities that
lie ahead in this dynamic field. Additionally, we provide insights into
real-world applications and robust evaluations of current conversational search
systems, aiming to guide future research and development in conversational
search.",2024-10-21,"Fengran Mo, Kelong Mao, Ziliang Zhao, Hongjin Qian, Haonan Chen, Yiruo Cheng, Xiaoxi Li, Yutao Zhu, Zhicheng Dou, Jian-Yun Nie",http://arxiv.org/pdf/2410.15576v1,cs.CL
Neural Search Space in Gboard Decoder,"Gboard Decoder produces suggestions by looking for paths that best match
input touch points on the context aware search space, which is backed by the
language Finite State Transducers (FST). The language FST is currently an
N-gram language model (LM). However, N-gram LMs, limited in context length, are
known to have sparsity problem under device model size constraint. In this
paper, we propose \textbf{Neural Search Space} which substitutes the N-gram LM
with a Neural Network LM (NN-LM) and dynamically constructs the search space
during decoding. Specifically, we integrate the long range context awareness of
NN-LM into the search space by converting its outputs given context, into the
language FST at runtime. This involves language FST structure redesign, pruning
strategy tuning, and data structure optimizations. Online experiments
demonstrate improved quality results, reducing Words Modified Ratio by [0.26\%,
1.19\%] on various locales with acceptable latency increases. This work opens
new avenues for further improving keyboard decoding quality by enhancing neural
LM more directly.",2024-10-21,"Yanxiang Zhang, Yuanbo Zhang, Haicheng Sun, Yun Wang, Billy Dou, Gary Sivek, Shumin Zhai",http://arxiv.org/pdf/2410.15575v1,cs.CL
OpenMU: Your Swiss Army Knife for Music Understanding,"We present OpenMU-Bench, a large-scale benchmark suite for addressing the
data scarcity issue in training multimodal language models to understand music.
To construct OpenMU-Bench, we leveraged existing datasets and bootstrapped new
annotations. OpenMU-Bench also broadens the scope of music understanding by
including lyrics understanding and music tool usage. Using OpenMU-Bench, we
trained our music understanding model, OpenMU, with extensive ablations,
demonstrating that OpenMU outperforms baseline models such as MU-Llama. Both
OpenMU and OpenMU-Bench are open-sourced to facilitate future research in music
understanding and to enhance creative music production efficiency.",2024-10-21,"Mengjie Zhao, Zhi Zhong, Zhuoyuan Mao, Shiqi Yang, Wei-Hsiang Liao, Shusuke Takahashi, Hiromi Wakaki, Yuki Mitsufuji",http://arxiv.org/pdf/2410.15573v3,cs.CL
Leveraging Retrieval-Augmented Generation for Culturally Inclusive Hakka Chatbots: Design Insights and User Perceptions,"In an era where cultural preservation is increasingly intertwined with
technological innovation, this study introduces a groundbreaking approach to
promoting and safeguarding the rich heritage of Taiwanese Hakka culture through
the development of a Retrieval-Augmented Generation (RAG)-enhanced chatbot.
Traditional large language models (LLMs), while powerful, often fall short in
delivering accurate and contextually rich responses, particularly in culturally
specific domains. By integrating external databases with generative AI models,
RAG technology bridges this gap, empowering chatbots to not only provide
precise answers but also resonate deeply with the cultural nuances that are
crucial for authentic interactions. This study delves into the intricate
process of augmenting the chatbot's knowledge base with targeted cultural data,
specifically curated to reflect the unique aspects of Hakka traditions,
language, and practices. Through dynamic information retrieval, the
RAG-enhanced chatbot becomes a versatile tool capable of handling complex
inquiries that demand an in-depth understanding of Hakka cultural context. This
is particularly significant in an age where digital platforms often dilute
cultural identities, making the role of culturally aware AI systems more
critical than ever. System usability studies conducted as part of our research
reveal a marked improvement in both user satisfaction and engagement,
highlighting the chatbot's effectiveness in fostering a deeper connection with
Hakka culture. The feedback underscores the potential of RAG technology to not
only enhance user experience but also to serve as a vital instrument in the
broader mission of ethnic mainstreaming and cultural celebration.",2024-10-21,"Chen-Chi Chang, Han-Pi Chang, Hung-Shin Lee",http://arxiv.org/pdf/2410.15572v1,cs.CL
Stacking Small Language Models for Generalizability,"Recent advances show that large language models (LLMs) generalize strong
performance across different natural language benchmarks. However, the large
size of LLMs makes training and inference expensive and impractical to run in
resource-limited settings. This paper introduces a new approach called
fine-tuning stacks of language models (FSLM), which involves stacking small
language models (SLM) as an alternative to LLMs. By fine-tuning each SLM to
perform a specific task, this approach breaks down high level reasoning into
multiple lower-level steps that specific SLMs are responsible for. As a result,
FSLM allows for lower training and inference costs, and also improves model
interpretability as each SLM communicates with the subsequent one through
natural language. By evaluating FSLM on common natural language benchmarks,
this paper highlights promising early results toward generalizable performance
using FSLM as a cost-effective alternative to LLMs.",2024-10-21,Laurence Liang,http://arxiv.org/pdf/2410.15570v1,cs.CL
Pruning Foundation Models for High Accuracy without Retraining,"Despite the superior performance, it is challenging to deploy foundation
models or large language models (LLMs) due to their massive parameters and
computations. While pruning is a promising technique to reduce model size and
accelerate the inference, the traditional pruning techniques can hardly be
applied for LLMs as they need to finetune the model on the full dataset with
multiple epochs consuming massive data and hardware resources. To deal with
this problem, post-training pruning methods are proposed to prune LLMs in
one-shot without retraining. However, their accuracy after pruning may suffer
from certain performance degradation due to the lack of retraining with massive
data. To address this issue, in this paper, we first formulate the
post-training problem for layer-wise LLM compression to simultaneously prune
multiple weights in LLMs. Next, we provide an optimal solution for this problem
and design our post-training pruning algorithm for both unstructured and
semi-structured sparsity. Our extensive experiments demonstrate the superior
performance of the proposed methods in comparison to SOTA baselines across
various LLM families including transformer-based LLMs and Mamba-based LLMs.
Code link: https://github.com/piuzha/APT",2024-10-21,"Pu Zhao, Fei Sun, Xuan Shen, Pinrui Yu, Zhenglun Kong, Yanzhi Wang, Xue Lin",http://arxiv.org/pdf/2410.15567v1,cs.CL
Multi-IF: Benchmarking LLMs on Multi-Turn and Multilingual Instructions Following,"Large Language Models (LLMs) have demonstrated impressive capabilities in
various tasks, including instruction following, which is crucial for aligning
model outputs with user expectations. However, evaluating LLMs' ability to
follow instructions remains challenging due to the complexity and subjectivity
of human language. Current benchmarks primarily focus on single-turn,
monolingual instructions, which do not adequately reflect the complexities of
real-world applications that require handling multi-turn and multilingual
interactions. To address this gap, we introduce Multi-IF, a new benchmark
designed to assess LLMs' proficiency in following multi-turn and multilingual
instructions. Multi-IF, which utilizes a hybrid framework combining LLM and
human annotators, expands upon the IFEval by incorporating multi-turn sequences
and translating the English prompts into another 7 languages, resulting in a
dataset of 4,501 multilingual conversations, where each has three turns. Our
evaluation of 14 state-of-the-art LLMs on Multi-IF reveals that it presents a
significantly more challenging task than existing benchmarks. All the models
tested showed a higher rate of failure in executing instructions correctly with
each additional turn. For example, o1-preview drops from 0.877 at the first
turn to 0.707 at the third turn in terms of average accuracy over all
languages. Moreover, languages with non-Latin scripts (Hindi, Russian, and
Chinese) generally exhibit higher error rates, suggesting potential limitations
in the models' multilingual capabilities. We release Multi-IF prompts and the
evaluation code base to encourage further research in this critical area.",2024-10-21,"Yun He, Di Jin, Chaoqi Wang, Chloe Bi, Karishma Mandyam, Hejia Zhang, Chen Zhu, Ning Li, Tengyu Xu, Hongjiang Lv, Shruti Bhosale, Chenguang Zhu, Karthik Abinav Sankararaman, Eryk Helenowski, Melanie Kambadur, Aditya Tayade, Hao Ma, Han Fang, Sinong Wang",http://arxiv.org/pdf/2410.15553v2,cs.CL
WHoW: A Cross-domain Approach for Analysing Conversation Moderation,"We propose WHoW, an evaluation framework for analyzing the facilitation
strategies of moderators across different domains/scenarios by examining their
motives (Why), dialogue acts (How) and target speaker (Who). Using this
framework, we annotated 5,657 moderation sentences with human judges and 15,494
sentences with GPT-4o from two domains: TV debates and radio panel discussions.
Comparative analysis demonstrates the framework's cross-domain generalisability
and reveals distinct moderation strategies: debate moderators emphasise
coordination and facilitate interaction through questions and instructions,
while panel discussion moderators prioritize information provision and actively
participate in discussions. Our analytical framework works for different
moderation scenarios, enhances our understanding of moderation behaviour
through automatic large-scale analysis, and facilitates the development of
moderator agents.",2024-10-21,"Ming-Bin Chen, Lea Frermann, Jey Han Lau",http://arxiv.org/pdf/2410.15551v1,cs.CL
Grammatical Error Correction for Low-Resource Languages: The Case of Zarma,"Grammatical error correction (GEC) aims to improve quality and readability of
texts through accurate correction of linguistic mistakes. Previous work has
focused on high-resource languages, while low-resource languages lack robust
tools. However, low-resource languages often face problems such as:
non-standard orthography, limited annotated corpora, and diverse dialects,
which slows down the development of GEC tools. We present a study on GEC for
Zarma, spoken by over five million in West Africa. We compare three approaches:
rule-based methods, machine translation (MT) models, and large language models
(LLMs). We evaluated them using a dataset of more than 250,000 examples,
including synthetic and human-annotated data. Our results showed that the
MT-based approach using M2M100 outperforms others, with a detection rate of 95.
82% and a suggestion accuracy of 78. 90% in automatic evaluations (AE) and an
average score of 3.0 out of 5.0 in manual evaluation (ME) from native speakers
for grammar and logical corrections. The rule-based method was effective for
spelling errors but failed on complex context-level errors. LLMs -- MT5-small
-- showed moderate performance. Our work supports use of MT models to enhance
GEC in low-resource settings, and we validated these results with Bambara,
another West African language.",2024-10-20,"Mamadou K. Keita, Christopher Homan, Marcos Zampieri, Adwoa Bremang, Habibatou Abdoulaye Alfari, Elysabhete Amadou Ibrahim, Dennis Owusu",http://arxiv.org/pdf/2410.15539v2,cs.CL
Do RAG Systems Cover What Matters? Evaluating and Optimizing Responses with Sub-Question Coverage,"Evaluating retrieval-augmented generation (RAG) systems remains challenging,
particularly for open-ended questions that lack definitive answers and require
coverage of multiple sub-topics. In this paper, we introduce a novel evaluation
framework based on sub-question coverage, which measures how well a RAG system
addresses different facets of a question. We propose decomposing questions into
sub-questions and classifying them into three types -- core, background, and
follow-up -- to reflect their roles and importance. Using this categorization,
we introduce a fine-grained evaluation protocol that provides insights into the
retrieval and generation characteristics of RAG systems, including three
commercial generative answer engines: You.com, Perplexity AI, and Bing Chat.
Interestingly, we find that while all answer engines cover core sub-questions
more often than background or follow-up ones, they still miss around 50% of
core sub-questions, revealing clear opportunities for improvement. Further,
sub-question coverage metrics prove effective for ranking responses, achieving
82% accuracy compared to human preference annotations. Lastly, we also
demonstrate that leveraging core sub-questions enhances both retrieval and
answer generation in a RAG system, resulting in a 74% win rate over the
baseline that lacks sub-questions.",2024-10-20,"Kaige Xie, Philippe Laban, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu",http://arxiv.org/pdf/2410.15531v1,cs.CL
M-RewardBench: Evaluating Reward Models in Multilingual Settings,"Reward models (RMs) have driven the state-of-the-art performance of LLMs
today by enabling the integration of human feedback into the language modeling
process. However, RMs are primarily trained and evaluated in English, and their
capabilities in multilingual settings remain largely understudied. In this
work, we conduct a systematic evaluation of several reward models in
multilingual settings. We first construct the first-of-its-kind multilingual RM
evaluation benchmark, M-RewardBench, consisting of 2.87k preference instances
for 23 typologically diverse languages, that tests the chat, safety, reasoning,
and translation capabilities of RMs. We then rigorously evaluate a wide range
of reward models on M-RewardBench, offering fresh insights into their
performance across diverse languages. We identify a significant gap in RMs'
performances between English and non-English languages and show that RM
preferences can change substantially from one language to another. We also
present several findings on how different multilingual aspects impact RM
performance. Specifically, we show that the performance of RMs is improved with
improved translation quality. Similarly, we demonstrate that the models exhibit
better performance for high-resource languages. We release M-RewardBench
dataset and the codebase in this study to facilitate a better understanding of
RM evaluation in multilingual settings.",2024-10-20,"Srishti Gureja, Lester James V. Miranda, Shayekh Bin Islam, Rishabh Maheshwary, Drishti Sharma, Gusti Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, Marzieh Fadaee",http://arxiv.org/pdf/2410.15522v3,cs.CL
SceneGraMMi: Scene Graph-boosted Hybrid-fusion for Multi-Modal Misinformation Veracity Prediction,"Misinformation undermines individual knowledge and affects broader societal
narratives. Despite growing interest in the research community in multi-modal
misinformation detection, existing methods exhibit limitations in capturing
semantic cues, key regions, and cross-modal similarities within multi-modal
datasets. We propose SceneGraMMi, a Scene Graph-boosted Hybrid-fusion approach
for Multi-modal Misinformation veracity prediction, which integrates scene
graphs across different modalities to improve detection performance.
Experimental results across four benchmark datasets show that SceneGraMMi
consistently outperforms state-of-the-art methods. In a comprehensive ablation
study, we highlight the contribution of each component, while Shapley values
are employed to examine the explainability of the model's decision-making
process.",2024-10-20,"Swarang Joshi, Siddharth Mavani, Joel Alex, Arnav Negi, Rahul Mishra, Ponnurangam Kumaraguru",http://arxiv.org/pdf/2410.15517v1,cs.CL
Reverse Question Answering: Can an LLM Write a Question so Hard (or Bad) that it Can't Answer?,"Question answering (QA), giving correct answers to questions, is a popular
task, but we test reverse question answering (RQA): for an input answer, give a
question with that answer. Past work tests QA and RQA separately, but we test
them jointly, comparing their difficulty, aiding benchmark design, and checking
reasoning consistency. We run 16 LLMs on QA and RQA with trivia
questions/answers, revealing: 1) Versus QA, LLMs are much less accurate in RQA
for numerical answers, but slightly more accurate in RQA for textual answers;
2) LLMs often answer their own invalid questions from RQA accurately in QA, so
RQA errors are not from knowledge gaps alone; 3) RQA errors correlate with
question difficulty and inversely correlate with answer frequencies in the
Dolma corpus; and 4) LLMs struggle to provide valid multi-hop questions. By
finding question and answer types that lead to RQA errors, we suggest
improvements for LLM reasoning.",2024-10-20,"Nishant Balepur, Feng Gu, Abhilasha Ravichander, Shi Feng, Jordan Boyd-Graber, Rachel Rudinger",http://arxiv.org/pdf/2410.15512v2,cs.CL
Exploring Curriculum Learning for Vision-Language Tasks: A Study on Small-Scale Multimodal Training,"For specialized domains, there is often not a wealth of data with which to
train large machine learning models. In such limited data / compute settings,
various methods exist aiming to $\textit{do more with less}$, such as
finetuning from a pretrained model, modulating difficulty levels as data are
presented to a model (curriculum learning), and considering the role of model
type / size. Approaches to efficient $\textit{machine}$ learning also take
inspiration from $\textit{human}$ learning by considering use cases where
machine learning systems have access to approximately the same number of words
experienced by a 13 year old child (100M words). We investigate the role of 3
primary variables in a limited data regime as part of the multimodal track of
the BabyLM challenge. We contrast: (i) curriculum learning, (ii), pretraining
(with text-only data), (iii) model type. We modulate these variables and assess
them on two types of tasks: (a) multimodal (text+image), and (b) unimodal
(text-only) tasks. We find that curriculum learning benefits multimodal
evaluations over non-curriclum learning models, particularly when combining
text-only pretraining. On text-only tasks, curriculum learning appears to help
models with smaller trainable parameter counts. We suggest possible reasons
based on architectural differences and training designs as to why one might
observe such results.",2024-10-20,"Rohan Saha, Abrar Fahim, Alona Fyshe, Alex Murphy",http://arxiv.org/pdf/2410.15509v1,cs.CL
RoMemes: A multimodal meme corpus for the Romanian language,"Memes are becoming increasingly more popular in online media, especially in
social networks. They usually combine graphical representations (images,
drawings, animations or video) with text to convey powerful messages. In order
to extract, process and understand the messages, AI applications need to employ
multimodal algorithms. In this paper, we introduce a curated dataset of real
memes in the Romanian language, with multiple annotation levels. Baseline
algorithms were employed to demonstrate the usability of the dataset. Results
indicate that further research is needed to improve the processing capabilities
of AI tools when faced with Internet memes.",2024-10-20,"Vasile Păiş, Sara Niţă, Alexandru-Iulius Jerpelea, Luca Pană, Eric Curea",http://arxiv.org/pdf/2410.15497v1,cs.CL
"""What is the value of {templates}?"" Rethinking Document Information Extraction Datasets for LLMs","The rise of large language models (LLMs) for visually rich document
understanding (VRDU) has kindled a need for prompt-response, document-based
datasets. As annotating new datasets from scratch is labor-intensive, the
existing literature has generated prompt-response datasets from available
resources using simple templates. For the case of key information extraction
(KIE), one of the most common VRDU tasks, past work has typically employed the
template ""What is the value for the {key}?"". However, given the variety of
questions encountered in the wild, simple and uniform templates are
insufficient for creating robust models in research and industrial contexts. In
this work, we present K2Q, a diverse collection of five datasets converted from
KIE to a prompt-response format using a plethora of bespoke templates. The
questions in K2Q can span multiple entities and be extractive or boolean. We
empirically compare the performance of seven baseline generative models on K2Q
with zero-shot prompting. We further compare three of these models when
training on K2Q versus training on simpler templates to motivate the need of
our work. We find that creating diverse and intricate KIE questions enhances
the performance and robustness of VRDU models. We hope this work encourages
future studies on data quality for generative model training.",2024-10-20,"Ran Zmigrod, Pranav Shetty, Mathieu Sibue, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu, Manuela Veloso",http://arxiv.org/pdf/2410.15484v1,cs.CL
Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning,"Post-training of pre-trained LLMs, which typically consists of the supervised
fine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is
crucial to effective and safe LLM applications. The widely adopted approach in
post-training popular open-source LLMs is to sequentially perform SFT and
RLHF/DPO. However, sequential training is sub-optimal in terms of SFT and
RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training
when undergoing the second stage's training. We theoretically prove the
sub-optimality of sequential post-training. Furthermore, we propose a practical
joint post-training framework with theoretical convergence guarantees and
empirically outperforms sequential post-training framework, while having
similar computational cost. Our code is available at
https://github.com/heshandevaka/XRIGHT.",2024-10-20,"Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen",http://arxiv.org/pdf/2410.15483v3,cs.CL
"Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI","The widespread adoption of large language models (LLMs) and generative AI
(GenAI) tools across diverse applications has amplified the importance of
addressing societal biases inherent within these technologies. While the NLP
community has extensively studied LLM bias, research investigating how
non-expert users perceive and interact with biases from these systems remains
limited. As these technologies become increasingly prevalent, understanding
this question is crucial to inform model developers in their efforts to
mitigate bias. To address this gap, this work presents the findings from a
university-level competition, which challenged participants to design prompts
for eliciting biased outputs from GenAI tools. We quantitatively and
qualitatively analyze the competition submissions and identify a diverse set of
biases in GenAI and strategies employed by participants to induce bias in
GenAI. Our finding provides unique insights into how non-expert users perceive
and interact with biases from GenAI tools.",2024-10-20,"Hangzhi Guo, Pranav Narayanan Venkit, Eunchae Jang, Mukund Srinath, Wenbo Zhang, Bonam Mingole, Vipul Gupta, Kush R. Varshney, S. Shyam Sundar, Amulya Yadav",http://arxiv.org/pdf/2410.15467v1,cs.CL
"Keep Guessing? When Considering Inference Scaling, Mind the Baselines","Scaling inference compute in large language models (LLMs) through repeated
sampling consistently increases the coverage (fraction of problems solved) as
the number of samples increases. We conjecture that this observed improvement
is partially due to the answer distribution of standard evaluation benchmarks,
which is skewed towards a relatively small set of common answers. To test this
conjecture, we define a baseline that enumerates answers according to their
prevalence in the training set. Experiments spanning two domains --
mathematical reasoning and factual knowledge -- reveal that this baseline
outperforms repeated model sampling for some LLMs, while the coverage for
others is on par with that of a mixture strategy that obtains $k$ answers by
using only $10$ model samples and similarly guessing the remaining $k-10$
attempts via enumeration. Our baseline enables a more accurate measurement of
how much repeated sampling improves coverage in such settings beyond
prompt-agnostic guessing.",2024-10-20,"Gal Yona, Or Honovich, Omer Levy, Roee Aharoni",http://arxiv.org/pdf/2410.15466v1,cs.CL
A Novel Interpretability Metric for Explaining Bias in Language Models: Applications on Multilingual Models from Southeast Asia,"Work on bias in pretrained language models (PLMs) focuses on bias evaluation
and mitigation and fails to tackle the question of bias attribution and
explainability. We propose a novel metric, the $\textit{bias attribution
score}$, which draws from information theory to measure token-level
contributions to biased behavior in PLMs. We then demonstrate the utility of
this metric by applying it on multilingual PLMs, including models from
Southeast Asia which have not yet been thoroughly examined in bias evaluation
literature. Our results confirm the presence of sexist and homophobic bias in
Southeast Asian PLMs. Interpretability and semantic analyses also reveal that
PLM bias is strongly induced by words relating to crime, intimate
relationships, and helping among other discursive categories, suggesting that
these are topics where PLMs strongly reproduce bias from pretraining data and
where PLMs should be used with more caution.",2024-10-20,"Lance Calvin Lim Gamboa, Mark Lee",http://arxiv.org/pdf/2410.15464v2,cs.CL
MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures,"In Medical question-answering (QA) tasks, the need for effective systems is
pivotal in delivering accurate responses to intricate medical queries. However,
existing approaches often struggle to grasp the intricate logical structures
and relationships inherent in medical contexts, thus limiting their capacity to
furnish precise and nuanced answers. In this work, we address this gap by
proposing a novel Abstractive QA system MedLogic-AQA that harnesses First Order
Logic (FOL) based rules extracted from both context and questions to generate
well-grounded answers. Through initial experimentation, we identified six
pertinent first-order logical rules, which were then used to train a
Logic-Understanding (LU) model capable of generating logical triples for a
given context, question, and answer. These logic triples are then integrated
into the training of MedLogic-AQA, enabling effective and coherent reasoning
during answer generation. This distinctive fusion of logical reasoning with
abstractive QA equips our system to produce answers that are logically sound,
relevant, and engaging. Evaluation with respect to both automated and
human-based demonstrates the robustness of MedLogic-AQA against strong
baselines. Through empirical assessments and case studies, we validate the
efficacy of MedLogic-AQA in elevating the quality and comprehensiveness of
answers in terms of reasoning as well as informativeness",2024-10-20,"Aizan Zafar, Kshitij Mishra, Asif Ekbal",http://arxiv.org/pdf/2410.15463v1,cs.CL
Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training,"As large language models (LLMs) are increasingly deployed across various
industries, concerns regarding their reliability, particularly due to
hallucinations - outputs that are factually inaccurate or irrelevant to user
input - have grown. Our research investigates the relationship between the
training process and the emergence of hallucinations to address a key gap in
existing research that focuses primarily on post hoc detection and mitigation
strategies. Using models from the Pythia suite (70M - 12B parameters) and
several hallucination detection metrics, we analyze hallucination trends
throughout training and explore LLM internal dynamics. We introduce Sensitivity
Dropout (SenD), a novel training protocol designed to mitigate hallucinations
by reducing variance during training. SenD achieves this by deterministically
dropping embedding indices with significant variability, referred to as
Sensitive Embedding Indices. In addition, we develop an unsupervised
hallucination detection metric, Efficient EigenScore (EES), which approximates
the traditional EigenScore at 2x speed. This efficient metric is integrated
into our protocol, allowing SenD to be both computationally scalable and
effective at reducing hallucinations. Our empirical evaluation demonstrates
that our approach improves LLM reliability at test time by up to 40% compared
to normal training while also providing an efficient method to improve factual
accuracy when adapting LLMs to Wikipedia, Medical, and LegalBench domains.",2024-10-20,"Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi",http://arxiv.org/pdf/2410.15460v3,cs.CL
CROPE: Evaluating In-Context Adaptation of Vision and Language Models to Culture-Specific Concepts,"As Vision and Language models (VLMs) are reaching users across the globe,
assessing their cultural understanding has become a critical challenge. In this
paper, we introduce CROPE, a visual question answering benchmark designed to
probe the knowledge of culture-specific concepts and evaluate the capacity for
cultural adaptation through contextual information. This allows us to
distinguish between parametric knowledge acquired during training and
contextual knowledge provided during inference via visual and textual
descriptions. Our evaluation of several state-of-the-art open VLMs shows large
performance disparities between culture-specific and common concepts in the
parametric setting. Moreover, experiments with contextual knowledge indicate
that models struggle to effectively utilize multimodal information and bind
culture-specific concepts to their depictions. Our findings reveal limitations
in the cultural understanding and adaptability of current VLMs that need to be
addressed toward more culturally inclusive models.",2024-10-20,"Malvina Nikandrou, Georgios Pantazopoulos, Nikolas Vitsakis, Ioannis Konstas, Alessandro Suglia",http://arxiv.org/pdf/2410.15453v2,cs.CL
Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering,"In the realm of Large Language Model (LLM) functionalities, providing
reliable information is paramount, yet reports suggest that LLM outputs lack
consistency. This inconsistency, often at-tributed to randomness in token
sampling, under-mines user trust as it leads to varying responses even for
identical queries. In this paper, we present a new approach for evaluating
semantic consistencies of LLM including comparison of alternative tech-niques.
Our approach evaluates whether LLM re-sponses are semantically congruent for a
given question, recognizing that as syntactically different sentences may
convey the same meaning. Here-tofore, To enhance LLM consistency, two main
approaches have been explored: Leverage external knowledge as context like the
RAG pattern or use Zero-shot-CoT to improve performance of LLM itself. We apply
our evaluation approach to these techniques, and demonstrate to compare the
im-pact of these methods on LLM response con-sistency across different domains
of question an-swering tasks. Using the TruthfulQA dataset to assess LLM
responses, the study induces N re-sponses per question from the LLM and
clusters semantically equivalent sentences to measure semantic consistency
across 37 categories. Through this, it quantitatively analyzes the
effectiveness of the aforementioned methods in improving LLM performance before
and after their adoption.",2024-10-20,"Yanggyu Lee, Jihie Kim",http://arxiv.org/pdf/2410.15440v1,cs.CL
A Comprehensive Evaluation of Cognitive Biases in LLMs,"We present a large-scale evaluation of 30 cognitive biases in 20
state-of-the-art large language models (LLMs) under various decision-making
scenarios. Our contributions include a novel general-purpose test framework for
reliable and large-scale generation of tests for LLMs, a benchmark dataset with
30,000 tests for detecting cognitive biases in LLMs, and a comprehensive
assessment of the biases found in the 20 evaluated LLMs. Our work confirms and
broadens previous findings suggesting the presence of cognitive biases in LLMs
by reporting evidence of all 30 tested biases in at least some of the 20 LLMs.
We publish our framework code to encourage future research on biases in LLMs:
https://github.com/simonmalberg/cognitive-biases-in-llms",2024-10-20,"Simon Malberg, Roman Poletukhin, Carolin M. Schuster, Georg Groh",http://arxiv.org/pdf/2410.15413v1,cs.CL
IPO: Interpretable Prompt Optimization for Vision-Language Models,"Pre-trained vision-language models like CLIP have remarkably adapted to
various downstream tasks. Nonetheless, their performance heavily depends on the
specificity of the input text prompts, which requires skillful prompt template
engineering. Instead, current approaches to prompt optimization learn the
prompts through gradient descent, where the prompts are treated as adjustable
parameters. However, these methods tend to lead to overfitting of the base
classes seen during training and produce prompts that are no longer
understandable by humans. This paper introduces a simple but interpretable
prompt optimizer (IPO), that utilizes large language models (LLMs) to generate
textual prompts dynamically. We introduce a Prompt Optimization Prompt that not
only guides LLMs in creating effective prompts but also stores past prompts
with their performance metrics, providing rich in-context information.
Additionally, we incorporate a large multimodal model (LMM) to condition on
visual content by generating image descriptions, which enhance the interaction
between textual and visual modalities. This allows for thae creation of
dataset-specific prompts that improve generalization performance, while
maintaining human comprehension. Extensive testing across 11 datasets reveals
that IPO not only improves the accuracy of existing gradient-descent-based
prompt learning methods but also considerably enhances the interpretability of
the generated prompts. By leveraging the strengths of LLMs, our approach
ensures that the prompts remain human-understandable, thereby facilitating
better transparency and oversight for vision-language models.",2024-10-20,"Yingjun Du, Wenfang Sun, Cees G. M. Snoek",http://arxiv.org/pdf/2410.15397v1,cs.CL
CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges,"The use of large language models (LLMs) as automated evaluation tools to
assess the quality of generated natural language, known as LLMs-as-Judges, has
demonstrated promising capabilities and is rapidly gaining widespread
attention. However, when applied to pairwise comparisons of candidate
responses, LLM-based evaluators often exhibit selection bias. Specifically,
their judgments may become inconsistent when the option positions or ID tokens
are swapped, compromising the effectiveness and fairness of the evaluation
result. To address this challenge, we introduce CalibraEval, a novel label-free
method for mitigating selection bias during inference. Specifically,
CalibraEval reformulates debiasing as an optimization task aimed at adjusting
observed prediction distributions to align with unbiased prediction
distributions. To solve this optimization problem, we propose a non-parametric
order-preserving algorithm (NOA). This algorithm leverages the partial order
relationships between model prediction distributions, thereby eliminating the
need for explicit labels and precise mathematical function modeling.Empirical
evaluations of LLMs in multiple representative benchmarks demonstrate that
CalibraEval effectively mitigates selection bias and improves performance
compared to existing debiasing methods. This work marks a step toward building
more robust and unbiased automated evaluation frameworks, paving the way for
improved reliability in AI-driven assessments",2024-10-20,"Haitao Li, Junjie Chen, Qingyao Ai, Zhumin Chu, Yujia Zhou, Qian Dong, Yiqun Liu",http://arxiv.org/pdf/2410.15393v1,cs.CL
BERTtime Stories: Investigating the Role of Synthetic Story Data in Language Pre-training,"We describe our contribution to the Strict and Strict-Small tracks of the 2nd
iteration of the BabyLM Challenge. The shared task is centered around efficient
pre-training given data constraints motivated by human development. In
response, we study the effect of synthetic story data in language pre-training
using TinyStories: a recently introduced dataset of short stories. Initially,
we train GPT-Neo models on subsets of TinyStories, while varying the amount of
available data. We find that, even with access to less than 100M words, the
models are able to generate high-quality, original completions to a given
story, and acquire substantial linguistic knowledge. To measure the effect of
synthetic story data, we train LTG-BERT encoder models on a combined dataset
of: a subset of TinyStories, story completions generated by GPT-Neo, and a
subset of the BabyLM dataset. Our experimentation reveals that synthetic data
can occasionally offer modest gains, but overall have a negative influence on
linguistic understanding. Our work offers an initial study on synthesizing
story data in low resource settings and underscores their potential for
augmentation in data-constrained language modeling. We publicly release our
models and implementation on our GitHub.",2024-10-20,"Nikitas Theodoropoulos, Giorgos Filandrianos, Vassilis Lyberatos, Maria Lymperaiou, Giorgos Stamou",http://arxiv.org/pdf/2410.15365v4,cs.CL
Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models,"Aligned Large Language Models (LLMs) have demonstrated remarkable performance
across various tasks. However, LLMs remain susceptible to jailbreak adversarial
attacks, where adversaries manipulate prompts to elicit malicious responses
that aligned LLMs should have avoided. Identifying these vulnerabilities is
crucial for understanding the inherent weaknesses of LLMs and preventing their
potential misuse. One pioneering work in jailbreaking is the GCG attack, a
discrete token optimization algorithm that seeks to find a suffix capable of
jailbreaking aligned LLMs. Despite the success of GCG, we find it suboptimal,
requiring significantly large computational costs, and the achieved
jailbreaking performance is limited. In this work, we propose Faster-GCG, an
efficient adversarial jailbreak method by delving deep into the design of GCG.
Experiments demonstrate that Faster-GCG can surpass the original GCG with only
1/10 of the computational cost, achieving significantly higher attack success
rates on various open-source aligned LLMs. In addition, We demonstrate that
Faster-GCG exhibits improved attack transferability when testing on
closed-sourced LLMs such as ChatGPT.",2024-10-20,"Xiao Li, Zhuhong Li, Qiongxiu Li, Bingze Lee, Jinghao Cui, Xiaolin Hu",http://arxiv.org/pdf/2410.15362v1,cs.CL
CompAct: Compressed Activations for Memory-Efficient LLM Training,"We introduce CompAct, a technique that reduces peak memory utilization on GPU
by 25-30% for pretraining and 50% for fine-tuning of LLMs. Peak device memory
is a major limiting factor in training LLMs, with various recent works aiming
to reduce model memory. However most works don't target the largest component
of allocated memory during training: the model's compute graph, which is stored
for the backward pass. By storing low-rank, compressed activations to be used
in the backward pass we greatly reduce the required memory, unlike previous
methods which only reduce optimizer overheads or the number of trained
parameters. Our compression uses random projection matrices, thus avoiding
additional memory overheads. Comparisons with previous techniques for either
pretraining or fine-tuning show that CompAct substantially improves existing
compute-performance tradeoffs. We expect CompAct's savings to scale even higher
for larger models.",2024-10-20,"Yara Shamshoum, Nitzan Hodos, Yuval Sieradzki, Assaf Schuster",http://arxiv.org/pdf/2410.15352v2,cs.CL
EPIC: Efficient Position-Independent Context Caching for Serving Large Language Models,"Large Language Models (LLMs) are critical for a wide range of applications,
but serving them efficiently becomes increasingly challenging as inputs become
more complex. Context caching improves serving performance by exploiting
inter-request dependency and reusing key-value (KV) cache across requests, thus
improving time-to-first-token (TTFT). However, existing prefix-based context
caching requires exact token prefix matches, limiting cache reuse in few-shot
learning, multi-document QA, or retrieval-augmented generation, where prefixes
may vary. In this paper, we present EPIC, an LLM serving system that introduces
position-independent context caching (PIC), enabling modular KV cache reuse
regardless of token chunk position (or prefix). EPIC features two key designs:
AttnLink, which leverages static attention sparsity to minimize recomputation
for accuracy recovery, and KVSplit, a customizable chunking method that
preserves semantic coherence. Our experiments demonstrate that Epic delivers up
to 8x improvements in TTFT and 7x throughput over existing systems, with
negligible or no accuracy loss. By addressing the limitations of traditional
caching approaches, Epic enables more scalable and efficient LLM inference.",2024-10-20,"Junhao Hu, Wenrui Huang, Haoyi Wang, Weidong Wang, Tiancheng Hu, Qin Zhang, Hao Feng, Xusheng Chen, Yizhou Shan, Tao Xie",http://arxiv.org/pdf/2410.15332v2,cs.CL
A Survey of Uncertainty Estimation in LLMs: Theory Meets Practice,"As large language models (LLMs) continue to evolve, understanding and
quantifying the uncertainty in their predictions is critical for enhancing
application credibility. However, the existing literature relevant to LLM
uncertainty estimation often relies on heuristic approaches, lacking systematic
classification of the methods. In this survey, we clarify the definitions of
uncertainty and confidence, highlighting their distinctions and implications
for model predictions. On this basis, we integrate theoretical perspectives,
including Bayesian inference, information theory, and ensemble strategies, to
categorize various classes of uncertainty estimation methods derived from
heuristic approaches. Additionally, we address challenges that arise when
applying these methods to LLMs. We also explore techniques for incorporating
uncertainty into diverse applications, including out-of-distribution detection,
data annotation, and question clarification. Our review provides insights into
uncertainty estimation from both definitional and theoretical angles,
contributing to a comprehensive understanding of this critical aspect in LLMs.
We aim to inspire the development of more reliable and effective uncertainty
estimation approaches for LLMs in real-world scenarios.",2024-10-20,"Hsiu-Yuan Huang, Yutong Yang, Zhaoxi Zhang, Sanwoo Lee, Yunfang Wu",http://arxiv.org/pdf/2410.15326v1,cs.CL
Causality for Large Language Models,"Recent breakthroughs in artificial intelligence have driven a paradigm shift,
where large language models (LLMs) with billions or trillions of parameters are
trained on vast datasets, achieving unprecedented success across a series of
language tasks. However, despite these successes, LLMs still rely on
probabilistic modeling, which often captures spurious correlations rooted in
linguistic patterns and social stereotypes, rather than the true causal
relationships between entities and events. This limitation renders LLMs
vulnerable to issues such as demographic biases, social stereotypes, and LLM
hallucinations. These challenges highlight the urgent need to integrate
causality into LLMs, moving beyond correlation-driven paradigms to build more
reliable and ethically aligned AI systems.
  While many existing surveys and studies focus on utilizing prompt engineering
to activate LLMs for causal knowledge or developing benchmarks to assess their
causal reasoning abilities, most of these efforts rely on human intervention to
activate pre-trained models. How to embed causality into the training process
of LLMs and build more general and intelligent models remains unexplored.
Recent research highlights that LLMs function as causal parrots, capable of
reciting causal knowledge without truly understanding or applying it. These
prompt-based methods are still limited to human interventional improvements.
This survey aims to address this gap by exploring how causality can enhance
LLMs at every stage of their lifecycle-from token embedding learning and
foundation model training to fine-tuning, alignment, inference, and
evaluation-paving the way for more interpretable, reliable, and
causally-informed models. Additionally, we further outline six promising future
directions to advance LLM development, enhance their causal reasoning
capabilities, and address the current limitations these models face.",2024-10-20,"Anpeng Wu, Kun Kuang, Minqin Zhu, Yingrong Wang, Yujia Zheng, Kairong Han, Baohong Li, Guangyi Chen, Fei Wu, Kun Zhang",http://arxiv.org/pdf/2410.15319v1,cs.CL
Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant,"Large Language Models (LLMs) have revolutionized natural language processing,
but their application to speech-based tasks remains challenging due to the
complexities of integrating audio and text modalities. This paper introduces
Ichigo, a mixed-modal model that seamlessly processes interleaved sequences of
speech and text. Utilizing a tokenized early-fusion approach, Ichigo quantizes
speech into discrete tokens and employs a uniform transformer-based
architecture for both speech and text modalities. This method enables joint
reasoning and generation across modalities without the need for separate
adapters. We present a comprehensive training methodology, including
pre-training on multilingual speech recognition datasets and fine-tuning on a
curated instruction dataset. Ichigo demonstrates state-of-the-art performance
on speech question-answering benchmarks, outperforming existing open-source
speech language models and achieving comparable results to cascaded systems.
Notably, Ichigo exhibits a latency of just 111 ms to first token generation,
significantly lower than current models. Our approach not only advances the
field of multimodal AI but also provides a framework for smaller research teams
to contribute effectively to open-source speech-language models.",2024-10-20,"Alan Dao, Dinh Bach Vu, Huy Hoang Ha",http://arxiv.org/pdf/2410.15316v3,cs.CL
KTCR: Improving Implicit Hate Detection with Knowledge Transfer driven Concept Refinement,"The constant shifts in social and political contexts, driven by emerging
social movements and political events, lead to new forms of hate content and
previously unrecognized hate patterns that machine learning models may not have
captured. Some recent literature proposes data augmentation-based techniques to
enrich existing hate datasets by incorporating samples that reveal new implicit
hate patterns. This approach aims to improve the model's performance on
out-of-domain implicit hate instances. It is observed, that further addition of
more samples for augmentation results in the decrease of the performance of the
model. In this work, we propose a Knowledge Transfer-driven Concept Refinement
method that distills and refines the concepts related to implicit hate samples
through novel prototype alignment and concept losses, alongside data
augmentation based on concept activation vectors. Experiments with several
publicly available datasets show that incorporating additional implicit samples
reflecting new hate patterns through concept refinement enhances the model's
performance, surpassing baseline results while maintaining cross-dataset
generalization capabilities.",2024-10-20,"Samarth Garg, Vivek Hruday Kavuri, Gargi Shroff, Rahul Mishra",http://arxiv.org/pdf/2410.15314v2,cs.CL
Who is Undercover? Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game,"Large Language Models (LLMs) are pivotal AI agents in complex tasks but still
face challenges in open decision-making problems within complex scenarios. To
address this, we use the language logic game ``Who is Undercover?'' (WIU) as an
experimental platform to propose the Multi-Perspective Team Tactic (MPTT)
framework. MPTT aims to cultivate LLMs' human-like language expression logic,
multi-dimensional thinking, and self-perception in complex scenarios. By
alternating speaking and voting sessions, integrating techniques like
self-perspective, identity-determination, self-reflection, self-summary and
multi-round find-teammates, LLM agents make rational decisions through
strategic concealment and communication, fostering human-like trust.
Preliminary results show that MPTT, combined with WIU, leverages LLMs'
cognitive capabilities to create a decision-making framework that can simulate
real society. This framework aids minority groups in communication and
expression, promoting fairness and diversity in decision-making. Additionally,
our Human-in-the-loop experiments demonstrate that LLMs can learn and align
with human behaviors through interactive, indicating their potential for active
participation in societal decision-making.",2024-10-20,"Ruiqi Dong, Zhixuan Liao, Guangwei Lai, Yuhan Ma, Danni Ma, Chenyou Fan",http://arxiv.org/pdf/2410.15311v1,cs.CL
LlamaLens: Specialized Multilingual LLM for Analyzing News and Social Media Content,"Large Language Models (LLMs) have demonstrated remarkable success as
general-purpose task solvers across various fields. However, their capabilities
remain limited when addressing domain-specific problems, particularly in
downstream NLP tasks. Research has shown that models fine-tuned on
instruction-based downstream NLP datasets outperform those that are not
fine-tuned. While most efforts in this area have primarily focused on
resource-rich languages like English and broad domains, little attention has
been given to multilingual settings and specific domains. To address this gap,
this study focuses on developing a specialized LLM, LlamaLens, for analyzing
news and social media content in a multilingual context. To the best of our
knowledge, this is the first attempt to tackle both domain specificity and
multilinguality, with a particular focus on news and social media. Our
experimental setup includes 18 tasks, represented by 52 datasets covering
Arabic, English, and Hindi. We demonstrate that LlamaLens outperforms the
current state-of-the-art (SOTA) on 23 testing sets, and achieves comparable
performance on 8 sets. We make the models and resources publicly available for
the research community
(https://huggingface.co/collections/QCRI/llamalens-672f7e0604a0498c6a2f0fe9).",2024-10-20,"Mohamed Bayan Kmainasi, Ali Ezzat Shahroor, Maram Hasanain, Sahinur Rahman Laskar, Naeemul Hassan, Firoj Alam",http://arxiv.org/pdf/2410.15308v2,cs.CL
Does ChatGPT Have a Poetic Style?,"Generating poetry has become a popular application of LLMs, perhaps
especially of OpenAI's widely-used chatbot ChatGPT. What kind of poet is
ChatGPT? Does ChatGPT have its own poetic style? Can it successfully produce
poems in different styles? To answer these questions, we prompt the GPT-3.5 and
GPT-4 models to generate English-language poems in 24 different poetic forms
and styles, about 40 different subjects, and in response to 3 different writing
prompt templates. We then analyze the resulting 5.7k poems, comparing them to a
sample of 3.7k poems from the Poetry Foundation and the Academy of American
Poets. We find that the GPT models, especially GPT-4, can successfully produce
poems in a range of both common and uncommon English-language forms in
superficial yet noteworthy ways, such as by producing poems of appropriate
lengths for sonnets (14 lines), villanelles (19 lines), and sestinas (39
lines). But the GPT models also exhibit their own distinct stylistic
tendencies, both within and outside of these specific forms. Our results show
that GPT poetry is much more constrained and uniform than human poetry, showing
a strong penchant for rhyme, quatrains (4-line stanzas), iambic meter,
first-person plural perspectives (we, us, our), and specific vocabulary like
""heart,"" ""embrace,"" ""echo,"" and ""whisper.""",2024-10-20,"Melanie Walsh, Anna Preus, Elizabeth Gronski",http://arxiv.org/pdf/2410.15299v2,cs.CL
Redefining Proactivity for Information Seeking Dialogue,"Information-Seeking Dialogue (ISD) agents aim to provide accurate responses
to user queries. While proficient in directly addressing user queries, these
agents, as well as LLMs in general, predominantly exhibit reactive behavior,
lacking the ability to generate proactive responses that actively engage users
in sustained conversations. However, existing definitions of proactive dialogue
in this context do not focus on how each response actively engages the user and
sustains the conversation. Hence, we present a new definition of proactivity
that focuses on enhancing the `proactiveness' of each generated response via
the introduction of new information related to the initial query. To this end,
we construct a proactive dialogue dataset comprising 2,000 single-turn
conversations, and introduce several automatic metrics to evaluate response
`proactiveness' which achieved high correlation with human annotation.
Additionally, we introduce two innovative Chain-of-Thought (CoT) prompts, the
3-step CoT and the 3-in-1 CoT prompts, which consistently outperform standard
prompts by up to 90% in the zero-shot setting.",2024-10-20,"Jing Yang Lee, Seokhwan Kim, Kartik Mehta, Jiun-Yu Kao, Yu-Hsiang Lin, Arpit Gupta",http://arxiv.org/pdf/2410.15297v2,cs.CL
Training Language Models to Critique With Multi-agent Feedback,"Critique ability, a meta-cognitive capability of humans, presents significant
challenges for LLMs to improve. Recent works primarily rely on supervised
fine-tuning (SFT) using critiques generated by a single LLM like GPT-4.
However, these model-generated critiques often exhibit flaws due to the
inherent complexity of the critique. Consequently, fine-tuning LLMs on such
flawed critiques typically limits the model's performance and propagates these
flaws into the learned model. To overcome these challenges, this paper proposes
a novel data generation pipeline, named MultiCritique, that improves the
critique ability of LLMs by utilizing multi-agent feedback in both the SFT and
reinforcement learning (RL) stages. First, our data generation pipeline
aggregates high-quality critiques from multiple agents instead of a single
model, with crucial information as input for simplifying the critique.
Furthermore, our pipeline improves the preference accuracy of critique quality
through multi-agent feedback, facilitating the effectiveness of RL in improving
the critique ability of LLMs. Based on our proposed MultiCritique data
generation pipeline, we construct the MultiCritiqueDataset for the SFT and RL
fine-tuning stages. Extensive experimental results on two benchmarks
demonstrate: 1) the superior quality of our constructed SFT dataset compared to
existing critique datasets; 2) additional improvements to the critique ability
of LLMs brought by the RL stage. Notably, our fine-tuned 7B model significantly
surpasses other advanced 7B-13B open-source models, approaching the performance
of advanced 70B LLMs and GPT-4. Codes, datasets and model weights will be
publicly available.",2024-10-20,"Tian Lan, Wenwei Zhang, Chengqi Lyu, Shuaibin Li, Chen Xu, Heyan Huang, Dahua Lin, Xian-Ling Mao, Kai Chen",http://arxiv.org/pdf/2410.15287v1,cs.CL
"Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Experiments, and Challenges","With the broader usage and highly successful development of Large Language
Models (LLMs), there has been a growth of interest and demand for applying LLMs
to autonomous driving technology. Driven by their natural language
understanding and reasoning ability, LLMs have the potential to enhance various
aspects of autonomous driving systems, from perception and scene understanding
to language interaction and decision-making. In this paper, we first introduce
the novel concept of designing LLMs for autonomous driving (LLM4AD). Then, we
propose a comprehensive benchmark for evaluating the instruction-following
abilities of LLM4AD in simulation. Furthermore, we conduct a series of
experiments on real-world vehicle platforms, thoroughly evaluating the
performance and potential of our LLM4AD systems. Finally, we envision the main
challenges of LLM4AD, including latency, deployment, security and privacy,
safety, trust and transparency, and personalization. Our research highlights
the significant potential of LLMs to enhance various aspects of autonomous
vehicle technology, from perception and scene understanding to language
interaction and decision-making.",2024-10-20,"Can Cui, Yunsheng Ma, Zichong Yang, Yupeng Zhou, Peiran Liu, Juanwu Lu, Lingxi Li, Yaobin Chen, Jitesh H. Panchal, Amr Abdelraouf, Rohit Gupta, Kyungtae Han, Ziran Wang",http://arxiv.org/pdf/2410.15281v3,cs.CL
BRIEF: Bridging Retrieval and Inference for Multi-hop Reasoning via Compression,"Retrieval-augmented generation (RAG) can supplement large language models
(LLMs) by integrating external knowledge. However, as the number of retrieved
documents increases, the input length to LLMs grows linearly, causing a
dramatic increase in latency and a degradation in long-context understanding.
This is particularly serious for multi-hop questions that require a chain of
reasoning across documents. To accelerate inference, reduce costs, and minimize
distractions, this paper presents BRIEF (Bridging Retrieval and Inference
through Evidence Fusion), a lightweight approach that performs query-aware
multi-hop reasoning by compressing retrieved documents into highly dense
textual summaries to integrate into in-context RAG. To enable learning
compression for multi-hop reasoning, we curate synthetic data by extracting
atomic propositions that encapsulate distinct factoids from the source
documents to compose synthetic summaries. Based on our synthetic data built
entirely by open-source models, BRIEF generates more concise summaries and
enables a range of LLMs to achieve exceptional open-domain question answering
(QA) performance. For example, on HotpotQA, BRIEF improves the compression rate
by 2 times compared to the state-of-the-art baseline, while outperforming it by
3.00% EM and 4.16% F1 with Flan-UL2 as the reader model. It also generates more
concise summaries than proprietary GPT-3.5, while demonstrating nearly
identical QA performance.",2024-10-20,"Yuankai Li, Jia-Chen Gu, Di Wu, Kai-Wei Chang, Nanyun Peng",http://arxiv.org/pdf/2410.15277v2,cs.CL
TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models,"Representation learning of Text-Attributed Graphs (TAGs) has garnered
significant attention due to its applications in various domains, including
recommendation systems and social networks. Despite advancements in TAG
learning methodologies, challenges remain in explainability due to the
black-box nature of existing TAG representation learning models. This paper
presents TAGExplainer, the first method designed to generate natural language
explanations for TAG learning. TAGExplainer employs a generative language model
that maps input-output pairs to explanations reflecting the model's
decision-making process. To address the lack of annotated ground truth
explanations in real-world scenarios, we propose first generating pseudo-labels
that capture the model's decisions from saliency-based explanations, then the
pseudo-label generator is iteratively trained based on three training
objectives focusing on faithfulness and brevity via Expert Iteration, to
improve the quality of generated pseudo-labels. The high-quality pseudo-labels
are finally utilized to train an end-to-end explanation generator model.
Extensive experiments are conducted to demonstrate the effectiveness of
TAGExplainer in producing faithful and concise natural language explanations.",2024-10-20,"Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao",http://arxiv.org/pdf/2410.15268v1,cs.CL
When Machine Unlearning Meets Retrieval-Augmented Generation (RAG): Keep Secret or Forget Knowledge?,"The deployment of large language models (LLMs) like ChatGPT and Gemini has
shown their powerful natural language generation capabilities. However, these
models can inadvertently learn and retain sensitive information and harmful
content during training, raising significant ethical and legal concerns. To
address these issues, machine unlearning has been introduced as a potential
solution. While existing unlearning methods take into account the specific
characteristics of LLMs, they often suffer from high computational demands,
limited applicability, or the risk of catastrophic forgetting. To address these
limitations, we propose a lightweight unlearning framework based on
Retrieval-Augmented Generation (RAG) technology. By modifying the external
knowledge base of RAG, we simulate the effects of forgetting without directly
interacting with the unlearned LLM. We approach the construction of unlearned
knowledge as a constrained optimization problem, deriving two key components
that underpin the effectiveness of RAG-based unlearning. This RAG-based
approach is particularly effective for closed-source LLMs, where existing
unlearning methods often fail. We evaluate our framework through extensive
experiments on both open-source and closed-source models, including ChatGPT,
Gemini, Llama-2-7b-chat-hf, and PaLM 2. The results demonstrate that our
approach meets five key unlearning criteria: effectiveness, universality,
harmlessness, simplicity, and robustness. Meanwhile, this approach can extend
to multimodal large language models and LLM-based agents.",2024-10-20,"Shang Wang, Tianqing Zhu, Dayong Ye, Wanlei Zhou",http://arxiv.org/pdf/2410.15267v1,cs.CL
Back to School: Translation Using Grammar Books,"Machine translation systems for high resource languages perform exceptionally
well and produce high quality translations. Unfortunately, the vast majority of
languages are not considered high resource and lack the quantity of parallel
sentences needed to train such systems. These under-represented languages are
not without resources, however, and bilingual dictionaries and grammar books
are available as linguistic reference material. With current large language
models (LLMs) supporting near book-length contexts, we can begin to use the
available material to ensure advancements are shared among all of the world's
languages. In this paper, we demonstrate incorporating grammar books in the
prompt of GPT-4 to improve machine translation and evaluate the performance on
16 topologically diverse low-resource languages, using a combination of
reference material to show that the machine translation performance of LLMs can
be improved using this method.",2024-10-20,"Jonathan Hus, Antonios Anastasopoulos",http://arxiv.org/pdf/2410.15263v1,cs.CL
Lossless KV Cache Compression to 2%,"Large language models have revolutionized data processing in numerous
domains, with their ability to handle extended context reasoning receiving
notable recognition. To speed up inference, maintaining a key-value (KV) cache
memory is essential. Nonetheless, the growing demands for KV cache memory
create significant hurdles for efficient implementation. This work introduces a
novel architecture, Cross-Layer Latent Attention (CLLA), aimed at compressing
the KV cache to less than 2% of its original size while maintaining comparable
performance levels. CLLA integrates multiple aspects of KV cache compression,
including attention head/dimension reduction, layer sharing, and quantization
techniques, into a cohesive framework. Our extensive experiments demonstrate
that CLLA achieves lossless performance on most tasks while utilizing minimal
KV cache, marking a significant advancement in practical KV cache compression.",2024-10-20,"Zhen Yang, J. N. Han, Kan Wu, Ruobing Xie, An Wang, Xingwu Sun, Zhanhui Kang",http://arxiv.org/pdf/2410.15252v1,cs.CL
On the Diversity of Synthetic Data and its Impact on Training Large Language Models,"The rise of Large Language Models (LLMs) has accentuated the need for
diverse, high-quality pre-training data. Synthetic data emerges as a viable
solution to the challenges of data scarcity and inaccessibility. While previous
literature has focused predominantly on the quality and quantity of real data,
our work enables the measurement of diversity in synthetic data and explores
its impact on LLM performance. We study the downstream effects of synthetic
data diversity during both the pre-training and fine-tuning stages by
introducing a new diversity metric, \textit{LLM cluster-agent}, designed to
evaluate the diversity of synthetic datasets. Through a series of controlled
experiments with models of 350M and 1.4B parameters, we demonstrate that the
proposed cluster-based LLM scoring of diversity correlates positively with both
pre-training and supervised fine-tuning performance. Our findings also reveal
that synthetic data diversity in pre-training affects supervised fine-tuning
more significantly than pre-training itself, even for smaller models. We hope
this study advances our understanding of the optimal use of synthetic data in
LLM training and opens new avenues for efficient data generation processes.",2024-10-19,"Hao Chen, Abdul Waheed, Xiang Li, Yidong Wang, Jindong Wang, Bhiksha Raj, Marah I. Abdin",http://arxiv.org/pdf/2410.15226v2,cs.CL
Chasing Random: Instruction Selection Strategies Fail to Generalize,"Prior work has shown that language models can be tuned to follow user
instructions using only a small set of high-quality instructions. This has
accelerated the development of methods that filter a large, noisy
instruction-tuning datasets down to high-quality subset which works just as
well. However, typically, the performance of these methods is not demonstrated
across a uniform experimental setup and thus their generalization capabilities
are not well established. In this work, we analyze popular selection strategies
across different source datasets, selection budgets and evaluation benchmarks:
Our results indicate that selection strategies generalize poorly, often failing
to consistently outperform even random baselines. We also analyze the
cost-performance trade-offs of using data selection. Our findings reveal that
data selection can often exceed the cost of fine-tuning on the full dataset,
yielding only marginal and sometimes no gains compared to tuning on the full
dataset or a random subset.",2024-10-19,"Harshita Diddee, Daphne Ippolito",http://arxiv.org/pdf/2410.15225v1,cs.CL
Fine-tuning foundational models to code diagnoses from veterinary health records,"Veterinary medical records represent a large data resource for application to
veterinary and One Health clinical research efforts. Use of the data is limited
by interoperability challenges including inconsistent data formats and data
siloing. Clinical coding using standardized medical terminologies enhances the
quality of medical records and facilitates their interoperability with
veterinary and human health records from other sites. Previous studies, such as
DeepTag and VetTag, evaluated the application of Natural Language Processing
(NLP) to automate veterinary diagnosis coding, employing long short-term memory
(LSTM) and transformer models to infer a subset of Systemized Nomenclature of
Medicine - Clinical Terms (SNOMED-CT) diagnosis codes from free-text clinical
notes. This study expands on these efforts by incorporating all 7,739 distinct
SNOMED-CT diagnosis codes recognized by the Colorado State University (CSU)
Veterinary Teaching Hospital (VTH) and by leveraging the increasing
availability of pre-trained large language models (LLMs). Ten freely-available
pre-trained LLMs were fine-tuned on the free-text notes from 246,473
manually-coded veterinary patient visits included in the CSU VTH's electronic
health records (EHRs), which resulted in superior performance relative to
previous efforts. The most accurate results were obtained when expansive
labeled data were used to fine-tune relatively large clinical LLMs, but the
study also showed that comparable results can be obtained using more limited
resources and non-clinical LLMs. The results of this study contribute to the
improvement of the quality of veterinary EHRs by investigating accessible
methods for automated coding and support both animal and human health research
by paving the way for more integrated and comprehensive health databases that
span species and institutions.",2024-10-19,"Mayla R. Boguslav, Adam Kiehl, David Kott, G. Joseph Strecker, Tracy Webb, Nadia Saklou, Terri Ward, Michael Kirby",http://arxiv.org/pdf/2410.15186v1,cs.CL
The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse,"The ability for individuals to constructively engage with one another across
lines of difference is a critical feature of a healthy pluralistic society.
This is also true in online discussion spaces like social media platforms. To
date, much social media research has focused on preventing ills -- like
political polarization and the spread of misinformation. While this is
important, enhancing the quality of online public discourse requires not just
reducing ills but also promoting foundational human virtues. In this study, we
focus on one particular virtue: ``intellectual humility'' (IH), or
acknowledging the potential limitations in one's own beliefs. Specifically, we
explore the development of computational methods for measuring IH at scale. We
manually curate and validate an IH codebook on 350 posts about religion drawn
from subreddits and use them to develop LLM-based models for automating this
measurement. Our best model achieves a Macro-F1 score of 0.64 across labels
(and 0.70 when predicting IH/IA/Neutral at the coarse level), higher than an
expected naive baseline of 0.51 (0.32 for IH/IA/Neutral) but lower than a human
annotator-informed upper bound of 0.85 (0.83 for IH/IA/Neutral). Our results
both highlight the challenging nature of detecting IH online -- opening the
door to new directions in NLP research -- and also lay a foundation for
computational social science researchers interested in analyzing and fostering
more IH in online public discourse.",2024-10-19,"Xiaobo Guo, Neil Potnis, Melody Yu, Nabeel Gillani, Soroush Vosoughi",http://arxiv.org/pdf/2410.15182v1,cs.CL
Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation,"The thematic fit estimation task measures the compatibility between a
predicate (typically a verb), an argument (typically a noun phrase), and a
specific semantic role assigned to the argument. Previous state-of-the-art work
has focused on modeling thematic fit through distributional or neural models of
event representation, trained in a supervised fashion with indirect labels. In
this work, we assess whether pre-trained autoregressive LLMs possess
consistent, expressible knowledge about thematic fit. We evaluate both closed
and open state-of-the-art LLMs on several psycholinguistic datasets, along
three axes: (1) Reasoning Form: multi-step logical reasoning (chain-of-thought
prompting) vs. simple prompting. (2) Input Form: providing context (generated
sentences) vs. raw tuples <predicate, argument, role>. (3) Output Form:
categorical vs. numeric. Our results show that chain-of-thought reasoning is
more effective on datasets with self-explanatory semantic role labels,
especially Location. Generated sentences helped only in few settings, and
lowered results in many others. Predefined categorical (compared to numeric)
output raised GPT's results across the board with few exceptions, but lowered
Llama's. We saw that semantically incoherent generated sentences, which the
models lack the ability to consistently filter out, hurt reasoning and overall
performance too. Our GPT-powered methods set new state-of-the-art on all tested
datasets.",2024-10-19,"Safeyah Khaled Alshemali, Daniel Bauer, Yuval Marton",http://arxiv.org/pdf/2410.15173v1,cs.CL
An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making,"Modern large language models (LLMs) have exhibited cooperative synergy on
complex task-solving, and collective decision-making (CDM) is a pivotal
component in LLM-based multi-agent collaboration frameworks. Our survey on 52
recent such systems uncovers a severe lack of diversity, with a heavy reliance
on dictatorial and plurality voting for CDM. Through the lens of social choice
theory, we scrutinize widely-adopted CDM methods and identify their
limitations. To enrich current landscape of LLM-based CDM, we present GEDI, an
electoral CDM module that incorporates various ordinal preferential voting
mechanisms. Our empirical case study across three benchmarks shows that the
integration of certain CDM methods can markedly improve the reasoning
capabilities and robustness of some leading LLMs, all without requiring
intricate system designs. Additionally, we find that some CDM mechanisms
generate positive synergies even with as few as three agents. The voting-based
methods also demonstrate robustness against single points of failure, as well
as diversity in terms of hit-rate@k and subject-wise impacts.",2024-10-19,"Xiutian Zhao, Ke Wang, Wei Peng",http://arxiv.org/pdf/2410.15168v1,cs.CL
Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction,"In recent years, Graph Neural Networks (GNNs) have become successful in
molecular property prediction tasks such as toxicity analysis. However, due to
the black-box nature of GNNs, their outputs can be concerning in high-stakes
decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph
Counterfactual Explanation (GCE) has emerged as a promising approach to improve
GNN transparency. However, current GCE methods usually fail to take
domain-specific knowledge into consideration, which can result in outputs that
are not easily comprehensible by humans. To address this challenge, we propose
a novel GCE method, LLM-GCE, to unleash the power of large language models
(LLMs) in explaining GNNs for molecular property prediction. Specifically, we
utilize an autoencoder to generate the counterfactual graph topology from a set
of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also
incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which
provides intermediate feedback derived from the generated counterfactuals as an
attempt to give more faithful guidance. Extensive experiments demonstrate the
superior performance of LLM-GCE. Our code is released on
https://github.com/YinhanHe123/new\_LLM4GNNExplanation.",2024-10-19,"Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li",http://arxiv.org/pdf/2410.15165v1,cs.CL
Evaluation Of P300 Speller Performance Using Large Language Models Along With Cross-Subject Training,"Amyotrophic lateral sclerosis (ALS), a progressive neuromuscular degenerative
disease, severely restricts patient communication capacity within a few years
of onset, resulting in a significant deterioration of quality of life. The P300
speller brain computer interface (BCI) offers an alternative communication
medium by leveraging a subject's EEG response to characters traditionally
highlighted on a character grid on a graphical user interface (GUI). A
recurring theme in P300-based research is enhancing performance to enable
faster subject interaction. This study builds on that theme by addressing key
limitations, particularly in the training of multi-subject classifiers, and by
integrating advanced language models to optimize stimuli presentation and word
prediction, thereby improving communication efficiency. Furthermore, various
advanced large language models such as Generative Pre-Trained Transformer
(GPT2), BERT, and BART, alongside Dijkstra's algorithm, are utilized to
optimize stimuli and provide word completion choices based on the spelling
history. In addition, a multi-layered smoothing approach is applied to allow
for out-of-vocabulary (OOV) words. By conducting extensive simulations based on
randomly sampled EEG data from subjects, we show substantial speed improvements
in typing passages that include rare and out-of-vocabulary (OOV) words, with
the extent of improvement varying depending on the language model utilized. The
gains through such character-level interface optimizations are approximately
10%, and GPT2 for multi-word prediction provides gains of around 40%. In
particular, some large language models achieve performance levels within 10% of
the theoretical performance limits established in this study. In addition, both
within and across subjects, training techniques are explored, and speed
improvements are shown to hold in both cases.",2024-10-19,"Nithin Parthasarathy, James Soetedjo, Saarang Panchavati, Nitya Parthasarathy, Corey Arnold, Nader Pouratian, William Speier",http://arxiv.org/pdf/2410.15161v1,cs.CL
Evaluating Deep Unlearning in Large Language Models,"Machine unlearning is a key requirement of many data protection regulations
such as GDPR. Prior work on unlearning has mostly considered superficial
unlearning tasks where a single or a few related pieces of information are
required to be removed. However, the task of unlearning a fact is much more
challenging in recent large language models (LLMs), because the facts in LLMs
can be deduced from each other. In this work, we investigate whether current
unlearning methods for LLMs succeed beyond superficial unlearning of facts.
Specifically, we formally propose a framework and a definition for deep
unlearning facts that are interrelated. We design the metric, recall, to
quantify the extent of deep unlearning. To systematically evaluate deep
unlearning, we construct a synthetic dataset EDU-RELAT, which consists of a
synthetic knowledge base of family relationships and biographies, together with
a realistic logical rule set that connects them. We use this dataset to test
four unlearning methods in four LLMs at different sizes. Our findings reveal
that in the task of deep unlearning only a single fact, they either fail to
properly unlearn with high recall, or end up unlearning many other irrelevant
facts. Our dataset and code are publicly available at:
https://github.com/wrh14/deep_unlearning.",2024-10-19,"Ruihan Wu, Chhavi Yadav, Russ Salakhutdinov, Kamalika Chaudhuri",http://arxiv.org/pdf/2410.15153v3,cs.CL
Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning,"Intermediate task transfer learning can greatly improve model performance.
If, for example, one has little training data for emotion detection, first
fine-tuning a language model on a sentiment classification dataset may improve
performance strongly. But which task to choose for transfer learning? Prior
methods producing useful task rankings are infeasible for large source pools,
as they require forward passes through all source language models. We overcome
this by introducing Embedding Space Maps (ESMs), light-weight neural networks
that approximate the effect of fine-tuning a language model. We conduct the
largest study on NLP task transferability and task selection with 12k
source-target pairs. We find that applying ESMs on a prior method reduces
execution time and disk space usage by factors of 10 and 278, respectively,
while retaining high selection performance (avg. regret@5 score of 2.95).",2024-10-19,"David Schulte, Felix Hamborg, Alan Akbik",http://arxiv.org/pdf/2410.15148v1,cs.CL
A survey of neural-network-based methods utilising comparable data for finding translation equivalents,"The importance of inducing bilingual dictionary components in many natural
language processing (NLP) applications is indisputable. However, the dictionary
compilation process requires extensive work and combines two disciplines, NLP
and lexicography, while the former often omits the latter. In this paper, we
present the most common approaches from NLP that endeavour to automatically
induce one of the essential dictionary components, translation equivalents and
focus on the neural-network-based methods using comparable data. We analyse
them from a lexicographic perspective since their viewpoints are crucial for
improving the described methods. Moreover, we identify the methods that
integrate these viewpoints and can be further exploited in various applications
that require them. This survey encourages a connection between the NLP and
lexicography fields as the NLP field can benefit from lexicographic insights,
and it serves as a helping and inspiring material for further research in the
context of neural-network-based methods utilising comparable data.",2024-10-19,"Michaela Denisová, Pavel Rychlý",http://arxiv.org/pdf/2410.15144v1,cs.CL
CAST: Corpus-Aware Self-similarity Enhanced Topic modelling,"Topic modelling is a pivotal unsupervised machine learning technique for
extracting valuable insights from large document collections. Existing neural
topic modelling methods often encode contextual information of documents, while
ignoring contextual details of candidate centroid words, leading to the
inaccurate selection of topic words due to the contextualization gap. In
parallel, it is found that functional words are frequently selected over
topical words. To address these limitations, we introduce CAST: Corpus-Aware
Self-similarity Enhanced Topic modelling, a novel topic modelling method that
builds upon candidate centroid word embeddings contextualized on the dataset,
and a novel self-similarity-based method to filter out less meaningful tokens.
Inspired by findings in contrastive learning that self-similarities of
functional token embeddings in different contexts are much lower than topical
tokens, we find self-similarity to be an effective metric to prevent functional
words from acting as candidate topic words. Our approach significantly enhances
the coherence and diversity of generated topics, as well as the topic model's
ability to handle noisy data. Experiments on news benchmark datasets and one
Twitter dataset demonstrate the method's superiority in generating coherent,
diverse topics, and handling noisy data, outperforming strong baselines.",2024-10-19,"Yanan Ma, Chenghao Xiao, Chenhan Yuan, Sabine N van der Veer, Lamiece Hassan, Chenghua Lin, Goran Nenadic",http://arxiv.org/pdf/2410.15136v2,cs.CL
TrendFact: A Benchmark for Explainable Hotspot Perception in Fact-Checking with Natural Language Explanation,"Although fact verification remains fundamental, explanation generation serves
as a critical enabler for trustworthy fact-checking systems by producing
interpretable rationales and facilitating comprehensive verification processes.
However, current benchmarks have limitations that include the lack of impact
assessment, insufficient high-quality explanatory annotations, and an
English-centric bias. To address these, we introduce TrendFact, the first
hotspot perception fact-checking benchmark that comprehensively evaluates fact
verification, evidence retrieval, and explanation generation tasks. TrendFact
consists of 7,643 carefully curated samples sourced from trending platforms and
professional fact-checking datasets, as well as an evidence library of 66,217
entries with publication dates. We further propose two metrics, ECS and HCPI,
to complement existing benchmarks by evaluating the system's explanation
consistency and hotspot perception capability, respectively. Experimental
results show that current fact-checking systems, including advanced RLMs such
as DeepSeek-R1, face significant limitations when evaluated on TrendFact,
highlighting the real-world challenges posed by it. To enhance the
fact-checking capabilities of reasoning large language models (RLMs), we
propose FactISR, which integrates dynamic evidence augmentation, evidence
triangulation, and an iterative self-reflection mechanism. Accordingly, FactISR
effectively improves RLM performance, offering new insights for explainable and
complex fact-checking.",2024-10-19,"Xiaocheng Zhang, Xi Wang, Yifei Lu, Jianing Wang, Zhuangzhuang Ye, Mengjiao Bao, Peng Yan, Xiaohong Su",http://arxiv.org/pdf/2410.15135v3,cs.CL
MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science,"We introduce a novel continued pre-training method, MELT (MatEriaLs-aware
continued pre-Training), specifically designed to efficiently adapt the
pre-trained language models (PLMs) for materials science. Unlike previous
adaptation strategies that solely focus on constructing domain-specific corpus,
MELT comprehensively considers both the corpus and the training strategy, given
that materials science corpus has distinct characteristics from other domains.
To this end, we first construct a comprehensive materials knowledge base from
the scientific corpus by building semantic graphs. Leveraging this extracted
knowledge, we integrate a curriculum into the adaptation process that begins
with familiar and generalized concepts and progressively moves toward more
specialized terms. We conduct extensive experiments across diverse benchmarks
to verify the effectiveness and generality of MELT. A comprehensive evaluation
convincingly supports the strength of MELT, demonstrating superior performance
compared to existing continued pre-training methods. The in-depth analysis also
shows that MELT enables PLMs to effectively represent materials entities
compared to the existing adaptation methods, thereby highlighting its broad
applicability across a wide spectrum of materials science.",2024-10-19,"Junho Kim, Yeachan Kim, Jun-Hyung Park, Yerim Oh, Suho Kim, SangKeun Lee",http://arxiv.org/pdf/2410.15126v1,cs.CL
Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models,"Generation of plausible but incorrect factual information, often termed
hallucination, has attracted significant research interest. Retrieval-augmented
language model (RALM) -- which enhances models with up-to-date knowledge --
emerges as a promising method to reduce hallucination. However, existing RALMs
may instead exacerbate hallucination when retrieving lengthy contexts. To
address this challenge, we propose COFT, a novel
\textbf{CO}arse-to-\textbf{F}ine highligh\textbf{T}ing method to focus on
different granularity-level key texts, thereby avoiding getting lost in lengthy
contexts. Specifically, COFT consists of three components: \textit{recaller},
\textit{scorer}, and \textit{selector}. First, \textit{recaller} applies a
knowledge graph to extract potential key entities in a given context. Second,
\textit{scorer} measures the importance of each entity by calculating its
contextual weight. Finally, \textit{selector} selects high contextual weight
entities with a dynamic threshold algorithm and highlights the corresponding
paragraphs, sentences, or words in a coarse-to-fine manner. Extensive
experiments on the knowledge hallucination benchmark demonstrate the
effectiveness of COFT, leading to a superior performance over $30\%$ in the F1
score metric. Moreover, COFT also exhibits remarkable versatility across
various long-form tasks, such as reading comprehension and question answering.",2024-10-19,"Qitan Lv, Jie Wang, Hanzhu Chen, Bin Li, Yongdong Zhang, Feng Wu",http://arxiv.org/pdf/2410.15116v1,cs.CL
On Designing Effective RL Reward at Training Time for LLM Reasoning,"Reward models have been increasingly critical for improving the reasoning
capability of LLMs. Existing research has shown that a well-trained reward
model can substantially improve model performances at inference time via
search. However, the potential of reward models during RL training time still
remains largely under-explored. It is currently unclear whether these reward
models can provide additional training signals to enhance the reasoning
capabilities of LLMs in RL training that uses sparse success rewards, which
verify the correctness of solutions. In this work, we evaluate popular reward
models for RL training, including the Outcome-supervised Reward Model (ORM) and
the Process-supervised Reward Model (PRM), and train a collection of LLMs for
math problems using RL by combining these learned rewards with success rewards.
Surprisingly, even though these learned reward models have strong
inference-time performances, they may NOT help or even hurt RL training,
producing worse performances than LLMs trained with the success reward only.
Our analysis reveals that an LLM can receive high rewards from some of these
reward models by repeating correct but unnecessary reasoning steps, leading to
a severe reward hacking issue. Therefore, we introduce two novel reward
refinement techniques, including Clipping and Delta. The key idea is to ensure
the accumulative reward of any reasoning trajectory is upper-bounded to keep a
learned reward model effective without being exploited. We evaluate our
techniques with multiple reward models over a set of 1.5B and 7B LLMs on MATH
and GSM8K benchmarks and demonstrate that with a carefully designed reward
function, RL training without any additional supervised tuning can improve all
the evaluated LLMs, including the state-of-the-art 7B LLM
Qwen2.5-Math-7B-Instruct on MATH and GSM8K benchmarks.",2024-10-19,"Jiaxuan Gao, Shusheng Xu, Wenjie Ye, Weilin Liu, Chuyi He, Wei Fu, Zhiyu Mei, Guangju Wang, Yi Wu",http://arxiv.org/pdf/2410.15115v3,cs.CL
Toward Robust RALMs: Revealing the Impact of Imperfect Retrieval on Retrieval-Augmented Language Models,"Retrieval Augmented Language Models (RALMs) have gained significant attention
for their ability to generate accurate answer and improve efficiency. However,
RALMs are inherently vulnerable to imperfect information due to their reliance
on the imperfect retriever or knowledge source. We identify three common
scenarios-unanswerable, adversarial, conflicting-where retrieved document sets
can confuse RALM with plausible real-world examples. We present the first
comprehensive investigation to assess how well RALMs detect and handle such
problematic scenarios. Among these scenarios, to systematically examine
adversarial robustness we propose a new adversarial attack method, Generative
model-based ADVersarial attack (GenADV) and a novel metric Robustness under
Additional Document (RAD). Our findings reveal that RALMs often fail to
identify the unanswerability or contradiction of a document set, which
frequently leads to hallucinations. Moreover, we show the addition of an
adversary significantly degrades RALM's performance, with the model becoming
even more vulnerable when the two scenarios overlap (adversarial+unanswerable).
Our research identifies critical areas for assessing and enhancing the
robustness of RALMs, laying the foundation for the development of more robust
models.",2024-10-19,"Seong-Il Park, Jay-Yoon Lee",http://arxiv.org/pdf/2410.15107v1,cs.CL
Towards Safer Heuristics With XPlain,"Many problems that cloud operators solve are computationally expensive, and
operators often use heuristic algorithms (that are faster and scale better than
optimal) to solve them more efficiently. Heuristic analyzers enable operators
to find when and by how much their heuristics underperform. However, these
tools do not provide enough detail for operators to mitigate the heuristic's
impact in practice: they only discover a single input instance that causes the
heuristic to underperform (and not the full set), and they do not explain why.
  We propose XPlain, a tool that extends these analyzers and helps operators
understand when and why their heuristics underperform. We present promising
initial results that show such an extension is viable.",2024-10-19,"Pantea Karimi, Solal Pirelli, Siva Kesava Reddy Kakarla, Ryan Beckett, Santiago Segarra, Beibin Li, Pooria Namyar, Behnaz Arzani",http://arxiv.org/pdf/2410.15086v1,cs.CL
End-to-End Transformer-based Automatic Speech Recognition for Northern Kurdish: A Pioneering Approach,"Automatic Speech Recognition (ASR) for low-resource languages remains a
challenging task due to limited training data. This paper introduces a
comprehensive study exploring the effectiveness of Whisper, a pre-trained ASR
model, for Northern Kurdish (Kurmanji) an under-resourced language spoken in
the Middle East. We investigate three fine-tuning strategies: vanilla, specific
parameters, and additional modules. Using a Northern Kurdish fine-tuning speech
corpus containing approximately 68 hours of validated transcribed data, our
experiments demonstrate that the additional module fine-tuning strategy
significantly improves ASR accuracy on a specialized test set, achieving a Word
Error Rate (WER) of 10.5% and Character Error Rate (CER) of 5.7% with Whisper
version 3. These results underscore the potential of sophisticated transformer
models for low-resource ASR and emphasize the importance of tailored
fine-tuning techniques for optimal performance.",2024-10-19,"Abdulhady Abas Abdullah, Shima Tabibian, Hadi Veisi, Aso Mahmudi, Tarik Rashid",http://arxiv.org/pdf/2410.16330v1,cs.CL
Weakly-supervised diagnosis identification from Italian discharge letters,"Objective: Recognizing diseases from discharge letters is crucial for cohort
selection and epidemiological analyses, as this is the only type of data
consistently produced across hospitals. This is a classic document
classification problem, typically requiring supervised learning. However,
manual annotation of large datasets of discharge letters is uncommon since it
is extremely time-consuming. We propose a novel weakly-supervised pipeline to
recognize diseases from Italian discharge letters. Methods: Our Natural
Language Processing pipeline is based on a fine-tuned version of the Italian
Umberto model. The pipeline extracts diagnosis-related sentences from a subset
of letters and applies a two-level clustering using the embeddings generated by
the fine-tuned Umberto model. These clusters are summarized and those mapped to
the diseases of interest are selected as weak labels. Finally, the same
BERT-based model is trained using these weak labels to detect the targeted
diseases. Results: A case study related to the identification of bronchiolitis
with 33'176 Italian discharge letters from 44 hospitals in the Veneto Region
shows the potential of our method, with an AUC of 77.7 % and an F1-Score of
75.1 % on manually annotated labels, improving compared to other non-supervised
methods and with a limited loss compared to fully supervised methods. Results
are robust to the cluster selection and the identified clusters highlight the
potential to recognize a variety of diseases. Conclusions: This study
demonstrates the feasibility of diagnosis identification from Italian discharge
letters in the absence of labelled data. Our pipeline showed strong performance
and robustness, and its flexibility allows for easy adaptation to various
diseases. This approach offers a scalable solution for clinical text
classification, reducing the need for manual annotation while maintaining good
accuracy.",2024-10-19,"Vittorio Torri, Elisa Barbieri, Anna Cantarutti, Carlo Giaquinto, Francesca Ieva",http://arxiv.org/pdf/2410.15051v1,cs.CL
Are LLMs Good Zero-Shot Fallacy Classifiers?,"Fallacies are defective arguments with faulty reasoning. Detecting and
classifying them is a crucial NLP task to prevent misinformation, manipulative
claims, and biased decisions. However, existing fallacy classifiers are limited
by the requirement for sufficient labeled data for training, which hinders
their out-of-distribution (OOD) generalization abilities. In this paper, we
focus on leveraging Large Language Models (LLMs) for zero-shot fallacy
classification. To elicit fallacy-related knowledge and reasoning abilities of
LLMs, we propose diverse single-round and multi-round prompting schemes,
applying different task-specific instructions such as extraction,
summarization, and Chain-of-Thought reasoning. With comprehensive experiments
on benchmark datasets, we suggest that LLMs could be potential zero-shot
fallacy classifiers. In general, LLMs under single-round prompting schemes have
achieved acceptable zero-shot performances compared to the best full-shot
baselines and can outperform them in all OOD inference scenarios and some
open-domain tasks. Our novel multi-round prompting schemes can effectively
bring about more improvements, especially for small LLMs. Our analysis further
underlines the future research on zero-shot fallacy classification. Codes and
data are available at: https://github.com/panFJCharlotte98/Fallacy_Detection.",2024-10-19,"Fengjun Pan, Xiaobao Wu, Zongrui Li, Anh Tuan Luu",http://arxiv.org/pdf/2410.15050v1,cs.CL
mHumanEval -- A Multilingual Benchmark to Evaluate Large Language Models for Code Generation,"Recent advancements in large language models (LLMs) have significantly
enhanced code generation from natural language prompts. The HumanEval
Benchmark, developed by OpenAI, remains the most widely used code generation
benchmark. However, this and other Code LLM benchmarks face critical
limitations, particularly in task diversity, test coverage, and linguistic
scope. Current evaluations primarily focus on English-to-Python conversion
tasks with limited test cases, potentially overestimating model performance.
While recent works have addressed test coverage and programming language (PL)
diversity, code generation from low-resource language prompts remains largely
unexplored. To address this gap, we introduce mHumanEval, an extended benchmark
supporting prompts in over 200 natural languages. We employ established machine
translation methods to compile the benchmark, coupled with a quality assurance
process. Furthermore, we provide expert human translations for 15 diverse
natural languages (NLs). We conclude by analyzing the multilingual code
generation capabilities of state-of-the-art (SOTA) Code LLMs, offering insights
into the current landscape of cross-lingual code generation.",2024-10-19,"Nishat Raihan, Antonios Anastasopoulos, Marcos Zampieri",http://arxiv.org/pdf/2410.15037v2,cs.CL
Improving General Text Embedding Model: Tackling Task Conflict and Data Imbalance through Model Merging,"Text embeddings are vital for tasks such as text retrieval and semantic
textual similarity (STS). Recently, the advent of pretrained language models,
along with unified benchmarks like the Massive Text Embedding Benchmark (MTEB),
has facilitated the development of versatile general-purpose text embedding
models. Advanced embedding models are typically developed using large-scale
multi-task data and joint training across multiple tasks. However, our
experimental analysis reveals two significant drawbacks of joint training: 1)
Task Conflict: Gradients from different tasks interfere with each other,
leading to negative transfer. 2) Data Imbalance: Disproportionate data
distribution introduces biases that negatively impact performance across tasks.
To overcome these challenges, we explore model merging-a technique that
combines independently trained models to mitigate gradient conflicts and
balance data distribution. We introduce a novel method, Self Positioning, which
efficiently searches for optimal model combinations within the interpolation
space of task vectors using stochastic gradient descent. Our experiments
demonstrate that Self Positioning significantly enhances multi-task performance
on the MTEB dataset, achieving an absolute improvement of 0.7 points. It
outperforms traditional resampling methods while reducing computational costs.
This work offers a robust approach to building generalized text embedding
models with superior performance across diverse embedding-related tasks.",2024-10-19,"Mingxin Li, Zhijie Nie, Yanzhao Zhang, Dingkun Long, Richong Zhang, Pengjun Xie",http://arxiv.org/pdf/2410.15035v1,cs.CL
Enhancing Multimodal Sentiment Analysis for Missing Modality through Self-Distillation and Unified Modality Cross-Attention,"In multimodal sentiment analysis, collecting text data is often more
challenging than video or audio due to higher annotation costs and inconsistent
automatic speech recognition (ASR) quality. To address this challenge, our
study has developed a robust model that effectively integrates multimodal
sentiment information, even in the absence of text modality. Specifically, we
have developed a Double-Flow Self-Distillation Framework, including Unified
Modality Cross-Attention (UMCA) and Modality Imagination Autoencoder (MIA),
which excels at processing both scenarios with complete modalities and those
with missing text modality. In detail, when the text modality is missing, our
framework uses the LLM-based model to simulate the text representation from the
audio modality, while the MIA module supplements information from the other two
modalities to make the simulated text representation similar to the real text
representation. To further align the simulated and real representations, and to
enable the model to capture the continuous nature of sample orders in sentiment
valence regression tasks, we have also introduced the Rank-N Contrast (RNC)
loss function. When testing on the CMU-MOSEI, our model achieved outstanding
performance on MAE and significantly outperformed other models when text
modality is missing. The code is available at:
https://github.com/WarmCongee/SDUMC",2024-10-19,"Yuzhe Weng, Haotian Wang, Tian Gao, Kewei Li, Shutong Niu, Jun Du",http://arxiv.org/pdf/2410.15029v2,cs.CL
Theoretical Aspects of Bias and Diversity in Minimum Bayes Risk Decoding,"Text generation commonly relies on greedy and beam decoding that limit the
search space and degrade output quality. Minimum Bayes Risk (MBR) decoding can
mitigate this problem by utilizing automatic evaluation metrics and
model-generated pseudo-references. Previous studies have conducted empirical
analyses to reveal the improvement by MBR decoding, and reported various
observations. However, despite these observations, the theoretical relationship
between them remains uncertain. To address this, we present a novel theoretical
interpretation of MBR decoding from the perspective of bias-diversity
decomposition. We decompose errors in the estimated quality of generated
hypotheses in MBR decoding into two key factors: bias, which reflects the
closeness between utility functions and human evaluations, and diversity, which
represents the variation in the estimated quality of utility functions. Our
theoretical analysis reveals the difficulty in simultaneously improving both
bias and diversity, and highlights the effectiveness of increasing diversity to
enhance MBR decoding performance. This analysis verifies the alignment between
our theoretical insights and the empirical results reported in previous work.
Furthermore, to support our theoretical findings, we propose a new metric,
pseudo-bias, which approximates the bias term using gold references. We also
introduce a new MBR approach, Metric-augmented MBR (MAMBR), which increases
diversity by adjusting the behavior of utility functions without altering the
pseudo-references. Experimental results across multiple NLP tasks show that the
decomposed terms in the bias-diversity decomposition correlate well with
performance, and that MAMBR improves text generation quality by modifying
utility function behavior. Our code will be available at
https://github.com/naist-nlp/mbr-bias-diversity.",2024-10-19,"Hidetaka Kamigaito, Hiroyuki Deguchi, Yusuke Sakai, Katsuhiko Hayashi, Taro Watanabe",http://arxiv.org/pdf/2410.15021v1,cs.CL
A Survey of Ontology Expansion for Conversational Understanding,"In the rapidly evolving field of conversational AI, Ontology Expansion
(OnExp) is crucial for enhancing the adaptability and robustness of
conversational agents. Traditional models rely on static, predefined
ontologies, limiting their ability to handle new and unforeseen user needs.
This survey paper provides a comprehensive review of the state-of-the-art
techniques in OnExp for conversational understanding. It categorizes the
existing literature into three main areas: (1) New Intent Discovery, (2) New
Slot-Value Discovery, and (3) Joint OnExp. By examining the methodologies,
benchmarks, and challenges associated with these areas, we highlight several
emerging frontiers in OnExp to improve agent performance in real-world
scenarios and discuss their corresponding challenges. This survey aspires to be
a foundational reference for researchers and practitioners, promoting further
exploration and innovation in this crucial domain.",2024-10-19,"Jinggui Liang, Yuxia Wu, Yuan Fang, Hao Fei, Lizi Liao",http://arxiv.org/pdf/2410.15019v1,cs.CL
DM-Codec: Distilling Multimodal Representations for Speech Tokenization,"Recent advancements in speech-language models have yielded significant
improvements in speech tokenization and synthesis. However, effectively mapping
the complex, multidimensional attributes of speech into discrete tokens remains
challenging. This process demands acoustic, semantic, and contextual
information for precise speech representations. Existing speech representations
generally fall into two categories: acoustic tokens from audio codecs and
semantic tokens from speech self-supervised learning models. Although recent
efforts have unified acoustic and semantic tokens for improved performance,
they overlook the crucial role of contextual representation in comprehensive
speech modeling. Our empirical investigations reveal that the absence of
contextual representations results in elevated Word Error Rate (WER) and Word
Information Lost (WIL) scores in speech transcriptions. To address these
limitations, we propose two novel distillation approaches: (1) a language model
(LM)-guided distillation method that incorporates contextual information, and
(2) a combined LM and self-supervised speech model (SM)-guided distillation
technique that effectively distills multimodal representations (acoustic,
semantic, and contextual) into a comprehensive speech tokenizer, termed
DM-Codec. The DM-Codec architecture adopts a streamlined encoder-decoder
framework with a Residual Vector Quantizer (RVQ) and incorporates the LM and SM
during the training process. Experiments show DM-Codec significantly
outperforms state-of-the-art speech tokenization models, reducing WER by up to
13.46%, WIL by 9.82%, and improving speech quality by 5.84% and intelligibility
by 1.85% on the LibriSpeech benchmark dataset. The code, samples, and model
checkpoints are available at https://github.com/mubtasimahasan/DM-Codec.",2024-10-19,"Md Mubtasim Ahasan, Md Fahim, Tasnim Mohiuddin, A K M Mahbubur Rahman, Aman Chadha, Tariq Iqbal, M Ashraful Amin, Md Mofijul Islam, Amin Ahsan Ali",http://arxiv.org/pdf/2410.15017v1,cs.CL
Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model,"Users of the transit system flood social networks daily with messages that
contain valuable insights crucial for improving service quality. These posts
help transit agencies quickly identify emerging issues. Parsing topics and
sentiments is key to gaining comprehensive insights to foster service
excellence. However, the volume of messages makes manual analysis impractical,
and standard NLP techniques like Term Frequency-Inverse Document Frequency
(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis
separates topics and sentiments before integrating them, often missing the
interaction between them. This incremental approach complicates classification
and reduces analytical productivity. To address these challenges, we propose a
novel approach to extracting and analyzing transit-related information,
including sentiment and sarcasm detection, identification of unusual system
problems, and location data from social media. Our method employs Large
Language Models (LLM), specifically Llama 3, for a streamlined analysis free
from pre-established topic labels. To enhance the model's domain-specific
knowledge, we utilize Retrieval-Augmented Generation (RAG), integrating
external knowledge sources into the information extraction pipeline. We
validated our method through extensive experiments comparing its performance
with traditional NLP approaches on user tweet data from the real world transit
system. Our results demonstrate the potential of LLMs to transform social media
data analysis in the public transit domain, providing actionable insights and
enhancing transit agencies' responsiveness by extracting a broader range of
information.",2024-10-19,"Jiahao Wang, Amer Shalaby",http://arxiv.org/pdf/2410.15016v1,cs.CL
CAP: Data Contamination Detection via Consistency Amplification,"Large language models (LLMs) are widely used, but concerns about data
contamination challenge the reliability of LLM evaluations. Existing
contamination detection methods are often task-specific or require extra
prerequisites, limiting practicality. We propose a novel framework, Consistency
Amplification-based Data Contamination Detection (CAP), which introduces the
Performance Consistency Ratio (PCR) to measure dataset leakage by leveraging LM
consistency. To the best of our knowledge, this is the first method to
explicitly differentiate between fine-tuning and contamination, which is
crucial for detecting contamination in domain-specific models. Additionally,
CAP is applicable to various benchmarks and works for both white-box and
black-box models. We validate CAP's effectiveness through experiments on seven
LLMs and four domain-specific benchmarks. Our findings also show that composite
benchmarks from various dataset sources are particularly prone to unintentional
contamination. Codes will be publicly available soon.",2024-10-19,"Yi Zhao, Jing Li, Linyi Yang",http://arxiv.org/pdf/2410.15005v1,cs.CL
ChitroJera: A Regionally Relevant Visual Question Answering Dataset for Bangla,"Visual Question Answer (VQA) poses the problem of answering a natural
language question about a visual context. Bangla, despite being a widely spoken
language, is considered low-resource in the realm of VQA due to the lack of a
proper benchmark dataset. The absence of such datasets challenges models that
are known to be performant in other languages. Furthermore, existing Bangla VQA
datasets offer little cultural relevance and are largely adapted from their
foreign counterparts. To address these challenges, we introduce a large-scale
Bangla VQA dataset titled ChitroJera, totaling over 15k samples where diverse
and locally relevant data sources are used. We assess the performance of text
encoders, image encoders, multimodal models, and our novel dual-encoder models.
The experiments reveal that the pre-trained dual-encoders outperform other
models of its scale. We also evaluate the performance of large language models
(LLMs) using prompt-based techniques, with LLMs achieving the best performance.
Given the underdeveloped state of existing datasets, we envision ChitroJera
expanding the scope of Vision-Language tasks in Bangla.",2024-10-19,"Deeparghya Dutta Barua, Md Sakib Ul Rahman Sourove, Md Farhan Ishmam, Fabiha Haider, Fariha Tanjim Shifat, Md Fahim, Md Farhad Alam",http://arxiv.org/pdf/2410.14991v1,cs.CL
Subversive Characters and Stereotyping Readers: Characterizing Queer Relationalities with Dialogue-Based Relation Extraction,"Television is often seen as a site for subcultural identification and
subversive fantasy, including in queer cultures. How might we measure
subversion, or the degree to which the depiction of social relationship between
a dyad (e.g. two characters who are colleagues) deviates from its typical
representation on TV? To explore this question, we introduce the task of
stereotypic relationship extraction. Built on cognitive stylistics, linguistic
anthropology, and dialogue relation extraction, in this paper, we attempt to
model the cognitive process of stereotyping TV characters in dialogic
interactions. Given a dyad, we want to predict: what social relationship do the
speakers exhibit through their words? Subversion is then characterized by the
discrepancy between the distribution of the model's predictions and the ground
truth labels. To demonstrate the usefulness of this task and gesture at a
methodological intervention, we enclose four case studies to characterize the
representation of queer relationalities in the Big Bang Theory, Frasier, and
Gilmore Girls, as we explore the suspicious and reparative modes of reading
with our computational methods.",2024-10-19,"Kent K. Chang, Anna Ho, David Bamman",http://arxiv.org/pdf/2410.14978v2,cs.CL
Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration From Cognitive Psychology,"The cognitive mechanism by which Large Language Models (LLMs) solve
mathematical problems remains a widely debated and unresolved issue. Currently,
there is little interpretable experimental evidence that connects LLMs'
problem-solving with human cognitive psychology.To determine if LLMs possess
human-like mathematical reasoning, we modified the problems used in the human
Cognitive Reflection Test (CRT). Our results show that, even with the use of
Chains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model
(noted for its reasoning capabilities), have a high error rate when solving
these modified CRT problems. Specifically, the average accuracy rate dropped by
up to 50% compared to the original questions.Further analysis of LLMs'
incorrect answers suggests that they primarily rely on pattern matching from
their training data, which aligns more with human intuition (System 1 thinking)
rather than with human-like reasoning (System 2 thinking). This finding
challenges the belief that LLMs have genuine mathematical reasoning abilities
comparable to humans. As a result, this work may adjust overly optimistic views
on LLMs' progress towards artificial general intelligence.",2024-10-19,"Wei Xie, Shuoyoucheng Ma, Zhenhua Wang, Enze Wang, Kai Chen, Xiaobing Sun, Baosheng Wang",http://arxiv.org/pdf/2410.14979v5,cs.CL
BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation,"Current EEG/MEG-to-text decoding systems suffer from three key limitations:
(1) reliance on teacher-forcing methods, which compromises robustness during
inference, (2) sensitivity to session-specific noise, hindering generalization
across subjects, and (3) misalignment between brain signals and linguistic
representations due to pre-trained language model over-dominance. To overcome
these challenges, we propose BrainECHO (Brain signal decoding via
vEctor-quantized speCtrogram reconstruction for WHisper-enhanced text
generatiOn), a multi-stage framework that employs decoupled representation
learning to achieve state-of-the-art performance on both EEG and MEG datasets.
Specifically, BrainECHO consists of three stages: (1) Discrete autoencoding,
which transforms continuous Mel spectrograms into a finite set of high-quality
discrete representations for subsequent stages. (2) Frozen alignment, where
brain signal embeddings are mapped to corresponding Mel spectrogram embeddings
in a frozen latent space, effectively filtering session-specific noise through
vector-quantized reconstruction, yielding a 3.65% improvement in BLEU-4 score.
(3) Constrained decoding fine-tuning, which leverages the pre-trained Whisper
model for audio-to-text translation, balancing signal adaptation with knowledge
preservation, and achieving 74%-89% decoding BLEU scores without excessive
reliance on teacher forcing. BrainECHO demonstrates robustness across sentence,
session, and subject-independent conditions, passing Gaussian noise tests and
showcasing its potential for enhancing language-based brain-computer
interfaces.",2024-10-19,"Jilong Li, Zhenxi Song, Jiaqi Wang, Meishan Zhang, Honghai Liu, Min Zhang, Zhiguo Zhang",http://arxiv.org/pdf/2410.14971v2,cs.CL
Team Ryu's Submission to SIGMORPHON 2024 Shared Task on Subword Tokenization,"This papers presents the submission of team Ryu to the canceled SIGMORPHON
2024 shared task on subword tokenization. My submission explores whether
morphological segmentation methods can be used as a part of subword tokenizers.
I adopt two approaches: the statistical segmentation method Morfessor and a
transformer based sequence-to-sequence (seq2seq) segmentation model in
tokenizers. The prediction results show that morphological segmentation could
be as effective as commonly used subword tokenizers. Additionally, I
investigate how a tokenizer's vocabulary influences the performance of language
models. A tokenizer with a balanced token frequency distribution tends to work
better. A balanced token vocabulary can be achieved by keeping frequent words
as unique tokens.",2024-10-19,Zilong Li,http://arxiv.org/pdf/2410.17094v1,cs.CL
ChronoFact: Timeline-based Temporal Fact Verification,"Temporal claims, often riddled with inaccuracies, are a significant challenge
in the digital misinformation landscape. Fact-checking systems that can
accurately verify such claims are crucial for combating misinformation. Current
systems struggle with the complexities of evaluating the accuracy of these
claims, especially when they include multiple, overlapping, or recurring
events. We introduce a novel timeline-based fact verification framework that
identify events from both claim and evidence and organize them into their
respective chronological timelines. The framework systematically examines the
relationships between the events in both claim and evidence to predict the
veracity of each claim event and their chronological accuracy. This allows us
to accurately determine the overall veracity of the claim. We also introduce a
new dataset of complex temporal claims involving timeline-based reasoning for
the training and evaluation of our proposed framework. Experimental results
demonstrate the effectiveness of our approach in handling the intricacies of
temporal claim verification.",2024-10-19,"Anab Maulana Barik, Wynne Hsu, Mong Li Lee",http://arxiv.org/pdf/2410.14964v2,cs.CL
SemiHVision: Enhancing Medical Multimodal Models with a Semi-Human Annotated Dataset and Fine-Tuned Instruction Generation,"Multimodal large language models (MLLMs) have made significant strides, yet
they face challenges in the medical domain due to limited specialized
knowledge. While recent medical MLLMs demonstrate strong performance in lab
settings, they often struggle in real-world applications, highlighting a
substantial gap between research and practice. In this paper, we seek to
address this gap at various stages of the end-to-end learning pipeline,
including data collection, model fine-tuning, and evaluation. At the data
collection stage, we introduce SemiHVision, a dataset that combines human
annotations with automated augmentation techniques to improve both medical
knowledge representation and diagnostic reasoning. For model fine-tuning, we
trained PMC-Cambrian-8B-AN over 2400 H100 GPU hours, resulting in performance
that surpasses public medical models like HuatuoGPT-Vision-34B (79.0% vs.
66.7%) and private general models like Claude3-Opus (55.7%) on traditional
benchmarks such as SLAKE and VQA-RAD. In the evaluation phase, we observed that
traditional benchmarks cannot accurately reflect realistic clinical task
capabilities. To overcome this limitation and provide more targeted guidance
for model evaluation, we introduce the JAMA Clinical Challenge, a novel
benchmark specifically designed to evaluate diagnostic reasoning. On this
benchmark, PMC-Cambrian-AN achieves state-of-the-art performance with a GPT-4
score of 1.29, significantly outperforming HuatuoGPT-Vision-34B (1.13) and
Claude3-Opus (1.17), demonstrating its superior diagnostic reasoning abilities.",2024-10-19,"Junda Wang, Yujan Ting, Eric Z. Chen, Hieu Tran, Hong Yu, Weijing Huang, Terrence Chen",http://arxiv.org/pdf/2410.14948v1,cs.CL
Baichuan Alignment Technical Report,"We introduce Baichuan Alignment, a detailed analysis of the alignment
techniques employed in the Baichuan series of models. This represents the
industry's first comprehensive account of alignment methodologies, offering
valuable insights for advancing AI research. We investigate the critical
components that enhance model performance during the alignment process,
including optimization methods, data strategies, capability enhancements, and
evaluation processes. The process spans three key stages: Prompt Augmentation
System(PAS), Supervised Fine-Tuning(SFT), and Preference Alignment. The
problems encountered, the solutions applied, and the improvements made are
thoroughly recorded.
  Through comparisons across well-established benchmarks, we highlight the
technological advancements enabled by Baichuan Alignment. Baichuan-Instruct is
an internal model, while Qwen2-Nova-72B and Llama3-PBM-Nova-70B are instruct
versions of the Qwen2-72B and Llama-3-70B base models, optimized through
Baichuan Alignment. Baichuan-Instruct demonstrates significant improvements in
core capabilities, with user experience gains ranging from 17% to 28%, and
performs exceptionally well on specialized benchmarks. In open-source benchmark
evaluations, both Qwen2-Nova-72B and Llama3-PBM-Nova-70B consistently
outperform their respective official instruct versions across nearly all
datasets. This report aims to clarify the key technologies behind the alignment
process, fostering a deeper understanding within the community.
Llama3-PBM-Nova-70B model is available at
https://huggingface.co/PKU-Baichuan-MLSystemLab/Llama3-PBM-Nova-70B.",2024-10-19,"Mingan Lin, Fan Yang, Yanjun Shen, Haoze Sun, Tianpeng Li, Tao Zhang, Chenzheng Zhu, Tao Zhang, Miao Zheng, Xu Li, Yijie Zhou, Mingyang Chen, Yanzhao Qin, Youquan Li, Hao Liang, Fei Li, Yadong Li, Mang Wang, Guosheng Dong, Kun Fang, Jianhua Xu, Bin Cui, Wentao Zhang, Zenan Zhou, Weipeng Chen",http://arxiv.org/pdf/2410.14940v4,cs.CL
A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models,"The robustness of Vision-Language Models (VLMs) such as CLIP is critical for
their deployment in safety-critical applications like autonomous driving,
healthcare diagnostics, and security systems, where accurate interpretation of
visual and textual data is essential. However, these models are highly
susceptible to adversarial attacks, which can severely compromise their
performance and reliability in real-world scenarios. Previous methods have
primarily focused on improving robustness through adversarial training and
generating adversarial examples using models like FGSM, AutoAttack, and
DeepFool. However, these approaches often rely on strong assumptions, such as
fixed perturbation norms or predefined attack patterns, and involve high
computational complexity, making them challenging to implement in practical
settings. In this paper, we propose a novel adversarial training framework that
integrates multiple attack strategies and advanced machine learning techniques
to significantly enhance the robustness of VLMs against a broad range of
adversarial attacks. Experiments conducted on real-world datasets, including
CIFAR-10 and CIFAR-100, demonstrate that the proposed method significantly
enhances model robustness. The fine-tuned CLIP model achieved an accuracy of
43.5% on adversarially perturbed images, compared to only 4% for the baseline
model. The neural network model achieved a high accuracy of 98% in these
challenging classification tasks, while the XGBoost model reached a success
rate of 85.26% in prediction tasks.",2024-10-18,"Yuhan Liang, Yijun Li, Yumeng Niu, Qianhe Shen, Hangyu Liu",http://arxiv.org/pdf/2410.14911v1,cs.CL
From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items,"LLMs can now perform a variety of complex writing tasks. They also excel in
answering questions pertaining to natural language inference and commonsense
reasoning. Composing these questions is itself a skilled writing task, so in
this paper we consider LLMs as authors of commonsense assessment items. We
prompt LLMs to generate items in the style of a prominent benchmark for
commonsense reasoning, the Choice of Plausible Alternatives (COPA). We examine
the outcome according to analyses facilitated by the LLMs and human annotation.
We find that LLMs that succeed in answering the original COPA benchmark are
also more successful in authoring their own items.",2024-10-18,"Melissa Roemmele, Andrew S. Gordon",http://arxiv.org/pdf/2410.14897v1,cs.CL
Class-RAG: Real-Time Content Moderation with Retrieval Augmented Generation,"Robust content moderation classifiers are essential for the safety of
Generative AI systems. In this task, differences between safe and unsafe inputs
are often extremely subtle, making it difficult for classifiers (and indeed,
even humans) to properly distinguish violating vs. benign samples without
context or explanation. Scaling risk discovery and mitigation through
continuous model fine-tuning is also slow, challenging and costly, preventing
developers from being able to respond quickly and effectively to emergent
harms. We propose a Classification approach employing Retrieval-Augmented
Generation (Class-RAG). Class-RAG extends the capability of its base LLM
through access to a retrieval library which can be dynamically updated to
enable semantic hotfixing for immediate, flexible risk mitigation. Compared to
model fine-tuning, Class-RAG demonstrates flexibility and transparency in
decision-making, outperforms on classification and is more robust against
adversarial attack, as evidenced by empirical studies. Our findings also
suggest that Class-RAG performance scales with retrieval library size,
indicating that increasing the library size is a viable and low-cost approach
to improve content moderation.",2024-10-18,"Jianfa Chen, Emily Shen, Trupti Bavalatti, Xiaowen Lin, Yongkai Wang, Shuming Hu, Harihar Subramanyam, Ksheeraj Sai Vepuri, Ming Jiang, Ji Qi, Li Chen, Nan Jiang, Ankit Jain",http://arxiv.org/pdf/2410.14881v2,cs.CL
Which LLMs are Difficult to Detect? A Detailed Analysis of Potential Factors Contributing to Difficulties in LLM Text Detection,"As LLMs increase in accessibility, LLM-generated texts have proliferated
across several fields, such as scientific, academic, and creative writing.
However, LLMs are not created equally; they may have different architectures
and training datasets. Thus, some LLMs may be more challenging to detect than
others. Using two datasets spanning four total writing domains, we train
AI-generated (AIG) text classifiers using the LibAUC library - a deep learning
library for training classifiers with imbalanced datasets. Our results in the
Deepfake Text dataset show that AIG-text detection varies across domains, with
scientific writing being relatively challenging. In the Rewritten Ivy Panda
(RIP) dataset focusing on student essays, we find that the OpenAI family of
LLMs was substantially difficult for our classifiers to distinguish from human
texts. Additionally, we explore possible factors that could explain the
difficulties in detecting OpenAI-generated texts.",2024-10-18,"Shantanu Thorat, Tianbao Yang",http://arxiv.org/pdf/2410.14875v2,cs.CL
How to Evaluate Reward Models for RLHF,"We introduce a new benchmark for reward models that quantifies their ability
to produce strong language models through RLHF (Reinforcement Learning from
Human Feedback). The gold-standard approach is to run a full RLHF training
pipeline and directly probe downstream LLM performance. However, this process
is prohibitively expensive. To address this, we build a predictive model of
downstream LLM performance by evaluating the reward model on proxy tasks. These
proxy tasks consist of a large-scale human preference and a verifiable
correctness preference dataset, in which we measure 12 metrics across 12
domains. To investigate which reward model metrics are most correlated to
gold-standard RLHF outcomes, we launch an end-to-end RLHF experiment on a
large-scale crowdsourced human preference platform to view real reward model
downstream performance as ground truth. Ultimately, we compile our data and
findings into Preference Proxy Evaluations (PPE), the first reward model
benchmark explicitly linked to post-RLHF real-world human preference
performance, which we open-source for public use and further development. Our
code and evaluations can be found at https://github.com/lmarena/PPE .",2024-10-18,"Evan Frick, Tianle Li, Connor Chen, Wei-Lin Chiang, Anastasios N. Angelopoulos, Jiantao Jiao, Banghua Zhu, Joseph E. Gonzalez, Ion Stoica",http://arxiv.org/pdf/2410.14872v2,cs.CL
DFlow: Diverse Dialogue Flow Simulation with Large Language Models,"Developing language model-based dialogue agents requires effective data to
train models that can follow specific task logic. However, most existing data
simulation methods focus on increasing diversity in language, topics, or
dialogue acts at the utterance level, largely neglecting a critical aspect of
task logic diversity at the dialogue level. This paper proposes a novel data
simulation method designed to enhance the diversity of synthetic dialogues by
focusing on task execution logic. Our method uses LLMs to generate decision
tree-structured task plans, which enables the derivation of diverse dialogue
trajectories for a given task. Each trajectory, referred to as a ""dialog flow"",
guides the generation of a multi-turn dialogue that follows a unique
trajectory. We apply this method to generate a task-oriented dialogue dataset
comprising 3,886 dialogue flows across 15 different domains. We validate the
effectiveness of this dataset using the next action prediction task, where
models fine-tuned on our dataset outperform strong baselines, including GPT-4.
Upon acceptance of this paper, we plan to release the code and data publicly.",2024-10-18,"Wanyu Du, Song Feng, James Gung, Lijia Sun, Yi Zhang, Saab Mansour, Yanjun Qi",http://arxiv.org/pdf/2410.14853v2,cs.CL
Enhancing Prompt Injection Attacks to LLMs via Poisoning Alignment,"In a prompt injection attack, an attacker injects a prompt into the original
one, aiming to make an LLM follow the injected prompt to perform an
attacker-chosen task. Existing attacks primarily focus on how to blend the
injected prompt into the original prompt without altering the LLM itself. Our
experiments show that these attacks achieve some success, but there is still
significant room for improvement. In this work, we show that an attacker can
boost the success of prompt injection attacks by poisoning the LLM's alignment
process. Specifically, we propose PoisonedAlign, a method to strategically
create poisoned alignment samples. When even a small fraction of the alignment
data is poisoned using our method, the aligned LLM becomes more vulnerable to
prompt injection while maintaining its foundational capabilities. The code is
available at https://github.com/Sadcardation/PoisonedAlign",2024-10-18,"Zedian Shao, Hongbin Liu, Jaden Mu, Neil Zhenqiang Gong",http://arxiv.org/pdf/2410.14827v2,cs.CL
SPRIG: Improving Large Language Model Performance by System Prompt Optimization,"Large Language Models (LLMs) have shown impressive capabilities in many
scenarios, but their performance depends, in part, on the choice of prompt.
Past research has focused on optimizing prompts specific to a task. However,
much less attention has been given to optimizing the general instructions
included in a prompt, known as a system prompt. To address this gap, we propose
SPRIG, an edit-based genetic algorithm that iteratively constructs prompts from
prespecified components to maximize the model's performance in general
scenarios. We evaluate the performance of system prompts on a collection of 47
different types of tasks to ensure generalizability. Our study finds that a
single optimized system prompt performs on par with task prompts optimized for
each individual task. Moreover, combining system and task-level optimizations
leads to further improvement, which showcases their complementary nature.
Experiments also reveal that the optimized system prompts generalize
effectively across model families, parameter sizes, and languages. This study
provides insights into the role of system-level instructions in maximizing LLM
potential.",2024-10-18,"Lechen Zhang, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens",http://arxiv.org/pdf/2410.14826v2,cs.CL
A Complexity-Based Theory of Compositionality,"Compositionality is believed to be fundamental to intelligence. In humans, it
underlies the structure of thought, language, and higher-level reasoning. In
AI, compositional representations can enable a powerful form of
out-of-distribution generalization, in which a model systematically adapts to
novel combinations of known concepts. However, while we have strong intuitions
about what compositionality is, there currently exists no formal definition for
it that is measurable and mathematical. Here, we propose such a definition,
which we call representational compositionality, that accounts for and extends
our intuitions about compositionality. The definition is conceptually simple,
quantitative, grounded in algorithmic information theory, and applicable to any
representation. Intuitively, representational compositionality states that a
compositional representation satisfies three properties. First, it must be
expressive. Second, it must be possible to re-describe the representation as a
function of discrete symbolic sequences with re-combinable parts, analogous to
sentences in natural language. Third, the function that relates these symbolic
sequences to the representation, analogous to semantics in natural language,
must be simple. Through experiments on both synthetic and real world data, we
validate our definition of compositionality and show how it unifies disparate
intuitions from across the literature in both AI and cognitive science. We also
show that representational compositionality, while theoretically intractable,
can be readily estimated using standard deep learning tools. Our definition has
the potential to inspire the design of novel, theoretically-driven models that
better capture the mechanisms of compositional thought.",2024-10-18,"Eric Elmoznino, Thomas Jiralerspong, Yoshua Bengio, Guillaume Lajoie",http://arxiv.org/pdf/2410.14817v4,cs.CL
Adapting Multilingual LLMs to Low-Resource Languages using Continued Pre-training and Synthetic Corpus,"Multilingual LLMs support a variety of languages; however, their performance
is suboptimal for low-resource languages. In this work, we emphasize the
importance of continued pre-training of multilingual LLMs and the use of
translation-based synthetic pre-training corpora for improving LLMs in
low-resource languages. We conduct our study in the context of the low-resource
Indic language Hindi. We introduce Nemotron-Mini-Hindi 4B, a bilingual SLM
supporting both Hindi and English, based on Nemotron-Mini 4B. The model is
trained using a mix of real and synthetic Hindi + English tokens, with
continuous pre-training performed on 400B tokens. We demonstrate that both the
base and instruct models achieve state-of-the-art results on Hindi benchmarks
while remaining competitive on English tasks. Additionally, we observe that the
continued pre-training approach enhances the model's overall factual accuracy.
We perform an ablation study to highlight the impact of Hindi pre-training,
showing significant improvements in Hindi chat capabilities and factual
accuracy, which cannot be achieved through Hindi alignment alone.",2024-10-18,"Raviraj Joshi, Kanishk Singla, Anusha Kamath, Raunak Kalani, Rakesh Paul, Utkarsh Vaidya, Sanjay Singh Chauhan, Niranjan Wartikar, Eileen Long",http://arxiv.org/pdf/2410.14815v2,cs.CL
Effects of Soft-Domain Transfer and Named Entity Information on Deception Detection,"In the modern age an enormous amount of communication occurs online, and it
is difficult to know when something written is genuine or deceitful. There are
many reasons for someone to deceive online (e.g., monetary gain, political
gain) and detecting this behavior without any physical interaction is a
difficult task. Additionally, deception occurs in several text-only domains and
it is unclear if these various sources can be leveraged to improve detection.
To address this, eight datasets were utilized from various domains to evaluate
their effect on classifier performance when combined with transfer learning via
intermediate layer concatenation of fine-tuned BERT models. We find
improvements in accuracy over the baseline. Furthermore, we evaluate multiple
distance measurements between datasets and find that Jensen-Shannon distance
correlates moderately with transfer learning performance. Finally, the impact
was evaluated of multiple methods, which produce additional information in a
dataset's text via named entities, on BERT performance and we find notable
improvement in accuracy of up to 11.2%.",2024-10-18,"Steven Triplett, Simon Minami, Rakesh Verma",http://arxiv.org/pdf/2410.14814v1,cs.CL
Isolated Causal Effects of Natural Language,"As language technologies become widespread, it is important to understand how
changes in language affect reader perceptions and behaviors. These
relationships may be formalized as the isolated causal effect of some focal
language-encoded intervention (e.g., factual inaccuracies) on an external
outcome (e.g., readers' beliefs). In this paper, we introduce a formal
estimation framework for isolated causal effects of language. We show that a
core challenge of estimating isolated effects is the need to approximate all
non-focal language outside of the intervention. Drawing on the principle of
omitted variable bias, we provide measures for evaluating the quality of both
non-focal language approximations and isolated effect estimates themselves. We
find that poor approximation of non-focal language can lead to bias in the
corresponding isolated effect estimates due to omission of relevant variables,
and we show how to assess the sensitivity of effect estimates to such bias
along the two key axes of fidelity and overlap. In experiments on
semi-synthetic and real-world data, we validate the ability of our framework to
correctly recover isolated effects and demonstrate the utility of our proposed
measures.",2024-10-18,"Victoria Lin, Louis-Philippe Morency, Eli Ben-Michael",http://arxiv.org/pdf/2410.14812v2,cs.CL
Cross-Document Event-Keyed Summarization,"Event-keyed summarization (EKS) requires summarizing a specific event
described in a document given the document text and an event representation
extracted from it. In this work, we extend EKS to the cross-document setting
(CDEKS), in which summaries must synthesize information from accounts of the
same event as given by multiple sources. We introduce SEAMUS (Summaries of
Events Across Multiple Sources), a high-quality dataset for CDEKS based on an
expert reannotation of the FAMUS dataset for cross-document argument
extraction. We present a suite of baselines on SEAMUS -- covering both smaller,
fine-tuned models, as well as zero- and few-shot prompted LLMs -- along with
detailed ablations and a human evaluation study, showing SEAMUS to be a
valuable benchmark for this new task.",2024-10-18,"William Walden, Pavlo Kuchmiichuk, Alexander Martin, Chihsheng Jin, Angela Cao, Claire Sun, Curisia Allen, Aaron Steven White",http://arxiv.org/pdf/2410.14795v2,cs.CL
Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts,"The rapid development of autoregressive Large Language Models (LLMs) has
significantly improved the quality of generated texts, necessitating reliable
machine-generated text detectors. A huge number of detectors and collections
with AI fragments have emerged, and several detection methods even showed
recognition quality up to 99.9% according to the target metrics in such
collections. However, the quality of such detectors tends to drop dramatically
in the wild, posing a question: Are detectors actually highly trustworthy or do
their high benchmark scores come from the poor quality of evaluation datasets?
In this paper, we emphasise the need for robust and qualitative methods for
evaluating generated data to be secure against bias and low generalising
ability of future model. We present a systematic review of datasets from
competitions dedicated to AI-generated content detection and propose methods
for evaluating the quality of datasets containing AI-generated fragments. In
addition, we discuss the possibility of using high-quality generated data to
achieve two goals: improving the training of detection models and improving the
training datasets themselves. Our contribution aims to facilitate a better
understanding of the dynamics between human and machine text, which will
ultimately support the integrity of information in an increasingly automated
world. The code is available at
https://github.com/Advacheck-OU/ai-dataset-analysing.",2024-10-18,"German Gritsai, Anastasia Voznyuk, Andrey Grabovoy, Yury Chekhovich",http://arxiv.org/pdf/2410.14677v3,cs.CL
SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment,"Existing preference alignment is a one-size-fits-all alignment mechanism,
where the part of the large language model (LLM) parametric knowledge with
non-preferred features is uniformly blocked to all the users. However, this
part of knowledge can be useful to advanced users whose expertise qualifies
them to handle these information. The one-size-fits-all alignment mechanism
undermines LLM's utility for these qualified users. To address this problem, we
propose SudoLM, a framework that lets LLMs learn access control over specific
parametric knowledge for users with different credentials via authorization
alignment. SudoLM allows authorized users to unlock their access to all the
parametric knowledge with an assigned SUDO key while blocking access to
non-qualified users. Experiments on two application scenarios demonstrate that
SudoLM effectively controls the user's access to the parametric knowledge and
maintains its general utility.",2024-10-18,"Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen",http://arxiv.org/pdf/2410.14676v2,cs.CL
To Trust or Not to Trust? Enhancing Large Language Models' Situated Faithfulness to External Contexts,"Large Language Models (LLMs) are often augmented with external contexts, such
as those used in retrieval-augmented generation (RAG). However, these contexts
can be inaccurate or intentionally misleading, leading to conflicts with the
model's internal knowledge. We argue that robust LLMs should demonstrate
situated faithfulness, dynamically calibrating their trust in external
information based on their confidence in the internal knowledge and the
external context to resolve knowledge conflicts. To benchmark this capability,
we evaluate LLMs across several QA datasets, including a newly created dataset
featuring in-the-wild incorrect contexts sourced from Reddit posts. We show
that when provided with both correct and incorrect contexts, both open-source
and proprietary models tend to overly rely on external information, regardless
of its factual accuracy. To enhance situated faithfulness, we propose two
approaches: Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence
Reasoning (RCR). SCR enables models to self-assess the confidence of external
information relative to their own internal knowledge to produce the most
accurate answer. RCR, in contrast, extracts explicit confidence signals from
the LLM and determines the final answer using predefined rules. Our results
show that for LLMs with strong reasoning capabilities, such as GPT-4o and
GPT-4o mini, SCR outperforms RCR, achieving improvements of up to 24.2% over a
direct input augmentation baseline. Conversely, for a smaller model like
Llama-3-8B, RCR outperforms SCR. Fine-tuning SCR with our proposed Confidence
Reasoning Direct Preference Optimization (CR-DPO) method improves performance
on both seen and unseen datasets, yielding an average improvement of 8.9% on
Llama-3-8B. In addition to quantitative results, we offer insights into the
relative strengths of SCR and RCR.",2024-10-18,"Yukun Huang, Sanxing Chen, Hongyi Cai, Bhuwan Dhingra",http://arxiv.org/pdf/2410.14675v2,cs.CL
NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples,"Vision-language models (VLMs) have made significant progress in recent
visual-question-answering (VQA) benchmarks that evaluate complex
visio-linguistic reasoning. However, are these models truly effective? In this
work, we show that VLMs still struggle with natural images and questions that
humans can easily answer, which we term natural adversarial samples. We also
find it surprisingly easy to generate these VQA samples from natural image-text
corpora using off-the-shelf models like CLIP and ChatGPT. We propose a
semi-automated approach to collect a new benchmark, NaturalBench, for reliably
evaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a
$\textbf{vision-centric}$ design by pairing each question with two images that
yield different answers, preventing blind solutions from answering without
using the images. This makes NaturalBench more challenging than previous
benchmarks that can be solved with commonsense priors. We evaluate 53
state-of-the-art VLMs on NaturalBench, showing that models like
LLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o
lag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is
hard from two angles: (1) Compositionality: Solving NaturalBench requires
diverse visio-linguistic skills, including understanding attribute bindings,
object relationships, and advanced reasoning like logic and counting. To this
end, unlike prior work that uses a single tag per sample, we tag each
NaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)
Biases: NaturalBench exposes severe biases in VLMs, as models often choose the
same answer regardless of the image. Lastly, we apply our benchmark curation
method to diverse data sources, including long captions (over 100 words) and
non-English languages like Chinese and Hindi, highlighting its potential for
dynamic evaluations of VLMs.",2024-10-18,"Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna, Graham Neubig, Deva Ramanan",http://arxiv.org/pdf/2410.14669v3,cs.CL
MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image Description and Reasoning Steps,"Multimodal Chain of Thought (MCoT) is a popular prompting strategy for
improving the performance of multimodal large language models (MLLMs) across a
range of complex reasoning tasks. Despite its popularity, there is a notable
absence of automated methods for evaluating the quality of reasoning steps in
MCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation
(MiCEval), a framework designed to assess the correctness of reasoning chains
by evaluating the quality of both the description and each reasoning step. The
evaluation of the description component focuses on the accuracy of the image
descriptions, while the reasoning step evaluates the quality of each step as it
is conditionally generated based on the preceding steps. MiCEval is built upon
a fine-grained dataset with annotations that rate each step according to
correctness, relevance, and informativeness. Extensive experiments on four
state-of-the-art MLLMs show that step-wise evaluations using MiCEval align more
closely with human judgments compared to existing methods based on cosine
similarity or fine-tuning approaches. MiCEval datasets and code can be found in
https://github.com/alenai97/MiCEval.",2024-10-18,"Xiongtao Zhou, Jie He, Lanyu Chen, Jingyu Li, Haojing Chen, Víctor Gutiérrez-Basulto, Jeff Z. Pan, Hanjie Chen",http://arxiv.org/pdf/2410.14668v4,cs.CL
DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph,"Summarizing movie screenplays presents a unique set of challenges compared to
standard document summarization. Screenplays are not only lengthy, but also
feature a complex interplay of characters, dialogues, and scenes, with numerous
direct and subtle relationships and contextual nuances that are difficult for
machine learning models to accurately capture and comprehend. Recent attempts
at screenplay summarization focus on fine-tuning transformer-based pre-trained
models, but these models often fall short in capturing long-term dependencies
and latent relationships, and frequently encounter the ""lost in the middle""
issue. To address these challenges, we introduce DiscoGraMS, a novel resource
that represents movie scripts as a movie character-aware discourse graph (CaD
Graph). This approach is well-suited for various downstream tasks, such as
summarization, question-answering, and salience detection. The model aims to
preserve all salient information, offering a more comprehensive and faithful
representation of the screenplay's content. We further explore a baseline
method that combines the CaD Graph with the corresponding movie script through
a late fusion of graph and text modalities, and we present very initial
promising results.",2024-10-18,"Maitreya Prafulla Chitale, Uday Bindal, Rajakrishnan Rajkumar, Rahul Mishra",http://arxiv.org/pdf/2410.14666v2,cs.CL
Real-time Fake News from Adversarial Feedback,"We show that existing evaluations for fake news detection based on
conventional sources, such as claims on fact-checking websites, result in high
accuracies over time for LLM-based detectors -- even after their knowledge
cutoffs. This suggests that recent popular fake news from such sources can be
easily detected due to pre-training and retrieval corpus contamination or
increasingly salient shallow patterns. Instead, we argue that a proper fake
news detection dataset should test a model's ability to reason factually about
the current world by retrieving and reading related evidence. To this end, we
develop a novel pipeline that leverages natural language feedback from a
RAG-based detector to iteratively modify real-time news into deceptive fake
news that challenges LLMs. Our iterative rewrite decreases the binary
classification ROC-AUC by an absolute 17.5 percent for a strong RAG-based
GPT-4o detector. Our experiments reveal the important role of RAG in both
detecting and generating fake news, as retrieval-free LLM detectors are
vulnerable to unseen events and adversarial attacks, while feedback from RAG
detection helps discover more deceitful patterns in fake news.",2024-10-18,"Sanxing Chen, Yukun Huang, Bhuwan Dhingra",http://arxiv.org/pdf/2410.14651v2,cs.CL
Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs,"Positional bias in large language models (LLMs) hinders their ability to
effectively process long inputs. A prominent example is the ""lost in the
middle"" phenomenon, where LLMs struggle to utilize relevant information
situated in the middle of the input. While prior research primarily focuses on
single pieces of relevant information, real-world applications often involve
multiple relevant information pieces. To bridge this gap, we present
LongPiBench, a benchmark designed to assess positional bias involving multiple
pieces of relevant information. Thorough experiments are conducted with five
commercial and six open-source models. These experiments reveal that while most
current models are robust against the ""lost in the middle"" issue, there exist
significant biases related to the spacing of relevant information pieces. These
findings highlight the importance of evaluating and reducing positional biases
to advance LLM's capabilities.",2024-10-18,"Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu",http://arxiv.org/pdf/2410.14641v1,cs.CL
GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings,"Training-free embedding methods directly leverage pretrained large language
models (LLMs) to embed text, bypassing the costly and complex procedure of
contrastive learning. Previous training-free embedding methods have mainly
focused on optimizing embedding prompts and have overlooked the benefits of
utilizing the generative abilities of LLMs. We propose a novel method, GenEOL,
which uses LLMs to generate diverse transformations of a sentence that preserve
its meaning, and aggregates the resulting embeddings of these transformations
to enhance the overall sentence embedding. GenEOL significantly outperforms the
existing training-free embedding methods by an average of 2.85 points across
several LLMs on the sentence semantic text similarity (STS) benchmark. GenEOL
also achieves notable gains in clustering, reranking, and pair-classification
tasks from the MTEB benchmark. Additionally, GenEOL stabilizes representation
quality across LLM layers and remains robust to perturbations of embedding
prompts.",2024-10-18,"Raghuveer Thirukovalluru, Bhuwan Dhingra",http://arxiv.org/pdf/2410.14635v2,cs.CL
Diverging Preferences: When do Annotators Disagree and do Models Know?,"We examine diverging preferences in human-labeled preference datasets. We
develop a taxonomy of disagreement sources spanning 10 categories across four
high-level classes -- task underspecification, response style, refusals, and
annotation errors. We find that the majority of disagreements are in opposition
with standard reward modeling approaches, which are designed with the
assumption that annotator disagreement is noise. We then explore how these
findings impact two areas of LLM development: reward modeling and evaluation.
In our experiments, we demonstrate how standard reward modeling methods, like
the Bradley-Terry model, fail to differentiate whether a given preference
judgment is the result of unanimous agreement among annotators or the majority
opinion among diverging user preferences. We also find that these tendencies
are also echoed by popular LLM-as-Judge evaluation methods, which consistently
identify a winning response in cases of diverging preferences. These findings
highlight remaining challenges in LLM evaluations, which are greatly influenced
by divisive features like response style, and in developing pluralistically
aligned LLMs. To address these issues, we develop methods for identifying
diverging preferences to mitigate their influence on evaluation and training.",2024-10-18,"Michael JQ Zhang, Zhilin Wang, Jena D. Hwang, Yi Dong, Olivier Delalleau, Yejin Choi, Eunsol Choi, Xiang Ren, Valentina Pyatkin",http://arxiv.org/pdf/2410.14632v2,cs.CL
CELI: Controller-Embedded Language Model Interactions,"We introduce Controller-Embedded Language Model Interactions (CELI), a
framework that integrates control logic directly within language model (LM)
prompts, facilitating complex, multi-stage task execution. CELI addresses
limitations of existing prompt engineering and workflow optimization techniques
by embedding control logic directly within the operational context of language
models, enabling dynamic adaptation to evolving task requirements. Our
framework transfers control from the traditional programming execution
environment to the LMs, allowing them to autonomously manage computational
workflows while maintaining seamless interaction with external systems and
functions. CELI supports arbitrary function calls with variable arguments,
bridging the gap between LMs' adaptive reasoning capabilities and conventional
software paradigms' structured control mechanisms. To evaluate CELI's
versatility and effectiveness, we conducted case studies in two distinct
domains: code generation (HumanEval benchmark) and multi-stage content
generation (Wikipedia-style articles). The results demonstrate notable
performance improvements across a range of domains. CELI achieved a 4.9
percentage point improvement over the best reported score of the baseline GPT-4
model on the HumanEval code generation benchmark. In multi-stage content
generation, 94.4% of CELI-produced Wikipedia-style articles met or exceeded
first draft quality when optimally configured, with 44.4% achieving high
quality. These outcomes underscore CELI's potential for optimizing AI-driven
workflows across diverse computational domains.",2024-10-18,"Jan-Samuel Wagner, Dave DeCaprio, Abishek Chiffon Muthu Raja, Jonathan M. Holman, Lauren K. Brady, Sky C. Cheung, Hosein Barzekar, Eric Yang, Mark Anthony Martinez II, David Soong, Sriram Sridhar, Han Si, Brandon W. Higgs, Hisham Hamadeh, Scott Ogden",http://arxiv.org/pdf/2410.14627v1,cs.CL
You Shall Know a Tool by the Traces it Leaves: The Predictability of Sentiment Analysis Tools,"If sentiment analysis tools were valid classifiers, one would expect them to
provide comparable results for sentiment classification on different kinds of
corpora and for different languages. In line with results of previous studies
we show that sentiment analysis tools disagree on the same dataset. Going
beyond previous studies we show that the sentiment tool used for sentiment
annotation can even be predicted from its outcome, revealing an algorithmic
bias of sentiment analysis. Based on Twitter, Wikipedia and different news
corpora from the English, German and French languages, our classifiers separate
sentiment tools with an averaged F1-score of 0.89 (for the English corpora). We
therefore warn against taking sentiment annotations as face value and argue for
the need of more and systematic NLP evaluation studies.",2024-10-18,"Daniel Baumartz, Mevlüt Bagci, Alexander Henlein, Maxim Konca, Andy Lücking, Alexander Mehler",http://arxiv.org/pdf/2410.14626v1,cs.CL
DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search,"Conversational Search (CS) involves retrieving relevant documents from a
corpus while considering the conversational context, integrating retrieval with
context modeling. Recent advancements in Large Language Models (LLMs) have
significantly enhanced CS by enabling query rewriting based on conversational
context. However, employing LLMs during inference poses efficiency challenges.
Existing solutions mitigate this issue by distilling embeddings derived from
human-rewritten queries, focusing primarily on learning the context modeling
task. These methods, however, often separate the contrastive retrieval task
from the distillation process, treating it as an independent loss term. To
overcome these limitations, we introduce DiSCo (Distillation of Sparse
Conversational retrieval), a novel approach that unifies retrieval and context
modeling through a relaxed distillation objective. Instead of relying
exclusively on representation learning, our method distills similarity scores
between conversations and documents, providing more freedom in the
representation space and better leveraging the contrastive nature of document
relevance. Extensive experiments on Learned Sparse Retrieval (LSR) across five
CS datasets demonstrate that DiSCo achieves substantial improvements in both
in-domain and out-of-domain retrieval tasks, achieving up to a six-point gain
in recall for out-of-domain datasets over state-of-the-art methods.
Additionally, DiSCo employs a multi-teacher distillation strategy, using
multiple LLMs as teachers, further enhancing performance and surpassing the
individual teachers in in-domain settings. Furthermore, analysis of model
sparsity reveals that DiSCo allows for more effective control over the sparsity
of the trained models.",2024-10-18,"Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas",http://arxiv.org/pdf/2410.14609v2,cs.CL
Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs,"Jailbreak attack can be used to access the vulnerabilities of Large Language
Models (LLMs) by inducing LLMs to generate the harmful content. And the most
common method of the attack is to construct semantically ambiguous prompts to
confuse and mislead the LLMs. To access the security and reveal the intrinsic
relation between the input prompt and the output for LLMs, the distribution of
attention weight is introduced to analyze the underlying reasons. By using
statistical analysis methods, some novel metrics are defined to better describe
the distribution of attention weight, such as the Attention Intensity on
Sensitive Words (Attn_SensWords), the Attention-based Contextual Dependency
Score (Attn_DepScore) and Attention Dispersion Entropy (Attn_Entropy). By
leveraging the distinct characteristics of these metrics, the beam search
algorithm and inspired by the military strategy ""Feint and Attack"", an
effective jailbreak attack strategy named as Attention-Based Attack (ABA) is
proposed. In the ABA, nested attack prompts are employed to divert the
attention distribution of the LLMs. In this manner, more harmless parts of the
input can be used to attract the attention of the LLMs. In addition, motivated
by ABA, an effective defense strategy called as Attention-Based Defense (ABD)
is also put forward. Compared with ABA, the ABD can be used to enhance the
robustness of LLMs by calibrating the attention distribution of the input
prompt. Some comparative experiments have been given to demonstrate the
effectiveness of ABA and ABD. Therefore, both ABA and ABD can be used to access
the security of the LLMs. The comparative experiment results also give a
logical explanation that the distribution of attention weight can bring great
influence on the output for LLMs.",2024-10-18,"Rui Pu, Chaozhuo Li, Rui Ha, Zejian Chen, Litian Zhang, Zheng Liu, Lirong Qiu, Xi Zhang",http://arxiv.org/pdf/2410.16327v1,cs.CL
Teaching Models to Balance Resisting and Accepting Persuasion,"Large language models (LLMs) are susceptible to persuasion, which can pose
risks when models are faced with an adversarial interlocutor. We take a first
step towards defending models against persuasion while also arguing that
defense against adversarial (i.e. negative) persuasion is only half of the
equation: models should also be able to accept beneficial (i.e. positive)
persuasion to improve their answers. We show that optimizing models for only
one side results in poor performance on the other. In order to balance positive
and negative persuasion, we introduce Persuasion-Training (or PBT), which
leverages multi-agent recursive dialogue trees to create data and trains models
via preference optimization to accept persuasion when appropriate. PBT allows
us to use data generated from dialogues between smaller 7-8B models for
training much larger 70B models. Moreover, PBT consistently improves resistance
to misinformation and resilience to being challenged while also resulting in
the best overall performance on holistic data containing both positive and
negative persuasion. Crucially, we show that PBT models are better teammates in
multi-agent debates across two domains (trivia and commonsense QA). We find
that without PBT, pairs of stronger and weaker models have unstable
performance, with the order in which the models present their answers
determining whether the team obtains the stronger or weaker model's
performance. PBT leads to better and more stable results and less order
dependence, with the stronger model consistently pulling the weaker one up.",2024-10-18,"Elias Stengel-Eskin, Peter Hase, Mohit Bansal",http://arxiv.org/pdf/2410.14596v2,cs.CL
Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases,"Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks
like secure database interactions and multi-agent code development. However,
scaling tool capacity beyond agent reasoning or model limits remains a
challenge. In this paper, we address these challenges by introducing Toolshed
Knowledge Bases, a tool knowledge base (vector database) designed to store
enhanced tool representations and optimize tool selection for large-scale
tool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a
novel ensemble of tool-applied advanced retrieval-augmented generation (RAG)
techniques across the pre-retrieval, intra-retrieval, and post-retrieval
phases, without requiring model fine-tuning. During pre-retrieval, tool
documents are enhanced with key information and stored in the Toolshed
Knowledge Base. Intra-retrieval focuses on query planning and transformation to
increase retrieval accuracy. Post-retrieval refines the retrieved tool
documents and enables self-reflection. Furthermore, by varying both the total
number of tools (tool-M) an Agent has access to and the tool selection
threshold (top-k), we address trade-offs between retrieval accuracy, agent
performance, and token cost. Our approach achieves 46%, 56%, and 47% absolute
improvements on the ToolE single-tool, ToolE multi-tool and Seal-Tools
benchmark datasets, respectively (Recall@5).",2024-10-18,"Elias Lumer, Vamse Kumar Subbiah, James A. Burke, Pradeep Honaganahalli Basavaraju, Austin Huber",http://arxiv.org/pdf/2410.14594v2,cs.CL
"Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a Continuum","There is increasing interest in looking at dialects in NLP. However, most
work to date still treats dialects as discrete categories. For instance,
evaluative work in variation-oriented NLP for English often works with Indian
English or African-American Venacular English as homogeneous categories (Faisal
et al., 2024; Ziems et al., 2023), yet even within one variety there is
substantial variation. We examine within-dialect variation and show that
performance critically varies within categories. We measure speech-to-text
performance on Italian dialects, and empirically observe a geographical
performance disparity. This disparity correlates substantially (-0.5) with
linguistic similarity to the highest performing dialect variety. We
cross-examine our results against dialectometry methods, and interpret the
performance disparity to be due to a bias towards dialects that are more
similar to the standard variety in the speech-to-text model examined. We
additionally leverage geostatistical methods to predict zero-shot performance
at unseen sites, and find the incorporation of geographical information to
substantially improve prediction performance, indicating there to be
geographical structure in the performance distribution.",2024-10-18,"Ryan Soh-Eun Shim, Barbara Plank",http://arxiv.org/pdf/2410.14589v1,cs.CL
Do LLMs estimate uncertainty well in instruction-following?,"Large language models (LLMs) could be valuable personal AI agents across
various domains, provided they can precisely follow user instructions. However,
recent studies have shown significant limitations in LLMs'
instruction-following capabilities, raising concerns about their reliability in
high-stakes applications. Accurately estimating LLMs' uncertainty in adhering
to instructions is critical to mitigating deployment risks. We present, to our
knowledge, the first systematic evaluation of the uncertainty estimation
abilities of LLMs in the context of instruction-following. Our study identifies
key challenges with existing instruction-following benchmarks, where multiple
factors are entangled with uncertainty stems from instruction-following,
complicating the isolation and comparison across methods and models. To address
these issues, we introduce a controlled evaluation setup with two benchmark
versions of data, enabling a comprehensive comparison of uncertainty estimation
methods under various conditions. Our findings show that existing uncertainty
methods struggle, particularly when models make subtle errors in instruction
following. While internal model states provide some improvement, they remain
inadequate in more complex scenarios. The insights from our controlled
evaluation setups provide a crucial understanding of LLMs' limitations and
potential for uncertainty estimation in instruction-following tasks, paving the
way for more trustworthy AI agents.",2024-10-18,"Juyeon Heo, Miao Xiong, Christina Heinze-Deml, Jaya Narain",http://arxiv.org/pdf/2410.14582v4,cs.CL
Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection,"Attention mechanisms have revolutionized several domains of artificial
intelligence, such as natural language processing and computer vision, by
enabling models to selectively focus on relevant parts of the input data. While
recent work has characterized the optimization dynamics of gradient descent
(GD) in attention-based models and the structural properties of its preferred
solutions, less is known about more general optimization algorithms such as
mirror descent (MD). In this paper, we investigate the convergence properties
and implicit biases of a family of MD algorithms tailored for softmax attention
mechanisms, with the potential function chosen as the $p$-th power of the
$\ell_p$-norm. Specifically, we show that these algorithms converge in
direction to a generalized hard-margin SVM with an $\ell_p$-norm objective when
applied to a classification problem using a softmax attention model. Notably,
our theoretical results reveal that the convergence rate is comparable to that
of traditional GD in simpler models, despite the highly nonlinear and nonconvex
nature of the present problem. Additionally, we delve into the joint
optimization dynamics of the key-query matrix and the decoder, establishing
conditions under which this complex joint optimization converges to their
respective hard-margin SVM solutions. Lastly, our numerical experiments on real
data demonstrate that MD algorithms improve generalization over standard GD and
excel in optimal token selection.",2024-10-18,"Addison Kristanto Julistiono, Davoud Ataee Tarzanagh, Navid Azizan",http://arxiv.org/pdf/2410.14581v3,cs.CL
Large Language Models Are Overparameterized Text Encoders,"Large language models (LLMs) demonstrate strong performance as text embedding
models when finetuned with supervised contrastive training. However, their
large size balloons inference time and memory requirements. In this paper, we
show that by pruning the last $p\%$ layers of an LLM before supervised training
for only 1000 steps, we can achieve a proportional reduction in memory and
inference time. We evaluate four different state-of-the-art LLMs on text
embedding tasks and find that our method can prune up to 30\% of layers with
negligible impact on performance and up to 80\% with only a modest drop. With
only three lines of code, our method is easily implemented in any pipeline for
transforming LLMs to text encoders. We also propose $\text{L}^3 \text{Prune}$,
a novel layer-pruning strategy based on the model's initial loss that provides
two optimal pruning configurations: a large variant with negligible performance
loss and a small variant for resource-constrained settings. On average, the
large variant prunes 21\% of the parameters with a $-0.3$ performance drop, and
the small variant only suffers from a $-5.1$ decrease while pruning 74\% of the
model. We consider these results strong evidence that LLMs are
overparameterized for text embedding tasks, and can be easily pruned.",2024-10-18,"Thennal D K, Tim Fischer, Chris Biemann",http://arxiv.org/pdf/2410.14578v1,cs.CL
MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts,"Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled
scalability in deep learning. SMoE has the potential to exponentially increase
parameter count while maintaining the efficiency of the model by only
activating a small subset of these parameters for a given sample. However, it
has been observed that SMoE suffers from unstable training and has difficulty
adapting to new distributions, leading to the model's lack of robustness to
data contamination. To overcome these limitations, we first establish a
connection between the dynamics of the expert representations in SMoEs and
gradient descent on a multi-objective optimization problem. Leveraging our
framework, we then integrate momentum into SMoE and propose a new family of
SMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate
that MomentumSMoE is more stable and robust than SMoE. In particular, we verify
the advantages of MomentumSMoE over SMoE on a variety of practical tasks
including ImageNet-1K object recognition and WikiText-103 language modeling. We
demonstrate the applicability of MomentumSMoE to many types of SMoE models,
including those in the Sparse MoE model for vision (V-MoE) and the Generalist
Language Model (GLaM). We also show that other advanced momentum-based
optimization methods, such as Adam, can be easily incorporated into the
MomentumSMoE framework for designing new SMoE models with even better
performance, almost negligible additional computation cost, and simple
implementations.",2024-10-18,"Rachel S. Y. Teo, Tan M. Nguyen",http://arxiv.org/pdf/2410.14574v1,cs.CL
ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions,"Retrieval-augmented generation (RAG) has become integral to large language
models (LLMs), particularly for conversational AI systems where user questions
may reference knowledge beyond the LLMs' training cutoff. However, many natural
user questions lack well-defined answers, either due to limited domain
knowledge or because the retrieval system returns documents that are relevant
in appearance but uninformative in content. In such cases, LLMs often produce
hallucinated answers without flagging them. While recent work has largely
focused on questions with false premises, we study out-of-scope questions,
where the retrieved document appears semantically similar to the question but
lacks the necessary information to answer it. In this paper, we propose a
guided hallucination-based approach ELOQ to automatically generate a diverse
set of out-of-scope questions from post-cutoff documents, followed by human
verification to ensure quality. We use this dataset to evaluate several LLMs on
their ability to detect out-of-scope questions and generate appropriate
responses. Finally, we introduce an improved detection method that enhances the
reliability of LLM-based question-answering systems in handling out-of-scope
questions.",2024-10-18,"Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang",http://arxiv.org/pdf/2410.14567v4,cs.CL
Graph Contrastive Learning via Cluster-refined Negative Sampling for Semi-supervised Text Classification,"Graph contrastive learning (GCL) has been widely applied to text
classification tasks due to its ability to generate self-supervised signals
from unlabeled data, thus facilitating model training. However, existing
GCL-based text classification methods often suffer from negative sampling bias,
where similar nodes are incorrectly paired as negative pairs. This can lead to
over-clustering, where instances of the same class are divided into different
clusters. To address the over-clustering issue, we propose an innovative
GCL-based method of graph contrastive learning via cluster-refined negative
sampling for semi-supervised text classification, namely ClusterText. Firstly,
we combine the pre-trained model Bert with graph neural networks to learn text
representations. Secondly, we introduce a clustering refinement strategy, which
clusters the learned text representations to obtain pseudo labels. For each
text node, its negative sample set is drawn from different clusters.
Additionally, we propose a self-correction mechanism to mitigate the loss of
true negative samples caused by clustering inconsistency. By calculating the
Euclidean distance between each text node and other nodes within the same
cluster, distant nodes are still selected as negative samples. Our proposed
ClusterText demonstrates good scalable computing, as it can effectively extract
important information from from a large amount of data. Experimental results
demonstrate the superiority of ClusterText in text classification tasks.",2024-10-18,"Wei Ai, Jianbin Li, Ze Wang, Jiayi Du, Tao Meng, Yuntao Shou, Keqin Li",http://arxiv.org/pdf/2410.18130v1,cs.CL
Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization,"Meeting summarization is crucial in digital communication, but existing
solutions struggle with salience identification to generate personalized,
workable summaries, and context understanding to fully comprehend the meetings'
content. Previous attempts to address these issues by considering related
supplementary resources (e.g., presentation slides) alongside transcripts are
hindered by models' limited context sizes and handling the additional
complexities of the multi-source tasks, such as identifying relevant
information in additional files and seamlessly aligning it with the meeting
content. This work explores multi-source meeting summarization considering
supplementary materials through a three-stage large language model approach:
identifying transcript passages needing additional context, inferring relevant
details from supplementary materials and inserting them into the transcript,
and generating a summary from this enriched transcript. Our multi-source
approach enhances model understanding, increasing summary relevance by ~9% and
producing more content-rich outputs. We introduce a personalization protocol
that extracts participant characteristics and tailors summaries accordingly,
improving informativeness by ~10%. This work further provides insights on
performance-cost trade-offs across four leading model families, including
edge-device capable options. Our approach can be extended to similar complex
generative tasks benefitting from additional resources and personalization,
such as dialogue systems and action planning.",2024-10-18,"Frederic Kirstein, Terry Ruas, Robert Kratel, Bela Gipp",http://arxiv.org/pdf/2410.14545v1,cs.CL
What's New in My Data? Novelty Exploration via Contrastive Generation,"Fine-tuning is widely used to adapt language models for specific goals, often
leveraging real-world data such as patient records, customer-service
interactions, or web content in languages not covered in pre-training. These
datasets are typically massive, noisy, and often confidential, making their
direct inspection challenging. However, understanding them is essential for
guiding model deployment and informing decisions about data cleaning or
suppressing any harmful behaviors learned during fine-tuning. In this study, we
introduce the task of novelty discovery through generation, which aims to
identify novel properties of a fine-tuning dataset by generating examples that
illustrate these properties. Our approach, Contrastive Generative Exploration
(CGE), assumes no direct access to the data but instead relies on a pre-trained
model and the same model after fine-tuning. By contrasting the predictions of
these two models, CGE can generate examples that highlight novel
characteristics of the fine-tuning data. However, this simple approach may
produce examples that are too similar to one another, failing to capture the
full range of novel phenomena present in the dataset. We address this by
introducing an iterative version of CGE, where the previously generated
examples are used to update the pre-trained model, and this updated model is
then contrasted with the fully fine-tuned model to generate the next example,
promoting diversity in the generated outputs. Our experiments demonstrate the
effectiveness of CGE in detecting novel content, such as toxic language, as
well as new natural and programming languages. Furthermore, we show that CGE
remains effective even when models are fine-tuned using differential privacy
techniques.",2024-10-18,"Masaru Isonuma, Ivan Titov",http://arxiv.org/pdf/2410.14765v1,cs.CL
AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an LLM-based Empathetic Coworker,"Client-Service Representatives (CSRs) are vital to organizations. Frequent
interactions with disgruntled clients, however, disrupt their mental
well-being. To help CSRs regulate their emotions while interacting with uncivil
clients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its
efficacy, perception, and use. Our comparative analyses between 665 human and
Care-Pilot-generated support messages highlight Care-Pilot's ability to adapt
to and demonstrate empathy in various incivility incidents. Additionally, 143
CSRs assessed Care-Pilot's empathy as more sincere and actionable than human
messages. Finally, we interviewed 20 CSRs who interacted with Care-Pilot in a
simulation exercise. They reported that Care-Pilot helped them avoid negative
thinking, recenter thoughts, and humanize clients; showing potential for
bridging gaps in coworker support. Yet, they also noted deployment challenges
and emphasized the indispensability of shared experiences. We discuss future
designs and societal implications of AI-mediated emotional labor, underscoring
empathy as a critical function for AI assistants for worker mental health.",2024-10-18,"Vedant Das Swain, Qiuyue ""Joy"" Zhong, Jash Rajesh Parekh, Yechan Jeon, Roy Zimmermann, Mary Czerwinski, Jina Suh, Varun Mishra, Koustuv Saha, Javier Hernandez",http://arxiv.org/pdf/2411.02408v2,cs.CL
"Do LLMs ""know"" internally when they follow instructions?","Instruction-following is crucial for building AI agents with large language
models (LLMs), as these models must adhere strictly to user-provided
constraints and guidelines. However, LLMs often fail to follow even simple and
clear instructions. To improve instruction-following behavior and prevent
undesirable outputs, a deeper understanding of how LLMs' internal states relate
to these outcomes is required. In this work, we investigate whether LLMs encode
information in their representations that correlate with instruction-following
success - a property we term knowing internally. Our analysis identifies a
direction in the input embedding space, termed the instruction-following
dimension, that predicts whether a response will comply with a given
instruction. We find that this dimension generalizes well across unseen tasks
but not across unseen instruction types. We demonstrate that modifying
representations along this dimension improves instruction-following success
rates compared to random changes, without compromising response quality.
Further investigation reveals that this dimension is more closely related to
the phrasing of prompts rather than the inherent difficulty of the task or
instructions. This work provides insight into the internal workings of LLMs'
instruction-following, paving the way for reliable LLM agents.",2024-10-18,"Juyeon Heo, Christina Heinze-Deml, Oussama Elachqar, Kwan Ho Ryan Chan, Shirley Ren, Udhay Nallasamy, Andy Miller, Jaya Narain",http://arxiv.org/pdf/2410.14516v5,cs.CL
SignAttention: On the Interpretability of Transformer Models for Sign Language Translation,"This paper presents the first comprehensive interpretability analysis of a
Transformer-based Sign Language Translation (SLT) model, focusing on the
translation from video-based Greek Sign Language to glosses and text.
Leveraging the Greek Sign Language Dataset, we examine the attention mechanisms
within the model to understand how it processes and aligns visual input with
sequential glosses. Our analysis reveals that the model pays attention to
clusters of frames rather than individual ones, with a diagonal alignment
pattern emerging between poses and glosses, which becomes less distinct as the
number of glosses increases. We also explore the relative contributions of
cross-attention and self-attention at each decoding step, finding that the
model initially relies on video frames but shifts its focus to previously
predicted tokens as the translation progresses. This work contributes to a
deeper understanding of SLT models, paving the way for the development of more
transparent and reliable translation systems essential for real-world
applications.",2024-10-18,"Pedro Alejandro Dal Bianco, Oscar Agustín Stanchi, Facundo Manuel Quiroga, Franco Ronchetti, Enzo Ferrante",http://arxiv.org/pdf/2410.14506v1,cs.CL
Enabling Scalable Evaluation of Bias Patterns in Medical LLMs,"Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.",2024-10-18,"Hamed Fayyaz, Raphael Poulain, Rahmatollah Beheshti",http://arxiv.org/pdf/2410.14763v2,cs.CL
Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of Language Models,"As large language models (LLMs) continue to advance, the need for precise and
efficient evaluation metrics becomes more pressing. Traditional approaches,
while informative, often face limitations in computational demands and
interpretability. In this paper, we introduce a novel hybrid evaluation method
that integrates two established techniques: entropy derived from covariance
matrices and the Matrix Nuclear Norm (MNN). Our method begins by normalizing
hidden states from LLMs, then computes the covariance matrix and MNN from these
representations. We further calculate the entropy of the covariance matrix to
capture uncertainty and redundancy in the model's outputs. By combining these
metrics into a composite score, we offer a comprehensive evaluation framework
that balances accuracy with computational efficiency. Additionally, our
approach allows for flexibility in adjusting the weightings between entropy and
MNN, tailoring the evaluation for different objectives. Through a series of
experiments on various LLMs, we demonstrate the robustness and efficacy of our
method, offering deeper insights into model performance. This work contributes
to the ongoing development of LLM evaluation and opens avenues for future
innovations in model assessment techniques.",2024-10-18,James Vo,http://arxiv.org/pdf/2410.14480v1,cs.CL
This Candidate is [MASK]. Letters of Reference and Job Market Outcomes using LLMs,"I implement a prompt-based learning strategy to extract measures of sentiment
and other features from confidential reference letters. I show that the
contents of reference letters is clearly reflected in the performance of job
market candidates in the Economics academic job market. In contrast, applying
traditional ``bag-of-words'' approaches produces measures of sentiment that,
while positively correlated to my LLM-based measure, are not predictive of job
market outcomes. Using a random forest, I show that both letter quality and
length are predictive of success in the job market. Letters authored by
advisers appear to be as important as those written by other referees.",2024-10-18,Fabian Slonimczyk,http://arxiv.org/pdf/2410.16325v1,cs.CL
A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference,"Recently, sharing key-value (KV) cache across layers has been found effective
in efficient inference of large language models (LLMs). To systematically
investigate different techniques of cross-layer KV sharing, we propose a
unified framework that covers several recent methods and their novel variants.
We conduct comprehensive experiments on all the configurations of the
framework, evaluating their generation throughput and performance in language
modeling and downstream tasks. We find that when reducing the size of the KV
cache by 2$\times$, most configurations can achieve higher throughput than
standard transformers while maintaining competitive performance. When further
reducing the size of the KV cache, however, pairing queries of all layers with
KVs of upper layers performs better, at the expense of additional training cost
and prefilling latency. We hope that this work will help users make more
informed choices of cross-layer KV sharing approaches and facilitate future
research on efficient LLM inference.",2024-10-18,"You Wu, Haoyi Wu, Kewei Tu",http://arxiv.org/pdf/2410.14442v2,cs.CL
Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation,"Parameter-efficient fine-tuning (PEFT) can bridge the gap between large
language models (LLMs) and downstream tasks. However, PEFT has been proven
vulnerable to malicious attacks. Research indicates that poisoned LLMs, even
after PEFT, retain the capability to activate internalized backdoors when input
samples contain predefined triggers. In this paper, we introduce a novel
weak-to-strong unlearning algorithm to defend against backdoor attacks based on
feature alignment knowledge distillation, named W2SDefense. Specifically, we
first train a small-scale language model through full-parameter fine-tuning to
serve as the clean teacher model. Then, this teacher model guides the
large-scale poisoned student model in unlearning the backdoor, leveraging PEFT.
Theoretical analysis suggests that W2SDefense has the potential to enhance the
student model's ability to unlearn backdoor features, preventing the activation
of the backdoor. We conduct comprehensive experiments on three state-of-the-art
large language models and several different backdoor attack algorithms. Our
empirical results demonstrate the outstanding performance of W2SDefense in
defending against backdoor attacks without compromising model performance.",2024-10-18,"Shuai Zhao, Xiaobao Wu, Cong-Duy Nguyen, Yanhao Jia, Meihuizi Jia, Yichao Feng, Luu Anh Tuan",http://arxiv.org/pdf/2410.14425v2,cs.CL
"Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion","Language models (LMs) can make a correct prediction based on many possible
signals in a prompt, not all corresponding to recall of factual associations.
However, current interpretations of LMs fail to take this into account. For
example, given the query ""Astrid Lindgren was born in"" with the corresponding
completion ""Sweden"", no difference is made between whether the prediction was
based on knowing where the author was born or assuming that a person with a
Swedish-sounding name was born in Sweden. In this paper, we present a
model-specific recipe - PrISM - for constructing datasets with examples of four
different prediction scenarios: generic language modeling, guesswork,
heuristics recall and exact fact recall. We apply two popular interpretability
methods to the scenarios: causal tracing (CT) and information flow analysis. We
find that both yield distinct results for each scenario. Results for exact fact
recall and generic language modeling scenarios confirm previous conclusions
about the importance of mid-range MLP sublayers for fact recall, while results
for guesswork and heuristics indicate a critical role of late last token
position MLP sublayers. In summary, we contribute resources for a more
extensive and granular study of fact completion in LMs, together with analyses
that provide a more nuanced understanding of how LMs process fact-related
queries.",2024-10-18,"Denitsa Saynova, Lovisa Hagström, Moa Johansson, Richard Johansson, Marco Kuhlmann",http://arxiv.org/pdf/2410.14405v3,cs.CL
SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning,"Syllogistic reasoning is crucial for Natural Language Inference (NLI). This
capability is particularly significant in specialized domains such as
biomedicine, where it can support automatic evidence interpretation and
scientific discovery. This paper presents SylloBio-NLI, a novel framework that
leverages external ontologies to systematically instantiate diverse syllogistic
arguments for biomedical NLI. We employ SylloBio-NLI to evaluate Large Language
Models (LLMs) on identifying valid conclusions and extracting supporting
evidence across 28 syllogistic schemes instantiated with human genome pathways.
Extensive experiments reveal that biomedical syllogistic reasoning is
particularly challenging for zero-shot LLMs, which achieve an average accuracy
between 70% on generalized modus ponens and 23% on disjunctive syllogism. At
the same time, we found that few-shot prompting can boost the performance of
different LLMs, including Gemma (+14%) and LLama-3 (+43%). However, a deeper
analysis shows that both techniques exhibit high sensitivity to superficial
lexical variations, highlighting a dependency between reliability, models'
architecture, and pre-training regime. Overall, our results indicate that,
while in-context examples have the potential to elicit syllogistic reasoning in
LLMs, existing models are still far from achieving the robustness and
consistency required for safe biomedical NLI applications.",2024-10-18,"Magdalena Wysocka, Danilo Carvalho, Oskar Wysocki, Marco Valentino, Andre Freitas",http://arxiv.org/pdf/2410.14399v2,cs.CL
"Generative AI, Pragmatics, and Authenticity in Second Language Learning","There are obvious benefits to integrating generative AI (artificial
intelligence) into language learning and teaching. Those include using AI as a
language tutor, creating learning materials, or assessing learner output.
However, due to how AI systems under-stand human language, based on a
mathematical model using statistical probability, they lack the lived
experience to be able to use language with the same social aware-ness as
humans. Additionally, there are built-in linguistic and cultural biases based
on their training data which is mostly in English and predominantly from
Western sources. Those facts limit AI suitability for some language learning
interactions. Stud-ies have clearly shown that systems such as ChatGPT often do
not produce language that is pragmatically appropriate. The lack of linguistic
and cultural authenticity has important implications for how AI is integrated
into second language acquisition as well as in instruction targeting
development of intercultural communication compe-tence.",2024-10-18,Robert Godwin-Jones`,http://arxiv.org/pdf/2410.14395v1,cs.CL
Context-Aware or Context-Insensitive? Assessing LLMs' Performance in Document-Level Translation,"Large language models (LLMs) are increasingly strong contenders in machine
translation. In this work, we focus on document-level translation, where some
words cannot be translated without context from outside the sentence.
Specifically, we investigate the ability of prominent LLMs to utilize the
document context during translation through a perturbation analysis (analyzing
models' robustness to perturbed and randomized document context) and an
attribution analysis (examining the contribution of relevant context to the
translation). We conduct an extensive evaluation across nine LLMs from diverse
model families and training paradigms, including translation-specialized LLMs,
alongside two encoder-decoder transformer baselines. We find that LLMs'
improved document-translation performance compared to encoder-decoder models is
not reflected in pronoun translation performance. Our analysis highlight the
need for context-aware finetuning of LLMs with a focus on relevant parts of the
context to improve their reliability for document-level translation.",2024-10-18,"Wafaa Mohammed, Vlad Niculae",http://arxiv.org/pdf/2410.14391v2,cs.CL
How Do Multilingual Language Models Remember Facts?,"Large Language Models (LLMs) store and retrieve vast amounts of factual
knowledge acquired during pre-training. Prior research has localized and
identified mechanisms behind knowledge recall; however, it has only focused on
English monolingual models. The question of how these mechanisms generalize to
non-English languages and multilingual LLMs remains unexplored. In this paper,
we address this gap by conducting a comprehensive analysis of three
multilingual LLMs. First, we show that previously identified recall mechanisms
in English largely apply to multilingual contexts, with nuances based on
language and architecture. Next, through patching intermediate representations,
we localize the role of language during recall, finding that subject enrichment
is language-independent, while object extraction is language-dependent.
Additionally, we discover that the last token representation acts as a Function
Vector (FV), encoding both the language of the query and the content to be
extracted from the subject. Furthermore, in decoder-only LLMs, FVs compose
these two pieces of information in two separate stages. These insights reveal
unique mechanisms in multilingual LLMs for recalling information, highlighting
the need for new methodologies--such as knowledge evaluation, fact editing, and
knowledge acquisition--that are specifically tailored for multilingual LLMs.",2024-10-18,"Constanza Fierro, Negar Foroutan, Desmond Elliott, Anders Søgaard",http://arxiv.org/pdf/2410.14387v2,cs.CL
Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning,"The fine-tuning of pre-trained language models (PLMs) has been shown to be
effective across various domains. By using domain-specific supervised data, the
general-purpose representation derived from PLMs can be transformed into a
domain-specific representation. However, these methods often fail to generalize
to out-of-domain (OOD) data due to their reliance on non-causal
representations, often described as spurious features. Existing methods either
make use of adjustments with strong assumptions about lack of hidden common
causes, or mitigate the effect of spurious features using multi-domain data. In
this work, we investigate how fine-tuned pre-trained language models aid
generalizability from single-domain scenarios under mild assumptions, targeting
more general and practical real-world scenarios. We show that a robust
representation can be derived through a so-called causal front-door adjustment,
based on a decomposition assumption, using fine-tuned representations as a
source of data augmentation. Comprehensive experiments in both synthetic and
real-world settings demonstrate the superior generalizability of the proposed
method compared to existing approaches. Our work thus sheds light on the domain
generalization problem by introducing links between fine-tuning and causal
mechanisms into representation learning.",2024-10-18,"Jialin Yu, Yuxiang Zhou, Yulan He, Nevin L. Zhang, Ricardo Silva",http://arxiv.org/pdf/2410.14375v1,cs.CL
Efficiently Computing Susceptibility to Context in Language Models,"One strength of modern language models is their ability to incorporate
information from a user-input context when answering queries. However, they are
not equally sensitive to the subtle changes to that context. To quantify this,
Du et al. (2024) gives an information-theoretic metric to measure such
sensitivity. Their metric, susceptibility, is defined as the degree to which
contexts can influence a model's response to a query at a distributional level.
However, exactly computing susceptibility is difficult and, thus, Du et al.
(2024) falls back on a Monte Carlo approximation. Due to the large number of
samples required, the Monte Carlo approximation is inefficient in practice. As
a faster alternative, we propose Fisher susceptibility, an efficient method to
estimate the susceptibility based on Fisher information. Empirically, we
validate that Fisher susceptibility is comparable to Monte Carlo estimated
susceptibility across a diverse set of query domains despite its being
$70\times$ faster. Exploiting the improved efficiency, we apply Fisher
susceptibility to analyze factors affecting the susceptibility of language
models. We observe that larger models are as susceptible as smaller ones.",2024-10-18,"Tianyu Liu, Kevin Du, Mrinmaya Sachan, Ryan Cotterell",http://arxiv.org/pdf/2410.14361v1,cs.CL
Critical Questions Generation: Motivation and Challenges,"The development of Large Language Models (LLMs) has brought impressive
performances on mitigation strategies against misinformation, such as
counterargument generation. However, LLMs are still seriously hindered by
outdated knowledge and by their tendency to generate hallucinated content. In
order to circumvent these issues, we propose a new task, namely, Critical
Questions Generation, consisting of processing an argumentative text to
generate the critical questions (CQs) raised by it. In argumentation theory CQs
are tools designed to lay bare the blind spots of an argument by pointing at
the information it could be missing. Thus, instead of trying to deploy LLMs to
produce knowledgeable and relevant counterarguments, we use them to question
arguments, without requiring any external knowledge. Research on CQs Generation
using LLMs requires a reference dataset for large scale experimentation. Thus,
in this work we investigate two complementary methods to create such a
resource: (i) instantiating CQs templates as defined by Walton's argumentation
theory and (ii), using LLMs as CQs generators. By doing so, we contribute with
a procedure to establish what is a valid CQ and conclude that, while LLMs are
reasonable CQ generators, they still have a wide margin for improvement in this
task.",2024-10-18,"Blanca Calvo Figueras, Rodrigo Agerri",http://arxiv.org/pdf/2410.14335v1,cs.CL
LoGU: Long-form Generation with Uncertainty Expressions,"While Large Language Models (LLMs) demonstrate impressive capabilities, they
still struggle with generating factually incorrect content (i.e.,
hallucinations). A promising approach to mitigate this issue is enabling models
to express uncertainty when unsure. Previous research on uncertainty modeling
has primarily focused on short-form QA, but realworld applications often
require much longer responses. In this work, we introduce the task of Long-form
Generation with Uncertainty(LoGU). We identify two key challenges: Uncertainty
Suppression, where models hesitate to express uncertainty, and Uncertainty
Misalignment, where models convey uncertainty inaccurately. To tackle these
challenges, we propose a refinement-based data collection framework and a
two-stage training pipeline. Our framework adopts a divide-and-conquer
strategy, refining uncertainty based on atomic claims. The collected data are
then used in training through supervised fine-tuning (SFT) and direct
preference optimization (DPO) to enhance uncertainty expression. Extensive
experiments on three long-form instruction following datasets show that our
method significantly improves accuracy, reduces hallucinations, and maintains
the comprehensiveness of responses.",2024-10-18,"Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang",http://arxiv.org/pdf/2410.14309v2,cs.CL
SwaQuAD-24: QA Benchmark Dataset in Swahili,"This paper proposes the creation of a Swahili Question Answering (QA)
benchmark dataset, aimed at addressing the underrepresentation of Swahili in
natural language processing (NLP). Drawing from established benchmarks like
SQuAD, GLUE, KenSwQuAD, and KLUE, the dataset will focus on providing
high-quality, annotated question-answer pairs that capture the linguistic
diversity and complexity of Swahili. The dataset is designed to support a
variety of applications, including machine translation, information retrieval,
and social services like healthcare chatbots. Ethical considerations, such as
data privacy, bias mitigation, and inclusivity, are central to the dataset
development. Additionally, the paper outlines future expansion plans to include
domain-specific content, multimodal integration, and broader crowdsourcing
efforts. The Swahili QA dataset aims to foster technological innovation in East
Africa and provide an essential resource for NLP research and applications in
low-resource languages.",2024-10-18,Alfred Malengo Kondoro,http://arxiv.org/pdf/2410.14289v1,cs.CL
EcomEdit: An Automated E-commerce Knowledge Editing Framework for Enhanced Product and Purchase Intention Understanding,"Knowledge Editing (KE) aims to correct and update factual information in
Large Language Models (LLMs) to ensure accuracy and relevance without
computationally expensive fine-tuning. Though it has been proven effective in
several domains, limited work has focused on its application within the
e-commerce sector. However, there are naturally occurring scenarios that make
KE necessary in this domain, such as the timely updating of product features
and trending purchase intentions by customers, which necessitate further
exploration. In this paper, we pioneer the application of KE in the e-commerce
domain by presenting ECOMEDIT, an automated e-commerce knowledge editing
framework tailored for e-commerce-related knowledge and tasks. Our framework
leverages more powerful LLMs as judges to enable automatic knowledge conflict
detection and incorporates conceptualization to enhance the semantic coverage
of the knowledge to be edited. Through extensive experiments, we demonstrate
the effectiveness of ECOMEDIT in improving LLMs' understanding of product
descriptions and purchase intentions. We also show that LLMs, after our
editing, can achieve stronger performance on downstream e-commerce tasks.",2024-10-18,"Ching Ming Samuel Lau, Weiqi Wang, Haochen Shi, Baixuan Xu, Jiaxin Bai, Yangqiu Song",http://arxiv.org/pdf/2410.14276v1,cs.CL
REEF: Representation Encoding Fingerprints for Large Language Models,"Protecting the intellectual property of open-source Large Language Models
(LLMs) is very important, because training LLMs costs extensive computational
resources and data. Therefore, model owners and third parties need to identify
whether a suspect model is a subsequent development of the victim model. To
this end, we propose a training-free REEF to identify the relationship between
the suspect and victim models from the perspective of LLMs' feature
representations. Specifically, REEF computes and compares the centered kernel
alignment similarity between the representations of a suspect model and a
victim model on the same samples. This training-free REEF does not impair the
model's general capabilities and is robust to sequential fine-tuning, pruning,
model merging, and permutations. In this way, REEF provides a simple and
effective way for third parties and models' owners to protect LLMs'
intellectual property together. The code is available at
https://github.com/tmylla/REEF.",2024-10-18,"Jie Zhang, Dongrui Liu, Chen Qian, Linfeng Zhang, Yong Liu, Yu Qiao, Jing Shao",http://arxiv.org/pdf/2410.14273v1,cs.CL
MoDification: Mixture of Depths Made Easy,"Long-context efficiency has recently become a trending topic in serving large
language models (LLMs). And mixture of depths (MoD) is proposed as a perfect
fit to bring down both latency and memory. In this paper, however, we discover
that MoD can barely transform existing LLMs without costly training over an
extensive number of tokens. To enable the transformations from any LLMs to MoD
ones, we showcase top-k operator in MoD should be promoted to threshold-p
operator, and refinement to architecture and data should also be crafted along.
All these designs form our method termed MoDification. Through a comprehensive
set of experiments covering model scales from 3B to 70B, we exhibit
MoDification strikes an excellent balance between efficiency and effectiveness.
MoDification can achieve up to ~1.2x speedup in latency and ~1.8x reduction in
memory compared to original LLMs especially in long-context applications.",2024-10-18,"Chen Zhang, Meizhi Zhong, Qimeng Wang, Xuantao Lu, Zheyu Ye, Chengqiang Lu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang, Dawei Song",http://arxiv.org/pdf/2410.14268v1,cs.CL
Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation,"This study explores the ability of Large Language Model (LLM) agents to
detect and correct hallucinations in AI-generated content. A primary agent was
tasked with creating a blog about a fictional Danish artist named Flipfloppidy,
which was then reviewed by another agent for factual inaccuracies. Most LLMs
hallucinated the existence of this artist. Across 4,900 test runs involving
various combinations of primary and reviewing agents, advanced AI models such
as Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy in
identifying hallucinations and successfully revised outputs in 85% to 100% of
cases following feedback. These findings underscore the potential of advanced
AI models to significantly enhance the accuracy and reliability of generated
content, providing a promising approach to improving AI workflow orchestration.",2024-10-18,"Ted Kwartler, Matthew Berman, Alan Aqrawi",http://arxiv.org/pdf/2410.14262v3,cs.CL
Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement,"The rapid development of large language models (LLMs), like ChatGPT, has
resulted in the widespread presence of LLM-generated content on social media
platforms, raising concerns about misinformation, data biases, and privacy
violations, which can undermine trust in online discourse. While detecting
LLM-generated content is crucial for mitigating these risks, current methods
often focus on binary classification, failing to address the complexities of
real-world scenarios like human-LLM collaboration. To move beyond binary
classification and address these challenges, we propose a new paradigm for
detecting LLM-generated content. This approach introduces two novel tasks: LLM
Role Recognition (LLM-RR), a multi-class classification task that identifies
specific roles of LLM in content generation, and LLM Influence Measurement
(LLM-IM), a regression task that quantifies the extent of LLM involvement in
content creation. To support these tasks, we propose LLMDetect, a benchmark
designed to evaluate detectors' performance on these new tasks. LLMDetect
includes the Hybrid News Detection Corpus (HNDC) for training detectors, as
well as DetectEval, a comprehensive evaluation suite that considers five
distinct cross-context variations and two multi-intensity variations within the
same LLM role. This allows for a thorough assessment of detectors'
generalization and robustness across diverse contexts. Our empirical validation
of 10 baseline detection methods demonstrates that fine-tuned PLM-based models
consistently outperform others on both tasks, while advanced LLMs face
challenges in accurately detecting their own generated content. Our
experimental results and analysis offer insights for developing more effective
detection models for LLM-generated content. This research enhances the
understanding of LLM-generated content and establishes a foundation for more
nuanced detection methodologies.",2024-10-18,"Zihao Cheng, Li Zhou, Feng Jiang, Benyou Wang, Haizhou Li",http://arxiv.org/pdf/2410.14259v2,cs.CL
Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas,"Scientific innovation is pivotal for humanity, and harnessing large language
models (LLMs) to generate research ideas could transform discovery. However,
existing LLMs often produce simplistic and repetitive suggestions due to their
limited ability in acquiring external knowledge for innovation. To address this
problem, we introduce an enhanced planning and search methodology designed to
boost the creative potential of LLM-based systems. Our approach involves an
iterative process to purposely plan the retrieval of external knowledge,
progressively enriching the idea generation with broader and deeper insights.
Validation through automated and human assessments indicates that our framework
substantially elevates the quality of generated ideas, particularly in novelty
and diversity. The number of unique novel ideas produced by our framework is
3.4 times higher than without it. Moreover, our method outperforms the current
state-of-the-art, generating at least 2.5 times more top-rated ideas based on
170 seed papers in a Swiss Tournament evaluation.",2024-10-18,"Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan",http://arxiv.org/pdf/2410.14255v2,cs.CL
Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation,"Post-training is essential for enabling large language models (LLMs) to
follow human instructions. However, its effectiveness depends on high-quality
instruction data, which is challenging to obtain in the real world due to
privacy concerns, data scarcity, and high annotation costs. To fill this gap,
inspired by the recent success of using LLMs to simulate human society, we
propose MATRIX, a multi-agent simulator that automatically generates diverse
text-based scenarios, capturing a wide range of real-world human needs in a
realistic and scalable manner. Leveraging these outputs, we introduce a novel
scenario-driven instruction generator MATRIX-Gen for controllable and highly
realistic data synthesis. Extensive experiments demonstrate that our framework
effectively generates both general and domain-specific data. On AlpacaEval 2
and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on datasets
synthesized by MATRIX-Gen with just 20K instruction-response pairs, outperforms
Meta's Llama-3-8B-Instruct model, which was trained on over 10M pairs.",2024-10-18,"Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Tian Jin, Xiaowen Dong, Yanfeng Wang, Siheng Chen",http://arxiv.org/pdf/2410.14251v2,cs.CL
Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models,"Evaluating Video Language Models (VLMs) is a challenging task. Due to its
transparency, Multiple-Choice Question Answering (MCQA) is widely used to
measure the performance of these models through accuracy. However, existing
MCQA benchmarks fail to capture the full reasoning capabilities of VLMs due to
selection bias, when models disproportionately favor certain answer options
based on positional patterns observed during training. In this work, we conduct
a comprehensive empirical analysis of several VLM architectures across major
datasets designed to assess complex video-focused reasoning. We identify where
the bias is most pronounced and demonstrate to what extent model responses
reflect genuine understanding of video content and related questions, as
opposed to reliance on arbitrary patterns or superficial cues, such as answer
position. By decomposing the MCQA task and adapting fairness bias metrics to
VLMs, we introduce a post-processing calibration technique BOLD to balance this
bias. Our results show that reducing selection bias improves not only debiasing
metrics but also overall model performance, including Accuracy and F1 Mean
score. Our method, by suppressing ""blind guessing"", offers a more cost- and
time-effective approach to mitigating selection bias compared to existing
techniques. This study represents the first focused investigation of selection
bias in video-to-text LLM-powered models.",2024-10-18,"Olga Loginova, Oleksandr Bezrukov, Alexey Kravets",http://arxiv.org/pdf/2410.14248v1,cs.CL
A Novel Method to Metigate Demographic and Expert Bias in ICD Coding with Causal Inference,"ICD(International Classification of Diseases) coding involves assigning ICD
codes to patients visit based on their medical notes. Considering ICD coding as
a multi-label text classification task, researchers have developed
sophisticated methods. Despite progress, these models often suffer from label
imbalance and may develop spurious correlations with demographic factors.
Additionally, while human coders assign ICD codes, the inclusion of irrelevant
information from unrelated experts introduces biases. To combat these issues,
we propose a novel method to mitigate Demographic and Expert biases in ICD
coding through Causal Inference (DECI). We provide a novel causality-based
interpretation in ICD Coding that models make predictions by three distinct
pathways. And based counterfactual reasoning, DECI mitigate demographic and
expert biases. Experimental results show that DECI outperforms state-of-the-art
models, offering a significant advancement in accurate and unbiased ICD coding.",2024-10-18,"Bin Zhang, Junli Wang",http://arxiv.org/pdf/2410.14236v1,cs.CL
Towards Robust Knowledge Representations in Multilingual LLMs for Equivalence and Inheritance based Consistent Reasoning,"Reasoning and linguistic skills form the cornerstone of human intelligence,
facilitating problem-solving and decision-making. Recent advances in Large
Language Models (LLMs) have led to impressive linguistic capabilities and
emergent reasoning behaviors, fueling widespread adoption across application
domains. However, LLMs still struggle with complex reasoning tasks,
highlighting their systemic limitations. In this work, we focus on evaluating
whether LLMs have the requisite representations to reason using two
foundational relationships: ""equivalence"" and ""inheritance"". We introduce novel
tasks and benchmarks spanning six languages and observe that current SOTA LLMs
often produce conflicting answers to the same questions across languages in
17.3-57.5% of cases and violate inheritance constraints in up to 37.2% cases.
To enhance consistency across languages, we propose novel ""Compositional
Representations"" where tokens are represented as composition of equivalent
tokens across languages, with resulting conflict reduction (up to -4.7%)
indicating benefits of shared LLM representations.",2024-10-18,"Gaurav Arora, Srujana Merugu, Shreya Jain, Vaibhav Saxena",http://arxiv.org/pdf/2410.14235v1,cs.CL
Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework,"Large language models (LLMs) have transformed human writing by enhancing
grammar correction, content expansion, and stylistic refinement. However, their
widespread use raises concerns about authorship, originality, and ethics, even
potentially threatening scholarly integrity. Existing detection methods, which
mainly rely on single-feature analysis and binary classification, often fail to
effectively identify LLM-generated text in academic contexts. To address these
challenges, we propose a novel Multi-level Fine-grained Detection (MFD)
framework that detects LLM-generated text by integrating low-level structural,
high-level semantic, and deep-level linguistic features, while conducting
sentence-level evaluations of lexicon, grammar, and syntax for comprehensive
analysis. To improve detection of subtle differences in LLM-generated text and
enhance robustness against paraphrasing, we apply two mainstream evasion
techniques to rewrite the text. These variations, along with original texts,
are used to train a text encoder via contrastive learning, extracting
high-level semantic features of sentence to boost detection generalization.
Furthermore, we leverage advanced LLM to analyze the entire text and extract
deep-level linguistic features, enhancing the model's ability to capture
complex patterns and nuances while effectively incorporating contextual
information. Extensive experiments on public datasets show that the MFD model
outperforms existing methods, achieving an MAE of 0.1346 and an accuracy of
88.56%. Our research provides institutions and publishers with an effective
mechanism to detect LLM-generated text, mitigating risks of compromised
authorship. Educators and editors can use the model's predictions to refine
verification and plagiarism prevention protocols, ensuring adherence to
standards.",2024-10-18,"Zhen Tao, Zhiyu Li, Runyu Chen, Dinghao Xi, Wei Xu",http://arxiv.org/pdf/2410.14231v1,cs.CL
Controllable Discovery of Intents: Incremental Deep Clustering Using Semi-Supervised Contrastive Learning,"Deriving value from a conversational AI system depends on the capacity of a
user to translate the prior knowledge into a configuration. In most cases,
discovering the set of relevant turn-level speaker intents is often one of the
key steps. Purely unsupervised algorithms provide a natural way to tackle
discovery problems but make it difficult to incorporate constraints and only
offer very limited control over the outcomes. Previous work has shown that
semi-supervised (deep) clustering techniques can allow the system to
incorporate prior knowledge and constraints in the intent discovery process.
However they did not address how to allow for control through human feedback.
In our Controllable Discovery of Intents (CDI) framework domain and prior
knowledge are incorporated using a sequence of unsupervised contrastive
learning on unlabeled data followed by fine-tuning on partially labeled data,
and finally iterative refinement of clustering and representations through
repeated clustering and pseudo-label fine-tuning. In addition, we draw from
continual learning literature and use learning-without-forgetting to prevent
catastrophic forgetting across those training stages. Finally, we show how this
deep-clustering process can become part of an incremental discovery strategy
with human-in-the-loop. We report results on both CLINC and BANKING datasets.
CDI outperforms previous works by a significant margin: 10.26% and 11.72%
respectively.",2024-10-18,"Mrinal Rawat, Hithesh Sankararaman, Victor Barres",http://arxiv.org/pdf/2410.14755v1,cs.CL
Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model,"Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task
that aims to extract entities and their relations from text-image pairs in
social media posts. Existing methods for JMERE require large amounts of labeled
data. However, gathering and annotating fine-grained multimodal data for JMERE
poses significant challenges. Initially, we construct diverse and comprehensive
multimodal few-shot datasets fitted to the original data distribution. To
address the insufficient information in the few-shot setting, we introduce the
\textbf{K}nowledge-\textbf{E}nhanced \textbf{C}ross-modal \textbf{P}rompt
\textbf{M}odel (KECPM) for JMERE. This method can effectively address the
problem of insufficient information in the few-shot setting by guiding a large
language model to generate supplementary background knowledge. Our proposed
method comprises two stages: (1) a knowledge ingestion stage that dynamically
formulates prompts based on semantic similarity guide ChatGPT generating
relevant knowledge and employs self-reflection to refine the knowledge; (2) a
knowledge-enhanced language model stage that merges the auxiliary knowledge
with the original input and utilizes a transformer-based model to align with
JMERE's required output format. We extensively evaluate our approach on a
few-shot dataset derived from the JMERE dataset, demonstrating its superiority
over strong baselines in terms of both micro and macro F$_1$ scores.
Additionally, we present qualitative analyses and case studies to elucidate the
effectiveness of our model.",2024-10-18,"Li Yuan, Yi Cai, Junsheng Huang",http://arxiv.org/pdf/2410.14225v2,cs.CL
Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning,"Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.",2024-10-18,"Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang",http://arxiv.org/pdf/2410.14211v4,cs.CL
Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning,"Synthetic data has been widely used to train large language models, but their
generative nature inevitably introduces noisy, non-informative, and misleading
learning signals. In this paper, we propose Montessori-Instruct, a novel data
synthesis framework that tailors the data synthesis ability of the teacher
language model toward the student language model's learning process.
Specifically, we utilize local data influence of synthetic training data points
on students to characterize students' learning preferences. Then, we train the
teacher model with Direct Preference Optimization (DPO) to generate synthetic
data tailored toward student learning preferences. Experiments with
Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and
MT-Bench demonstrate that Montessori-Instruct significantly outperforms
standard synthesis methods by 18.35\% and 46.24\% relatively. Our method also
beats data synthesized by a stronger teacher model, GPT-4o. Further analysis
confirms the benefits of teacher's learning to generate more influential
training data in the student's improved learning, the advantages of local data
influence in accurately measuring student preferences, and the robustness of
Montessori-Instruct across different student models. Our code and data are
open-sourced at https://github.com/cxcscmu/Montessori-Instruct.",2024-10-18,"Xiaochuan Li, Zichun Yu, Chenyan Xiong",http://arxiv.org/pdf/2410.14208v1,cs.CL
MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations,"Medical task-oriented dialogue systems can assist doctors by collecting
patient medical history, aiding in diagnosis, or guiding treatment selection,
thereby reducing doctor burnout and expanding access to medical services.
However, doctor-patient dialogue datasets are not readily available, primarily
due to privacy regulations. Moreover, existing datasets lack comprehensive
annotations involving medical slots and their different attributes, such as
symptoms and their onset, progression, and severity. These comprehensive
annotations are crucial for accurate diagnosis. Finally, most existing datasets
are non-English, limiting their utility for the larger research community.
  In response, we introduce MediTOD, a new dataset of doctor-patient dialogues
in English for the medical history-taking task. Collaborating with doctors, we
devise a questionnaire-based labeling scheme tailored to the medical domain.
Then, medical professionals create the dataset with high-quality comprehensive
annotations, capturing medical slots and their attributes. We establish
benchmarks in supervised and few-shot settings on MediTOD for natural language
understanding, policy learning, and natural language generation subtasks,
evaluating models from both TOD and biomedical domains. We make MediTOD
publicly available for future research.",2024-10-18,"Vishal Vivek Saley, Goonjan Saha, Rocktim Jyoti Das, Dinesh Raghu, Mausam",http://arxiv.org/pdf/2410.14204v1,cs.CL
Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs,"Existing automated essay scoring (AES) has solely relied on essay text
without using explanatory rationales for the scores, thereby forgoing an
opportunity to capture the specific aspects evaluated by rubric indicators in a
fine-grained manner. This paper introduces Rationale-based Multiple Trait
Scoring (RMTS), a novel approach for multi-trait essay scoring that integrates
prompt-engineering-based large language models (LLMs) with a fine-tuning-based
essay scoring model using a smaller large language model (S-LLM). RMTS uses an
LLM-based trait-wise rationale generation system where a separate LLM agent
generates trait-specific rationales based on rubric guidelines, which the
scoring model uses to accurately predict multi-trait scores. Extensive
experiments on benchmark datasets, including ASAP, ASAP++, and Feedback Prize,
show that RMTS significantly outperforms state-of-the-art models and vanilla
S-LLMs in trait-specific scoring. By assisting quantitative assessment with
fine-grained qualitative rationales, RMTS enhances the trait-wise reliability,
providing partial explanations about essays. The code is available at
https://github.com/BBeeChu/RMTS.git.",2024-10-18,"SeongYeub Chu, JongWoo Kim, Bryan Wong, MunYong Yi",http://arxiv.org/pdf/2410.14202v3,cs.CL
E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model,"The development of 3D medical vision-language models holds significant
potential for disease diagnosis and patient treatment. However, compared to 2D
medical images, 3D medical images, such as CT scans, face challenges related to
limited training data and high dimension, which severely restrict the progress
of 3D medical vision-language models. To address these issues, we collect a
large amount of unlabeled 3D CT data and utilize self-supervised learning to
construct a 3D visual foundation model for extracting 3D visual features. Then,
we apply 3D spatial convolutions to aggregate and project high-level image
features, reducing computational complexity while preserving spatial
information. We also construct two instruction-tuning datasets based on BIMCV-R
and CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates
superior performance compared to existing methods in report generation, visual
question answering, and disease diagnosis. Code and data will be made publicly
available soon.",2024-10-18,"Haoran Lai, Zihang Jiang, Qingsong Yao, Rongsheng Wang, Zhiyang He, Xiaodong Tao, Wei Wei, Weifu Lv, S. Kevin Zhou",http://arxiv.org/pdf/2410.14200v1,cs.CL
Supervised Chain of Thought,"Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
""one-prompt-for-all"" approach, using a single prompt structure (e.g., ""think
step by step"") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.",2024-10-18,"Xiang Zhang, Dujian Ding",http://arxiv.org/pdf/2410.14198v1,cs.CL
Speciesism in Natural Language Processing Research,"Natural Language Processing (NLP) research on AI Safety and social bias in AI
has focused on safety for humans and social bias against human minorities.
However, some AI ethicists have argued that the moral significance of nonhuman
animals has been ignored in AI research. Therefore, the purpose of this study
is to investigate whether there is speciesism, i.e., discrimination against
nonhuman animals, in NLP research. First, we explain why nonhuman animals are
relevant in NLP research. Next, we survey the findings of existing research on
speciesism in NLP researchers, data, and models and further investigate this
problem in this study. The findings of this study suggest that speciesism
exists within researchers, data, and models, respectively. Specifically, our
survey and experiments show that (a) among NLP researchers, even those who
study social bias in AI, do not recognize speciesism or speciesist bias; (b)
among NLP data, speciesist bias is inherent in the data annotated in the
datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,
exhibit speciesist bias by default. Finally, we discuss how we can reduce
speciesism in NLP research.",2024-10-18,"Masashi Takeshita, Rafal Rzepka",http://arxiv.org/pdf/2410.14194v1,cs.CL
MetaAlign: Align Large Language Models with Diverse Preferences during Inference Time,"Large Language Models (LLMs) acquire extensive knowledge and remarkable
abilities from extensive text corpora, making them powerful tools for various
applications. To make LLMs more usable, aligning them with human preferences is
essential. Existing alignment techniques, such as Reinforcement Learning from
Human Feedback (RLHF) and Direct Preference Optimization (DPO), typically embed
predefined preferences directly within the model's parameters. These methods,
however, often result in a static alignment that can not account for the
diversity of human preferences in practical applications. In response to this
challenge, we propose an effective method, \textbf{MetaAlign}, which aims to
help LLMs dynamically align with various explicit or implicit preferences
specified at inference time. Experimental results show that LLMs optimized on
our meticulously constructed MetaAlign Dataset can effectively align with any
preferences specified at the inference stage, validating the feasibility of
MetaAlign. We hope that our work can provide some insights into the alignment
of language models.",2024-10-18,"Mozhi Zhang, Pengyu Wang, Chenkun Tan, Mianqiu Huang, Dong Zhang, Yaqian Zhou, Xipeng Qiu",http://arxiv.org/pdf/2410.14184v1,cs.CL
Enhancing Retrieval Performance: An Ensemble Approach For Hard Negative Mining,"Ranking consistently emerges as a primary focus in information retrieval
research. Retrieval and ranking models serve as the foundation for numerous
applications, including web search, open domain QA, enterprise domain QA, and
text-based recommender systems. Typically, these models undergo training on
triplets consisting of binary relevance assignments, comprising one positive
and one negative passage. However, their utilization involves a context where a
significantly more nuanced understanding of relevance is necessary, especially
when re-ranking a large pool of potentially relevant passages. Although
collecting positive examples through user feedback like impressions or clicks
is straightforward, identifying suitable negative pairs from a vast pool of
possibly millions or even billions of documents possess a greater challenge.
Generating a substantial number of negative pairs is often necessary to
maintain the high quality of the model. Several approaches have been suggested
in literature to tackle the issue of selecting suitable negative pairs from an
extensive corpus. This study focuses on explaining the crucial role of hard
negatives in the training process of cross-encoder models, specifically aiming
to explain the performance gains observed with hard negative sampling compared
to random sampling. We have developed a robust hard negative mining technique
for efficient training of cross-encoder re-rank models on an enterprise dataset
which has domain specific context. We provide a novel perspective to enhance
retrieval models, ultimately influencing the performance of advanced LLM
systems like Retrieval-Augmented Generation (RAG) and Reasoning and Action
Agents (ReAct). The proposed approach demonstrates that learning both
similarity and dissimilarity simultaneously with cross-encoders improves
performance of retrieval systems.",2024-10-18,Hansa Meghwani,http://arxiv.org/pdf/2411.02404v1,cs.CL
LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs,"Artificial Intelligence (AI) is revolutionizing scientific research, yet its
growing integration into laboratory environments presents critical safety
challenges. While large language models (LLMs) increasingly assist in tasks
ranging from procedural guidance to autonomous experiment orchestration, an
""illusion of understanding"" may lead researchers to overestimate their
reliability. Such overreliance is especially hazardous in high-stakes
laboratory settings, where failures in hazard identification or risk assessment
can result in severe accidents. To address these concerns, we propose the
Laboratory Safety Benchmark (LabSafety Bench), a comprehensive framework that
evaluates LLMs and vision language models (VLMs) on their ability to identify
potential hazards, assess risks, and predict the consequences of unsafe actions
in lab environments. LabSafety Bench comprises 765 multiple-choice questions
aligned with US Occupational Safety and Health Administration (OSHA) protocols,
along with 520 realistic laboratory scenarios featuring dual evaluation tasks:
the Hazards Identification Test and the Consequence Identification Test, with
4090 open-ended questions in total. Evaluations across eight proprietary
models, seven open-weight LLMs, and four VLMs reveal that, despite advanced
performance on structured assessments, no model achieves the safety threshold
required for reliable operation. None scored above 75% on the Hazards
Identification Test. Moreover, while proprietary models tend to excel in
multiple-choice evaluations, their performance in open-ended, real-world
scenario responses is comparable to that of open-source models. These findings
underscore the urgent need for specialized evaluation frameworks to ensure the
safe and responsible deployment of AI in laboratory settings.",2024-10-18,"Yujun Zhou, Jingdong Yang, Yue Huang, Kehan Guo, Zoe Emory, Bikram Ghosh, Amita Bedar, Sujay Shekar, Pin-Yu Chen, Tian Gao, Werner Geyer, Nuno Moniz, Nitesh V Chawla, Xiangliang Zhang",http://arxiv.org/pdf/2410.14182v2,cs.CL
XForecast: Evaluating Natural Language Explanations for Time Series Forecasting,"Time series forecasting aids decision-making, especially for stakeholders who
rely on accurate predictions, making it very important to understand and
explain these models to ensure informed decisions. Traditional explainable AI
(XAI) methods, which underline feature or temporal importance, often require
expert knowledge. In contrast, natural language explanations (NLEs) are more
accessible to laypeople. However, evaluating forecast NLEs is difficult due to
the complex causal relationships in time series data. To address this, we
introduce two new performance metrics based on simulatability, assessing how
well a human surrogate can predict model forecasts using the explanations.
Experiments show these metrics differentiate good from poor explanations and
align with human judgments. Utilizing these metrics, we further evaluate the
ability of state-of-the-art large language models (LLMs) to generate
explanations for time series data, finding that numerical reasoning, rather
than model size, is the main factor influencing explanation quality.",2024-10-18,"Taha Aksu, Chenghao Liu, Amrita Saha, Sarah Tan, Caiming Xiong, Doyen Sahoo",http://arxiv.org/pdf/2410.14180v2,cs.CL
MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems,"Multimodal Large Language Models (MLLMs) have demonstrated impressive
abilities across various tasks, including visual question answering and chart
comprehension, yet existing benchmarks for chart-related tasks fall short in
capturing the complexity of real-world multi-chart scenarios. Current
benchmarks primarily focus on single-chart tasks, neglecting the multi-hop
reasoning required to extract and integrate information from multiple charts,
which is essential in practical applications. To fill this gap, we introduce
MultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:
direct question answering, parallel question answering, comparative reasoning,
and sequential reasoning. Our evaluation of a wide range of MLLMs reveals
significant performance gaps compared to humans. These results highlight the
challenges in multi-chart comprehension and the potential of MultiChartQA to
drive advancements in this field. Our code and data are available at
https://github.com/Zivenzhu/Multi-chart-QA",2024-10-18,"Zifeng Zhu, Mengzhao Jia, Zhihan Zhang, Lang Li, Meng Jiang",http://arxiv.org/pdf/2410.14179v2,cs.CL
TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling,"Inference-time alignment enhances the performance of large language models
without requiring additional training or fine-tuning but presents challenges
due to balancing computational efficiency with high-quality output. Best-of-N
(BoN) sampling, as a simple yet powerful approach, generates multiple responses
and selects the best one, achieving improved performance but with a high
computational cost. We propose TreeBoN, a novel framework that integrates a
speculative tree-search strategy into Best-of-N (BoN) Sampling. TreeBoN
maintains a set of parent nodes, iteratively branching and pruning low-quality
responses, thereby reducing computational overhead while maintaining high
output quality. Our approach also leverages token-level rewards from Direct
Preference Optimization (DPO) to guide tree expansion and prune low-quality
paths. We evaluate TreeBoN using AlpacaFarm, HH-RLHF, UltraFeedback, GSM8K, and
TutorEval datasets, demonstrating consistent improvements. Specifically,
TreeBoN achieves the highest win rate of 65% on TutorEval and around 60% win
rates across other different datasets, outperforming standard BoN with the same
computational cost and showcasing its scalability and alignment efficacy.",2024-10-18,"Jiahao Qiu, Yifu Lu, Yifan Zeng, Jiacheng Guo, Jiayi Geng, Huazheng Wang, Kaixuan Huang, Yue Wu, Mengdi Wang",http://arxiv.org/pdf/2410.16033v3,cs.CL
LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with Simple Word-based Counting Problems,"Interestingly, LLMs yet struggle with some basic tasks that humans find
trivial to handle, e.g., counting the number of character r's in the word
""strawberry"". There are several popular conjectures (e.g., tokenization,
architecture and training data) regarding the reason for deficiency of LLMs in
simple word-based counting problems, sharing the similar belief that such
failure stems from model pretraining hence probably inevitable during
deployment. In this paper, we carefully design multiple evaluation settings to
investigate validity of prevalent conjectures. Meanwhile, we measure
transferability of advanced mathematical and coding reasoning capabilities from
specialized LLMs to simple counting tasks. Although specialized LLMs suffer
from counting problems as well, we find conjectures about inherent deficiency
of LLMs invalid and further seek opportunities to elicit knowledge and
capabilities from LLMs that are beneficial to counting tasks. Compared with
strategies such as finetuning and in-context learning that are commonly adopted
to enhance performance on new or challenging tasks, we show that engaging
reasoning is the most robust and efficient way to help LLMs better perceive
tasks with more accurate responses.
  We hope our conjecture validation design could provide insights into the
study of future critical failure modes of LLMs. Based on challenges in
transferring advanced capabilities to much simpler tasks, we call for more
attention to model capability acquisition and evaluation. We also highlight the
importance of cultivating consciousness of ""reasoning before responding"" during
model pretraining.",2024-10-18,"Nan Xu, Xuezhe Ma",http://arxiv.org/pdf/2410.14166v2,cs.CL
Automated Genre-Aware Article Scoring and Feedback Using Large Language Models,"This paper focuses on the development of an advanced intelligent article
scoring system that not only assesses the overall quality of written work but
also offers detailed feature-based scoring tailored to various article genres.
By integrating the pre-trained BERT model with the large language model
Chat-GPT, the system gains a deep understanding of both the content and
structure of the text, enabling it to provide a thorough evaluation along with
targeted suggestions for improvement. Experimental results demonstrate that
this system outperforms traditional scoring methods across multiple public
datasets, particularly in feature-based assessments, offering a more accurate
reflection of the quality of different article types. Moreover, the system
generates personalized feedback to assist users in enhancing their writing
skills, underscoring the potential and practical value of automated scoring
technologies in educational contexts.",2024-10-18,"Chihang Wang, Yuxin Dong, Zhenhong Zhang, Ruotong Wang, Shuo Wang, Jiajing Chen",http://arxiv.org/pdf/2410.14165v1,cs.CL
Collaboratively adding new knowledge to an LLM,"We address the question of how to successively add new knowledge to an LLM
whilst retaining previously-added knowledge. We consider two settings,
semi-cooperative and fully-cooperative. Overall, LoRA performs better in most
cases than full-fine tuning of all parameters when both new knowledge
acquisition and retention of old, including recent, knowledge are taken into
account. In the semi-cooperative setting, where datasets are not available
after training, MOE mixing, model merging, and LoRA-based orthogonal subspace
sequential learning, using a small weight on the orthogonality term, perform
well. In the fully-cooperative setting where datasets remain available, joint
training and sequential training with replay are both effective approaches with
LoRA training generally preferable to full fine-tuning. The codes needed to
reproduce the results are provided in an open source repository.",2024-10-18,"Rhui Dih Lee, Laura Wynter",http://arxiv.org/pdf/2410.14753v2,cs.CL
Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning,"Autoregressive language models, despite their impressive capabilities,
struggle with complex reasoning and long-term planning tasks. We introduce
discrete diffusion models as a novel solution to these challenges. Through the
lens of subgoal imbalance, we demonstrate how diffusion models effectively
learn difficult subgoals that elude autoregressive approaches. We propose
Multi-Granularity Diffusion Modeling (MGDM), which prioritizes subgoals based
on difficulty during learning. On complex tasks like Countdown, Sudoku, and
Boolean Satisfiability Problems, MGDM significantly outperforms autoregressive
models without using search techniques. For instance, MGDM achieves 91.5\% and
100\% accuracy on Countdown and Sudoku, respectively, compared to 45.8\% and
20.7\% for autoregressive models. Our work highlights the potential of
diffusion-based approaches in advancing AI capabilities for sophisticated
language understanding and problem-solving tasks. All associated codes are
available at
\href{https://github.com/HKUNLP/diffusion-vs-ar}{https://github.com/HKUNLP/diffusion-vs-ar}.",2024-10-18,"Jiacheng Ye, Jiahui Gao, Shansan Gong, Lin Zheng, Xin Jiang, Zhenguo Li, Lingpeng Kong",http://arxiv.org/pdf/2410.14157v3,cs.CL
Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models,"Large Language Models (LLMs) are capable of generating persuasive Natural
Language Explanations (NLEs) to justify their answers. However, the
faithfulness of these explanations should not be readily trusted at face value.
Recent studies have proposed various methods to measure the faithfulness of
NLEs, typically by inserting perturbations at the explanation or feature level.
We argue that these approaches are neither comprehensive nor correctly designed
according to the established definition of faithfulness. Moreover, we highlight
the risks of grounding faithfulness findings on out-of-distribution samples. In
this work, we leverage a causal mediation technique called activation patching,
to measure the faithfulness of an explanation towards supporting the explained
answer. Our proposed metric, Causal Faithfulness quantifies the consistency of
causal attributions between explanations and the corresponding model outputs as
the indicator of faithfulness. We experimented across models varying from 2B to
27B parameters and found that models that underwent alignment tuning tend to
produce more faithful and plausible explanations. We find that Causal
Faithfulness is a promising improvement over existing faithfulness tests by
taking into account the model's internal computations and avoiding out of
distribution concerns that could otherwise undermine the validity of
faithfulness assessments. We release the code in
\url{https://github.com/wj210/Causal-Faithfulness}",2024-10-18,"Wei Jie Yeo, Ranjan Satapathy, Erik Cambria",http://arxiv.org/pdf/2410.14155v2,cs.CL
SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent,"Public scarce resource allocation plays a crucial role in economics as it
directly influences the efficiency and equity in society. Traditional studies
including theoretical model-based, empirical study-based and simulation-based
methods encounter limitations due to the idealized assumption of complete
information and individual rationality, as well as constraints posed by limited
available data. In this work, we propose an innovative framework, SRAP-Agent
(Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based
Agent), which integrates Large Language Models (LLMs) into economic
simulations, aiming to bridge the gap between theoretical models and real-world
dynamics. Using public housing allocation scenarios as a case study, we conduct
extensive policy simulation experiments to verify the feasibility and
effectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm
with certain optimization objectives. The source code can be found in
https://github.com/jijiarui-cather/SRAPAgent_Framework",2024-10-18,"Jiarui Ji, Yang Li, Hongtao Liu, Zhicheng Du, Zhewei Wei, Weiran Shen, Qi Qi, Yankai Lin",http://arxiv.org/pdf/2410.14152v1,cs.CL
Utilizing Large Language Models for Event Deconstruction to Enhance Multimodal Aspect-Based Sentiment Analysis,"With the rapid development of the internet, the richness of User-Generated
Contentcontinues to increase, making Multimodal Aspect-Based Sentiment Analysis
(MABSA) a research hotspot. Existing studies have achieved certain results in
MABSA, but they have not effectively addressed the analytical challenges in
scenarios where multiple entities and sentiments coexist. This paper
innovatively introduces Large Language Models (LLMs) for event decomposition
and proposes a reinforcement learning framework for Multimodal Aspect-based
Sentiment Analysis (MABSA-RL) framework. This framework decomposes the original
text into a set of events using LLMs, reducing the complexity of analysis,
introducing reinforcement learning to optimize model parameters. Experimental
results show that MABSA-RL outperforms existing advanced methods on two
benchmark datasets. This paper provides a new research perspective and method
for multimodal aspect-level sentiment analysis.",2024-10-18,"Xiaoyong Huang, Heli Sun, Qunshu Gao, Wenjie Huang, Ruichen Cao",http://arxiv.org/pdf/2410.14150v1,cs.CL
Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment,"The recent advancements in large language models (LLMs) and pre-trained
vision models have accelerated the development of vision-language large models
(VLLMs), enhancing the interaction between visual and linguistic modalities.
Despite their notable success across various domains, VLLMs face challenges in
modality alignment, which can lead to issues like hallucinations and unsafe
content generation. Current alignment techniques often rely on coarse feedback
and external datasets, limiting scalability and performance. In this paper, we
propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel
self-alignment method that utilizes the model's own visual encoder as a
fine-grained verifier to improve vision-language alignment without the need for
additional data. By leveraging token-level feedback from the vision encoder,
FiSAO significantly improves vision-language alignment, even surpassing
traditional preference tuning methods that require additional data. Through
both theoretical analysis and experimental validation, we demonstrate that
FiSAO effectively addresses the misalignment problem in VLLMs, marking the
first instance of token-level rewards being applied to such models.",2024-10-18,"Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua",http://arxiv.org/pdf/2410.14148v4,cs.CL
CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using Large Language Models,"Generating emotionally appropriate responses in conversations with large
language models presents a significant challenge due to the complexities of
human emotions and cognitive processes, which remain largely underexplored in
their critical role in social interactions. In this study, we introduce a
two-stage automatic data generation framework to create CAPE, a Chinese dataset
named Cognitive Appraisal theory-based Emotional corpus. This corpus
facilitates the generation of dialogues with contextually appropriate emotional
responses by accounting for diverse personal and situational factors. We
propose two tasks utilizing this dataset: emotion prediction and next utterance
prediction. Both automated and human evaluations demonstrate that agents
trained on our dataset can deliver responses that are more aligned with human
emotional expressions. Our study shows the potential for advancing emotional
expression in conversational agents, paving the way for more nuanced and
meaningful human-computer interactions.",2024-10-18,"June M. Liu, He Cao, Renliang Sun, Rui Wang, Yu Li, Jiaxing Zhang",http://arxiv.org/pdf/2410.14145v1,cs.CL
A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models,"Large language models (LLMs) show remarkable abilities with instruction
tuning. However, they fail to achieve ideal tasks when lacking high-quality
instruction tuning data on target tasks. Multi-Aspect Controllable Text
Generation (MCTG) is a representative task for this dilemma, where aspect
datasets are usually biased and correlated. Existing work exploits additional
model structures and strategies for solutions, limiting adaptability to LLMs.
To activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based
on data augmentation. We analyze bias and correlations in traditional datasets,
and address these concerns with augmented control attributes and sentences.
Augmented datasets are feasible for instruction tuning. In our experiments,
LLMs perform better in MCTG after data augmentation, with a 20% accuracy rise
and less aspect correlations.",2024-10-18,"Chenyang Zhang, Jiayi Lin, Haibo Tong, Bingxuan Hou, Dongyu Zhang, Jialin Li, Junli Wang",http://arxiv.org/pdf/2410.14144v1,cs.CL
Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents,"When assisting people in daily tasks, robots need to accurately interpret
visual cues and respond effectively in diverse safety-critical situations, such
as sharp objects on the floor. In this context, we present M-CoDAL, a
multimodal-dialogue system specifically designed for embodied agents to better
understand and communicate in safety-critical situations. The system leverages
discourse coherence relations to enhance its contextual understanding and
communication abilities. To train this system, we introduce a novel
clustering-based active learning mechanism that utilizes an external Large
Language Model (LLM) to identify informative instances. Our approach is
evaluated using a newly created multimodal dataset comprising 1K safety
violations extracted from 2K Reddit images. These violations are annotated
using a Large Multimodal Model (LMM) and verified by human annotators. Results
with this dataset demonstrate that our approach improves resolution of safety
situations, user sentiment, as well as safety of the conversation. Next, we
deploy our dialogue system on a Hello Robot Stretch robot and conduct a
within-subject user study with real-world participants. In the study,
participants role-play two safety scenarios with different levels of severity
with the robot and receive interventions from our model and a baseline system
powered by OpenAI's ChatGPT. The study results corroborate and extend the
findings from the automated evaluation, showing that our proposed system is
more persuasive in a real-world embodied agent setting.",2024-10-18,"Sabit Hassan, Hye-Young Chung, Xiang Zhi Tan, Malihe Alikhani",http://arxiv.org/pdf/2410.14141v2,cs.CL
ViConsFormer: Constituting Meaningful Phrases of Scene Texts using Transformer-based Method in Vietnamese Text-based Visual Question Answering,"Text-based VQA is a challenging task that requires machines to use scene
texts in given images to yield the most appropriate answer for the given
question. The main challenge of text-based VQA is exploiting the meaning and
information from scene texts. Recent studies tackled this challenge by
considering the spatial information of scene texts in images via embedding 2D
coordinates of their bounding boxes. In this study, we follow the definition of
meaning from linguistics to introduce a novel method that effectively exploits
the information from scene texts written in Vietnamese. Experimental results
show that our proposed method obtains state-of-the-art results on two
large-scale Vietnamese Text-based VQA datasets. The implementation can be found
at this link.",2024-10-18,"Nghia Hieu Nguyen, Tho Thanh Quan, Ngan Luu-Thuy Nguyen",http://arxiv.org/pdf/2410.14132v2,cs.CL
KeyInst: Keyword Instruction for Improving SQL Formulation in Text-to-SQL,"Text-to-SQL parsing involves the translation of natural language queries
(NLQs) into their corresponding SQL commands. A principal challenge within this
domain is the formulation of SQL queries that are not only syntactically
correct but also semantically aligned with the natural language input. However,
the intrinsic disparity between the NLQ and the SQL poses a significant
challenge. In this research, we introduce Keyword Instruction (KeyInst), a
novel method designed to enhance SQL formulation by Large Language Models
(LLMs). KeyInst essentially provides guidance on pivotal SQL keywords likely to
be part of the final query, thus facilitates a smoother SQL query formulation
process. We explore two strategies for integrating KeyInst into Text-to-SQL
parsing: a pipeline strategy and a single-pass strategy. The former first
generates KeyInst for question, which are then used to prompt LLMs. The latter
employs a fine-tuned model to concurrently generate KeyInst and SQL in one
step. We developed StrucQL, a benchmark specifically designed for the
evaluation of SQL formulation. Extensive experiments on StrucQL and other
benchmarks demonstrate that KeyInst significantly improves upon the existing
Text-to-SQL prompting techniques.",2024-10-18,"Xiping Liu, Zhao Tan",http://arxiv.org/pdf/2411.00788v1,cs.CL
TimeSeriesExam: A time series understanding exam,"Large Language Models (LLMs) have recently demonstrated a remarkable ability
to model time series data. These capabilities can be partly explained if LLMs
understand basic time series concepts. However, our knowledge of what these
models understand about time series data remains relatively limited. To address
this gap, we introduce TimeSeriesExam, a configurable and scalable
multiple-choice question exam designed to assess LLMs across five core time
series understanding categories: pattern recognition, noise understanding,
similarity analysis, anomaly detection, and causality analysis. TimeSeriesExam
comprises of over 700 questions, procedurally generated using 104 carefully
curated templates and iteratively refined to balance difficulty and their
ability to discriminate good from bad models. We test 7 state-of-the-art LLMs
on the TimeSeriesExam and provide the first comprehensive evaluation of their
time series understanding abilities. Our results suggest that closed-source
models such as GPT-4 and Gemini understand simple time series concepts
significantly better than their open-source counterparts, while all models
struggle with complex concepts such as causality analysis. We believe that the
ability to programatically generate questions is fundamental to assessing and
improving LLM's ability to understand and reason about time series data.",2024-10-18,"Yifu Cai, Arjun Choudhry, Mononito Goswami, Artur Dubrawski",http://arxiv.org/pdf/2410.14752v1,cs.CL
Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning,"Mathematical reasoning has been challenging for large language models (LLMs).
However, the introduction of step-by-step Chain-of-Thought (CoT) inference has
significantly advanced the mathematical capabilities of LLMs. Despite this
progress, current approaches either necessitate extensive inference datasets
for training or depend on few-shot methods that frequently compromise
computational accuracy. To address these bottlenecks in mathematical reasoning,
we propose a novel method called Step Guidied Reasoning, which is more stable
and generalizable than few-shot methods and does not involve further
fine-tuning of the model. In this approach, LLMs reflect on small reasoning
steps, similar to how humans deliberate and focus attention on what to do next.
By incorporating this reflective process into the inference stage, LLMs can
effectively guide their reasoning from one step to the next. Through extensive
experiments, we demonstrate the significant effect of Step Guidied Reasoning in
augmenting mathematical performance in state-of-the-art language models.
Qwen2-72B-Instruct outperforms its math-specific counterpart,
Qwen2.5-72B-Math-Instruct, on MMLU- STEM with a score of 90.9%, compared to
87.3%. The average scores of Qwen2-7B-Instruct and Qwen2-72B-Instruct increase
from 27.1% to 36.3% and from 36.5% to 47.4% on the mathematics domain,
respectively.",2024-10-18,"Lang Cao, Chao Peng, Renhong Chen, Wu Ning, Yingtian Zou, Yitong Li",http://arxiv.org/pdf/2410.19817v2,cs.CL
Be My Donor. Transfer the NLP Datasets Between the Languages Using LLM,"In this work, we investigated how one can use the LLM to transfer the dataset
and its annotation from one language to another. This is crucial since sharing
the knowledge between different languages could boost certain underresourced
directions in the target language, saving lots of efforts in data annotation or
quick prototyping. We experiment with English and Russian pairs translating the
DEFT corpus. This corpus contains three layers of annotation dedicated to
term-definition pair mining, which is a rare annotation type for Russian. We
provide a pipeline for the annotation transferring using ChatGPT3.5-turbo and
Llama-3.1-8b as core LLMs. In the end, we train the BERT-based models on the
translated dataset to establish a baseline.",2024-10-17,"Dmitrii Popov, Egor Terentev, Igor Buyanov",http://arxiv.org/pdf/2410.14074v1,cs.CL
Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers,"Recent advancements in vision-language models (VLMs) have expanded their
potential for real-world applications, enabling these models to perform complex
reasoning on images. In the widely used fully autoregressive transformer-based
models like LLaVA, projected visual tokens are prepended to textual tokens.
Oftentimes, visual tokens are significantly more than prompt tokens, resulting
in increased computational overhead during both training and inference. In this
paper, we propose Visual Compact Token Registers (Victor), a method that
reduces the number of visual tokens by summarizing them into a smaller set of
register tokens. Victor adds a few learnable register tokens after the visual
tokens and summarizes the visual information into these registers using the
first few layers in the language tower of VLMs. After these few layers, all
visual tokens are discarded, significantly improving computational efficiency
for both training and inference. Notably, our method is easy to implement and
requires a small number of new trainable parameters with minimal impact on
model performance. In our experiment, with merely 8 visual registers--about 1%
of the original tokens--Victor shows less than a 4% accuracy drop while
reducing the total training time by 43% and boosting the inference throughput
by 3.3X.",2024-10-17,"Yuxin Wen, Qingqing Cao, Qichen Fu, Sachin Mehta, Mahyar Najibi",http://arxiv.org/pdf/2410.14072v1,cs.CL
"SouLLMate: An Application Enhancing Diverse Mental Health Support with Adaptive LLMs, Prompt Engineering, and RAG Techniques","Mental health issues significantly impact individuals' daily lives, yet many
do not receive the help they need even with available online resources. This
study aims to provide diverse, accessible, stigma-free, personalized, and
real-time mental health support through cutting-edge AI technologies. It makes
the following contributions: (1) Conducting an extensive survey of recent
mental health support methods to identify prevalent functionalities and unmet
needs. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates
LLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt
engineering, and domain knowledge. This system offers advanced features such as
Risk Detection and Proactive Guidance Dialogue, and utilizes RAG for
personalized profile uploads and Conversational Information Extraction. (3)
Developing novel evaluation approaches for preliminary assessments and risk
detection via professionally annotated interview data and real-life suicide
tendency data. (4) Proposing the Key Indicator Summarization (KIS), Proactive
Questioning Strategy (PQS), and Stacked Multi-Model Reasoning (SMMR) methods to
enhance model performance and usability through context-sensitive response
adjustments, semantic coherence evaluations, and enhanced accuracy of
long-context reasoning in language models. This study contributes to advancing
mental health support technologies, potentially improving the accessibility and
effectiveness of mental health care globally.",2024-10-17,"Qiming Guo, Jinwen Tang, Wenbo Sun, Haoteng Tang, Yi Shang, Wenlu Wang",http://arxiv.org/pdf/2410.16322v1,cs.CL
UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models,"This paper introduces the UCFE: User-Centric Financial Expertise benchmark,
an innovative framework designed to evaluate the ability of large language
models (LLMs) to handle complex real-world financial tasks. UCFE benchmark
adopts a hybrid approach that combines human expert evaluations with dynamic,
task-specific interactions to simulate the complexities of evolving financial
scenarios. Firstly, we conducted a user study involving 804 participants,
collecting their feedback on financial tasks. Secondly, based on this feedback,
we created our dataset that encompasses a wide range of user intents and
interactions. This dataset serves as the foundation for benchmarking 11 LLMs
services using the LLM-as-Judge methodology. Our results show a significant
alignment between benchmark scores and human preferences, with a Pearson
correlation coefficient of 0.78, confirming the effectiveness of the UCFE
dataset and our evaluation approach. UCFE benchmark not only reveals the
potential of LLMs in the financial domain but also provides a robust framework
for assessing their performance and user satisfaction.",2024-10-17,"Yuzhe Yang, Yifei Zhang, Yan Hu, Yilin Guo, Ruoli Gan, Yueru He, Mingcong Lei, Xiao Zhang, Haining Wang, Qianqian Xie, Jimin Huang, Honghai Yu, Benyou Wang",http://arxiv.org/pdf/2410.14059v3,cs.CL
Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs,"Translating text that contains entity names is a challenging task, as
cultural-related references can vary significantly across languages. These
variations may also be caused by transcreation, an adaptation process that
entails more than transliteration and word-for-word translation. In this paper,
we address the problem of cross-cultural translation on two fronts: (i) we
introduce XC-Translate, the first large-scale, manually-created benchmark for
machine translation that focuses on text that contains potentially
culturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end
method to integrate information from a multilingual knowledge graph into a
neural machine translation model by leveraging a dense retrieval mechanism. Our
experiments and analyses show that current machine translation systems and
large language models still struggle to translate texts containing entity
names, whereas KG-MT outperforms state-of-the-art approaches by a large margin,
obtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,
respectively.",2024-10-17,"Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li",http://arxiv.org/pdf/2410.14057v1,cs.CL
From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs,"Recent advancements in large language models have significantly improved
their context windows, yet challenges in effective long-term memory management
remain. We introduce MemTree, an algorithm that leverages a dynamic,
tree-structured memory representation to optimize the organization, retrieval,
and integration of information, akin to human cognitive schemas. MemTree
organizes memory hierarchically, with each node encapsulating aggregated
textual content, corresponding semantic embeddings, and varying abstraction
levels across the tree's depths. Our algorithm dynamically adapts this memory
structure by computing and comparing semantic embeddings of new and existing
information to enrich the model's context-awareness. This approach allows
MemTree to handle complex reasoning and extended interactions more effectively
than traditional memory augmentation methods, which often rely on flat lookup
tables. Evaluations on benchmarks for multi-turn dialogue understanding and
document question answering show that MemTree significantly enhances
performance in scenarios that demand structured memory management.",2024-10-17,"Alireza Rezazadeh, Zichao Li, Wei Wei, Yujia Bao",http://arxiv.org/pdf/2410.14052v3,cs.CL
Learning Multimodal Cues of Children's Uncertainty,"Understanding uncertainty plays a critical role in achieving common ground
(Clark et al.,1983). This is especially important for multimodal AI systems
that collaborate with users to solve a problem or guide the user through a
challenging concept. In this work, for the first time, we present a dataset
annotated in collaboration with developmental and cognitive psychologists for
the purpose of studying nonverbal cues of uncertainty. We then present an
analysis of the data, studying different roles of uncertainty and its
relationship with task difficulty and performance. Lastly, we present a
multimodal machine learning model that can predict uncertainty given a
real-time video clip of a participant, which we find improves upon a baseline
multimodal transformer model. This work informs research on cognitive
coordination between human-human and human-AI and has broad implications for
gesture understanding and generation. The anonymized version of our data and
code will be publicly available upon the completion of the required consent
forms and data sheets.",2024-10-17,"Qi Cheng, Mert İnan, Rahma Mbarki, Grace Grmek, Theresa Choi, Yiming Sun, Kimele Persaud, Jenny Wang, Malihe Alikhani",http://arxiv.org/pdf/2410.14050v1,cs.CL
Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection,"In-context learning (ICL) is a powerful paradigm where large language models
(LLMs) benefit from task demonstrations added to the prompt. Yet, selecting
optimal demonstrations is not trivial, especially for complex or multi-modal
tasks where input and output distributions differ. We hypothesize that forming
task-specific representations of the input is key. In this paper, we propose a
method to align representations of natural language questions and those of SQL
queries in a shared embedding space. Our technique, dubbed MARLO -
Metadata-Agnostic Representation Learning for Text-tO-SQL - uses query
structure to model querying intent without over-indexing on underlying database
metadata (i.e. tables, columns, or domain-specific entities of a database
referenced in the question or query). This allows MARLO to select examples that
are structurally and semantically relevant for the task rather than examples
that are spuriously related to a certain domain or question phrasing. When used
to retrieve examples based on question similarity, MARLO shows superior
performance compared to generic embedding models (on average +2.9\%pt. in
execution accuracy) on the Spider benchmark. It also outperforms the next best
method that masks metadata information by +0.8\%pt. in execution accuracy on
average, while imposing a significantly lower inference latency.",2024-10-17,"Chuhong Mai, Ro-ee Tal, Thahir Mohamed",http://arxiv.org/pdf/2410.14049v1,cs.CL
Retrieval of Temporal Event Sequences from Textual Descriptions,"Retrieving temporal event sequences from textual descriptions is crucial for
applications such as analyzing e-commerce behavior, monitoring social media
activities, and tracking criminal incidents. To advance this task, we introduce
TESRBench, a comprehensive benchmark for temporal event sequence retrieval
(TESR) from textual descriptions. TESRBench includes diverse real-world
datasets with synthesized and reviewed textual descriptions, providing a strong
foundation for evaluating retrieval performance and addressing challenges in
this domain. Building on this benchmark, we propose TPP-Embedding, a novel
model for embedding and retrieving event sequences. The model leverages the
TPP-LLM framework, integrating large language models (LLMs) with temporal point
processes (TPPs) to encode both event texts and times. By pooling
representations and applying a contrastive loss, it unifies temporal dynamics
and event semantics in a shared embedding space, aligning sequence-level
embeddings of event sequences and their descriptions. TPP-Embedding
demonstrates superior performance over baseline models across TESRBench
datasets, establishing it as a powerful solution for the temporal event
sequence retrieval task.",2024-10-17,"Zefang Liu, Yinzhu Quan",http://arxiv.org/pdf/2410.14043v2,cs.CL
Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles,"Prompt compression condenses contexts while maintaining their informativeness
for different usage scenarios. It not only shortens the inference time and
reduces computational costs during the usage of large language models, but also
lowers expenses when using closed-source models. In a preliminary study, we
discover that when instructing language models to compress prompts, different
compression styles (e.g., extractive or abstractive) impact performance of
compressed prompts on downstream tasks. Building on this insight, we propose
Style-Compress, a lightweight framework that adapts a smaller language model to
compress prompts for a larger model on a new task without additional training.
Our approach iteratively generates and selects effective compressed prompts as
task-specific demonstrations through style variation and in-context learning,
enabling smaller models to act as efficient compressors with task-specific
examples. Style-Compress outperforms two baseline compression models in four
tasks: original prompt reconstruction, text summarization, multi-hop QA, and
CoT reasoning. In addition, with only 10 samples and 100 queries for
adaptation, prompts compressed by Style-Compress achieve performance on par
with or better than original prompts at a compression ratio of 0.25 or 0.5.",2024-10-17,"Xiao Pu, Tianxing He, Xiaojun Wan",http://arxiv.org/pdf/2410.14042v1,cs.CL
From Barriers to Tactics: A Behavioral Science-Informed Agentic Workflow for Personalized Nutrition Coaching,"Effective management of cardiometabolic conditions requires sustained
positive nutrition habits, often hindered by complex and individualized
barriers. Direct human management is simply not scalable, while previous
attempts aimed at automating nutrition coaching lack the personalization needed
to address these diverse challenges. This paper introduces a novel LLM-powered
agentic workflow designed to provide personalized nutrition coaching by
directly targeting and mitigating patient-specific barriers. Grounded in
behavioral science principles, the workflow leverages a comprehensive mapping
of nutrition-related barriers to corresponding evidence-based strategies. A
specialized LLM agent intentionally probes for and identifies the root cause of
a patient's dietary struggles. Subsequently, a separate LLM agent delivers
tailored tactics designed to overcome those specific barriers with patient
context. We designed and validated our approach through a user study with
individuals with cardiometabolic conditions, demonstrating the system's ability
to accurately identify barriers and provide personalized guidance. Furthermore,
we conducted a large-scale simulation study, grounding on real patient
vignettes and expert-validated metrics, to evaluate the system's performance
across a wide range of scenarios. Our findings demonstrate the potential of
this LLM-powered agentic workflow to improve nutrition coaching by providing
personalized, scalable, and behaviorally-informed interventions.",2024-10-17,"Eric Yang, Tomas Garcia, Hannah Williams, Bhawesh Kumar, Martin Ramé, Eileen Rivera, Yiran Ma, Jonathan Amar, Caricia Catalani, Yugang Jia",http://arxiv.org/pdf/2410.14041v1,cs.CL
Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series,"Interacting systems are prevalent in nature. It is challenging to accurately
predict the dynamics of the system if its constituent components are analyzed
independently. We develop a graph-based model that unveils the systemic
interactions of time series observed at irregular time points, by using a
directed acyclic graph to model the conditional dependencies (a form of causal
notation) of the system components and learning this graph in tandem with a
continuous-time model that parameterizes the solution curves of ordinary
differential equations (ODEs). Our technique, a graph neural flow, leads to
substantial enhancements over non-graph-based methods, as well as graph-based
methods without the modeling of conditional dependencies. We validate our
approach on several tasks, including time series classification and
forecasting, to demonstrate its efficacy.",2024-10-17,"Giangiacomo Mercatali, Andre Freitas, Jie Chen",http://arxiv.org/pdf/2410.14030v2,cs.CL
Measuring and Modifying the Readability of English Texts with GPT-4,"The success of Large Language Models (LLMs) in other domains has raised the
question of whether LLMs can reliably assess and manipulate the readability of
text. We approach this question empirically. First, using a published corpus of
4,724 English text excerpts, we find that readability estimates produced
``zero-shot'' from GPT-4 Turbo and GPT-4o mini exhibit relatively high
correlation with human judgments (r = 0.76 and r = 0.74, respectively),
out-performing estimates derived from traditional readability formulas and
various psycholinguistic indices. Then, in a pre-registered human experiment (N
= 59), we ask whether Turbo can reliably make text easier or harder to read. We
find evidence to support this hypothesis, though considerable variance in human
judgments remains unexplained. We conclude by discussing the limitations of
this approach, including limited scope, as well as the validity of the
``readability'' construct and its dependence on context, audience, and goal.",2024-10-17,"Sean Trott, Pamela D. Rivière",http://arxiv.org/pdf/2410.14028v1,cs.CL
Generating Signed Language Instructions in Large-Scale Dialogue Systems,"We introduce a goal-oriented conversational AI system enhanced with American
Sign Language (ASL) instructions, presenting the first implementation of such a
system on a worldwide multimodal conversational AI platform. Accessible through
a touch-based interface, our system receives input from users and seamlessly
generates ASL instructions by leveraging retrieval methods and cognitively
based gloss translations. Central to our design is a sign translation module
powered by Large Language Models, alongside a token-based video retrieval
system for delivering instructional content from recipes and wikiHow guides.
Our development process is deeply rooted in a commitment to community
engagement, incorporating insights from the Deaf and Hard-of-Hearing community,
as well as experts in cognitive and ASL learning sciences. The effectiveness of
our signing instructions is validated by user feedback, achieving ratings on
par with those of the system in its non-signing variant. Additionally, our
system demonstrates exceptional performance in retrieval accuracy and
text-generation quality, measured by metrics such as BERTScore. We have made
our codebase and datasets publicly accessible at
https://github.com/Merterm/signed-dialogue, and a demo of our signed
instruction video retrieval system is available at
https://huggingface.co/spaces/merterm/signed-instructions.",2024-10-17,"Mert İnan, Katherine Atwell, Anthony Sicilia, Lorna Quandt, Malihe Alikhani",http://arxiv.org/pdf/2410.14026v1,cs.CL
LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education,"With the increasing adoption of large language models (LLMs) in education,
concerns about inherent biases in these models have gained prominence. We
evaluate LLMs for bias in the personalized educational setting, specifically
focusing on the models' roles as ""teachers."" We reveal significant biases in
how models generate and select educational content tailored to different
demographic groups, including race, ethnicity, sex, gender, disability status,
income, and national origin. We introduce and apply two bias score
metrics--Mean Absolute Bias (MAB) and Maximum Difference Bias (MDB)--to analyze
9 open and closed state-of-the-art LLMs. Our experiments, which utilize over
17,000 educational explanations across multiple difficulty levels and topics,
uncover that models potentially harm student learning by both perpetuating
harmful stereotypes and reversing them. We find that bias is similar for all
frontier models, with the highest MAB along income levels while MDB is highest
relative to both income and disability status. For both metrics, we find the
lowest bias exists for sex/gender and race/ethnicity.",2024-10-17,"Iain Weissburg, Sathvika Anand, Sharon Levy, Haewon Jeong",http://arxiv.org/pdf/2410.14012v2,cs.CL
Personalized Adaptation via In-Context Preference Learning,"Reinforcement Learning from Human Feedback (RLHF) is widely used to align
Language Models (LMs) with human preferences. However, existing approaches
often neglect individual user preferences, leading to suboptimal
personalization. We present the Preference Pretrained Transformer (PPT), a
novel approach for adaptive personalization using online user feedback. PPT
leverages the in-context learning capabilities of transformers to dynamically
adapt to individual preferences. Our approach consists of two phases: (1) an
offline phase where we train a single policy model using a history-dependent
loss function, and (2) an online phase where the model adapts to user
preferences through in-context learning. We demonstrate PPT's effectiveness in
a contextual bandit setting, showing that it achieves personalized adaptation
superior to existing methods while significantly reducing the computational
costs. Our results suggest the potential of in-context learning for scalable
and efficient personalization in large language models.",2024-10-17,"Allison Lau, Younwoo Choi, Vahid Balazadeh, Keertana Chidambaram, Vasilis Syrgkanis, Rahul G. Krishnan",http://arxiv.org/pdf/2410.14001v1,cs.CL
ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries,"Recent advancements in large language models (LLMs) have significantly
enhanced their ability to understand both natural language and code, driving
their use in tasks like natural language-to-code (NL2Code) and code
summarization. However, LLMs are prone to hallucination-outputs that stray from
intended meanings. Detecting hallucinations in code summarization is especially
difficult due to the complex interplay between programming and natural
languages. We introduce a first-of-its-kind dataset with $\sim$10K samples,
curated specifically for hallucination detection in code summarization. We
further propose a novel Entity Tracing Framework (ETF) that a) utilizes static
program analysis to identify code entities from the program and b) uses LLMs to
map and verify these entities and their intents within generated code
summaries. Our experimental analysis demonstrates the effectiveness of the
framework, leading to a 0.73 F1 score. This approach provides an interpretable
method for detecting hallucinations by grounding entities, allowing us to
evaluate summary accuracy.",2024-10-17,"Kishan Maharaj, Vitobha Munigala, Srikanth G. Tamilselvam, Prince Kumar, Sayandeep Sen, Palani Kodeswaran, Abhijit Mishra, Pushpak Bhattacharyya",http://arxiv.org/pdf/2410.14748v3,cs.CL
RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs,"Answering complex real-world questions often requires accurate retrieval from
textual knowledge graphs (TKGs). The scarcity of annotated data, along with
intricate topological structures, makes this task particularly challenging. As
the nature of relational path information could enhance the inference ability
of Large Language Models (LLMs), efficiently retrieving more complex relational
path information from TKGs presents another key challenge. To tackle these
challenges, we first develop a Dataset for LLMs Complex Reasoning over Textual
Knowledge Graphs (RiTeK) with a broad topological structure coverage.We
synthesize realistic user queries that integrate diverse topological
structures, relational information, and complex textual descriptions. We
conduct rigorous expert evaluation to validate the quality of our synthesized
queries. And then, we introduce an enhanced Monte Carlo Tree Search (MCTS)
method, Relational MCTS, to automatically extract relational path information
from textual graphs for specific queries. Our dataset mainly covers the medical
domain as the relation types and entity are complex and publicly available.
Experimental results indicate that RiTeK poses significant challenges for
current retrieval and LLM systems, while the proposed Relational MCTS method
enhances LLM inference ability and achieves state-of-the-art performance on
RiTeK.",2024-10-17,"Jiatan Huang, Mingchen Li, Zonghai Yao, Zhichao Yang, Yongkang Xiao, Feiyun Ouyang, Xiaohan Li, Shuo Han, Hong Yu",http://arxiv.org/pdf/2410.13987v1,cs.CL
Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers,"Distributional semantics is the linguistic theory that a word's meaning can
be derived from its distribution in natural language (i.e., its use). Language
models are commonly viewed as an implementation of distributional semantics, as
they are optimized to capture the statistical features of natural language. It
is often argued that distributional semantics models should excel at capturing
graded/vague meaning based on linguistic conventions, but struggle with
truth-conditional reasoning and symbolic processing. We evaluate this claim
with a case study on vague (e.g. ""many"") and exact (e.g. ""more than half"")
quantifiers. Contrary to expectations, we find that, across a broad range of
models of various types, LLMs align more closely with human judgements on exact
quantifiers versus vague ones. These findings call for a re-evaluation of the
assumptions underpinning what distributional semantics models are, as well as
what they can capture.",2024-10-17,"Zhang Enyan, Zewei Wang, Michael A. Lepori, Ellie Pavlick, Helena Aparicio",http://arxiv.org/pdf/2410.13984v1,cs.CL
Debiasing Large Vision-Language Models by Ablating Protected Attribute Representations,"Large Vision Language Models (LVLMs) such as LLaVA have demonstrated
impressive capabilities as general-purpose chatbots that can engage in
conversations about a provided input image. However, their responses are
influenced by societal biases present in their training datasets, leading to
undesirable differences in how the model responds when presented with images
depicting people of different demographics. In this work, we propose a novel
debiasing framework for LVLMs by directly ablating biased attributes during
text generation to avoid generating text related to protected attributes, or
even representing them internally. Our method requires no training and a
relatively small amount of representative biased outputs (~1000 samples). Our
experiments show that not only can we can minimize the propensity of LVLMs to
generate text related to protected attributes, but we can even use synthetic
data to inform the ablation while retaining captioning performance on real data
such as COCO. Furthermore, we find the resulting generations from a debiased
LVLM exhibit similar accuracy as a baseline biased model, showing that
debiasing effects can be achieved without sacrificing model performance.",2024-10-17,"Neale Ratzlaff, Matthew Lyle Olson, Musashi Hinck, Shao-Yen Tseng, Vasudev Lal, Phillip Howard",http://arxiv.org/pdf/2410.13976v1,cs.CL
Detecting AI-Generated Texts in Cross-Domains,"Existing tools to detect text generated by a large language model (LLM) have
met with certain success, but their performance can drop when dealing with
texts in new domains. To tackle this issue, we train a ranking classifier
called RoBERTa-Ranker, a modified version of RoBERTa, as a baseline model using
a dataset we constructed that includes a wider variety of texts written by
humans and generated by various LLMs. We then present a method to fine-tune
RoBERTa-Ranker that requires only a small amount of labeled data in a new
domain. Experiments show that this fine-tuned domain-aware model outperforms
the popular DetectGPT and GPTZero on both in-domain and cross-domain texts,
where AI-generated texts may either be in a different domain or generated by a
different LLM not used to generate the training datasets. This approach makes
it feasible and economical to build a single system to detect AI-generated
texts across various domains.",2024-10-17,"You Zhou, Jie Wang",http://arxiv.org/pdf/2410.13966v1,cs.CL
From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization,"Although many studies have investigated and reduced hallucinations in large
language models (LLMs) for single-document tasks, research on hallucination in
multi-document summarization (MDS) tasks remains largely unexplored.
Specifically, it is unclear how the challenges arising from handling multiple
documents (e.g., repetition and diversity of information) affect models
outputs. In this work, we investigate how hallucinations manifest in LLMs when
summarizing topic-specific information from multiple documents. Since no
benchmarks exist for investigating hallucinations in MDS, we use existing news
and conversation datasets, annotated with topic-specific insights, to create
two novel multi-document benchmarks. When evaluating 5 LLMs on our benchmarks,
we observe that on average, up to 75% of the content in LLM-generated summary
is hallucinated, with hallucinations more likely to occur towards the end of
the summaries. Moreover, when summarizing non-existent topic-related
information, gpt-3.5-turbo and GPT-4o still generate summaries about 79.35% and
44% of the time, raising concerns about their tendency to fabricate content. To
understand the characteristics of these hallucinations, we manually evaluate
700+ insights and find that most errors stem from either failing to follow
instructions or producing overly generic insights. Motivated by these
observations, we investigate the efficacy of simple post-hoc baselines in
mitigating hallucinations but find them only moderately effective. Our results
underscore the need for more effective approaches to systematically mitigate
hallucinations in MDS. We release our dataset and code at
github.com/megagonlabs/Hallucination_MDS.",2024-10-17,"Catarina G. Belem, Pouya Pezeshkpour, Hayate Iso, Seiji Maekawa, Nikita Bhutani, Estevam Hruschka",http://arxiv.org/pdf/2410.13961v2,cs.CL
Ethics Whitepaper: Whitepaper on Ethical Research into Large Language Models,"This whitepaper offers an overview of the ethical considerations surrounding
research into or with large language models (LLMs). As LLMs become more
integrated into widely used applications, their societal impact increases,
bringing important ethical questions to the forefront. With a growing body of
work examining the ethical development, deployment, and use of LLMs, this
whitepaper provides a comprehensive and practical guide to best practices,
designed to help those in research and in industry to uphold the highest
ethical standards in their work.",2024-10-17,"Eddie L. Ungless, Nikolas Vitsakis, Zeerak Talat, James Garforth, Björn Ross, Arno Onken, Atoosa Kasirzadeh, Alexandra Birch",http://arxiv.org/pdf/2410.19812v1,cs.CL
FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven Question Answering Pipeline,"Financial decision-making hinges on the analysis of relevant information
embedded in the enormous volume of documents in the financial domain. To
address this challenge, we developed FinQAPT, an end-to-end pipeline that
streamlines the identification of relevant financial reports based on a query,
extracts pertinent context, and leverages Large Language Models (LLMs) to
perform downstream tasks. To evaluate the pipeline, we experimented with
various techniques to optimize the performance of each module using the FinQA
dataset. We introduced a novel clustering-based negative sampling technique to
enhance context extraction and a novel prompting method called Dynamic N-shot
Prompting to boost the numerical question-answering capabilities of LLMs. At
the module level, we achieved state-of-the-art accuracy on FinQA, attaining an
accuracy of 80.6%. However, at the pipeline level, we observed decreased
performance due to challenges in extracting relevant context from financial
reports. We conducted a detailed error analysis of each module and the
end-to-end pipeline, pinpointing specific challenges that must be addressed to
develop a robust solution for handling complex financial tasks.",2024-10-17,"Kuldeep Singh, Simerjot Kaur, Charese Smiley",http://arxiv.org/pdf/2410.13959v2,cs.CL
Identifying High Consideration E-Commerce Search Queries,"In e-commerce, high consideration search missions typically require careful
and elaborate decision making, and involve a substantial research investment
from customers. We consider the task of identifying High Consideration (HC)
queries. Identifying such queries enables e-commerce sites to better serve user
needs using targeted experiences such as curated QA widgets that help users
reach purchase decisions. We explore the task by proposing an Engagement-based
Query Ranking (EQR) approach, focusing on query ranking to indicate potential
engagement levels with query-related shopping knowledge content during product
search. Unlike previous studies on predicting trends, EQR prioritizes
query-level features related to customer behavior, finance, and catalog
information rather than popularity signals. We introduce an accurate and
scalable method for EQR and present experimental results demonstrating its
effectiveness. Offline experiments show strong ranking performance. Human
evaluation shows a precision of 96% for HC queries identified by our model. The
model was commercially deployed, and shown to outperform human-selected queries
in terms of downstream customer impact, as measured through engagement.",2024-10-17,"Zhiyu Chen, Jason Choi, Besnik Fetahu, Shervin Malmasi",http://arxiv.org/pdf/2410.13951v1,cs.CL
Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation,"Large Language Models (LLMs) have achieved impressive results across numerous
NLP tasks but still encounter difficulties in machine translation. Traditional
methods to improve translation have typically involved fine-tuning LLMs using
parallel corpora. However, vanilla fine-tuning often leads to catastrophic
forgetting of the instruction-following capabilities and alignment with human
preferences, compromising their broad general abilities and introducing
potential security risks. These abilities, which are developed using
proprietary and unavailable training data, make existing continual instruction
tuning methods ineffective. To overcome this issue, we propose a novel approach
called RaDis (Rationale Distillation). RaDis harnesses the strong generative
capabilities of LLMs to create rationales for training data, which are then
""replayed"" to prevent forgetting. These rationales encapsulate general
knowledge and safety principles, acting as self-distillation targets to
regulate the training process. By jointly training on both reference
translations and self-generated rationales, the model can learn new translation
skills while preserving its overall general abilities. Extensive experiments
demonstrate that our method enhances machine translation performance while
maintaining the broader capabilities of LLMs across other tasks. This work
presents a pathway for creating more versatile LLMs that excel in specialized
tasks without compromising generality and safety.",2024-10-17,"Junhong Wu, Yang Zhao, Yangyifan Xu, Bing Liu, Chengqing Zong",http://arxiv.org/pdf/2410.13944v1,cs.CL
Accounting for Sycophancy in Language Model Uncertainty Estimation,"Effective human-machine collaboration requires machine learning models to
externalize uncertainty, so users can reflect and intervene when necessary. For
language models, these representations of uncertainty may be impacted by
sycophancy bias: proclivity to agree with users, even if they are wrong. For
instance, models may be over-confident in (incorrect) problem solutions
suggested by a user. We study the relationship between sycophancy and
uncertainty estimation for the first time. We propose a generalization of the
definition of sycophancy bias to measure downstream impacts on uncertainty
estimation, and also propose a new algorithm (SyRoUP) to account for sycophancy
in the uncertainty estimation process. Unlike previous works on sycophancy, we
study a broad array of user behaviors, varying both correctness and confidence
of user suggestions to see how model answers (and their certainty) change. Our
experiments across conversation forecasting and question-answering tasks show
that user confidence plays a critical role in modulating the effects of
sycophancy, and that SyRoUP can better predict these effects. From these
results, we argue that externalizing both model and user uncertainty can help
to mitigate the impacts of sycophancy bias.",2024-10-17,"Anthony Sicilia, Mert Inan, Malihe Alikhani",http://arxiv.org/pdf/2410.14746v1,cs.CL
How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs,"Despite the remarkable success of Transformer-based Large Language Models
(LLMs) across various domains, understanding and enhancing their mathematical
capabilities remains a significant challenge. In this paper, we conduct a
rigorous theoretical analysis of LLMs' mathematical abilities, with a specific
focus on their arithmetic performances. We identify numerical precision as a
key factor that influences their effectiveness in mathematical tasks. Our
results show that Transformers operating with low numerical precision fail to
address arithmetic tasks, such as iterated addition and integer multiplication,
unless the model size grows super-polynomially with respect to the input
length. In contrast, Transformers with standard numerical precision can
efficiently handle these tasks with significantly smaller model sizes. We
further support our theoretical findings through empirical experiments that
explore the impact of varying numerical precision on arithmetic tasks,
providing valuable insights for improving the mathematical reasoning
capabilities of LLMs.",2024-10-17,"Guhao Feng, Kai Yang, Yuntian Gu, Xinyue Ai, Shengjie Luo, Jiacheng Sun, Di He, Zhenguo Li, Liwei Wang",http://arxiv.org/pdf/2410.13857v1,cs.CL
Can MLLMs Understand the Deep Implication Behind Chinese Images?,"As the capabilities of Multimodal Large Language Models (MLLMs) continue to
improve, the need for higher-order capability evaluation of MLLMs is
increasing. However, there is a lack of work evaluating MLLM for higher-order
perception and understanding of Chinese visual content. To fill the gap, we
introduce the **C**hinese **I**mage **I**mplication understanding
**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception
and understanding capabilities of MLLMs for Chinese images. CII-Bench stands
out in several ways compared to existing benchmarks. Firstly, to ensure the
authenticity of the Chinese context, images in CII-Bench are sourced from the
Chinese Internet and manually reviewed, with corresponding answers also
manually crafted. Additionally, CII-Bench incorporates images that represent
Chinese traditional culture, such as famous Chinese traditional paintings,
which can deeply reflect the model's understanding of Chinese traditional
culture. Through extensive experiments on CII-Bench across multiple MLLMs, we
have made significant findings. Initially, a substantial gap is observed
between the performance of MLLMs and humans on CII-Bench. The highest accuracy
of MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an
impressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional
culture images, suggesting limitations in their ability to understand
high-level semantics and lack a deep knowledge base of Chinese traditional
culture. Finally, it is observed that most models exhibit enhanced accuracy
when image emotion hints are incorporated into the prompts. We believe that
CII-Bench will enable MLLMs to gain a better understanding of Chinese semantics
and Chinese-specific images, advancing the journey towards expert artificial
general intelligence (AGI). Our project is publicly available at
https://cii-bench.github.io/.",2024-10-17,"Chenhao Zhang, Xi Feng, Yuelin Bai, Xinrun Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni",http://arxiv.org/pdf/2410.13854v1,cs.CL
Retrospective Learning from Interactions,"Multi-turn interactions between large language models (LLMs) and users
naturally include implicit feedback signals. If an LLM responds in an
unexpected way to an instruction, the user is likely to signal it by rephrasing
the request, expressing frustration, or pivoting to an alternative task. Such
signals are task-independent and occupy a relatively constrained subspace of
language, allowing the LLM to identify them even if it fails on the actual
task. We introduce ReSpect, a method to learn from such signals in past
interactions via retrospection without additional annotations. We deploy
ReSpect in a new multimodal interaction scenario, where humans instruct a
multimodal LLM to solve an abstract reasoning task with a combinatorial
solution space. Through thousands of interactions with humans, we show how
ReSpect gradually improves task completion rate from 31% to 82%, all without
any external annotation.",2024-10-17,"Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi",http://arxiv.org/pdf/2410.13852v2,cs.CL
Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation,"In this paper, we introduce Janus, an autoregressive framework that unifies
multimodal understanding and generation. Prior research often relies on a
single visual encoder for both tasks, such as Chameleon. However, due to the
differing levels of information granularity required by multimodal
understanding and generation, this approach can lead to suboptimal performance,
particularly in multimodal understanding. To address this issue, we decouple
visual encoding into separate pathways, while still leveraging a single,
unified transformer architecture for processing. The decoupling not only
alleviates the conflict between the visual encoder's roles in understanding and
generation, but also enhances the framework's flexibility. For instance, both
the multimodal understanding and generation components can independently select
their most suitable encoding methods. Experiments show that Janus surpasses
previous unified model and matches or exceeds the performance of task-specific
models. The simplicity, high flexibility, and effectiveness of Janus make it a
strong candidate for next-generation unified multimodal models.",2024-10-17,"Chengyue Wu, Xiaokang Chen, Zhiyu Wu, Yiyang Ma, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan, Ping Luo",http://arxiv.org/pdf/2410.13848v1,cs.CL
LightTransfer: Your Long-Context LLM is Secretly a Hybrid Model with Effortless Adaptation,"Scaling language models to handle longer contexts introduces substantial
memory challenges due to the growing cost of key-value (KV) caches. Motivated
by the efficiency gains of hybrid models and the broad availability of
pretrained large transformer backbones, we explore transitioning transformer
models into hybrid architectures for a more efficient generation. In this work,
we propose LightTransfer, a lightweight method that transforms models such as
LLaMA into hybrid variants. Our approach identifies lazy layers -- those
focusing on recent or initial tokens -- and replaces their full attention with
streaming attention. This transformation can be performed without any training
for long-context understanding tasks or with minimal fine-tuning for o1-like
long reasoning generation tasks that require stronger reasoning capabilities.
Experiments across diverse benchmarks and models (e.g., LLaMA, Mistral,
QwQ-STILL) demonstrate that, even when half of the layers are identified as
lazy, LightTransfer achieves up to 2.17$\times$ throughput improvement with
minimal performance loss ($<1.5\%$ on LongBench) and achieves 53.3\% on math
benchmark AIME24 of advanced o1-like long reasoning model QwQ-STILL.",2024-10-17,"Xuan Zhang, Fengzhuo Zhang, Cunxiao Du, Chao Du, Tianyu Pang, Wei Gao, Min Lin",http://arxiv.org/pdf/2410.13846v2,cs.CL
A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models,"Post-training has emerged as a crucial paradigm for adapting large-scale
pre-trained models to various tasks, whose effects are fully reflected by delta
parameters (i.e., the disparity between post-trained and pre-trained
parameters). While numerous studies have explored delta parameter properties
via operations like pruning, quantization, low-rank approximation, and
extrapolation, a unified framework for systematically examining these
characteristics has been lacking. In this paper, we propose a novel perspective
based on Riemann sum approximation of the loss function to elucidate delta
parameter editing operations. Our analysis categorizes existing methods into
three classes based on their post-editing performance: competitive, decreased,
and improved, explaining how they are expressed by the Riemann sum
approximation term and how they alter the model performance. Extensive
experiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,
and Mistral, corroborate our theoretical findings. Furthermore, we introduce
extensions to existing techniques like DARE and BitDelta, highlighting their
limitations in leveraging the properties of delta parameters and reorganizing
them into general expressions to enhance the applicability and effectiveness of
delta parameter editing in post-trained models.",2024-10-17,"Qiaoyu Tang, Le Yu, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Le Sun",http://arxiv.org/pdf/2410.13841v1,cs.CL
Automatically Interpreting Millions of Features in Large Language Models,"While the activations of neurons in deep neural networks usually do not have
a simple human-understandable interpretation, sparse autoencoders (SAEs) can be
used to transform these activations into a higher-dimensional latent space
which may be more easily interpretable. However, these SAEs can have millions
of distinct latent features, making it infeasible for humans to manually
interpret each one. In this work, we build an open-source automated pipeline to
generate and evaluate natural language explanations for SAE features using
LLMs. We test our framework on SAEs of varying sizes, activation functions, and
losses, trained on two different open-weight LLMs. We introduce five new
techniques to score the quality of explanations that are cheaper to run than
the previous state of the art. One of these techniques, intervention scoring,
evaluates the interpretability of the effects of intervening on a feature,
which we find explains features that are not recalled by existing methods. We
propose guidelines for generating better explanations that remain valid for a
broader set of activating contexts, and discuss pitfalls with existing scoring
techniques. We use our explanations to measure the semantic similarity of
independently trained SAEs, and find that SAEs trained on nearby layers of the
residual stream are highly similar. Our large-scale analysis confirms that SAE
latents are indeed much more interpretable than neurons, even when neurons are
sparsified using top-$k$ postprocessing. Our code is available at
https://github.com/EleutherAI/sae-auto-interp, and our explanations are
available at
https://huggingface.co/datasets/EleutherAI/auto_interp_explanations.",2024-10-17,"Gonçalo Paulo, Alex Mallen, Caden Juang, Nora Belrose",http://arxiv.org/pdf/2410.13928v2,cs.CL
A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement,"Reinforcement Learning from Human Feedback (RLHF) has become the predominant
approach for language model (LM) alignment. At its core, RLHF uses a
margin-based loss for preference optimization, specifying ideal LM behavior
only by the difference between preferred and dispreferred responses. In this
paper, we identify a common pitfall of margin-based methods -- the
under-specification of ideal LM behavior on preferred and dispreferred
responses individually, which leads to two unintended consequences as the
margin increases: (1) The probability of dispreferred (e.g., unsafe) responses
may increase, resulting in potential safety alignment failures. (2) The
probability of preferred responses may decrease, even when those responses are
ideal. We demystify the reasons behind these problematic behaviors:
margin-based losses couple the change in the preferred probability to the
gradient of the dispreferred one, and vice versa, often preventing the
preferred probability from increasing while the dispreferred one decreases, and
thus causing a synchronized increase or decrease in both probabilities. We term
this effect, inherent in margin-based objectives, gradient entanglement.
Formally, we derive conditions for general margin-based alignment objectives
under which gradient entanglement becomes concerning: the inner product of the
gradients of preferred and dispreferred log-probabilities is large relative to
the individual gradient norms. We theoretically investigate why such inner
products can be large when aligning language models and empirically validate
our findings. Empirical implications of our framework extend to explaining
important differences in the training dynamics of various preference
optimization algorithms, and suggesting potential algorithm designs to mitigate
the under-specification issue of margin-based methods and thereby improving
language model alignment.",2024-10-17,"Hui Yuan, Yifan Zeng, Yue Wu, Huazheng Wang, Mengdi Wang, Liu Leqi",http://arxiv.org/pdf/2410.13828v2,cs.CL
AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents,"Autonomy via agents using large language models (LLMs) for personalized,
standardized tasks boosts human efficiency. Automating web tasks (like booking
hotels within a budget) is increasingly sought after. Fulfilling practical
needs, the web agent also serves as an important proof-of-concept example for
various agent grounding scenarios, with its success promising advancements in
many future applications. Prior research often handcrafts web agent strategies
(e.g., prompting templates, multi-agent systems, search methods, etc.) and the
corresponding in-context examples, which may not generalize well across all
real-world scenarios. On the other hand, there has been limited study on the
misalignment between a web agent's observation/action representation and the
pre-training data of the LLM it's based on. This discrepancy is especially
notable when LLMs are primarily trained for language completion rather than
tasks involving embodied navigation actions and symbolic web elements. Our
study enhances an LLM-based web agent by simply refining its observation and
action space to better align with the LLM's capabilities. This approach enables
our base agent to significantly outperform previous methods on a wide variety
of web tasks. Specifically, on WebArena, a benchmark featuring general-purpose
web interaction tasks, our agent AgentOccam surpasses the previous
state-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute
points respectively, and boosts the success rate by 26.6 points (+161%) over
similar plain web agents with its observation and action space alignment. We
achieve this without using in-context examples, new agent roles, online
feedback or search strategies. AgentOccam's simple design highlights LLMs'
impressive zero-shot performance on web tasks, and underlines the critical role
of carefully tuning observation and action spaces for LLM-based agents.",2024-10-17,"Ke Yang, Yao Liu, Sapana Chaudhary, Rasool Fakoor, Pratik Chaudhari, George Karypis, Huzefa Rangwala",http://arxiv.org/pdf/2410.13825v2,cs.CL
Harnessing Webpage UIs for Text-Rich Visual Understanding,"Text-rich visual understanding-the ability to process environments where
dense textual content is integrated with visuals-is crucial for multimodal
large language models (MLLMs) to interact effectively with structured
environments. To enhance this capability, we propose synthesizing general
multimodal instructions from webpage UIs using text-based large language models
(LLMs). Despite lacking direct visual input, text-based LLMs are able to
process structured text representations from webpage accessibility trees. These
instructions are then paired with UI screenshots to train multimodal models. We
introduce MultiUI, a dataset containing 7.3 million samples from 1 million
websites, covering diverse multimodal tasks and UI layouts. Models trained on
MultiUI not only excel in web UI tasks-achieving up to a 48% improvement on
VisualWebBench and a 19.1% boost in element accuracy on a web agent dataset
Mind2Web-but also generalize surprisingly well to non-web UI tasks and even to
non-UI domains, such as document understanding, OCR, and chart interpretation.
These results highlight the broad applicability of web UI data for advancing
text-rich visual understanding across various scenarios.",2024-10-17,"Junpeng Liu, Tianyue Ou, Yifan Song, Yuxiao Qu, Wai Lam, Chenyan Xiong, Wenhu Chen, Graham Neubig, Xiang Yue",http://arxiv.org/pdf/2410.13824v3,cs.CL
ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise,"Control system design is a crucial aspect of modern engineering with
far-reaching applications across diverse sectors including aerospace,
automotive systems, power grids, and robotics. Despite advances made by Large
Language Models (LLMs) in various domains, their application in control system
design remains limited due to the complexity and specificity of control theory.
To bridge this gap, we introduce ControlAgent, a new paradigm that automates
control system design via novel integration of LLM agents and control-oriented
domain expertise. ControlAgent encodes expert control knowledge and emulates
human iterative design processes by gradually tuning controller parameters to
meet user-specified requirements for stability, performance, and robustness.
ControlAgent integrates multiple collaborative LLM agents, including a central
agent responsible for task distribution and task-specific agents dedicated to
detailed controller design for various types of systems and requirements.
ControlAgent also employs a Python computation agent that performs complex
calculations and controller evaluations based on standard design information
provided by task-specified LLM agents. Combined with a history and feedback
module, the task-specific LLM agents iteratively refine controller parameters
based on real-time feedback from prior designs. Overall, ControlAgent mimics
the design processes used by (human) practicing engineers, but removes all the
human efforts and can be run in a fully automated way to give end-to-end
solutions for control system design with user-specified requirements. To
validate ControlAgent's effectiveness, we develop ControlEval, an evaluation
dataset that comprises 500 control tasks with various specific design goals.
The effectiveness of ControlAgent is demonstrated via extensive comparative
evaluations between LLM-based and traditional human-involved toolbox-based
baselines.",2024-10-17,"Xingang Guo, Darioush Keivan, Usman Syed, Lianhui Qin, Huan Zhang, Geir Dullerud, Peter Seiler, Bin Hu",http://arxiv.org/pdf/2410.19811v1,cs.CL
De-mark: Watermark Removal in Large Language Models,"Watermarking techniques offer a promising way to identify machine-generated
content via embedding covert information into the contents generated from
language models (LMs). However, the robustness of the watermarking schemes has
not been well explored. In this paper, we present De-mark, an advanced
framework designed to remove n-gram-based watermarks effectively. Our method
utilizes a novel querying strategy, termed random selection probing, which aids
in assessing the strength of the watermark and identifying the red-green list
within the n-gram watermark. Experiments on popular LMs, such as Llama3 and
ChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermark
removal and exploitation tasks.",2024-10-17,"Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang",http://arxiv.org/pdf/2410.13808v1,cs.CL
A Watermark for Order-Agnostic Language Models,"Statistical watermarking techniques are well-established for sequentially
decoded language models (LMs). However, these techniques cannot be directly
applied to order-agnostic LMs, as the tokens in order-agnostic LMs are not
generated sequentially. In this work, we introduce Pattern-mark, a
pattern-based watermarking framework specifically designed for order-agnostic
LMs. We develop a Markov-chain-based watermark generator that produces
watermark key sequences with high-frequency key patterns. Correspondingly, we
propose a statistical pattern-based detection algorithm that recovers the key
sequence during detection and conducts statistical tests based on the count of
high-frequency patterns. Our extensive evaluations on order-agnostic LMs, such
as ProteinMPNN and CMLM, demonstrate Pattern-mark's enhanced detection
efficiency, generation quality, and robustness, positioning it as a superior
watermarking technique for order-agnostic LMs.",2024-10-17,"Ruibo Chen, Yihan Wu, Yanshuo Chen, Chenxi Liu, Junfeng Guo, Heng Huang",http://arxiv.org/pdf/2410.13805v1,cs.CL
BenTo: Benchmark Task Reduction with In-Context Transferability,"Evaluating large language models (LLMs) is costly: it requires the generation
and examination of LLM outputs on a large-scale benchmark of various tasks.
This paper investigates how to efficiently reduce the tasks used to benchmark
LLMs without affecting the evaluation quality. Our study reveals that task
transferability and relevance provide critical information to identify the most
representative subset of tasks via optimizing a facility location function. We
propose a practically efficient metric for estimating the transferability
between two tasks via in-context learning (ICL). By analyzing the pairwise
transferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or
FLAN) to 5% while inducing only a <4% difference to the evaluation on the
original benchmark. Compared to prior works, our method is training-free,
gradient-free, and highly efficient requiring ICL only.",2024-10-17,"Hongyu Zhao, Ming Li, Lichao Sun, Tianyi Zhou",http://arxiv.org/pdf/2410.13804v3,cs.CL
Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions,"Large language models (LLMs) must often respond to highly ambiguous user
requests. In such cases, the LLM's best response may be to ask a clarifying
question to elicit more information. Existing LLMs often respond by
presupposing a single interpretation of such ambiguous requests, frustrating
users who intended a different interpretation. We speculate this is caused by
current preference data labeling practice, where LLM responses are evaluated
only on their prior contexts. To address this, we assign preference labels by
simulating their expected outcomes in future turns. This allows LLMs to learn
to ask clarifying questions when it can generate responses that are tailored to
each user interpretation in future turns. On open-domain QA datasets with
multiple annotations, we evaluate systems based on their ability to ask
clarifying questions to recover each user's interpretation and expected answer.
We compare systems trained using our proposed preference labeling methods
against standard methods, which assign preferences based on only prior context.
Our method achieves a 5% improvement in F1 measured against the answer set from
different interpretations of each query, showing the value of modeling future
conversation turns. We further demonstrate that our method can be used to train
models to judiciously determine when to ask clarifying questions, directly
answering the question when clarification is unnecessary. In our experiments,
we find that our method achieves a 3% improvement in accuracy of such judgments
over existing methods.",2024-10-17,"Michael J. Q. Zhang, W. Bradley Knox, Eunsol Choi",http://arxiv.org/pdf/2410.13788v2,cs.CL
Looking Inward: Language Models Can Learn About Themselves by Introspection,"Humans acquire knowledge by observing the external world, but also by
introspection. Introspection gives a person privileged access to their current
state of mind (e.g., thoughts and feelings) that is not accessible to external
observers. Can LLMs introspect? We define introspection as acquiring knowledge
that is not contained in or derived from training data but instead originates
from internal states. Such a capability could enhance model interpretability.
Instead of painstakingly analyzing a model's internal workings, we could simply
ask the model about its beliefs, world models, and goals. More speculatively,
an introspective model might self-report on whether it possesses certain
internal states such as subjective feelings or desires and this could inform us
about the moral status of these states. Such self-reports would not be entirely
dictated by the model's training data.
  We study introspection by finetuning LLMs to predict properties of their own
behavior in hypothetical scenarios. For example, ""Given the input P, would your
output favor the short- or long-term option?"" If a model M1 can introspect, it
should outperform a different model M2 in predicting M1's behavior even if M2
is trained on M1's ground-truth behavior. The idea is that M1 has privileged
access to its own behavioral tendencies, and this enables it to predict itself
better than M2 (even if M2 is generally stronger).
  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to
predict itself), we find that the model M1 outperforms M2 in predicting itself,
providing evidence for introspection. Notably, M1 continues to predict its
behavior accurately even after we intentionally modify its ground-truth
behavior. However, while we successfully elicit introspection on simple tasks,
we are unsuccessful on more complex tasks or those requiring
out-of-distribution generalization.",2024-10-17,"Felix J Binder, James Chua, Tomek Korbak, Henry Sleight, John Hughes, Robert Long, Ethan Perez, Miles Turpin, Owain Evans",http://arxiv.org/pdf/2410.13787v1,cs.CL
PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment,"Alignment of large language models (LLMs) involves training models on
preference-contrastive output pairs to adjust their responses according to
human preferences. To obtain such contrastive pairs, traditional methods like
RLHF and RLAIF rely on limited contrasting patterns, such as varying model
variants or decoding temperatures. This singularity leads to two issues: (1)
alignment is not comprehensive; and thereby (2) models are susceptible to
jailbreaking attacks. To address these issues, we investigate how to construct
more comprehensive and diversified contrasting patterns to enhance preference
data (RQ1) and verify the impact of the diversification of contrasting patterns
on model alignment (RQ2). For RQ1, we propose PopAlign, a framework that
integrates diversified contrasting patterns across the prompt, model, and
pipeline levels, introducing six contrasting strategies that do not require
additional feedback labeling procedures. Regarding RQ2, we conduct thorough
experiments demonstrating that PopAlign significantly outperforms existing
methods, leading to more comprehensive alignment.",2024-10-17,"Zekun Moore Wang, Shawn Wang, Kang Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang",http://arxiv.org/pdf/2410.13785v1,cs.CL
Quantity vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?,"Monolingual data, being readily available in large quantities, has been used
to upscale the scarcely available parallel data to train better models for
automatic translation. Self-learning, where a model is made to learn from its
output, is one approach to exploit such data. However, it has been shown that
too much of this data can be detrimental to the performance of the model if the
available parallel data is comparatively extremely low. In this study, we
investigate whether the monolingual data can also be too little and if this
reduction, based on quality, has any effect on the performance of the
translation model. Experiments have shown that on English-German low-resource
NMT, it is often better to select only the most useful additional data, based
on quality or closeness to the domain of the test data, than utilizing all of
the available data.",2024-10-17,"Idris Abdulmumin, Bashir Shehu Galadanci, Garba Aliyu, Shamsuddeen Hassan Muhammad",http://arxiv.org/pdf/2410.13783v1,cs.CL
Optimal Quantization for Matrix Multiplication,"Recent work in machine learning community proposed multiple methods for
performing lossy compression (quantization) of large matrices. This
quantization is important for accelerating matrix multiplication (main
component of large language models), which is often bottlenecked by the speed
of loading these matrices from memory. Unlike classical vector quantization and
rate-distortion theory, the goal of these new compression algorithms is to be
able to approximate not the matrices themselves, but their matrix product.
Specifically, given a pair of real matrices $A,B$ an encoder (compressor) is
applied to each of them independently producing descriptions with $R$ bits per
entry. These representations subsequently are used by the decoder to estimate
matrix product $A^\top B$. In this work, we provide a non-asymptotic lower
bound on the mean squared error of this approximation (as a function of rate
$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,
we construct a universal quantizer based on nested lattices with an explicit
guarantee of approximation error for any (non-random) pair of matrices $A$, $B$
in terms of only Frobenius norms $\|\bar{A}\|_F, \|\bar{B}\|_F$ and
$\|\bar{A}^\top \bar{B}\|_F$, where $\bar{A},\bar{B}$ are versions of $A,B$
with zero-centered columns, respectively. For iid Gaussian matrices our
quantizer achieves the lower bound and is, thus, asymptotically optimal. A
practical low-complexity version of our quantizer achieves performance quite
close to optimal. In addition, we derive rate-distortion function for matrix
multiplication of iid Gaussian matrices, which exhibits an interesting
phase-transition at $R\approx 0.906$ bit/entry.",2024-10-17,"Or Ordentlich, Yury Polyanskiy",http://arxiv.org/pdf/2410.13780v2,cs.CL
The Mystery of the Pathological Path-star Task for Language Models,"The recently introduced path-star task is a minimal task designed to
exemplify limitations to the abilities of language models (Bachmann and
Nagarajan, 2024). It involves a path-star graph where multiple arms radiate
from a single starting node and each node is unique. Given the start node and a
specified target node that ends an arm, the task is to generate the arm
containing that target node. This is straightforward for a human but
surprisingly difficult for language models, which did not outperform the random
baseline. The authors hypothesized this is due to a deficiency in
teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative
settings and that the issue is partially due to representation. We introduce a
regularization method using structured samples of the same graph but with
differing target nodes, improving results across a variety of model types. We
provide RASP proofs showing the task is theoretically solvable. Finally, we
find settings where an encoder-only model can consistently solve the task.",2024-10-17,Arvid Frydenlund,http://arxiv.org/pdf/2410.13779v2,cs.CL
Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors,"In-context Learning (ICL) has become the primary method for performing
natural language tasks with Large Language Models (LLMs). The knowledge
acquired during pre-training is crucial for this few-shot capability, providing
the model with task priors. However, recent studies have shown that ICL
predominantly relies on retrieving task priors rather than ""learning"" to
perform tasks. This limitation is particularly evident in complex subjective
domains such as emotion and morality, where priors significantly influence
posterior predictions. In this work, we examine whether this is the result of
the aggregation used in corresponding datasets, where trying to combine
low-agreement, disparate annotations might lead to annotation artifacts that
create detrimental noise in the prompt. Moreover, we evaluate the posterior
bias towards certain annotators by grounding our study in appropriate,
quantitative measures of LLM priors. Our results indicate that aggregation is a
confounding factor in the modeling of subjective tasks, and advocate focusing
on modeling individuals instead. However, aggregation does not explain the
entire gap between ICL and the state of the art, meaning other factors in such
tasks also account for the observed phenomena. Finally, by rigorously studying
annotator-level labels, we find that it is possible for minority annotators to
both better align with LLMs and have their perspectives further amplified.",2024-10-17,"Georgios Chochlakis, Alexandros Potamianos, Kristina Lerman, Shrikanth Narayanan",http://arxiv.org/pdf/2410.13776v3,cs.CL
Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval,"Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like ""Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses"",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.",2024-10-17,"Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley",http://arxiv.org/pdf/2410.13765v2,cs.CL
Semi-supervised Fine-tuning for Large Language Models,"Supervised fine-tuning (SFT) is crucial in adapting large language model
(LLMs) to a specific domain or task. However, only a limited amount of labeled
data is available in practical applications, which poses a severe challenge for
SFT in yielding satisfactory results. Therefore, a data-efficient framework
that can fully exploit labeled and unlabeled data for LLM fine-tuning is highly
anticipated.Towards this end, we introduce a semi-supervised
fine-tuning(SemiFT) task and a framework named SemiEvol for LLM alignment from
a propagate-and-select manner. For knowledge propagation, SemiEvol adopts a
bi-level approach, propagating knowledge from labeled data to unlabeled data
through both in-weight and in-context methods. For knowledge selection,
SemiEvol incorporates a collaborative learning mechanism, selecting
higher-quality pseudo-response samples. We conducted experiments using
GPT-4o-mini and Llama-3.1 on seven general or domain-specific datasets,
demonstrating significant improvements in model performance on target data.
Furthermore, we compared SemiEvol with SFT and self-evolution methods,
highlighting its practicality in hybrid data scenarios.",2024-10-17,"Junyu Luo, Xiao Luo, Xiusi Chen, Zhiping Xiao, Wei Ju, Ming Zhang",http://arxiv.org/pdf/2410.14745v2,cs.CL
MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation,"Existing Multimodal Large Language Model (MLLM)-based agents face significant
challenges in handling complex GUI (Graphical User Interface) interactions on
devices. These challenges arise from the dynamic and structured nature of GUI
environments, which integrate text, images, and spatial relationships, as well
as the variability in action spaces across different pages and tasks. To
address these limitations, we propose MobA, a novel MLLM-based mobile assistant
system. MobA introduces an adaptive planning module that incorporates a
reflection mechanism for error recovery and dynamically adjusts plans to align
with the real environment contexts and action module's execution capacity.
Additionally, a multifaceted memory module provides comprehensive memory
support to enhance adaptability and efficiency. We also present MobBench, a
dataset designed for complex mobile interactions. Experimental results on
MobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI
environments and perform complex mobile tasks.",2024-10-17,"Zichen Zhu, Hao Tang, Yansi Li, Dingye Liu, Hongshen Xu, Kunyao Lan, Danyang Zhang, Yixuan Jiang, Hao Zhou, Chenrun Wang, Situo Zhang, Liangtai Sun, Yixiao Wang, Yuheng Sun, Lu Chen, Kai Yu",http://arxiv.org/pdf/2410.13757v3,cs.CL
LLM-Human Pipeline for Cultural Context Grounding of Conversations,"Conversations often adhere to well-understood social norms that vary across
cultures. For example, while ""addressing parents by name"" is commonplace in the
West, it is rare in most Asian cultures. Adherence or violation of such norms
often dictates the tenor of conversations. Humans are able to navigate social
situations requiring cultural awareness quite adeptly. However, it is a hard
task for NLP models.
  In this paper, we tackle this problem by introducing a ""Cultural Context
Schema"" for conversations. It comprises (1) conversational information such as
emotions, dialogue acts, etc., and (2) cultural information such as social
norms, violations, etc. We generate ~110k social norm and violation
descriptions for ~23k conversations from Chinese culture using LLMs. We refine
them using automated verification strategies which are evaluated against
culturally aware human judgements. We organize these descriptions into
meaningful structures we call ""Norm Concepts"", using an interactive
human-in-loop framework. We ground the norm concepts and the descriptions in
conversations using symbolic annotation. Finally, we use the obtained dataset
for downstream tasks such as emotion, sentiment, and dialogue act detection. We
show that it significantly improves the empirical performance.",2024-10-17,"Rajkumar Pujari, Dan Goldwasser",http://arxiv.org/pdf/2410.13727v2,cs.CL
MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems,"Traditional retrieval-augmented generation (RAG) benchmarks evaluate systems
using heuristic-based metrics, but these require human preferences as the
ground truth for reference. In contrast, arena-based benchmarks, where systems
compete against each other, require an expensive large language model (LLM) as
a judge for a reliable evaluation. We present a simple efficient technique to
combine the best of both worlds. The idea is to train a surrogate judge using
heuristic metrics as input, to output the LLM as a judge prediction. In our
work, we develop MIRAGE-Bench, a synthetic arena-based RAG benchmark for 18
diverse languages on Wikipedia focused on multilingual answer generation
evaluation. It extensively couples both heuristic features and LLM as a judge
for evaluation. We benchmark 19 multilingual LLMs, and observe a high
correlation (Kendall Tau ($\tau$) = 0.909) using our surrogate judge and
between GPT-4o as a teacher using the Bradley-Terry framework. Our results show
proprietary and large open-source LLMs currently dominate on MIRAGE-Bench. Our
code and datasets are made publicly available here:
https://github.com/vectara/mirage-bench.",2024-10-17,"Nandan Thakur, Suleman Kazi, Ge Luo, Jimmy Lin, Amin Ahmad",http://arxiv.org/pdf/2410.13716v2,cs.CL
On the Role of Attention Heads in Large Language Model Safety,"Large language models (LLMs) achieve state-of-the-art performance on multiple
language tasks, yet their safety guardrails can be circumvented, leading to
harmful generations. In light of this, recent research on safety mechanisms has
emerged, revealing that when safety representations or component are
suppressed, the safety capability of LLMs are compromised. However, existing
research tends to overlook the safety impact of multi-head attention
mechanisms, despite their crucial role in various model functionalities. Hence,
in this paper, we aim to explore the connection between standard attention
mechanisms and safety capability to fill this gap in the safety-related
mechanistic interpretability. We propose a novel metric which tailored for
multi-head attention, the Safety Head ImPortant Score (Ships), to assess the
individual heads' contributions to model safety. Based on this, we generalize
Ships to the dataset level and further introduce the Safety Attention Head
AttRibution Algorithm (Sahara) to attribute the critical safety attention heads
inside the model. Our findings show that the special attention head has a
significant impact on safety. Ablating a single safety head allows aligned
model (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,
while only modifying 0.006% of the parameters, in contrast to the ~ 5%
modification required in previous studies. More importantly, we demonstrate
that attention heads primarily function as feature extractors for safety and
models fine-tuned from the same base model exhibit overlapping safety heads
through comprehensive experiments. Together, our attribution approach and
findings provide a novel perspective for unpacking the black box of safety
mechanisms within large models.",2024-10-17,"Zhenhong Zhou, Haiyang Yu, Xinghua Zhang, Rongwu Xu, Fei Huang, Kun Wang, Yang Liu, Junfeng Fang, Yongbin Li",http://arxiv.org/pdf/2410.13708v2,cs.CL
Unconstrained Model Merging for Enhanced LLM Reasoning,"Recent advancements in building domain-specific large language models (LLMs)
have shown remarkable success, especially in tasks requiring reasoning
abilities like logical inference over complex relationships and multi-step
problem solving. However, creating a powerful all-in-one LLM remains
challenging due to the need for proprietary data and vast computational
resources. As a resource-friendly alternative, we explore the potential of
merging multiple expert models into a single LLM. Existing studies on model
merging mainly focus on generalist LLMs instead of domain experts, or the LLMs
under the same architecture and size. In this work, we propose an unconstrained
model merging framework that accommodates both homogeneous and heterogeneous
model architectures with a focus on reasoning tasks. A fine-grained layer-wise
weight merging strategy is designed for homogeneous models merging, while
heterogeneous model merging is built upon the probabilistic distribution
knowledge derived from instruction-response fine-tuning data. Across 7
benchmarks and 9 reasoning-optimized LLMs, we reveal key findings that
combinatorial reasoning emerges from merging which surpasses simple additive
effects. We propose that unconstrained model merging could serve as a
foundation for decentralized LLMs, marking a notable progression from the
existing centralized LLM framework. This evolution could enhance wider
participation and stimulate additional advancement in the field of artificial
intelligence, effectively addressing the constraints posed by centralized
models.",2024-10-17,"Yiming Zhang, Baoyi He, Shengyu Zhang, Yuhao Fu, Qi Zhou, Zhijie Sang, Zijin Hong, Kejing Yang, Wenjun Wang, Jianbo Yuan, Guanghan Ning, Linyi Li, Chunlin Ji, Fei Wu, Hongxia Yang",http://arxiv.org/pdf/2410.13699v2,cs.CL
Exploring the Design Space of Visual Context Representation in Video MLLMs,"Video Multimodal Large Language Models (MLLMs) have shown remarkable
capability of understanding the video semantics on various downstream tasks.
Despite the advancements, there is still a lack of systematic research on
visual context representation, which refers to the scheme to select frames from
a video and further select the tokens from a frame. In this paper, we explore
the design space for visual context representation, and aim to improve the
performance of video MLLMs by finding more effective representation schemes.
Firstly, we formulate the task of visual context representation as a
constrained optimization problem, and model the language modeling loss as a
function of the number of frames and the number of embeddings (or tokens) per
frame, given the maximum visual context window size. Then, we explore the
scaling effects in frame selection and token selection respectively, and fit
the corresponding function curve by conducting extensive empirical experiments.
We examine the effectiveness of typical selection strategies and present
empirical findings to determine the two factors. Furthermore, we study the
joint effect of frame selection and token selection, and derive the optimal
formula for determining the two factors. We demonstrate that the derived
optimal settings show alignment with the best-performed results of empirical
experiments. Our code and model are available at:
https://github.com/RUCAIBox/Opt-Visor.",2024-10-17,"Yifan Du, Yuqi Huo, Kun Zhou, Zijia Zhao, Haoyu Lu, Han Huang, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen",http://arxiv.org/pdf/2410.13694v1,cs.CL
Pose-Based Sign Language Appearance Transfer,"We introduce a method for transferring the signer's appearance in sign
language skeletal poses while preserving the sign content. Using estimated
poses, we transfer the appearance of one signer to another, maintaining natural
movements and transitions. This approach improves pose-based rendering and sign
stitching while obfuscating identity. Our experiments show that while the
method reduces signer identification accuracy, it slightly harms sign
recognition performance, highlighting a tradeoff between privacy and utility.
Our code is available at
https://github.com/sign-language-processing/pose-anonymization.",2024-10-17,"Amit Moryossef, Gerard Sant, Zifan Jiang",http://arxiv.org/pdf/2410.13675v2,cs.CL
HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings,"Assessing the capabilities and limitations of large language models (LLMs)
has garnered significant interest, yet the evaluation of multiple models in
real-world scenarios remains rare. Multilingual evaluation often relies on
translated benchmarks, which typically do not capture linguistic and cultural
nuances present in the source language. This study provides an extensive
assessment of 24 LLMs on real world data collected from Indian patients
interacting with a medical chatbot in Indian English and 4 other Indic
languages. We employ a uniform Retrieval Augmented Generation framework to
generate responses, which are evaluated using both automated techniques and
human evaluators on four specific metrics relevant to our application. We find
that models vary significantly in their performance and that instruction tuned
Indic models do not always perform well on Indic language queries. Further, we
empirically show that factual correctness is generally lower for responses to
Indic queries compared to English queries. Finally, our qualitative work shows
that code-mixed and culturally relevant queries in our dataset pose challenges
to evaluated models.",2024-10-17,"Varun Gumma, Anandhita Raghunath, Mohit Jain, Sunayana Sitaram",http://arxiv.org/pdf/2410.13671v1,cs.CL
signwriting-evaluation: Effective Sign Language Evaluation via SignWriting,"The lack of automatic evaluation metrics tailored for SignWriting presents a
significant obstacle in developing effective transcription and translation
models for signed languages. This paper introduces a comprehensive suite of
evaluation metrics specifically designed for SignWriting, including adaptations
of standard metrics such as \texttt{BLEU} and \texttt{chrF}, the application of
\texttt{CLIPScore} to SignWriting images, and a novel symbol distance metric
unique to our approach. We address the distinct challenges of evaluating single
signs versus continuous signing and provide qualitative demonstrations of
metric efficacy through score distribution analyses and nearest-neighbor
searches within the SignBank corpus. Our findings reveal the strengths and
limitations of each metric, offering valuable insights for future advancements
using SignWriting. This work contributes essential tools for evaluating
SignWriting models, facilitating progress in the field of sign language
processing. Our code is available at
\url{https://github.com/sign-language-processing/signwriting-evaluation}.",2024-10-17,"Amit Moryossef, Rotem Zilberman, Ohad Langer",http://arxiv.org/pdf/2410.13668v1,cs.CL
ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization,"Dialogue agents have been receiving increasing attention for years, and this
trend has been further boosted by the recent progress of large language models
(LLMs). Stance detection and dialogue summarization are two core tasks of
dialogue agents in application scenarios that involve argumentative dialogues.
However, research on these tasks is limited by the insufficiency of public
datasets, especially for non-English languages. To address this language
resource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first
Chinese dataset for benchmarking target-independent stance detection and debate
summarization. Our dataset consists of 1,218 real-world debates that were
conducted in Chinese on 476 unique topics, containing 2,436 stance-specific
summaries and 14,133 fully annotated utterances. Besides providing a versatile
testbed for future research, we also conduct an empirical study on the dataset
and propose an integrated task. The results show the challenging nature of the
dataset and suggest a potential of incorporating stance detection in
summarization for argumentative dialogue.",2024-10-17,"Xiutian Zhao, Ke Wang, Wei Peng",http://arxiv.org/pdf/2410.13667v1,cs.CL
VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks,"Deriving inference from heterogeneous inputs (such as images, text, and
audio) is an important skill for humans to perform day-to-day tasks. A similar
ability is desirable for the development of advanced Artificial Intelligence
(AI) systems. While state-of-the-art models are rapidly closing the gap with
human-level performance on diverse computer vision and NLP tasks separately,
they struggle to solve tasks that require joint reasoning over visual and
textual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask
benchmark for natural language understanding, we propose VL-GLUE in this paper.
VL-GLUE consists of over 100k samples spanned across seven different tasks,
which at their core require visuo-linguistic reasoning. Moreover, our benchmark
comprises of diverse image types (from synthetically rendered figures, and
day-to-day scenes to charts and complex diagrams) and includes a broad variety
of domain-specific text (from cooking, politics, and sports to high-school
curricula), demonstrating the need for multi-modal understanding in the
real-world. We show that this benchmark is quite challenging for existing
large-scale vision-language models and encourage development of systems that
possess robust visuo-linguistic reasoning capabilities.",2024-10-17,"Shailaja Keyur Sampat, Mutsumi Nakamura, Shankar Kailas, Kartik Aggarwal, Mandy Zhou, Yezhou Yang, Chitta Baral",http://arxiv.org/pdf/2410.13666v1,cs.CL
Red and blue language: Word choices in the Trump & Harris 2024 presidential debate,"Political debates are a peculiar type of political discourse, in which
candidates directly confront one another, addressing not only the the
moderator's questions, but also their opponent's statements, as well as the
concerns of voters from both parties and undecided voters. Therefore, language
is adjusted to meet specific expectations and achieve persuasion. We analyse
how the language of Trump and Harris during the debate (September 10th 2024)
differs in relation to the following semantic and pragmatic features, for which
we formulated targeted hypotheses: framing values and ideology, appealing to
emotion, using words with different degrees of concreteness and specificity,
addressing others through singular or plural pronouns. Our findings include:
differences in the use of figurative frames (Harris often framing issues around
recovery and empowerment, Trump often focused on crisis and decline); similar
use of emotional language, with Trump showing a slight higher tendency toward
negativity and toward less subjective language compared to Harris; no
significant difference in the specificity of candidates' responses; similar use
of abstract language, with Trump showing more variability than Harris,
depending on the subject discussed; differences in addressing the opponent,
with Trump not mentioning Harris by name, while Harris referring to Trump
frequently; different uses of pronouns, with Harris using both singular and
plural pronouns equally, while Trump using more singular pronouns. The results
are discussed in relation to previous literature on Red and Blue language,
which refers to distinct linguistic patterns associated with conservative (Red)
and liberal (Blue) political ideologies.",2024-10-17,"Philipp Wicke, Marianna M. Bolognesi",http://arxiv.org/pdf/2410.13654v1,cs.CL
A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks,"In virtual assistant (VA) systems it is important to reject or redirect user
queries that fall outside the scope of the system. One of the most accurate
approaches for out-of-scope (OOS) rejection is to combine it with the task of
intent classification on in-scope queries, and to use methods based on the
similarity of embeddings produced by transformer-based sentence encoders.
Typically, such encoders are fine-tuned for the intent-classification task,
using cross-entropy loss. Recent work has shown that while this produces
suitable embeddings for the intent-classification task, it also tends to
disperse in-scope embeddings over the full sentence embedding space. This
causes the in-scope embeddings to potentially overlap with OOS embeddings,
thereby making OOS rejection difficult. This is compounded when OOS data is
unknown. To mitigate this issue our work proposes to regularize the
cross-entropy loss with an in-scope embedding reconstruction loss learned using
an auto-encoder. Our method achieves a 1-4% improvement in the area under the
precision-recall curve for rejecting out-of-sample (OOS) instances, without
compromising intent classification performance.",2024-10-17,"Tianyi Zhang, Atta Norouzian, Aanchan Mohan, Frederick Ducatelle",http://arxiv.org/pdf/2410.13649v2,cs.CL
SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs,"While prior work has explored whether large language models (LLMs) possess a
""theory of mind"" (ToM) - the ability to attribute mental states to oneself and
others - there has been little work testing whether LLMs can implicitly apply
such knowledge to predict behavior, or to judge whether an observed behavior is
rational. Such skills are critical for appropriate interaction in social
environments. We create a new dataset, SimpleTom, containing concise, diverse
stories (e.g., ""The can of Pringles has moldy chips in it. Mary picks up the
can in the supermarket and walks to the cashier.""), each with three questions
that test different degrees of ToM reasoning, asking models to predict (a)
mental state (""Is Mary aware of the mold?""), (b) behavior (""Will Mary pay for
the chips or report the mold?""), and (c) judgment (""Mary paid for the chips.
Was that reasonable?""). To our knowledge, SimpleToM is the first dataset to
systematically explore downstream reasoning requiring knowledge of mental
states in realistic scenarios. Our experimental results are intriguing: While
most models can reliably predict mental state on our dataset (a), they often
fail to correctly predict the behavior (b), and fare even worse at judging
whether given behaviors are reasonable (c), despite being correctly aware of
the protagonist's mental state should make such secondary predictions obvious.
We further show that we can help models do better at (b) and (c) via
interventions such as reminding the model of its earlier mental state answer
and mental-state-specific chain-of-thought prompting, raising the action
prediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment
accuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models
can be coaxed to perform well, it requires task-specific interventions, and the
natural model performances remain low, a cautionary tale for LLM deployment.",2024-10-17,"Yuling Gu, Oyvind Tafjord, Hyunwoo Kim, Jared Moore, Ronan Le Bras, Peter Clark, Yejin Choi",http://arxiv.org/pdf/2410.13648v1,cs.CL
An Active Learning Framework for Inclusive Generation by Large Language Models,"Ensuring that Large Language Models (LLMs) generate text representative of
diverse sub-populations is essential, particularly when key concepts related to
under-represented groups are scarce in the training data. We address this
challenge with a novel clustering-based active learning framework, enhanced
with knowledge distillation. The proposed framework transforms the intermediate
outputs of the learner model, enabling effective active learning for generative
tasks for the first time. Integration of clustering and knowledge distillation
yields more representative models without prior knowledge of underlying data
distribution and overbearing human efforts. We validate our approach in
practice through case studies in counter-narration and style transfer. We
construct two new datasets in tandem with model training, showing a performance
improvement of 2%-10% over baseline models. Our results also show more
consistent performance across various data subgroups and increased lexical
diversity, underscoring our model's resilience to skewness in available data.
Further, our results show that the data acquired via our approach improves the
performance of secondary models not involved in the learning loop, showcasing
practical utility of the framework.",2024-10-17,"Sabit Hassan, Anthony Sicilia, Malihe Alikhani",http://arxiv.org/pdf/2410.13641v2,cs.CL
Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation,"LLM self-evaluation relies on the LLM's own ability to estimate response
correctness, which can greatly improve its deployment reliability. In this
research track, we propose the Chain-of-Embedding (CoE) in the latent space to
enable LLMs to perform output-free self-evaluation. CoE consists of all
progressive hidden states produced during the inference time, which can be
treated as the latent thinking path of LLMs. We find that when LLMs respond
correctly and incorrectly, their CoE features differ, these discrepancies
assist us in estimating LLM response correctness. Experiments in four diverse
domains and seven LLMs fully demonstrate the effectiveness of our method.
Meanwhile, its label-free design intent without any training and
millisecond-level computational cost ensures real-time feedback in large-scale
scenarios. More importantly, we provide interesting insights into LLM response
correctness from the perspective of hidden state changes inside LLMs.",2024-10-17,"Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Rui Wang",http://arxiv.org/pdf/2410.13640v2,cs.CL
A Comparative Study on Reasoning Patterns of OpenAI's o1 Model,"Enabling Large Language Models (LLMs) to handle a wider range of complex
tasks (e.g., coding, math) has drawn great attention from many researchers. As
LLMs continue to evolve, merely increasing the number of model parameters
yields diminishing performance improvements and heavy computational costs.
Recently, OpenAI's o1 model has shown that inference strategies (i.e.,
Test-time Compute methods) can also significantly enhance the reasoning
capabilities of LLMs. However, the mechanisms behind these methods are still
unexplored. In our work, to investigate the reasoning patterns of o1, we
compare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent
Workflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general
reasoning benchmarks in three domains (i.e., math, coding, commonsense
reasoning). Specifically, first, our experiments show that the o1 model has
achieved the best performance on most datasets. Second, as for the methods of
searching diverse responses (e.g., BoN), we find the reward models' capability
and the search space both limit the upper boundary of these methods. Third, as
for the methods that break the problem into many sub-problems, the Agent
Workflow has achieved better performance than Step-wise BoN due to the
domain-specific system prompt for planning better reasoning processes. Fourth,
it is worth mentioning that we have summarized six reasoning patterns of o1,
and provided a detailed analysis on several reasoning benchmarks.",2024-10-17,"Siwei Wu, Zhongyuan Peng, Xinrun Du, Tuney Zheng, Minghao Liu, Jialong Wu, Jiachen Ma, Yizhi Li, Jian Yang, Wangchunshu Zhou, Qunshu Lin, Junbo Zhao, Zhaoxiang Zhang, Wenhao Huang, Ge Zhang, Chenghua Lin, J. H. Liu",http://arxiv.org/pdf/2410.13639v2,cs.CL
Eliciting Uncertainty in Chain-of-Thought to Mitigate Bias against Forecasting Harmful User Behaviors,"Conversation forecasting tasks a model with predicting the outcome of an
unfolding conversation. For instance, it can be applied in social media
moderation to predict harmful user behaviors before they occur, allowing for
preventative interventions. While large language models (LLMs) have recently
been proposed as an effective tool for conversation forecasting, it's unclear
what biases they may have, especially against forecasting the (potentially
harmful) outcomes we request them to predict during moderation. This paper
explores to what extent model uncertainty can be used as a tool to mitigate
potential biases. Specifically, we ask three primary research questions: 1) how
does LLM forecasting accuracy change when we ask models to represent their
uncertainty; 2) how does LLM bias change when we ask models to represent their
uncertainty; 3) how can we use uncertainty representations to reduce or
completely mitigate biases without many training data points. We address these
questions for 5 open-source language models tested on 2 datasets designed to
evaluate conversation forecasting for social media moderation.",2024-10-17,"Anthony Sicilia, Malihe Alikhani",http://arxiv.org/pdf/2410.14744v1,cs.CL
H2OVL-Mississippi Vision Language Models Technical Report,"Smaller vision-language models (VLMs) are becoming increasingly important for
privacy-focused, on-device applications due to their ability to run efficiently
on consumer hardware for processing enterprise commercial documents and images.
These models require strong language understanding and visual capabilities to
enhance human-machine interaction. To address this need, we present
H2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs
using 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny
model with 0.8 billion parameters that specializes in text recognition,
achieving state of the art performance on the Text Recognition portion of
OCRBench and surpassing much larger models in this area. Additionally, we are
releasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use
cases, exhibiting highly competitive metrics across various academic
benchmarks. Both models build upon our prior work with H2O-Danube language
models, extending their capabilities into the visual domain. We release them
under the Apache 2.0 license, making VLMs accessible to everyone, democratizing
document AI and visual LLMs.",2024-10-17,"Shaikat Galib, Shanshan Wang, Guanshuo Xu, Pascal Pfeiffer, Ryan Chesler, Mark Landry, Sri Satish Ambati",http://arxiv.org/pdf/2410.13611v1,cs.CL
MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling,"Integrating tools into Large Language Models (LLMs) has facilitated the
widespread application. Despite this, in specialized downstream task contexts,
reliance solely on tools is insufficient to fully address the complexities of
the real world. This particularly restricts the effective deployment of LLMs in
fields such as medicine. In this paper, we focus on the downstream tasks of
medical calculators, which use standardized tests to assess an individual's
health status. We introduce MeNTi, a universal agent architecture for LLMs.
MeNTi integrates a specialized medical toolkit and employs meta-tool and nested
calling mechanisms to enhance LLM tool utilization. Specifically, it achieves
flexible tool selection and nested tool calling to address practical issues
faced in intricate medical scenarios, including calculator selection, slot
filling, and unit conversion. To assess the capabilities of LLMs for
quantitative assessment throughout the clinical process of calculator
scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical
calculators to perform calculations and assess patient health status. CalcQA is
constructed by professional physicians and includes 100 case-calculator pairs,
complemented by a toolkit of 281 medical tools. The experimental results
demonstrate significant performance improvements with our framework. This
research paves new directions for applying LLMs in demanding scenarios of
medicine.",2024-10-17,"Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang",http://arxiv.org/pdf/2410.13610v3,cs.CL
Large Language Models as Narrative-Driven Recommenders,"Narrative-driven recommenders aim to provide personalized suggestions for
user requests expressed in free-form text such as ""I want to watch a thriller
with a mind-bending story, like Shutter Island."" Although large language models
(LLMs) have been shown to excel in processing general natural language queries,
their effectiveness for handling such recommendation requests remains
relatively unexplored. To close this gap, we compare the performance of 38
open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in
a movie recommendation setting. For this, we utilize a gold-standard,
crowdworker-annotated dataset of posts from reddit's movie suggestion community
and employ various prompting strategies, including zero-shot, identity, and
few-shot prompting. Our findings demonstrate the ability of LLMs to generate
contextually relevant movie recommendations, significantly outperforming other
state-of-the-art approaches, such as doc2vec. While we find that closed-source
and large-parameterized models generally perform best, medium-sized open-source
models remain competitive, being only slightly outperformed by their more
computationally expensive counterparts. Furthermore, we observe no significant
differences across prompting strategies for most models, underscoring the
effectiveness of simple approaches such as zero-shot prompting for
narrative-driven recommendations. Overall, this work offers valuable insights
for recommender system researchers as well as practitioners aiming to integrate
LLMs into real-world recommendation tools.",2024-10-17,"Lukas Eberhard, Thorsten Ruprechter, Denis Helic",http://arxiv.org/pdf/2410.13604v1,cs.CL
Enhancing Fact Retrieval in PLMs through Truthfulness,"Pre-trained Language Models (PLMs) encode various facts about the world at
their pre-training phase as they are trained to predict the next or missing
word in a sentence. There has a been an interest in quantifying and improving
the amount of facts that can be extracted from PLMs, as they have been
envisioned to act as soft knowledge bases, which can be queried in natural
language. Different approaches exist to enhance fact retrieval from PLM. Recent
work shows that the hidden states of PLMs can be leveraged to determine the
truthfulness of the PLMs' inputs. Leveraging this finding to improve factual
knowledge retrieval remains unexplored. In this work, we investigate the use of
a helper model to improve fact retrieval. The helper model assesses the
truthfulness of an input based on the corresponding hidden states
representations from the PLMs. We evaluate this approach on several masked PLMs
and show that it enhances fact retrieval by up to 33\%. Our findings highlight
the potential of hidden states representations from PLMs in improving their
factual knowledge retrieval.",2024-10-17,"Paul Youssef, Jörg Schlötterer, Christin Seifert",http://arxiv.org/pdf/2410.13562v1,cs.CL
SynapticRAG: Enhancing Temporal Memory Retrieval in Large Language Models through Synaptic Mechanisms,"Existing retrieval methods in Large Language Models show degradation in
accuracy when handling temporally distributed conversations, primarily due to
their reliance on simple similarity-based retrieval. Unlike existing memory
retrieval methods that rely solely on semantic similarity, we propose
SynapticRAG, which uniquely combines temporal association triggers with
biologically-inspired synaptic propagation mechanisms. Our approach uses
temporal association triggers and synaptic-like stimulus propagation to
identify relevant dialogue histories. A dynamic leaky integrate-and-fire
mechanism then selects the most contextually appropriate memories. Experiments
on four datasets of English, Chinese and Japanese show that compared to
state-of-the-art memory retrieval methods, SynapticRAG achieves consistent
improvements across multiple metrics up to 14.66% points. This work bridges the
gap between cognitive science and language model development, providing a new
framework for memory management in conversational systems.",2024-10-17,"Yuki Hou, Haruki Tamoto, Qinghua Zhao, Homei Miyashita",http://arxiv.org/pdf/2410.13553v2,cs.CL
Bias in the Mirror: Are LLMs opinions robust to their own adversarial attacks ?,"Large language models (LLMs) inherit biases from their training data and
alignment processes, influencing their responses in subtle ways. While many
studies have examined these biases, little work has explored their robustness
during interactions. In this paper, we introduce a novel approach where two
instances of an LLM engage in self-debate, arguing opposing viewpoints to
persuade a neutral version of the model. Through this, we evaluate how firmly
biases hold and whether models are susceptible to reinforcing misinformation or
shifting to harmful viewpoints. Our experiments span multiple LLMs of varying
sizes, origins, and languages, providing deeper insights into bias persistence
and flexibility across linguistic and cultural contexts.",2024-10-17,"Virgile Rennard, Christos Xypolopoulos, Michalis Vazirgiannis",http://arxiv.org/pdf/2410.13517v2,cs.CL
GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models,"Geometry problem-solving demands advanced reasoning abilities to process
multimodal inputs and employ mathematical knowledge effectively.
Vision-language models (VLMs) have made significant progress in various
multimodal tasks. Yet, they still struggle with geometry problems and are
significantly limited by their inability to perform mathematical operations not
seen during pre-training, such as calculating the cosine of an arbitrary angle,
and by difficulties in correctly applying relevant geometry formulas. To
overcome these challenges, we present GeoCoder, which leverages modular
code-finetuning to generate and execute code using a predefined geometry
function library. By executing the code, we achieve accurate and deterministic
calculations, contrasting the stochastic nature of autoregressive token
prediction, while the function library minimizes errors in formula usage. We
also propose a multimodal retrieval-augmented variant of GeoCoder, named
RAG-GeoCoder, which incorporates a non-parametric memory module for retrieving
functions from the geometry library, thereby reducing reliance on parametric
memory. Our modular code-finetuning approach enhances the geometric reasoning
capabilities of VLMs, yielding an average improvement of over 16% across
various question complexities on the GeomVerse dataset compared to other
finetuning methods.",2024-10-17,"Aditya Sharma, Aman Dalmia, Mehran Kazemi, Amal Zouaq, Christopher J. Pal",http://arxiv.org/pdf/2410.13510v1,cs.CL
RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards,"Retrieval-Augmented Generation (RAG) has proven its effectiveness in
mitigating hallucinations in Large Language Models (LLMs) by retrieving
knowledge from external resources. To adapt LLMs for the RAG systems, current
approaches use instruction tuning to optimize LLMs, improving their ability to
utilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses
on equipping LLMs to handle diverse RAG tasks using different instructions.
However, it trains RAG modules to overfit training signals and overlooks the
varying data preferences among agents within the RAG system. In this paper, we
propose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG
systems by aligning data preferences between different RAG modules. DDR works
by collecting the rewards to optimize each agent in the RAG system with the
rollout method, which prompts agents to sample some potential responses as
perturbations, evaluates the impact of these perturbations on the whole RAG
system, and subsequently optimizes the agent to produce outputs that improve
the performance of the RAG system. Our experiments on various
knowledge-intensive tasks demonstrate that DDR significantly outperforms the
SFT method, particularly for LLMs with smaller-scale parameters that depend
more on the retrieved knowledge. Additionally, DDR exhibits a stronger
capability to align the data preference between RAG modules. The DDR method
makes the generation module more effective in extracting key information from
documents and mitigating conflicts between parametric memory and external
knowledge. All codes are available at https://github.com/OpenMatch/RAG-DDR.",2024-10-17,"Xinze Li, Sen Mei, Zhenghao Liu, Yukun Yan, Shuo Wang, Shi Yu, Zheni Zeng, Hao Chen, Ge Yu, Zhiyuan Liu, Maosong Sun, Chenyan Xiong",http://arxiv.org/pdf/2410.13509v2,cs.CL
MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs,"Large language models (LLMs) can solve arithmetic word problems with high
accuracy, but little is known about how well they generalize to more complex
problems. This is difficult to study, as (i) much of the available evaluation
data has already been seen by the most capable models during training, and (ii)
existing benchmarks do not capture how problem proofs may be arbitrarily
complex in various ways. In this paper, we present a data-generation framework
for evaluating LLMs on problems with arbitrarily complex arithmetic proofs,
called MathGAP. MathGAP generates problem statements and chain-of-thought
reasoning traces according to specifications about their arithmetic proof
structure, enabling systematic studies on easy-to-hard generalization with
respect to complexity of proof trees. Using MathGAP, we find that LLMs show a
significant decrease in performance as proofs get deeper and wider. This effect
is more pronounced in complex, nonlinear proof structures, which are
challenging even for the most capable models. The models are also sensitive to
simple changes in sentence ordering. However, they remain capable of solving
some complex problems, suggesting that reasoning generalization is noisy.",2024-10-17,"Andreas Opedal, Haruki Shirakami, Bernhard Schölkopf, Abulhair Saparov, Mrinmaya Sachan",http://arxiv.org/pdf/2410.13502v3,cs.CL
"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques","Text generation is the automated process of producing written or spoken
language using computational methods. It involves generating coherent and
contextually relevant text based on predefined rules or learned patterns.
However, challenges in text generation arise from maintaining coherence,
ensuring diversity and creativity, and avoiding biases or inappropriate
content. This research paper developed a novel approach to improve text
generation in the context of joint Natural Language Generation (NLG) and
Natural Language Understanding (NLU) learning. The data is prepared by
gathering and preprocessing annotated datasets, including cleaning,
tokenization, stemming, and stop-word removal. Feature extraction techniques
such as POS tagging, Bag of words, and Term Frequency-Inverse Document
Frequency (TF-IDF) are applied. Transformer-based encoders and decoders,
capturing long range dependencies and improving source-target sequence
modelling. Pre-trained language models like Optimized BERT are incorporated,
along with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).
Reinforcement learning with policy gradient techniques, semi-supervised
training, improved attention mechanisms, and differentiable approximations like
straight-through Gumbel SoftMax estimator are employed to fine-tune the models
and handle complex linguistic tasks effectively. The proposed model is
implemented using Python.",2024-10-17,"Rahimanuddin Shaik, Katikela Sreeharsha Kishore",http://arxiv.org/pdf/2410.13498v2,cs.CL
Repetition Neurons: How Do Language Models Produce Repetitions?,"This paper introduces repetition neurons, regarded as skill neurons
responsible for the repetition problem in text generation tasks. These neurons
are progressively activated more strongly as repetition continues, indicating
that they perceive repetition as a task to copy the previous context
repeatedly, similar to in-context learning. We identify these repetition
neurons by comparing activation values before and after the onset of repetition
in texts generated by recent pre-trained language models. We analyze the
repetition neurons in three English and one Japanese pre-trained language
models and observe similar patterns across them.",2024-10-17,"Tatsuya Hiraoka, Kentaro Inui",http://arxiv.org/pdf/2410.13497v2,cs.CL
Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes,"Detecting offensive memes is crucial, yet standard deep neural network
systems often remain opaque. Various input attribution-based methods attempt to
interpret their behavior, but they face challenges with implicitly offensive
memes and non-causal attributions. To address these issues, we propose a
framework based on a Structural Causal Model (SCM). In this framework,
VisualBERT is trained to predict the class of an input meme based on both meme
input and causal concepts, allowing for transparent interpretation. Our
qualitative evaluation demonstrates the framework's effectiveness in
understanding model behavior, particularly in determining whether the model was
right due to the right reason, and in identifying reasons behind
misclassification. Additionally, quantitative analysis assesses the
significance of proposed modelling choices, such as de-confounding, adversarial
learning, and dynamic routing, and compares them with input attribution
methods. Surprisingly, we find that input attribution methods do not guarantee
causality within our framework, raising questions about their reliability in
safety-critical applications. The project page is at:
https://newcodevelop.github.io/causality_adventure/",2024-10-17,"Dibyanayan Bandyopadhyay, Mohammed Hasanuzzaman, Asif Ekbal",http://arxiv.org/pdf/2410.13488v1,cs.CL
IterSelectTune: An Iterative Training Framework for Efficient Instruction-Tuning Data Selection,"As large language models (LLMs) continue to advance, instruction tuning has
become critical for improving their ability to generate accurate and
contextually appropriate responses. Although numerous instruction-tuning
datasets have been developed to enhance LLM performance, selecting high-quality
instruction data from large source datasets typically demands significant human
effort. In this work, we introduce $\textbf{IterSelectTune}$, an efficient,
cost-effective iterative training policy for selecting high-quality instruction
data with no human involvement and limited reliance on GPT-4. By fine-tuning on
approximately 20\% of the source data, our method consistently outperforms
models fine-tuned on the full dataset across multiple benchmarks and public
test datasets. These results highlight the effectiveness of our approach in
enhancing LLM performance while reducing the computational resources required
for instruction tuning.",2024-10-17,"Jielin Song, Siyu Liu, Bin Zhu, Yanghui Rao",http://arxiv.org/pdf/2410.13464v1,cs.CL
Progressive Mixed-Precision Decoding for Efficient LLM Inference,"In spite of the great potential of large language models (LLMs) across
various tasks, their deployment on resource-constrained devices remains
challenging due to their excessive computational and memory demands.
Quantization has emerged as an effective solution by storing weights in reduced
precision. However, utilizing low precisions (i.e.~2/3-bit) to substantially
alleviate the memory-boundedness of LLM decoding, still suffers from
prohibitive performance drop. In this work, we argue that existing approaches
fail to explore the diversity in computational patterns, redundancy, and
sensitivity to approximations of the different phases of LLM inference,
resorting to a uniform quantization policy throughout. Instead, we propose a
novel phase-aware method that selectively allocates precision during different
phases of LLM inference, achieving both strong context extraction during
prefill and efficient memory bandwidth utilization during decoding. To further
address the memory-boundedness of the decoding phase, we introduce Progressive
Mixed-Precision Decoding (PMPD), a technique that enables the gradual lowering
of precision deeper in the generated sequence, together with a spectrum of
precision-switching schedulers that dynamically drive the precision-lowering
decisions in either task-adaptive or prompt-adaptive manner. Extensive
evaluation across diverse language tasks shows that when targeting Nvidia GPUs,
PMPD achieves 1.4$-$12.2$\times$ speedup in matrix-vector multiplications over
fp16 models, while when targeting an LLM-optimized NPU, our approach delivers a
throughput gain of 3.8$-$8.0$\times$ over fp16 models and up to 1.54$\times$
over uniform quantization approaches while preserving the output quality.",2024-10-17,"Hao Mark Chen, Fuwen Tan, Alexandros Kouris, Royson Lee, Hongxiang Fan, Stylianos I. Venieris",http://arxiv.org/pdf/2410.13461v2,cs.CL
Decomposition Dilemmas: Does Claim Decomposition Boost or Burden Fact-Checking Performance?,"Fact-checking pipelines increasingly adopt the Decompose-Then-Verify
paradigm, where texts are broken down into smaller claims for individual
verification and subsequently combined for a veracity decision. While
decomposition is widely-adopted in such pipelines, its effects on final
fact-checking performance remain underexplored. Some studies have reported
improvements from decompostition, while others have observed performance
declines, indicating its inconsistent impact. To date, no comprehensive
analysis has been conducted to understand this variability. To address this
gap, we present an in-depth analysis that explicitly examines the impact of
decomposition on downstream verification performance. Through error case
inspection and experiments, we introduce a categorization of decomposition
errors and reveal a trade-off between accuracy gains and the noise introduced
through decomposition. Our analysis provides new insights into understanding
current system's instability and offers guidance for future studies toward
improving claim decomposition in fact-checking pipelines.",2024-10-17,"Qisheng Hu, Quanyu Long, Wenya Wang",http://arxiv.org/pdf/2411.02400v2,cs.CL
Breaking the Manual Annotation Bottleneck: Creating a Comprehensive Legal Case Criticality Dataset through Semi-Automated Labeling,"Predicting case criticality helps legal professionals in the court system
manage large volumes of case law. This paper introduces the Criticality
Prediction dataset, a new resource for evaluating the potential influence of
Swiss Federal Supreme Court decisions on future jurisprudence. Unlike existing
approaches that rely on resource-intensive manual annotations, we
semi-automatically derive labels leading to a much larger dataset than
otherwise possible. Our dataset features a two-tier labeling system: (1) the
LD-Label, which identifies cases published as Leading Decisions (LD), and (2)
the Citation-Label, which ranks cases by their citation frequency and recency.
This allows for a more nuanced evaluation of case importance. We evaluate
several multilingual models, including fine-tuned variants and large language
models, and find that fine-tuned models consistently outperform zero-shot
baselines, demonstrating the need for task-specific adaptation. Our
contributions include the introduction of this task and the release of a
multilingual dataset to the research community.",2024-10-17,"Ronja Stern, Ken Kawamura, Matthias Stürmer, Ilias Chalkidis, Joel Niklaus",http://arxiv.org/pdf/2410.13460v1,cs.CL
MedINST: Meta Dataset of Biomedical Instructions,"The integration of large language model (LLM) techniques in the field of
medical analysis has brought about significant advancements, yet the scarcity
of large, diverse, and well-annotated datasets remains a major challenge.
Medical data and tasks, which vary in format, size, and other parameters,
require extensive preprocessing and standardization for effective use in
training LLMs. To address these challenges, we introduce MedINST, the Meta
Dataset of Biomedical Instructions, a novel multi-domain, multi-task
instructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over
7 million training samples, making it the most comprehensive biomedical
instruction dataset to date. Using MedINST as the meta dataset, we curate
MedINST32, a challenging benchmark with different task difficulties aiming to
evaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and
evaluate on MedINST32, showcasing enhanced cross-task generalization.",2024-10-17,"Wenhan Han, Meng Fang, Zihan Zhang, Yu Yin, Zirui Song, Ling Chen, Mykola Pechenizkiy, Qingyu Chen",http://arxiv.org/pdf/2410.13458v1,cs.CL
Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland,"Legal research is a time-consuming task that most lawyers face on a daily
basis. A large part of legal research entails looking up relevant caselaw and
bringing it in relation to the case at hand. Lawyers heavily rely on summaries
(also called headnotes) to find the right cases quickly. However, not all
decisions are annotated with headnotes and writing them is time-consuming.
Automated headnote creation has the potential to make hundreds of thousands of
decisions more accessible for legal research in Switzerland alone. To kickstart
this, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a
novel cross-lingual resource featuring 18K court rulings from the Swiss Federal
Supreme Court (SFSC), in German, French, and Italian, along with German
headnotes. We fine-tune and evaluate three mT5 variants, along with proprietary
models. Our analysis highlights that while proprietary models perform well in
zero-shot and one-shot settings, fine-tuned smaller models still provide a
strong competitive edge. We publicly release the dataset to facilitate further
research in multilingual legal summarization and the development of assistive
technologies for legal professionals",2024-10-17,"Luca Rolshoven, Vishvaksenan Rasiah, Srinanda Brügger Bose, Matthias Stürmer, Joel Niklaus",http://arxiv.org/pdf/2410.13456v1,cs.CL
Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR,"Automatic speech recognition (ASR) for low-resource languages remains a
challenge due to the scarcity of labeled training data. Parameter-efficient
fine-tuning and text-only adaptation are two popular methods that have been
used to address such low-resource settings. In this work, we investigate how
these techniques can be effectively combined using a multilingual multimodal
model like SeamlessM4T. Multimodal models are able to leverage unlabeled text
via text-only adaptation with further parameter-efficient ASR fine-tuning, thus
boosting ASR performance. We also show cross-lingual transfer from a
high-resource language, achieving up to a relative 17% WER reduction over a
baseline in a zero-shot setting without any labeled speech.",2024-10-17,"Abhishek Gupta, Amruta Parulekar, Sameep Chattopadhyay, Preethi Jyothi",http://arxiv.org/pdf/2410.13445v1,cs.CL
NLIP_Lab-IITH Multilingual MT System for WAT24 MT Shared Task,"This paper describes NLIP Lab's multilingual machine translation system for
the WAT24 shared task on multilingual Indic MT task for 22 scheduled languages
belonging to 4 language families. We explore pre-training for Indic languages
using alignment agreement objectives. We utilize bi-lingual dictionaries to
substitute words from source sentences. Furthermore, we fine-tuned language
direction-specific multilingual translation models using small and high-quality
seed data. Our primary submission is a 243M parameters multilingual translation
model covering 22 Indic languages. In the IN22-Gen benchmark, we achieved an
average chrF++ score of 46.80 and 18.19 BLEU score for the En-Indic direction.
In the Indic-En direction, we achieved an average chrF++ score of 56.34 and
30.82 BLEU score. In the In22-Conv benchmark, we achieved an average chrF++
score of 43.43 and BLEU score of 16.58 in the En-Indic direction, and in the
Indic-En direction, we achieved an average of 52.44 and 29.77 for chrF++ and
BLEU respectively. Our model\footnote{Our code and models are available at
\url{https://github.com/maharajbrahma/WAT2024-MultiIndicMT}} is competitive
with IndicTransv1 (474M parameter model).",2024-10-17,"Maharaj Brahma, Pramit Sahoo, Maunendra Sankar Desarkar",http://arxiv.org/pdf/2410.13443v1,cs.CL
Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive Learning,"Supervised contrastive learning has achieved remarkable success by leveraging
label information; however, determining positive samples in multi-label
scenarios remains a critical challenge. In multi-label supervised contrastive
learning (MSCL), multi-label relations are not yet fully defined, leading to
ambiguity in identifying positive samples and formulating contrastive loss
functions to construct the representation space. To address these challenges,
we: (i) first define five distinct multi-label relations in MSCL to
systematically identify positive samples, (ii) introduce a novel
Similarity-Dissimilarity Loss that dynamically re-weights samples through
computing the similarity and dissimilarity factors between positive samples and
given anchors based on multi-label relations, and (iii) further provide
theoretical grounded proofs for our method through rigorous mathematical
analysis that supports the formulation and effectiveness of the proposed loss
function. We conduct the experiments across both image and text modalities, and
extend the evaluation to medical domain. The results demonstrate that our
method consistently outperforms baselines in a comprehensive evaluation,
confirming its effectiveness and robustness. Code is available at:
https://github.com/guangminghuang/similarity-dissimilarity-loss.",2024-10-17,"Guangming Huang, Yunfei Long, Cunjin Luo",http://arxiv.org/pdf/2410.13439v4,cs.CL
Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models,"Recent advancements in large language models (LLMs) have demonstrated that
progressive refinement, rather than providing a single answer, results in more
accurate and thoughtful outputs. However, existing methods often rely heavily
on supervision signals to evaluate previous responses, making it difficult to
assess output quality in more open-ended scenarios effectively. Additionally,
these methods are typically designed for specific tasks, which limits their
generalization to new domains. To address these limitations, we propose
Progressive Thought Refinement (PTR), a framework that enables LLMs to refine
their responses progressively. PTR operates in two phases: (1) Thought data
construction stage: We propose a weak and strong model collaborative selection
strategy to build a high-quality progressive refinement dataset to ensure
logical consistency from thought to answers, and the answers are gradually
refined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training
structure to mask the ""thought"" and adjust loss weights to encourage LLMs to
refine prior thought, teaching them to implicitly understand ""how to improve""
rather than ""what is correct."" Experimental results show that PTR significantly
enhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)
without task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also
demonstrate substantial improvements in the quality of responses beyond mere
accuracy, suggesting that PTR truly teaches LLMs to self-improve over time.",2024-10-17,"Chengyu Du, Jinyi Han, Yizhou Ying, Aili Chen, Qianyu He, Haokun Zhao, Sirui Xia, Haoran Guo, Jiaqing Liang, Zulong Chen, Liangyue Li, Yanghua Xiao",http://arxiv.org/pdf/2410.13413v1,cs.CL
Attr-Int: A Simple and Effective Entity Alignment Framework for Heterogeneous Knowledge Graphs,"Entity alignment (EA) refers to the task of linking entities in different
knowledge graphs (KGs). Existing EA methods rely heavily on structural
isomorphism. However, in real-world KGs, aligned entities usually have
non-isomorphic neighborhood structures, which paralyses the application of
these structure-dependent methods. In this paper, we investigate and tackle the
problem of entity alignment between heterogeneous KGs. First, we propose two
new benchmarks to closely simulate real-world EA scenarios of heterogeneity.
Then we conduct extensive experiments to evaluate the performance of
representative EA methods on the new benchmarks. Finally, we propose a simple
and effective entity alignment framework called Attr-Int, in which innovative
attribute information interaction methods can be seamlessly integrated with any
embedding encoder for entity alignment, improving the performance of existing
entity alignment techniques. Experiments demonstrate that our framework
outperforms the state-of-the-art approaches on two new benchmarks.",2024-10-17,"Linyan Yang, Jingwei Cheng, Chuanhao Xu, Xihao Wang, Jiayi Li, Fu Zhang",http://arxiv.org/pdf/2410.13409v2,cs.CL
MoR: Mixture of Ranks for Low-Rank Adaptation Tuning,"Low-Rank Adaptation (LoRA) drives research to align its performance with full
fine-tuning. However, significant challenges remain: (1) Simply increasing the
rank size of LoRA does not effectively capture high-rank information, which
leads to a performance bottleneck.(2) MoE-style LoRA methods substantially
increase parameters and inference latency, contradicting the goals of efficient
fine-tuning and ease of application. To address these challenges, we introduce
Mixture of Ranks (MoR), which learns rank-specific information for different
tasks based on input and efficiently integrates multi-rank information. We
firstly propose a new framework that equates the integration of multiple LoRAs
to expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA
already captures sufficient intrinsic information, and MoR can derive high-rank
information through mathematical transformations of the low-rank components.
Thus, MoR can reduces the learning difficulty of LoRA and enhances its
multi-task capabilities. MoR achieves impressive results, with MoR delivering a
1.31\% performance improvement while using only 93.93\% of the parameters
compared to baseline methods.",2024-10-17,"Chuanyu Tang, Yilong Chen, Zhenyu Zhang, Junyuan Shang, Wenyuan Zhang, Yong Huang, Tingwen Liu",http://arxiv.org/pdf/2410.13408v2,cs.CL
Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and Humans,"This chapter introduces a research project titled ""Analyzing the Political
Discourse: A Collaboration Between Humans and Artificial Intelligence"", which
was initiated in preparation for Greece's 2023 general elections. The project
focused on the analysis of political leaders' campaign speeches, employing
Artificial Intelligence (AI), in conjunction with an interdisciplinary team
comprising journalists, a political scientist, and data scientists. The chapter
delves into various aspects of political discourse analysis, including
sentiment analysis, polarization, populism, topic detection, and Named Entities
Recognition (NER). This experimental study investigates the capabilities of
large language model (LLMs), and in particular OpenAI's ChatGPT, for analyzing
political speech, evaluates its strengths and weaknesses, and highlights the
essential role of human oversight in using AI in journalism projects and
potentially other societal sectors. The project stands as an innovative example
of human-AI collaboration (known also as ""hybrid intelligence"") within the
realm of digital humanities, offering valuable insights for future initiatives.",2024-10-17,"Thanasis Troboukis, Kelly Kiki, Antonis Galanopoulos, Pavlos Sermpezis, Stelios Karamanidis, Ilias Dimitriadis, Athena Vakali",http://arxiv.org/pdf/2410.13400v1,cs.CL
Linguistically Grounded Analysis of Language Models using Shapley Head Values,"Understanding how linguistic knowledge is encoded in language models is
crucial for improving their generalisation capabilities. In this paper, we
investigate the processing of morphosyntactic phenomena, by leveraging a
recently proposed method for probing language models via Shapley Head Values
(SHVs). Using the English language BLiMP dataset, we test our approach on two
widely used models, BERT and RoBERTa, and compare how linguistic constructions
such as anaphor agreement and filler-gap dependencies are handled. Through
quantitative pruning and qualitative clustering analysis, we demonstrate that
attention heads responsible for processing related linguistic phenomena cluster
together. Our results show that SHV-based attributions reveal distinct patterns
across both models, providing insights into how language models organize and
process linguistic information. These findings support the hypothesis that
language models learn subnetworks corresponding to linguistic theory, with
potential implications for cross-linguistic model analysis and interpretability
in Natural Language Processing (NLP).",2024-10-17,"Marcell Fekete, Johannes Bjerva",http://arxiv.org/pdf/2410.13396v2,cs.CL
Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs,"Evaluating machine-generated text remains a significant challenge in NLP,
especially for non-English languages. Current methodologies, including
automated metrics, human assessments, and LLM-based evaluations, predominantly
focus on English, revealing a significant gap in multilingual evaluation
frameworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an
extensible framework that includes evaluator LLMs (Hercule) and a novel test
set (Recon) specifically designed for multilingual evaluation. Our test set
features 500 human-annotated instructions spanning various task capabilities
along with human judgment scores across six languages. This would enable
benchmarking of general-purpose multilingual LLMs and facilitate
meta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a
cross-lingual evaluation model that addresses the scarcity of reference answers
in the target language by learning to assign scores to responses based on
easily available reference answers in English. Our experiments demonstrate that
Hercule aligns more closely with human judgments compared to proprietary
models, demonstrating the effectiveness of such cross-lingual evaluation in low
resource scenarios. Further, it is also effective in zero-shot evaluation on
unseen languages. This study is the first comprehensive examination of
cross-lingual evaluation using LLMs, presenting a scalable and effective
approach for multilingual assessment. All code, datasets, and models will be
publicly available to enable further research in this important area.",2024-10-17,"Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, Mitesh M. Khapra",http://arxiv.org/pdf/2410.13394v1,cs.CL
Judgment of Learning: A Human Ability Beyond Generative Artificial Intelligence,"Large language models (LLMs) increasingly mimic human cognition in various
language-based tasks. However, their capacity for metacognition - particularly
in predicting memory performance - remains unexplored. Here, we introduce a
cross-agent prediction model to assess whether ChatGPT-based LLMs align with
human judgments of learning (JOL), a metacognitive measure where individuals
predict their own future memory performance. We tested humans and LLMs on pairs
of sentences, one of which was a garden-path sentence - a sentence that
initially misleads the reader toward an incorrect interpretation before
requiring reanalysis. By manipulating contextual fit (fitting vs. unfitting
sentences), we probed how intrinsic cues (i.e., relatedness) affect both LLM
and human JOL. Our results revealed that while human JOL reliably predicted
actual memory performance, none of the tested LLMs (GPT-3.5-turbo, GPT-4-turbo,
and GPT-4o) demonstrated comparable predictive accuracy. This discrepancy
emerged regardless of whether sentences appeared in fitting or unfitting
contexts. These findings indicate that, despite LLMs' demonstrated capacity to
model human cognition at the object-level, they struggle at the meta-level,
failing to capture the variability in individual memory predictions. By
identifying this shortcoming, our study underscores the need for further
refinements in LLMs' self-monitoring abilities, which could enhance their
utility in educational settings, personalized learning, and human-AI
interactions. Strengthening LLMs' metacognitive performance may reduce the
reliance on human oversight, paving the way for more autonomous and seamless
integration of AI into tasks requiring deeper cognitive awareness.",2024-10-17,"Markus Huff, Elanur Ulakçı",http://arxiv.org/pdf/2410.13392v2,cs.CL
On the Use of Audio to Improve Dialogue Policies,"With the significant progress of speech technologies, spoken goal-oriented
dialogue systems are becoming increasingly popular. One of the main modules of
a dialogue system is typically the dialogue policy, which is responsible for
determining system actions. This component usually relies only on audio
transcriptions, being strongly dependent on their quality and ignoring very
important extralinguistic information embedded in the user's speech. In this
paper, we propose new architectures to add audio information by combining
speech and text embeddings using a Double Multi-Head Attention component. Our
experiments show that audio embedding-aware dialogue policies outperform
text-based ones, particularly in noisy transcription scenarios, and that how
text and audio embeddings are combined is crucial to improve performance. We
obtained a 9.8% relative improvement in the User Request Score compared to an
only-text-based dialogue system on the DSTC2 dataset.",2024-10-17,"Daniel Roncel, Federico Costa, Javier Hernando",http://arxiv.org/pdf/2410.13385v1,cs.CL
RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models,"The development of large language models (LLMs) has significantly enhanced
the capabilities of multimodal LLMs (MLLMs) as general assistants. However,
lack of user-specific knowledge still restricts their application in human's
daily life. In this paper, we introduce the Retrieval Augmented Personalization
(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we
turn it into a personalized assistant in three steps. (a) Remember: We design a
key-value database to store user-related information, e.g., user's name, avatar
and other attributes. (b) Retrieve: When the user initiates a conversation, RAP
will retrieve relevant information from the database using a multimodal
retriever. (c) Generate: The input query and retrieved concepts' information
are fed into MLLMs to generate personalized, knowledge-augmented responses.
Unlike previous methods, RAP allows real-time concept editing via updating the
external database. To further improve generation quality and alignment with
user-specific information, we design a pipeline for data collection and create
a specialized dataset for personalized training of MLLMs. Based on the dataset,
we train a series of MLLMs as personalized multimodal assistants. By
pretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual
concepts without additional finetuning. Our models demonstrate outstanding
flexibility and generation quality across a variety of tasks, such as
personalized image captioning, question answering and visual recognition. The
code, data and models are available at https://hoar012.github.io/RAP-Project/.",2024-10-17,"Haoran Hao, Jiaming Han, Changsheng Li, Yu-Feng Li, Xiangyu Yue",http://arxiv.org/pdf/2410.13360v3,cs.CL
Decoding Fatigue Levels of Pilots Using EEG Signals with Hybrid Deep Neural Networks,"The detection of pilots' mental states is critical, as abnormal mental states
have the potential to cause catastrophic accidents. This study demonstrates the
feasibility of using deep learning techniques to classify different fatigue
levels, specifically a normal state, low fatigue, and high fatigue. To the best
of our knowledge, this is the first study to classify fatigue levels in pilots.
Our approach employs the hybrid deep neural network comprising five
convolutional blocks and one long short-term memory block to extract the
significant features from electroencephalography signals. Ten pilots
participated in the experiment, which was conducted in a simulated flight
environment. Compared to four conventional models, our proposed model achieved
a superior grand-average accuracy of 0.8801, outperforming other models by at
least 0.0599 in classifying fatigue levels. In addition to successfully
classifying fatigue levels, our model provided valuable feedback to subjects.
Therefore, we anticipate that our study will make the significant contributions
to the advancement of autonomous flight and driving technologies, leveraging
artificial intelligence in the future.",2024-10-30,"Dae-Hyeok Lee, Sung-Jin Kim, Si-Hyun Kim",http://arxiv.org/pdf/2411.09707v1,cs.LG
Federated Learning for Diabetic Retinopathy Diagnosis: Enhancing Accuracy and Generalizability in Under-Resourced Regions,"Diabetic retinopathy is the leading cause of vision loss in working-age
adults worldwide, yet under-resourced regions lack ophthalmologists. Current
state-of-the-art deep learning systems struggle at these institutions due to
limited generalizability. This paper explores a novel federated learning system
for diabetic retinopathy diagnosis with the EfficientNetB0 architecture to
leverage fundus data from multiple institutions to improve diagnostic
generalizability at under-resourced hospitals while preserving patient-privacy.
The federated model achieved 93.21% accuracy in five-category classification on
an unseen dataset and 91.05% on lower-quality images from a simulated
under-resourced institution. The model was deployed onto two apps for quick and
accurate diagnosis.",2024-10-30,"Gajan Mohan Raj, Michael G. Morley, Mohammad Eslami",http://arxiv.org/pdf/2411.00869v1,cs.LG
Generative forecasting of brain activity enhances Alzheimer's classification and interpretation,"Understanding the relationship between cognition and intrinsic brain activity
through purely data-driven approaches remains a significant challenge in
neuroscience. Resting-state functional magnetic resonance imaging (rs-fMRI)
offers a non-invasive method to monitor regional neural activity, providing a
rich and complex spatiotemporal data structure. Deep learning has shown promise
in capturing these intricate representations. However, the limited availability
of large datasets, especially for disease-specific groups such as Alzheimer's
Disease (AD), constrains the generalizability of deep learning models. In this
study, we focus on multivariate time series forecasting of independent
component networks derived from rs-fMRI as a form of data augmentation, using
both a conventional LSTM-based model and the novel Transformer-based BrainLM
model. We assess their utility in AD classification, demonstrating how
generative forecasting enhances classification performance. Post-hoc
interpretation of BrainLM reveals class-specific brain network sensitivities
associated with AD.",2024-10-30,"Yutong Gao, Vince D. Calhoun, Robyn L. Miller",http://arxiv.org/pdf/2410.23515v1,cs.LG
Dynamic Strategy Planning for Efficient Question Answering with Large Language Models,"Research has shown the effectiveness of reasoning (e.g., Chain-of-Thought),
planning (e.g., SelfAsk), and retrieval augmented generation strategies to
improve the performance of Large Language Models (LLMs) on various tasks, such
as question answering. However, using a single fixed strategy to answer
different kinds of questions is suboptimal in performance and inefficient in
terms of generated output tokens and performed retrievals. In our work, we
propose a novel technique DyPlan, to induce a dynamic strategy selection
process in LLMs, to improve performance and reduce costs in question-answering.
DyPlan incorporates an initial decision step to select the most suitable
strategy conditioned on the input question and guides the LLM's response
generation accordingly. We extend DyPlan to DyPlan-verify, adding an internal
verification and correction process to further enrich the generated answer.
Experiments on three prominent multi-hop question answering (MHQA) datasets
reveal how DyPlan can improve model performance by 7-13% while reducing the
cost by 11-32% relative to the best baseline model.",2024-10-30,"Tanmay Parekh, Pradyot Prakash, Alexander Radovic, Akshay Shekher, Denis Savenkov",http://arxiv.org/pdf/2410.23511v2,cs.LG
Tiny Transformers Excel at Sentence Compression,"It is staggering that words of the English language, which are on average
represented by 5--6 bytes of ASCII, require as much as 24 kilobytes when served
to large language models. We show that there is room for more information in
every token embedding. We demonstrate that 1--3-layer transformers are capable
of encoding and subsequently decoding standard English sentences into as little
as a single 3-kilobyte token. Our work implies that even small networks can
learn to construct valid English sentences and suggests the possibility of
optimising large language models by moving from sub-word token embeddings
towards larger fragments of text.",2024-10-30,"Peter Belcak, Roger Wattenhofer",http://arxiv.org/pdf/2410.23510v1,cs.LG
The Belief State Transformer,"We introduce the ""Belief State Transformer"", a next-token predictor that
takes both a prefix and suffix as inputs, with a novel objective of predicting
both the next token for the prefix and the previous token for the suffix. The
Belief State Transformer effectively learns to solve challenging problems that
conventional forward-only transformers struggle with, in a domain-independent
fashion. Key to this success is learning a compact belief state that captures
all relevant information necessary for accurate predictions. Empirical
ablations show that each component of the model is essential in difficult
scenarios where standard Transformers fall short. For the task of story writing
with known prefixes and suffixes, our approach outperforms the
Fill-in-the-Middle method for reaching known goals and demonstrates improved
performance even when the goals are unknown. Altogether, the Belief State
Transformer enables more efficient goal-conditioned decoding, better test-time
inference, and high-quality text representations on small scale problems.
Website: https://sites.google.com/view/belief-state-transformer",2024-10-30,"Edward S. Hu, Kwangjun Ahn, Qinghua Liu, Haoran Xu, Manan Tomar, Ada Langford, Dinesh Jayaraman, Alex Lamb, John Langford",http://arxiv.org/pdf/2410.23506v2,cs.LG
Development and Comparative Analysis of Machine Learning Models for Hypoxemia Severity Triage in CBRNE Emergency Scenarios Using Physiological and Demographic Data from Medical-Grade Devices,"This paper presents the development of machine learning (ML) models to
predict hypoxemia severity during emergency triage, especially in Chemical,
Biological, Radiological, Nuclear, and Explosive (CBRNE) events, using
physiological data from medical-grade sensors. Gradient Boosting Models
(XGBoost, LightGBM, CatBoost) and sequential models (LSTM, GRU) were trained on
physiological and demographic data from the MIMIC-III and IV datasets. A robust
preprocessing pipeline addressed missing data, class imbalances, and
incorporated synthetic data flagged with masks. Gradient Boosting Models (GBMs)
outperformed sequential models in terms of training speed, interpretability,
and reliability, making them well-suited for real-time decision-making. While
their performance was comparable to that of sequential models, the GBMs used
score features from six physiological variables derived from the enhanced
National Early Warning Score (NEWS) 2, which we termed NEWS2+. This approach
significantly improved prediction accuracy. While sequential models handled
temporal data well, their performance gains did not justify the higher
computational cost. A 5-minute prediction window was chosen for timely
intervention, with minute-level interpolations standardizing the data. Feature
importance analysis highlighted the significant role of mask and score features
in enhancing both transparency and performance. Temporal dependencies proved to
be less critical, as Gradient Boosting Models were able to capture key patterns
effectively without relying on them. This study highlights ML's potential to
improve triage and reduce alarm fatigue. Future work will integrate data from
multiple hospitals to enhance model generalizability across clinical settings.",2024-10-30,"Santino Nanini, Mariem Abid, Yassir Mamouni, Arnaud Wiedemann, Philippe Jouvet, Stephane Bourassa",http://arxiv.org/pdf/2410.23503v1,cs.LG
All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling,"We analyze identifiability as a possible explanation for the ubiquity of
linear properties across language models, such as the vector difference between
the representations of ""easy"" and ""easiest"" being parallel to that between
""lucky"" and ""luckiest"". For this, we ask whether finding a linear property in
one model implies that any model that induces the same distribution has that
property, too. To answer that, we first prove an identifiability result to
characterize distribution-equivalent next-token predictors, lifting a diversity
requirement of previous results. Second, based on a refinement of relational
linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how
many notions of linearity are amenable to our analysis. Finally, we show that
under suitable conditions, these linear properties either hold in all or none
distribution-equivalent next-token predictors.",2024-10-30,"Emanuele Marconato, Sébastien Lachapelle, Sebastian Weichwald, Luigi Gresele",http://arxiv.org/pdf/2410.23501v2,cs.LG
Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems,"Causal discovery with time series data remains a challenging yet increasingly
important task across many scientific domains. Convergent cross mapping (CCM)
and related methods have been proposed to study time series that are generated
by dynamical systems, where traditional approaches like Granger causality are
unreliable. However, CCM often yields inaccurate results depending upon the
quality of the data. We propose the Tangent Space Causal Inference (TSCI)
method for detecting causalities in dynamical systems. TSCI works by
considering vector fields as explicit representations of the systems' dynamics
and checks for the degree of synchronization between the learned vector fields.
The TSCI approach is model-agnostic and can be used as a drop-in replacement
for CCM and its generalizations. We first present a basic version of the TSCI
algorithm, which is shown to be more effective than the basic CCM algorithm
with very little additional computation. We additionally present augmented
versions of TSCI that leverage the expressive power of latent variable models
and deep learning. We validate our theory on standard systems, and we
demonstrate improved causal inference performance across a number of benchmark
tasks.",2024-10-30,"Kurt Butler, Daniel Waxman, Petar M. Djurić",http://arxiv.org/pdf/2410.23499v1,cs.LG
Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm,"Reinforcement learning utilizing kernel ridge regression to predict the
expected value function represents a powerful method with great
representational capacity. This setting is a highly versatile framework
amenable to analytical results. We consider kernel-based function approximation
for RL in the infinite horizon average reward setting, also referred to as the
undiscounted setting. We propose an optimistic algorithm, similar to
acquisition function based algorithms in the special case of bandits. We
establish novel no-regret performance guarantees for our algorithm, under
kernel-based modelling assumptions. Additionally, we derive a novel confidence
interval for the kernel-based prediction of the expected value function,
applicable across various RL problems.",2024-10-30,"Sattar Vakili, Julia Olkhovskaya",http://arxiv.org/pdf/2410.23498v1,cs.LG
DASH: Warm-Starting Neural Network Training in Stationary Settings without Loss of Plasticity,"Warm-starting neural network training by initializing networks with
previously learned weights is appealing, as practical neural networks are often
deployed under a continuous influx of new data. However, it often leads to loss
of plasticity, where the network loses its ability to learn new information,
resulting in worse generalization than training from scratch. This occurs even
under stationary data distributions, and its underlying mechanism is poorly
understood. We develop a framework emulating real-world neural network training
and identify noise memorization as the primary cause of plasticity loss when
warm-starting on stationary data. Motivated by this, we propose Direction-Aware
SHrinking (DASH), a method aiming to mitigate plasticity loss by selectively
forgetting memorized noise while preserving learned features. We validate our
approach on vision tasks, demonstrating improvements in test accuracy and
training efficiency.",2024-10-30,"Baekrok Shin, Junsoo Oh, Hanseul Cho, Chulhee Yun",http://arxiv.org/pdf/2410.23495v2,cs.LG
Causality-Driven Audits of Model Robustness,"Robustness audits of deep neural networks (DNN) provide a means to uncover
model sensitivities to the challenging real-world imaging conditions that
significantly degrade DNN performance in-the-wild. Such conditions are often
the result of the compounding of multiple factors inherent to the environment,
sensor, or processing pipeline and may lead to complex image distortions that
are not easily categorized. When robustness audits are limited to a set of
pre-determined imaging effects or distortions, the results cannot be (easily)
transferred to real-world conditions where image corruptions may be more
complex or nuanced. To address this challenge, we present a new alternative
robustness auditing method that uses causal inference to measure DNN
sensitivities to the factors of the imaging process that cause complex
distortions. Our approach uses causal models to explicitly encode assumptions
about the domain-relevant factors and their interactions. Then, through
extensive experiments on natural and rendered images across multiple vision
tasks, we show that our approach reliably estimates causal effects of each
factor on DNN performance using observational domain data. These causal effects
directly tie DNN sensitivities to observable properties of the imaging pipeline
in the domain of interest towards reducing the risk of unexpected DNN failures
when deployed in that domain.",2024-10-30,"Nathan Drenkow, Chris Ribaudo, Mathias Unberath",http://arxiv.org/pdf/2410.23494v1,cs.LG
Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System,"Recent approaches in machine learning often solve a task using a composition
of multiple models or agentic architectures. When targeting a composed system
with adversarial attacks, it might not be computationally or informationally
feasible to train an end-to-end proxy model or a proxy model for every
component of the system. We introduce a method to craft an adversarial attack
against the overall multi-model system when we only have a proxy model for the
final black-box model, and when the transformation applied by the initial
models can make the adversarial perturbations ineffective. Current methods
handle this by applying many copies of the first model/transformation to an
input and then re-use a standard adversarial attack by averaging gradients, or
learning a proxy model for both stages. To our knowledge, this is the first
attack specifically designed for this threat model and our method has a
substantially higher attack success rate (80% vs 25%) and contains 9.4% smaller
perturbations (MSE) compared to prior state-of-the-art methods. Our experiments
focus on a supervised image pipeline, but we are confident the attack will
generalize to other multi-model settings [e.g. a mix of open/closed source
foundation models], or agentic systems",2024-10-30,"Julian Collado, Kevin Stangl",http://arxiv.org/pdf/2410.23483v1,cs.LG
Multi-fidelity Machine Learning for Uncertainty Quantification and Optimization,"In system analysis and design optimization, multiple computational models are
typically available to represent a given physical system. These models can be
broadly classified as high-fidelity models, which provide highly accurate
predictions but require significant computational resources, and low-fidelity
models, which are computationally efficient but less accurate. Multi-fidelity
methods integrate high- and low-fidelity models to balance computational cost
and predictive accuracy. This perspective paper provides an in-depth overview
of the emerging field of machine learning-based multi-fidelity methods, with a
particular emphasis on uncertainty quantification and optimization. For
uncertainty quantification, a particular focus is on multi-fidelity graph
neural networks, compared with multi-fidelity polynomial chaos expansion. For
optimization, our emphasis is on multi-fidelity Bayesian optimization, offering
a unified perspective on multi-fidelity priors and proposing an application
strategy when the objective function is an integral or a weighted sum. We
highlight the current state of the art, identify critical gaps in the
literature, and outline key research opportunities in this evolving field.",2024-10-30,"Ruda Zhang, Negin Alemazkoor",http://arxiv.org/pdf/2410.23482v1,cs.LG
Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems,"There is an urgent need to identify both short and long-term risks from newly
emerging types of Artificial Intelligence (AI), as well as available risk
management measures. In response, and to support global efforts in regulating
AI and writing safety standards, we compile an extensive catalog of risk
sources and risk management measures for general-purpose AI (GPAI) systems,
complete with descriptions and supporting examples where relevant. This work
involves identifying technical, operational, and societal risks across model
development, training, and deployment stages, as well as surveying established
and experimental methods for managing these risks. To the best of our
knowledge, this paper is the first of its kind to provide extensive
documentation of both GPAI risk sources and risk management measures that are
descriptive, self-contained and neutral with respect to any existing regulatory
framework. This work intends to help AI providers, standards experts,
researchers, policymakers, and regulators in identifying and mitigating
systemic risks from GPAI systems. For this reason, the catalog is released
under a public domain license for ease of direct use by stakeholders in AI
governance and standards.",2024-10-30,"Rokas Gipiškis, Ayrton San Joaquin, Ze Shen Chin, Adrian Regenfuß, Ariel Gil, Koen Holtman",http://arxiv.org/pdf/2410.23472v2,cs.LG
Gradient-free training of recurrent neural networks,"Recurrent neural networks are a successful neural architecture for many
time-dependent problems, including time series analysis, forecasting, and
modeling of dynamical systems. Training such networks with backpropagation
through time is a notoriously difficult problem because their loss gradients
tend to explode or vanish. In this contribution, we introduce a computational
approach to construct all weights and biases of a recurrent neural network
without using gradient-based methods. The approach is based on a combination of
random feature networks and Koopman operator theory for dynamical systems. The
hidden parameters of a single recurrent block are sampled at random, while the
outer weights are constructed using extended dynamic mode decomposition. This
approach alleviates all problems with backpropagation commonly related to
recurrent networks. The connection to Koopman operator theory also allows us to
start using results in this area to analyze recurrent neural networks. In
computational experiments on time series, forecasting for chaotic dynamical
systems, and control problems, as well as on weather data, we observe that the
training time and forecasting accuracy of the recurrent neural networks we
construct are improved when compared to commonly used gradient-based methods.",2024-10-30,"Erik Lien Bolager, Ana Cukarska, Iryna Burak, Zahra Monfared, Felix Dietrich",http://arxiv.org/pdf/2410.23467v2,cs.LG
NMformer: A Transformer for Noisy Modulation Classification in Wireless Communication,"Modulation classification is a very challenging task since the signals
intertwine with various ambient noises. Methods are required that can classify
them without adding extra steps like denoising, which introduces computational
complexity. In this study, we propose a vision transformer (ViT) based model
named NMformer to predict the channel modulation images with different noise
levels in wireless communication. Since ViTs are most effective for RGB images,
we generated constellation diagrams from the modulated signals. The diagrams
provide the information from the signals in a 2-D representation form. We
trained NMformer on 106, 800 modulation images to build the base classifier and
only used 3, 000 images to fine-tune for specific tasks. Our proposed model has
two different kinds of prediction setups: in-distribution and
out-of-distribution. Our model achieves 4.67% higher accuracy than the base
classifier when finetuned and tested on high signal-to-noise ratios (SNRs)
in-distribution classes. Moreover, the fine-tuned low SNR task achieves a
higher accuracy than the base classifier. The fine-tuned classifier becomes
much more effective than the base classifier by achieving higher accuracy when
predicted, even on unseen data from out-of-distribution classes. Extensive
experiments show the effectiveness of NMformer for a wide range of SNRs.",2024-10-30,"Atik Faysal, Mohammad Rostami, Reihaneh Gh. Roshan, Huaxia Wang, Nikhil Muralidhar",http://arxiv.org/pdf/2411.02428v1,cs.LG
MDCure: A Scalable Pipeline for Multi-Document Instruction-Following,"Multi-document (MD) processing is crucial for LLMs to handle real-world tasks
such as summarization and question-answering across large sets of documents.
While LLMs have improved at processing long inputs, MD contexts still present
unique difficulties, including management of inter-document dependencies,
redundancy, and incoherent structures. To address this challenge, we introduce
MDCure, a scalable and effective instruction data generation framework to
enhance the MD capabilities of LLMs without the computational cost of
pre-training or reliance on human-annotated data. MDCure generates high-quality
synthetic MD instruction data over sets of articles via targeted prompts. We
also introduce MDCureRM, a cost-effective, MD-specific reward model to score
and filter generated data based on their training utility for MD settings.
MDCure is compatible with open- and closed-source models in addition to policy
optimization methods such as PPO, enabling even small open-source models to
surpass proprietary LLMs as strong generators of high-quality MD instruction
data without further data filtering. With MDCure, we fine-tune a wide variety
of LLMs up to 70B parameters in size from the FlanT5, Qwen2, and LLAMA3.1 model
families. Extensive evaluations on a wide range of MD and long-context
benchmarks spanning various tasks and domains show MDCure consistently improves
performance over pre-trained baselines and base models by up to 75.1%. Our
code, datasets, and models are available at https://github.com/yale-nlp/MDCure.",2024-10-30,"Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan",http://arxiv.org/pdf/2410.23463v3,cs.LG
Mechanistic Interpretability of Reinforcement Learning Agents,"This paper explores the mechanistic interpretability of reinforcement
learning (RL) agents through an analysis of a neural network trained on
procedural maze environments. By dissecting the network's inner workings, we
identified fundamental features like maze walls and pathways, forming the basis
of the model's decision-making process. A significant observation was the goal
misgeneralization, where the RL agent developed biases towards certain
navigation strategies, such as consistently moving towards the top right
corner, even in the absence of explicit goals. Using techniques like saliency
mapping and feature mapping, we visualized these biases. We furthered this
exploration with the development of novel tools for interactively exploring
layer activations.",2024-10-30,"Tristan Trim, Triston Grayston",http://arxiv.org/pdf/2411.00867v1,cs.LG
Transformation-Invariant Learning and Theoretical Guarantees for OOD Generalization,"Learning with identical train and test distributions has been extensively
investigated both practically and theoretically. Much remains to be understood,
however, in statistical learning under distribution shifts. This paper focuses
on a distribution shift setting where train and test distributions can be
related by classes of (data) transformation maps. We initiate a theoretical
study for this framework, investigating learning scenarios where the target
class of transformations is either known or unknown. We establish learning
rules and algorithmic reductions to Empirical Risk Minimization (ERM),
accompanied with learning guarantees. We obtain upper bounds on the sample
complexity in terms of the VC dimension of the class composing predictors with
transformations, which we show in many cases is not much larger than the VC
dimension of the class of predictors. We highlight that the learning rules we
derive offer a game-theoretic viewpoint on distribution shift: a learner
searching for predictors and an adversary searching for transformation maps to
respectively minimize and maximize the worst-case loss.",2024-10-30,"Omar Montasser, Han Shao, Emmanuel Abbe",http://arxiv.org/pdf/2410.23461v1,cs.LG
Rethinking Deep Thinking: Stable Learning of Algorithms using Lipschitz Constraints,"Iterative algorithms solve problems by taking steps until a solution is
reached. Models in the form of Deep Thinking (DT) networks have been
demonstrated to learn iterative algorithms in a way that can scale to different
sized problems at inference time using recurrent computation and convolutions.
However, they are often unstable during training, and have no guarantees of
convergence/termination at the solution. This paper addresses the problem of
instability by analyzing the growth in intermediate representations, allowing
us to build models (referred to as Deep Thinking with Lipschitz Constraints
(DT-L)) with many fewer parameters and providing more reliable solutions.
Additionally our DT-L formulation provides guarantees of convergence of the
learned iterative procedure to a unique solution at inference time. We
demonstrate DT-L is capable of robustly learning algorithms which extrapolate
to harder problems than in the training set. We benchmark on the traveling
salesperson problem to evaluate the capabilities of the modified system in an
NP-hard problem where DT fails to learn.",2024-10-30,"Jay Bear, Adam Prügel-Bennett, Jonathon Hare",http://arxiv.org/pdf/2410.23451v1,cs.LG
Return Augmented Decision Transformer for Off-Dynamics Reinforcement Learning,"We study offline off-dynamics reinforcement learning (RL) to utilize data
from an easily accessible source domain to enhance policy learning in a target
domain with limited data. Our approach centers on return-conditioned supervised
learning (RCSL), particularly focusing on the decision transformer (DT), which
can predict actions conditioned on desired return guidance and complete
trajectory history. Previous works tackle the dynamics shift problem by
augmenting the reward in the trajectory from the source domain to match the
optimal trajectory in the target domain. However, this strategy can not be
directly applicable in RCSL owing to (1) the unique form of the RCSL policy
class, which explicitly depends on the return, and (2) the absence of a
straightforward representation of the optimal trajectory distribution. We
propose the Return Augmented Decision Transformer (RADT) method, where we
augment the return in the source domain by aligning its distribution with that
in the target domain. We provide the theoretical analysis demonstrating that
the RCSL policy learned from RADT achieves the same level of suboptimality as
would be obtained without a dynamics shift. We introduce two practical
implementations RADT-DARA and RADT-MV respectively. Extensive experiments
conducted on D4RL datasets reveal that our methods generally outperform dynamic
programming based methods in off-dynamics RL scenarios.",2024-10-30,"Ruhan Wang, Yu Yang, Zhishuai Liu, Dongruo Zhou, Pan Xu",http://arxiv.org/pdf/2410.23450v1,cs.LG
Venire: A Machine Learning-Guided Panel Review System for Community Content Moderation,"Research into community content moderation often assumes that moderation
teams govern with a single, unified voice. However, recent work has found that
moderators disagree with one another at modest, but concerning rates. The
problem is not the root disagreements themselves. Subjectivity in moderation is
unavoidable, and there are clear benefits to including diverse perspectives
within a moderation team. Instead, the crux of the issue is that, due to
resource constraints, moderation decisions end up being made by individual
decision-makers. The result is decision-making that is inconsistent, which is
frustrating for community members. To address this, we develop Venire, an
ML-backed system for panel review on Reddit. Venire uses a machine learning
model trained on log data to identify the cases where moderators are most
likely to disagree. Venire fast-tracks these cases for multi-person review.
Ideally, Venire allows moderators to surface and resolve disagreements that
would have otherwise gone unnoticed. We conduct three studies through which we
design and evaluate Venire: a set of formative interviews with moderators,
technical evaluations on two datasets, and a think-aloud study in which
moderators used Venire to make decisions on real moderation cases.
Quantitatively, we demonstrate that Venire is able to improve decision
consistency and surface latent disagreements. Qualitatively, we find that
Venire helps moderators resolve difficult moderation cases more confidently.
Venire represents a novel paradigm for human-AI content moderation, and shifts
the conversation from replacing human decision-making to supporting it.",2024-10-30,"Vinay Koshy, Frederick Choi, Yi-Shyuan Chiang, Hari Sundaram, Eshwar Chandrasekharan, Karrie Karahalios",http://arxiv.org/pdf/2410.23448v1,cs.LG
Learning Lipschitz Operators with respect to Gaussian Measures with Near-Optimal Sample Complexity,"Operator learning, the approximation of mappings between infinite-dimensional
function spaces using ideas from machine learning, has gained increasing
research attention in recent years. Approximate operators, learned from data,
hold promise to serve as efficient surrogate models for problems in
computational science and engineering, complementing traditional numerical
methods. However, despite their empirical success, our understanding of the
underpinning mathematical theory is in large part still incomplete. In this
paper, we study the approximation of Lipschitz operators in expectation with
respect to Gaussian measures. We prove higher Gaussian Sobolev regularity of
Lipschitz operators and establish lower and upper bounds on the Hermite
polynomial approximation error. We further consider the reconstruction of
Lipschitz operators from $m$ arbitrary (adaptive) linear samples. A key finding
is the tight characterization of the smallest achievable error for all possible
(adaptive) sampling and reconstruction maps in terms of $m$. It is shown that
Hermite polynomial approximation is an optimal recovery strategy, but we have
the following curse of sample complexity: No method to approximate Lipschitz
operators based on $m$ samples can achieve algebraic convergence rates in $m$.
On the positive side, we prove that a sufficiently fast spectral decay of the
covariance operator of the Gaussian measure guarantees convergence rates which
are arbitrarily close to any algebraic rate in the large data limit $m \to
\infty$. A main focus of this work is on the recovery of Lipschitz operators
from finitely many point samples. We use Christoffel sampling and weighted
least-squares approximation to propose an algorithm which provably achieves
near-optimal sample complexity in high probability.",2024-10-30,"Ben Adcock, Michael Griebel, Gregor Maier",http://arxiv.org/pdf/2410.23440v2,cs.LG
Learning and Transferring Sparse Contextual Bigrams with Linear Transformers,"Transformers have excelled in natural language modeling and one reason behind
this success is their exceptional ability to combine contextual informal and
global knowledge. However, the theoretical basis remains unclear. In this
paper, first we introduce the Sparse Contextual Bigram (SCB), a natural
extension of the classical bigram model, where the next token's generation
depends on a sparse set of earlier positions determined by the last token. We
then analyze the training dynamics and sample complexity of learning SCB using
a one-layer linear transformer with a gradient-based algorithm. We show that
when trained from scratch, the training process can be split into an initial
sample-intensive stage where the correlation is boosted from zero to a
nontrivial value, followed by a more sample-efficient stage of further
improvement. Additionally, we prove that, provided a nontrivial correlation
between the downstream and pretraining tasks, finetuning from a pretrained
model allows us to bypass the initial sample-intensive stage. We also
empirically demonstrate that our algorithm can outperform SGD in this setting
and discuss its relationship with the usual softmax-based transformers.",2024-10-30,"Yunwei Ren, Zixuan Wang, Jason D. Lee",http://arxiv.org/pdf/2410.23438v1,cs.LG
Mind the Gap: A Generalized Approach for Cross-Modal Embedding Alignment,"Retrieval-Augmented Generation (RAG) systems enhance text generation by
incorporating external knowledge but often struggle when retrieving context
across different text modalities due to semantic gaps. We introduce a
generalized projection-based method, inspired by adapter modules in transfer
learning, that efficiently bridges these gaps between various text types, such
as programming code and pseudocode, or English and French sentences. Our
approach emphasizes speed, accuracy, and data efficiency, requiring minimal
resources for training and inference. By aligning embeddings from heterogeneous
text modalities into a unified space through a lightweight projection network,
our model significantly outperforms traditional retrieval methods like the
Okapi BM25 algorithm and models like Dense Passage Retrieval (DPR), while
approaching the accuracy of Sentence Transformers. Extensive evaluations
demonstrate the effectiveness and generalizability of our method across
different tasks, highlighting its potential for real-time, resource-constrained
applications.",2024-10-30,"Arihan Yadav, Alan McMillan",http://arxiv.org/pdf/2410.23437v1,cs.LG
Model-free Low-Rank Reinforcement Learning via Leveraged Entry-wise Matrix Estimation,"We consider the problem of learning an $\varepsilon$-optimal policy in
controlled dynamical systems with low-rank latent structure. For this problem,
we present LoRa-PI (Low-Rank Policy Iteration), a model-free learning algorithm
alternating between policy improvement and policy evaluation steps. In the
latter, the algorithm estimates the low-rank matrix corresponding to the
(state, action) value function of the current policy using the following
two-phase procedure. The entries of the matrix are first sampled uniformly at
random to estimate, via a spectral method, the leverage scores of its rows and
columns. These scores are then used to extract a few important rows and columns
whose entries are further sampled. The algorithm exploits these new samples to
complete the matrix estimation using a CUR-like method. For this leveraged
matrix estimation procedure, we establish entry-wise guarantees that
remarkably, do not depend on the coherence of the matrix but only on its
spikiness. These guarantees imply that LoRa-PI learns an $\varepsilon$-optimal
policy using $\widetilde{O}({S+A\over \mathrm{poly}(1-\gamma)\varepsilon^2})$
samples where $S$ (resp. $A$) denotes the number of states (resp. actions) and
$\gamma$ the discount factor. Our algorithm achieves this order-optimal (in
$S$, $A$ and $\varepsilon$) sample complexity under milder conditions than
those assumed in previously proposed approaches.",2024-10-30,"Stefan Stojanovic, Yassir Jedra, Alexandre Proutiere",http://arxiv.org/pdf/2410.23434v2,cs.LG
Assessing Concordance between RNA-Seq and NanoString Technologies in Ebola-Infected Nonhuman Primates Using Machine Learning,"This study evaluates the concordance between RNA sequencing (RNA-Seq) and
NanoString technologies for gene expression analysis in non-human primates
(NHPs) infected with Ebola virus (EBOV). We performed a detailed comparison of
both platforms, demonstrating a strong correlation between them, with Spearman
coefficients for 56 out of 62 samples ranging from 0.78 to 0.88, with a mean of
0.83 and a median of 0.85. Bland-Altman analysis further confirmed high
consistency, with most measurements falling within 95% confidence limits. A
machine learning approach, using the Supervised Magnitude-Altitude Scoring
(SMAS) method trained on NanoString data, identified OAS1 as a key marker for
distinguishing RT-qPCR positive from negative samples. Remarkably, when applied
to RNA-Seq data, OAS1 also achieved 100% accuracy in differentiating infected
from uninfected samples using logistic regression, demonstrating its robustness
across platforms. Further differential expression analysis identified 12 common
genes including ISG15, OAS1, IFI44, IFI27, IFIT2, IFIT3, IFI44L, MX1, MX2,
OAS2, RSAD2, and OASL which demonstrated the highest levels of statistical
significance and biological relevance across both platforms. Gene Ontology (GO)
analysis confirmed that these genes are directly involved in key immune and
viral infection pathways, reinforcing their importance in EBOV infection. In
addition, RNA-Seq uniquely identified genes such as CASP5, USP18, and DDX60,
which play key roles in immune regulation and antiviral defense. This finding
highlights the broader detection capabilities of RNA-Seq and underscores the
complementary strengths of both platforms in providing a comprehensive and
accurate assessment of gene expression changes during Ebola virus infection.",2024-10-30,"Mostafa Rezapour, Aarthi Narayanan, Wyatt H. Mowery, Metin Nafi Gurcan",http://arxiv.org/pdf/2410.23433v1,cs.LG
eDOC: Explainable Decoding Out-of-domain Cell Types with Evidential Learning,"Single-cell RNA-seq (scRNA-seq) technology is a powerful tool for unraveling
the complexity of biological systems. One of essential and fundamental tasks in
scRNA-seq data analysis is Cell Type Annotation (CTA). In spite of tremendous
efforts in developing machine learning methods for this problem, several
challenges remains. They include identifying Out-of-Domain (OOD) cell types,
quantifying the uncertainty of unseen cell type annotations, and determining
interpretable cell type-specific gene drivers for an OOD case. OOD cell types
are often associated with therapeutic responses and disease origins, making
them critical for precision medicine and early disease diagnosis. Additionally,
scRNA-seq data contains tens thousands of gene expressions. Pinpointing gene
drivers underlying CTA can provide deep insight into gene regulatory mechanisms
and serve as disease biomarkers. In this study, we develop a new method, eDOC,
to address aforementioned challenges. eDOC leverages a transformer architecture
with evidential learning to annotate In-Domain (IND) and OOD cell types as well
as to highlight genes that contribute both IND cells and OOD cells in a single
cell resolution. Rigorous experiments demonstrate that eDOC significantly
improves the efficiency and effectiveness of OOD cell type and gene driver
identification compared to other state-of-the-art methods. Our findings suggest
that eDOC may provide new insights into single-cell biology.",2024-10-30,"Chaochen Wu, Meiyun Zuo, Lei Xie",http://arxiv.org/pdf/2411.00054v1,cs.LG
Communication-Efficient Federated Learning over Wireless Channels via Gradient Sketching,"Large-scale federated learning (FL) over wireless multiple access channels
(MACs) has emerged as a crucial learning paradigm with a wide range of
applications. However, its widespread adoption is hindered by several major
challenges, including limited bandwidth shared by many edge devices, noisy and
erroneous wireless communications, and heterogeneous datasets with different
distributions across edge devices. To overcome these fundamental challenges, we
propose Federated Proximal Sketching (FPS), tailored towards band-limited
wireless channels and handling data heterogeneity across edge devices. FPS uses
a count sketch data structure to address the bandwidth bottleneck and enable
efficient compression while maintaining accurate estimation of significant
coordinates. Additionally, we modify the loss function in FPS such that it is
equipped to deal with varying degrees of data heterogeneity. We establish the
convergence of the FPS algorithm under mild technical conditions and
characterize how the bias induced due to factors like data heterogeneity and
noisy wireless channels play a role in the overall result. We complement the
proposed theoretical framework with numerical experiments that demonstrate the
stability, accuracy, and efficiency of FPS in comparison to state-of-the-art
methods on both synthetic and real-world datasets. Overall, our results show
that FPS is a promising solution to tackling the above challenges of FL over
wireless MACs.",2024-10-30,"Vineet Sunil Gattani, Junshan Zhang, Gautam Dasarathy",http://arxiv.org/pdf/2410.23424v1,cs.LG
Dynamic Information Sub-Selection for Decision Support,"We introduce Dynamic Information Sub-Selection (DISS), a novel framework of
AI assistance designed to enhance the performance of black-box decision-makers
by tailoring their information processing on a per-instance basis. Blackbox
decision-makers (e.g., humans or real-time systems) often face challenges in
processing all possible information at hand (e.g., due to cognitive biases or
resource constraints), which can degrade decision efficacy. DISS addresses
these challenges through policies that dynamically select the most effective
features and options to forward to the black-box decision-maker for prediction.
We develop a scalable frequentist data acquisition strategy and a
decision-maker mimicking technique for enhanced budget efficiency. We explore
several impactful applications of DISS, including biased decision-maker
support, expert assignment optimization, large language model decision support,
and interpretability. Empirical validation of our proposed DISS methodology
shows superior performance to state-of-the-art methods across various
applications.",2024-10-30,"Hung-Tien Huang, Maxwell Lennon, Shreyas Bhat Brahmavar, Sean Sylvia, Junier B. Oliva",http://arxiv.org/pdf/2410.23423v1,cs.LG
Stepping Out of the Shadows: Reinforcement Learning in Shadow Mode,"Reinforcement learning (RL) is not yet competitive for many cyber-physical
systems, such as robotics, process automation, and power systems, as training
on a system with physical components cannot be accelerated, and simulation
models do not exist or suffer from a large simulation-to-reality gap. During
the long training time, expensive equipment cannot be used and might even be
damaged due to inappropriate actions of the reinforcement learning agent. Our
novel approach addresses exactly this problem: We train the reinforcement agent
in a so-called shadow mode with the assistance of an existing conventional
controller, which does not have to be trained and instantaneously performs
reasonably well. In shadow mode, the agent relies on the controller to provide
action samples and guidance towards favourable states to learn the task, while
simultaneously estimating for which states the learned agent will receive a
higher reward than the conventional controller. The RL agent will then control
the system for these states and all other regions remain under the control of
the existing controller. Over time, the RL agent will take over for an
increasing amount of states, while leaving control to the baseline, where it
cannot surpass its performance. Thus, we keep regret during training low and
improve the performance compared to only using conventional controllers or
reinforcement learning. We present and evaluate two mechanisms for deciding
whether to use the RL agent or the conventional controller. The usefulness of
our approach is demonstrated for a reach-avoid task, for which we are able to
effectively train an agent, where standard approaches fail.",2024-10-30,"Philipp Gassert, Matthias Althoff",http://arxiv.org/pdf/2410.23419v1,cs.LG
FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions,"Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.",2024-10-30,"Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood",http://arxiv.org/pdf/2410.23405v1,cs.LG
On the Optimality of Dilated Entropy and Lower Bounds for Online Learning in Extensive-Form Games,"First-order methods (FOMs) are arguably the most scalable algorithms for
equilibrium computation in large extensive-form games. To operationalize these
methods, a distance-generating function, acting as a regularizer for the
strategy space, must be chosen. The ratio between the strong convexity modulus
and the diameter of the regularizer is a key parameter in the analysis of FOMs.
A natural question is then: what is the optimal distance-generating function
for extensive-form decision spaces? In this paper, we make a number of
contributions, ultimately establishing that the weight-one dilated entropy
(DilEnt) distance-generating function is optimal up to logarithmic factors. The
DilEnt regularizer is notable due to its iterate-equivalence with Kernelized
OMWU (KOMWU) -- the algorithm with state-of-the-art dependence on the game tree
size in extensive-form games -- when used in conjunction with the online mirror
descent (OMD) algorithm. However, the standard analysis for OMD is unable to
establish such a result; the only current analysis is by appealing to the
iterate equivalence to KOMWU. We close this gap by introducing a pair of
primal-dual treeplex norms, which we contend form the natural analytic
viewpoint for studying the strong convexity of DilEnt. Using these norm pairs,
we recover the diameter-to-strong-convexity ratio that predicts the same
performance as KOMWU. Along with a new regret lower bound for online learning
in sequence-form strategy spaces, we show that this ratio is nearly optimal.
Finally, we showcase our analytic techniques by refining the analysis of
Clairvoyant OMD when paired with DilEnt, establishing an $\mathcal{O}(n \log
|\mathcal{V}| \log T/T)$ approximation rate to coarse correlated equilibrium in
$n$-player games, where $|\mathcal{V}|$ is the number of reduced normal-form
strategies of the players, establishing the new state of the art.",2024-10-30,"Zhiyuan Fan, Christian Kroer, Gabriele Farina",http://arxiv.org/pdf/2410.23398v1,cs.LG
Adaptive Network Intervention for Complex Systems: A Hierarchical Graph Reinforcement Learning Approach,"Effective governance and steering of behavior in complex multi-agent systems
(MAS) are essential for managing system-wide outcomes, particularly in
environments where interactions are structured by dynamic networks. In many
applications, the goal is to promote pro-social behavior among agents, where
network structure plays a pivotal role in shaping these interactions. This
paper introduces a Hierarchical Graph Reinforcement Learning (HGRL) framework
that governs such systems through targeted interventions in the network
structure. Operating within the constraints of limited managerial authority,
the HGRL framework demonstrates superior performance across a range of
environmental conditions, outperforming established baseline methods. Our
findings highlight the critical influence of agent-to-agent learning (social
learning) on system behavior: under low social learning, the HGRL manager
preserves cooperation, forming robust core-periphery networks dominated by
cooperators. In contrast, high social learning accelerates defection, leading
to sparser, chain-like networks. Additionally, the study underscores the
importance of the system manager's authority level in preventing system-wide
failures, such as agent rebellion or collapse, positioning HGRL as a powerful
tool for dynamic network-based governance.",2024-10-30,"Qiliang Chen, Babak Heydari",http://arxiv.org/pdf/2410.23396v1,cs.LG
Resource Governance in Networked Systems via Integrated Variational Autoencoders and Reinforcement Learning,"We introduce a framework that integrates variational autoencoders (VAE) with
reinforcement learning (RL) to balance system performance and resource usage in
multi-agent systems by dynamically adjusting network structures over time. A
key innovation of this method is its capability to handle the vast action space
of the network structure. This is achieved by combining Variational
Auto-Encoder and Deep Reinforcement Learning to control the latent space
encoded from the network structures. The proposed method, evaluated on the
modified OpenAI particle environment under various scenarios, not only
demonstrates superior performance compared to baselines but also reveals
interesting strategies and insights through the learned behaviors.",2024-10-30,"Qiliang Chen, Babak Heydari",http://arxiv.org/pdf/2410.23393v1,cs.LG
Understanding Representation of Deep Equilibrium Models from Neural Collapse Perspective,"Deep Equilibrium Model (DEQ), which serves as a typical implicit neural
network, emphasizes their memory efficiency and competitive performance
compared to explicit neural networks. However, there has been relatively
limited theoretical analysis on the representation of DEQ. In this paper, we
utilize the Neural Collapse ($\mathcal{NC}$) as a tool to systematically
analyze the representation of DEQ under both balanced and imbalanced
conditions. $\mathcal{NC}$ is an interesting phenomenon in the neural network
training process that characterizes the geometry of class features and
classifier weights. While extensively studied in traditional explicit neural
networks, the $\mathcal{NC}$ phenomenon has not received substantial attention
in the context of implicit neural networks. We theoretically show that
$\mathcal{NC}$ exists in DEQ under balanced conditions. Moreover, in imbalanced
settings, despite the presence of minority collapse, DEQ demonstrated
advantages over explicit neural networks. These advantages include the
convergence of extracted features to the vertices of a simplex equiangular
tight frame and self-duality properties under mild conditions, highlighting
DEQ's superiority in handling imbalanced datasets. Finally, we validate our
theoretical analyses through experiments in both balanced and imbalanced
scenarios.",2024-10-30,"Haixiang Sun, Ye Shi",http://arxiv.org/pdf/2410.23391v2,cs.LG
Ensemble learning of the atrial fiber orientation with physics-informed neural networks,"The anisotropic structure of the myocardium is a key determinant of the
cardiac function. To date, there is no imaging modality to assess in-vivo the
cardiac fiber structure. We recently proposed Fibernet, a method for the
automatic identification of the anisotropic conduction -- and thus fibers -- in
the atria from local electrical recordings. Fibernet uses cardiac activation as
recorded during electroanatomical mappings to infer local conduction properties
using physics-informed neural networks. In this work, we extend Fibernet to
cope with the uncertainty in the estimated fiber field. Specifically, we use an
ensemble of neural networks to produce multiple samples, all fitting the
observed data, and compute posterior statistics. We also introduce a
methodology to select the best fiber orientation members and define the input
of the neural networks directly on the atrial surface. With these improvements,
we outperform the previous methodology in terms of fiber orientation error in 8
different atrial anatomies. Currently, our approach can estimate the fiber
orientation and conduction velocities in under 7 minutes with quantified
uncertainty, which opens the door to its application in clinical practice. We
hope the proposed methodology will enable further personalization of cardiac
digital twins for precision medicine.",2024-10-30,"Efraín Magaña, Simone Pezzuto, Francisco Sahli Costabal",http://arxiv.org/pdf/2410.23388v1,cs.LG
STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG,"Magnetoencephalography (MEG) allows the non-invasive detection of interictal
epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients
traditionally relies on the visual identification of IEDs, which is time
consuming and partially subjective. Automatic, data-driven detection methods
exist but show limited performance. Still, the rise of deep learning (DL)-with
its ability to reproduce human-like abilities-could revolutionize clinical MEG
practice. Here, we developed and validated STIED, a simple yet powerful
supervised DL algorithm combining two convolutional neural networks with
temporal (1D time-course) and spatial (2D topography) features of MEG signals
inspired from current clinical guidelines. Our DL model enabled both temporal
and spatial localization of IEDs in patients suffering from focal epilepsy with
frequent and high amplitude spikes (FE group), with high-performance
metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning
from spatiotemporal features of IEDs. This performance can be attributed to our
handling of input data, which mimics established clinical MEG practice. Reverse
engineering further revealed that STIED encodes fine spatiotemporal features of
IEDs rather than their mere amplitude. The model trained on the FE group also
showed promising results when applied to a separate group of presurgical
patients with different types of refractory focal epilepsy, though further work
is needed to distinguish IEDs from physiological transients. This study paves
the way of incorporating STIED and DL algorithms into the routine clinical MEG
evaluation of epilepsy.",2024-10-30,"Raquel Fernández-Martín, Alfonso Gijón, Odile Feys, Elodie Juvené, Alec Aeby, Charline Urbain, Xavier De Tiège, Vincent Wens",http://arxiv.org/pdf/2410.23386v1,cs.LG
Estimating Neural Network Robustness via Lipschitz Constant and Architecture Sensitivity,"Ensuring neural network robustness is essential for the safe and reliable
operation of robotic learning systems, especially in perception and
decision-making tasks within real-world environments. This paper investigates
the robustness of neural networks in perception systems, specifically examining
their sensitivity to targeted, small-scale perturbations. We identify the
Lipschitz constant as a key metric for quantifying and enhancing network
robustness. We derive an analytical expression to compute the Lipschitz
constant based on neural network architecture, providing a theoretical basis
for estimating and improving robustness. Several experiments reveal the
relationship between network design, the Lipschitz constant, and robustness,
offering practical insights for developing safer, more robust robot learning
systems.",2024-10-30,"Abulikemu Abuduweili, Changliu Liu",http://arxiv.org/pdf/2410.23382v1,cs.LG
Advancing Crime Linkage Analysis with Machine Learning: A Comprehensive Review and Framework for Data-Driven Approaches,"Crime linkage is the process of analyzing criminal behavior data to determine
whether a pair or group of crime cases are connected or belong to a series of
offenses. This domain has been extensively studied by researchers in sociology,
psychology, and statistics. More recently, it has drawn interest from computer
scientists, especially with advances in artificial intelligence. Despite this,
the literature indicates that work in this latter discipline is still in its
early stages. This study aims to understand the challenges faced by machine
learning approaches in crime linkage and to support foundational knowledge for
future data-driven methods. To achieve this goal, we conducted a comprehensive
survey of the main literature on the topic and developed a general framework
for crime linkage processes, thoroughly describing each step. Our goal was to
unify insights from diverse fields into a shared terminology to enhance the
research landscape for those intrigued by this subject.",2024-10-30,"Vinicius Lima, Umit Karabiyik",http://arxiv.org/pdf/2411.00864v1,cs.LG
Non-binary artificial neuron with phase variation implemented on a quantum computer,"The first artificial quantum neuron models followed a similar path to classic
models, as they work only with discrete values. Here we introduce an algorithm
that generalizes the binary model manipulating the phase of complex numbers. We
propose, test, and implement a neuron model that works with continuous values
in a quantum computer. Through simulations, we demonstrate that our model may
work in a hybrid training scheme utilizing gradient descent as a learning
algorithm. This work represents another step in the direction of evaluation of
the use of artificial neural networks efficiently implemented on near-term
quantum devices.",2024-10-30,"Jhordan Silveira de Borba, Jonas Maziero",http://arxiv.org/pdf/2410.23373v1,cs.LG
Tightening convex relaxations of trained neural networks: a unified approach for convex and S-shaped activations,"The non-convex nature of trained neural networks has created significant
obstacles in their incorporation into optimization models. Considering the wide
array of applications that this embedding has, the optimization and deep
learning communities have dedicated significant efforts to the convexification
of trained neural networks. Many approaches to date have considered obtaining
convex relaxations for each non-linear activation in isolation, which poses
limitations in the tightness of the relaxations. Anderson et al. (2020)
strengthened these relaxations and provided a framework to obtain the convex
hull of the graph of a piecewise linear convex activation composed with an
affine function; this effectively convexifies activations such as the ReLU
together with the affine transformation that precedes it. In this article, we
contribute to this line of work by developing a recursive formula that yields a
tight convexification for the composition of an activation with an affine
function for a wide scope of activation functions, namely, convex or
``S-shaped"". Our approach can be used to efficiently compute separating
hyperplanes or determine that none exists in various settings, including
non-polyhedral cases. We provide computational experiments to test the
empirical benefits of these convex approximations.",2024-10-30,"Pablo Carrasco, Gonzalo Muñoz",http://arxiv.org/pdf/2410.23362v1,cs.LG
Domain-decomposed image classification algorithms using linear discriminant analysis and convolutional neural networks,"In many modern computer application problems, the classification of image
data plays an important role. Among many different supervised machine learning
models, convolutional neural networks (CNNs) and linear discriminant analysis
(LDA) as well as sophisticated variants thereof are popular techniques. In this
work, two different domain decomposed CNN models are experimentally compared
for different image classification problems. Both models are loosely inspired
by domain decomposition methods and in addition, combined with a transfer
learning strategy. The resulting models show improved classification accuracies
compared to the corresponding, composed global CNN model without transfer
learning and besides, also help to speed up the training process. Moreover, a
novel decomposed LDA strategy is proposed which also relies on a localization
approach and which is combined with a small neural network model. In comparison
with a global LDA applied to the entire input data, the presented decomposed
LDA approach shows increased classification accuracies for the considered test
problems.",2024-10-30,"Axel Klawonn, Martin Lanser, Janine Weber",http://arxiv.org/pdf/2410.23359v1,cs.LG
Sequential Order-Robust Mamba for Time Series Forecasting,"Mamba has recently emerged as a promising alternative to Transformers,
offering near-linear complexity in processing sequential data. However, while
channels in time series (TS) data have no specific order in general, recent
studies have adopted Mamba to capture channel dependencies (CD) in TS,
introducing a sequential order bias. To address this issue, we propose
SOR-Mamba, a TS forecasting method that 1) incorporates a regularization
strategy to minimize the discrepancy between two embedding vectors generated
from data with reversed channel orders, thereby enhancing robustness to channel
order, and 2) eliminates the 1D-convolution originally designed to capture
local information in sequential data. Furthermore, we introduce channel
correlation modeling (CCM), a pretraining task aimed at preserving correlations
between channels from the data space to the latent space in order to enhance
the ability to capture CD. Extensive experiments demonstrate the efficacy of
the proposed method across standard and transfer learning scenarios. Code is
available at https://github.com/seunghan96/SOR-Mamba.",2024-10-30,"Seunghan Lee, Juri Hong, Kibok Lee, Taeyoung Park",http://arxiv.org/pdf/2410.23356v1,cs.LG
Random Heterogeneous Neurochaos Learning Architecture for Data Classification,"Inspired by the human brain's structure and function, Artificial Neural
Networks (ANN) were developed for data classification. However, existing Neural
Networks, including Deep Neural Networks, do not mimic the brain's rich
structure. They lack key features such as randomness and neuron heterogeneity,
which are inherently chaotic in their firing behavior. Neurochaos Learning
(NL), a chaos-based neural network, recently employed one-dimensional chaotic
maps like Generalized L\""uroth Series (GLS) and Logistic map as neurons. For
the first time, we propose a random heterogeneous extension of NL, where
various chaotic neurons are randomly placed in the input layer, mimicking the
randomness and heterogeneous nature of human brain networks. We evaluated the
performance of the newly proposed Random Heterogeneous Neurochaos Learning
(RHNL) architectures combined with traditional Machine Learning (ML) methods.
On public datasets, RHNL outperformed both homogeneous NL and fixed
heterogeneous NL architectures in nearly all classification tasks. RHNL
achieved high F1 scores on the Wine dataset (1.0), Bank Note Authentication
dataset (0.99), Breast Cancer Wisconsin dataset (0.99), and Free Spoken Digit
Dataset (FSDD) (0.98). These RHNL results are among the best in the literature
for these datasets. We investigated RHNL performance on image datasets, where
it outperformed stand-alone ML classifiers. In low training sample regimes,
RHNL was the best among stand-alone ML. Our architecture bridges the gap
between existing ANN architectures and the human brain's chaotic, random, and
heterogeneous properties. We foresee the development of several novel learning
algorithms centered around Random Heterogeneous Neurochaos Learning in the
coming days.",2024-10-30,"Remya Ajai A S, Nithin Nagaraj",http://arxiv.org/pdf/2410.23351v1,cs.LG
ASURA-FDPS-ML: Star-by-star Galaxy Simulations Accelerated by Surrogate Modeling for Supernova Feedback,"We introduce new high-resolution galaxy simulations accelerated by a
surrogate model that reduces the computation cost by approximately 75 percent.
Massive stars with a Zero Age Main Sequence mass of more than about 10
$\mathrm{M_\odot}$ explode as core-collapse supernovae (CCSNe), which play a
critical role in galaxy formation. The energy released by CCSNe is essential
for regulating star formation and driving feedback processes in the
interstellar medium (ISM). However, the short integration timesteps required
for SNe feedback have presented significant bottlenecks in astrophysical
simulations across various scales. Overcoming this challenge is crucial for
enabling star-by-star galaxy simulations, which aim to capture the dynamics of
individual stars and the inhomogeneous shell's expansion within the turbulent
ISM. To address this, our new framework combines direct numerical simulations
and surrogate modeling, including machine learning and Gibbs sampling. The star
formation history and the time evolution of outflow rates in the galaxy match
those obtained from resolved direct numerical simulations. Our new approach
achieves high-resolution fidelity while reducing computational costs,
effectively bridging the physical scale gap and enabling multi-scale
simulations.",2024-10-30,"Keiya Hirashima, Kana Moriwaki, Michiko S. Fujii, Yutaka Hirai, Takayuki R. Saitoh, Junnichiro Makino, Ulrich P. Steinwandel, Shirley Ho",http://arxiv.org/pdf/2410.23346v2,cs.LG
MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts,"Text-to-image diffusion has attracted vast attention due to its impressive
image-generation capabilities. However, when it comes to human-centric
text-to-image generation, particularly in the context of faces and hands, the
results often fall short of naturalness due to insufficient training priors. We
alleviate the issue in this work from two perspectives. 1) From the data
aspect, we carefully collect a human-centric dataset comprising over one
million high-quality human-in-the-scene images and two specific sets of
close-up images of faces and hands. These datasets collectively provide a rich
prior knowledge base to enhance the human-centric image generation capabilities
of the diffusion model. 2) On the methodological front, we propose a simple yet
effective method called Mixture of Low-rank Experts (MoLE) by considering
low-rank modules trained on close-up hand and face images respectively as
experts. This concept draws inspiration from our observation of low-rank
refinement, where a low-rank module trained by a customized close-up dataset
has the potential to enhance the corresponding image part when applied at an
appropriate scale. To validate the superiority of MoLE in the context of
human-centric image generation compared to state-of-the-art, we construct two
benchmarks and perform evaluations with diverse metrics and human studies.
Datasets, model, and code are released at
https://sites.google.com/view/mole4diffuser/.",2024-10-30,"Jie Zhu, Yixiong Chen, Mingyu Ding, Ping Luo, Leye Wang, Jingdong Wang",http://arxiv.org/pdf/2410.23332v1,cs.LG
Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards,"Training robots directly from human videos is an emerging area in robotics
and computer vision. While there has been notable progress with two-fingered
grippers, learning autonomous tasks for multi-fingered robot hands in this way
remains challenging. A key reason for this difficulty is that a policy trained
on human hands may not directly transfer to a robot hand due to morphology
differences. In this work, we present HuDOR, a technique that enables online
fine-tuning of policies by directly computing rewards from human videos.
Importantly, this reward function is built using object-oriented trajectories
derived from off-the-shelf point trackers, providing meaningful learning
signals despite the morphology gap and visual differences between human and
robot hands. Given a single video of a human solving a task, such as gently
opening a music box, HuDOR enables our four-fingered Allegro hand to learn the
task with just an hour of online interaction. Our experiments across four tasks
show that HuDOR achieves a 4x improvement over baselines. Code and videos are
available on our website, https://object-rewards.github.io.",2024-10-30,"Irmak Guzey, Yinlong Dai, Georgy Savva, Raunaq Bhirangi, Lerrel Pinto",http://arxiv.org/pdf/2410.23289v1,cs.LG
Provable Acceleration for Diffusion Models under Minimal Assumptions,"Score-based diffusion models, while achieving minimax optimality for
sampling, are often hampered by slow sampling speeds due to the high
computational burden of score function evaluations. Despite the recent
remarkable empirical advances in speeding up the score-based samplers,
theoretical understanding of acceleration techniques remains largely limited.
To bridge this gap, we propose a novel training-free acceleration scheme for
stochastic samplers. Under minimal assumptions -- namely, $L^2$-accurate score
estimates and a finite second-moment condition on the target distribution --
our accelerated sampler provably achieves $\varepsilon$-accuracy in total
variation within $\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations,
thereby significantly improving upon the $\widetilde{O}(d/\varepsilon)$
iteration complexity of standard score-based samplers for $\varepsilon\leq
1/\sqrt{d}$. Notably, our convergence theory does not rely on restrictive
assumptions on the target distribution or higher-order score estimation
guarantees.",2024-10-30,"Gen Li, Changxiao Cai",http://arxiv.org/pdf/2410.23285v3,cs.LG
SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation,"Human beings are endowed with a complementary learning system, which bridges
the slow learning of general world dynamics with fast storage of episodic
memory from a new experience. Previous video generation models, however,
primarily focus on slow learning by pre-training on vast amounts of data,
overlooking the fast learning phase crucial for episodic memory storage. This
oversight leads to inconsistencies across temporally distant frames when
generating longer videos, as these frames fall beyond the model's context
window. To this end, we introduce SlowFast-VGen, a novel dual-speed learning
system for action-driven long video generation. Our approach incorporates a
masked conditional video diffusion model for the slow learning of world
dynamics, alongside an inference-time fast learning strategy based on a
temporal LoRA module. Specifically, the fast learning process updates its
temporal LoRA parameters based on local inputs and outputs, thereby efficiently
storing episodic memory in its parameters. We further propose a slow-fast
learning loop algorithm that seamlessly integrates the inner fast learning loop
into the outer slow learning loop, enabling the recall of prior multi-episode
experiences for context-aware skill learning. To facilitate the slow learning
of an approximate world model, we collect a large-scale dataset of 200k videos
with language action annotations, covering a wide range of scenarios. Extensive
experiments show that SlowFast-VGen outperforms baselines across various
metrics for action-driven video generation, achieving an FVD score of 514
compared to 782, and maintaining consistency in longer videos, with an average
of 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm
significantly enhances performances on long-horizon planning tasks as well.
Project Website: https://slowfast-vgen.github.io",2024-10-30,"Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Linjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang",http://arxiv.org/pdf/2410.23277v2,cs.LG
Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks,"We introduce a novel Dynamic Graph Neural Network (DGNN) architecture for
solving conditional $m$-steps ahead forecasting problems in temporal financial
networks. The proposed DGNN is validated on simulated data from a temporal
financial network model capturing stylized features of Interest Rate Swaps
(IRSs) transaction networks, where financial entities trade swap contracts
dynamically and the network topology evolves conditionally on a reference rate.
The proposed model is able to produce accurate conditional forecasts of net
variation margins up to a $21$-day horizon by leveraging conditional
information under pre-determined stress test scenarios. Our work shows that the
network dynamics can be successfully incorporated into stress-testing
practices, thus providing regulators and policymakers with a crucial tool for
systemic risk monitoring.",2024-10-30,"Matteo Citterio, Marco D'Errico, Gabriele Visentin",http://arxiv.org/pdf/2410.23275v1,cs.LG
Multi-student Diffusion Distillation for Better One-step Generators,"Diffusion models achieve high-quality sample generation at the cost of a
lengthy multistep inference procedure. To overcome this, diffusion distillation
techniques produce student generators capable of matching or surpassing the
teacher in a single step. However, the student model's inference speed is
limited by the size of the teacher architecture, preventing real-time
generation for computationally heavy applications. In this work, we introduce
Multi-Student Distillation (MSD), a framework to distill a conditional teacher
diffusion model into multiple single-step generators. Each student generator is
responsible for a subset of the conditioning data, thereby obtaining higher
generation quality for the same capacity. MSD trains multiple distilled
students, allowing smaller sizes and, therefore, faster inference. Also, MSD
offers a lightweight quality boost over single-student distillation with the
same architecture. We demonstrate MSD is effective by training multiple
same-sized or smaller students on single-step distillation using distribution
matching and adversarial distillation techniques. With smaller students, MSD
gets competitive results with faster inference for single-step generation.
Using 4 same-sized students, MSD significantly outperforms single-student
baseline counterparts and achieves remarkable FID scores for one-step image
generation: 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.",2024-10-30,"Yanke Song, Jonathan Lorraine, Weili Nie, Karsten Kreis, James Lucas",http://arxiv.org/pdf/2410.23274v2,cs.LG
Proportional Fairness in Non-Centroid Clustering,"We revisit the recently developed framework of proportionally fair
clustering, where the goal is to provide group fairness guarantees that become
stronger for groups of data points (agents) that are large and cohesive. Prior
work applies this framework to centroid clustering, where the loss of an agent
is its distance to the centroid assigned to its cluster. We expand the
framework to non-centroid clustering, where the loss of an agent is a function
of the other agents in its cluster, by adapting two proportional fairness
criteria -- the core and its relaxation, fully justified representation (FJR)
-- to this setting.
  We show that the core can be approximated only under structured loss
functions, and even then, the best approximation we are able to establish,
using an adaptation of the GreedyCapture algorithm developed for centroid
clustering [Chen et al., 2019; Micha and Shah, 2020], is unappealing for a
natural loss function. In contrast, we design a new (inefficient) algorithm,
GreedyCohesiveClustering, which achieves the relaxation FJR exactly under
arbitrary loss functions, and show that the efficient GreedyCapture algorithm
achieves a constant approximation of FJR. We also design an efficient auditing
algorithm, which estimates the FJR approximation of any given clustering
solution up to a constant factor. Our experiments on real data suggest that
traditional clustering algorithms are highly unfair, whereas GreedyCapture is
considerably fairer and incurs only a modest loss in common clustering
objectives.",2024-10-30,"Ioannis Caragiannis, Evi Micha, Nisarg Shah",http://arxiv.org/pdf/2410.23273v1,cs.LG
A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction,"Probabilistic prediction of sequences from images and other high-dimensional
data is a key challenge, particularly in risk-sensitive applications. In these
settings, it is often desirable to quantify the uncertainty associated with the
prediction (instead of just determining the most likely sequence, as in
language modeling). In this paper, we propose a Monte Carlo framework to
estimate probabilities and confidence intervals associated with the
distribution of a discrete sequence. Our framework uses a Monte Carlo
simulator, implemented as an autoregressively trained neural network, to sample
sequences conditioned on an image input. We then use these samples to estimate
the probabilities and confidence intervals. Experiments on synthetic and real
data show that the framework produces accurate discriminative predictions, but
can suffer from miscalibration. In order to address this shortcoming, we
propose a time-dependent regularization method, which is shown to produce
calibrated predictions.",2024-10-30,"Qidong Yang, Weicheng Zhu, Joseph Keslin, Laure Zanna, Tim G. J. Rudner, Carlos Fernandez-Granda",http://arxiv.org/pdf/2410.23272v1,cs.LG
CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP,"Machine unlearning (MU) has gained significant attention as a means to remove
specific data from trained models without requiring a full retraining process.
While progress has been made in unimodal domains like text and image
classification, unlearning in multimodal models remains relatively
underexplored. In this work, we address the unique challenges of unlearning in
CLIP, a prominent multimodal model that aligns visual and textual
representations. We introduce CLIPErase, a novel approach that disentangles and
selectively forgets both visual and textual associations, ensuring that
unlearning does not compromise model performance. CLIPErase consists of three
key modules: a Forgetting Module that disrupts the associations in the forget
set, a Retention Module that preserves performance on the retain set, and a
Consistency Module that maintains consistency with the original model.
Extensive experiments on the CIFAR-100 and Flickr30K datasets across four CLIP
downstream tasks demonstrate that CLIPErase effectively forgets designated
associations in zero-shot tasks for multimodal samples, while preserving the
model's performance on the retain set after unlearning.",2024-10-30,"Tianyu Yang, Lisen Dai, Zheyuan Liu, Xiangqi Wang, Meng Jiang, Yapeng Tian, Xiangliang Zhang",http://arxiv.org/pdf/2410.23330v1,cs.LG
EMMA: End-to-End Multimodal Model for Autonomous Driving,"We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.",2024-10-30,"Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan",http://arxiv.org/pdf/2410.23262v2,cs.LG
$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources,"Pre-training is notoriously compute-intensive and academic researchers are
notoriously under-resourced. It is, therefore, commonly assumed that academics
can't pre-train models. In this paper, we seek to clarify this assumption. We
first survey academic researchers to learn about their available compute and
then empirically measure the time to replicate models on such resources. We
introduce a benchmark to measure the time to pre-train models on given GPUs and
also identify ideal settings for maximizing training speed. We run our
benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on
our experiments. Our results reveal a brighter picture for academic
pre-training: for example, although Pythia-1B was originally trained on 64 GPUs
for 3 days, we find it is also possible to replicate this model (with the same
hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We conclude
with a cost-benefit analysis to help clarify the trade-offs between price and
pre-training time. We believe our benchmark will help academic researchers
conduct experiments that require training larger models on more data. We fully
release our codebase at: https://github.com/apoorvkh/academic-pretraining.",2024-10-30,"Apoorv Khandelwal, Tian Yun, Nihal V. Nayak, Jack Merullo, Stephen H. Bach, Chen Sun, Ellie Pavlick",http://arxiv.org/pdf/2410.23261v1,cs.LG
bit2bit: 1-bit quanta video reconstruction via self-supervised photon prediction,"Quanta image sensors, such as SPAD arrays, are an emerging sensor technology,
producing 1-bit arrays representing photon detection events over exposures as
short as a few nanoseconds. In practice, raw data are post-processed using
heavy spatiotemporal binning to create more useful and interpretable images at
the cost of degrading spatiotemporal resolution. In this work, we propose
bit2bit, a new method for reconstructing high-quality image stacks at the
original spatiotemporal resolution from sparse binary quanta image data.
Inspired by recent work on Poisson denoising, we developed an algorithm that
creates a dense image sequence from sparse binary photon data by predicting the
photon arrival location probability distribution. However, due to the binary
nature of the data, we show that the assumption of a Poisson distribution is
inadequate. Instead, we model the process with a Bernoulli lattice process from
the truncated Poisson. This leads to the proposal of a novel self-supervised
solution based on a masked loss function. We evaluate our method using both
simulated and real data. On simulated data from a conventional video, we
achieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06
photons per pixel per frame). We also present a novel dataset containing a wide
range of real SPAD high-speed videos under various challenging imaging
conditions. The scenes cover strong/weak ambient light, strong motion,
ultra-fast events, etc., which will be made available to the community, on
which we demonstrate the promise of our approach. Both reconstruction quality
and throughput substantially surpass the state-of-the-art methods (e.g., Quanta
Burst Photography (QBP)). Our approach significantly enhances the visualization
and usability of the data, enabling the application of existing analysis
techniques.",2024-10-30,"Yehe Liu, Alexander Krull, Hector Basevi, Ales Leonardis, Michael W. Jenkins",http://arxiv.org/pdf/2410.23247v3,cs.LG
Very fast Bayesian Additive Regression Trees on GPU,"Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian
regression technique based on an ensemble of decision trees. It is part of the
toolbox of many statisticians. The overall statistical quality of the
regression is typically higher than other generic alternatives, and it requires
less manual tuning, making it a good default choice. However, it is a niche
method compared to its natural competitor XGBoost, due to the longer running
time, making sample sizes above 10,000-100,000 a nuisance. I present a
GPU-enabled implementation of BART, faster by up to 200x relative to a single
CPU core, making BART competitive in running time with XGBoost. This
implementation is available in the Python package bartz.",2024-10-30,Giacomo Petrillo,http://arxiv.org/pdf/2410.23244v1,cs.LG
Full-waveform earthquake source inversion using simulation-based inference,"This paper presents a novel framework for full-waveform seismic source
inversion using simulation-based inference (SBI). Traditional probabilistic
approaches often rely on simplifying assumptions about data errors, which we
show can lead to inaccurate uncertainty quantification. SBI addresses this
limitation by building an empirical probabilistic model of the data errors
using machine learning models, known as neural density estimators, which can
then be integrated into the Bayesian inference framework. We apply the SBI
framework to point-source moment tensor inversions as well as joint moment
tensor and time-location inversions. We construct a range of synthetic examples
to explore the quality of the SBI solutions, as well as to compare the SBI
results with standard Gaussian likelihood-based Bayesian inversions. We then
demonstrate that under real seismic noise, common Gaussian likelihood
assumptions for treating full-waveform data yield overconfident posterior
distributions that underestimate the moment tensor component uncertainties by
up to a factor of 3. We contrast this with SBI, which produces well-calibrated
posteriors that generally agree with the true seismic source parameters, and
offers an order-of-magnitude reduction in the number of simulations required to
perform inference compared to standard Monte Carlo techniques. Finally, we
apply our methodology to a pair of moderate magnitude earthquakes in the North
Atlantic. We utilise seismic waveforms recorded by the recent UPFLOW ocean
bottom seismometer array as well as by regional land stations in the Azores,
comparing full moment tensor and source-time location posteriors between SBI
and a Gaussian likelihood approach. We find that our adaptation of SBI can be
directly applied to real earthquake sources to efficiently produce high quality
posterior distributions that significantly improve upon Gaussian likelihood
approaches.",2024-10-30,"A. A. Saoulis, D. Piras, A. Spurio Mancini, B. Joachimi, A. M. G. Ferreira",http://arxiv.org/pdf/2410.23238v2,cs.LG
Attribute-to-Delete: Machine Unlearning via Datamodel Matching,"Machine unlearning -- efficiently removing the effect of a small ""forget set""
of training data on a pre-trained machine learning model -- has recently
attracted significant research interest. Despite this interest, however, recent
work shows that existing machine unlearning techniques do not hold up to
thorough evaluation in non-convex settings. In this work, we introduce a new
machine unlearning technique that exhibits strong empirical performance even in
such challenging settings. Our starting point is the perspective that the goal
of unlearning is to produce a model whose outputs are statistically
indistinguishable from those of a model re-trained on all but the forget set.
This perspective naturally suggests a reduction from the unlearning problem to
that of data attribution, where the goal is to predict the effect of changing
the training set on a model's outputs. Thus motivated, we propose the following
meta-algorithm, which we call Datamodel Matching (DMM): given a trained model,
we (a) use data attribution to predict the output of the model if it were
re-trained on all but the forget set points; then (b) fine-tune the pre-trained
model to match these predicted outputs. In a simple convex setting, we show how
this approach provably outperforms a variety of iterative unlearning
algorithms. Empirically, we use a combination of existing evaluations and a new
metric based on the KL-divergence to show that even in non-convex settings, DMM
achieves strong unlearning performance relative to existing algorithms. An
added benefit of DMM is that it is a meta-algorithm, in the sense that future
advances in data attribution translate directly into better unlearning
algorithms, pointing to a clear direction for future progress in unlearning.",2024-10-30,"Kristian Georgiev, Roy Rinberg, Sung Min Park, Shivam Garg, Andrew Ilyas, Aleksander Madry, Seth Neel",http://arxiv.org/pdf/2410.23232v2,cs.LG
Aligning Audio-Visual Joint Representations with an Agentic Workflow,"Visual content and accompanied audio signals naturally formulate a joint
representation to improve audio-visual (AV) related applications. While studies
develop various AV representation learning frameworks, the importance of AV
data alignment is usually undermined for achieving high-quality representation.
We observe that an audio signal may contain background noise interference.
Also, non-synchronization may appear between audio and video streams. These
non-strict data alignment limits representation quality and downgrade
application performance. In this paper, we propose to improve AV joint
representations from a data-centric perspective by aligning audio signals to
visual data. Our alignment is conducted in an agentic workflow controlled by an
LLM-based assistant named AVAgent. For each input AV data pair, our AVAgent
uses a multi-modal LLM to convert audio and visual data into language
descriptions separately (i.e., tool use). Then, AVAgent reasons whether this
paired data is aligned well and plans to edit the audio signal if needed (i.e.,
planning). The audio editing is executed by predefined actions that filter
noise or augment data. Moreover, we use a VLM to evaluate how modified audio
signals match the visual content and provide feedback to AVAgent (i.e.,
reflection). The tool use, planning, and reflection steps operate cyclically to
become an agentic workflow where audio signals are gradually aligned to visual
content. To this end, existing methods can directly leverage the aligned AV
data via our agentic workflow to improve AV joint representations. The
experimental results comprehensively demonstrate the state-of-the-art
performance of the proposed approach against previous baselines in diverse
downstream tasks.",2024-10-30,"Shentong Mo, Yibing Song",http://arxiv.org/pdf/2410.23230v2,cs.LG
Emergence of meta-stable clustering in mean-field transformer models,"We model the evolution of tokens within a deep stack of Transformer layers as
a continuous-time flow on the unit sphere, governed by a mean-field interacting
particle system, building on the framework introduced in (Geshkovski et al.,
2023). Studying the corresponding mean-field Partial Differential Equation
(PDE), which can be interpreted as a Wasserstein gradient flow, in this paper
we provide a mathematical investigation of the long-term behavior of this
system, with a particular focus on the emergence and persistence of meta-stable
phases and clustering phenomena, key elements in applications like next-token
prediction. More specifically, we perform a perturbative analysis of the
mean-field PDE around the iid uniform initialization and prove that, in the
limit of large number of tokens, the model remains close to a meta-stable
manifold of solutions with a given structure (e.g., periodicity). Further, the
structure characterizing the meta-stable manifold is explicitly identified, as
a function of the inverse temperature parameter of the model, by the index
maximizing a certain rescaling of Gegenbauer polynomials.",2024-10-30,"Giuseppe Bruno, Federico Pasqualotto, Andrea Agazzi",http://arxiv.org/pdf/2410.23228v2,cs.LG
(FL)$^2$: Overcoming Few Labels in Federated Semi-Supervised Learning,"Federated Learning (FL) is a distributed machine learning framework that
trains accurate global models while preserving clients' privacy-sensitive data.
However, most FL approaches assume that clients possess labeled data, which is
often not the case in practice. Federated Semi-Supervised Learning (FSSL)
addresses this label deficiency problem, targeting situations where only the
server has a small amount of labeled data while clients do not. However, a
significant performance gap exists between Centralized Semi-Supervised Learning
(SSL) and FSSL. This gap arises from confirmation bias, which is more
pronounced in FSSL due to multiple local training epochs and the separation of
labeled and unlabeled data. We propose $(FL)^2$, a robust training method for
unlabeled clients using sharpness-aware consistency regularization. We show
that regularizing the original pseudo-labeling loss is suboptimal, and hence we
carefully select unlabeled samples for regularization. We further introduce
client-specific adaptive thresholding and learning status-aware aggregation to
adjust the training process based on the learning progress of each client. Our
experiments on three benchmark datasets demonstrate that our approach
significantly improves performance and bridges the gap with SSL, particularly
in scenarios with scarce labeled data.",2024-10-30,"Seungjoo Lee, Thanh-Long V. Le, Jaemin Shin, Sung-Ju Lee",http://arxiv.org/pdf/2410.23227v2,cs.LG
COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences,"Many alignment methods, including reinforcement learning from human feedback
(RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to
capture the full range of general human preferences. To achieve robust
alignment with general preferences, we model the alignment problem as a
two-player zero-sum game, where the Nash equilibrium policy guarantees a 50%
win rate against any competing policy. However, previous algorithms for finding
the Nash policy either diverge or converge to a Nash policy in a modified game,
even in a simple synthetic setting, thereby failing to maintain the 50% win
rate guarantee against all other policies. We propose a meta-algorithm,
Convergent Meta Alignment Algorithm (COMAL), for language model alignment with
general preferences, inspired by convergent algorithms in game theory.
Theoretically, we prove that our meta-algorithm converges to an exact Nash
policy in the last iterate. Additionally, our meta-algorithm is simple and can
be integrated with many existing methods designed for RLHF and preference
optimization with minimal changes. Experimental results demonstrate the
effectiveness of the proposed framework when combined with existing preference
policy optimization methods.",2024-10-30,"Yixin Liu, Argyris Oikonomou, Weiqiang Zheng, Yang Cai, Arman Cohan",http://arxiv.org/pdf/2410.23223v1,cs.LG
Partial Channel Dependence with Channel Masks for Time Series Foundation Models,"Recent advancements in foundation models have been successfully extended to
the time series (TS) domain, facilitated by the emergence of large-scale TS
datasets. However, previous efforts have primarily focused on designing model
architectures to address explicit heterogeneity among datasets such as various
numbers of channels, while often overlooking implicit heterogeneity such as
varying dependencies between channels. In this work, we introduce the concept
of partial channel dependence (PCD), which enables a more sophisticated
adjustment of channel dependencies based on dataset-specific information. To
achieve PCD, we propose a channel mask that captures the relationships between
channels within a dataset using two key components: 1) a correlation matrix
that encodes relative dependencies between channels, and 2) domain parameters
that learn the absolute dependencies specific to each dataset, refining the
correlation matrix. We validate the effectiveness of PCD across four tasks in
TS including forecasting, classification, imputation, and anomaly detection,
under diverse settings, including few-shot and zero-shot scenarios with both TS
foundation models and single-task models. Code is available at
https://github.com/seunghan96/CM.",2024-10-30,"Seunghan Lee, Taeyoung Park, Kibok Lee",http://arxiv.org/pdf/2410.23222v1,cs.LG
Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval,"The hallucinations of large language models (LLMs) are increasingly mitigated
by allowing LLMs to search for information and to ground their answers in real
sources. Unfortunately, LLMs often struggle with posing the right search
queries, especially when dealing with complex or otherwise indirect topics.
Observing that LLMs can learn to search for relevant facts by $\textit{trying}$
different queries and learning to up-weight queries that successfully produce
relevant results, we introduce $\underline{Le}$arning to $\underline{Re}$trieve
by $\underline{T}$rying (LeReT), a reinforcement learning framework that
explores search queries and uses preference-based optimization to improve their
quality. LeReT can improve the absolute retrieval accuracy by up to 29% and the
downstream generator evaluations by 17%. The simplicity and flexibility of
LeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes
it a promising technique for improving general LLM pipelines. Project website:
http://sherylhsu.com/LeReT/.",2024-10-30,"Sheryl Hsu, Omar Khattab, Chelsea Finn, Archit Sharma",http://arxiv.org/pdf/2410.23214v2,cs.LG
Improved convergence rate of kNN graph Laplacians,"In graph-based data analysis, $k$-nearest neighbor ($k$NN) graphs are widely
used due to their adaptivity to local data densities. Allowing weighted edges
in the graph, the kernelized graph affinity provides a more general type of
$k$NN graph where the $k$NN distance is used to set the kernel bandwidth
adaptively. In this work, we consider a general class of $k$NN graph where the
graph affinity is $W_{ij} = \epsilon^{-d/2} \; k_0 ( \| x_i - x_j \|^2 /
\epsilon \phi( \widehat{\rho}(x_i), \widehat{\rho}(x_j) )^2 ) $, with
$\widehat{\rho}(x)$ being the (rescaled) $k$NN distance at the point $x$,
$\phi$ a symmetric bi-variate function, and $k_0$ a non-negative function on
$[0,\infty)$. Under the manifold data setting, where $N$ i.i.d. samples $x_i$
are drawn from a density $p$ on a $d$-dimensional unknown manifold embedded in
a high dimensional Euclidean space, we prove the point-wise convergence of the
$k$NN graph Laplacian to the limiting manifold operator (depending on $p$) at
the rate of $O(N^{-2/(d+6)}\,)$, up to a log factor, when $k_0$ and $\phi$ have
$C^3$ regularity and satisfy other technical conditions. This fast rate is
obtained when $\epsilon \sim N^{-2/(d+6)}\,$ and $k \sim N^{6/(d+6)}\,$, both
at the optimal order to balance the theoretical bias and variance errors. When
$k_0$ and $\phi$ have lower regularities, including when $k_0$ is a compactly
supported function as in the standard $k$NN graph, the convergence rate
degenerates to $O(N^{-1/(d+4)}\,)$. Our improved convergence rate is based on a
refined analysis of the $k$NN estimator, which can be of independent interest.
We validate our theory by numerical experiments on simulated data.",2024-10-30,"Yixuan Tan, Xiuyuan Cheng",http://arxiv.org/pdf/2410.23212v1,cs.LG
Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks,"While large models trained with self-supervised learning on offline datasets
have shown remarkable capabilities in text and image domains, achieving the
same generalisation for agents that act in sequential decision problems remains
an open challenge. In this work, we take a step towards this goal by
procedurally generating tens of millions of 2D physics-based tasks and using
these to train a general reinforcement learning (RL) agent for physical
control. To this end, we introduce Kinetix: an open-ended space of
physics-based RL environments that can represent tasks ranging from robotic
locomotion and grasping to video games and classic RL environments, all within
a unified framework. Kinetix makes use of our novel hardware-accelerated
physics engine Jax2D that allows us to cheaply simulate billions of environment
steps during training. Our trained agent exhibits strong physical reasoning
capabilities in 2D space, being able to zero-shot solve unseen human-designed
environments. Furthermore, fine-tuning this general agent on tasks of interest
shows significantly stronger performance than training an RL agent *tabula
rasa*. This includes solving some environments that standard RL training
completely fails at. We believe this demonstrates the feasibility of large
scale, mixed-quality pre-training for online RL and we hope that Kinetix will
serve as a useful framework to investigate this further.",2024-10-30,"Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster",http://arxiv.org/pdf/2410.23208v2,cs.LG
ProTransformer: Robustify Transformers via Plug-and-Play Paradigm,"Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.",2024-10-30,"Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu",http://arxiv.org/pdf/2410.23182v1,cs.LG
Does equivariance matter at scale?,"Given large data sets and sufficient compute, is it beneficial to design
neural architectures for the structure and symmetries of each problem? Or is it
more efficient to learn them from data? We study empirically how equivariant
and non-equivariant networks scale with compute and training samples. Focusing
on a benchmark problem of rigid-body interactions and on general-purpose
transformer architectures, we perform a series of experiments, varying the
model size, training steps, and dataset size. We find evidence for three
conclusions. First, equivariance improves data efficiency, but training
non-equivariant models with data augmentation can close this gap given
sufficient epochs. Second, scaling with compute follows a power law, with
equivariant models outperforming non-equivariant ones at each tested compute
budget. Finally, the optimal allocation of a compute budget onto model size and
training duration differs between equivariant and non-equivariant models.",2024-10-30,"Johann Brehmer, Sönke Behrends, Pim de Haan, Taco Cohen",http://arxiv.org/pdf/2410.23179v1,cs.LG
Uncertainty quantification for fast reconstruction methods using augmented equivariant bootstrap: Application to radio interferometry,"The advent of next-generation radio interferometers like the Square Kilometer
Array promises to revolutionise our radio astronomy observational capabilities.
The unprecedented volume of data these devices generate requires fast and
accurate image reconstruction algorithms to solve the ill-posed radio
interferometric imaging problem. Most state-of-the-art reconstruction methods
lack trustworthy and scalable uncertainty quantification, which is critical for
the rigorous scientific interpretation of radio observations. We propose an
unsupervised technique based on a conformalized version of a radio-augmented
equivariant bootstrapping method, which allows us to quantify uncertainties for
fast reconstruction methods. Noticeably, we rely on reconstructions from
ultra-fast unrolled algorithms. The proposed method brings more reliable
uncertainty estimations to our problem than existing alternatives.",2024-10-30,"Mostafa Cherif, Tobías I. Liaudat, Jonathan Kern, Christophe Kervazo, Jérôme Bobin",http://arxiv.org/pdf/2410.23178v2,cs.LG
Functional Gradient Flows for Constrained Sampling,"Recently, through a unified gradient flow perspective of Markov chain Monte
Carlo (MCMC) and variational inference (VI), particle-based variational
inference methods (ParVIs) have been proposed that tend to combine the best of
both worlds. While typical ParVIs such as Stein Variational Gradient Descent
(SVGD) approximate the gradient flow within a reproducing kernel Hilbert space
(RKHS), many attempts have been made recently to replace RKHS with more
expressive function spaces, such as neural networks. While successful, these
methods are mainly designed for sampling from unconstrained domains. In this
paper, we offer a general solution to constrained sampling by introducing a
boundary condition for the gradient flow which would confine the particles
within the specific domain. This allows us to propose a new functional gradient
ParVI method for constrained sampling, called constrained functional gradient
flow (CFG), with provable continuous-time convergence in total variation (TV).
We also present novel numerical strategies to handle the boundary integral term
arising from the domain constraints. Our theory and experiments demonstrate the
effectiveness of the proposed framework.",2024-10-30,"Shiyue Zhang, Longlin Yu, Ziheng Cheng, Cheng Zhang",http://arxiv.org/pdf/2410.23170v1,cs.LG
The Persistence of Neural Collapse Despite Low-Rank Bias: An Analytic Perspective Through Unconstrained Features,"Modern deep neural networks have been observed to exhibit a simple structure
in their final layer features and weights, commonly referred to as neural
collapse. This phenomenon has also been noted in layers beyond the final one,
an extension known as deep neural collapse. Recent findings indicate that such
a structure is generally not optimal in the deep unconstrained feature model,
an approximation of an expressive network. This is attributed to a low-rank
bias induced by regularization, which favors solutions with lower-rank than
those typically associated with deep neural collapse. In this work, we extend
these observations to the cross-entropy loss and analyze how the low-rank bias
influences various solutions. Additionally, we explore how this bias induces
specific structures in the singular values of the weights at global optima.
Furthermore, we examine the loss surface of these models and provide evidence
that the frequent observation of deep neural collapse in practice, despite its
suboptimality, may result from its higher degeneracy on the loss surface.",2024-10-30,"Connall Garrod, Jonathan P. Keating",http://arxiv.org/pdf/2410.23169v1,cs.LG
TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters,"Transformers have become the predominant architecture in foundation models
due to their excellent performance across various domains. However, the
substantial cost of scaling these models remains a significant concern. This
problem arises primarily from their dependence on a fixed number of parameters
within linear projections. When architectural modifications (e.g., channel
dimensions) are introduced, the entire model typically requires retraining from
scratch. As model sizes continue growing, this strategy results in increasingly
high computational costs and becomes unsustainable. To overcome this problem,
we introduce TokenFormer, a natively scalable architecture that leverages the
attention mechanism not only for computations among input tokens but also for
interactions between tokens and model parameters, thereby enhancing
architectural flexibility. By treating model parameters as tokens, we replace
all the linear projections in Transformers with our token-parameter attention
layer, where input tokens act as queries and model parameters as keys and
values. This reformulation allows for progressive and efficient scaling without
necessitating retraining from scratch. Our model scales from 124M to 1.4B
parameters by incrementally adding new key-value parameter pairs, achieving
performance comparable to Transformers trained from scratch while greatly
reducing training costs. Code and models are available at
https://github.com/Haiyang-W/TokenFormer.",2024-10-30,"Haiyang Wang, Yue Fan, Muhammad Ferjad Naeem, Yongqin Xian, Jan Eric Lenssen, Liwei Wang, Federico Tombari, Bernt Schiele",http://arxiv.org/pdf/2410.23168v2,cs.LG
SciPIP: An LLM-based Scientific Paper Idea Proposer,"The rapid advancement of large language models (LLMs) has opened new
possibilities for automating the proposal of innovative scientific ideas. This
process involves two key phases: literature retrieval and idea generation.
However, existing approaches often fall short due to their reliance on
keyword-based search tools during the retrieval phase, which neglects crucial
semantic information and frequently results in incomplete retrieval outcomes.
Similarly, in the idea generation phase, current methodologies tend to depend
solely on the internal knowledge of LLMs or metadata from retrieved papers,
thereby overlooking significant valuable insights contained within the full
texts. To address these limitations, we introduce SciPIP, an innovative
framework designed to enhance the LLM-based proposal of scientific ideas
through improvements in both literature retrieval and idea generation. Our
approach begins with the construction of a comprehensive literature database
that supports advanced retrieval based not only on keywords but also on
semantics and citation relationships. This is complemented by the introduction
of a multi-granularity retrieval algorithm aimed at ensuring more thorough and
exhaustive retrieval results. For the idea generation phase, we propose a
dual-path framework that effectively integrates both the content of retrieved
papers and the extensive internal knowledge of LLMs. This integration
significantly boosts the novelty, feasibility, and practical value of proposed
ideas. Our experiments, conducted across various domains such as natural
language processing and computer vision, demonstrate SciPIP's capability to
generate a multitude of innovative and useful ideas. These findings underscore
SciPIP's potential as a valuable tool for researchers seeking to advance their
fields with groundbreaking concepts.",2024-10-30,"Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang Xie, Binbin Lin, Xiaofei He, Jieping Ye",http://arxiv.org/pdf/2410.23166v2,cs.LG
FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities,"Developing a foundation model for time series forecasting across diverse
domains has attracted significant attention in recent years. Existing works
typically assume regularly sampled, well-structured data, limiting their
applicability to more generalized scenarios where time series often contain
missing values, unequal sequence lengths, and irregular time intervals between
measurements. To cover diverse domains and handle variable regularities, we
propose FlexTSF, a universal time series forecasting model that possesses
better generalization and natively support both regular and irregular time
series. FlexTSF produces forecasts in an autoregressive manner and incorporates
three novel designs: VT-Norm, a normalization strategy to ablate data domain
barriers, IVP Patcher, a patching module to learn representations from flexibly
structured time series, and LED attention, an attention mechanism to seamlessly
integrate these two and propagate forecasts with awareness of domain and time
information. Experiments on 12 datasets show that FlexTSF outperforms
state-of-the-art forecasting models respectively designed for regular and
irregular time series. Furthermore, after self-supervised pre-training, FlexTSF
shows exceptional performance in both zero-shot and few-show settings for time
series forecasting.",2024-10-30,"Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk",http://arxiv.org/pdf/2410.23160v1,cs.LG
Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting,"Deep learning approaches have been widely adopted for precipitation
nowcasting in recent years. Previous studies mainly focus on proposing new
model architectures to improve pixel-wise metrics. However, they frequently
result in blurry predictions which provide limited utility to forecasting
operations. In this work, we propose a new Fourier Amplitude and Correlation
Loss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss
(FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitude
of the model prediction and FCL complements the missing phase information. The
two loss terms work together to replace the traditional $L_2$ losses such as
MSE and weighted MSE for the spatiotemporal prediction problem on signal-based
data. Our method is generic, parameter-free and efficient. Extensive
experiments using one synthetic dataset and three radar echo datasets
demonstrate that our method improves perceptual metrics and meteorology skill
scores, with a small trade-off to pixel-wise accuracy and structural
similarity. Moreover, to improve the error margin in meteorological skill
scores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we
propose and adopt the Regional Histogram Divergence (RHD), a distance metric
that considers the patch-wise similarity between signal-based imagery patterns
with tolerance to local transforms. Code is available at
https://github.com/argenycw/FACL",2024-10-30,"Chiu-Wai Yan, Shi Quan Foo, Van Hoan Trinh, Dit-Yan Yeung, Ka-Hing Wong, Wai-Kin Wong",http://arxiv.org/pdf/2410.23159v1,cs.LG
Directional anomaly detection,"Semi-supervised anomaly detection is based on the principle that potential
anomalies are those records that look different from normal training data.
However, in some cases we are specifically interested in anomalies that
correspond to high attribute values (or low, but not both). We present two
asymmetrical distance measures that take this directionality into account: ramp
distance and signed distance. Through experiments on synthetic and real-life
datasets we show that ramp distance performs as well or better than the
absolute distance traditionally used in anomaly detection. While signed
distance also performs well on synthetic data, it performs substantially poorer
on real-life datasets. We argue that this reflects the fact that in practice,
good scores on some attributes should not be allowed to compensate for bad
scores on others.",2024-10-30,"Oliver Urs Lenz, Matthijs van Leeuwen",http://arxiv.org/pdf/2410.23158v1,cs.LG
VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning,"Broadly intelligent agents should form task-specific abstractions that
selectively expose the essential elements of a task, while abstracting away the
complexity of the raw sensorimotor space. In this work, we present
Neuro-Symbolic Predicates, a first-order abstraction language that combines the
strengths of symbolic and neural knowledge representations. We outline an
online algorithm for inventing such predicates and learning abstract world
models. We compare our approach to hierarchical reinforcement learning,
vision-language model planning, and symbolic predicate invention approaches, on
both in- and out-of-distribution tasks across five simulated robotic domains.
Results show that our approach offers better sample complexity, stronger
out-of-distribution generalization, and improved interpretability.",2024-10-30,"Yichao Liang, Nishanth Kumar, Hao Tang, Adrian Weller, Joshua B. Tenenbaum, Tom Silver, João F. Henriques, Kevin Ellis",http://arxiv.org/pdf/2410.23156v2,cs.LG
QWO: Speeding Up Permutation-Based Causal Discovery in LiGAMs,"Causal discovery is essential for understanding relationships among variables
of interest in many scientific domains. In this paper, we focus on
permutation-based methods for learning causal graphs in Linear Gaussian Acyclic
Models (LiGAMs), where the permutation encodes a causal ordering of the
variables. Existing methods in this setting are not scalable due to their high
computational complexity. These methods are comprised of two main components:
(i) constructing a specific DAG, $\mathcal{G}^\pi$, for a given permutation
$\pi$, which represents the best structure that can be learned from the
available data while adhering to $\pi$, and (ii) searching over the space of
permutations (i.e., causal orders) to minimize the number of edges in
$\mathcal{G}^\pi$. We introduce QWO, a novel approach that significantly
enhances the efficiency of computing $\mathcal{G}^\pi$ for a given permutation
$\pi$. QWO has a speed-up of $O(n^2)$ ($n$ is the number of variables) compared
to the state-of-the-art BIC-based method, making it highly scalable. We show
that our method is theoretically sound and can be integrated into existing
search strategies such as GRASP and hill-climbing-based methods to improve
their performance.",2024-10-30,"Mohammad Shahverdikondori, Ehsan Mokhtarian, Negar Kiyavash",http://arxiv.org/pdf/2410.23155v1,cs.LG
Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems,"The rapid growth of end-user AI applications, such as computer vision and
generative AI, has led to immense data and processing demands often exceeding
user devices' capabilities. Edge AI addresses this by offloading computation to
the network edge, crucial for future services in 6G networks. However, it faces
challenges such as limited resources during simultaneous offloads and the
unrealistic assumption of homogeneous system architecture. To address these, we
propose a research roadmap focused on profiling AI models, capturing data about
model types, hyperparameters, and underlying hardware to predict resource
utilisation and task completion time. Initial experiments with over 3,000 runs
show promise in optimising resource allocation and enhancing Edge AI
performance.",2024-10-30,"Juan Marcelo Parra-Ullauri, Oscar Dilley, Hari Madhukumar, Dimitra Simeonidou",http://arxiv.org/pdf/2411.00859v1,cs.LG
DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection,"Diabetes is a chronic disorder identified by the high sugar level in the
blood that can cause various different disorders such as kidney failure, heart
attack, sightlessness, and stroke. Developments in the healthcare domain by
facilitating the early detection of diabetes risk can help not only caregivers
but also patients. AIoMT is a recent technology that integrates IoT and machine
learning methods to give services for medical purposes, which is a powerful
technology for the early detection of diabetes. In this paper, we take
advantage of AIoMT and propose a hybrid diabetes risk detection method, DiabML,
which uses the BWO algorithm and ML methods. BWO is utilized for feature
selection and SMOTE for imbalance handling in the pre-processing procedure. The
simulation results prove the superiority of the proposed DiabML method compared
to the existing works. DiabML achieves 86.1\% classification accuracy by
AdaBoost classifier outperforms the relevant existing methods.",2024-10-30,"Vahideh Hayyolalam, Öznur Özkasap",http://arxiv.org/pdf/2411.00858v1,cs.LG
When can classical neural networks represent quantum states?,"A naive classical representation of an n-qubit state requires specifying
exponentially many amplitudes in the computational basis. Past works have
demonstrated that classical neural networks can succinctly express these
amplitudes for many physically relevant states, leading to computationally
powerful representations known as neural quantum states. What underpins the
efficacy of such representations? We show that conditional correlations present
in the measurement distribution of quantum states control the performance of
their neural representations. Such conditional correlations are basis
dependent, arise due to measurement-induced entanglement, and reveal features
not accessible through conventional few-body correlations often examined in
studies of phases of matter. By combining theoretical and numerical analysis,
we demonstrate how the state's entanglement and sign structure, along with the
choice of measurement basis, give rise to distinct patterns of short- or
long-range conditional correlations. Our findings provide a rigorous framework
for exploring the expressive power of neural quantum states.",2024-10-30,"Tai-Hsuan Yang, Mehdi Soleimanifar, Thiago Bergamaschi, John Preskill",http://arxiv.org/pdf/2410.23152v1,cs.LG
Navigating in High-Dimensional Search Space: A Hierarchical Bayesian Optimization Approach,"Optimizing black-box functions in high-dimensional search spaces has been
known to be challenging for traditional Bayesian Optimization (BO). In this
paper, we introduce HiBO, a novel hierarchical algorithm integrating
global-level search space partitioning information into the acquisition
strategy of a local BO-based optimizer. HiBO employs a search-tree-based
global-level navigator to adaptively split the search space into partitions
with different sampling potential. The local optimizer then utilizes this
global-level information to guide its acquisition strategy towards most
promising regions within the search space. A comprehensive set of evaluations
demonstrates that HiBO outperforms state-of-the-art methods in high-dimensional
synthetic benchmarks and presents significant practical effectiveness in the
real-world task of tuning configurations of database management systems
(DBMSs).",2024-10-30,"Wenxuan Li, Taiyi Wang, Eiko Yoneki",http://arxiv.org/pdf/2410.23148v6,cs.LG
FoLDTree: A ULDA-Based Decision Tree Framework for Efficient Oblique Splits and Feature Selection,"Traditional decision trees are limited by axis-orthogonal splits, which can
perform poorly when true decision boundaries are oblique. While oblique
decision tree methods address this limitation, they often face high
computational costs, difficulties with multi-class classification, and a lack
of effective feature selection. In this paper, we introduce LDATree and
FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant
Analysis (ULDA) and Forward ULDA into a decision tree structure. These methods
enable efficient oblique splits, handle missing values, support feature
selection, and provide both class labels and probabilities as model outputs.
Through evaluations on simulated and real-world datasets, LDATree and FoLDTree
consistently outperform axis-orthogonal and other oblique decision tree
methods, achieving accuracy levels comparable to the random forest. The results
highlight the potential of these frameworks as robust alternatives to
traditional single-tree methods.",2024-10-30,"Siyu Wang, Kehui Yao",http://arxiv.org/pdf/2410.23147v2,cs.LG
"The Good, the Bad, and the Ugly: The Role of AI Quality Disclosure in Lie Detection","We investigate how low-quality AI advisors, lacking quality disclosures, can
help spread text-based lies while seeming to help people detect lies.
Participants in our experiment discern truth from lies by evaluating
transcripts from a game show that mimicked deceptive social media exchanges on
topics with objective truths. We find that when relying on low-quality advisors
without disclosures, participants' truth-detection rates fall below their own
abilities, which recovered once the AI's true effectiveness was revealed.
Conversely, high-quality advisor enhances truth detection, regardless of
disclosure. We discover that participants' expectations about AI capabilities
contribute to their undue reliance on opaque, low-quality advisors.",2024-10-30,"Haimanti Bhattacharya, Subhasish Dugar, Sanchaita Hazra, Bodhisattwa Prasad Majumder",http://arxiv.org/pdf/2410.23143v2,cs.LG
FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training,"Deep neural networks are susceptible to adversarial attacks and common
corruptions, which undermine their robustness. In order to enhance model
resilience against such challenges, Adversarial Training (AT) has emerged as a
prominent solution. Nevertheless, adversarial robustness is often attained at
the expense of model fairness during AT, i.e., disparity in class-wise
robustness of the model. While distinctive classes become more robust towards
such adversaries, hard to detect classes suffer. Recently, research has focused
on improving model fairness specifically for perturbed images, overlooking the
accuracy of the most likely non-perturbed data. Additionally, despite their
robustness against the adversaries encountered during model training,
state-of-the-art adversarial trained models have difficulty maintaining
robustness and fairness when confronted with diverse adversarial threats or
common corruptions. In this work, we address the above concerns by introducing
a novel approach called Fair Targeted Adversarial Training (FAIR-TAT). We show
that using targeted adversarial attacks for adversarial training (instead of
untargeted attacks) can allow for more favorable trade-offs with respect to
adversarial fairness. Empirical results validate the efficacy of our approach.",2024-10-30,"Tejaswini Medi, Steffen Jung, Margret Keuper",http://arxiv.org/pdf/2410.23142v2,cs.LG
Revisiting MAE pre-training for 3D medical image segmentation,"Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision, its
adoption in 3D medical image computing has been limited by three key pitfalls:
Small pre-training dataset sizes, architectures inadequate for 3D medical image
analysis, and insufficient evaluation practices. In this paper, we address
these issues by i) leveraging a large-scale dataset of 39k 3D brain MRI volumes
and ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points setting a new state-of-the-art. Our code
and models are made available here.",2024-10-30,"Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Maximilian Miller, Leander Maerkisch, Paul F. Jäger, Klaus Maier-Hein",http://arxiv.org/pdf/2410.23132v3,cs.LG
Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis,"In federated learning, it is common to assume that clients are always
available to participate in training, which may not be feasible with user
devices in practice. Recent works analyze federated learning under more
realistic participation patterns, such as cyclic client availability or
arbitrary participation. However, all such works either require strong
assumptions (e.g., all clients participate almost surely within a bounded
window), do not achieve linear speedup and reduced communication rounds, or are
not applicable in the general non-convex setting. In this work, we focus on
nonconvex optimization and consider participation patterns in which the chance
of participation over a fixed window of rounds is equal among all clients,
which includes cyclic client availability as a special case. Under this
setting, we propose a new algorithm, named Amplified SCAFFOLD, and prove that
it achieves linear speedup, reduced communication, and resilience to data
heterogeneity simultaneously. In particular, for cyclic participation, our
algorithm is proved to enjoy $\mathcal{O}(\epsilon^{-2})$ communication rounds
to find an $\epsilon$-stationary point in the non-convex stochastic setting. In
contrast, the prior work under the same setting requires $\mathcal{O}(\kappa^2
\epsilon^{-4})$ communication rounds, where $\kappa$ denotes the data
heterogeneity. Therefore, our algorithm significantly reduces communication
rounds due to better dependency in terms of $\epsilon$ and $\kappa$. Our
analysis relies on a fine-grained treatment of the nested dependence between
client participation and errors in the control variates, which results in
tighter guarantees than previous work. We also provide experimental results
with (1) synthetic data and (2) real-world data with a large number of clients
$(N = 250)$, demonstrating the effectiveness of our algorithm under periodic
client participation.",2024-10-30,"Michael Crawshaw, Mingrui Liu",http://arxiv.org/pdf/2410.23131v3,cs.LG
Why Fine-grained Labels in Pretraining Benefit Generalization?,"Recent studies show that pretraining a deep neural network with fine-grained
labeled data, followed by fine-tuning on coarse-labeled data for downstream
tasks, often yields better generalization than pretraining with coarse-labeled
data. While there is ample empirical evidence supporting this, the theoretical
justification remains an open problem. This paper addresses this gap by
introducing a ""hierarchical multi-view"" structure to confine the input data
distribution. Under this framework, we prove that: 1) coarse-grained
pretraining only allows a neural network to learn the common features well,
while 2) fine-grained pretraining helps the network learn the rare features in
addition to the common ones, leading to improved accuracy on hard downstream
test samples.",2024-10-30,"Guan Zhe Hong, Yin Cui, Ariel Fuxman, Stanley Chan, Enming Luo",http://arxiv.org/pdf/2410.23129v2,cs.LG
Deep learning meets tree phenology modeling: PhenoFormer vs. process-based models,"Phenology, the timing of cyclical plant life events such as leaf emergence
and coloration, is crucial in the bio-climatic system. Climate change drives
shifts in these phenological events, impacting ecosystems and the climate
itself. Accurate phenology models are essential to predict the occurrence of
these phases under changing climatic conditions. Existing methods include
hypothesis-driven process models and data-driven statistical approaches.
Process models account for dormancy stages and various phenology drivers, while
statistical models typically rely on linear or traditional machine learning
techniques. Research shows that process models often outperform statistical
methods when predicting under climate conditions outside historical ranges,
especially with climate change scenarios. However, deep learning approaches
remain underexplored in climate phenology modeling. We introduce PhenoFormer, a
neural architecture better suited than traditional statistical methods at
predicting phenology under shift in climate data distribution, while also
bringing significant improvements or performing on par to the best performing
process-based models. Our numerical experiments on a 70-year dataset of 70,000
phenological observations from 9 woody species in Switzerland show that
PhenoFormer outperforms traditional machine learning methods by an average of
13% R2 and 1.1 days RMSE for spring phenology, and 11% R2 and 0.7 days RMSE for
autumn phenology, while matching or exceeding the best process-based models.
Our results demonstrate that deep learning has the potential to be a valuable
methodological tool for accurate climate-phenology prediction, and our
PhenoFormer is a first promising step in improving phenological predictions
before a complete understanding of the underlying physiological mechanisms is
available.",2024-10-30,"Vivien Sainte Fare Garnot, Lynsay Spafford, Jelle Lever, Christian Sigg, Barbara Pietragalla, Yann Vitasse, Arthur Gessler, Jan Dirk Wegner",http://arxiv.org/pdf/2410.23327v1,cs.LG
Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes,"We study the optimal memorization capacity of modern Hopfield models and
Kernelized Hopfield Models (KHMs), a transformer-compatible class of Dense
Associative Memories. We present a tight analysis by establishing a connection
between the memory configuration of KHMs and spherical codes from information
theory. Specifically, we treat the stored memory set as a specialized spherical
code. This enables us to cast the memorization problem in KHMs into a point
arrangement problem on a hypersphere. We show that the optimal capacity of KHMs
occurs when the feature space allows memories to form an optimal spherical
code. This unique perspective leads to: (i) An analysis of how KHMs achieve
optimal memory capacity, and identify corresponding necessary conditions.
Importantly, we establish an upper capacity bound that matches the well-known
exponential lower bound in the literature. This provides the first tight and
optimal asymptotic memory capacity for modern Hopfield models. (ii) A
sub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs'
optimal capacity. (iii) An analysis of the scaling behavior of the required
feature dimension relative to the number of stored memories. These efforts
improve both the retrieval capability of KHMs and the representation learning
of corresponding transformers. Experimentally, we provide thorough numerical
results to back up theoretical findings.",2024-10-30,"Jerry Yao-Chieh Hu, Dennis Wu, Han Liu",http://arxiv.org/pdf/2410.23126v2,cs.LG
Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models,"Despite the outstanding performance in vision-language reasoning, Large
Vision-Language Models (LVLMs) might generate hallucinated contents that do not
exist in the given image. Most existing LVLM hallucination benchmarks are
constrained to evaluate the object-related hallucinations. However, the
potential hallucination on the relations between two objects, i.e., relation
hallucination, still lacks investigation. To remedy that, in this paper we
design a unified framework to measure object and relation hallucination in
LVLMs simultaneously. The core idea of our framework is to conduct
hallucination evaluation on (object, relation, object) triplets extracted from
LVLMs' responses, and thus, could be easily generalized to different
vision-language tasks. Based on our framework, we further introduce Tri-HE, a
novel Triplet-level Hallucination Evaluation benchmark which can be used to
study both object and relation hallucination at the same time. We conduct
comprehensive evaluations on Tri-HE and observe that the relation hallucination
issue is even more serious than object hallucination among existing LVLMs,
highlighting a previously neglected problem towards reliable LVLMs. Moreover,
based on our findings, we design a simple yet effective training-free approach
to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced
counterparts on Tri-HE, achieving comparable performance with the powerful
GPT-4V. Our dataset and code for the reproduction of our experiments are
available publicly at https://github.com/wujunjie1998/Tri-HE.",2024-10-30,"Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung",http://arxiv.org/pdf/2410.23114v2,cs.LG
Exploring Gradient Subspaces: Addressing and Overcoming LoRA's Limitations in Federated Fine-Tuning of Large Language Models,"Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, particularly in task generalization for both text and vision
data. While fine-tuning these models can significantly enhance their
performance on specific downstream tasks, it often requires high-quality data
that cannot be shared due to privacy concerns. Federated Learning (FL) offers a
promising solution for collaborative training without direct data sharing.
However, many parameter-efficient fine-tuning strategies for LLMs in FL,
particularly those based on Low-Rank Adaptation (LoRA), face limitations. In
this paper, we critically analyze the convergence and performance guarantees of
popular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to
constrained subspace learning of low-rank matrices. This limitation hinders
effective fine-tuning of LLMs in federated settings. Through rigorous
analytical and empirical evaluations, we demonstrate that direct weight
averaging outperforms LoRA-based strategies, leading to superior performance
for fine-tuned models. Our comprehensive comparison unmasks inefficiencies in
LoRA approaches and underscores the advantages of direct weight aggregation. We
extend our analysis to low-rank gradient-based optimizers, such as GaLore, used
during local training steps. Our findings show that GaLore along with
direct-weight aggregation is a more effective approach, outperforming federated
LoRA methods like FlexLoRA and FFA-LoRA across both text and image modalities.
While privacy remains paramount in FL discourse, our focus is on assessing
performance outcomes of federated fine-tuned models and evaluating various FL
frameworks from both theoretical and empirical perspectives. Our findings
advocate reassessing the reliance on LoRA within FL contexts, paving the way
for more efficient training methodologies.",2024-10-30,"Navyansh Mahla, Kshitij Sharad Jadhav, Ganesh Ramakrishnan",http://arxiv.org/pdf/2410.23111v6,cs.LG
Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models,"Generative Adversarial Networks (GANs) are unsupervised models designed to
learn and replicate a target distribution. The vanilla versions of these models
can be extended to more controllable models. Conditional Generative Adversarial
Networks (CGANs) extend vanilla GANs by conditioning both the generator and
discriminator on some additional information (labels). Controllable models
based on complementary learning, such as Rumi-GAN, have been introduced.
Rumi-GANs leverage negative examples to enhance the generator's ability to
learn positive examples. We evaluate the performance of two controllable GAN
variants, CGAN and Rumi-GAN, in generating game levels targeting specific
constraints of interest: playability and controllability. This evaluation is
conducted under two scenarios: with and without the inclusion of negative
examples. The goal is to determine whether incorporating negative examples
helps the GAN models avoid generating undesirable outputs. Our findings
highlight the strengths and weaknesses of each method in enforcing the
generation of specific conditions when generating outputs based on given
positive and negative examples.",2024-10-30,"Mahsa Bazzaz, Seth Cooper",http://arxiv.org/pdf/2410.23108v1,cs.LG
Decoupling Semantic Similarity from Spatial Alignment for Neural Networks,"What representation do deep neural networks learn? How similar are images to
each other for neural networks? Despite the overwhelming success of deep
learning methods key questions about their internal workings still remain
largely unanswered, due to their internal high dimensionality and complexity.
To address this, one approach is to measure the similarity of activation
responses to various inputs. Representational Similarity Matrices (RSMs)
distill this similarity into scalar values for each input pair. These matrices
encapsulate the entire similarity structure of a system, indicating which input
leads to similar responses. While the similarity between images is ambiguous,
we argue that the spatial location of semantic objects does neither influence
human perception nor deep learning classifiers. Thus this should be reflected
in the definition of similarity between image responses for computer vision
systems. Revisiting the established similarity calculations for RSMs we expose
their sensitivity to spatial alignment. In this paper, we propose to solve this
through semantic RSMs, which are invariant to spatial permutation. We measure
semantic similarity between input responses by formulating it as a set-matching
problem. Further, we quantify the superiority of semantic RSMs over
spatio-semantic RSMs through image retrieval and by comparing the similarity
between representations to the similarity between predicted class
probabilities.",2024-10-30,"Tassilo Wald, Constantin Ulrich, Gregor Köhler, David Zimmerer, Stefan Denner, Michael Baumgartner, Fabian Isensee, Priyank Jaini, Klaus H. Maier-Hein",http://arxiv.org/pdf/2410.23107v1,cs.LG
Guided Game Level Repair via Explainable AI,"Procedurally generated levels created by machine learning models can be
unsolvable without further editing. Various methods have been developed to
automatically repair these levels by enforcing hard constraints during the
post-processing step. However, as levels increase in size, these
constraint-based repairs become increasingly slow. This paper proposes using
explainability methods to identify specific regions of a level that contribute
to its unsolvability. By assigning higher weights to these regions,
constraint-based solvers can prioritize these problematic areas, enabling more
efficient repairs. Our results, tested across three games, demonstrate that
this approach can help to repair procedurally generated levels faster.",2024-10-30,"Mahsa Bazzaz, Seth Cooper",http://arxiv.org/pdf/2410.23101v2,cs.LG
Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning,"In-context learning can help Large Language Models (LLMs) to adapt new tasks
without additional training. However, this performance heavily depends on the
quality of the demonstrations, driving research into effective demonstration
selection algorithms to optimize this process. These algorithms assist users in
selecting the best $k$ input-label pairs (demonstration examples) based on a
given test input, enabling LLMs to in-context learn the relationship between
the provided examples and the test inputs. Despite all the proposed
demonstration selection algorithms, their efficiency and effectiveness remain
unclear. This lack of clarity make it difficult to apply these algorithms in
real-world scenarios and poses challenges for future research aimed at
developing improved methods. This paper revisits six proposed algorithms,
evaluating them on five datasets from both efficiency and effectiveness
perspectives. Our experiments reveal significant variations in algorithm
performance across different tasks, with some methods struggling to outperform
random selection in certain scenarios. We also find that increasing the number
of demonstrations does not always lead to better performance, and that there
are often trade-offs between accuracy and computational efficiency. Our code is
available at https://github.com/Tizzzzy/Demonstration_Selection_Overview.",2024-10-30,"Dong Shu, Mengnan Du",http://arxiv.org/pdf/2410.23099v1,cs.LG
MassSpecGym: A benchmark for the discovery and identification of molecules,"The discovery and identification of molecules in biological and environmental
samples is crucial for advancing biomedical and chemical sciences. Tandem mass
spectrometry (MS/MS) is the leading technique for high-throughput elucidation
of molecular structures. However, decoding a molecular structure from its mass
spectrum is exceptionally challenging, even when performed by human experts. As
a result, the vast majority of acquired MS/MS spectra remain uninterpreted,
thereby limiting our understanding of the underlying (bio)chemical processes.
Despite decades of progress in machine learning applications for predicting
molecular structures from MS/MS spectra, the development of new methods is
severely hindered by the lack of standard datasets and evaluation protocols. To
address this problem, we propose MassSpecGym -- the first comprehensive
benchmark for the discovery and identification of molecules from MS/MS data.
Our benchmark comprises the largest publicly available collection of
high-quality labeled MS/MS spectra and defines three MS/MS annotation
challenges: de novo molecular structure generation, molecule retrieval, and
spectrum simulation. It includes new evaluation metrics and a
generalization-demanding data split, therefore standardizing the MS/MS
annotation tasks and rendering the problem accessible to the broad machine
learning community. MassSpecGym is publicly available at
https://github.com/pluskal-lab/MassSpecGym.",2024-10-30,"Roman Bushuiev, Anton Bushuiev, Niek F. de Jonge, Adamo Young, Fleming Kretschmer, Raman Samusevich, Janne Heirman, Fei Wang, Luke Zhang, Kai Dührkop, Marcus Ludwig, Nils A. Haupt, Apurva Kalia, Corinna Brungs, Robin Schmid, Russell Greiner, Bo Wang, David S. Wishart, Li-Ping Liu, Juho Rousu, Wout Bittremieux, Hannes Rost, Tytus D. Mak, Soha Hassoun, Florian Huber, Justin J. J. van der Hooft, Michael A. Stravs, Sebastian Böcker, Josef Sivic, Tomáš Pluskal",http://arxiv.org/pdf/2410.23326v3,cs.LG
AI in Investment Analysis: LLMs for Equity Stock Ratings,"Investment Analysis is a cornerstone of the Financial Services industry. The
rapid integration of advanced machine learning techniques, particularly Large
Language Models (LLMs), offers opportunities to enhance the equity rating
process. This paper explores the application of LLMs to generate multi-horizon
stock ratings by ingesting diverse datasets. Traditional stock rating methods
rely heavily on the expertise of financial analysts, and face several
challenges such as data overload, inconsistencies in filings, and delayed
reactions to market events. Our study addresses these issues by leveraging LLMs
to improve the accuracy and consistency of stock ratings. Additionally, we
assess the efficacy of using different data modalities with LLMs for the
financial domain.
  We utilize varied datasets comprising fundamental financial, market, and news
data from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a
training cutoff in Sep. 2021 to prevent information leakage). Our results show
that our benchmark method outperforms traditional stock rating methods when
assessed by forward returns, specially when incorporating financial
fundamentals. While integrating news data improves short-term performance,
substituting detailed news summaries with sentiment scores reduces token use
without loss of performance. In many cases, omitting news data entirely
enhances performance by reducing bias.
  Our research shows that LLMs can be leveraged to effectively utilize large
amounts of multimodal financial data, as showcased by their effectiveness at
the stock rating prediction task. Our work provides a reproducible and
efficient framework for generating accurate stock ratings, serving as a
cost-effective alternative to traditional methods. Future work will extend to
longer timeframes, incorporate diverse data, and utilize newer models for
enhanced insights.",2024-10-30,"Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, Tucker Balch",http://arxiv.org/pdf/2411.00856v1,cs.LG
Statistical-Computational Trade-offs for Density Estimation,"We study the density estimation problem defined as follows: given $k$
distributions $p_1, \ldots, p_k$ over a discrete domain $[n]$, as well as a
collection of samples chosen from a ``query'' distribution $q$ over $[n]$,
output $p_i$ that is ``close'' to $q$. Recently~\cite{aamand2023data} gave the
first and only known result that achieves sublinear bounds in {\em both} the
sampling complexity and the query time while preserving polynomial data
structure space. However, their improvement over linear samples and time is
only by subpolynomial factors.
  Our main result is a lower bound showing that, for a broad class of data
structures, their bounds cannot be significantly improved. In particular, if an
algorithm uses $O(n/\log^c k)$ samples for some constant $c>0$ and polynomial
space, then the query time of the data structure must be at least
$k^{1-O(1)/\log \log k}$, i.e., close to linear in the number of distributions
$k$. This is a novel \emph{statistical-computational} trade-off for density
estimation, demonstrating that any data structure must use close to a linear
number of samples or take close to linear query time. The lower bound holds
even in the realizable case where $q=p_i$ for some $i$, and when the
distributions are flat (specifically, all distributions are uniform over half
of the domain $[n]$). We also give a simple data structure for our lower bound
instance with asymptotically matching upper bounds. Experiments show that the
data structure is quite efficient in practice.",2024-10-30,"Anders Aamand, Alexandr Andoni, Justin Y. Chen, Piotr Indyk, Shyam Narayanan, Sandeep Silwal, Haike Xu",http://arxiv.org/pdf/2410.23087v1,cs.LG
CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models,"Interpreting the decisions of Convolutional Neural Networks (CNNs) is
essential for understanding their behavior, yet explainability remains a
significant challenge, particularly for self-supervised models. Most existing
methods for generating saliency maps rely on ground truth labels, restricting
their use to supervised tasks. EigenCAM is the only notable label-independent
alternative, leveraging Singular Value Decomposition to generate saliency maps
applicable across CNN models, but it does not fully exploit the tensorial
structure of feature maps. In this work, we introduce the Tucker Saliency Map
(TSM) method, which applies Tucker tensor decomposition to better capture the
inherent structure of feature maps, producing more accurate singular vectors
and values. These are used to generate high-fidelity saliency maps, effectively
highlighting objects of interest in the input. We further extend EigenCAM and
TSM into multivector variants -Multivec-EigenCAM and Multivector Tucker
Saliency Maps (MTSM)- which utilize all singular vectors and values, further
improving saliency map quality. Quantitative evaluations on supervised
classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve
competitive performance with label-dependent methods. Moreover, TSM enhances
explainability by approximately 50% over EigenCAM for both supervised and
self-supervised models. Multivec-EigenCAM and MTSM further advance
state-of-the-art explainability performance on self-supervised models, with
MTSM achieving the best results.",2024-10-30,"Aymene Mohammed Bouayed, Samuel Deslauriers-Gauthier, Adrian Iaccovelli, David Naccache",http://arxiv.org/pdf/2410.23072v1,cs.LG
Vision-Language Models Can Self-Improve Reasoning via Reflection,"Chain-of-thought (CoT) has proven to improve the reasoning capability of
large language models (LLMs). However, due to the complexity of multimodal
scenarios and the difficulty in collecting high-quality CoT data, CoT reasoning
in multimodal LLMs has been largely overlooked. To this end, we propose a
simple yet effective self-training framework, R3V, which iteratively enhances
the model's Vision-language Reasoning by Reflecting on CoT Rationales. Our
framework consists of two interleaved parts: (1) iteratively bootstrapping
positive and negative solutions for reasoning datasets, and (2) reflection on
rationale for learning from mistakes. Specifically, we introduce the
self-refine and self-select losses, enabling the model to refine flawed
rationale and derive the correct answer by comparing rationale candidates.
Experiments on a wide range of vision-language tasks show that R3V consistently
improves multimodal LLM reasoning, achieving a relative improvement of 23 to 60
percent over GPT-distilled baselines. Additionally, our approach supports
self-reflection on generated solutions, further boosting performance through
test-time computation.",2024-10-30,"Kanzhi Cheng, Yantao Li, Fangzhi Xu, Jianbing Zhang, Hao Zhou, Yang Liu",http://arxiv.org/pdf/2411.00855v1,cs.LG
"Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification","State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely
heavily on multi-label attention layers to focus on key tokens in input text,
but obtaining optimal attention weights is challenging and resource-intensive.
To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a
novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses
existing state-of-the-art methods across all metrics on mimicfull, mimicfifty,
mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot
scenarios, outperforming previous models specifically designed for few-shot
scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36
percentage points on mimicfew, demonstrating its superior capability in
handling rare codes. PLANT also shows remarkable data efficiency in few-shot
scenarios, achieving precision comparable to traditional models with
significantly less data. These results are achieved through key technical
innovations: leveraging a pretrained Learning-to-Rank model as the planted
attention layer, integrating mutual-information gain to enhance attention,
introducing an inattention mechanism, and implementing a stateful-decoder to
maintain context. Comprehensive ablation studies validate the importance of
these contributions in realizing the performance gains.",2024-10-30,"Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu",http://arxiv.org/pdf/2410.23066v1,cs.LG
Controlling Language and Diffusion Models by Transporting Activations,"The increasing capabilities of large generative models and their ever more
widespread deployment have raised concerns about their reliability, safety, and
potential misuse. To address these issues, recent works have proposed to
control model generation by steering model activations in order to effectively
induce or prevent the emergence of concepts or behaviors in the generated
output. In this paper we introduce Activation Transport (AcT), a general
framework to steer activations guided by optimal transport theory that
generalizes many previous activation-steering works. AcT is modality-agnostic
and provides fine-grained control over the model behavior with negligible
computational overhead, while minimally impacting model abilities. We
experimentally show the effectiveness and versatility of our approach by
addressing key challenges in large language models (LLMs) and text-to-image
diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate
toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,
we show how AcT enables fine-grained style control and concept negation.",2024-10-30,"Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zappella, Nicholas Apostoloff, Marco Cuturi, Xavier Suau",http://arxiv.org/pdf/2410.23054v2,cs.LG
Legitimate ground-truth-free metrics for deep uncertainty classification scoring,"Despite the increasing demand for safer machine learning practices, the use
of Uncertainty Quantification (UQ) methods in production remains limited. This
limitation is exacerbated by the challenge of validating UQ methods in absence
of UQ ground truth. In classification tasks, when only a usual set of test data
is at hand, several authors suggested different metrics that can be computed
from such test points while assessing the quality of quantified uncertainties.
This paper investigates such metrics and proves that they are theoretically
well-behaved and actually tied to some uncertainty ground truth which is easily
interpretable in terms of model prediction trustworthiness ranking. Equipped
with those new results, and given the applicability of those metrics in the
usual supervised paradigm, we argue that our contributions will help promoting
a broader use of UQ in deep learning.",2024-10-30,"Arthur Pignet, Chiara Regniez, John Klein",http://arxiv.org/pdf/2410.23046v2,cs.LG
Toward Understanding In-context vs. In-weight Learning,"It has recently been demonstrated empirically that in-context learning
emerges in transformers when certain distributional properties are present in
the training data, but this ability can also diminish upon further training. We
provide a new theoretical understanding of these phenomena by identifying
simplified distributional properties that give rise to the emergence and
eventual disappearance of in-context learning. We do so by first analyzing a
simplified model that uses a gating mechanism to choose between an in-weight
and an in-context predictor. Through a combination of a generalization error
and regret analysis we identify conditions where in-context and in-weight
learning emerge. These theoretical findings are then corroborated
experimentally by comparing the behaviour of a full transformer on the
simplified distributions to that of the stylized model, demonstrating aligned
results. We then extend the study to a full large language model, showing how
fine-tuning on various collections of natural language prompts can elicit
similar in-context and in-weight learning behaviour.",2024-10-30,"Bryan Chan, Xinyi Chen, András György, Dale Schuurmans",http://arxiv.org/pdf/2410.23042v3,cs.LG
Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation,"Link adaptation (LA) is an essential function in modern wireless
communication systems that dynamically adjusts the transmission rate of a
communication link to match time- and frequency-varying radio link conditions.
However, factors such as user mobility, fast fading, imperfect channel quality
information, and aging of measurements make the modeling of LA challenging. To
bypass the need for explicit modeling, recent research has introduced online
reinforcement learning (RL) approaches as an alternative to the more commonly
used rule-based algorithms. Yet, RL-based approaches face deployment
challenges, as training in live networks can potentially degrade real-time
performance. To address this challenge, this paper considers offline RL as a
candidate to learn LA policies with minimal effects on the network operation.
We propose three LA designs based on batch-constrained deep Q-learning,
conservative Q-learning, and decision transformer. Our results show that
offline RL algorithms can match the performance of state-of-the-art online RL
methods when data is collected with a proper behavioral policy.",2024-10-30,"Samuele Peri, Alessio Russo, Gabor Fodor, Pablo Soldati",http://arxiv.org/pdf/2410.23031v2,cs.LG
Planning and Learning in Risk-Aware Restless Multi-Arm Bandit Problem,"In restless multi-arm bandits, a central agent is tasked with optimally
distributing limited resources across several bandits (arms), with each arm
being a Markov decision process. In this work, we generalize the traditional
restless multi-arm bandit problem with a risk-neutral objective by
incorporating risk-awareness. We establish indexability conditions for the case
of a risk-aware objective and provide a solution based on Whittle index. In
addition, we address the learning problem when the true transition
probabilities are unknown by proposing a Thompson sampling approach and show
that it achieves bounded regret that scales sublinearly with the number of
episodes and quadratically with the number of arms. The efficacy of our method
in reducing risk exposure in restless multi-arm bandits is illustrated through
a set of numerical experiments in the contexts of machine replacement and
patient scheduling applications under both planning and learning setups.",2024-10-30,"Nima Akbarzadeh, Yossiri Adulyasak, Erick Delage",http://arxiv.org/pdf/2410.23029v2,cs.LG
Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback,"Automatically synthesizing dense rewards from natural language descriptions
is a promising paradigm in reinforcement learning (RL), with applications to
sparse reward problems, open-ended exploration, and hierarchical skill design.
Recent works have made promising steps by exploiting the prior knowledge of
large language models (LLMs). However, these approaches suffer from important
limitations: they are either not scalable to problems requiring billions of
environment samples, due to requiring LLM annotations for each observation, or
they require a diverse offline dataset, which may not exist or be impossible to
collect. In this work, we address these limitations through a combination of
algorithmic and systems-level contributions. We propose \oni, a distributed
architecture that simultaneously learns an RL policy and an intrinsic reward
function using LLM feedback. Our approach annotates the agent's collected
experience via an asynchronous LLM server, which is then distilled into an
intrinsic reward model. We explore a range of algorithmic choices for reward
modeling with varying complexity, including hashing, classification, and
ranking models. By studying their relative tradeoffs, we shed light on
questions regarding intrinsic reward design for sparse reward problems. Our
approach achieves state-of-the-art performance across a range of challenging,
sparse reward tasks from the NetHack Learning Environment in a simple unified
process, solely using the agent's gathered experience, without requiring
external datasets. We make our code available at
\url{https://github.com/facebookresearch/oni}.",2024-10-30,"Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos",http://arxiv.org/pdf/2410.23022v2,cs.LG
Scoring Rules and Calibration for Imprecise Probabilities,"What does it mean to say that, for example, the probability for rain tomorrow
is between 20% and 30%? The theory for the evaluation of precise probabilistic
forecasts is well-developed and is grounded in the key concepts of proper
scoring rules and calibration. For the case of imprecise probabilistic
forecasts (sets of probabilities), such theory is still lacking. In this work,
we therefore generalize proper scoring rules and calibration to the imprecise
case. We develop these concepts as relative to data models and decision
problems. As a consequence, the imprecision is embedded in a clear context. We
establish a close link to the paradigm of (group) distributional robustness and
in doing so provide new insights for it. We argue that proper scoring rules and
calibration serve two distinct goals, which are aligned in the precise case,
but intriguingly are not necessarily aligned in the imprecise case. The concept
of decision-theoretic entropy plays a key role for both goals. Finally, we
demonstrate the theoretical insights in machine learning practice, in
particular we illustrate subtle pitfalls relating to the choice of loss
function in distributional robustness.",2024-10-30,"Christian Fröhlich, Robert C. Williamson",http://arxiv.org/pdf/2410.23001v1,cs.LG
VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning,"Although previous research on large language models (LLMs) and large
multi-modal models (LMMs) has systematically explored mathematical
problem-solving (MPS) within visual contexts, the analysis of how these models
process visual information during problem-solving remains insufficient. To
address this gap, we present VisAidMath, a benchmark for evaluating the MPS
process related to visual information. We follow a rigorous data curation
pipeline involving both automated processes and manual annotations to ensure
data quality and reliability. Consequently, this benchmark includes 1,200
challenging problems from various mathematical branches, vision-aid
formulations, and difficulty levels, collected from diverse sources such as
textbooks, examination papers, and Olympiad problems. Based on the proposed
benchmark, we conduct comprehensive evaluations on ten mainstream LLMs and
LMMs, highlighting deficiencies in the visual-aided reasoning process. For
example, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning
task, even with a drop of 2 points when provided with golden visual aids.
In-depth analysis reveals that the main cause of deficiencies lies in
hallucination regarding the implicit visual reasoning process, shedding light
on future research directions in the visual-aided MPS process.",2024-10-30,"Jingkun Ma, Runzhe Zhan, Derek F. Wong, Yang Li, Di Sun, Hou Pong Chan, Lidia S. Chao",http://arxiv.org/pdf/2410.22995v1,cs.LG
Dynamic Matching with Post-allocation Service and its Application to Refugee Resettlement,"Motivated by our collaboration with a major refugee resettlement agency in
the U.S., we study a dynamic matching problem where each new arrival (a refugee
case) must be matched immediately and irrevocably to one of the static
resources (a location with a fixed annual quota). In addition to consuming the
static resource, each case requires post-allocation service from a server, such
as a translator. Given the time-consuming nature of service, a server may not
be available at a given time, thus we refer to it as a dynamic resource. Upon
matching, the case will wait to avail service in a first-come-first-serve
manner. Bursty matching to a location may result in undesirable congestion at
its corresponding server. Consequently, the central planner (the agency) faces
a dynamic matching problem with an objective that combines the matching reward
(captured by pair-specific employment outcomes) with the cost for congestion
for dynamic resources and over-allocation for the static ones. Motivated by the
observed fluctuations in the composition of refugee pools across the years, we
design algorithms that do not rely on distributional knowledge constructed
based on past years' data. To that end, we develop learning-based algorithms
that are asymptotically optimal in certain regimes, easy to interpret, and
computationally fast. Our design is based on learning the dual variables of the
underlying optimization problem; however, the main challenge lies in the
time-varying nature of the dual variables associated with dynamic resources. To
overcome this challenge, our theoretical development brings together techniques
from Lyapunov analysis, adversarial online learning, and stochastic
optimization. On the application side, when tested on real data from our
partner agency, our method outperforms existing ones making it a viable
candidate for replacing the current practice upon experimentation.",2024-10-30,"Kirk Bansak, Soonbong Lee, Vahideh Manshadi, Rad Niazadeh, Elisabeth Paulson",http://arxiv.org/pdf/2410.22992v1,cs.LG
V2X-Assisted Distributed Computing and Control Framework for Connected and Automated Vehicles under Ramp Merging Scenario,"This paper investigates distributed computing and cooperative control of
connected and automated vehicles (CAVs) in ramp merging scenario under
transportation cyber-physical system. Firstly, a centralized cooperative
trajectory planning problem is formulated subject to the safely constraints and
traffic performance in ramp merging scenario, where the trajectories of all
vehicles are jointly optimized. To get rid of the reliance on a central
controller and reduce computation time, a distributed solution to this problem
implemented among CAVs through Vehicles-to-Everything (V2X) communication is
proposed. Unlike existing method, our method can distribute the computational
task among CAVs and carry out parallel solving through V2X communication. Then,
a multi-vehicles model predictive control (MPC) problem aimed at maximizing
system stability and minimizing control input is formulated based on the
solution of the first problem subject to strict safety constants and input
limits. Due to these complex constraints, this problem becomes
high-dimensional, centralized, and non-convex. To solve it in a short time, a
decomposition and convex reformulation method, namely distributed cooperative
iterative model predictive control (DCIMPC), is proposed. This method leverages
the communication capability of CAVs to decompose the problem, making full use
of the computational resources on vehicles to achieve fast solutions and
distributed control. The two above problems with their corresponding solving
methods form the systemic framework of the V2X assisted distributed computing
and control. Simulations have been conducted to evaluate the framework's
convergence, safety, and solving speed. Additionally, extra experiments are
conducted to validate the performance of DCIMPC. The results show that our
method can greatly improve computation speed without sacrificing system
performance.",2024-10-30,"Qiong Wu, Jiahou Chu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief",http://arxiv.org/pdf/2410.22987v1,cs.LG
Higher-order Cross-structural Embedding Model for Time Series Analysis,"Time series analysis has gained significant attention due to its critical
applications in diverse fields such as healthcare, finance, and sensor
networks. The complexity and non-stationarity of time series make it
challenging to capture the interaction patterns across different timestamps.
Current approaches struggle to model higher-order interactions within time
series, and focus on learning temporal or spatial dependencies separately,
which limits performance in downstream tasks. To address these gaps, we propose
Higher-order Cross-structural Embedding Model for Time Series (High-TS), a
novel framework that jointly models both temporal and spatial perspectives by
combining multiscale Transformer with Topological Deep Learning (TDL).
Meanwhile, High-TS utilizes contrastive learning to integrate these two
structures for generating robust and discriminative representations. Extensive
experiments show that High-TS outperforms state-of-the-art methods in various
time series tasks and demonstrate the importance of higher-order
cross-structural information in improving model performance.",2024-10-30,"Guancen Lin, Cong Shen, Aijing Lin",http://arxiv.org/pdf/2410.22984v1,cs.LG
Dual-Optimized Adaptive Graph Reconstruction for Multi-View Graph Clustering,"Multi-view clustering is an important machine learning task for multi-media
data, encompassing various domains such as images, videos, and texts. Moreover,
with the growing abundance of graph data, the significance of multi-view graph
clustering (MVGC) has become evident. Most existing methods focus on graph
neural networks (GNNs) to extract information from both graph structure and
feature data to learn distinguishable node representations. However,
traditional GNNs are designed with the assumption of homophilous graphs, making
them unsuitable for widely prevalent heterophilous graphs. Several techniques
have been introduced to enhance GNNs for heterophilous graphs. While these
methods partially mitigate the heterophilous graph issue, they often neglect
the advantages of traditional GNNs, such as their simplicity, interpretability,
and efficiency. In this paper, we propose a novel multi-view graph clustering
method based on dual-optimized adaptive graph reconstruction, named DOAGC. It
mainly aims to reconstruct the graph structure adapted to traditional GNNs to
deal with heterophilous graph issues while maintaining the advantages of
traditional GNNs. Specifically, we first develop an adaptive graph
reconstruction mechanism that accounts for node correlation and original
structural information. To further optimize the reconstruction graph, we design
a dual optimization strategy and demonstrate the feasibility of our
optimization strategy through mutual information theory. Numerous experiments
demonstrate that DOAGC effectively mitigates the heterophilous graph problem.",2024-10-30,"Zichen Wen, Tianyi Wu, Yazhou Ren, Yawen Ling, Chenhang Cui, Xiaorong Pu, Lifang He",http://arxiv.org/pdf/2410.22983v1,cs.LG
Accelerated AI Inference via Dynamic Execution Methods,"In this paper, we focus on Dynamic Execution techniques that optimize the
computation flow based on input. This aims to identify simpler problems that
can be solved using fewer resources, similar to human cognition. The techniques
discussed include early exit from deep networks, speculative sampling for
language models, and adaptive steps for diffusion models. Experimental results
demonstrate that these dynamic approaches can significantly improve latency and
throughput without compromising quality. When combined with model-based
optimizations, such as quantization, dynamic execution provides a powerful
multi-pronged strategy to optimize AI inference.
  Generative AI requires a large amount of compute resources. This is expected
to grow, and demand for resources in data centers through to the edge is
expected to continue to increase at high rates. We take advantage of existing
research and provide additional innovations for some generative optimizations.
In the case of LLMs, we provide more efficient sampling methods that depend on
the complexity of the data. In the case of diffusion model generation, we
provide a new method that also leverages the difficulty of the input prompt to
predict an optimal early stopping point.
  Therefore, dynamic execution methods are relevant because they add another
dimension of performance optimizations. Performance is critical from a
competitive point of view, but increasing capacity can result in significant
power savings and cost savings. We have provided several integrations of these
techniques into several Intel performance libraries and Huggingface Optimum.
These integrations will make them easier to use and increase the adoption of
these techniques.",2024-10-30,"Haim Barad, Jascha Achterberg, Tien Pei Chou, Jean Yu",http://arxiv.org/pdf/2411.00853v1,cs.LG
DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting,"Multivariate time series forecasting plays a crucial role in various
real-world applications. Significant efforts have been made to integrate
advanced network architectures and training strategies that enhance the capture
of temporal dependencies, thereby improving forecasting accuracy. On the other
hand, mainstream approaches typically utilize a single unified model with
simplistic channel-mixing embedding or cross-channel attention operations to
account for the critical intricate inter-channel dependencies. Moreover, some
methods even trade capacity for robust prediction based on the
channel-independent assumption. Nonetheless, as time series data may display
distinct evolving patterns due to the unique characteristics of each channel
(including multiple strong seasonalities and trend changes), the unified
modeling methods could yield suboptimal results. To this end, we propose
DisenTS, a tailored framework for modeling disentangled channel evolving
patterns in general multivariate time series forecasting. The central idea of
DisenTS is to model the potential diverse patterns within the multivariate time
series data in a decoupled manner. Technically, the framework employs multiple
distinct forecasting models, each tasked with uncovering a unique evolving
pattern. To guide the learning process without supervision of pattern
partition, we introduce a novel Forecaster Aware Gate (FAG) module that
generates the routing signals adaptively according to both the forecasters'
states and input series' characteristics. The forecasters' states are derived
from the Linear Weight Approximation (LWA) strategy, which quantizes the
complex deep neural networks into compact matrices. Additionally, the
Similarity Constraint (SC) is further proposed to guide each model to
specialize in an underlying pattern by minimizing the mutual information
between the representations.",2024-10-30,"Zhiding Liu, Jiqian Yang, Qingyang Mao, Yuze Zhao, Mingyue Cheng, Zhi Li, Qi Liu, Enhong Chen",http://arxiv.org/pdf/2410.22981v1,cs.LG
Graph Integration for Diffusion-Based Manifold Alignment,"Data from individual observations can originate from various sources or
modalities but are often intrinsically linked. Multimodal data integration can
enrich information content compared to single-source data. Manifold alignment
is a form of data integration that seeks a shared, underlying low-dimensional
representation of multiple data sources that emphasizes similarities between
alternative representations of the same entities. Semi-supervised manifold
alignment relies on partially known correspondences between domains, either
through shared features or through other known associations. In this paper, we
introduce two semi-supervised manifold alignment methods. The first method,
Shortest Paths on the Union of Domains (SPUD), forms a unified graph structure
using known correspondences to establish graph edges. By learning inter-domain
geodesic distances, SPUD creates a global, multi-domain structure. The second
method, MASH (Manifold Alignment via Stochastic Hopping), learns local geometry
within each domain and forms a joint diffusion operator using known
correspondences to iteratively learn new inter-domain correspondences through a
random-walk approach. Through the diffusion process, MASH forms a coupling
matrix that links heterogeneous domains into a unified structure. We compare
SPUD and MASH with existing semi-supervised manifold alignment methods and show
that they outperform competing methods in aligning true correspondences and
cross-domain classification. In addition, we show how these methods can be
applied to transfer label information between domains.",2024-10-30,"Jake S. Rhodes, Adam G. Rustad",http://arxiv.org/pdf/2410.22978v1,cs.LG
Adaptive NAD: Online and Self-adaptive Unsupervised Network Anomaly Detector,"The widespread usage of the Internet of Things (IoT) has raised the risks of
cyber threats, thus developing Anomaly Detection Systems (ADSs) that can adapt
to evolving or new attacks is critical. Previous studies primarily focused on
offline unsupervised learning methods to safeguard ADSs, which is not
applicable in practical real-world applications. Besides, most of them strongly
rely on assumptions of known legitimates and fail to satisfy the interpretable
requirements in security applications, creating barriers to the adoption in
practice. In this paper, we design Adaptive NAD, a general framework to improve
and interpret online unsupervised anomaly detection in security domains. An
interpretable two-layer anomaly detection strategy is proposed to generate
reliable high-confidence pseudo-labels. Then, an online learning scheme is
introduced to update Adaptive NAD by a novel threshold calculation technique to
adapt to new threats. Experimental results demonstrate that Adaptive NAD
achieves more than 5.4%, 23.0%, and 3.2% improvements in SPAUC compared with
state-of-the-art solutions on the CIC-Darknet2020, CIC-DoHBrw-2020, and
Edge-IIoTset datasets, respectively. The code is released at
https://github.com/MyLearnCodeSpace/Adaptive-NAD.",2024-10-30,"Yachao Yuan, Yu Huang, Yali Yuan, Jin Wang",http://arxiv.org/pdf/2410.22967v3,cs.LG
Scalable Sampling for High Utility Patterns,"Discovering valuable insights from data through meaningful associations is a
crucial task. However, it becomes challenging when trying to identify
representative patterns in quantitative databases, especially with large
datasets, as enumeration-based strategies struggle due to the vast search space
involved. To tackle this challenge, output space sampling methods have emerged
as a promising solution thanks to its ability to discover valuable patterns
with reduced computational overhead. However, existing sampling methods often
encounter limitations when dealing with large quantitative database, resulting
in scalability-related challenges. In this work, we propose a novel high
utility pattern sampling algorithm and its on-disk version both designed for
large quantitative databases based on two original theorems. Our approach
ensures both the interactivity required for user-centered methods and strong
statistical guarantees through random sampling. Thanks to our method, users can
instantly discover relevant and representative utility pattern, facilitating
efficient exploration of the database within seconds. To demonstrate the
interest of our approach, we present a compelling use case involving
archaeological knowledge graph sub-profiles discovery. Experiments on semantic
and none-semantic quantitative databases show that our approach outperforms the
state-of-the art methods.",2024-10-30,"Lamine Diop, Marc Plantevit",http://arxiv.org/pdf/2410.22964v1,cs.LG
A Study of Secure Algorithms for Vertical Federated Learning: Take Secure Logistic Regression as an Example,"After entering the era of big data, more and more companies build services
with machine learning techniques. However, it is costly for companies to
collect data and extract helpful handcraft features on their own. Although it
is a way to combine with other companies' data for boosting the model's
performance, this approach may be prohibited by laws. In other words, finding
the balance between sharing data with others and keeping data from privacy
leakage is a crucial topic worthy of close attention. This paper focuses on
distributed data and conducts secure model training tasks on a vertical
federated learning scheme. Here, secure implies that the whole process is
executed in the encrypted domain. Therefore, the privacy concern is released.",2024-10-30,"Huan-Chih Wang, Ja-Ling Wu",http://arxiv.org/pdf/2410.22960v1,cs.LG
Retrieval-Augmented Generation with Estimation of Source Reliability,"Retrieval-augmented generation (RAG) addresses key limitations of large
language models (LLMs), such as hallucinations and outdated knowledge, by
incorporating external databases. These databases typically consult multiple
sources to encompass up-to-date and various information. However, standard RAG
methods often overlook the heterogeneous source reliability in the multi-source
database and retrieve documents solely based on relevance, making them prone to
propagating misinformation. To address this, we propose Reliability-Aware RAG
(RA-RAG) which estimates the reliability of multiple sources and incorporates
this information into both retrieval and aggregation processes. Specifically,
it iteratively estimates source reliability and true answers for a set of
queries with no labelling. Then, it selectively retrieves relevant documents
from a few of reliable sources and aggregates them using weighted majority
voting, where the selective retrieval ensures scalability while not
compromising the performance. We also introduce a benchmark designed to reflect
real-world scenarios with heterogeneous source reliability and demonstrate the
effectiveness of RA-RAG compared to a set of baselines.",2024-10-30,"Jeongyeon Hwang, Junyoung Park, Hyejin Park, Sangdon Park, Jungseul Ok",http://arxiv.org/pdf/2410.22954v2,cs.LG
SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry,"Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.",2024-10-30,"Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra",http://arxiv.org/pdf/2410.22950v1,cs.LG
MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering,"Studying protein mutations within amino acid sequences holds tremendous
significance in life sciences. Protein language models (PLMs) have demonstrated
strong capabilities in broad biological applications. However, due to
architectural design and lack of supervision, PLMs model mutations implicitly
with evolutionary plausibility, which is not satisfactory to serve as
explainable and engineerable tools in real-world studies. To address these
issues, we present MutaPLM, a unified framework for interpreting and navigating
protein mutations with protein language models. MutaPLM introduces a protein
delta network that captures explicit protein mutation representations within a
unified feature space, and a transfer learning pipeline with a chain-of-thought
(CoT) strategy to harvest protein mutation knowledge from biomedical texts. We
also construct MutaDescribe, the first large-scale protein mutation dataset
with rich textual annotations, which provides cross-modal supervision signals.
Through comprehensive experiments, we demonstrate that MutaPLM excels at
providing human-understandable explanations for mutational effects and
prioritizing novel mutations with desirable properties. Our code, model, and
data are open-sourced at https://github.com/PharMolix/MutaPLM.",2024-10-30,"Yizhen Luo, Zikun Nie, Massimo Hong, Suyuan Zhao, Hao Zhou, Zaiqing Nie",http://arxiv.org/pdf/2410.22949v1,cs.LG
ELBOing Stein: Variational Bayes with Stein Mixture Inference,"Stein variational gradient descent (SVGD) [Liu and Wang, 2016] performs
approximate Bayesian inference by representing the posterior with a set of
particles. However, SVGD suffers from variance collapse, i.e. poor predictions
due to underestimating uncertainty [Ba et al., 2021], even for
moderately-dimensional models such as small Bayesian neural networks (BNNs). To
address this issue, we generalize SVGD by letting each particle parameterize a
component distribution in a mixture model. Our method, Stein Mixture Inference
(SMI), optimizes a lower bound to the evidence (ELBO) and introduces
user-specified guides parameterized by particles. SMI extends the Nonlinear
SVGD framework [Wang and Liu, 2019] to the case of variational Bayes. SMI
effectively avoids variance collapse, judging by a previously described test
developed for this purpose, and performs well on standard data sets. In
addition, SMI requires considerably fewer particles than SVGD to accurately
estimate uncertainty for small BNNs. The synergistic combination of NSVGD, ELBO
optimization and user-specified guides establishes a promising approach towards
variational Bayesian inference in the case of tall and wide data.",2024-10-30,"Ola Rønning, Eric Nalisnick, Christophe Ley, Padhraic Smyth, Thomas Hamelryck",http://arxiv.org/pdf/2410.22948v2,cs.LG
KALAM: toolKit for Automating high-Level synthesis of Analog computing systeMs,"Diverse computing paradigms have emerged to meet the growing needs for
intelligent energy-efficient systems. The Margin Propagation (MP) framework,
being one such initiative in the analog computing domain, stands out due to its
scalability across biasing conditions, temperatures, and diminishing process
technology nodes. However, the lack of digital-like automation tools for
designing analog systems (including that of MP analog) hinders their adoption
for designing large systems. The inherent scalability and modularity of MP
systems present a unique opportunity in this regard. This paper introduces
KALAM (toolKit for Automating high-Level synthesis of Analog computing
systeMs), which leverages factor graphs as the foundational paradigm for
synthesizing MP-based analog computing systems. Factor graphs are the basis of
various signal processing tasks and, when coupled with MP, can be used to
design scalable and energy-efficient analog signal processors. Using Python
scripting language, the KALAM automation flow translates an input factor graph
to its equivalent SPICE-compatible circuit netlist that can be used to validate
the intended functionality. KALAM also allows the integration of design
optimization strategies such as precision tuning, variable elimination, and
mathematical simplification. We demonstrate KALAM's versatility for tasks such
as Bayesian inference, Low-Density Parity Check (LDPC) decoding, and Artificial
Neural Networks (ANN). Simulation results of the netlists align closely with
software implementations, affirming the efficacy of our proposed automation
tool.",2024-10-30,"Ankita Nandi, Krishil Gandhi, Mahendra Pratap Singh, Shantanu Chakrabartty, Chetan Singh Thakur",http://arxiv.org/pdf/2410.22946v1,cs.LG
"Focus On This, Not That! Steering LLMs With Adaptive Feature Specification","Despite the success of Instruction Tuning (IT) in training large language
models (LLMs) to perform arbitrary user-specified tasks, these models often
still leverage spurious or biased features learned from their training data,
leading to undesired behaviours when deploying them in new contexts. In this
work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to
condition their responses by focusing on specific features whilst ignoring
others, leading to different behaviours based on what features are specified.
Across several experimental settings, we show that focus-tuned models can be
adaptively steered by focusing on different features at inference-time: for
instance, robustness can be improved by focusing on task-causal features and
ignoring spurious features, and social bias can be mitigated by ignoring
demographic categories. Furthermore, FIT can steer behaviour in new contexts,
generalising under distribution shift and to new unseen features at inference
time, and thereby facilitating more robust, fair, and controllable LLM
applications in real-world environments.",2024-10-30,"Tom A. Lamb, Adam Davies, Alasdair Paren, Philip H. S. Torr, Francesco Pinto",http://arxiv.org/pdf/2410.22944v3,cs.LG
DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data,"The application of reinforcement learning in traffic signal control (TSC) has
been extensively researched and yielded notable achievements. However, most
existing works for TSC assume that traffic data from all surrounding
intersections is fully and continuously available through sensors. In
real-world applications, this assumption often fails due to sensor malfunctions
or data loss, making TSC with missing data a critical challenge. To meet the
needs of practical applications, we introduce DiffLight, a novel conditional
diffusion model for TSC under data-missing scenarios in the offline setting.
Specifically, we integrate two essential sub-tasks, i.e., traffic data
imputation and decision-making, by leveraging a Partial Rewards Conditioned
Diffusion (PRCD) model to prevent missing rewards from interfering with the
learning process. Meanwhile, to effectively capture the spatial-temporal
dependencies among intersections, we design a Spatial-Temporal transFormer
(STFormer) architecture. In addition, we propose a Diffusion Communication
Mechanism (DCM) to promote better communication and control performance under
data-missing scenarios. Extensive experiments on five datasets with various
data-missing scenarios demonstrate that DiffLight is an effective controller to
address TSC with missing data. The code of DiffLight is released at
https://github.com/lokol5579/DiffLight-release.",2024-10-30,"Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan",http://arxiv.org/pdf/2410.22938v2,cs.LG
An Individual Identity-Driven Framework for Animal Re-Identification,"Reliable re-identification of individuals within large wildlife populations
is crucial for biological studies, ecological research, and wildlife
conservation. Classic computer vision techniques offer a promising direction
for Animal Re-identification (Animal ReID), but their backbones' close-set
nature limits their applicability and generalizability. Despite the
demonstrated effectiveness of vision-language models like CLIP in
re-identifying persons and vehicles, their application to Animal ReID remains
limited due to unique challenges, such as the various visual representations of
animals, including variations in poses and forms. To address these limitations,
we leverage CLIP's cross-modal capabilities to introduce a two-stage framework,
the \textbf{Indiv}idual \textbf{A}nimal \textbf{ID}entity-Driven (IndivAID)
framework, specifically designed for Animal ReID. In the first stage, IndivAID
trains a text description generator by extracting individual semantic
information from each image, generating both image-specific and
individual-specific textual descriptions that fully capture the diverse visual
concepts of each individual across animal images. In the second stage, IndivAID
refines its learning of visual concepts by dynamically incorporating
individual-specific textual descriptions with an integrated attention module to
further highlight discriminative features of individuals for Animal ReID.
Evaluation against state-of-the-art methods across eight benchmark datasets and
a real-world Stoat dataset demonstrates IndivAID's effectiveness and
applicability. Code is available at \url{https://github.com/ywu840/IndivAID}.",2024-10-30,"Yihao Wu, Di Zhao, Jingfeng Zhang, Yun Sing Koh",http://arxiv.org/pdf/2410.22927v1,cs.LG
"EF-LLM: Energy Forecasting LLM with AI-assisted Automation, Enhanced Sparse Prediction, Hallucination Detection","Accurate prediction helps to achieve supply-demand balance in energy systems,
supporting decision-making and scheduling. Traditional models, lacking
AI-assisted automation, rely on experts, incur high costs, and struggle with
sparse data prediction. To address these challenges, we propose the Energy
Forecasting Large Language Model (EF-LLM), which integrates domain knowledge
and temporal data for time-series forecasting, supporting both pre-forecast
operations and post-forecast decision-support. EF-LLM's human-AI interaction
capabilities lower the entry barrier in forecasting tasks, reducing the need
for extra expert involvement. To achieve this, we propose a continual learning
approach with updatable LoRA and a multi-channel architecture for aligning
heterogeneous multimodal data, enabling EF-LLM to continually learn
heterogeneous multimodal knowledge. In addition, EF-LLM enables accurate
predictions under sparse data conditions through its ability to process
multimodal data. We propose Fusion Parameter-Efficient Fine-Tuning (F-PEFT)
method to effectively leverage both time-series data and text for this purpose.
EF-LLM is also the first energy-specific LLM to detect hallucinations and
quantify their occurrence rate, achieved via multi-task learning, semantic
similarity analysis, and ANOVA. We have achieved success in energy prediction
scenarios for load, photovoltaic, and wind power forecast.",2024-10-30,"Zihang Qiu, Chaojie Li, Zhongyang Wang, Renyou Xie, Borui Zhang, Huadong Mo, Guo Chen, Zhaoyang Dong",http://arxiv.org/pdf/2411.00852v2,cs.LG
Automatic feature selection and weighting in molecular systems using Differentiable Information Imbalance,"Feature selection is essential in the analysis of molecular systems and many
other fields, but several uncertainties remain: What is the optimal number of
features for a simplified, interpretable model that retains essential
information? How should features with different units be aligned, and how
should their relative importance be weighted? Here, we introduce the
Differentiable Information Imbalance (DII), an automated method to rank
information content between sets of features. Using distances in a ground truth
feature space, DII identifies a low-dimensional subset of features that best
preserves these relationships. Each feature is scaled by a weight, which is
optimized by minimizing the DII through gradient descent. This allows
simultaneously performing unit alignment and relative importance scaling, while
preserving interpretability. DII can also produce sparse solutions and
determine the optimal size of the reduced feature space. We demonstrate the
usefulness of this approach on two benchmark molecular problems: (1)
identifying collective variables that describe conformations of a biomolecule,
and (2) selecting features for training a machine-learning force field. These
results show the potential of DII in addressing feature selection challenges
and optimizing dimensionality in various applications. The method is available
in the Python library DADApy.",2024-10-30,"Romina Wild, Felix Wodaczek, Vittorio Del Tatto, Bingqing Cheng, Alessandro Laio",http://arxiv.org/pdf/2411.00851v2,cs.LG
Simulation-Free Training of Neural ODEs on Paired Data,"In this work, we investigate a method for simulation-free training of Neural
Ordinary Differential Equations (NODEs) for learning deterministic mappings
between paired data. Despite the analogy of NODEs as continuous-depth residual
networks, their application in typical supervised learning tasks has not been
popular, mainly due to the large number of function evaluations required by ODE
solvers and numerical instability in gradient estimation. To alleviate this
problem, we employ the flow matching framework for simulation-free training of
NODEs, which directly regresses the parameterized dynamics function to a
predefined target velocity field. Contrary to generative tasks, however, we
show that applying flow matching directly between paired data can often lead to
an ill-defined flow that breaks the coupling of the data pairs (e.g., due to
crossing trajectories). We propose a simple extension that applies flow
matching in the embedding space of data pairs, where the embeddings are learned
jointly with the dynamic function to ensure the validity of the flow which is
also easier to learn. We demonstrate the effectiveness of our method on both
regression and classification tasks, where our method outperforms existing
NODEs with a significantly lower number of function evaluations. The code is
available at https://github.com/seminkim/simulation-free-node.",2024-10-30,"Semin Kim, Jaehoon Yoo, Jinwoo Kim, Yeonwoo Cha, Saehoon Kim, Seunghoon Hong",http://arxiv.org/pdf/2410.22918v1,cs.LG
GWQ: Gradient-Aware Weight Quantization for Large Language Models,"Large language models (LLMs) show impressive performance in solving complex
language tasks. However, its large number of parameters presents significant
challenges for the deployment. So, compressing LLMs to low bits can enable to
deploy on resource-constrained devices. To address this problem, we propose
gradient-aware weight quantization (GWQ), the first quantization approach for
low-bit weight quantization that leverages gradients to localize outliers,
requiring only a minimal amount of calibration data for outlier detection. GWQ
retains the top 1\% outliers preferentially at FP16 precision, while the
remaining non-outlier weights are stored in a low-bit. We widely evaluate GWQ
on different task include language modeling, grounding detection, massive
multitask language understanding and vision-language question and answering.
Results show that models quantified by GWQ performs better than other
quantization method. During quantization process, GWQ only need one calibration
set to realize effective quant. Also, GWQ achieves 1.2x inference speedup in
comparison to the original model and effectively reduces the inference memory.",2024-10-30,"Yihua Shao, Yan Gu, Siyu Chen, Haiyang Liu, Zijian Ling, Minxi Yan, Ziyang Yan, Chenyu Zhang, Michele Magno, Haotong Qin, Yan Wang, Jingcai Guo, Ling Shao, Hao Tang",http://arxiv.org/pdf/2411.00850v3,cs.LG
Self-optimization in distributed manufacturing systems using Modular State-based Stackelberg Games,"In this study, we introduce Modular State-based Stackelberg Games (Mod-SbSG),
a novel game structure developed for distributed self-learning in modular
manufacturing systems. Mod-SbSG enhances cooperative decision-making among
self-learning agents within production systems by integrating State-based
Potential Games (SbPG) with Stackelberg games. This hierarchical structure
assigns more important modules of the manufacturing system a first-mover
advantage, while less important modules respond optimally to the leaders'
decisions. This decision-making process differs from typical multi-agent
learning algorithms in manufacturing systems, where decisions are made
simultaneously. We provide convergence guarantees for the novel game structure
and design learning algorithms to account for the hierarchical game structure.
We further analyse the effects of single-leader/multiple-follower and
multiple-leader/multiple-follower scenarios within a Mod-SbSG. To assess its
effectiveness, we implement and test Mod-SbSG in an industrial control setting
using two laboratory-scale testbeds featuring sequential and serial-parallel
processes. The proposed approach delivers promising results compared to the
vanilla SbPG, which reduces overflow by 97.1%, and in some cases, prevents
overflow entirely. Additionally, it decreases power consumption by 5-13% while
satisfying the production demand, which significantly improves potential
(global objective) values.",2024-10-30,"Steve Yuwono, Ahmar Kamal Hussain, Dorothea Schwung, Andreas Schwung",http://arxiv.org/pdf/2410.22912v1,cs.LG
CopRA: A Progressive LoRA Training Strategy,"Low-Rank Adaptation (LoRA) is a parameter-efficient technique for rapidly
fine-tuning foundation models. In standard LoRA training dynamics, models tend
to quickly converge to a local optimum near the initialization. However, this
local optimum may not be ideal for out-of-distribution data or tasks such as
merging and pruning. In this work, we propose a novel progressive training
strategy for LoRA with random layer dropping. This strategy also optimizes the
Shapley value of LoRA parameters in each layer, treating each layer as a player
in a cooperative game. We refer to this method as Cooperative LoRA (CopRA). Our
experimental results demonstrate that parameters trained with CopRA exhibit
linear mode connectivity, which enables efficient model merging. This also
paves the way for federated learning and multi-task learning via LoRA merging.
Additionally, by optimizing the Shapley value, CopRA shows superior performance
in pruning tasks.",2024-10-30,"Zhan Zhuang, Xiequn Wang, Yulong Zhang, Wei Li, Yu Zhang, Ying Wei",http://arxiv.org/pdf/2410.22911v1,cs.LG
Federated UCBVI: Communication-Efficient Federated Regret Minimization with Heterogeneous Agents,"In this paper, we present the Federated Upper Confidence Bound Value
Iteration algorithm ($\texttt{Fed-UCBVI}$), a novel extension of the
$\texttt{UCBVI}$ algorithm (Azar et al., 2017) tailored for the federated
learning framework. We prove that the regret of $\texttt{Fed-UCBVI}$ scales as
$\tilde{\mathcal{O}}(\sqrt{H^3 |\mathcal{S}| |\mathcal{A}| T / M})$, with a
small additional term due to heterogeneity, where $|\mathcal{S}|$ is the number
of states, $|\mathcal{A}|$ is the number of actions, $H$ is the episode length,
$M$ is the number of agents, and $T$ is the number of episodes. Notably, in the
single-agent setting, this upper bound matches the minimax lower bound up to
polylogarithmic factors, while in the multi-agent scenario,
$\texttt{Fed-UCBVI}$ has linear speed-up. To conduct our analysis, we introduce
a new measure of heterogeneity, which may hold independent theoretical
interest. Furthermore, we show that, unlike existing federated reinforcement
learning approaches, $\texttt{Fed-UCBVI}$'s communication complexity only
marginally increases with the number of agents.",2024-10-30,"Safwan Labbi, Daniil Tiapkin, Lorenzo Mancini, Paul Mangold, Eric Moulines",http://arxiv.org/pdf/2410.22908v1,cs.LG
VPO: Leveraging the Number of Votes in Preference Optimization,"Direct Preference Optimization (DPO) trains a language model using human
preference data, bypassing the explicit reward modeling phase of Reinforcement
Learning from Human Feedback (RLHF). By iterating over sentence pairs in a
preference dataset, DPO enhances generation quality by increasing the
likelihood of producing preferred sentences over less favored ones. Preference
datasets are typically created by selecting preferred sentences through a
voting process involving multiple individuals, as opinions can vary due to the
subjective nature of human preferences. While the number of votes offers
insight into whether a sentence pair is clearly preferable or controversial,
current methods do not fully leverage this information. In this paper, we
introduce a technique that leverages user voting data to better align with
diverse subjective preferences. We employ the Bayesian Minimum Mean Square
Error (Bayesian MMSE) estimator to model the probability that one generation is
preferable to another. Using this estimated probability as a target, we develop
the Vote-based Preference Optimization (VPO) framework, which incorporates the
number of votes on both sides to distinguish between controversial and obvious
generation pairs. We show that previous algorithms, such as DPO and Identity
Preference Optimization (IPO), can be extended using the proposed framework,
termed VDPO and VIPO. Our experiments demonstrate that these proposed
algorithms outperform various existing methods, including their base
algorithms.",2024-10-30,"Jae Hyeon Cho, Minkyung Park, Byung-Jun Lee",http://arxiv.org/pdf/2410.22891v1,cs.LG
Generalization Bounds via Conditional $f$-Information,"In this work, we introduce novel information-theoretic generalization bounds
using the conditional $f$-information framework, an extension of the
traditional conditional mutual information (MI) framework. We provide a generic
approach to derive generalization bounds via $f$-information in the supersample
setting, applicable to both bounded and unbounded loss functions. Unlike
previous MI-based bounds, our proof strategy does not rely on upper bounding
the cumulant-generating function (CGF) in the variational formula of MI.
Instead, we set the CGF or its upper bound to zero by carefully selecting the
measurable function invoked in the variational formula. Although some of our
techniques are partially inspired by recent advances in the coin-betting
framework (e.g., Jang et al. (2023)), our results are independent of any
previous findings from regret guarantees of online gambling algorithms.
Additionally, our newly derived MI-based bound recovers many previous results
and improves our understanding of their potential limitations. Finally, we
empirically compare various $f$-information measures for generalization,
demonstrating the improvement of our new bounds over the previous bounds.",2024-10-30,"Ziqiao Wang, Yongyi Mao",http://arxiv.org/pdf/2410.22887v1,cs.LG
Stealing User Prompts from Mixture of Experts,"Mixture-of-Experts (MoE) models improve the efficiency and scalability of
dense language models by routing each token to a small number of experts in
each layer. In this paper, we show how an adversary that can arrange for their
queries to appear in the same batch of examples as a victim's queries can
exploit Expert-Choice-Routing to fully disclose a victim's prompt. We
successfully demonstrate the effectiveness of this attack on a two-layer
Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA
implementation. Our results show that we can extract the entire prompt using
$O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100
queries on average per token in the setting we consider. This is the first
attack to exploit architectural flaws for the purpose of extracting user
prompts, introducing a new class of LLM vulnerabilities.",2024-10-30,"Itay Yona, Ilia Shumailov, Jamie Hayes, Nicholas Carlini",http://arxiv.org/pdf/2410.22884v1,cs.LG
Data subsampling for Poisson regression with pth-root-link,"We develop and analyze data subsampling techniques for Poisson regression,
the standard model for count data $y\in\mathbb{N}$. In particular, we consider
the Poisson generalized linear model with ID- and square root-link functions.
We consider the method of coresets, which are small weighted subsets that
approximate the loss function of Poisson regression up to a factor of
$1\pm\varepsilon$. We show $\Omega(n)$ lower bounds against coresets for
Poisson regression that continue to hold against arbitrary data reduction
techniques up to logarithmic factors. By introducing a novel complexity
parameter and a domain shifting approach, we show that sublinear coresets with
$1\pm\varepsilon$ approximation guarantee exist when the complexity parameter
is small. In particular, the dependence on the number of input points can be
reduced to polylogarithmic. We show that the dependence on other input
parameters can also be bounded sublinearly, though not always logarithmically.
In particular, we show that the square root-link admits an $O(\log(y_{\max}))$
dependence, where $y_{\max}$ denotes the largest count presented in the data,
while the ID-link requires a $\Theta(\sqrt{y_{\max}/\log(y_{\max})})$
dependence. As an auxiliary result for proving the tightness of the bound with
respect to $y_{\max}$ in the case of the ID-link, we show an improved bound on
the principal branch of the Lambert $W_0$ function, which may be of independent
interest. We further show the limitations of our analysis when $p$th degree
root-link functions for $p\geq 3$ are considered, which indicate that other
analytical or computational methods would be required if such a generalization
is even possible.",2024-10-30,"Han Cheng Lie, Alexander Munteanu",http://arxiv.org/pdf/2410.22872v1,cs.LG
Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions,"Particle collisions at accelerators such as the Large Hadron Collider,
recorded and analyzed by experiments such as ATLAS and CMS, enable exquisite
measurements of the Standard Model and searches for new phenomena. Simulations
of collision events at these detectors have played a pivotal role in shaping
the design of future experiments and analyzing ongoing ones. However, the quest
for accuracy in Large Hadron Collider (LHC) collisions comes at an imposing
computational cost, with projections estimating the need for millions of
CPU-years annually during the High Luminosity LHC (HL-LHC) run
\cite{collaboration2022atlas}. Simulating a single LHC event with
\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of
the calorimeter subdetectors in particular imposing substantial computational
demands \cite{rousseau2023experimental}. To address this challenge, we propose
a conditioned quantum-assisted deep generative model. Our model integrates a
conditioned variational autoencoder (VAE) on the exterior with a conditioned
Restricted Boltzmann Machine (RBM) in the latent space, providing enhanced
expressiveness compared to conventional VAEs. The RBM nodes and connections are
meticulously engineered to enable the use of qubits and couplers on D-Wave's
Pegasus-structured \textit{Advantage} quantum annealer (QA) for sampling. We
introduce a novel method for conditioning the quantum-assisted RBM using
\textit{flux biases}. We further propose a novel adaptive mapping to estimate
the effective inverse temperature in quantum annealers. The effectiveness of
our framework is illustrated using Dataset 2 of the CaloChallenge
\cite{calochallenge}.",2024-10-30,"J. Quetzalcoatl Toledo-Marin, Sebastian Gonzalez, Hao Jia, Ian Lu, Deniz Sogutlu, Abhishek Abhishek, Colin Gay, Eric Paquet, Roger Melko, Geoffrey C. Fox, Maximilian Swiatlowski, Wojciech Fedorko",http://arxiv.org/pdf/2410.22870v5,cs.LG
Towards Population Scale Testis Volume Segmentation in DIXON MRI,"Testis size is known to be one of the main predictors of male fertility,
usually assessed in clinical workup via palpation or imaging. Despite its
potential, population-level evaluation of testicular volume using imaging
remains underexplored. Previous studies, limited by small and biased datasets,
have demonstrated the feasibility of machine learning for testis volume
segmentation. This paper presents an evaluation of segmentation methods for
testicular volume using Magnet Resonance Imaging data from the UKBiobank. The
best model achieves a median dice score of $0.87$, compared to median dice
score of $0.83$ for human interrater reliability on the same dataset, enabling
large-scale annotation on a population scale for the first time. Our overall
aim is to provide a trained model, comparative baseline methods, and annotated
training data to enhance accessibility and reproducibility in testis MRI
segmentation research.",2024-10-30,"Jan Ernsting, Phillip Nikolas Beeken, Lynn Ogoniak, Jacqueline Kockwelp, Tim Hahn, Alexander Siegfried Busch, Benjamin Risse",http://arxiv.org/pdf/2410.22866v1,cs.LG
AtGCN: A Graph Convolutional Network For Ataxic Gait Detection,"Video-based gait analysis can be defined as the task of diagnosing
pathologies, such as ataxia, using videos of patients walking in front of a
camera. This paper presents a graph convolution network called AtGCN for
detecting ataxic gait and identifying its severity using 2D videos. The problem
is especially challenging as the deviation of an ataxic gait from a healthy
gait is very subtle. The datasets for ataxic gait detection are also quite
small, with the largest dataset having only 149 videos. The paper addresses the
first problem using special spatiotemporal graph convolution that successfully
captures important gait-related features. To handle the small dataset size, a
deep spatiotemporal graph convolution network pre-trained on an action
recognition dataset is systematically truncated and then fine-tuned on the
ataxia dataset to obtain the AtGCN model. The paper also presents an
augmentation strategy that segments a video sequence into multiple gait cycles.
The proposed AtGCN model then operates on a graph of body part locations
belonging to a single gait cycle. The evaluation results support the strength
of the proposed AtGCN model, as it outperforms the state-of-the-art in
detection and severity prediction with an accuracy of 93.46% and a MAE of
0.4169, respectively.",2024-10-30,"Karan Bania, Tanmay Verlekar",http://arxiv.org/pdf/2410.22862v1,cs.LG
Hyperparameter Optimization in Machine Learning,"Hyperparameters are configuration variables controlling the behavior of
machine learning algorithms. They are ubiquitous in machine learning and
artificial intelligence and the choice of their values determines the
effectiveness of systems based on these technologies. Manual hyperparameter
search is often unsatisfactory and becomes infeasible when the number of
hyperparameters is large. Automating the search is an important step towards
advancing, streamlining, and systematizing machine learning, freeing
researchers and practitioners alike from the burden of finding a good set of
hyperparameters by trial and error. In this survey, we present a unified
treatment of hyperparameter optimization, providing the reader with examples,
insights into the state-of-the-art, and numerous links to further reading. We
cover the main families of techniques to automate hyperparameter search, often
referred to as hyperparameter optimization or tuning, including random and
quasi-random search, bandit-, model-, population-, and gradient-based
approaches. We further discuss extensions, including online, constrained, and
multi-objective formulations, touch upon connections with other fields such as
meta-learning and neural architecture search, and conclude with open questions
and future research directions.",2024-10-30,"Luca Franceschi, Michele Donini, Valerio Perrone, Aaron Klein, Cédric Archambeau, Matthias Seeger, Massimiliano Pontil, Paolo Frasconi",http://arxiv.org/pdf/2410.22854v2,cs.LG
Dataset of polarimetric images of mechanically generated water surface waves coupled with surface elevation records by wave gauges linear array,"Effective spatio-temporal measurements of water surface elevation (water
waves) in laboratory experiments are essential for scientific and engineering
research. Existing techniques are often cumbersome, computationally heavy and
generally suffer from limited wavenumber/frequency response. To address these
challenges a novel method was developed, using polarization filter equipped
camera as the main sensor and Machine Learning (ML) algorithms for data
processing [1,2]. The developed method training and evaluation was based on
in-house made supervised dataset. Here we present this supervised dataset of
polarimetric images of the water surface coupled with the water surface
elevation measurements made by a linear array of resistance-type wave gauges
(WG). The water waves were mechanically generated in a laboratory waves basin,
and the polarimetric images were captured under an artificial light source.
Meticulous camera and WGs calibration and instruments synchronization supported
high spatio-temporal resolution. The data set covers several wavefield
conditions, from simple monochromatic wave trains of various steepness, to
irregular wavefield of JONSWAP prescribed spectral shape and several wave
breaking scenarios. The dataset contains measurements repeated in several
camera positions relative to the wave field propagation direction.",2024-10-30,"Noam Ginio, Michael Lindenbaum, Barak Fishbain, Dan Liberzon",http://arxiv.org/pdf/2410.22849v1,cs.LG
Danoliteracy of Generative Large Language Models,"The language technology moonshot moment of Generative Large Language Models
(GLLMs) was not limited to English: These models brought a surge of
technological applications, investments, and hype to low-resource languages as
well. However, the capabilities of these models in languages such as Danish
were, until recently, difficult to verify beyond qualitative demonstrations due
to a lack of applicable evaluation corpora. We present a GLLM benchmark to
evaluate \emph{Danoliteracy}, a measure of Danish language and cultural
competency across eight diverse scenarios such as Danish citizenship tests and
abstractive social media question answering. This limited-size benchmark was
found to produce a robust ranking that correlates to human feedback at $\rho
\sim 0.8$ with GPT-4 and Claude Opus models achieving the highest rankings.
Analyzing these model results across scenarios, we find one strong underlying
factor explaining $95\%$ of scenario performance variance for GLLMs in Danish,
suggesting a $g$ factor of model consistency in language adaptation.",2024-10-30,"Søren Vejlgaard Holm, Lars Kai Hansen, Martin Carsten Nielsen",http://arxiv.org/pdf/2410.22839v2,cs.LG
Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients,"Federated fine-tuning for Large Language Models (LLMs) has recently gained
attention due to the heavy communication overhead of transmitting large model
updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its
application in federated learning is complicated by discordance in aggregation.
Existing methods addressing this discordance often suffer from performance
degradation at low ranks in heterogeneous data settings. In response, we
introduce LoRA-A2 (Low Rank Adaptation with Alternating freeze and Adaptive
rank selection), which demonstrates robustness in challenging settings with low
ranks and high data heterogeneity. Our experimental findings reveal that
LoRA-A2 maintains performance even under extreme heterogeneity and low rank
conditions, achieving up to a 99.8% reduction in uploaded parameters compared
to full fine-tuning without compromising performance. This adaptive mechanism
boosts robustness and communication efficiency in federated fine-tuning,
enabling the practical deployment of LLMs in resource-constrained environments.",2024-10-30,"Jabin Koo, Minwoo Jang, Jungseul Ok",http://arxiv.org/pdf/2410.22815v1,cs.LG
Universality of the $π^2/6$ Pathway in Avoiding Model Collapse,"Researchers in empirical machine learning recently spotlighted their fears of
so-called Model Collapse. They imagined a discard workflow, where an initial
generative model is trained with real data, after which the real data are
discarded, and subsequently, the model generates synthetic data on which a new
model is trained. They came to the conclusion that models degenerate as
model-fitting generations proceed. However, other researchers considered an
augment workflow, where the original real data continue to be used in each
generation of training, augmented by synthetic data from models fit in all
earlier generations. Empirical results on canonical datasets and learning
procedures confirmed the occurrence of model collapse under the discard
workflow and avoidance of model collapse under the augment workflow. Under the
augment workflow, theoretical evidence also confirmed avoidance in particular
instances; specifically, Gerstgrasser et al. (2024) found that for classical
Linear Regression, test risk at any later generation is bounded by a moderate
multiple, viz. pi-squared-over-6 of the test risk of training with the original
real data alone. Some commentators questioned the generality of theoretical
conclusions based on the generative model assumed in Gerstgrasser et al.
(2024): could similar conclusions be reached for other task/model pairings? In
this work, we demonstrate the universality of the pi-squared-over-6 augment
risk bound across a large family of canonical statistical models, offering key
insights into exactly why collapse happens under the discard workflow and is
avoided under the augment workflow. In the process, we provide a framework that
is able to accommodate a large variety of workflows (beyond discard and
augment), thereby enabling an experimenter to judge the comparative merits of
multiple different workflows by simulating a simple Gaussian process.",2024-10-30,"Apratim Dey, David Donoho",http://arxiv.org/pdf/2410.22812v1,cs.LG
MILP-StuDio: MILP Instance Generation via Block Structure Decomposition,"Mixed-integer linear programming (MILP) is one of the most popular
mathematical formulations with numerous applications. In practice, improving
the performance of MILP solvers often requires a large amount of high-quality
data, which can be challenging to collect. Researchers thus turn to generation
techniques to generate additional MILP instances. However, existing approaches
do not take into account specific block structures -- which are closely related
to the problem formulations -- in the constraint coefficient matrices (CCMs) of
MILPs. Consequently, they are prone to generate computationally trivial or
infeasible instances due to the disruptions of block structures and thus
problem formulations. To address this challenge, we propose a novel MILP
generation framework, called Block Structure Decomposition (MILP-StuDio), to
generate high-quality instances by preserving the block structures.
Specifically, MILP-StuDio begins by identifying the blocks in CCMs and
decomposing the instances into block units, which serve as the building blocks
of MILP instances. We then design three operators to construct new instances by
removing, substituting, and appending block units in the original instances,
enabling us to generate instances with flexible sizes. An appealing feature of
MILP-StuDio is its strong ability to preserve the feasibility and computational
hardness of the generated instances. Experiments on the commonly-used
benchmarks demonstrate that using instances generated by MILP-StuDio is able to
significantly reduce over 10% of the solving time for learning-based solvers.",2024-10-30,"Haoyang Liu, Jie Wang, Wanbo Zhang, Zijie Geng, Yufei Kuang, Xijun Li, Bin Li, Yongdong Zhang, Feng Wu",http://arxiv.org/pdf/2410.22806v2,cs.LG
Run-Time Adaptation of Neural Beamforming for Robust Speech Dereverberation and Denoising,"This paper describes speech enhancement for realtime automatic speech
recognition (ASR) in real environments. A standard approach to this task is to
use neural beamforming that can work efficiently in an online manner. It
estimates the masks of clean dry speech from a noisy echoic mixture spectrogram
with a deep neural network (DNN) and then computes a enhancement filter used
for beamforming. The performance of such a supervised approach, however, is
drastically degraded under mismatched conditions. This calls for run-time
adaptation of the DNN. Although the ground-truth speech spectrogram required
for adaptation is not available at run time, blind dereverberation and
separation methods such as weighted prediction error (WPE) and fast
multichannel nonnegative matrix factorization (FastMNMF) can be used for
generating pseudo groundtruth data from a mixture. Based on this idea, a prior
work proposed a dual-process system based on a cascade of WPE and minimum
variance distortionless response (MVDR) beamforming asynchronously fine-tuned
by block-online FastMNMF. To integrate the dereverberation capability into
neural beamforming and make it fine-tunable at run time, we propose to use
weighted power minimization distortionless response (WPD) beamforming, a
unified version of WPE and minimum power distortionless response (MPDR), whose
joint dereverberation and denoising filter is estimated using a DNN. We
evaluated the impact of run-time adaptation under various conditions with
different numbers of speakers, reverberation times, and signal-to-noise ratios
(SNRs).",2024-10-30,"Yoto Fujita, Aditya Arie Nugraha, Diego Di Carlo, Yoshiaki Bando, Mathieu Fontaine, Kazuyoshi Yoshii",http://arxiv.org/pdf/2410.22805v1,cs.LG
DOA-Aware Audio-Visual Self-Supervised Learning for Sound Event Localization and Detection,"This paper describes sound event localization and detection (SELD) for
spatial audio recordings captured by firstorder ambisonics (FOA) microphones.
In this task, one may train a deep neural network (DNN) using FOA data
annotated with the classes and directions of arrival (DOAs) of sound events.
However, the performance of this approach is severely bounded by the amount of
annotated data. To overcome this limitation, we propose a novel method of
pretraining the feature extraction part of the DNN in a self-supervised manner.
We use spatial audio-visual recordings abundantly available as virtual reality
contents. Assuming that sound objects are concurrently observed by the FOA
microphones and the omni-directional camera, we jointly train audio and visual
encoders with contrastive learning such that the audio and visual embeddings of
the same recording and DOA are made close. A key feature of our method is that
the DOA-wise audio embeddings are jointly extracted from the raw audio data,
while the DOA-wise visual embeddings are separately extracted from the local
visual crops centered on the corresponding DOA. This encourages the latent
features of the audio encoder to represent both the classes and DOAs of sound
events. The experiment using the DCASE2022 Task 3 dataset of 20 hours shows
non-annotated audio-visual recordings of 100 hours reduced the error score of
SELD from 36.4 pts to 34.9 pts.",2024-10-30,"Yoto Fujita, Yoshiaki Bando, Keisuke Imoto, Masaki Onishi, Kazuyoshi Yoshii",http://arxiv.org/pdf/2410.22803v1,cs.LG
Machine Learning Nonadiabatic Dynamics: Eliminating Phase Freedom of Nonadiabatic Couplings with the State-Intraction State-Averaged Spin-Restricted Ensemble-Referenced Kohn-Sham Approach,"Excited-state molecular dynamics (ESMD) simulations near conical
intersections (CIs) pose significant challenges when using machine learning
potentials (MLPs). Although MLPs have gained recognition for their integration
into mixed quantum-classical (MQC) methods, such as trajectory surface hopping
(TSH), and their capacity to model correlated electron-nuclear dynamics
efficiently, difficulties persist in managing nonadiabatic dynamics.
Specifically, singularities at CIs and double-valued coupling elements result
in discontinuities that disrupt the smoothness of predictive functions. Partial
solutions have been provided by learning diabatic Hamiltonians with phaseless
loss functions to these challenges. However, a definitive method for addressing
the discontinuities caused by CIs and double-valued coupling elements has yet
to be developed. Here, we introduce the phaseless coupling term, $\Delta^2$,
derived from the square of the off-diagonal elements of the diabatic
Hamiltonian in the state-interaction state-averaged spin-restricted
ensemble-referenced Kohn-Sham (SI-SA-REKS, briefly SSR)(2,2) formalism. This
approach improves the stability and accuracy of the MLP model by addressing the
issues arising from CI singularities and double-valued coupling functions. We
apply this method to the penta-2,4-dieniminium cation (PSB3), demonstrating its
effectiveness in improving MLP training for ML-based nonadiabatic dynamics. Our
results show that the $\Delta^2$ based ML-ESMD method can reproduce ab initio
ESMD simulations, underscoring its potential and efficiency for broader
applications, particularly in large-scale and long-timescale ESMD simulations.",2024-10-30,"Sung Wook Moon, Soohaeng Yoo Willow, Tae Hyeon Park, Seung Kyu Min, Chang Woo Myung",http://arxiv.org/pdf/2410.22801v2,cs.LG
Solving Differential Equations with Constrained Learning,"(Partial) differential equations (PDEs) are fundamental tools for describing
natural phenomena, making their solution crucial in science and engineering.
While traditional methods, such as the finite element method, provide reliable
solutions, their accuracy is often tied to the use of computationally intensive
fine meshes. Moreover, they do not naturally account for measurements or prior
solutions, and any change in the problem parameters requires results to be
fully recomputed. Neural network-based approaches, such as physics-informed
neural networks and neural operators, offer a mesh-free alternative by directly
fitting those models to the PDE solution. They can also integrate prior
knowledge and tackle entire families of PDEs by simply aggregating additional
training losses. Nevertheless, they are highly sensitive to hyperparameters
such as collocation points and the weights associated with each loss. This
paper addresses these challenges by developing a science-constrained learning
(SCL) framework. It demonstrates that finding a (weak) solution of a PDE is
equivalent to solving a constrained learning problem with worst-case losses.
This explains the limitations of previous methods that minimize the expected
value of aggregated losses. SCL also organically integrates structural
constraints (e.g., invariances) and (partial) measurements or known solutions.
The resulting constrained learning problems can be tackled using a practical
algorithm that yields accurate solutions across a variety of PDEs, neural
network architectures, and prior knowledge levels without extensive
hyperparameter tuning and sometimes even at a lower computational cost.",2024-10-30,"Viggo Moro, Luiz F. O. Chamon",http://arxiv.org/pdf/2410.22796v2,cs.LG
Theoretical Investigations and Practical Enhancements on Tail Task Risk Minimization in Meta Learning,"Meta learning is a promising paradigm in the era of large models and task
distributional robustness has become an indispensable consideration in
real-world scenarios. Recent advances have examined the effectiveness of tail
task risk minimization in fast adaptation robustness improvement
\citep{wang2023simple}. This work contributes to more theoretical
investigations and practical enhancements in the field. Specifically, we reduce
the distributionally robust strategy to a max-min optimization problem,
constitute the Stackelberg equilibrium as the solution concept, and estimate
the convergence rate. In the presence of tail risk, we further derive the
generalization bound, establish connections with estimated quantiles, and
practically improve the studied strategy. Accordingly, extensive evaluations
demonstrate the significance of our proposal and its scalability to multimodal
large models in boosting robustness.",2024-10-30,"Yiqin Lv, Qi Wang, Dong Liang, Zheng Xie",http://arxiv.org/pdf/2410.22788v1,cs.LG
Contrastive Learning and Adversarial Disentanglement for Task-Oriented Semantic Communications,"Task-oriented semantic communication systems have emerged as a promising
approach to achieving efficient and intelligent data transmission, where only
information relevant to a specific task is communicated. However, existing
methods struggle to fully disentangle task-relevant and task-irrelevant
information, leading to privacy concerns and subpar performance. To address
this, we propose an information-bottleneck method, named CLAD (contrastive
learning and adversarial disentanglement). CLAD utilizes contrastive learning
to effectively capture task-relevant features while employing adversarial
disentanglement to discard task-irrelevant information. Additionally, due to
the lack of reliable and reproducible methods to gain insight into the
informativeness and minimality of the encoded feature vectors, we introduce a
new technique to compute the information retention index (IRI), a comparative
metric used as a proxy for the mutual information between the encoded features
and the input, reflecting the minimality of the encoded features. The IRI
quantifies the minimality and informativeness of the encoded feature vectors
across different task-oriented communication techniques. Our extensive
experiments demonstrate that CLAD outperforms state-of-the-art baselines in
terms of semantic extraction, task performance, privacy preservation, and IRI.
CLAD achieves a predictive performance improvement of around 2.5-3%, along with
a 77-90% reduction in IRI and a 57-76% decrease in adversarial attribute
inference attack accuracy.",2024-10-30,"Omar Erak, Omar Alhussein, Wen Tong",http://arxiv.org/pdf/2410.22784v2,cs.LG
Rule by Rule: Learning with Confidence through Vocabulary Expansion,"In this paper, we present an innovative iterative approach to rule learning
specifically designed for (but not limited to) text-based data. Our method
focuses on progressively expanding the vocabulary utilized in each iteration
resulting in a significant reduction of memory consumption. Moreover, we
introduce a Value of Confidence as an indicator of the reliability of the
generated rules. By leveraging the Value of Confidence, our approach ensures
that only the most robust and trustworthy rules are retained, thereby improving
the overall quality of the rule learning process. We demonstrate the
effectiveness of our method through extensive experiments on various textual as
well as non-textual datasets including a use case of significant interest to
insurance industries, showcasing its potential for real-world applications.",2024-10-30,"Albert Nössig, Tobias Hell, Georg Moser",http://arxiv.org/pdf/2411.00049v1,cs.LG
MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning,"Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have significantly
improved the adaptation of LLMs to downstream tasks in a resource-efficient
manner. However, in multi-task scenarios, challenges such as training imbalance
and the seesaw effect frequently emerge. Mixture-of-LoRA (MoLoRA), which
combines LoRA with sparse Mixture-of-Experts, mitigates some of these issues by
promoting task-specific learning across experts. Despite this, MoLoRA remains
inefficient in terms of training speed, parameter utilization, and overall
multi-task performance. In this paper, we propose Mixture of Asymmetric
Low-Rank Adaptaion (MALoRA), a flexible fine-tuning framework that leverages
asymmetric optimization across LoRA experts. MALoRA reduces the number of
trainable parameters by 30% to 48%, increases training speed by 1.2x, and
matches the computational efficiency of single-task LoRA models. Additionally,
MALoRA addresses overfitting issues commonly seen in high-rank configurations,
enhancing performance stability. Extensive experiments across diverse
multi-task learning scenarios demonstrate that MALoRA consistently outperforms
all baseline methods in both inter-domain and intra-domain tasks.",2024-10-30,"Xujia Wang, Haiyan Zhao, Shuo Wang, Hanqing Wang, Zhiyuan Liu",http://arxiv.org/pdf/2410.22782v1,cs.LG
Unfolding Target Detection with State Space Model,"Target detection is a fundamental task in radar sensing, serving as the
precursor to any further processing for various applications. Numerous
detection algorithms have been proposed. Classical methods based on signal
processing, e.g., the most widely used CFAR, are challenging to tune and
sensitive to environmental conditions. Deep learning-based methods can be more
accurate and robust, yet usually lack interpretability and physical relevance.
In this paper, we introduce a novel method that combines signal processing and
deep learning by unfolding the CFAR detector with a state space model
architecture. By reserving the CFAR pipeline yet turning its sophisticated
configurations into trainable parameters, our method achieves high detection
performance without manual parameter tuning, while preserving model
interpretability. We implement a lightweight model of only 260K parameters and
conduct real-world experiments for human target detection using FMCW radars.
The results highlight the remarkable performance of the proposed method,
outperforming CFAR and its variants by 10X in detection rate and false alarm
rate. Our code is open-sourced here: https://github.com/aiot-lab/NeuroDet.",2024-10-30,"Luca Jiang-Tao Yu, Chenshu Wu",http://arxiv.org/pdf/2410.22774v1,cs.LG
An Overview of Causal Inference using Kernel Embeddings,"Kernel embeddings have emerged as a powerful tool for representing
probability measures in a variety of statistical inference problems. By mapping
probability measures into a reproducing kernel Hilbert space (RKHS), kernel
embeddings enable flexible representations of complex relationships between
variables. They serve as a mechanism for efficiently transferring the
representation of a distribution downstream to other tasks, such as hypothesis
testing or causal effect estimation. In the context of causal inference, the
main challenges include identifying causal associations and estimating the
average treatment effect from observational data, where confounding variables
may obscure direct cause-and-effect relationships. Kernel embeddings provide a
robust nonparametric framework for addressing these challenges. They allow for
the representations of distributions of observational data and their seamless
transformation into representations of interventional distributions to estimate
relevant causal quantities. We overview recent research that leverages the
expressiveness of kernel embeddings in tandem with causal inference.",2024-10-30,Dino Sejdinovic,http://arxiv.org/pdf/2410.22754v1,cs.LG
Understanding Aggregations of Proper Learners in Multiclass Classification,"Multiclass learnability is known to exhibit a properness barrier: there are
learnable classes which cannot be learned by any proper learner. Binary
classification faces no such barrier for learnability, but a similar one for
optimal learning, which can in general only be achieved by improper learners.
Fortunately, recent advances in binary classification have demonstrated that
this requirement can be satisfied using aggregations of proper learners, some
of which are strikingly simple. This raises a natural question: to what extent
can simple aggregations of proper learners overcome the properness barrier in
multiclass classification?
  We give a positive answer to this question for classes which have finite
Graph dimension, $d_G$. Namely, we demonstrate that the optimal binary learners
of Hanneke, Larsen, and Aden-Ali et al. (appropriately generalized to the
multiclass setting) achieve sample complexity $O\left(\frac{d_G + \ln(1 /
\delta)}{\epsilon}\right)$. This forms a strict improvement upon the sample
complexity of ERM. We complement this with a lower bound demonstrating that for
certain classes of Graph dimension $d_G$, majorities of ERM learners require
$\Omega \left( \frac{d_G + \ln(1 / \delta)}{\epsilon}\right)$ samples.
Furthermore, we show that a single ERM requires $\Omega \left(\frac{d_G \ln(1 /
\epsilon) + \ln(1 / \delta)}{\epsilon}\right)$ samples on such classes,
exceeding the lower bound of Daniely et al. (2015) by a factor of $\ln(1 /
\epsilon)$. For multiclass learning in full generality -- i.e., for classes of
finite DS dimension but possibly infinite Graph dimension -- we give a strong
refutation to these learning strategies, by exhibiting a learnable class which
cannot be learned to constant error by any aggregation of a finite number of
proper learners.",2024-10-30,"Julian Asilis, Mikael Møller Høgsgaard, Grigoris Velegkas",http://arxiv.org/pdf/2410.22749v1,cs.LG
Explainable Artificial Intelligence for Dependent Features: Additive Effects of Collinearity,"Explainable Artificial Intelligence (XAI) emerged to reveal the internal
mechanism of machine learning models and how the features affect the prediction
outcome. Collinearity is one of the big issues that XAI methods face when
identifying the most informative features in the model. Current XAI approaches
assume the features in the models are independent and calculate the effect of
each feature toward model prediction independently from the rest of the
features. However, such assumption is not realistic in real life applications.
We propose an Additive Effects of Collinearity (AEC) as a novel XAI method that
aim to considers the collinearity issue when it models the effect of each
feature in the model on the outcome. AEC is based on the idea of dividing
multivariate models into several univariate models in order to examine their
impact on each other and consequently on the outcome. The proposed method is
implemented using simulated and real data to validate its efficiency comparing
with the a state of arts XAI method. The results indicate that AEC is more
robust and stable against the impact of collinearity when it explains AI models
compared with the state of arts XAI method.",2024-10-30,Ahmed M Salih,http://arxiv.org/pdf/2411.00846v1,cs.LG
Beyond Current Boundaries: Integrating Deep Learning and AlphaFold for Enhanced Protein Structure Prediction from Low-Resolution Cryo-EM Maps,"Constructing atomic models from cryo-electron microscopy (cryo-EM) maps is a
crucial yet intricate task in structural biology. While advancements in deep
learning, such as convolutional neural networks (CNNs) and graph neural
networks (GNNs), have spurred the development of sophisticated map-to-model
tools like DeepTracer and ModelAngelo, their efficacy notably diminishes with
low-resolution maps beyond 4 {\AA}. To address this shortfall, our research
introduces DeepTracer-LowResEnhance, an innovative framework that synergizes a
deep learning-enhanced map refinement technique with the power of AlphaFold.
This methodology is designed to markedly improve the construction of models
from low-resolution cryo-EM maps. DeepTracer-LowResEnhance was rigorously
tested on a set of 37 protein cryo-EM maps, with resolutions ranging between
2.5 to 8.4 {\AA}, including 22 maps with resolutions lower than 4 {\AA}. The
outcomes were compelling, demonstrating that 95.5\% of the low-resolution maps
exhibited a significant uptick in the count of total predicted residues. This
denotes a pronounced improvement in atomic model building for low-resolution
maps. Additionally, a comparative analysis alongside Phenix's auto-sharpening
functionality delineates DeepTracer-LowResEnhance's superior capability in
rendering more detailed and precise atomic models, thereby pushing the
boundaries of current computational structural biology methodologies.",2024-10-30,"Xin, Ma, Dong Si",http://arxiv.org/pdf/2410.23321v1,cs.LG
Residual Multi-Task Learner for Applied Ranking,"Modern e-commerce platforms rely heavily on modeling diverse user feedback to
provide personalized services. Consequently, multi-task learning has become an
integral part of their ranking systems. However, existing multi-task learning
methods encounter two main challenges: some lack explicit modeling of task
relationships, resulting in inferior performance, while others have limited
applicability due to being computationally intensive, having scalability
issues, or relying on strong assumptions. To address these limitations and
better fit our real-world scenario, pre-rank in Shopee Search, we introduce in
this paper ResFlow, a lightweight multi-task learning framework that enables
efficient cross-task information sharing via residual connections between
corresponding layers of task networks. Extensive experiments on datasets from
various scenarios and modalities demonstrate its superior performance and
adaptability over state-of-the-art methods. The online A/B tests in Shopee
Search showcase its practical value in large-scale industrial applications,
evidenced by a 1.29% increase in OPU (order-per-user) without additional system
latency. ResFlow is now fully deployed in the pre-rank module of Shopee Search.
To facilitate efficient online deployment, we propose a novel offline metric
Weighted Recall@K, which aligns well with our online metric OPU, addressing the
longstanding online-offline metric misalignment issue. Besides, we propose to
fuse scores from the multiple tasks additively when ranking items, which
outperforms traditional multiplicative fusion. The code is released at
https://github.com/BrunoTruthAlliance/ResFlow",2024-10-30,"Cong Fu, Kun Wang, Jiahua Wu, Yizhou Chen, Guangda Huzhang, Yabo Ni, Anxiang Zeng, Zhiming Zhou",http://arxiv.org/pdf/2411.09705v1,cs.LG
MIXAD: Memory-Induced Explainable Time Series Anomaly Detection,"For modern industrial applications, accurately detecting and diagnosing
anomalies in multivariate time series data is essential. Despite such need,
most state-of-the-art methods often prioritize detection performance over model
interpretability. Addressing this gap, we introduce MIXAD (Memory-Induced
Explainable Time Series Anomaly Detection), a model designed for interpretable
anomaly detection. MIXAD leverages a memory network alongside spatiotemporal
processing units to understand the intricate dynamics and topological
structures inherent in sensor relationships. We also introduce a novel anomaly
scoring method that detects significant shifts in memory activation patterns
during anomalies. Our approach not only ensures decent detection performance
but also outperforms state-of-the-art baselines by 34.30% and 34.51% in
interpretability metrics.",2024-10-30,"Minha Kim, Kishor Kumar Bhaumik, Amin Ahsan Ali, Simon S. Woo",http://arxiv.org/pdf/2410.22735v1,cs.LG
Extensional Properties of Recurrent Neural Networks,"A property of a recurrent neural network (RNN) is called \emph{extensional}
if, loosely speaking, it is a property of the function computed by the RNN
rather than a property of the RNN algorithm. Many properties of interest in
RNNs are extensional, for example, robustness against small changes of input or
good clustering of inputs. Given an RNN, it is natural to ask whether it has
such a property. We give a negative answer to the general question about
testing extensional properties of RNNs. Namely, we prove a version of Rice's
theorem for RNNs: any nontrivial extensional property of RNNs is undecidable.",2024-10-30,"Evgeny Dantsin, Alexander Wolpert",http://arxiv.org/pdf/2410.22730v1,cs.LG
"Identifying Drift, Diffusion, and Causal Structure from Temporal Snapshots","Stochastic differential equations (SDEs) are a fundamental tool for modelling
dynamic processes, including gene regulatory networks (GRNs), contaminant
transport, financial markets, and image generation. However, learning the
underlying SDE from data is a challenging task, especially if individual
trajectories are not observable. Motivated by burgeoning research in
single-cell datasets, we present the first comprehensive approach for jointly
identifying the drift and diffusion of an SDE from its temporal marginals.
Assuming linear drift and additive diffusion, we prove that these parameters
are identifiable from marginals if and only if the initial distribution lacks
any generalized rotational symmetries. We further prove that the causal graph
of any SDE with additive diffusion can be recovered from the SDE parameters. To
complement this theory, we adapt entropy-regularized optimal transport to
handle anisotropic diffusion, and introduce APPEX (Alternating Projection
Parameter Estimation from $X_0$), an iterative algorithm designed to estimate
the drift, diffusion, and causal graph of an additive noise SDE, solely from
temporal marginals. We show that APPEX iteratively decreases Kullback-Leibler
divergence to the true solution, and demonstrate its effectiveness on simulated
data from linear additive noise SDEs.",2024-10-30,"Vincent Guan, Joseph Janssen, Hossein Rahmani, Andrew Warren, Stephen Zhang, Elina Robeva, Geoffrey Schiebinger",http://arxiv.org/pdf/2410.22729v2,cs.LG
Offline Behavior Distillation,"Massive reinforcement learning (RL) data are typically collected to train
policies offline without the need for interactions, but the large data volume
can cause training inefficiencies. To tackle this issue, we formulate offline
behavior distillation (OBD), which synthesizes limited expert behavioral data
from sub-optimal RL data, enabling rapid policy learning. We propose two naive
OBD objectives, DBC and PBC, which measure distillation performance via the
decision difference between policies trained on distilled data and either
offline data or a near-expert policy. Due to intractable bi-level optimization,
the OBD objective is difficult to minimize to small values, which deteriorates
PBC by its distillation performance guarantee with quadratic discount
complexity $\mathcal{O}(1/(1-\gamma)^2)$. We theoretically establish the
equivalence between the policy performance and action-value weighted decision
difference, and introduce action-value weighted PBC (Av-PBC) as a more
effective OBD objective. By optimizing the weighted decision difference, Av-PBC
achieves a superior distillation guarantee with linear discount complexity
$\mathcal{O}(1/(1-\gamma))$. Extensive experiments on multiple D4RL datasets
reveal that Av-PBC offers significant improvements in OBD performance, fast
distillation convergence speed, and robust cross-architecture/optimizer
generalization.",2024-10-30,"Shiye Lei, Sen Zhang, Dacheng Tao",http://arxiv.org/pdf/2410.22728v1,cs.LG
End-to-end Graph Learning Approach for Cognitive Diagnosis of Student Tutorial,"Cognitive diagnosis (CD) utilizes students' existing studying records to
estimate their mastery of unknown knowledge concepts, which is vital for
evaluating their learning abilities. Accurate CD is extremely challenging
because CD is associated with complex relationships and mechanisms among
students, knowledge concepts, studying records, etc. However, existing
approaches loosely consider these relationships and mechanisms by a
non-end-to-end learning framework, resulting in sub-optimal feature extractions
and fusions for CD. Different from them, this paper innovatively proposes an
End-to-end Graph Neural Networks-based Cognitive Diagnosis (EGNN-CD) model.
EGNN-CD consists of three main parts: knowledge concept network (KCN), graph
neural networks-based feature extraction (GNNFE), and cognitive ability
prediction (CAP). First, KCN constructs CD-related interaction by
comprehensively extracting physical information from students, exercises, and
knowledge concepts. Second, a four-channel GNNFE is designed to extract
high-order and individual features from the constructed KCN. Finally, CAP
employs a multi-layer perceptron to fuse the extracted features to predict
students' learning abilities in an end-to-end learning way. With such designs,
the feature extractions and fusions are guaranteed to be comprehensive and
optimal for CD. Extensive experiments on three real datasets demonstrate that
our EGNN-CD achieves significantly higher accuracy than state-of-the-art models
in CD.",2024-10-30,"Fulai Yang, Di Wu, Yi He, Li Tao, Xin Luo",http://arxiv.org/pdf/2411.00845v1,cs.LG
Enhancing binary classification: A new stacking method via leveraging computational geometry,"Stacking, a potent ensemble learning method, leverages a meta-model to
harness the strengths of multiple base models, thereby enhancing prediction
accuracy. Traditional stacking techniques typically utilize established
learning models, such as logistic regression, as the meta-model. This paper
introduces a novel approach that integrates computational geometry techniques,
specifically solving the maximum weighted rectangle problem, to develop a new
meta-model for binary classification. Our method is evaluated on multiple open
datasets, with statistical analysis showing its stability and demonstrating
improvements in accuracy compared to current state-of-the-art stacking methods
with out-of-fold predictions. This new stacking method also boasts two
significant advantages: enhanced interpretability and the elimination of
hyperparameter tuning for the meta-model, thus increasing its practicality.
These merits make our method highly applicable not only in stacking ensemble
learning but also in various real-world applications, such as hospital health
evaluation scoring and bank credit scoring systems, offering a fresh evaluation
perspective.",2024-10-30,"Wei Wu, Liang Tang, Zhongjie Zhao, Chung-Piaw Teo",http://arxiv.org/pdf/2410.22722v1,cs.LG
Community search signatures as foundation features for human-centered geospatial modeling,"Aggregated relative search frequencies offer a unique composite signal
reflecting people's habits, concerns, interests, intents, and general
information needs, which are not found in other readily available datasets.
Temporal search trends have been successfully used in time series modeling
across a variety of domains such as infectious diseases, unemployment rates,
and retail sales. However, most existing applications require curating
specialized datasets of individual keywords, queries, or query clusters, and
the search data need to be temporally aligned with the outcome variable of
interest. We propose a novel approach for generating an aggregated and
anonymized representation of search interest as foundation features at the
community level for geospatial modeling. We benchmark these features using
spatial datasets across multiple domains. In zip codes with a population
greater than 3000 that cover over 95% of the contiguous US population, our
models for predicting missing values in a 20% set of holdout counties achieve
an average $R^2$ score of 0.74 across 21 health variables, and 0.80 across 6
demographic and environmental variables. Our results demonstrate that these
search features can be used for spatial predictions without strict temporal
alignment, and that the resulting models outperform spatial interpolation and
state of the art methods using satellite imagery features.",2024-10-30,"Mimi Sun, Chaitanya Kamath, Mohit Agarwal, Arbaaz Muslim, Hector Yee, David Schottlander, Shailesh Bavadekar, Niv Efron, Shravya Shetty, Gautam Prasad",http://arxiv.org/pdf/2410.22721v1,cs.LG
Exactly Minimax-Optimal Locally Differentially Private Sampling,"The sampling problem under local differential privacy has recently been
studied with potential applications to generative models, but a fundamental
analysis of its privacy-utility trade-off (PUT) remains incomplete. In this
work, we define the fundamental PUT of private sampling in the minimax sense,
using the f-divergence between original and sampling distributions as the
utility measure. We characterize the exact PUT for both finite and continuous
data spaces under some mild conditions on the data distributions, and propose
sampling mechanisms that are universally optimal for all f-divergences. Our
numerical experiments demonstrate the superiority of our mechanisms over
baselines, in terms of theoretical utilities for finite data space and of
empirical utilities for continuous data space.",2024-10-30,"Hyun-Young Park, Shahab Asoodeh, Si-Hyeon Lee",http://arxiv.org/pdf/2410.22699v1,cs.LG
An Iterative Algorithm for Regularized Non-negative Matrix Factorizations,"We generalize the non-negative matrix factorization algorithm of Lee and
Seung to accept a weighted norm, and to support ridge and Lasso regularization.
We recast the Lee and Seung multiplicative update as an additive update which
does not get stuck on zero values. We apply the companion R package rnnmf to
the problem of finding a reduced rank representation of a database of
cocktails.",2024-10-30,Steven E. Pav,http://arxiv.org/pdf/2410.22698v1,cs.LG
MassiveGNN: Efficient Training via Prefetching for Massively Connected Distributed Graphs,"Graph Neural Networks (GNN) are indispensable in learning from
graph-structured data, yet their rising computational costs, especially on
massively connected graphs, pose significant challenges in terms of execution
performance. To tackle this, distributed-memory solutions such as partitioning
the graph to concurrently train multiple replicas of GNNs are in practice.
However, approaches requiring a partitioned graph usually suffer from
communication overhead and load imbalance, even under optimal partitioning and
communication strategies due to irregularities in the neighborhood minibatch
sampling.
  This paper proposes practical trade-offs for improving the sampling and
communication overheads for representation learning on distributed graphs
(using popular GraphSAGE architecture) by developing a parameterized continuous
prefetch and eviction scheme on top of the state-of-the-art Amazon DistDGL
distributed GNN framework, demonstrating about 15-40% improvement in end-to-end
training performance on the National Energy Research Scientific Computing
Center's (NERSC) Perlmutter supercomputer for various OGB datasets.",2024-10-30,"Aishwarya Sarkar, Sayan Ghosh, Nathan R. Tallent, Ali Jannesari",http://arxiv.org/pdf/2410.22697v2,cs.LG
Permutation Invariant Learning with High-Dimensional Particle Filters,"Sequential learning in deep models often suffers from challenges such as
catastrophic forgetting and loss of plasticity, largely due to the permutation
dependence of gradient-based algorithms, where the order of training data
impacts the learning outcome. In this work, we introduce a novel
permutation-invariant learning framework based on high-dimensional particle
filters. We theoretically demonstrate that particle filters are invariant to
the sequential ordering of training minibatches or tasks, offering a principled
solution to mitigate catastrophic forgetting and loss-of-plasticity. We develop
an efficient particle filter for optimizing high-dimensional models, combining
the strengths of Bayesian methods with gradient-based optimization. Through
extensive experiments on continual supervised and reinforcement learning
benchmarks, including SplitMNIST, SplitCIFAR100, and ProcGen, we empirically
show that our method consistently improves performance, while reducing variance
compared to standard baselines.",2024-10-30,"Akhilan Boopathy, Aneesh Muppidi, Peggy Yang, Abhiram Iyer, William Yue, Ila Fiete",http://arxiv.org/pdf/2410.22695v1,cs.LG
A Comprehensive Study on Quantization Techniques for Large Language Models,"Large Language Models (LLMs) have been extensively researched and used in
both academia and industry since the rise in popularity of the Transformer
model, which demonstrates excellent performance in AI. However, the
computational demands of LLMs are immense, and the energy resources required to
run them are often limited. For instance, popular models like GPT-3, with 175
billion parameters and a storage requirement of 350 GB, present significant
challenges for deployment on resource-constrained IoT devices and embedded
systems. These systems often lack the computational capacity to handle such
large models. Quantization, a technique that reduces the precision of model
values to a smaller set of discrete values, offers a promising solution by
reducing the size of LLMs and accelerating inference. In this research, we
provide a comprehensive analysis of quantization techniques within the machine
learning field, with a particular focus on their application to LLMs. We begin
by exploring the mathematical theory of quantization, followed by a review of
common quantization methods and how they are implemented. Furthermore, we
examine several prominent quantization methods applied to LLMs, detailing their
algorithms and performance outcomes.",2024-10-30,"Jiedong Lang, Zhehao Guo, Shuyu Huang",http://arxiv.org/pdf/2411.02530v1,cs.LG
Choice Between Partial Trajectories: Disentangling Goals from Beliefs,"As AI agents generate increasingly sophisticated behaviors, manually encoding
human preferences to guide these agents becomes more challenging. To address
this, it has been suggested that agents instead learn preferences from human
choice data. This approach requires a model of choice behavior that the agent
can use to interpret the data. For choices between partial trajectories of
states and actions, previous models assume choice probabilities are determined
by the partial return or the cumulative advantage.
  We consider an alternative model based instead on the bootstrapped return,
which adds to the partial return an estimate of the future return. Benefits of
the bootstrapped return model stem from its treatment of human beliefs. Unlike
partial return, choices based on bootstrapped return reflect human beliefs
about the environment. Further, while recovering the reward function from
choices based on cumulative advantage requires that those beliefs are correct,
doing so from choices based on bootstrapped return does not.
  To motivate the bootstrapped return model, we formulate axioms and prove an
Alignment Theorem. This result formalizes how, for a general class of
preferences, such models are able to disentangle goals from beliefs. This
ensures recovery of an aligned reward function when learning from choices based
on bootstrapped return.
  The bootstrapped return model also affords greater robustness to choice
behavior. Even when choices are based on partial return, learning via a
bootstrapped return model recovers an aligned reward function. The same holds
with choices based on the cumulative advantage if the human and the agent both
adhere to correct and consistent beliefs about the environment. On the other
hand, if choices are based on bootstrapped return, learning via partial return
or cumulative advantage models does not generally produce an aligned reward
function.",2024-10-30,"Henrik Marklund, Benjamin Van Roy",http://arxiv.org/pdf/2410.22690v3,cs.LG
Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings,"Accurately quantifying uncertainty in large language models (LLMs) is crucial
for their reliable deployment, especially in high-stakes applications. Current
state-of-the-art methods for measuring semantic uncertainty in LLMs rely on
strict bidirectional entailment criteria between multiple generated responses
and also depend on sequence likelihoods. While effective, these approaches
often overestimate uncertainty due to their sensitivity to minor wording
differences, additional correct information, and non-important words in the
sequence. We propose a novel approach that leverages semantic embeddings to
achieve smoother and more robust estimation of semantic uncertainty in LLMs. By
capturing semantic similarities without depending on sequence likelihoods, our
method inherently reduces any biases introduced by irrelevant words in the
answers. Furthermore, we introduce an amortised version of our approach by
explicitly modelling semantics as latent variables in a joint probabilistic
model. This allows for uncertainty estimation in the embedding space with a
single forward pass, significantly reducing computational overhead compared to
existing multi-pass methods. Experiments across multiple question-answering
datasets and frontier LLMs demonstrate that our embedding-based methods provide
more accurate and nuanced uncertainty quantification than traditional
approaches.",2024-10-30,"Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui",http://arxiv.org/pdf/2410.22685v1,cs.LG
Extralonger: Toward a Unified Perspective of Spatial-Temporal Factors for Extra-Long-Term Traffic Forecasting,"Traffic forecasting plays a key role in Intelligent Transportation Systems,
and significant strides have been made in this field. However, most existing
methods can only predict up to four hours in the future, which doesn't quite
meet real-world demands. we identify that the prediction horizon is limited to
a few hours mainly due to the separation of temporal and spatial factors, which
results in high complexity. Drawing inspiration from Albert Einstein's
relativity theory, which suggests space and time are unified and inseparable,
we introduce Extralonger, which unifies temporal and spatial factors.
Extralonger notably extends the prediction horizon to a week on real-world
benchmarks, demonstrating superior efficiency in the training time, inference
time, and memory usage. It sets new standards in long-term and extra-long-term
scenarios. The code is available at https://github.com/PlanckChang/Extralonger.",2024-10-30,"Zhiwei Zhang, Shaojun E, Fandong Meng, Jie Zhou, Wenjuan Han",http://arxiv.org/pdf/2411.00844v1,cs.LG
Byzantine-Robust Federated Learning: An Overview With Focus on Developing Sybil-based Attacks to Backdoor Augmented Secure Aggregation Protocols,"Federated Learning (FL) paradigms enable large numbers of clients to
collaboratively train Machine Learning models on private data. However, due to
their multi-party nature, traditional FL schemes are left vulnerable to
Byzantine attacks that attempt to hurt model performance by injecting malicious
backdoors. A wide variety of prevention methods have been proposed to protect
frameworks from such attacks. This paper provides a exhaustive and updated
taxonomy of existing methods and frameworks, before zooming in and conducting
an in-depth analysis of the strengths and weaknesses of the Robustness of
Federated Learning (RoFL) protocol. From there, we propose two novel
Sybil-based attacks that take advantage of vulnerabilities in RoFL. Finally, we
conclude with comprehensive proposals for future testing, describe and detail
implementation of the proposed attacks, and offer direction for improvements in
the RoFL protocol as well as Byzantine-robust frameworks as a whole.",2024-10-30,Atharv Deshmukh,http://arxiv.org/pdf/2410.22680v1,cs.LG
The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation,"Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. This work proposes
augmenting LLMs with predictor networks trained to estimate circuit quality
directly from HDL code. To enhance performance, the model is regularized using
embeddings from graph neural networks (GNNs) trained on Look-Up Table (LUT)
graphs, thereby incorporating lower-level circuit insights. The proposed method
demonstrates superior performance compared to existing graph-based RTL-level
estimation techniques on the established benchmark OpenABCD, while providing
instant feedback on HDL code quality.",2024-10-30,"Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan",http://arxiv.org/pdf/2411.00843v2,cs.LG
Is Function Similarity Over-Engineered? Building a Benchmark,"Binary analysis is a core component of many critical security tasks,
including reverse engineering, malware analysis, and vulnerability detection.
Manual analysis is often time-consuming, but identifying commonly-used or
previously-seen functions can reduce the time it takes to understand a new
file. However, given the complexity of assembly, and the NP-hard nature of
determining function equivalence, this task is extremely difficult. Common
approaches often use sophisticated disassembly and decompilation tools, graph
analysis, and other expensive pre-processing steps to perform function
similarity searches over some corpus. In this work, we identify a number of
discrepancies between the current research environment and the underlying
application need. To remedy this, we build a new benchmark, REFuSE-Bench, for
binary function similarity detection consisting of high-quality datasets and
tests that better reflect real-world use cases. In doing so, we address issues
like data duplication and accurate labeling, experiment with real malware, and
perform the first serious evaluation of ML binary function similarity models on
Windows data. Our benchmark reveals that a new, simple basline, one which looks
at only the raw bytes of a function, and requires no disassembly or other
pre-processing, is able to achieve state-of-the-art performance in multiple
settings. Our findings challenge conventional assumptions that complex models
with highly-engineered features are being used to their full potential, and
demonstrate that simpler approaches can provide significant value.",2024-10-30,"Rebecca Saul, Chang Liu, Noah Fleischmann, Richard Zak, Kristopher Micinski, Edward Raff, James Holt",http://arxiv.org/pdf/2410.22677v1,cs.LG
Dynamic PET Image Prediction Using a Network Combining Reversible and Irreversible Modules,"Dynamic positron emission tomography (PET) images can reveal the distribution
of tracers in the organism and the dynamic processes involved in biochemical
reactions, and it is widely used in clinical practice. Despite the high
effectiveness of dynamic PET imaging in studying the kinetics and metabolic
processes of radiotracers. Pro-longed scan times can cause discomfort for both
patients and medical personnel. This study proposes a dynamic frame prediction
method for dynamic PET imaging, reduc-ing dynamic PET scanning time by applying
a multi-module deep learning framework composed of reversible and irreversible
modules. The network can predict kinetic parameter images based on the early
frames of dynamic PET images, and then generate complete dynamic PET images. In
validation experiments with simulated data, our network demonstrated good
predictive performance for kinetic parameters and was able to reconstruct
high-quality dynamic PET images. Additionally, in clinical data experiments,
the network exhibited good generalization performance and attached that the
proposed method has promising clinical application prospects.",2024-10-30,"Jie Sun, Qian Xia, Chuanfu Sun, Yumei Chen, Huafeng Liu, Wentao Zhu, Qiegen Liu",http://arxiv.org/pdf/2410.22674v1,cs.LG
Calibrating Practical Privacy Risks for Differentially Private Machine Learning,"Differential privacy quantifies privacy through the privacy budget
$\epsilon$, yet its practical interpretation is complicated by variations
across models and datasets. Recent research on differentially private machine
learning and membership inference has highlighted that with the same
theoretical $\epsilon$ setting, the likelihood-ratio-based membership inference
(LiRA) attacking success rate (ASR) may vary according to specific datasets and
models, which might be a better indicator for evaluating real-world privacy
risks. Inspired by this practical privacy measure, we study the approaches that
can lower the attacking success rate to allow for more flexible privacy budget
settings in model training. We find that by selectively suppressing
privacy-sensitive features, we can achieve lower ASR values without
compromising application-specific data utility. We use the SHAP and LIME model
explainer to evaluate feature sensitivities and develop feature-masking
strategies. Our findings demonstrate that the LiRA $ASR^M$ on model $M$ can
properly indicate the inherent privacy risk of a dataset for modeling, and it's
possible to modify datasets to enable the use of larger theoretical $\epsilon$
settings to achieve equivalent practical privacy protection. We have conducted
extensive experiments to show the inherent link between ASR and the dataset's
privacy risk. By carefully selecting features to mask, we can preserve more
data utility with equivalent practical privacy protection and relaxed
$\epsilon$ settings. The implementation details are shared online at the
provided GitHub URL
\url{https://anonymous.4open.science/r/On-sensitive-features-and-empirical-epsilon-lower-bounds-BF67/}.",2024-10-30,"Yuechun Gu, Keke Chen",http://arxiv.org/pdf/2410.22673v1,cs.LG
A Walsh Hadamard Derived Linear Vector Symbolic Architecture,"Vector Symbolic Architectures (VSAs) are one approach to developing
Neuro-symbolic AI, where two vectors in $\mathbb{R}^d$ are `bound' together to
produce a new vector in the same space. VSAs support the commutativity and
associativity of this binding operation, along with an inverse operation,
allowing one to construct symbolic-style manipulations over real-valued
vectors. Most VSAs were developed before deep learning and automatic
differentiation became popular and instead focused on efficacy in hand-designed
systems. In this work, we introduce the Hadamard-derived linear Binding (HLB),
which is designed to have favorable computational efficiency, and efficacy in
classic VSA tasks, and perform well in differentiable systems. Code is
available at
https://github.com/FutureComputing4AI/Hadamard-derived-Linear-Binding",2024-10-30,"Mohammad Mahmudul Alam, Alexander Oberle, Edward Raff, Stella Biderman, Tim Oates, James Holt",http://arxiv.org/pdf/2410.22669v1,cs.LG
Video prediction using score-based conditional density estimation,"Temporal prediction is inherently uncertain, but representing the ambiguity
in natural image sequences is a challenging high-dimensional probabilistic
inference problem. For natural scenes, the curse of dimensionality renders
explicit density estimation statistically and computationally intractable.
Here, we describe an implicit regression-based framework for learning and
sampling the conditional density of the next frame in a video given previous
observed frames. We show that sequence-to-image deep networks trained on a
simple resilience-to-noise objective function extract adaptive representations
for temporal prediction. Synthetic experiments demonstrate that this
score-based framework can handle occlusion boundaries: unlike classical methods
that average over bifurcating temporal trajectories, it chooses among likely
trajectories, selecting more probable options with higher frequency.
Furthermore, analysis of networks trained on natural image sequences reveals
that the representation automatically weights predictive evidence by its
reliability, which is a hallmark of statistical inference",2024-10-30,"Pierre-Étienne H. Fiquet, Eero P. Simoncelli",http://arxiv.org/pdf/2411.00842v1,cs.LG
Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation,"Continual Imitation Learning (CiL) involves extracting and accumulating task
knowledge from demonstrations across multiple stages and tasks to achieve a
multi-task policy. With recent advancements in foundation models, there has
been a growing interest in adapter-based CiL approaches, where adapters are
established parameter-efficiently for tasks newly demonstrated. While these
approaches isolate parameters for specific tasks and tend to mitigate
catastrophic forgetting, they limit knowledge sharing among different
demonstrations. We introduce IsCiL, an adapter-based CiL framework that
addresses this limitation of knowledge sharing by incrementally learning
shareable skills from different demonstrations, thus enabling sample-efficient
task adaptation using the skills particularly in non-stationary CiL
environments. In IsCiL, demonstrations are mapped into the state embedding
space, where proper skills can be retrieved upon input states through
prototype-based memory. These retrievable skills are incrementally learned on
their corresponding adapters. Our CiL experiments with complex tasks in
Franka-Kitchen and Meta-World demonstrate robust performance of IsCiL in both
task adaptation and sample-efficiency. We also show a simple extension of IsCiL
for task unlearning scenarios.",2024-10-30,"Daehee Lee, Minjong Yoo, Woo Kyung Kim, Wonje Choi, Honguk Woo",http://arxiv.org/pdf/2410.22658v2,cs.LG
Reweighting Local Mimina with Tilted SAM,"Sharpness-Aware Minimization (SAM) has been demonstrated to improve the
generalization performance of overparameterized models by seeking flat minima
on the loss landscape through optimizing model parameters that incur the
largest loss within a neighborhood. Nevertheless, such min-max formulations are
computationally challenging especially when the problem is highly non-convex.
Additionally, focusing only on the worst-case local solution while ignoring
potentially many other local solutions may be suboptimal when searching for
flat minima. In this work, we propose Tilted SAM (TSAM), a generalization of
SAM inspired by exponential tilting that effectively assigns higher priority to
local solutions that are flatter and that incur larger losses. TSAM is
parameterized by a tilt hyperparameter t and reduces to SAM as t approaches
infinity. We prove that (1) the TSAM objective is smoother than SAM and thus
easier to optimize; and (2) TSAM explicitly favors flatter minima as t
increases. This is desirable as flatter minima could have better generalization
properties for certain tasks. We develop algorithms motivated by the
discretization of Hamiltonian dynamics to solve TSAM. Empirically, TSAM arrives
at flatter local minima and results in superior test performance than the
baselines of SAM and ERM across a range of image and text tasks.",2024-10-30,"Tian Li, Tianyi Zhou, Jeffrey A. Bilmes",http://arxiv.org/pdf/2410.22656v1,cs.LG
FT-PrivacyScore: Personalized Privacy Scoring Service for Machine Learning Participation,"Training data privacy has been a top concern in AI modeling. While methods
like differentiated private learning allow data contributors to quantify
acceptable privacy loss, model utility is often significantly damaged. In
practice, controlled data access remains a mainstream method for protecting
data privacy in many industrial and research environments. In controlled data
access, authorized model builders work in a restricted environment to access
sensitive data, which can fully preserve data utility with reduced risk of data
leak. However, unlike differential privacy, there is no quantitative measure
for individual data contributors to tell their privacy risk before
participating in a machine learning task. We developed the demo prototype
FT-PrivacyScore to show that it's possible to efficiently and quantitatively
estimate the privacy risk of participating in a model fine-tuning task. The
demo source code will be available at
\url{https://github.com/RhincodonE/demo_privacy_scoring}.",2024-10-30,"Yuechun Gu, Jiajie He, Keke Chen",http://arxiv.org/pdf/2410.22651v1,cs.LG
WaveRoRA: Wavelet Rotary Route Attention for Multivariate Time Series Forecasting,"In recent years, Transformer-based models (Transformers) have achieved
significant success in multivariate time series forecasting (MTSF). However,
previous works focus on extracting features either from the time domain or the
frequency domain, which inadequately captures the trends and periodic
characteristics. To address this issue, we propose a wavelet learning framework
to model complex temporal dependencies of the time series data. The wavelet
domain integrates both time and frequency information, allowing for the
analysis of local characteristics of signals at different scales. Additionally,
the Softmax self-attention mechanism used by Transformers has quadratic
complexity, which leads to excessive computational costs when capturing
long-term dependencies. Therefore, we propose a novel attention mechanism:
Rotary Route Attention (RoRA). Unlike Softmax attention, RoRA utilizes rotary
position embeddings to inject relative positional information to sequence
tokens and introduces a small number of routing tokens $r$ to aggregate
information from the $KV$ matrices and redistribute it to the $Q$ matrix,
offering linear complexity. We further propose WaveRoRA, which leverages RoRA
to capture inter-series dependencies in the wavelet domain. We conduct
extensive experiments on eight real-world datasets. The results indicate that
WaveRoRA outperforms existing state-of-the-art models while maintaining lower
computational costs. Our code is available at
https://github.com/Leopold2333/WaveRoRA.",2024-10-30,"Aobo Liang, Yan Sun, Nadra Guizani",http://arxiv.org/pdf/2410.22649v2,cs.LG
SleepNetZero: Zero-Burden Zero-Shot Reliable Sleep Staging With Neural Networks Based on Ballistocardiograms,"Sleep monitoring plays a crucial role in maintaining good health, with sleep
staging serving as an essential metric in the monitoring process. Traditional
methods, utilizing medical sensors like EEG and ECG, can be effective but often
present challenges such as unnatural user experience, complex deployment, and
high costs. Ballistocardiography~(BCG), a type of piezoelectric sensor signal,
offers a non-invasive, user-friendly, and easily deployable alternative for
long-term home monitoring. However, reliable BCG-based sleep staging is
challenging due to the limited sleep monitoring data available for BCG. A
restricted training dataset prevents the model from generalization across
populations. Additionally, transferring to BCG faces difficulty ensuring model
robustness when migrating from other data sources. To address these issues, we
introduce SleepNetZero, a zero-shot learning based approach for sleep staging.
To tackle the generalization challenge, we propose a series of BCG feature
extraction methods that align BCG components with corresponding respiratory,
cardiac, and movement channels in PSG. This allows models to be trained on
large-scale PSG datasets that are diverse in population. For the migration
challenge, we employ data augmentation techniques, significantly enhancing
generalizability. We conducted extensive training and testing on large
datasets~(12393 records from 9637 different subjects), achieving an accuracy of
0.803 and a Cohen's Kappa of 0.718. ZeroSleepNet was also deployed in real
prototype~(monitoring pads) and tested in actual hospital settings~(265 users),
demonstrating an accuracy of 0.697 and a Cohen's Kappa of 0.589. To the best of
our knowledge, this work represents the first known reliable BCG-based sleep
staging effort and marks a significant step towards in-home health monitoring.",2024-10-30,"Shuzhen Li, Yuxin Chen, Xuesong Chen, Ruiyang Gao, Yupeng Zhang, Chao Yu, Yunfei Li, Ziyi Ye, Weijun Huang, Hongliang Yi, Yue Leng, Yi Wu",http://arxiv.org/pdf/2410.22646v1,cs.LG
Consistency Diffusion Bridge Models,"Diffusion models (DMs) have become the dominant paradigm of generative
modeling in a variety of domains by learning stochastic processes from noise to
data. Recently, diffusion denoising bridge models (DDBMs), a new formulation of
generative modeling that builds stochastic processes between fixed data
endpoints based on a reference diffusion process, have achieved empirical
success across tasks with coupled data distribution, such as image-to-image
translation. However, DDBM's sampling process typically requires hundreds of
network evaluations to achieve decent performance, which may impede their
practical deployment due to high computational demands. In this work, inspired
by the recent advance of consistency models in DMs, we tackle this problem by
learning the consistency function of the probability-flow ordinary differential
equation (PF-ODE) of DDBMs, which directly predicts the solution at a starting
step given any point on the ODE trajectory. Based on a dedicated general-form
ODE solver, we propose two paradigms: consistency bridge distillation and
consistency bridge training, which is flexible to apply on DDBMs with broad
design choices. Experimental results show that our proposed method could sample
$4\times$ to $50\times$ faster than the base DDBM and produce better visual
quality given the same step in various tasks with pixel resolution ranging from
$64 \times 64$ to $256 \times 256$, as well as supporting downstream tasks such
as semantic interpolation in the data space.",2024-10-30,"Guande He, Kaiwen Zheng, Jianfei Chen, Fan Bao, Jun Zhu",http://arxiv.org/pdf/2410.22637v2,cs.LG
A Theoretical Perspective for Speculative Decoding Algorithm,"Transformer-based autoregressive sampling has been the major bottleneck for
slowing down large language model inferences. One effective way to accelerate
inference is \emph{Speculative Decoding}, which employs a small model to sample
a sequence of draft tokens and a large model to validate. Given its empirical
effectiveness, the theoretical understanding of Speculative Decoding is falling
behind. This paper tackles this gap by conceptualizing the decoding problem via
markov chain abstraction and studying the key properties, \emph{output quality
and inference acceleration}, from a theoretical perspective. Our analysis
covers the theoretical limits of speculative decoding, batch algorithms, and
output quality-inference acceleration tradeoffs. Our results reveal the
fundamental connections between different components of LLMs via total
variation distances and show how they jointly affect the efficiency of decoding
algorithms.",2024-10-30,"Ming Yin, Minshuo Chen, Kaixuan Huang, Mengdi Wang",http://arxiv.org/pdf/2411.00841v1,cs.LG
DECRL: A Deep Evolutionary Clustering Jointed Temporal Knowledge Graph Representation Learning Approach,"Temporal Knowledge Graph (TKG) representation learning aims to map temporal
evolving entities and relations to embedded representations in a continuous
low-dimensional vector space. However, existing approaches cannot capture the
temporal evolution of high-order correlations in TKGs. To this end, we propose
a Deep Evolutionary Clustering jointed temporal knowledge graph Representation
Learning approach (DECRL). Specifically, a deep evolutionary clustering module
is proposed to capture the temporal evolution of high-order correlations among
entities. Furthermore, a cluster-aware unsupervised alignment mechanism is
introduced to ensure the precise one-to-one alignment of soft overlapping
clusters across timestamps, thereby maintaining the temporal smoothness of
clusters. In addition, an implicit correlation encoder is introduced to capture
latent correlations between any pair of clusters under the guidance of a global
graph. Extensive experiments on seven real-world datasets demonstrate that
DECRL achieves the state-of-the-art performances, outperforming the best
baseline by an average of 9.53%, 12.98%, 10.42%, and 14.68% in MRR, Hits@1,
Hits@3, and Hits@10, respectively.",2024-10-30,"Qian Chen, Ling Chen",http://arxiv.org/pdf/2410.22631v2,cs.LG
NetworkGym: Reinforcement Learning Environments for Multi-Access Traffic Management in Network Simulation,"Mobile devices such as smartphones, laptops, and tablets can often connect to
multiple access networks (e.g., Wi-Fi, LTE, and 5G) simultaneously. Recent
advancements facilitate seamless integration of these connections below the
transport layer, enhancing the experience for apps that lack inherent
multi-path support. This optimization hinges on dynamically determining the
traffic distribution across networks for each device, a process referred to as
\textit{multi-access traffic splitting}. This paper introduces
\textit{NetworkGym}, a high-fidelity network environment simulator that
facilitates generating multiple network traffic flows and multi-access traffic
splitting. This simulator facilitates training and evaluating different
RL-based solutions for the multi-access traffic splitting problem. Our initial
explorations demonstrate that the majority of existing state-of-the-art offline
RL algorithms (e.g. CQL) fail to outperform certain hand-crafted heuristic
policies on average. This illustrates the urgent need to evaluate offline RL
algorithms against a broader range of benchmarks, rather than relying solely on
popular ones such as D4RL. We also propose an extension to the TD3+BC
algorithm, named Pessimistic TD3 (PTD3), and demonstrate that it outperforms
many state-of-the-art offline RL algorithms. PTD3's behavioral constraint
mechanism, which relies on value-function pessimism, is theoretically motivated
and relatively simple to implement.",2024-10-30,"Momin Haider, Ming Yin, Menglei Zhang, Arpit Gupta, Jing Zhu, Yu-Xiang Wang",http://arxiv.org/pdf/2411.04138v1,cs.LG
PARDON: Privacy-Aware and Robust Federated Domain Generalization,"Federated Learning (FL) shows promise in preserving privacy and enabling
collaborative learning. However, most current solutions focus on private data
collected from a single domain. A significant challenge arises when client data
comes from diverse domains (i.e., domain shift), leading to poor performance on
unseen domains. Existing Federated Domain Generalization approaches address
this problem but assume each client holds data for an entire domain, limiting
their practicality in real-world scenarios with domain-based heterogeneity and
client sampling. In addition, certain methods enable information sharing among
clients, raising privacy concerns as this information could be used to
reconstruct sensitive private data.
  To overcome this, we introduce FISC, a novel FedDG paradigm designed to
robustly handle more complicated domain distributions between clients while
ensuring security. FISC enables learning across domains by extracting an
interpolative style from local styles and employing contrastive learning. This
strategy gives clients multi-domain representations and unbiased convergent
targets. Empirical results on multiple datasets, including PACS, Office-Home,
and IWildCam, show FISC outperforms state-of-the-art (SOTA) methods. Our method
achieves accuracy on unseen domains, with improvements ranging from 3.64% to
57.22% on unseen domains. Our code is available at
https://github.com/judydnguyen/PARDON-FedDG.",2024-10-30,"Dung Thuy Nguyen, Taylor T. Johnson, Kevin Leach",http://arxiv.org/pdf/2410.22622v2,cs.LG
Solving Minimum-Cost Reach Avoid using Reinforcement Learning,"Current reinforcement-learning methods are unable to directly learn policies
that solve the minimum cost reach-avoid problem to minimize cumulative costs
subject to the constraints of reaching the goal and avoiding unsafe states, as
the structure of this new optimization problem is incompatible with current
methods. Instead, a surrogate problem is solved where all objectives are
combined with a weighted sum. However, this surrogate objective results in
suboptimal policies that do not directly minimize the cumulative cost. In this
work, we propose RC-PPO, a reinforcement-learning-based method for solving the
minimum-cost reach-avoid problem by using connections to Hamilton-Jacobi
reachability. Empirical results demonstrate that RC-PPO learns policies with
comparable goal-reaching rates to while achieving up to 57% lower cumulative
costs compared to existing methods on a suite of minimum-cost reach-avoid
benchmarks on the Mujoco simulator. The project page can be found at
https://oswinso.xyz/rcppo.",2024-10-29,"Oswin So, Cheng Ge, Chuchu Fan",http://arxiv.org/pdf/2410.22600v1,cs.LG
"Peri-AIIMS: Perioperative Artificial Intelligence Driven Integrated Modeling of Surgeries using Anesthetic, Physical and Cognitive Statuses for Predicting Hospital Outcomes","The association between preoperative cognitive status and surgical outcomes
is a critical, yet scarcely explored area of research. Linking intraoperative
data with postoperative outcomes is a promising and low-cost way of evaluating
long-term impacts of surgical interventions. In this study, we evaluated how
preoperative cognitive status as measured by the clock drawing test contributed
to predicting length of hospital stay, hospital charges, average pain
experienced during follow-up, and 1-year mortality over and above
intraoperative variables, demographics, preoperative physical status and
comorbidities. We expanded our analysis to 6 specific surgical groups where
sufficient data was available for cross-validation. The clock drawing images
were represented by 10 constructional features discovered by a semi-supervised
deep learning algorithm, previously validated to differentiate between dementia
and non-dementia patients. Different machine learning models were trained to
classify postoperative outcomes in hold-out test sets. The models were compared
to their relative performance, time complexity, and interpretability. Shapley
Additive Explanations (SHAP) analysis was used to find the most predictive
features for classifying different outcomes in different surgical contexts.
Relative classification performances achieved by different feature sets showed
that the perioperative cognitive dataset which included clock drawing features
in addition to intraoperative variables, demographics, and comorbidities served
as the best dataset for 12 of 18 possible surgery-outcome combinations...",2024-10-29,"Sabyasachi Bandyopadhyay, Jiaqing Zhang, Ronald L. Ison, David J. Libon, Patrick Tighe, Catherine Price, Parisa Rashidi",http://arxiv.org/pdf/2411.00840v1,cs.LG
Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse,"Machine learning models routinely automate decisions in applications like
lending and hiring. In such settings, consumer protection rules require
companies that deploy models to explain predictions to decision subjects. These
rules are motivated, in part, by the belief that explanations can promote
recourse by revealing information that individuals can use to contest or
improve their outcomes. In practice, many companies comply with these rules by
providing individuals with a list of the most important features for their
prediction, which they identify based on feature importance scores from feature
attribution methods such as SHAP or LIME. In this work, we show how these
practices can undermine consumers by highlighting features that would not lead
to an improved outcome and by explaining predictions that cannot be changed. We
propose to address these issues by highlighting features based on their
responsiveness score -- i.e., the probability that an individual can attain a
target prediction by changing a specific feature. We develop efficient methods
to compute responsiveness scores for any model and any dataset. We conduct an
extensive empirical study on the responsiveness of explanations in lending. Our
results show that standard practices in consumer finance can backfire by
presenting consumers with reasons without recourse, and demonstrate how our
approach improves consumer protection by highlighting responsive features and
identifying fixed predictions.",2024-10-29,"Seung Hyun Cheon, Anneke Wernerfelt, Sorelle A. Friedler, Berk Ustun",http://arxiv.org/pdf/2410.22598v2,cs.LG
Are Large-Language Models Graph Algorithmic Reasoners?,"We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.",2024-10-29,"Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang",http://arxiv.org/pdf/2410.22597v1,cs.LG
Gaussian Derivative Change-point Detection for Early Warnings of Industrial System Failures,"An early warning of future system failure is essential for conducting
predictive maintenance and enhancing system availability. This paper introduces
a three-step framework for assessing system health to predict imminent system
breakdowns. First, the Gaussian Derivative Change-Point Detection (GDCPD)
algorithm is proposed for detecting changes in the high-dimensional feature
space. GDCPD conducts a multivariate Change-Point Detection (CPD) by
implementing Gaussian derivative processes for identifying change locations on
critical system features, as these changes eventually will lead to system
failure. To assess the significance of these changes, Weighted Mahalanobis
Distance (WMD) is applied in both offline and online analyses. In the offline
setting, WMD helps establish a threshold that determines significant system
variations, while in the online setting, it facilitates real-time monitoring,
issuing alarms for potential future system breakdowns. Utilizing the insights
gained from the GDCPD and monitoring scheme, Long Short-Term Memory (LSTM)
network is then employed to estimate the Remaining Useful Life (RUL) of the
system. The experimental study of a real-world system demonstrates the
effectiveness of the proposed methodology in accurately forecasting system
failures well before they occur. By integrating CPD with real-time monitoring
and RUL prediction, this methodology significantly advances system health
monitoring and early warning capabilities.",2024-10-29,"Hao Zhao, Rong Pan",http://arxiv.org/pdf/2410.22594v2,cs.LG
FGCE: Feasible Group Counterfactual Explanations for Auditing Fairness,"This paper introduces the first graph-based framework for generating group
counterfactual explanations to audit model fairness, a crucial aspect of
trustworthy machine learning. Counterfactual explanations are instrumental in
understanding and mitigating unfairness by revealing how inputs should change
to achieve a desired outcome. Our framework, named Feasible Group
Counterfactual Explanations (FGCEs), captures real-world feasibility
constraints and constructs subgroups with similar counterfactuals, setting it
apart from existing methods. It also addresses key trade-offs in counterfactual
generation, including the balance between the number of counterfactuals, their
associated costs, and the breadth of coverage achieved. To evaluate these
trade-offs and assess fairness, we propose measures tailored to group
counterfactual generation. Our experimental results on benchmark datasets
demonstrate the effectiveness of our approach in managing feasibility
constraints and trade-offs, as well as the potential of our proposed metrics in
identifying and quantifying fairness issues.",2024-10-29,"Christos Fragkathoulas, Vasiliki Papanikou, Evaggelia Pitoura, Evimaria Terzi",http://arxiv.org/pdf/2410.22591v2,cs.LG
Pre-Trained Vision Models as Perception Backbones for Safety Filters in Autonomous Driving,"End-to-end vision-based autonomous driving has achieved impressive success,
but safety remains a major concern. The safe control problem has been addressed
in low-dimensional settings using safety filters, e.g., those based on control
barrier functions. Designing safety filters for vision-based controllers in the
high-dimensional settings of autonomous driving can similarly alleviate the
safety problem, but is significantly more challenging. In this paper, we
address this challenge by using frozen pre-trained vision representation models
as perception backbones to design vision-based safety filters, inspired by
these models' success as backbones of robotic control policies. We empirically
evaluate the offline performance of four common pre-trained vision models in
this context. We try three existing methods for training safety filters for
black-box dynamics, as the dynamics over representation spaces are not known.
We use the DeepAccident dataset that consists of action-annotated videos from
multiple cameras on vehicles in CARLA simulating real accident scenarios. Our
results show that the filters resulting from our approach are competitive with
the ones that are given the ground truth state of the ego vehicle and its
environment.",2024-10-29,"Yuxuan Yang, Hussein Sibai",http://arxiv.org/pdf/2410.22585v1,cs.LG
CausAdv: A Causal-based Framework for Detecting Adversarial Examples,"Deep learning has led to tremendous success in many real-world applications
of computer vision, thanks to sophisticated architectures such as Convolutional
neural networks (CNNs). However, CNNs have been shown to be vulnerable to
crafted adversarial perturbations in inputs. These inputs appear almost
indistinguishable from natural images, yet they are incorrectly classified by
CNN architectures. This vulnerability of adversarial examples has led
researchers to focus on enhancing the robustness of deep learning models in
general, and CNNs in particular, by creating defense and detection methods to
distinguish adversarials inputs from natural ones. In this paper, we address
the adversarial robustness of CNNs through causal reasoning.
  We propose CausAdv: a causal framework for detecting adversarial examples
based on counterfactual reasoning. CausAdv learns causal and non-causal
features of every input, and quantifies the counterfactual information (CI) of
every filter of the last convolutional layer. Then we perform statistical
analysis on the filters CI of every sample, whether clan or adversarials, to
demonstrate how adversarial examples indeed exhibit different CI distributions
compared to clean samples. Our results show that causal reasoning enhances the
process of adversarials detection without the need to train a separate
detector. In addition, we illustrate the efficiency of causal explanations as a
helpful detection technique through visualizing the causal features. The
results can be reproduced using the code available in the repository:
https://github.com/HichemDebbi/CausAdv.",2024-10-29,Hichem Debbi,http://arxiv.org/pdf/2411.00839v1,cs.LG
BENCHAGENTS: Automated Benchmark Creation with Agent Interaction,"Evaluations are limited by benchmark availability. As models evolve, there is
a need to create benchmarks that can measure progress on new generative
capabilities. However, creating new benchmarks through human annotations is
slow and expensive, restricting comprehensive evaluations for any capability.
We introduce BENCHAGENTS, a framework that methodically leverages large
language models (LLMs) to automate benchmark creation for complex capabilities
while inherently ensuring data and metric quality. BENCHAGENTS decomposes the
benchmark creation process into planning, generation, data verification, and
evaluation, each of which is executed by an LLM agent. These agents interact
with each other and utilize human-in-the-loop feedback from benchmark
developers to explicitly improve and flexibly control data diversity and
quality. We use BENCHAGENTS to create benchmarks to evaluate capabilities
related to planning and constraint satisfaction during text generation. We then
use these benchmarks to study seven state-of-the-art models and extract new
insights on common failure modes and model differences.",2024-10-29,"Natasha Butt, Varun Chandrasekaran, Neel Joshi, Besmira Nushi, Vidhisha Balachandran",http://arxiv.org/pdf/2410.22584v1,cs.LG
Energy-Aware Multi-Agent Reinforcement Learning for Collaborative Execution in Mission-Oriented Drone Networks,"Mission-oriented drone networks have been widely used for structural
inspection, disaster monitoring, border surveillance, etc. Due to the limited
battery capacity of drones, mission execution strategy impacts network
performance and mission completion. However, collaborative execution is a
challenging problem for drones in such a dynamic environment as it also
involves efficient trajectory design. We leverage multi-agent reinforcement
learning (MARL) to manage the challenge in this study, letting each drone learn
to collaboratively execute tasks and plan trajectories based on its current
status and environment. Simulation results show that the proposed collaborative
execution model can successfully complete the mission at least 80% of the time,
regardless of task locations and lengths, and can even achieve a 100% success
rate when the task density is not way too sparse. To the best of our knowledge,
our work is one of the pioneer studies on leveraging MARL on collaborative
execution for mission-oriented drone networks; the unique value of this work
lies in drone battery level driving our model design.",2024-10-29,"Ying Li, Changling Li, Jiyao Chen, Christine Roinou",http://arxiv.org/pdf/2410.22578v1,cs.LG
Flow Matching for Posterior Inference with Simulator Feedback,"Flow-based generative modeling is a powerful tool for solving inverse
problems in physical sciences that can be used for sampling and likelihood
evaluation with much lower inference times than traditional methods. We propose
to refine flows with additional control signals based on a simulator. Control
signals can include gradients and a problem-specific cost function if the
simulator is differentiable, or they can be fully learned from the simulator
output. In our proposed method, we pretrain the flow network and include
feedback from the simulator exclusively for finetuning, therefore requiring
only a small amount of additional parameters and compute. We motivate our
design choices on several benchmark problems for simulation-based inference and
evaluate flow matching with simulator feedback against classical MCMC methods
for modeling strong gravitational lens systems, a challenging inverse problem
in astronomy. We demonstrate that including feedback from the simulator
improves the accuracy by $53\%$, making it competitive with traditional
techniques while being up to $67$x faster for inference.",2024-10-29,"Benjamin Holzschuh, Nils Thuerey",http://arxiv.org/pdf/2410.22573v1,cs.LG
"Orb: A Fast, Scalable Neural Network Potential","We introduce Orb, a family of universal interatomic potentials for atomistic
modelling of materials. Orb models are 3-6 times faster than existing universal
potentials, stable under simulation for a range of out of distribution
materials and, upon release, represented a 31% reduction in error over other
methods on the Matbench Discovery benchmark. We explore several aspects of
foundation model development for materials, with a focus on diffusion
pretraining. We evaluate Orb as a model for geometry optimization, Monte Carlo
and molecular dynamics simulations.",2024-10-29,"Mark Neumann, James Gin, Benjamin Rhodes, Steven Bennett, Zhiyi Li, Hitarth Choubisa, Arthur Hussey, Jonathan Godwin",http://arxiv.org/pdf/2410.22570v1,cs.LG
Fast Deep Hedging with Second-Order Optimization,"Hedging exotic options in presence of market frictions is an important risk
management task. Deep hedging can solve such hedging problems by training
neural network policies in realistic simulated markets. Training these neural
networks may be delicate and suffer from slow convergence, particularly for
options with long maturities and complex sensitivities to market parameters. To
address this, we propose a second-order optimization scheme for deep hedging.
We leverage pathwise differentiability to construct a curvature matrix, which
we approximate as block-diagonal and Kronecker-factored to efficiently
precondition gradients. We evaluate our method on a challenging and practically
important problem: hedging a cliquet option on a stock with stochastic
volatility by trading in the spot and vanilla options. We find that our
second-order scheme can optimize the policy in 1/4 of the number of steps that
standard adaptive moment-based optimization takes.",2024-10-29,"Konrad Mueller, Amira Akkari, Lukas Gonon, Ben Wood",http://arxiv.org/pdf/2410.22568v1,cs.LG
Vertical Federated Learning with Missing Features During Training and Inference,"Vertical federated learning trains models from feature-partitioned datasets
across multiple clients, who collaborate without sharing their local data.
Standard approaches assume that all feature partitions are available during
both training and inference. Yet, in practice, this assumption rarely holds, as
for many samples only a subset of the clients observe their partition. However,
not utilizing incomplete samples during training harms generalization, and not
supporting them during inference limits the utility of the model. Moreover, if
any client leaves the federation after training, its partition becomes
unavailable, rendering the learned model unusable. Missing feature blocks are
therefore a key challenge limiting the applicability of vertical federated
learning in real-world scenarios. To address this, we propose LASER-VFL, a
vertical federated learning method for efficient training and inference of
split neural network-based models that is capable of handling arbitrary sets of
partitions. Our approach is simple yet effective, relying on the sharing of
model parameters and on task-sampling to train a family of predictors. We show
that LASER-VFL achieves a $\mathcal{O}({1}/{\sqrt{T}})$ convergence rate for
nonconvex objectives and, under the Polyak-{\L}ojasiewicz inequality, it
achieves linear convergence to a neighborhood of the optimum. Numerical
experiments show improved performance of LASER-VFL over the baselines.
Remarkably, this is the case even in the absence of missing features. For
example, for CIFAR-100, we see an improvement in accuracy of $19.3\%$ when each
of four feature blocks is observed with a probability of 0.5 and of $9.5\%$
when all features are observed. The code for this work is available at
https://github.com/Valdeira/LASER-VFL.",2024-10-29,"Pedro Valdeira, Shiqiang Wang, Yuejie Chi",http://arxiv.org/pdf/2410.22564v3,cs.LG
Unpicking Data at the Seams: Understanding Disentanglement in VAEs,"Disentanglement, or identifying statistically independent factors of the
data, is relevant to much of machine learning, from controlled data generation
and robust classification to efficient encoding and improving our understanding
of the data itself. Disentanglement arises in several generative paradigms
including Variational Autoencoders (VAEs), Generative Adversarial Networks and
diffusion models. Prior work takes a step towards understanding disentanglement
in VAEs by showing diagonal posterior covariance matrices promote orthogonality
between columns of the decoder's Jacobian. Building on this, we close the gap
in our understanding of disentanglement by showing how if follows from such
orthogonality and equates to factoring the data distribution into statistically
independent components.",2024-10-29,Carl Allen,http://arxiv.org/pdf/2410.22559v5,cs.LG
Unsupervised Multimodal Fusion of In-process Sensor Data for Advanced Manufacturing Process Monitoring,"Effective monitoring of manufacturing processes is crucial for maintaining
product quality and operational efficiency. Modern manufacturing environments
generate vast amounts of multimodal data, including visual imagery from various
perspectives and resolutions, hyperspectral data, and machine health monitoring
information such as actuator positions, accelerometer readings, and temperature
measurements. However, interpreting this complex, high-dimensional data
presents significant challenges, particularly when labeled datasets are
unavailable. This paper presents a novel approach to multimodal sensor data
fusion in manufacturing processes, inspired by the Contrastive Language-Image
Pre-training (CLIP) model. We leverage contrastive learning techniques to
correlate different data modalities without the need for labeled data,
developing encoders for five distinct modalities: visual imagery, audio
signals, laser position (x and y coordinates), and laser power measurements. By
compressing these high-dimensional datasets into low-dimensional
representational spaces, our approach facilitates downstream tasks such as
process control, anomaly detection, and quality assurance. We evaluate the
effectiveness of our approach through experiments, demonstrating its potential
to enhance process monitoring capabilities in advanced manufacturing systems.
This research contributes to smart manufacturing by providing a flexible,
scalable framework for multimodal data fusion that can adapt to diverse
manufacturing environments and sensor configurations.",2024-10-29,"Matthew McKinney, Anthony Garland, Dale Cillessen, Jesse Adamczyk, Dan Bolintineanu, Michael Heiden, Elliott Fowler, Brad L. Boyce",http://arxiv.org/pdf/2410.22558v1,cs.LG
Denoising Diffusion Probabilistic Models for Magnetic Resonance Fingerprinting,"Magnetic Resonance Fingerprinting (MRF) is a time-efficient approach to
quantitative MRI, enabling the mapping of multiple tissue properties from a
single, accelerated scan. However, achieving accurate reconstructions remains
challenging, particularly in highly accelerated and undersampled acquisitions,
which are crucial for reducing scan times. While deep learning techniques have
advanced image reconstruction, the recent introduction of diffusion models
offers new possibilities for imaging tasks, though their application in the
medical field is still emerging. Notably, diffusion models have not yet been
explored for the MRF problem. In this work, we propose for the first time a
conditional diffusion probabilistic model for MRF image reconstruction.
Qualitative and quantitative comparisons on in-vivo brain scan data demonstrate
that the proposed approach can outperform established deep learning and
compressed sensing algorithms for MRF reconstruction. Extensive ablation
studies also explore strategies to improve computational efficiency of our
approach.",2024-10-29,"Perla Mayo, Carolin M. Pirkl, Alin Achim, Bjoern H. Menze, Mohammad Golbabaee",http://arxiv.org/pdf/2410.23318v2,cs.LG
Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents,"In this paper, we introduce Auto-Intent, a method to adapt a pre-trained
large language model (LLM) as an agent for a target domain without direct
fine-tuning, where we empirically focus on web navigation tasks. Our approach
first discovers the underlying intents from target domain demonstrations
unsupervisedly, in a highly compact form (up to three words). With the
extracted intents, we train our intent predictor to predict the next intent
given the agent's past observations and actions. In particular, we propose a
self-exploration approach where top-k probable intent predictions are provided
as a hint to the pre-trained LLM agent, which leads to enhanced decision-making
capabilities. Auto-Intent substantially improves the performance of GPT-{3.5,
4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation
benchmarks from Mind2Web and online navigation tasks from WebArena with its
cross-benchmark generalization from Mind2Web.",2024-10-29,"Jaekyeom Kim, Dong-Ki Kim, Lajanugen Logeswaran, Sungryull Sohn, Honglak Lee",http://arxiv.org/pdf/2410.22552v1,cs.LG
Towards Neural-Network-based optical temperature sensing of Semiconductor Membrane External Cavity Laser,"A machine-learning non-contact method to determine the temperature of a laser
gain medium via its laser emission with a trained few-layer neural net model is
presented. The training of the feed-forward Neural Network (NN) enables the
prediction of the device's properties solely from spectral data, here recorded
by visible-/nearinfrared-light compact micro-spectrometers for both a diode
pump laser and optically-pumped gain membrane of a semiconductor disk laser.
Fiber spectrometers are used for the acquisition of large quantities of
labelled intensity data, which can afterwards be used for the prediction
process. Such pretrained deep NNs enable a fast, reliable and easy way to infer
the temperature of a laser system such as our Membrane External Cavity Laser,
at a later monitoring stage without the need of additional optical diagnostics
or read-out temperature sensors. With the miniature mobile spectrometer and the
remote detection ability, the temperature inference capability can be adapted
for various laser diodes using transfer learning methods with pretrained
models. Here, mean-square-error values for the temperature inference
corresponding to sub-percent accuracy of our sensor scheme are reached, while
computational cost can be saved by reducing the network depth at the here
displayed cost of accuracy, as appropriate for different application scenarios.",2024-10-29,"Jakob Mannstadt, Arash Rahimi-Iman",http://arxiv.org/pdf/2410.22528v1,cs.LG
Hindsight Experience Replay Accelerates Proximal Policy Optimization,"Hindsight experience replay (HER) accelerates off-policy reinforcement
learning algorithms for environments that emit sparse rewards by modifying the
goal of the episode post-hoc to be some state achieved during the episode.
Because post-hoc modification of the observed goal violates the assumptions of
on-policy algorithms, HER is not typically applied to on-policy algorithms.
Here, we show that HER can dramatically accelerate proximal policy optimization
(PPO), an on-policy reinforcement learning algorithm, when tested on a custom
predator-prey environment.",2024-10-29,"Douglas C. Crowder, Darrien M. McKenzie, Matthew L. Trappett, Frances S. Chance",http://arxiv.org/pdf/2410.22524v1,cs.LG
Multimodal Structure Preservation Learning,"When selecting data to build machine learning models in practical
applications, factors such as availability, acquisition cost, and
discriminatory power are crucial considerations. Different data modalities
often capture unique aspects of the underlying phenomenon, making their
utilities complementary. On the other hand, some sources of data host
structural information that is key to their value. Hence, the utility of one
data type can sometimes be enhanced by matching the structure of another. We
propose Multimodal Structure Preservation Learning (MSPL) as a novel method of
learning data representations that leverages the clustering structure provided
by one data modality to enhance the utility of data from another modality. We
demonstrate the effectiveness of MSPL in uncovering latent structures in
synthetic time series data and recovering clusters from whole genome sequencing
and antimicrobial resistance data using mass spectrometry data in support of
epidemiology applications. The results show that MSPL can imbue the learned
features with external structures and help reap the beneficial synergies
occurring across disparate data modalities.",2024-10-29,"Chang Liu, Jieshi Chen, Lee H. Harrison, Artur Dubrawski",http://arxiv.org/pdf/2410.22520v1,cs.LG
Evaluating utility in synthetic banking microdata applications,"Financial regulators such as central banks collect vast amounts of data, but
access to the resulting fine-grained banking microdata is severely restricted
by banking secrecy laws. Recent developments have resulted in mechanisms that
generate faithful synthetic data, but current evaluation frameworks lack a
focus on the specific challenges of banking institutions and microdata. We
develop a framework that considers the utility and privacy requirements of
regulators, and apply this to financial usage indices, term deposit yield
curves, and credit card transition matrices. Using the Central Bank of
Paraguay's data, we provide the first implementation of synthetic banking
microdata using a central bank's collected information, with the resulting
synthetic datasets for all three domain applications being publicly available
and featuring information not yet released in statistical disclosure. We find
that applications less susceptible to post-processing information loss, which
are based on frequency tables, are particularly suited for this approach, and
that marginal-based inference mechanisms to outperform generative adversarial
network models for these applications. Our results demonstrate that synthetic
data generation is a promising privacy-enhancing technology for financial
regulators seeking to complement their statistical disclosure, while
highlighting the crucial role of evaluating such endeavors in terms of utility
and privacy requirements.",2024-10-29,"Hugo E. Caceres, Ben Moews",http://arxiv.org/pdf/2410.22519v1,cs.LG
Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models,"We explore the internal mechanisms of how bias emerges in large language
models (LLMs) when provided with ambiguous comparative prompts: inputs that
compare or enforce choosing between two or more entities without providing
clear context for preference. Most approaches for bias mitigation focus on
either post-hoc analysis or data augmentation. However, these are transient
solutions, without addressing the root cause: the model itself. Numerous prior
works show the influence of the attention module towards steering generations.
We believe that analyzing attention is also crucial for understanding bias, as
it provides insight into how the LLM distributes its focus across different
entities and how this contributes to biased decisions. To this end, we first
introduce a metric to quantify the LLM's preference for one entity over
another. We then propose $\texttt{ATLAS}$ (Attention-based Targeted Layer
Analysis and Scaling), a technique to localize bias to specific layers of the
LLM by analyzing attention scores and then reduce bias by scaling attention in
these biased layers. To evaluate our method, we conduct experiments across 3
datasets (BBQ, Crows-Pairs, and WinoGender) using $\texttt{GPT-2 XL}$ (1.5B),
$\texttt{GPT-J}$ (6B), $\texttt{LLaMA-2}$ (7B) and $\texttt{LLaMA-3}$ (8B). Our
experiments demonstrate that bias is concentrated in the later layers,
typically around the last third. We also show how $\texttt{ATLAS}$ effectively
mitigates bias through targeted interventions without compromising downstream
performance and an average increase of only 0.82% in perplexity when the
intervention is applied. We see an average improvement of 0.28 points in the
bias score across all the datasets.",2024-10-29,"Rishabh Adiga, Besmira Nushi, Varun Chandrasekaran",http://arxiv.org/pdf/2410.22517v1,cs.LG
Unlocking Point Processes through Point Set Diffusion,"Point processes model the distribution of random point sets in mathematical
spaces, such as spatial and temporal domains, with applications in fields like
seismology, neuroscience, and economics. Existing statistical and machine
learning models for point processes are predominantly constrained by their
reliance on the characteristic intensity function, introducing an inherent
trade-off between efficiency and flexibility. In this paper, we introduce Point
Set Diffusion, a diffusion-based latent variable model that can represent
arbitrary point processes on general metric spaces without relying on the
intensity function. By directly learning to stochastically interpolate between
noise and data point sets, our approach enables efficient, parallel sampling
and flexible generation for complex conditional tasks defined on the metric
space. Experiments on synthetic and real-world datasets demonstrate that Point
Set Diffusion achieves state-of-the-art performance in unconditional and
conditional generation of spatial and spatiotemporal point processes while
providing up to orders of magnitude faster sampling than autoregressive
baselines.",2024-10-29,"David Lüdke, Enric Rabasseda Raventós, Marcel Kollovieh, Stephan Günnemann",http://arxiv.org/pdf/2410.22493v1,cs.LG
MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary embolism phenotype in the MIMIC-IV dataset,"Pulmonary embolism (PE) is a leading cause of preventable in-hospital
mortality. Advances in diagnosis, risk stratification, and prevention can
improve outcomes. There are few large publicly available datasets that contain
PE labels for research. Using the MIMIC-IV database, we extracted all available
radiology reports of computed tomography pulmonary angiography (CTPA) scans and
two physicians manually labeled the results as PE positive (acute PE) or PE
negative. We then applied a previously finetuned Bio_ClinicalBERT transformer
language model, VTE-BERT, to extract labels automatically. We verified
VTE-BERT's reliability by measuring its performance against manual
adjudication. We also compared the performance of VTE-BERT to diagnosis codes.
We found that VTE-BERT has a sensitivity of 92.4% and positive predictive value
(PPV) of 87.8% on all 19,942 patients with CTPA radiology reports from the
emergency room and/or hospital admission. In contrast, diagnosis codes have a
sensitivity of 95.4% and PPV of 83.8% on the subset of 11,990 hospitalized
patients with discharge diagnosis codes. We successfully add nearly 20,000
labels to CTPAs in a publicly available dataset and demonstrate the external
validity of a semi-supervised language model in accelerating hematologic
research.",2024-10-29,"B. D. Lam, S. Ma, I. Kovalenko, P. Wang, O. Jafari, A. Li, S. Horng",http://arxiv.org/pdf/2411.00044v1,cs.LG
Privacy-Preserving Dynamic Assortment Selection,"With the growing demand for personalized assortment recommendations, concerns
over data privacy have intensified, highlighting the urgent need for effective
privacy-preserving strategies. This paper presents a novel framework for
privacy-preserving dynamic assortment selection using the multinomial logit
(MNL) bandits model. Our approach employs a perturbed upper confidence bound
method, integrating calibrated noise into user utility estimates to balance
between exploration and exploitation while ensuring robust privacy protection.
We rigorously prove that our policy satisfies Joint Differential Privacy (JDP),
which better suits dynamic environments than traditional differential privacy,
effectively mitigating inference attack risks. This analysis is built upon a
novel objective perturbation technique tailored for MNL bandits, which is also
of independent interest. Theoretically, we derive a near-optimal regret bound
of $\tilde{O}(\sqrt{T})$ for our policy and explicitly quantify how privacy
protection impacts regret. Through extensive simulations and an application to
the Expedia hotel dataset, we demonstrate substantial performance enhancements
over the benchmark method.",2024-10-29,"Young Hyun Cho, Will Wei Sun",http://arxiv.org/pdf/2410.22488v1,cs.LG
Bayesian Counterfactual Prediction Models for HIV Care Retention with Incomplete Outcome and Covariate Information,"Like many chronic diseases, human immunodeficiency virus (HIV) is managed
over time at regular clinic visits. At each visit, patient features are
assessed, treatments are prescribed, and a subsequent visit is scheduled. There
is a need for data-driven methods for both predicting retention and
recommending scheduling decisions that optimize retention. Prediction models
can be useful for estimating retention rates across a range of scheduling
options. However, training such models with electronic health records (EHR)
involves several complexities. First, formal causal inference methods are
needed to adjust for observed confounding when estimating retention rates under
counterfactual scheduling decisions. Second, competing events such as death
preclude retention, while censoring events render retention missing. Third,
inconsistent monitoring of features such as viral load and CD4 count lead to
covariate missingness. This paper presents an all-in-one approach for both
predicting HIV retention and optimizing scheduling while accounting for these
complexities. We formulate and identify causal retention estimands in terms of
potential return-time under a hypothetical scheduling decision. Flexible
Bayesian approaches are used to model the observed return-time distribution
while accounting for competing and censoring events and form posterior point
and uncertainty estimates for these estimands. We address the urgent need for
data-driven decision support in HIV care by applying our method to EHR from the
Academic Model Providing Access to Healthcare (AMPATH) - a consortium of
clinics that treat HIV in Western Kenya.",2024-10-29,"Arman Oganisian, Joseph Hogan, Edwin Sang, Allison DeLong, Ben Mosong, Hamish Fraser, Ann Mwangi",http://arxiv.org/pdf/2410.22481v1,cs.LG
Learning Identifiable Factorized Causal Representations of Cellular Responses,"The study of cells and their responses to genetic or chemical perturbations
promises to accelerate the discovery of therapeutic targets. However, designing
adequate and insightful models for such data is difficult because the response
of a cell to perturbations essentially depends on its biological context (e.g.,
genetic background or cell type). For example, while discovering therapeutic
targets, one may want to enrich for drugs that specifically target a certain
cell type. This challenge emphasizes the need for methods that explicitly take
into account potential interactions between drugs and contexts. Towards this
goal, we propose a novel Factorized Causal Representation (FCR) learning method
that reveals causal structure in single-cell perturbation data from several
cell lines. Based on the framework of identifiable deep generative models, FCR
learns multiple cellular representations that are disentangled, comprised of
covariate-specific ($\mathbf{z}_x$), treatment-specific ($\mathbf{z}_{t}$), and
interaction-specific ($\mathbf{z}_{tx}$) blocks. Based on recent advances in
non-linear ICA theory, we prove the component-wise identifiability of
$\mathbf{z}_{tx}$ and block-wise identifiability of $\mathbf{z}_t$ and
$\mathbf{z}_x$. Then, we present our implementation of FCR, and empirically
demonstrate that it outperforms state-of-the-art baselines in various tasks
across four single-cell datasets.",2024-10-29,"Haiyi Mao, Romain Lopez, Kai Liu, Jan-Christian Hütter, David Richmond, Panayiotis V. Benos, Lin Qiu",http://arxiv.org/pdf/2410.22472v3,cs.LG
Multimodal Quantum Natural Language Processing: A Novel Framework for using Quantum Methods to Analyse Real Data,"Despite significant advances in quantum computing across various domains,
research on applying quantum approaches to language compositionality - such as
modeling linguistic structures and interactions - remains limited. This gap
extends to the integration of quantum language data with real-world data from
sources like images, video, and audio. This thesis explores how quantum
computational methods can enhance the compositional modeling of language
through multimodal data integration. Specifically, it advances Multimodal
Quantum Natural Language Processing (MQNLP) by applying the Lambeq toolkit to
conduct a comparative analysis of four compositional models and evaluate their
influence on image-text classification tasks. Results indicate that
syntax-based models, particularly DisCoCat and TreeReader, excel in effectively
capturing grammatical structures, while bag-of-words and sequential models
struggle due to limited syntactic awareness. These findings underscore the
potential of quantum methods to enhance language modeling and drive
breakthroughs as quantum technology evolves.",2024-10-29,Hala Hawashin,http://arxiv.org/pdf/2411.05023v1,cs.LG
"Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset","Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.",2024-10-29,"Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar",http://arxiv.org/pdf/2410.22457v1,cs.LG
Explainable convolutional neural network model provides an alternative genome-wide association perspective on mutations in SARS-CoV-2,"Identifying mutations of SARS-CoV-2 strains associated with their phenotypic
changes is critical for pandemic prediction and prevention. We compared an
explainable convolutional neural network (CNN) approach and the traditional
genome-wide association study (GWAS) on the mutations associated with WHO
labels of SARS-CoV-2, a proxy for virulence phenotypes. We trained a CNN
classification model that can predict genomic sequences into Variants of
Concern (VOCs) and then applied Shapley Additive explanations (SHAP) model to
identify mutations that are important for the correct predictions. For
comparison, we performed traditional GWAS to identify mutations associated with
VOCs. Comparison of the two approaches shows that the explainable neural
network approach can more effectively reveal known nucleotide substitutions
associated with VOCs, such as those in the spike gene regions. Our results
suggest that explainable neural networks for genomic sequences offer a
promising alternative to the traditional genome wide analysis approaches.",2024-10-29,"Parisa Hatami, Richard Annan, Luis Urias Miranda, Jane Gorman, Mengjun Xie, Letu Qingge, Hong Qin",http://arxiv.org/pdf/2410.22452v2,cs.LG
A Closer Look at Neural Codec Resynthesis: Bridging the Gap between Codec and Waveform Generation,"Neural Audio Codecs, initially designed as a compression technique, have
gained more attention recently for speech generation. Codec models represent
each audio frame as a sequence of tokens, i.e., discrete embeddings. The
discrete and low-frequency nature of neural codecs introduced a new way to
generate speech with token-based models. As these tokens encode information at
various levels of granularity, from coarse to fine, most existing works focus
on how to better generate the coarse tokens. In this paper, we focus on an
equally important but often overlooked question: How can we better resynthesize
the waveform from coarse tokens? We point out that both the choice of learning
target and resynthesis approach have a dramatic impact on the generated audio
quality. Specifically, we study two different strategies based on token
prediction and regression, and introduce a new method based on Schr\""odinger
Bridge. We examine how different design choices affect machine and human
perception.",2024-10-29,"Alexander H. Liu, Qirui Wang, Yuan Gong, James Glass",http://arxiv.org/pdf/2410.22448v1,cs.LG
Power side-channel leakage localization through adversarial training of deep neural networks,"Supervised deep learning has emerged as an effective tool for carrying out
power side-channel attacks on cryptographic implementations. While
increasingly-powerful deep learning-based attacks are regularly published,
comparatively-little work has gone into using deep learning to defend against
these attacks. In this work we propose a technique for identifying which
timesteps in a power trace are responsible for leaking a cryptographic key,
through an adversarial game between a deep learning-based side-channel attacker
which seeks to classify a sensitive variable from the power traces recorded
during encryption, and a trainable noise generator which seeks to thwart this
attack by introducing a minimal amount of noise into the power traces. We
demonstrate on synthetic datasets that our method can outperform existing
techniques in the presence of common countermeasures such as Boolean masking
and trace desynchronization. Results on real datasets are weak because the
technique is highly sensitive to hyperparameters and early-stop point, and we
lack a holdout dataset with ground truth knowledge of leaking points for model
selection. Nonetheless, we believe our work represents an important first step
towards deep side-channel leakage localization without relying on strong
assumptions about the implementation or the nature of its leakage. An
open-source PyTorch implementation of our experiments is provided.",2024-10-29,"Jimmy Gammell, Anand Raghunathan, Kaushik Roy",http://arxiv.org/pdf/2410.22425v1,cs.LG
Local Policies Enable Zero-shot Long-horizon Manipulation,"Sim2real for robotic manipulation is difficult due to the challenges of
simulating complex contacts and generating realistic task distributions. To
tackle the latter problem, we introduce ManipGen, which leverages a new class
of policies for sim2real transfer: local policies. Locality enables a variety
of appealing properties including invariances to absolute robot and object
pose, skill ordering, and global scene configuration. We combine these policies
with foundation models for vision, language and motion planning and demonstrate
SOTA zero-shot performance of our method to Robosuite benchmark tasks in
simulation (97%). We transfer our local policies from simulation to reality and
observe they can solve unseen long-horizon manipulation tasks with up to 8
stages with significant pose, object and scene configuration variation.
ManipGen outperforms SOTA approaches such as SayCan, OpenVLA, LLMTrajGen and
VoxPoser across 50 real-world manipulation tasks by 36%, 76%, 62% and 60%
respectively. Video results at https://mihdalal.github.io/manipgen/",2024-10-29,"Murtaza Dalal, Min Liu, Walter Talbott, Chen Chen, Deepak Pathak, Jian Zhang, Ruslan Salakhutdinov",http://arxiv.org/pdf/2410.22332v2,cs.LG
Vision-Language Models Create Cross-Modal Task Representations,"Autoregressive vision-language models (VLMs) can handle many tasks within a
single model, yet the representations that enable this capability remain
opaque. We find that VLMs align conceptually equivalent inputs into a shared
task vector, which is invariant to modality (text, image) and format (examples,
instruction), and may simplify VLM processing. We measure this alignment via
cross-modal transfer -- the ability of a task vector derived in one modality to
trigger the correct generation in another -- on a range of tasks and model
architectures. Although the task vector is highly compressed, we find that this
single vector outperforms prompting the model with the full task information,
unique to this cross-modal case. Furthermore, we show that task vectors can be
transferred from a base language model to its fine-tuned vision-language
counterpart, and that they can be derived solely from instructions without the
need for examples. Taken together, our findings shed light on how VLMs
internally process task information, and how they map different modalities into
common semantic representations. Project page:
https://vlm-cross-modal-reps.github.io.",2024-10-29,"Grace Luo, Trevor Darrell, Amir Bar",http://arxiv.org/pdf/2410.22330v2,cs.LG
Optimizing Posterior Samples for Bayesian Optimization via Rootfinding,"Bayesian optimization devolves the global optimization of a costly objective
function to the global optimization of a sequence of acquisition functions.
This inner-loop optimization can be catastrophically difficult if it involves
posterior sample paths, especially in higher dimensions. We introduce an
efficient global optimization strategy for posterior samples based on global
rootfinding. It provides gradient-based optimizers with two sets of judiciously
selected starting points, designed to combine exploration and exploitation. The
number of starting points can be kept small without sacrificing optimization
quality. Remarkably, even with just one point from each set, the global optimum
is discovered most of the time. The algorithm scales practically linearly to
high dimensions, breaking the curse of dimensionality. For Gaussian process
Thompson sampling (GP-TS), we demonstrate remarkable improvement in both inner-
and outer-loop optimization, surprisingly outperforming alternatives like EI
and GP-UCB in most cases. Our approach also improves the performance of other
posterior sample-based acquisition functions, such as variants of entropy
search. Furthermore, we propose a sample-average formulation of GP-TS, which
has a parameter to explicitly control exploitation and can be computed at the
cost of one posterior sample. Our implementation is available at
https://github.com/UQUH/TSRoots .",2024-10-29,"Taiwo A. Adebiyi, Bach Do, Ruda Zhang",http://arxiv.org/pdf/2410.22322v4,cs.LG
Breast Cancer Histopathology Classification using CBAM-EfficientNetV2 with Transfer Learning,"Breast cancer histopathology image classification is critical for early
detection and improved patient outcomes. 1 This study introduces a novel
approach leveraging EfficientNetV2 models, to improve feature extraction and
focus on relevant tissue regions. The proposed models were evaluated on the
BreakHis dataset across multiple magnification scales (40X, 100X, 200X, and
400X). 2 Among them, the EfficientNetV2-XL with CBAM achieved outstanding
performance, reaching a peak accuracy of 99.01 percent and an F1-score of 98.31
percent at 400X magnification, outperforming state-of-the-art methods. 3 By
integrating Contrast Limited Adaptive Histogram Equalization (CLAHE) for
preprocessing and optimizing computational efficiency, this method demonstrates
its suitability for real-time clinical deployment. 3 The results underscore the
potential of attention-enhanced scalable architectures in advancing diagnostic
precision for breast cancer detection.",2024-10-29,Naren Sengodan,http://arxiv.org/pdf/2410.22392v6,cs.LG
A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks,"In recent years, there has been a trend in the field of Reinforcement
Learning (RL) towards large action models trained offline on large-scale
datasets via sequence modeling. Existing models are primarily based on the
Transformer architecture, which result in powerful agents. However, due to slow
inference times, Transformer-based approaches are impractical for real-time
applications, such as robotics. Recently, modern recurrent architectures, such
as xLSTM and Mamba, have been proposed that exhibit parallelization benefits
during training similar to the Transformer architecture while offering fast
inference. In this work, we study the aptitude of these modern recurrent
architectures for large action models. Consequently, we propose a Large
Recurrent Action Model (LRAM) with an xLSTM at its core that comes with
linear-time inference complexity and natural sequence length extrapolation
abilities. Experiments on 432 tasks from 6 domains show that LRAM compares
favorably to Transformers in terms of performance and speed.",2024-10-29,"Thomas Schmied, Thomas Adler, Vihang Patil, Maximilian Beck, Korbinian Pöppel, Johannes Brandstetter, Günter Klambauer, Razvan Pascanu, Sepp Hochreiter",http://arxiv.org/pdf/2410.22391v2,cs.LG
Online Detecting LLM-Generated Texts via Sequential Hypothesis Testing by Betting,"Developing algorithms to differentiate between machine-generated texts and
human-written texts has garnered substantial attention in recent years.
Existing methods in this direction typically concern an offline setting where a
dataset containing a mix of real and machine-generated texts is given upfront,
and the task is to determine whether each sample in the dataset is from a large
language model (LLM) or a human. However, in many practical scenarios, sources
such as news websites, social media accounts, or on other forums publish
content in a streaming fashion. Therefore, in this online scenario, how to
quickly and accurately determine whether the source is an LLM with strong
statistical guarantees is crucial for these media or platforms to function
effectively and prevent the spread of misinformation and other potential misuse
of LLMs. To tackle the problem of online detection, we develop an algorithm
based on the techniques of sequential hypothesis testing by betting that not
only builds upon and complements existing offline detection techniques but also
enjoys statistical guarantees, which include a controlled false positive rate
and the expected time to correctly identify a source as an LLM. Experiments
were conducted to demonstrate the effectiveness of our method.",2024-10-29,"Can Chen, Jun-Kun Wang",http://arxiv.org/pdf/2410.22318v2,cs.LG
Convex Formulations for Training Two-Layer ReLU Neural Networks,"Solving non-convex, NP-hard optimization problems is crucial for training
machine learning models, including neural networks. However, non-convexity
often leads to black-box machine learning models with unclear inner workings.
While convex formulations have been used for verifying neural network
robustness, their application to training neural networks remains less
explored. In response to this challenge, we reformulate the problem of training
infinite-width two-layer ReLU networks as a convex completely positive program
in a finite-dimensional (lifted) space. Despite the convexity, solving this
problem remains NP-hard due to the complete positivity constraint. To overcome
this challenge, we introduce a semidefinite relaxation that can be solved in
polynomial time. We then experimentally evaluate the tightness of this
relaxation, demonstrating its competitive performance in test accuracy across a
range of classification tasks.",2024-10-29,"Karthik Prakhya, Tolga Birdal, Alp Yurtsever",http://arxiv.org/pdf/2410.22311v2,cs.LG
SVIP: Towards Verifiable Inference of Open-source Large Language Models,"Open-source Large Language Models (LLMs) have recently demonstrated
remarkable capabilities in natural language understanding and generation,
leading to widespread adoption across various domains. However, their
increasing model sizes render local deployment impractical for individual
users, pushing many to rely on computing service providers for inference
through a blackbox API. This reliance introduces a new risk: a computing
provider may stealthily substitute the requested LLM with a smaller, less
capable model without consent from users, thereby delivering inferior outputs
while benefiting from cost savings. In this paper, we formalize the problem of
verifiable inference for LLMs. Existing verifiable computing solutions based on
cryptographic or game-theoretic techniques are either computationally
uneconomical or rest on strong assumptions. We introduce SVIP, a secret-based
verifiable LLM inference protocol that leverages intermediate outputs from LLM
as unique model identifiers. By training a proxy task on these outputs and
requiring the computing provider to return both the generated text and the
processed intermediate outputs, users can reliably verify whether the computing
provider is acting honestly. In addition, the integration of a secret mechanism
further enhances the security of our protocol. We thoroughly analyze our
protocol under multiple strong and adaptive adversarial scenarios. Our
extensive experiments demonstrate that SVIP is accurate, generalizable,
computationally efficient, and resistant to various attacks. Notably, SVIP
achieves false negative rates below 5% and false positive rates below 3%, while
requiring less than 0.01 seconds per query for verification.",2024-10-29,"Yifan Sun, Yuhang Li, Yue Zhang, Yuchen Jin, Huan Zhang",http://arxiv.org/pdf/2410.22307v1,cs.LG
Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning,"Mathematical reasoning is a crucial capability for Large Language Models
(LLMs), yet generating detailed and accurate reasoning traces remains a
significant challenge. This paper introduces a novel approach to produce
high-quality reasoning traces for LLM fine-tuning using online learning
\textbf{Flows}. Our method employs an incremental output production Flow, where
component LLMs collaboratively construct solutions through iterative
communication. We train the Flow using online Direct Preference Optimization
(DPO) learning with rollouts, generating DPO pairs for each training example
and updating models in real-time. We directly compare the quality of reasoning
traces generated by our method with those produced through direct model
inference, demonstrating the effectiveness of our approach in improving LLM
performance in mathematical reasoning tasks.",2024-10-29,"Yihe Deng, Paul Mineiro",http://arxiv.org/pdf/2410.22304v1,cs.LG
$\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning,"Our work aims to minimize interaction in secure computation due to the high
cost and challenges associated with communication rounds, particularly in
scenarios with many clients. In this work, we revisit the problem of secure
aggregation in the single-server setting where a single evaluation server can
securely aggregate client-held individual inputs. Our key contribution is the
introduction of One-shot Private Aggregation ($\mathsf{OPA}$) where clients
speak only once (or even choose not to speak) per aggregation evaluation. Since
each client communicates only once per aggregation, this simplifies managing
dropouts and dynamic participation, contrasting with multi-round protocols and
aligning with plaintext secure aggregation, where clients interact only once.
We construct $\mathsf{OPA}$ based on LWR, LWE, class groups, DCR and
demonstrate applications to privacy-preserving Federated Learning (FL) where
clients \emph{speak once}. This is a sharp departure from prior multi-round FL
protocols whose study was initiated by Bonawitz et al. (CCS, 2017). Moreover,
unlike the YOSO (You Only Speak Once) model for general secure computation,
$\mathsf{OPA}$ eliminates complex committee selection protocols to achieve
adaptive security. Beyond asymptotic improvements, $\mathsf{OPA}$ is practical,
outperforming state-of-the-art solutions. We benchmark logistic regression
classifiers for two datasets, while also building an MLP classifier to train on
MNIST, CIFAR-10, and CIFAR-100 datasets. We build two flavors of $\caps$ (1)
from (threshold) key homomorphic PRF and (2) from seed homomorphic PRG and
secret sharing.",2024-10-29,"Harish Karthikeyan, Antigoni Polychroniadou",http://arxiv.org/pdf/2410.22303v1,cs.LG
Emotion-Guided Image to Music Generation,"Generating music from images can enhance various applications, including
background music for photo slideshows, social media experiences, and video
creation. This paper presents an emotion-guided image-to-music generation
framework that leverages the Valence-Arousal (VA) emotional space to produce
music that aligns with the emotional tone of a given image. Unlike previous
models that rely on contrastive learning for emotional consistency, the
proposed approach directly integrates a VA loss function to enable accurate
emotional alignment. The model employs a CNN-Transformer architecture,
featuring pre-trained CNN image feature extractors and three Transformer
encoders to capture complex, high-level emotional features from MIDI music.
Three Transformer decoders refine these features to generate musically and
emotionally consistent MIDI sequences. Experimental results on a newly curated
emotionally paired image-MIDI dataset demonstrate the proposed model's superior
performance across metrics such as Polyphony Rate, Pitch Entropy, Groove
Consistency, and loss convergence.",2024-10-29,"Souraja Kundu, Saket Singh, Yuji Iwahori",http://arxiv.org/pdf/2410.22299v1,cs.LG
Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained Biophysical Sequence Optimization Tasks,"Although large language models (LLMs) have shown promise in biomolecule
optimization problems, they incur heavy computational costs and struggle to
satisfy precise constraints. On the other hand, specialized solvers like
LaMBO-2 offer efficiency and fine-grained control but require more domain
expertise. Comparing these approaches is challenging due to expensive
laboratory validation and inadequate synthetic benchmarks. We address this by
introducing Ehrlich functions, a synthetic test suite that captures the
geometric structure of biophysical sequence optimization problems. With
prompting alone, off-the-shelf LLMs struggle to optimize Ehrlich functions. In
response, we propose LLOME (Language Model Optimization with Margin
Expectation), a bilevel optimization routine for online black-box optimization.
When combined with a novel preference learning loss, we find LLOME can not only
learn to solve some Ehrlich functions, but can even outperform LaMBO-2 on
moderately difficult Ehrlich variants. However, LLOME is comparable to LaMBO-2
on very easy or difficult variants, exhibits some likelihood-reward
miscalibration, and struggles without explicit rewards. Our results indicate
LLMs can provide significant benefits in some cases, but specialized solvers
are still competitive and incur less overhead.",2024-10-29,"Angelica Chen, Samuel D. Stanton, Frances Ding, Robert G. Alberstein, Andrew M. Watkins, Richard Bonneau, Vladimir Gligorijević, Kyunghyun Cho, Nathan C. Frey",http://arxiv.org/pdf/2410.22296v4,cs.LG
"Batch, match, and patch: low-rank approximations for score-based variational inference","Black-box variational inference (BBVI) scales poorly to high-dimensional
problems when it is used to estimate a multivariate Gaussian approximation with
a full covariance matrix. In this paper, we extend the batch-and-match (BaM)
framework for score-based BBVI to problems where it is prohibitively expensive
to store such covariance matrices, let alone to estimate them. Unlike classical
algorithms for BBVI, which use stochastic gradient descent to minimize the
reverse Kullback-Leibler divergence, BaM uses more specialized updates to match
the scores of the target density and its Gaussian approximation. We extend the
updates for BaM by integrating them with a more compact parameterization of
full covariance matrices. In particular, borrowing ideas from factor analysis,
we add an extra step to each iteration of BaM--a patch--that projects each
newly updated covariance matrix into a more efficiently parameterized family of
diagonal plus low rank matrices. We evaluate this approach on a variety of
synthetic target distributions and real-world problems in high-dimensional
inference.",2024-10-29,"Chirag Modi, Diana Cai, Lawrence K. Saul",http://arxiv.org/pdf/2410.22292v2,cs.LG
A Message Passing Neural Network Surrogate Model for Bond-Associated Peridynamic Material Correspondence Formulation,"Peridynamics is a non-local continuum mechanics theory that offers unique
advantages for modeling problems involving discontinuities and complex
deformations. Within the peridynamic framework, various formulations exist,
among which the material correspondence formulation stands out for its ability
to directly incorporate traditional continuum material models, making it highly
applicable to a range of engineering challenges. A notable advancement in this
area is the bond-associated correspondence model, which not only resolves
issues of material instability but also achieves high computational accuracy.
However, the bond-associated model typically requires higher computational
costs than FEA, which can limit its practical application. To address this
computational challenge, we propose a novel surrogate model based on a
message-passing neural network (MPNN) specifically designed for the
bond-associated peridynamic material correspondence formulation. Leveraging the
similarities between graph structure and the neighborhood connectivity inherent
to peridynamics, we construct an MPNN that can transfers domain knowledge from
peridynamics into a computational graph and shorten the computation time via
GPU acceleration. Unlike conventional graph neural networks that focus on node
features, our model emphasizes edge-based features, capturing the essential
material point interactions in the formulation. A key advantage of this neural
network approach is its flexibility: it does not require fixed neighborhood
connectivity, making it adaptable across diverse configurations and scalable
for complex systems. Furthermore, the model inherently possesses translational
and rotational invariance, enabling it to maintain physical objectivity: a
critical requirement for accurate mechanical modeling.",2024-10-29,"Xuan Hu, Qijun Chen, Nicholas H. Luo, Richy J. Zheng, Shaofan Li",http://arxiv.org/pdf/2411.08911v1,cs.LG
Embedding-based classifiers can detect prompt injection attacks,"Large Language Models (LLMs) are seeing significant adoption in every type of
organization due to their exceptional generative capabilities. However, LLMs
are found to be vulnerable to various adversarial attacks, particularly prompt
injection attacks, which trick them into producing harmful or inappropriate
content. Adversaries execute such attacks by crafting malicious prompts to
deceive the LLMs. In this paper, we propose a novel approach based on
embedding-based Machine Learning (ML) classifiers to protect LLM-based
applications against this severe threat. We leverage three commonly used
embedding models to generate embeddings of malicious and benign prompts and
utilize ML classifiers to predict whether an input prompt is malicious. Out of
several traditional ML methods, we achieve the best performance with
classifiers built using Random Forest and XGBoost. Our classifiers outperform
state-of-the-art prompt injection classifiers available in open-source
implementations, which use encoder-only neural networks.",2024-10-29,"Md. Ahsan Ayub, Subhabrata Majumdar",http://arxiv.org/pdf/2410.22284v1,cs.LG
Leveraging Recurrent Neural Networks for Predicting Motor Movements from Primate Motor Cortex Neural Recordings,"This paper presents an efficient deep learning solution for decoding motor
movements from neural recordings in non-human primates. An Autoencoder Gated
Recurrent Unit (AEGRU) model was adopted as the model architecture for this
task. The autoencoder is only used during the training stage to achieve better
generalization. Together with the preprocessing techniques, our model achieved
0.71 $R^2$ score, surpassing the baseline models in Neurobench and is ranked
first for $R^2$ in the IEEE BioCAS 2024 Grand Challenge on Neural Decoding.
Model pruning is also applied leading to a reduction of 41.4% of the
multiply-accumulate (MAC) operations with little change in the $R^2$ score
compared to the unpruned model.",2024-10-29,"Yuanxi Wang, Zuowen Wang, Shih-Chii Liu",http://arxiv.org/pdf/2410.22283v2,cs.LG
FNDEX: Fake News and Doxxing Detection with Explainable AI,"The widespread and diverse online media platforms and other internet-driven
communication technologies have presented significant challenges in defining
the boundaries of freedom of expression. Consequently, the internet has been
transformed into a potential cyber weapon. Within this evolving landscape, two
particularly hazardous phenomena have emerged: fake news and doxxing. Although
these threats have been subjects of extensive scholarly analysis, the
crossroads where they intersect remain unexplored. This research addresses this
convergence by introducing a novel system. The Fake News and Doxxing Detection
with Explainable Artificial Intelligence (FNDEX) system leverages the
capabilities of three distinct transformer models to achieve high-performance
detection for both fake news and doxxing. To enhance data security, a rigorous
three-step anonymization process is employed, rooted in a pattern-based
approach for anonymizing personally identifiable information. Finally, this
research emphasizes the importance of generating coherent explanations for the
outcomes produced by both detection models. Our experiments on realistic
datasets demonstrate that our system significantly outperforms the existing
baselines",2024-10-29,"Dorsaf Sallami, Esma Aïmeur",http://arxiv.org/pdf/2410.22390v1,cs.LG
Fourier Head: Helping Large Language Models Learn Complex Probability Distributions,"As the quality of large language models has improved, there has been
increased interest in using them to model non-linguistic tokens. For example,
the Decision Transformer recasts agentic decision making as a sequence modeling
problem, using a decoder-only LLM to model the distribution over the discrete
action space for an Atari agent. However, when adapting LLMs to non-linguistic
domains, it remains unclear if softmax over discrete bins captures the
continuous structure of the tokens and the potentially complex distributions
needed for high quality token generation. We introduce a neural network layer,
constructed using Fourier series, which we can easily substitute for any linear
layer if we want the outputs to have a more continuous structure. We perform
extensive analysis on synthetic datasets, as well as on large-scale decision
making and time series forecasting tasks. We also provide theoretical evidence
that this layer can better learn signal from data while ignoring high-frequency
noise. All of our results support the effectiveness of our proposed Fourier
head in scenarios where the underlying data distribution has a natural
continuous structure. For example, the Fourier head improves a Decision
Transformer agent's returns across four benchmark Atari games by as much as
377%, and increases a state-of-the-art times series foundation model's
forecasting performance by 3.5% across 20 benchmarks unseen during training.",2024-10-29,"Nate Gillman, Daksh Aggarwal, Michael Freeman, Saurabh Singh, Chen Sun",http://arxiv.org/pdf/2410.22269v2,cs.LG
Meta-Learning Adaptable Foundation Models,"The power of foundation models (FMs) lies in their capacity to learn highly
expressive representations that can be adapted to a broad spectrum of tasks.
However, these pretrained models require multiple stages of fine-tuning to
become effective for downstream applications. Conventionally, the model is
first retrained on the aggregate of a diverse set of tasks of interest and then
adapted to specific low-resource downstream tasks by utilizing a
parameter-efficient fine-tuning (PEFT) scheme. While this two-phase procedure
seems reasonable, the independence of the retraining and fine-tuning phases
causes a major issue, as there is no guarantee the retrained model will achieve
good performance post-fine-tuning. To explicitly address this issue, we
introduce a meta-learning framework infused with PEFT in this intermediate
retraining stage to learn a model that can be easily adapted to unseen tasks.
For our theoretical results, we focus on linear models using low-rank
adaptations. In this setting, we demonstrate the suboptimality of standard
retraining for finding an adaptable set of parameters. Further, we prove that
our method recovers the optimally adaptable parameters. We then apply these
theoretical insights to retraining the RoBERTa model to predict the
continuation of conversations between different personas within the ConvAI2
dataset. Empirically, we observe significant performance benefits using our
proposed meta-learning scheme during retraining relative to the conventional
approach.",2024-10-29,"Jacob L. Block, Sundararajan Srinivasan, Liam Collins, Aryan Mokhtari, Sanjay Shakkottai",http://arxiv.org/pdf/2410.22264v1,cs.LG
LipKernel: Lipschitz-Bounded Convolutional Neural Networks via Dissipative Layers,"We propose a novel layer-wise parameterization for convolutional neural
networks (CNNs) that includes built-in robustness guarantees by enforcing a
prescribed Lipschitz bound. Each layer in our parameterization is designed to
satisfy a linear matrix inequality (LMI), which in turn implies dissipativity
with respect to a specific supply rate. Collectively, these layer-wise LMIs
ensure Lipschitz boundedness for the input-output mapping of the neural
network, yielding a more expressive parameterization than through spectral
bounds or orthogonal layers. Our new method LipKernel directly parameterizes
dissipative convolution kernels using a 2-D Roesser-type state space model.
This means that the convolutional layers are given in standard form after
training and can be evaluated without computational overhead. In numerical
experiments, we show that the run-time using our method is orders of magnitude
faster than state-of-the-art Lipschitz-bounded networks that parameterize
convolutions in the Fourier domain, making our approach particularly attractive
for improving robustness of learning-based real-time perception or control in
robotics, autonomous vehicles, or automation systems. We focus on CNNs, and in
contrast to previous works, our approach accommodates a wide variety of layers
typically used in CNNs, including 1-D and 2-D convolutional layers, maximum and
average pooling layers, as well as strided and dilated convolutions and zero
padding. However, our approach naturally extends beyond CNNs as we can
incorporate any layer that is incrementally dissipative.",2024-10-29,"Patricia Pauli, Ruigang Wang, Ian Manchester, Frank Allgöwer",http://arxiv.org/pdf/2410.22258v1,cs.LG
Hypergraph-based multi-scale spatio-temporal graph convolution network for Time-Series anomaly detection,"Multivariate time series anomaly detection technology plays an important role
in many fields including aerospace, water treatment, cloud service providers,
etc. Excellent anomaly detection models can greatly improve work efficiency and
avoid major economic losses. However, with the development of technology, the
increasing size and complexity of data, and the lack of labels for relevant
abnormal data, it is becoming increasingly challenging to perform effective and
accurate anomaly detection in high-dimensional and complex data sets. In this
paper, we propose a hypergraph based spatiotemporal graph convolutional neural
network model STGCN_Hyper, which explicitly captures high-order, multi-hop
correlations between multiple variables through a hypergraph based dynamic
graph structure learning module. On this basis, we further use the hypergraph
based spatiotemporal graph convolutional network to utilize the learned
hypergraph structure to effectively propagate and aggregate one-hop and
multi-hop related node information in the convolutional network, thereby
obtaining rich spatial information. Furthermore, through the multi-scale TCN
dilated convolution module, the STGCN_hyper model can also capture the
dependencies of features at different scales in the temporal dimension. An
unsupervised anomaly detector based on PCA and GMM is also integrated into the
STGCN_hyper model. Through the anomaly score of the detector, the model can
detect the anomalies in an unsupervised way. Experimental results on multiple
time series datasets show that our model can flexibly learn the multi-scale
time series features in the data and the dependencies between features, and
outperforms most existing baseline models in terms of precision, recall,
F1-score on anomaly detection tasks. Our code is available on:
https://git.ecdf.ed.ac.uk/msc-23-24/s2044819",2024-10-29,Hongyi Xu,http://arxiv.org/pdf/2410.22256v1,cs.LG
Scalable Message Passing Neural Networks: No Need for Attention in Large Graph Representation Learning,"We propose Scalable Message Passing Neural Networks (SMPNNs) and demonstrate
that, by integrating standard convolutional message passing into a Pre-Layer
Normalization Transformer-style block instead of attention, we can produce
high-performing deep message-passing-based Graph Neural Networks (GNNs). This
modification yields results competitive with the state-of-the-art in large
graph transductive learning, particularly outperforming the best Graph
Transformers in the literature, without requiring the otherwise computationally
and memory-expensive attention mechanism. Our architecture not only scales to
large graphs but also makes it possible to construct deep message-passing
networks, unlike simple GNNs, which have traditionally been constrained to
shallow architectures due to oversmoothing. Moreover, we provide a new
theoretical analysis of oversmoothing based on universal approximation which we
use to motivate SMPNNs. We show that in the context of graph convolutions,
residual connections are necessary for maintaining the universal approximation
properties of downstream learners and that removing them can lead to a loss of
universality.",2024-10-29,"Haitz Sáez de Ocáriz Borde, Artem Lukoianov, Anastasis Kratsios, Michael Bronstein, Xiaowen Dong",http://arxiv.org/pdf/2411.00835v1,cs.LG
Pushing the Performance Envelope of DNN-based Recommendation Systems Inference on GPUs,"Personalized recommendation is a ubiquitous application on the internet, with
many industries and hyperscalers extensively leveraging Deep Learning
Recommendation Models (DLRMs) for their personalization needs (like ad serving
or movie suggestions). With growing model and dataset sizes pushing computation
and memory requirements, GPUs are being increasingly preferred for executing
DLRM inference. However, serving newer DLRMs, while meeting acceptable
latencies, continues to remain challenging, making traditional deployments
increasingly more GPU-hungry, resulting in higher inference serving costs. In
this paper, we show that the embedding stage continues to be the primary
bottleneck in the GPU inference pipeline, leading up to a 3.2x embedding-only
performance slowdown.
  To thoroughly grasp the problem, we conduct a detailed microarchitecture
characterization and highlight the presence of low occupancy in the standard
embedding kernels. By leveraging direct compiler optimizations, we achieve
optimal occupancy, pushing the performance by up to 53%. Yet, long memory
latency stalls continue to exist. To tackle this challenge, we propose
specialized plug-and-play-based software prefetching and L2 pinning techniques,
which help in hiding and decreasing the latencies. Further, we propose
combining them, as they complement each other. Experimental evaluations using
A100 GPUs with large models and datasets show that our proposed techniques
improve performance by up to 103% for the embedding stage, and up to 77% for
the overall DLRM inference pipeline.",2024-10-29,"Rishabh Jain, Vivek M. Bhasi, Adwait Jog, Anand Sivasubramaniam, Mahmut T. Kandemir, Chita R. Das",http://arxiv.org/pdf/2410.22249v1,cs.LG
Abrupt Learning in Transformers: A Case Study on Matrix Completion,"Recent analysis on the training dynamics of Transformers has unveiled an
interesting characteristic: the training loss plateaus for a significant number
of training steps, and then suddenly (and sharply) drops to near--optimal
values. To understand this phenomenon in depth, we formulate the low-rank
matrix completion problem as a masked language modeling (MLM) task, and show
that it is possible to train a BERT model to solve this task to low error.
Furthermore, the loss curve shows a plateau early in training followed by a
sudden drop to near-optimal values, despite no changes in the training
procedure or hyper-parameters. To gain interpretability insights into this
sudden drop, we examine the model's predictions, attention heads, and hidden
states before and after this transition. Concretely, we observe that (a) the
model transitions from simply copying the masked input to accurately predicting
the masked entries; (b) the attention heads transition to interpretable
patterns relevant to the task; and (c) the embeddings and hidden states encode
information relevant to the problem. We also analyze the training dynamics of
individual model components to understand the sudden drop in loss.",2024-10-29,"Pulkit Gopalani, Ekdeep Singh Lubana, Wei Hu",http://arxiv.org/pdf/2410.22244v1,cs.LG
DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers,"Despite their high predictive accuracies, current machine learning systems
often exhibit systematic biases stemming from annotation artifacts or
insufficient support for certain classes in the dataset. Recent work proposes
automatic methods for identifying and explaining systematic biases using
keywords. We introduce DISCERN, a framework for interpreting systematic biases
in text classifiers using language explanations. DISCERN iteratively generates
precise natural language descriptions of systematic errors by employing an
interactive loop between two large language models. Finally, we use the
descriptions to improve classifiers by augmenting classifier training sets with
synthetically generated instances or annotated examples via active learning. On
three text-classification datasets, we demonstrate that language explanations
from our framework induce consistent performance improvements that go beyond
what is achievable with exemplars of systematic bias. Finally, in human
evaluations, we show that users can interpret systematic biases more
effectively (by over 25% relative) and efficiently when described through
language explanations as opposed to cluster exemplars.",2024-10-29,"Rakesh R. Menon, Shashank Srivastava",http://arxiv.org/pdf/2410.22239v1,cs.LG
Auditing $f$-Differential Privacy in One Run,"Empirical auditing has emerged as a means of catching some of the flaws in
the implementation of privacy-preserving algorithms. Existing auditing
mechanisms, however, are either computationally inefficient requiring multiple
runs of the machine learning algorithms or suboptimal in calculating an
empirical privacy. In this work, we present a tight and efficient auditing
procedure and analysis that can effectively assess the privacy of mechanisms.
Our approach is efficient; similar to the recent work of Steinke, Nasr, and
Jagielski (2023), our auditing procedure leverages the randomness of examples
in the input dataset and requires only a single run of the target mechanism.
And it is more accurate; we provide a novel analysis that enables us to achieve
tight empirical privacy estimates by using the hypothesized $f$-DP curve of the
mechanism, which provides a more accurate measure of privacy than the
traditional $\epsilon,\delta$ differential privacy parameters. We use our
auditing procure and analysis to obtain empirical privacy, demonstrating that
our auditing procedure delivers tighter privacy estimates.",2024-10-29,"Saeed Mahloujifar, Luca Melis, Kamalika Chaudhuri",http://arxiv.org/pdf/2410.22235v1,cs.LG
Automated Feedback in Math Education: A Comparative Analysis of LLMs for Open-Ended Responses,"The effectiveness of feedback in enhancing learning outcomes is well
documented within Educational Data Mining (EDM). Various prior research has
explored methodologies to enhance the effectiveness of feedback. Recent
developments in Large Language Models (LLMs) have extended their utility in
enhancing automated feedback systems. This study aims to explore the potential
of LLMs in facilitating automated feedback in math education. We examine the
effectiveness of LLMs in evaluating student responses by comparing 3 different
models: Llama, SBERT-Canberra, and GPT4 model. The evaluation requires the
model to provide both a quantitative score and qualitative feedback on the
student's responses to open-ended math problems. We employ Mistral, a version
of Llama catered to math, and fine-tune this model for evaluating student
responses by leveraging a dataset of student responses and teacher-written
feedback for middle-school math problems. A similar approach was taken for
training the SBERT model as well, while the GPT4 model used a zero-shot
learning approach. We evaluate the model's performance in scoring accuracy and
the quality of feedback by utilizing judgments from 2 teachers. The teachers
utilized a shared rubric in assessing the accuracy and relevance of the
generated feedback. We conduct both quantitative and qualitative analyses of
the model performance. By offering a detailed comparison of these methods, this
study aims to further the ongoing development of automated feedback systems and
outlines potential future directions for leveraging generative LLMs to create
more personalized learning experiences.",2024-10-29,"Sami Baral, Eamon Worden, Wen-Chiang Lim, Zhuang Luo, Christopher Santorelli, Ashish Gurung, Neil Heffernan",http://arxiv.org/pdf/2411.08910v1,cs.LG
Subgraph Aggregation for Out-of-Distribution Generalization on Graphs,"Out-of-distribution (OOD) generalization in Graph Neural Networks (GNNs) has
gained significant attention due to its critical importance in graph-based
predictions in real-world scenarios. Existing methods primarily focus on
extracting a single causal subgraph from the input graph to achieve
generalizable predictions. However, relying on a single subgraph can lead to
susceptibility to spurious correlations and is insufficient for learning
invariant patterns behind graph data. Moreover, in many real-world
applications, such as molecular property prediction, multiple critical
subgraphs may influence the target label property. To address these challenges,
we propose a novel framework, SubGraph Aggregation (SuGAr), designed to learn a
diverse set of subgraphs that are crucial for OOD generalization on graphs.
Specifically, SuGAr employs a tailored subgraph sampler and diversity
regularizer to extract a diverse set of invariant subgraphs. These invariant
subgraphs are then aggregated by averaging their representations, which
enriches the subgraph signals and enhances coverage of the underlying causal
structures, thereby improving OOD generalization. Extensive experiments on both
synthetic and real-world datasets demonstrate that \ours outperforms
state-of-the-art methods, achieving up to a 24% improvement in OOD
generalization on graphs. To the best of our knowledge, this is the first work
to study graph OOD generalization by learning multiple invariant subgraphs.
code: https://github.com/Nanolbw/SuGAr",2024-10-29,"Bowen Liu, Haoyang Li, Shuning Wang, Shuo Nie, Shanghang Zhang",http://arxiv.org/pdf/2410.22228v2,cs.LG
Hybrid model of the kernel method for quantum computers,"The field of quantum machine learning is a promising way to lead to a
revolution in intelligent data processing methods. In this way, a hybrid
learning method based on classic kernel methods is proposed. This proposal also
requires the development of a quantum algorithm for the calculation of internal
products between vectors of continuous values. In order for this to be
possible, it was necessary to make adaptations to the classic kernel method,
since it is necessary to consider the limitations imposed by the Hilbert space
of the quantum processor. As a test case, we applied this new algorithm to
learn to classify whether new points generated randomly, in a finite square
located under a plane, were found inside or outside a circle located inside
this square. It was found that the algorithm was able to correctly detect new
points in 99% of the samples tested, with a small difference due to considering
the radius slightly larger than the ideal. However, the kernel method was able
to perform classifications correctly, as well as the internal product algorithm
successfully performed the internal product calculations using quantum
resources. Thus, the present work represents a contribution to the area,
proposing a new model of machine learning accessible to both physicists and
computer scientists.",2024-10-29,"Jhordan Silveira de Borba, Jonas Maziero",http://arxiv.org/pdf/2410.23315v1,cs.LG
ET-Flow: Equivariant Flow-Matching for Molecular Conformer Generation,"Predicting low-energy molecular conformations given a molecular graph is an
important but challenging task in computational drug discovery. Existing
state-of-the-art approaches either resort to large scale transformer-based
models that diffuse over conformer fields, or use computationally expensive
methods to generate initial structures and diffuse over torsion angles. In this
work, we introduce Equivariant Transformer Flow (ET-Flow). We showcase that a
well-designed flow matching approach with equivariance and harmonic prior
alleviates the need for complex internal geometry calculations and large
architectures, contrary to the prevailing methods in the field. Our approach
results in a straightforward and scalable method that directly operates on
all-atom coordinates with minimal assumptions. With the advantages of
equivariance and flow matching, ET-Flow significantly increases the precision
and physical validity of the generated conformers, while being a lighter model
and faster at inference. Code is available
https://github.com/shenoynikhil/ETFlow.",2024-10-29,"Majdi Hassan, Nikhil Shenoy, Jungyoon Lee, Hannes Stark, Stephan Thaler, Dominique Beaini",http://arxiv.org/pdf/2410.22388v1,cs.LG
Long-context Protein Language Modeling Using Bidirectional Mamba with Shared Projection Layers,"Self-supervised training of language models (LMs) has seen great success for
protein sequences in learning meaningful representations and for generative
drug design. Most protein LMs are based on the Transformer architecture trained
on individual proteins with short context lengths. Such protein LMs cannot
extrapolate to longer proteins and protein complexes well. They also fail to
account for the underlying biological mechanisms carried out by biomolecular
interactions and dynamics i.e., proteins often interact with other proteins,
molecules, and pathways in complex biological systems. In this work, we propose
LC-PLM based on an alternative protein LM architecture, BiMamba-S, built upon
selective structured state-space models, to learn high-quality universal
protein representations at the amino acid token level using masked language
modeling. We also introduce its graph-contextual variant, LC-PLM, which
contextualizes protein-protein interaction (PPI) graphs for a second stage of
training. LC-PLM demonstrates favorable neural scaling laws, better length
extrapolation capability, and up to 30% and 16% improvements on protein
downstream tasks compared to Transformer-based ESM-2 when trained with 100B and
1T tokens, respectively. LC-PLM-G further trained within the context of PPI
graphs shows promising results on protein structure and function prediction
tasks. Our study demonstrates the benefit of increasing the context size with
computationally efficient LM architecture (e.g., structured state space models)
in learning universal protein representations and incorporating molecular
interaction contexts contained in biological graphs.",2024-10-29,"Yingheng Wang, Zichen Wang, Gil Sadeh, Luca Zancato, Alessandro Achille, George Karypis, Huzefa Rangwala",http://arxiv.org/pdf/2411.08909v3,cs.LG
GoRINNs: Godunov-Riemann Informed Neural Networks for Learning Hyperbolic Conservation Laws,"We present GoRINNs: numerical analysis-informed (shallow) neural networks for
the solution of inverse problems of non-linear systems of conservation laws.
GoRINNs is a hybrid/blended machine learning scheme based on high-resolution
Godunov schemes for the solution of the Riemann problem in hyperbolic Partial
Differential Equations (PDEs). In contrast to other existing machine learning
methods that learn the numerical fluxes or just parameters of conservative
Finite Volume methods, relying on deep neural networks (that may lead to poor
approximations due to the computational complexity involved in their training),
GoRINNs learn the closures of the conservation laws per se based on
""intelligently"" numerical-assisted shallow neural networks. Due to their
structure, in particular, GoRINNs provide explainable, conservative schemes,
that solve the inverse problem for hyperbolic PDEs, on the basis of approximate
Riemann solvers that satisfy the Rankine-Hugoniot condition. The performance of
GoRINNs is assessed via four benchmark problems, namely the Burgers', the
Shallow Water, the Lighthill-Whitham-Richards and the Payne-Whitham traffic
flow models. The solution profiles of these PDEs exhibit shock waves,
rarefactions and/or contact discontinuities at finite times. We demonstrate
that GoRINNs provide a very high accuracy both in the smooth and discontinuous
regions.",2024-10-29,"Dimitrios G. Patsatzis, Mario di Bernardo, Lucia Russo, Constantinos Siettos",http://arxiv.org/pdf/2410.22193v3,cs.LG
$r$Age-$k$: Communication-Efficient Federated Learning Using Age Factor,"Federated learning (FL) is a collaborative approach where multiple clients,
coordinated by a parameter server (PS), train a unified machine-learning model.
The approach, however, suffers from two key challenges: data heterogeneity and
communication overhead. Data heterogeneity refers to inconsistencies in model
training arising from heterogeneous data at different clients. Communication
overhead arises from the large volumes of parameter updates exchanged between
the PS and clients. Existing solutions typically address these challenges
separately. This paper introduces a new communication-efficient algorithm that
uses the age of information metric to simultaneously tackle both limitations of
FL. We introduce age vectors at the PS, which keep track of how often the
different model parameters are updated from the clients. The PS uses this to
selectively request updates for specific gradient indices from each client.
Further, the PS employs age vectors to identify clients with statistically
similar data and group them into clusters. The PS combines the age vectors of
the clustered clients to efficiently coordinate gradient index updates among
clients within a cluster. We evaluate our approach using the MNIST and CIFAR10
datasets in highly non-i.i.d. settings. The experimental results show that our
proposed method can expedite training, surpassing other communication-efficient
strategies in efficiency.",2024-10-29,"Matin Mortaheb, Priyanka Kaswan, Sennur Ulukus",http://arxiv.org/pdf/2410.22192v1,cs.LG
Multi-Level Feature Distillation of Joint Teachers Trained on Distinct Image Datasets,"We propose a novel teacher-student framework to distill knowledge from
multiple teachers trained on distinct datasets. Each teacher is first trained
from scratch on its own dataset. Then, the teachers are combined into a joint
architecture, which fuses the features of all teachers at multiple
representation levels. The joint teacher architecture is fine-tuned on samples
from all datasets, thus gathering useful generic information from all data
samples. Finally, we employ a multi-level feature distillation procedure to
transfer the knowledge to a student model for each of the considered datasets.
We conduct image classification experiments on seven benchmarks, and action
recognition experiments on three benchmarks. To illustrate the power of our
feature distillation procedure, the student architectures are chosen to be
identical to those of the individual teachers. To demonstrate the flexibility
of our approach, we combine teachers with distinct architectures. We show that
our novel Multi-Level Feature Distillation (MLFD) can significantly surpass
equivalent architectures that are either trained on individual datasets, or
jointly trained on all datasets at once. Furthermore, we confirm that each step
of the proposed training procedure is well motivated by a comprehensive
ablation study. We publicly release our code at
https://github.com/AdrianIordache/MLFD.",2024-10-29,"Adrian Iordache, Bogdan Alexe, Radu Tudor Ionescu",http://arxiv.org/pdf/2410.22184v1,cs.LG
Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech,"Autoregressive (AR) Transformer-based sequence models are known to have
difficulty generalizing to sequences longer than those seen during training.
When applied to text-to-speech (TTS), these models tend to drop or repeat words
or produce erratic output, especially for longer utterances. In this paper, we
introduce enhancements aimed at AR Transformer-based encoder-decoder TTS
systems that address these robustness and length generalization issues. Our
approach uses an alignment mechanism to provide cross-attention operations with
relative location information. The associated alignment position is learned as
a latent property of the model via backpropagation and requires no external
alignment information during training. While the approach is tailored to the
monotonic nature of TTS input-output alignment, it is still able to benefit
from the flexible modeling power of interleaved multi-head self- and
cross-attention operations. A system incorporating these improvements, which we
call Very Attentive Tacotron, matches the naturalness and expressiveness of a
baseline T5-based TTS system, while eliminating problems with repeated or
dropped words and enabling generalization to any practical utterance length.",2024-10-29,"Eric Battenberg, RJ Skerry-Ryan, Daisy Stanton, Soroosh Mariooryad, Matt Shannon, Julian Salazar, David Kao",http://arxiv.org/pdf/2410.22179v2,cs.LG
EconoJax: A Fast & Scalable Economic Simulation in Jax,"Accurate economic simulations often require many experimental runs,
particularly when combined with reinforcement learning. Unfortunately, training
reinforcement learning agents in multi-agent economic environments can be slow.
This paper introduces EconoJax, a fast simulated economy, based on the AI
economist. EconoJax, and its training pipeline, are completely written in JAX.
This allows EconoJax to scale to large population sizes and perform large
experiments, while keeping training times within minutes. Through experiments
with populations of 100 agents, we show how real-world economic behavior
emerges through training within 15 minutes, in contrast to previous work that
required several days. We additionally perform experiments in varying sized
action spaces to test if some multi-agent methods produce more diverse behavior
compared to others. Here, our findings indicate no notable differences in
produced behavior with different methods as is sometimes suggested in earlier
works. To aid further research, we open-source EconoJax on Github.",2024-10-29,"Koen Ponse, Aske Plaat, Niki van Stein, Thomas M. Moerland",http://arxiv.org/pdf/2410.22165v2,cs.LG
Standardization Trends on Safety and Trustworthiness Technology for Advanced AI,"Artificial Intelligence (AI) has rapidly evolved over the past decade and has
advanced in areas such as language comprehension, image and video recognition,
programming, and scientific reasoning. Recent AI technologies based on large
language models and foundation models are approaching or surpassing artificial
general intelligence. These systems demonstrate superior performance in complex
problem solving, natural language processing, and multi-domain tasks, and can
potentially transform fields such as science, industry, healthcare, and
education. However, these advancements have raised concerns regarding the
safety and trustworthiness of advanced AI, including risks related to
uncontrollability, ethical conflicts, long-term socioeconomic impacts, and
safety assurance. Efforts are being expended to develop internationally
agreed-upon standards to ensure the safety and reliability of AI. This study
analyzes international trends in safety and trustworthiness standardization for
advanced AI, identifies key areas for standardization, proposes future
directions and strategies, and draws policy implications. The goal is to
support the safe and trustworthy development of advanced AI and enhance
international competitiveness through effective standardization.",2024-10-29,Jonghong Jeon,http://arxiv.org/pdf/2410.22151v1,cs.LG
Learning Successor Features the Simple Way,"In Deep Reinforcement Learning (RL), it is a challenge to learn
representations that do not exhibit catastrophic forgetting or interference in
non-stationary environments. Successor Features (SFs) offer a potential
solution to this challenge. However, canonical techniques for learning SFs from
pixel-level observations often lead to representation collapse, wherein
representations degenerate and fail to capture meaningful variations in the
data. More recent methods for learning SFs can avoid representation collapse,
but they often involve complex losses and multiple learning phases, reducing
their efficiency. We introduce a novel, simple method for learning SFs directly
from pixels. Our approach uses a combination of a Temporal-difference (TD) loss
and a reward prediction loss, which together capture the basic mathematical
definition of SFs. We show that our approach matches or outperforms existing SF
learning techniques in both 2D (Minigrid), 3D (Miniworld) mazes and Mujoco, for
both single and continual learning scenarios. As well, our technique is
efficient, and can reach higher levels of performance in less time than other
approaches. Our work provides a new, streamlined technique for learning SFs
directly from pixel observations, with no pretraining required.",2024-10-29,"Raymond Chua, Arna Ghosh, Christos Kaplanis, Blake A. Richards, Doina Precup",http://arxiv.org/pdf/2410.22133v2,cs.LG
RankUp: Boosting Semi-Supervised Regression with an Auxiliary Ranking Classifier,"State-of-the-art (SOTA) semi-supervised learning techniques, such as FixMatch
and it's variants, have demonstrated impressive performance in classification
tasks. However, these methods are not directly applicable to regression tasks.
In this paper, we present RankUp, a simple yet effective approach that adapts
existing semi-supervised classification techniques to enhance the performance
of regression tasks. RankUp achieves this by converting the original regression
task into a ranking problem and training it concurrently with the original
regression objective. This auxiliary ranking classifier outputs a
classification result, thus enabling integration with existing semi-supervised
classification methods. Moreover, we introduce regression distribution
alignment (RDA), a complementary technique that further enhances RankUp's
performance by refining pseudo-labels through distribution alignment. Despite
its simplicity, RankUp, with or without RDA, achieves SOTA results in across a
range of regression benchmarks, including computer vision, audio, and natural
language processing tasks. Our code and log data are open-sourced at
https://github.com/pm25/semi-supervised-regression.",2024-10-29,"Pin-Yen Huang, Szu-Wei Fu, Yu Tsao",http://arxiv.org/pdf/2410.22124v1,cs.LG
Vision Paper: Designing Graph Neural Networks in Compliance with the European Artificial Intelligence Act,"The European Union's Artificial Intelligence Act (AI Act) introduces
comprehensive guidelines for the development and oversight of Artificial
Intelligence (AI) and Machine Learning (ML) systems, with significant
implications for Graph Neural Networks (GNNs). This paper addresses the unique
challenges posed by the AI Act for GNNs, which operate on complex
graph-structured data. The legislation's requirements for data management, data
governance, robustness, human oversight, and privacy necessitate tailored
strategies for GNNs. Our study explores the impact of these requirements on GNN
training and proposes methods to ensure compliance. We provide an in-depth
analysis of bias, robustness, explainability, and privacy in the context of
GNNs, highlighting the need for fair sampling strategies and effective
interpretability techniques. Our contributions fill the research gap by
offering specific guidance for GNNs under the new legislative framework and
identifying open questions and future research directions.",2024-10-29,"Barbara Hoffmann, Jana Vatter, Ruben Mayer",http://arxiv.org/pdf/2410.22120v1,cs.LG
Deep Q-Exponential Processes,"Motivated by deep neural networks, the deep Gaussian process (DGP)
generalizes the standard GP by stacking multiple layers of GPs. Despite the
enhanced expressiveness, GP, as an $L_2$ regularization prior, tends to be
over-smooth and sub-optimal for inhomogeneous subjects, such as images with
edges. Recently, Q-exponential process (Q-EP) has been proposed as an $L_q$
relaxation to GP and demonstrated with more desirable regularization properties
through a parameter $q>0$ with $q=2$ corresponding to GP. Sharing the similar
tractability of posterior and predictive distributions with GP, Q-EP can also
be stacked to improve its modeling flexibility. In this paper, we generalize
Q-EP to deep Q-EP to enjoy both proper regularization and improved
expressiveness. The generalization is realized by introducing shallow Q-EP as a
latent variable model and then building a hierarchy of the shallow Q-EP layers.
Sparse approximation by inducing points and scalable variational strategy are
applied to facilitate the inference. We demonstrate the numerical advantages of
the proposed deep Q-EP model by comparing with multiple state-of-the-art deep
probabilistic models.",2024-10-29,"Zhi Chang, Chukwudi Obite, Shuang Zhou, Shiwei Lan",http://arxiv.org/pdf/2410.22119v1,cs.LG
The Impact of Inference Acceleration on Bias of LLMs,"Last few years have seen unprecedented advances in capabilities of Large
Language Models (LLMs). These advancements promise to benefit a vast array of
application domains. However, due to their immense size, performing inference
with LLMs is both costly and slow. Consequently, a plethora of recent work has
proposed strategies to enhance inference efficiency, e.g., quantization,
pruning, and caching. These acceleration strategies reduce the inference cost
and latency, often by several factors, while maintaining much of the predictive
performance measured via common benchmarks. In this work, we explore another
critical aspect of LLM performance: demographic bias in model generations due
to inference acceleration optimizations. Using a wide range of metrics, we
probe bias in model outputs from a number of angles. Analysis of outputs before
and after inference acceleration shows significant change in bias. Worryingly,
these bias effects are complex and unpredictable. A combination of an
acceleration strategy and bias type may show little bias change in one model
but may lead to a large effect in another. Our results highlight a need for
in-depth and case-by-case evaluation of model bias after it has been modified
to accelerate inference.",2024-10-29,"Elisabeth Kirsten, Ivan Habernal, Vedant Nanda, Muhammad Bilal Zafar",http://arxiv.org/pdf/2410.22118v2,cs.LG
Policy Gradient for Robust Markov Decision Processes,"We develop a generic policy gradient method with the global optimality
guarantee for robust Markov Decision Processes (MDPs). While policy gradient
methods are widely used for solving dynamic decision problems due to their
scalable and efficient nature, adapting these methods to account for model
ambiguity has been challenging, often making it impractical to learn robust
policies. This paper introduces a novel policy gradient method, Double-Loop
Robust Policy Mirror Descent (DRPMD), for solving robust MDPs. DRPMD employs a
general mirror descent update rule for the policy optimization with adaptive
tolerance per iteration, guaranteeing convergence to a globally optimal policy.
We provide a comprehensive analysis of DRPMD, including new convergence results
under both direct and softmax parameterizations, and provide novel insights
into the inner problem solution through Transition Mirror Ascent (TMA).
Additionally, we propose innovative parametric transition kernels for both
discrete and continuous state-action spaces, broadening the applicability of
our approach. Empirical results validate the robustness and global convergence
of DRPMD across various challenging robust MDP settings.",2024-10-29,"Qiuhao Wang, Shaohang Xu, Chin Pang Ho, Marek Petrik",http://arxiv.org/pdf/2410.22114v2,cs.LG
Where Do Large Learning Rates Lead Us?,"It is generally accepted that starting neural networks training with large
learning rates (LRs) improves generalization. Following a line of research
devoted to understanding this effect, we conduct an empirical study in a
controlled setting focusing on two questions: 1) how large an initial LR is
required for obtaining optimal quality, and 2) what are the key differences
between models trained with different LRs? We discover that only a narrow range
of initial LRs slightly above the convergence threshold lead to optimal results
after fine-tuning with a small LR or weight averaging. By studying the local
geometry of reached minima, we observe that using LRs from this optimal range
allows for the optimization to locate a basin that only contains high-quality
minima. Additionally, we show that these initial LRs result in a sparse set of
learned features, with a clear focus on those most relevant for the task. In
contrast, starting training with too small LRs leads to unstable minima and
attempts to learn all features simultaneously, resulting in poor
generalization. Conversely, using initial LRs that are too large fails to
detect a basin with good solutions and extract meaningful patterns from the
data.",2024-10-29,"Ildus Sadrtdinov, Maxim Kodryan, Eduard Pokonechny, Ekaterina Lobacheva, Dmitry Vetrov",http://arxiv.org/pdf/2410.22113v1,cs.LG
Data Generation for Hardware-Friendly Post-Training Quantization,"Zero-shot quantization (ZSQ) using synthetic data is a key approach for
post-training quantization (PTQ) under privacy and security constraints.
However, existing data generation methods often struggle to effectively
generate data suitable for hardware-friendly quantization, where all model
layers are quantized. We analyze existing data generation methods based on
batch normalization (BN) matching and identify several gaps between synthetic
and real data: 1) Current generation algorithms do not optimize the entire
synthetic dataset simultaneously; 2) Data augmentations applied during training
are often overlooked; and 3) A distribution shift occurs in the final model
layers due to the absence of BN in those layers. These gaps negatively impact
ZSQ performance, particularly in hardware-friendly quantization scenarios. In
this work, we propose Data Generation for Hardware-friendly quantization (DGH),
a novel method that addresses these gaps. DGH jointly optimizes all generated
images, regardless of the image set size or GPU memory constraints. To address
data augmentation mismatches, DGH includes a preprocessing stage that mimics
the augmentation process and enhances image quality by incorporating natural
image priors. Finally, we propose a new distribution-stretching loss that
aligns the support of the feature map distribution between real and synthetic
data. This loss is applied to the model's output and can be adapted to various
tasks. DGH demonstrates significant improvements in quantization performance
across multiple tasks, achieving up to a 30% increase in accuracy for
hardware-friendly ZSQ in both classification and object detection, often
performing on par with real data.",2024-10-29,"Lior Dikstein, Ariel Lapid, Arnon Netzer, Hai Victor Habi",http://arxiv.org/pdf/2410.22110v2,cs.LG
Joint Extraction and Classification of Danish Competences for Job Matching,"The matching of competences, such as skills, occupations or knowledges, is a
key desiderata for candidates to be fit for jobs. Automatic extraction of
competences from CVs and Jobs can greatly promote recruiters' productivity in
locating relevant candidates for job vacancies. This work presents the first
model that jointly extracts and classifies competence from Danish job postings.
Different from existing works on skill extraction and skill classification, our
model is trained on a large volume of annotated Danish corpora and is capable
of extracting a wide range of Danish competences, including skills, occupations
and knowledges of different categories. More importantly, as a single BERT-like
architecture for joint extraction and classification, our model is lightweight
and efficient at inference. On a real-scenario job matching dataset, our model
beats the state-of-the-art models in the overall performance of Danish
competence extraction and classification, and saves over 50% time at inference.",2024-10-29,"Qiuchi Li, Christina Lioma",http://arxiv.org/pdf/2410.22103v1,cs.LG
InLINE: Inner-Layer Information Exchange for Multi-task Learning on Heterogeneous Graphs,"Heterogeneous graph is an important structure for modeling complex relational
data in real-world scenarios and usually involves various node prediction tasks
within a single graph. Training these tasks separately may neglect beneficial
information sharing, hence a preferred way is to learn several tasks in a same
model by Multi-Task Learning (MTL). However, MTL introduces the issue of
negative transfer, where the training of different tasks interferes with each
other as they may focus on different information from the data, resulting in
suboptimal performance. To solve the issue, existing MTL methods use separate
backbones for each task, then selectively exchange beneficial features through
interactions among the output embeddings from each layer of different
backbones, which we refer to as outer-layer exchange. However, the negative
transfer in heterogeneous graphs arises not simply from the varying importance
of an individual node feature across tasks, but also from the varying
importance of inter-relation between two nodes across tasks. These
inter-relations are entangled in the output embedding, making it difficult for
existing methods to discriminate beneficial information from the embedding. To
address this challenge, we propose the Inner-Layer Information Exchange
(InLINE) model that facilitate fine-grained information exchanges within each
graph layer rather than through output embeddings. Specifically, InLINE
consists of (1) Structure Disentangled Experts for layer-wise structure
disentanglement, (2) Structure Disentangled Gates for assigning disentangled
information to different tasks. Evaluations on two public datasets and a large
industry dataset show that our model effectively alleviates the significant
performance drop on specific tasks caused by negative transfer, improving Macro
F1 by 6.3% on DBLP dataset and AUC by 3.6% on the industry dataset compared to
SoA methods.",2024-10-29,"Xinyue Feng, Jinquan Hang, Yuequn Zhang, Haotian Wang, Desheng Zhang, Guang Wang",http://arxiv.org/pdf/2410.22089v1,cs.LG
P$^2$C$^2$Net: PDE-Preserved Coarse Correction Network for efficient prediction of spatiotemporal dynamics,"When solving partial differential equations (PDEs), classical numerical
methods often require fine mesh grids and small time stepping to meet
stability, consistency, and convergence conditions, leading to high
computational cost. Recently, machine learning has been increasingly utilized
to solve PDE problems, but they often encounter challenges related to
interpretability, generalizability, and strong dependency on rich labeled data.
Hence, we introduce a new PDE-Preserved Coarse Correction Network
(P$^2$C$^2$Net) to efficiently solve spatiotemporal PDE problems on coarse mesh
grids in small data regimes. The model consists of two synergistic modules: (1)
a trainable PDE block that learns to update the coarse solution (i.e., the
system state), based on a high-order numerical scheme with boundary condition
encoding, and (2) a neural network block that consistently corrects the
solution on the fly. In particular, we propose a learnable symmetric Conv
filter, with weights shared over the entire model, to accurately estimate the
spatial derivatives of PDE based on the neural-corrected system state. The
resulting physics-encoded model is capable of handling limited training data
(e.g., 3--5 trajectories) and accelerates the prediction of PDE solutions on
coarse spatiotemporal grids while maintaining a high accuracy. P$^2$C$^2$Net
achieves consistent state-of-the-art performance with over 50\% gain (e.g., in
terms of relative prediction error) across four datasets covering complex
reaction-diffusion processes and turbulent flows.",2024-10-29,"Qi Wang, Pu Ren, Hao Zhou, Xin-Yang Liu, Zhiwen Deng, Yi Zhang, Ruizhi Chengze, Hongsheng Liu, Zidong Wang, Jian-Xun Wang, Ji-Rong_Wen, Hao Sun, Yang Liu",http://arxiv.org/pdf/2411.00040v1,cs.LG
Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate,"Machine unlearning has been used to remove unwanted knowledge acquired by
large language models (LLMs). In this paper, we examine machine unlearning from
an optimization perspective, framing it as a regularized multi-task
optimization problem, where one task optimizes a forgetting objective and
another optimizes the model performance. In particular, we introduce a
normalized gradient difference (NGDiff) algorithm, enabling us to have better
control over the trade-off between the objectives, while integrating a new,
automatic learning rate scheduler. We provide a theoretical analysis and
empirically demonstrate the superior performance of NGDiff among
state-of-the-art unlearning methods on the TOFU and MUSE datasets while
exhibiting stable training.",2024-10-29,"Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong",http://arxiv.org/pdf/2410.22086v3,cs.LG
Yoga Pose Classification Using Transfer Learning,"Yoga has recently become an essential aspect of human existence for
maintaining a healthy body and mind. People find it tough to devote time to the
gym for workouts as their lives get more hectic and they work from home. This
kind of human pose estimation is one of the notable problems as it has to deal
with locating body key points or joints. Yoga-82, a benchmark dataset for
large-scale yoga pose recognition with 82 classes, has challenging positions
that could make precise annotations impossible. We have used VGG-16, ResNet-50,
ResNet-101, and DenseNet-121 and finetuned them in different ways to get better
results. We also used Neural Architecture Search to add more layers on top of
this pre-trained architecture. The experimental result shows the best
performance of DenseNet-121 having the top-1 accuracy of 85% and top-5 accuracy
of 96% outperforming the current state-of-the-art result.",2024-10-29,"M. M. Akash, Rahul Deb Mohalder, Md. Al Mamun Khan, Laboni Paul, Ferdous Bin Ali",http://arxiv.org/pdf/2411.00833v1,cs.LG
Variational inference for pile-up removal at hadron colliders with diffusion models,"In this paper, we present a novel method for pile-up removal of pp
interactions using variational inference with diffusion models, called Vipr.
Instead of using classification methods to identify which particles are from
the primary collision, a generative model is trained to predict the
constituents of the hard-scatter particle jets with pile-up removed. This
results in an estimate of the full posterior over hard-scatter jet
constituents, which has not yet been explored in the context of pile-up
removal. We evaluate the performance of Vipr in a sample of jets from simulated
$t\bar{t}$ events overlain with pile-up contamination. Vipr outperforms
SoftDrop in predicting the substructure of the hard-scatter jets over a wide
range of pile-up scenarios.",2024-10-29,"Malte Algren, Christopher Pollard, John Andrew Raine, Tobias Golling",http://arxiv.org/pdf/2410.22074v1,cs.LG
FreeGaussian: Annotation-free Controllable 3D Gaussian Splats with Flow Derivatives,"Reconstructing controllable Gaussian splats from monocular video is a
challenging task due to its inherently insufficient constraints. Widely adopted
approaches supervise complex interactions with additional masks and control
signal annotations, limiting their real-world applications. In this paper, we
propose an annotation guidance-free method, dubbed FreeGaussian, that
mathematically derives dynamic Gaussian motion from optical flow and camera
motion using novel dynamic Gaussian constraints. By establishing a connection
between 2D flows and 3D Gaussian dynamic control, our method enables
self-supervised optimization and continuity of dynamic Gaussian motions from
flow priors. Furthermore, we introduce a 3D spherical vector controlling
scheme, which represents the state with a 3D Gaussian trajectory, thereby
eliminating the need for complex 1D control signal calculations and simplifying
controllable Gaussian modeling. Quantitative and qualitative evaluations on
extensive experiments demonstrate the state-of-the-art visual performance and
control capability of our method. Project page: https://freegaussian.github.io.",2024-10-29,"Qizhi Chen, Delin Qu, Junli Liu, Yiwen Tang, Haoming Song, Dong Wang, Bin Zhao, Xuelong Li",http://arxiv.org/pdf/2410.22070v2,cs.LG
Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks,"We study the implicit bias of the general family of steepest descent
algorithms with infinitesimal learning rate in deep homogeneous neural
networks. We show that: (a) an algorithm-dependent geometric margin starts
increasing once the networks reach perfect training accuracy, and (b) any limit
point of the training trajectory corresponds to a KKT point of the
corresponding margin-maximization problem. We experimentally zoom into the
trajectories of neural networks optimized with various steepest descent
algorithms, highlighting connections to the implicit bias of popular adaptive
methods (Adam and Shampoo).",2024-10-29,"Nikolaos Tsilivis, Gal Vardi, Julia Kempe",http://arxiv.org/pdf/2410.22069v2,cs.LG
Hamiltonian Monte Carlo on ReLU Neural Networks is Inefficient,"We analyze the error rates of the Hamiltonian Monte Carlo algorithm with
leapfrog integrator for Bayesian neural network inference. We show that due to
the non-differentiability of activation functions in the ReLU family, leapfrog
HMC for networks with these activation functions has a large local error rate
of $\Omega(\epsilon)$ rather than the classical error rate of $O(\epsilon^3)$.
This leads to a higher rejection rate of the proposals, making the method
inefficient. We then verify our theoretical findings through empirical
simulations as well as experiments on a real-world dataset that highlight the
inefficiency of HMC inference on ReLU-based neural networks compared to
analytical networks.",2024-10-29,"Vu C. Dinh, Lam Si Tung Ho, Cuong V. Nguyen",http://arxiv.org/pdf/2410.22065v1,cs.LG
Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models,"Fine-tuning large language models (LLMs) has become essential for adapting
pretrained models to specific downstream tasks. In this paper, we propose
Linear Chain Transformation (LinChain), a novel approach that introduces a
sequence of linear transformations during fine-tuning to enrich optimization
dynamics. By incorporating multiple linear transformations into the parameter
update process, LinChain expands the effective rank of updates and enhances the
model's ability to learn complex task-specific representations. We demonstrate
that this method significantly improves the performance of LLM fine-tuning over
state-of-the-art methods by providing more flexible optimization paths during
training, while maintaining the inference efficiency of the resulting model.
Our experiments on various benchmark tasks show that LinChain leads to better
generalization, fewer learnable parameters, and improved task adaptation,
making it a compelling strategy for LLM fine-tuning.",2024-10-29,"Yulong Wang, Chang Zuo, Yin Xuan, Hong Li, Ni Wei",http://arxiv.org/pdf/2411.00039v1,cs.LG
"CHORDONOMICON: A Dataset of 666,000 Songs and their Chord Progressions","Chord progressions encapsulate important information about music, pertaining
to its structure and conveyed emotions. They serve as the backbone of musical
composition, and in many cases, they are the sole information required for a
musician to play along and follow the music. Despite their importance, chord
progressions as a data domain remain underexplored. There is a lack of
large-scale datasets suitable for deep learning applications, and limited
research exploring chord progressions as an input modality. In this work, we
present Chordonomicon, a dataset of over 666,000 songs and their chord
progressions, annotated with structural parts, genre, and release date -
created by scraping various sources of user-generated progressions and
associated metadata. We demonstrate the practical utility of the Chordonomicon
dataset for classification and generation tasks, and discuss its potential to
provide valuable insights to the research community. Chord progressions are
unique in their ability to be represented in multiple formats (e.g. text,
graph) and the wealth of information chords convey in given contexts, such as
their harmonic function . These characteristics make the Chordonomicon an ideal
testbed for exploring advanced machine learning techniques, including
transformers, graph machine learning, and hybrid systems that combine knowledge
representation and machine learning.",2024-10-29,"Spyridon Kantarelis, Konstantinos Thomas, Vassilis Lyberatos, Edmund Dervakos, Giorgos Stamou",http://arxiv.org/pdf/2410.22046v3,cs.LG
Enhance Hyperbolic Representation Learning via Second-order Pooling,"Hyperbolic representation learning is well known for its ability to capture
hierarchical information. However, the distance between samples from different
levels of hierarchical classes can be required large. We reveal that the
hyperbolic discriminant objective forces the backbone to capture this
hierarchical information, which may inevitably increase the Lipschitz constant
of the backbone. This can hinder the full utilization of the backbone's
generalization ability. To address this issue, we introduce second-order
pooling into hyperbolic representation learning, as it naturally increases the
distance between samples without compromising the generalization ability of the
input features. In this way, the Lipschitz constant of the backbone does not
necessarily need to be large. However, current off-the-shelf low-dimensional
bilinear pooling methods cannot be directly employed in hyperbolic
representation learning because they inevitably reduce the distance expansion
capability. To solve this problem, we propose a kernel approximation
regularization, which enables the low-dimensional bilinear features to
approximate the kernel function well in low-dimensional space. Finally, we
conduct extensive experiments on graph-structured datasets to demonstrate the
effectiveness of the proposed method.",2024-10-29,"Kun Song, Ruben Solozabal, Li hao, Lu Ren, Moloud Abdar, Qing Li, Fakhri Karray, Martin Takac",http://arxiv.org/pdf/2410.22026v1,cs.LG
Generative AI Enabled Matching for 6G Multiple Access,"In wireless networks, applying deep learning models to solve matching
problems between different entities has become a mainstream and effective
approach. However, the complex network topology in 6G multiple access presents
significant challenges for the real-time performance and stability of matching
generation. Generative artificial intelligence (GenAI) has demonstrated strong
capabilities in graph feature extraction, exploration, and generation, offering
potential for graph-structured matching generation. In this paper, we propose a
GenAI-enabled matching generation framework to support 6G multiple access.
Specifically, we first summarize the classical matching theory, discuss common
GenAI models and applications from the perspective of matching generation.
Then, we propose a framework based on generative diffusion models (GDMs) that
iteratively denoises toward reward maximization to generate a matching strategy
that meets specific requirements. Experimental results show that, compared to
decision-based AI approaches, our framework can generate more effective
matching strategies based on given conditions and predefined rewards, helping
to solve complex problems in 6G multiple access, such as task allocation.",2024-10-29,"Xudong Wang, Hongyang Du, Dusit Niyato, Lijie Zhou, Lei Feng, Zhixiang Yang, Fanqin Zhou, Wenjing Li",http://arxiv.org/pdf/2411.04137v1,cs.LG
On uniqueness in structured model learning,"This paper addresses the problem of uniqueness in learning physical laws for
systems of partial differential equations (PDEs). Contrary to most existing
approaches, it considers a framework of structured model learning, where
existing, approximately correct physical models are augmented with components
that are learned from data. The main result of the paper is a uniqueness result
that covers a large class of PDEs and a suitable class of neural networks used
for approximating the unknown model components. The uniqueness result shows
that, in the idealized setting of full, noiseless measurements, a unique
identification of the unknown model components is possible as
regularization-minimizing solution of the PDE system. Furthermore, the paper
provides a convergence result showing that model components learned on the
basis of incomplete, noisy measurements approximate the ground truth model
component in the limit. These results are possible under specific properties of
the approximating neural networks and due to a dedicated choice of
regularization. With this, a practical contribution of this analytic paper is
to provide a class of model learning frameworks different to standard settings
where uniqueness can be expected in the limit of full measurements.",2024-10-29,"Martin Holler, Erion Morina",http://arxiv.org/pdf/2410.22009v1,cs.LG
Debiasing Alternative Data for Credit Underwriting Using Causal Inference,"Alternative data provides valuable insights for lenders to evaluate a
borrower's creditworthiness, which could help expand credit access to
underserved groups and lower costs for borrowers. But some forms of alternative
data have historically been excluded from credit underwriting because it could
act as an illegal proxy for a protected class like race or gender, causing
redlining. We propose a method for applying causal inference to a supervised
machine learning model to debias alternative data so that it might be used for
credit underwriting. We demonstrate how our algorithm can be used against a
public credit dataset to improve model accuracy across different racial groups,
while providing theoretically robust nondiscrimination guarantees.",2024-10-29,Chris Lam,http://arxiv.org/pdf/2410.22382v2,cs.LG
A Machine Learning-Based Secure Face Verification Scheme and Its Applications to Digital Surveillance,"Face verification is a well-known image analysis application and is widely
used to recognize individuals in contemporary society. However, most real-world
recognition systems ignore the importance of protecting the identity-sensitive
facial images that are used for verification. To address this problem, we
investigate how to implement a secure face verification system that protects
the facial images from being imitated. In our work, we use the DeepID2
convolutional neural network to extract the features of a facial image and an
EM algorithm to solve the facial verification problem. To maintain the privacy
of facial images, we apply homomorphic encryption schemes to encrypt the facial
data and compute the EM algorithm in the ciphertext domain. We develop three
face verification systems for surveillance (or entrance) control of a local
community based on three levels of privacy concerns. The associated timing
performances are presented to demonstrate their feasibility for practical
implementation.",2024-10-29,"Huan-Chih Wang, Ja-Ling Wu",http://arxiv.org/pdf/2410.21993v1,cs.LG
Node Regression on Latent Position Random Graphs via Local Averaging,"Node regression consists in predicting the value of a graph label at a node,
given observations at the other nodes. To gain some insight into the
performance of various estimators for this task, we perform a theoretical study
in a context where the graph is random. Specifically, we assume that the graph
is generated by a Latent Position Model, where each node of the graph has a
latent position, and the probability that two nodes are connected depend on the
distance between the latent positions of the two nodes. In this context, we
begin by studying the simplest possible estimator for graph regression, which
consists in averaging the value of the label at all neighboring nodes. We show
that in Latent Position Models this estimator tends to a Nadaraya Watson
estimator in the latent space, and that its rate of convergence is in fact the
same. One issue with this standard estimator is that it averages over a region
consisting of all neighbors of a node, and that depending on the graph model
this may be too much or too little. An alternative consists in first estimating
the true distances between the latent positions, then injecting these estimated
distances into a classical Nadaraya Watson estimator. This enables averaging in
regions either smaller or larger than the typical graph neighborhood. We show
that this method can achieve standard nonparametric rates in certain instances
even when the graph neighborhood is too large or too small.",2024-10-29,"Martin Gjorgjevski, Nicolas Keriven, Simon Barthelmé, Yohann De Castro",http://arxiv.org/pdf/2410.21987v1,cs.LG
"Individualised recovery trajectories of patients with impeded mobility, using distance between probability distributions of learnt graphs","Patients who are undergoing physical rehabilitation, benefit from feedback
that follows from reliable assessment of their cumulative performance attained
at a given time. In this paper, we provide a method for the learning of the
recovery trajectory of an individual patient, as they undertake exercises as
part of their physical therapy towards recovery of their loss of movement
ability, following a critical illness. The difference between the Movement
Recovery Scores (MRSs) attained by a patient, when undertaking a given exercise
routine on successive instances, is given by a statistical distance/divergence
between the (posterior) probabilities of random graphs that are Bayesianly
learnt using time series data on locations of 20 of the patient's joints,
recorded on an e-platform as the patient exercises. This allows for the
computation of the MRS on every occasion the patient undertakes this exercise,
using which, the recovery trajectory is drawn. We learn each graph as a Random
Geometric Graph drawn in a probabilistic metric space, and identify the
closed-form marginal posterior of any edge of the graph, given the correlation
structure of the multivariate time series data on joint locations. On the basis
of our recovery learning, we offer recommendations on the optimal exercise
routines for patients with given level of mobility impairment.",2024-10-29,"Chuqiao Zhang, Crina Grosan, Dalia Chakrabarty",http://arxiv.org/pdf/2410.21983v1,cs.LG
On the Robustness of Adversarial Training Against Uncertainty Attacks,"In learning problems, the noise inherent to the task at hand hinders the
possibility to infer without a certain degree of uncertainty. Quantifying this
uncertainty, regardless of its wide use, assumes high relevance for
security-sensitive applications. Within these scenarios, it becomes fundamental
to guarantee good (i.e., trustworthy) uncertainty measures, which downstream
modules can securely employ to drive the final decision-making process.
However, an attacker may be interested in forcing the system to produce either
(i) highly uncertain outputs jeopardizing the system's availability or (ii) low
uncertainty estimates, making the system accept uncertain samples that would
instead require a careful inspection (e.g., human intervention). Therefore, it
becomes fundamental to understand how to obtain robust uncertainty estimates
against these kinds of attacks. In this work, we reveal both empirically and
theoretically that defending against adversarial examples, i.e., carefully
perturbed samples that cause misclassification, additionally guarantees a more
secure, trustworthy uncertainty estimate under common attack scenarios without
the need for an ad-hoc defense strategy. To support our claims, we evaluate
multiple adversarial-robust models from the publicly available benchmark
RobustBench on the CIFAR-10 and ImageNet datasets.",2024-10-29,"Emanuele Ledda, Giovanni Scodeller, Daniele Angioni, Giorgio Piras, Antonio Emanuele Cinà, Giorgio Fumera, Battista Biggio, Fabio Roli",http://arxiv.org/pdf/2410.21952v1,cs.LG
Human-Readable Programs as Actors of Reinforcement Learning Agents Using Critic-Moderated Evolution,"With Deep Reinforcement Learning (DRL) being increasingly considered for the
control of real-world systems, the lack of transparency of the neural network
at the core of RL becomes a concern. Programmatic Reinforcement Learning (PRL)
is able to to create representations of this black-box in the form of source
code, not only increasing the explainability of the controller but also
allowing for user adaptations. However, these methods focus on distilling a
black-box policy into a program and do so after learning using the Mean Squared
Error between produced and wanted behaviour, discarding other elements of the
RL algorithm. The distilled policy may therefore perform significantly worse
than the black-box learned policy.
  In this paper, we propose to directly learn a program as the policy of an RL
agent. We build on TD3 and use its critics as the basis of the objective
function of a genetic algorithm that syntheses the program. Our approach builds
the program during training, as opposed to after the fact. This steers the
program to actual high rewards, instead of a simple Mean Squared Error. Also,
our approach leverages the TD3 critics to achieve high sample-efficiency, as
opposed to pure genetic methods that rely on Monte-Carlo evaluations. Our
experiments demonstrate the validity, explainability and sample-efficiency of
our approach in a simple gridworld environment.",2024-10-29,"Senne Deproost, Denis Steckelmacher, Ann Nowé",http://arxiv.org/pdf/2410.21940v1,cs.LG
ReMix: Training Generalized Person Re-identification on a Mixture of Data,"Modern person re-identification (Re-ID) methods have a weak generalization
ability and experience a major accuracy drop when capturing environments
change. This is because existing multi-camera Re-ID datasets are limited in
size and diversity, since such data is difficult to obtain. At the same time,
enormous volumes of unlabeled single-camera records are available. Such data
can be easily collected, and therefore, it is more diverse. Currently,
single-camera data is used only for self-supervised pre-training of Re-ID
methods. However, the diversity of single-camera data is suppressed by
fine-tuning on limited multi-camera data after pre-training. In this paper, we
propose ReMix, a generalized Re-ID method jointly trained on a mixture of
limited labeled multi-camera and large unlabeled single-camera data. Effective
training of our method is achieved through a novel data sampling strategy and
new loss functions that are adapted for joint use with both types of data.
Experiments show that ReMix has a high generalization ability and outperforms
state-of-the-art methods in generalizable person Re-ID. To the best of our
knowledge, this is the first work that explores joint training on a mixture of
multi-camera and single-camera data in person Re-ID.",2024-10-29,"Timur Mamedov, Anton Konushin, Vadim Konushin",http://arxiv.org/pdf/2410.21938v1,cs.LG
Dreaming Out Loud: A Self-Synthesis Approach For Training Vision-Language Models With Developmentally Plausible Data,"While today's large language models exhibit impressive abilities in
generating human-like text, they require massive amounts of data during
training. We here take inspiration from human cognitive development to train
models in limited data conditions. Specifically we present a self-synthesis
approach that iterates through four phases: Phase 1 sets up fundamental
language abilities, training the model from scratch on a small corpus. Language
is then associated with the visual environment in phase 2, integrating the
model with a vision encoder to generate descriptive captions from labeled
images. In the ""self-synthesis"" phase 3, the model generates captions for
unlabeled images, that it then uses to further train its language component
with a mix of synthetic, and previous real-world text. This phase is meant to
expand the model's linguistic repertoire, similar to humans self-annotating new
experiences. Finally, phase 4 develops advanced cognitive skills, by training
the model on specific tasks such as visual question answering and reasoning.
Our approach offers a proof of concept for training a multimodal model using a
developmentally plausible amount of data.",2024-10-29,"Badr AlKhamissi, Yingtian Tang, Abdülkadir Gökce, Johannes Mehrer, Martin Schrimpf",http://arxiv.org/pdf/2411.00828v1,cs.LG
Differentiable Inductive Logic Programming for Fraud Detection,"Current trends in Machine Learning prefer explainability even when it comes
at the cost of performance. Therefore, explainable AI methods are particularly
important in the field of Fraud Detection. This work investigates the
applicability of Differentiable Inductive Logic Programming (DILP) as an
explainable AI approach to Fraud Detection. Although the scalability of DILP is
a well-known issue, we show that with some data curation such as cleaning and
adjusting the tabular and numerical data to the expected format of background
facts statements, it becomes much more applicable. While in processing it does
not provide any significant advantage on rather more traditional methods such
as Decision Trees, or more recent ones like Deep Symbolic Classification, it
still gives comparable results. We showcase its limitations and points to
improve, as well as potential use cases where it can be much more useful
compared to traditional methods, such as recursive rule learning.",2024-10-29,"Boris Wolfson, Erman Acar",http://arxiv.org/pdf/2410.21928v1,cs.LG
Turkey's Earthquakes: Damage Prediction and Feature Significance Using A Multivariate Analysis,"Accurate damage prediction is crucial for disaster preparedness and response
strategies, particularly given the frequent earthquakes in Turkey. Utilizing
datasets on earthquake data, infrastructural quality metrics, and contemporary
socioeconomic factors, we tested various machine-learning architectures to
forecast death tolls and fatalities per affected population. Our findings
indicate that the Random Forest model provides the most reliable predictions.
The model highlights earthquake magnitude and building stability as the primary
determinants of damage. This research contributes to the reduction of
fatalities in future seismic events in Turkey.",2024-10-29,"Shrey Shah, Alex Lin, Scott Lin, Josh Patel, Michael Lam, Kevin Zhu",http://arxiv.org/pdf/2411.08903v1,cs.LG
Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss,"Traditional implicit generative models are capable of learning highly complex
data distributions. However, their training involves distinguishing real data
from synthetically generated data using adversarial discriminators, which can
lead to unstable training dynamics and mode dropping issues. In this work, we
build on the \textit{invariant statistical loss} (ISL) method introduced in
\cite{de2024training}, and extend it to handle heavy-tailed and multivariate
data distributions.
  The data generated by many real-world phenomena can only be properly
characterised using heavy-tailed probability distributions, and traditional
implicit methods struggle to effectively capture their asymptotic behavior. To
address this problem, we introduce a generator trained with ISL, that uses
input noise from a generalised Pareto distribution (GPD). We refer to this
generative scheme as Pareto-ISL for conciseness. Our experiments demonstrate
that Pareto-ISL accurately models the tails of the distributions while still
effectively capturing their central characteristics.
  The original ISL function was conceived for 1D data sets. When the actual
data is $n$-dimensional, a straightforward extension of the method was obtained
by targeting the $n$ marginal distributions of the data. This approach is
computationally infeasible and ineffective in high-dimensional spaces. To
overcome this, we extend the 1D approach using random projections and define a
new loss function suited for multivariate data, keeping problems tractable by
adjusting the number of projections. We assess its performance in
multidimensional generative modeling and explore its potential as a pretraining
technique for generative adversarial networks (GANs) to prevent mode collapse,
reporting promising results and highlighting its robustness across various
hyperparameter settings.",2024-10-29,"José Manuel de Frutos, Manuel A. Vázquez, Pablo Olmos, Joaquín Míguez",http://arxiv.org/pdf/2410.22381v1,cs.LG
Online Test of a Neural Network Deep Convection Parameterization in ARP-GEM1,"In this study, we present the integration of a neural network-based
parameterization into the global atmospheric model ARP-GEM1, leveraging the
Python interface of the OASIS coupler. This approach facilitates the exchange
of fields between the Fortran-based ARP-GEM1 model and a Python component
responsible for neural network inference. As a proof-of-concept experiment, we
trained a neural network to emulate the deep convection parameterization of
ARP-GEM1. Using the flexible Fortran/Python interface, we have successfully
replaced ARP-GEM1's deep convection scheme with a neural network emulator. To
assess the performance of the neural network deep convection scheme, we have
run a 5-years ARP-GEM1 simulation using the neural network emulator. The
evaluation of averaged fields showed good agreement with output from an
ARP-GEM1 simulation using the physics-based deep convection scheme. The Python
component was deployed on a separate partition from the general circulation
model, using GPUs to increase inference speed of the neural network.",2024-10-29,"Blanka Balogh, David Saint-Martin, Olivier Geoffroy",http://arxiv.org/pdf/2410.21920v1,cs.LG
Identifiability Analysis of Linear ODE Systems with Hidden Confounders,"The identifiability analysis of linear Ordinary Differential Equation (ODE)
systems is a necessary prerequisite for making reliable causal inferences about
these systems. While identifiability has been well studied in scenarios where
the system is fully observable, the conditions for identifiability remain
unexplored when latent variables interact with the system. This paper aims to
address this gap by presenting a systematic analysis of identifiability in
linear ODE systems incorporating hidden confounders. Specifically, we
investigate two cases of such systems. In the first case, latent confounders
exhibit no causal relationships, yet their evolution adheres to specific
functional forms, such as polynomial functions of time $t$. Subsequently, we
extend this analysis to encompass scenarios where hidden confounders exhibit
causal dependencies, with the causal structure of latent variables described by
a Directed Acyclic Graph (DAG). The second case represents a more intricate
variation of the first case, prompting a more comprehensive identifiability
analysis. Accordingly, we conduct detailed identifiability analyses of the
second system under various observation conditions, including both continuous
and discrete observations from single or multiple trajectories. To validate our
theoretical results, we perform a series of simulations, which support and
substantiate our findings.",2024-10-29,"Yuanyuan Wang, Biwei Huang, Wei Huang, Xi Geng, Mingming Gong",http://arxiv.org/pdf/2410.21917v2,cs.LG
SceneGenAgent: Precise Industrial Scene Generation with Coding Agent,"The modeling of industrial scenes is essential for simulations in industrial
manufacturing. While large language models (LLMs) have shown significant
progress in generating general 3D scenes from textual descriptions, generating
industrial scenes with LLMs poses a unique challenge due to their demand for
precise measurements and positioning, requiring complex planning over spatial
arrangement. To address this challenge, we introduce SceneGenAgent, an
LLM-based agent for generating industrial scenes through C# code. SceneGenAgent
ensures precise layout planning through a structured and calculable format,
layout verification, and iterative refinement to meet the quantitative
requirements of industrial scenarios. Experiment results demonstrate that LLMs
powered by SceneGenAgent exceed their original performance, reaching up to
81.0% success rate in real-world industrial scene generation tasks and
effectively meeting most scene generation requirements. To further enhance
accessibility, we construct SceneInstruct, a dataset designed for fine-tuning
open-source LLMs to integrate into SceneGenAgent. Experiments show that
fine-tuning open-source LLMs on SceneInstruct yields significant performance
improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our
code and data are available at https://github.com/THUDM/SceneGenAgent .",2024-10-29,"Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong",http://arxiv.org/pdf/2410.21909v2,cs.LG
Discrete Modeling via Boundary Conditional Diffusion Processes,"We present an novel framework for efficiently and effectively extending the
powerful continuous diffusion processes to discrete modeling. Previous
approaches have suffered from the discrepancy between discrete data and
continuous modeling. Our study reveals that the absence of guidance from
discrete boundaries in learning probability contours is one of the main
reasons. To address this issue, we propose a two-step forward process that
first estimates the boundary as a prior distribution and then rescales the
forward trajectory to construct a boundary conditional diffusion model. The
reverse process is proportionally adjusted to guarantee that the learned
contours yield more precise discrete data. Experimental results indicate that
our approach achieves strong performance in both language modeling and discrete
image generation tasks. In language modeling, our approach surpasses previous
state-of-the-art continuous diffusion language models in three translation
tasks and a summarization task, while also demonstrating competitive
performance compared to auto-regressive transformers. Moreover, our method
achieves comparable results to continuous diffusion models when using discrete
ordinal pixels and establishes a new state-of-the-art for categorical image
generation on the Cifar-10 dataset.",2024-10-29,"Yuxuan Gu, Xiaocheng Feng, Lei Huang, Yingsheng Wu, Zekun Zhou, Weihong Zhong, Kun Zhu, Bing Qin",http://arxiv.org/pdf/2410.22380v1,cs.LG
Evaluating K-Fold Cross Validation for Transformer Based Symbolic Regression Models,"Symbolic Regression remains an NP-Hard problem, with extensive research
focusing on AI models for this task. Transformer models have shown promise in
Symbolic Regression, but performance suffers with smaller datasets. We propose
applying k-fold cross-validation to a transformer-based symbolic regression
model trained on a significantly reduced dataset (15,000 data points, down from
500,000). This technique partitions the training data into multiple subsets
(folds), iteratively training on some while validating on others. Our aim is to
provide an estimate of model generalization and mitigate overfitting issues
associated with smaller datasets. Results show that this process improves the
model's output consistency and generalization by a relative improvement in
validation loss of 53.31%. Potentially enabling more efficient and accessible
symbolic regression in resource-constrained environments.",2024-10-29,"Kaustubh Kislay, Shlok Singh, Soham Joshi, Rohan Dutta, Jay Shim George Flint, Kevin Zhu",http://arxiv.org/pdf/2410.21896v1,cs.LG
Bayesian Optimization for Hyperparameters Tuning in Neural Networks,"This study investigates the application of Bayesian Optimization (BO) for the
hyperparameter tuning of neural networks, specifically targeting the
enhancement of Convolutional Neural Networks (CNN) for image classification
tasks. Bayesian Optimization is a derivative-free global optimization method
suitable for expensive black-box functions with continuous inputs and limited
evaluation budgets. The BO algorithm leverages Gaussian Process regression and
acquisition functions like Upper Confidence Bound (UCB) and Expected
Improvement (EI) to identify optimal configurations effectively. Using the Ax
and BOTorch frameworks, this work demonstrates the efficiency of BO in reducing
the number of hyperparameter tuning trials while achieving competitive model
performance. Experimental outcomes reveal that BO effectively balances
exploration and exploitation, converging rapidly towards optimal settings for
CNN architectures. This approach underlines the potential of BO in automating
neural network tuning, contributing to improved accuracy and computational
efficiency in machine learning pipelines.",2024-10-29,Gabriele Onorato,http://arxiv.org/pdf/2410.21886v1,cs.LG
SCGNet-Stacked Convolution with Gated Recurrent Unit Network for Cyber Network Intrusion Detection and Intrusion Type Classification,"Intrusion detection system (IDS) is a piece of hardware or software that
looks for malicious activity or policy violations in a network. It looks for
malicious activity or security flaws on a network or system. IDS protects hosts
or networks by looking for indications of known attacks or deviations from
normal behavior (Network-based intrusion detection system, or NIDS for short).
Due to the rapidly increasing amount of network data, traditional intrusion
detection systems (IDSs) are far from being able to quickly and efficiently
identify complex and varied network attacks, especially those linked to
low-frequency attacks. The SCGNet (Stacked Convolution with Gated Recurrent
Unit Network) is a novel deep learning architecture that we propose in this
study. It exhibits promising results on the NSL-KDD dataset in both task,
network attack detection, and attack type classification with 99.76% and 98.92%
accuracy, respectively. We have also introduced a general data preprocessing
pipeline that is easily applicable to other similar datasets. We have also
experimented with conventional machine-learning techniques to evaluate the
performance of the data processing pipeline.",2024-10-29,"Rajana Akter, Shahnure Rabib, Rahul Deb Mohalder, Laboni Paul, Ferdous Bin Ali",http://arxiv.org/pdf/2410.21873v1,cs.LG
Cross-Entropy Is All You Need To Invert the Data Generating Process,"Supervised learning has become a cornerstone of modern machine learning, yet
a comprehensive theory explaining its effectiveness remains elusive. Empirical
phenomena, such as neural analogy-making and the linear representation
hypothesis, suggest that supervised models can learn interpretable factors of
variation in a linear fashion. Recent advances in self-supervised learning,
particularly nonlinear Independent Component Analysis, have shown that these
methods can recover latent structures by inverting the data generating process.
We extend these identifiability results to parametric instance discrimination,
then show how insights transfer to the ubiquitous setting of supervised
learning with cross-entropy minimization. We prove that even in standard
classification tasks, models learn representations of ground-truth factors of
variation up to a linear transformation. We corroborate our theoretical
contribution with a series of empirical studies. First, using simulated data
matching our theoretical assumptions, we demonstrate successful disentanglement
of latent factors. Second, we show that on DisLib, a widely-used
disentanglement benchmark, simple classification tasks recover latent
structures up to linear transformations. Finally, we reveal that models trained
on ImageNet encode representations that permit linear decoding of proxy factors
of variation. Together, our theoretical findings and experiments offer a
compelling explanation for recent observations of linear representations, such
as superposition in neural networks. This work takes a significant step toward
a cohesive theory that accounts for the unreasonable effectiveness of
supervised deep learning.",2024-10-29,"Patrik Reizinger, Alice Bizeul, Attila Juhos, Julia E. Vogt, Randall Balestriero, Wieland Brendel, David Klindt",http://arxiv.org/pdf/2410.21869v3,cs.LG
Hierarchical mixtures of Unigram models for short text clustering: The role of Beta-Liouville priors,"This paper presents a variant of the Multinomial mixture model tailored to
the unsupervised classification of short text data. While the Multinomial
probability vector is traditionally assigned a Dirichlet prior distribution,
this work explores an alternative formulation based on the Beta-Liouville
distribution, which offers a more flexible correlation structure than the
Dirichlet. We examine the theoretical properties of the Beta-Liouville
distribution, with particular focus on its conjugacy with the Multinomial
likelihood. This property enables the derivation of update equations for a CAVI
(Coordinate Ascent Variational Inference) algorithm, facilitating approximate
posterior inference of the model parameters. In addition, we introduce a
stochastic variant of the CAVI algorithm to enhance scalability. The paper
concludes with empirical examples demonstrating effective strategies for
selecting the Beta-Liouville hyperparameters.",2024-10-29,"Massimo Bilancia, Samuele Magro",http://arxiv.org/pdf/2410.21862v3,cs.LG
Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels,"We develop a nonparametric, kernel-based joint estimator for conditional mean
and covariance matrices in large and unbalanced panels. The estimator is
supported by rigorous consistency results and finite-sample guarantees,
ensuring its reliability for empirical applications. We apply it to an
extensive panel of monthly US stock excess returns from 1962 to 2021, using
macroeconomic and firm-specific covariates as conditioning variables. The
estimator effectively captures time-varying cross-sectional dependencies,
demonstrating robust statistical and economic performance. We find that
idiosyncratic risk explains, on average, more than 75% of the cross-sectional
variance.",2024-10-29,"Damir Filipovic, Paul Schneider",http://arxiv.org/pdf/2410.21858v5,cs.LG
Learning Infinitesimal Generators of Continuous Symmetries from Data,"Exploiting symmetry inherent in data can significantly improve the sample
efficiency of a learning procedure and the generalization of learned models.
When data clearly reveals underlying symmetry, leveraging this symmetry can
naturally inform the design of model architectures or learning strategies. Yet,
in numerous real-world scenarios, identifying the specific symmetry within a
given data distribution often proves ambiguous. To tackle this, some existing
works learn symmetry in a data-driven manner, parameterizing and learning
expected symmetry through data. However, these methods often rely on explicit
knowledge, such as pre-defined Lie groups, which are typically restricted to
linear or affine transformations. In this paper, we propose a novel symmetry
learning algorithm based on transformations defined with one-parameter groups,
continuously parameterized transformations flowing along the directions of
vector fields called infinitesimal generators. Our method is built upon minimal
inductive biases, encompassing not only commonly utilized symmetries rooted in
Lie groups but also extending to symmetries derived from nonlinear generators.
To learn these symmetries, we introduce a notion of a validity score that
examine whether the transformed data is still valid for the given task. The
validity score is designed to be fully differentiable and easily computable,
enabling effective searches for transformations that achieve symmetries innate
to the data. We apply our method mainly in two domains: image data and partial
differential equations, and demonstrate its advantages. Our codes are available
at \url{https://github.com/kogyeonghoon/learning-symmetry-from-scratch.git}.",2024-10-29,"Gyeonghoon Ko, Hyunsu Kim, Juho Lee",http://arxiv.org/pdf/2410.21853v2,cs.LG
SoccerGuard: Investigating Injury Risk Factors for Professional Soccer Players with Machine Learning,"We present SoccerGuard, a novel framework for predicting injuries in women's
soccer using Machine Learning (ML). This framework can ingest data from
multiple sources, including subjective wellness and training load reports from
players, objective GPS sensor measurements, third-party player statistics, and
injury reports verified by medical personnel. We experiment with a number of
different settings related to synthetic data generation, input and output
window sizes, and ML models for prediction. Our results show that, given the
right configurations and feature combinations, injury event prediction can be
undertaken with considerable accuracy. The optimal results are achieved when
input windows are reduced and larger combined output windows are defined, in
combination with an ideally balanced data set. The framework also includes a
dashboard with a user-friendly Graphical User Interface (GUI) to support
interactive analysis and visualization.",2024-10-29,"Finn Bartels, Lu Xing, Cise Midoglu, Matthias Boeker, Toralf Kirsten, Pål Halvorsen",http://arxiv.org/pdf/2411.08901v1,cs.LG
A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification,"In recent years, spatio-temporal graph neural networks (GNNs) have attracted
considerable interest in the field of time series analysis, due to their
ability to capture dependencies among variables and across time points. The
objective of the presented systematic literature review is hence to provide a
comprehensive overview of the various modeling approaches and application
domains of GNNs for time series classification and forecasting. A database
search was conducted, and over 150 journal papers were selected for a detailed
examination of the current state-of-the-art in the field. This examination is
intended to offer to the reader a comprehensive collection of proposed models,
links to related source code, available datasets, benchmark models, and fitting
results. All this information is hoped to assist researchers in future studies.
To the best of our knowledge, this is the first systematic literature review
presenting a detailed comparison of the results of current spatio-temporal GNN
models in different domains. In addition, in its final part this review
discusses current limitations and challenges in the application of
spatio-temporal GNNs, such as comparability, reproducibility, explainability,
poor information capacity, and scalability.",2024-10-29,"Flavio Corradini, Flavio Gerosa, Marco Gori, Carlo Lucheroni, Marco Piangerelli, Martina Zannotti",http://arxiv.org/pdf/2410.22377v2,cs.LG
Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models,"Recently, we have observed that Large Multi-modal Models (LMMs) are
revolutionizing the way machines interact with the world, unlocking new
possibilities across various multi-modal applications. To adapt LMMs for
downstream tasks, parameter-efficient fine-tuning (PEFT) which only trains
additional prefix tokens or modules, has gained popularity. Nevertheless, there
has been little analysis of how PEFT works in LMMs. In this paper, we delve
into the strengths and weaknesses of each tuning strategy, shifting the focus
from the efficiency typically associated with these approaches. We first
discover that model parameter tuning methods such as LoRA and Adapters distort
the feature representation space learned during pre-training and limit the full
utilization of pre-trained knowledge. We also demonstrate that prefix-tuning
excels at preserving the representation space, despite its lower performance on
downstream tasks. These findings suggest a simple two-step PEFT strategy called
Prefix-Tuned PEFT (PT-PEFT), which successively performs prefix-tuning and then
PEFT (i.e., Adapter, LoRA), combines the benefits of both. Experimental results
show that PT-PEFT not only improves performance in image captioning and visual
question answering compared to vanilla PEFT methods but also helps preserve the
representation space of the four pre-trained models.",2024-10-29,"Donghoon Kim, Gusang Lee, Kyuhong Shim, Byonghyo Shim",http://arxiv.org/pdf/2411.00029v1,cs.LG
Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance,"State-of-the-art text-to-image (T2I) diffusion models often struggle to
generate rare compositions of concepts, e.g., objects with unusual attributes.
In this paper, we show that the compositional generation power of diffusion
models on such rare concepts can be significantly enhanced by the Large
Language Model (LLM) guidance. We start with empirical and theoretical
analysis, demonstrating that exposing frequent concepts relevant to the target
rare concepts during the diffusion sampling process yields more accurate
concept composition. Based on this, we propose a training-free approach, R2F,
that plans and executes the overall rare-to-frequent concept guidance
throughout the diffusion inference by leveraging the abundant semantic
knowledge in LLMs. Our framework is flexible across any pre-trained diffusion
models and LLMs, and can be seamlessly integrated with the region-guided
diffusion approaches. Extensive experiments on three datasets, including our
newly proposed benchmark, RareBench, containing various prompts with rare
compositions of concepts, R2F significantly surpasses existing models including
SD3.0 and FLUX by up to 28.1%p in T2I alignment. Code is available at
https://github.com/krafton-ai/Rare-to-Frequent.",2024-10-29,"Dongmin Park, Sebin Kim, Taehong Moon, Minkyu Kim, Kangwook Lee, Jaewoong Cho",http://arxiv.org/pdf/2410.22376v2,cs.LG
Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Transformers,"The debate between self-interpretable models and post-hoc explanations for
black-box models is central to Explainable AI (XAI). Self-interpretable models,
such as concept-based networks, offer insights by connecting decisions to
human-understandable concepts but often struggle with performance and
scalability. Conversely, post-hoc methods like Shapley values, while
theoretically robust, are computationally expensive and resource-intensive. To
bridge the gap between these two lines of research, we propose a novel method
that combines their strengths, providing theoretically guaranteed
self-interpretability for black-box models without compromising prediction
accuracy. Specifically, we introduce a parameter-efficient pipeline,
AutoGnothi, which integrates a small side network into the black-box model,
allowing it to generate Shapley value explanations without changing the
original network parameters. This side-tuning approach significantly reduces
memory, training, and inference costs, outperforming traditional
parameter-efficient methods, where full fine-tuning serves as the optimal
baseline. AutoGnothi enables the black-box model to predict and explain its
predictions with minimal overhead. Extensive experiments show that AutoGnothi
offers accurate explanations for both vision and language tasks, delivering
superior computational efficiency with comparable interpretability.",2024-10-29,"Shaobo Wang, Hongxuan Tang, Mingyang Wang, Hongrui Zhang, Xuyang Liu, Weiya Li, Xuming Hu, Linfeng Zhang",http://arxiv.org/pdf/2410.21815v2,cs.LG
Efficient and Effective Weight-Ensembling Mixture of Experts for Multi-Task Model Merging,"Multi-task learning (MTL) leverages a shared model to accomplish multiple
tasks and facilitate knowledge transfer. Recent research on task
arithmetic-based MTL demonstrates that merging the parameters of independently
fine-tuned models can effectively achieve MTL. However, existing merging
methods primarily seek a static optimal solution within the original model
parameter space, which often results in performance degradation due to the
inherent diversity among tasks and potential interferences. To address this
challenge, in this paper, we propose a Weight-Ensembling Mixture of Experts
(WEMoE) method for multi-task model merging. Specifically, we first identify
critical (or sensitive) modules by analyzing parameter variations in core
modules of Transformer-based models before and after finetuning. Then, our
WEMoE statically merges non-critical modules while transforming critical
modules into a mixture-of-experts (MoE) structure. During inference, expert
modules in the MoE are dynamically merged based on input samples, enabling a
more flexible and adaptive merging approach. Building on WEMoE, we further
introduce an efficient-and-effective WEMoE (E-WEMoE) method, whose core
mechanism involves eliminating non-essential elements in the critical modules
of WEMoE and implementing shared routing across multiple MoE modules, thereby
significantly reducing both the trainable parameters, the overall parameter
count, and computational overhead of the merged model by WEMoE. Experimental
results across various architectures and tasks demonstrate that both WEMoE and
E-WEMoE outperform state-of-the-art (SOTA) model merging methods in terms of
MTL performance, generalization, and robustness.",2024-10-29,"Li Shen, Anke Tang, Enneng Yang, Guibing Guo, Yong Luo, Lefei Zhang, Xiaochun Cao, Bo Du, Dacheng Tao",http://arxiv.org/pdf/2410.21804v1,cs.LG
Exponentially Consistent Statistical Classification of Continuous Sequences with Distribution Uncertainty,"In multiple classification, one aims to determine whether a testing sequence
is generated from the same distribution as one of the M training sequences or
not. Unlike most of existing studies that focus on discrete-valued sequences
with perfect distribution match, we study multiple classification for
continuous sequences with distribution uncertainty, where the generating
distributions of the testing and training sequences deviate even under the true
hypothesis. In particular, we propose distribution free tests and prove that
the error probabilities of our tests decay exponentially fast for three
different test designs: fixed-length, sequential, and two-phase tests. We first
consider the simple case without the null hypothesis, where the testing
sequence is known to be generated from a distribution close to the generating
distribution of one of the training sequences. Subsequently, we generalize our
results to a more general case with the null hypothesis by allowing the testing
sequence to be generated from a distribution that is vastly different from the
generating distributions of all training sequences.",2024-10-29,"Lina Zhu, Lin Zhou",http://arxiv.org/pdf/2410.21799v1,cs.LG
Robot Policy Learning with Temporal Optimal Transport Reward,"Reward specification is one of the most tricky problems in Reinforcement
Learning, which usually requires tedious hand engineering in practice. One
promising approach to tackle this challenge is to adopt existing expert video
demonstrations for policy learning. Some recent work investigates how to learn
robot policies from only a single/few expert video demonstrations. For example,
reward labeling via Optimal Transport (OT) has been shown to be an effective
strategy to generate a proxy reward by measuring the alignment between the
robot trajectory and the expert demonstrations. However, previous work mostly
overlooks that the OT reward is invariant to temporal order information, which
could bring extra noise to the reward signal. To address this issue, in this
paper, we introduce the Temporal Optimal Transport (TemporalOT) reward to
incorporate temporal order information for learning a more accurate OT-based
proxy reward. Extensive experiments on the Meta-world benchmark tasks validate
the efficacy of the proposed method. Code is available at:
https://github.com/fuyw/TemporalOT",2024-10-29,"Yuwei Fu, Haichao Zhang, Di Wu, Wei Xu, Benoit Boulet",http://arxiv.org/pdf/2410.21795v2,cs.LG
MARCO: Multi-Agent Real-time Chat Orchestration,"Large language model advancements have enabled the development of multi-agent
frameworks to tackle complex, real-world problems such as to automate tasks
that require interactions with diverse tools, reasoning, and human
collaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration
framework for automating tasks using LLMs. MARCO addresses key challenges in
utilizing LLMs for complex, multi-step task execution. It incorporates robust
guardrails to steer LLM behavior, validate outputs, and recover from errors
that stem from inconsistent output formatting, function and parameter
hallucination, and lack of domain knowledge. Through extensive experiments we
demonstrate MARCO's superior performance with 94.48% and 92.74% accuracy on
task execution for Digital Restaurant Service Platform conversations and Retail
conversations datasets respectively along with 44.91% improved latency and
33.71% cost reduction. We also report effects of guardrails in performance gain
along with comparisons of various LLM models, both open-source and proprietary.
The modular and generic design of MARCO allows it to be adapted for automating
tasks across domains and to execute complex usecases through multi-turn
interactions.",2024-10-29,"Anubhav Shrimal, Stanley Kanagaraj, Kriti Biswas, Swarnalatha Raghuraman, Anish Nediyanchath, Yi Zhang, Promod Yenigalla",http://arxiv.org/pdf/2410.21784v1,cs.LG
RNA-GPT: Multimodal Generative System for RNA Sequence Understanding,"RNAs are essential molecules that carry genetic information vital for life,
with profound implications for drug development and biotechnology. Despite this
importance, RNA research is often hindered by the vast literature available on
the topic. To streamline this process, we introduce RNA-GPT, a multi-modal RNA
chat model designed to simplify RNA discovery by leveraging extensive RNA
literature. RNA-GPT integrates RNA sequence encoders with linear projection
layers and state-of-the-art large language models (LLMs) for precise
representation alignment, enabling it to process user-uploaded RNA sequences
and deliver concise, accurate responses. Built on a scalable training pipeline,
RNA-GPT utilizes RNA-QA, an automated system that gathers RNA annotations from
RNACentral using a divide-and-conquer approach with GPT-4o and latent Dirichlet
allocation (LDA) to efficiently handle large datasets and generate
instruction-tuning samples. Our experiments indicate that RNA-GPT effectively
addresses complex RNA queries, thereby facilitating RNA research. Additionally,
we present RNA-QA, a dataset of 407,616 RNA samples for modality alignment and
instruction tuning, further advancing the potential of RNA research tools.",2024-10-29,"Yijia Xiao, Edward Sun, Yiqiao Jin, Wei Wang",http://arxiv.org/pdf/2411.08900v1,cs.LG
Robust Graph Neural Networks for Stability Analysis in Dynamic Networks,"In the current context of accelerated globalization and digitalization, the
complexity and uncertainty of financial markets are increasing, and the
identification and prevention of economic risks have become a key link in
maintaining the stability of the financial system. Traditional risk
identification methods often have limitations because they are difficult to
cope with the multi-level and dynamically changing complex relationships in
financial networks. With the rapid development of financial technology, graph
neural network (GNN) technology, as an emerging deep learning method, has
gradually shown great potential in the field of financial risk management. GNN
can map transaction behaviors, financial institutions, individuals, and their
interactive relationships in financial networks into graph structures, and
effectively capture potential patterns and abnormal signals in financial data
through embedded representation learning. Using this technology, financial
institutions can extract valuable information from complex transaction
networks, identify hidden dangers or abnormal behaviors that may cause systemic
risks in a timely manner, optimize decision-making processes, and improve the
accuracy of risk warnings. This paper explores the economic risk identification
algorithm based on the GNN algorithm, aiming to provide financial institutions
and regulators with more intelligent technical tools to help maintain the
security and stability of the financial market. Improving the efficiency of
economic risk identification through innovative technical means is expected to
further enhance the risk resistance of the financial system and lay the
foundation for building a robust global financial system.",2024-10-29,"Xin Zhang, Zhen Xu, Yue Liu, Mengfang Sun, Tong Zhou, Wenying Sun",http://arxiv.org/pdf/2411.11848v1,cs.LG
Online Mirror Descent for Tchebycheff Scalarization in Multi-Objective Optimization,"The goal of multi-objective optimization (MOO) is to learn under multiple,
potentially conflicting, objectives. One widely used technique to tackle MOO is
through linear scalarization, where one fixed preference vector is used to
combine the objectives into a single scalar value for optimization. However,
recent work (Hu et al., 2024) has shown linear scalarization often fails to
capture the non-convex regions of the Pareto Front, failing to recover the
complete set of Pareto optimal solutions. In light of the above limitations,
this paper focuses on Tchebycheff scalarization that optimizes for the
worst-case objective. In particular, we propose an online mirror descent
algorithm for Tchebycheff scalarization, which we call OMD-TCH. We show that
OMD-TCH enjoys a convergence rate of $O(\sqrt{\log m/T})$ where $m$ is the
number of objectives and $T$ is the number of iteration rounds. We also propose
a novel adaptive online-to-batch conversion scheme that significantly improves
the practical performance of OMD-TCH while maintaining the same convergence
guarantees. We demonstrate the effectiveness of OMD-TCH and the adaptive
conversion scheme on both synthetic problems and federated learning tasks under
fairness constraints, showing state-of-the-art performance.",2024-10-29,"Meitong Liu, Xiaoyuan Zhang, Chulin Xie, Kate Donahue, Han Zhao",http://arxiv.org/pdf/2410.21764v2,cs.LG
Reliable and Compact Graph Fine-tuning via GraphSparse Prompting,"Recently, graph prompt learning has garnered increasing attention in adapting
pre-trained GNN models for downstream graph learning tasks. However, existing
works generally conduct prompting over all graph elements (e.g., nodes, edges,
node attributes, etc.), which is suboptimal and obviously redundant. To address
this issue, we propose exploiting sparse representation theory for graph
prompting and present Graph Sparse Prompting (GSP). GSP aims to adaptively and
sparsely select the optimal elements (e.g., certain node attributes) to achieve
compact prompting for downstream tasks. Specifically, we propose two kinds of
GSP models, termed Graph Sparse Feature Prompting (GSFP) and Graph Sparse
multi-Feature Prompting (GSmFP). Both GSFP and GSmFP provide a general scheme
for tuning any specific pre-trained GNNs that can achieve attribute selection
and compact prompt learning simultaneously. A simple yet effective algorithm
has been designed for solving GSFP and GSmFP models. Experiments on 16
widely-used benchmark datasets validate the effectiveness and advantages of the
proposed GSFPs.",2024-10-29,"Bo Jiang, Hao Wu, Beibei Wang, Jin Tang, Bin Luo",http://arxiv.org/pdf/2410.21749v1,cs.LG
RDSA: A Robust Deep Graph Clustering Framework via Dual Soft Assignment,"Graph clustering is an essential aspect of network analysis that involves
grouping nodes into separate clusters. Recent developments in deep learning
have resulted in graph clustering, which has proven effective in many
applications. Nonetheless, these methods often encounter difficulties when
dealing with real-world graphs, particularly in the presence of noisy edges.
Additionally, many denoising graph clustering methods tend to suffer from lower
performance, training instability, and challenges in scaling to large datasets
compared to non-denoised models. To tackle these issues, we introduce a new
framework called the Robust Deep Graph Clustering Framework via Dual Soft
Assignment (RDSA). RDSA consists of three key components: (i) a node embedding
module that effectively integrates the graph's topological features and node
attributes; (ii) a structure-based soft assignment module that improves graph
modularity by utilizing an affinity matrix for node assignments; and (iii) a
node-based soft assignment module that identifies community landmarks and
refines node assignments to enhance the model's robustness. We assess RDSA on
various real-world datasets, demonstrating its superior performance relative to
existing state-of-the-art methods. Our findings indicate that RDSA provides
robust clustering across different graph types, excelling in clustering
effectiveness and robustness, including adaptability to noise, stability, and
scalability.",2024-10-29,"Yang Xiang, Li Fan, Tulika Saha, Xiaoying Pang, Yushan Pan, Haiyang Zhang, Chengtao Ji",http://arxiv.org/pdf/2410.21745v4,cs.LG
Efficient Reprogramming of Memristive Crossbars for DNNs: Weight Sorting and Bit Stucking,"We introduce a novel approach to reduce the number of times required for
reprogramming memristors on bit-sliced compute-in-memory crossbars for deep
neural networks (DNNs). Our idea addresses the limited non-volatile memory
endurance, which restrict the number of times they can be reprogrammed.
  To reduce reprogramming demands, we employ two techniques: (1) we organize
weights into sorted sections to schedule reprogramming of similar crossbars,
maximizing memristor state reuse, and (2) we reprogram only a fraction of
randomly selected memristors in low-order columns, leveraging their bit-level
distribution and recognizing their relatively small impact on model accuracy.
  We evaluate our approach for state-of-the-art models on the ImageNet-1K
dataset. We demonstrate a substantial reduction in crossbar reprogramming by
3.7x for ResNet-50 and 21x for ViT-Base, while maintaining model accuracy
within a 1% margin.",2024-10-29,"Matheus Farias, H. T. Kung",http://arxiv.org/pdf/2410.21730v1,cs.LG
Uncertainty Quantification via Hölder Divergence for Multi-View Representation Learning,"Evidence-based deep learning represents a burgeoning paradigm for uncertainty
estimation, offering reliable predictions with negligible extra computational
overheads. Existing methods usually adopt Kullback-Leibler divergence to
estimate the uncertainty of network predictions, ignoring domain gaps among
various modalities. To tackle this issue, this paper introduces a novel
algorithm based on H\""older Divergence (HD) to enhance the reliability of
multi-view learning by addressing inherent uncertainty challenges from
incomplete or noisy data. Generally, our method extracts the representations of
multiple modalities through parallel network branches, and then employs HD to
estimate the prediction uncertainties. Through the Dempster-Shafer theory,
integration of uncertainty from different modalities, thereby generating a
comprehensive result that considers all available representations.
Mathematically, HD proves to better measure the ``distance'' between real data
distribution and predictive distribution of the model and improve the
performances of multi-class recognition tasks.
  Specifically, our method surpass the existing state-of-the-art counterparts
on all evaluating benchmarks.
  We further conduct extensive experiments on different backbones to verify our
superior robustness. It is demonstrated that our method successfully pushes the
corresponding performance boundaries. Finally, we perform experiments on more
challenging scenarios, \textit{i.e.}, learning with incomplete or noisy data,
revealing that our method exhibits a high tolerance to such corrupted data.",2024-10-29,"Yan Zhang, Ming Li, Chun Li, Zhaoxia Liu, Ye Zhang, Fei Richard Yu",http://arxiv.org/pdf/2411.00826v2,cs.LG
On the Statistical Complexity of Estimating Vendi Scores from Empirical Data,"Evaluating the diversity of generative models without access to reference
data poses methodological challenges. The reference-free Vendi score offers a
solution by quantifying the diversity of generated data using matrix-based
entropy measures. The Vendi score is usually computed via the
eigendecomposition of an $n \times n$ kernel matrix for $n$ generated samples.
However, the heavy computational cost of eigendecomposition for large $n$ often
limits the sample size used in practice to a few tens of thousands. In this
paper, we investigate the statistical convergence of the Vendi score. We
numerically demonstrate that for kernel functions with an infinite feature map
dimension, the score estimated from a limited sample size may exhibit a
non-negligible bias relative to the population Vendi score, i.e., the
asymptotic limit as the sample size approaches infinity. To address this, we
introduce a truncation of the Vendi statistic, called the $t$-truncated Vendi
statistic, which is guaranteed to converge to its asymptotic limit given
$n=O(t)$ samples. We show that the existing Nystr\""om method and the FKEA
approximation method for approximating the Vendi score both converge to the
population truncated Vendi score. We perform several numerical experiments to
illustrate the concentration of the Nystr\""om and FKEA-computed Vendi scores
around the truncated Vendi and discuss how the truncated Vendi score correlates
with the diversity of image and text data.",2024-10-29,"Azim Ospanov, Farzan Farnia",http://arxiv.org/pdf/2410.21719v2,cs.LG
Generating Realistic Tabular Data with Large Language Models,"While most generative models show achievements in image data generation, few
are developed for tabular data generation. Recently, due to success of large
language models (LLM) in diverse tasks, they have also been used for tabular
data generation. However, these methods do not capture the correct correlation
between the features and the target variable, hindering their applications in
downstream predictive tasks. To address this problem, we propose a LLM-based
method with three important improvements to correctly capture the ground-truth
feature-class correlation in the real data. First, we propose a novel
permutation strategy for the input data in the fine-tuning phase. Second, we
propose a feature-conditional sampling approach to generate synthetic samples.
Finally, we generate the labels by constructing prompts based on the generated
samples to query our fine-tuned LLM. Our extensive experiments show that our
method significantly outperforms 10 SOTA baselines on 20 datasets in downstream
tasks. It also produces highly realistic synthetic samples in terms of quality
and diversity. More importantly, classifiers trained with our synthetic data
can even compete with classifiers trained with the original data on half of the
benchmark datasets, which is a significant achievement in tabular data
generation.",2024-10-29,"Dang Nguyen, Sunil Gupta, Kien Do, Thin Nguyen, Svetha Venkatesh",http://arxiv.org/pdf/2410.21717v1,cs.LG
Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN,"The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.",2024-10-29,"Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li",http://arxiv.org/pdf/2411.00028v2,cs.LG
Sliced-Wasserstein-based Anomaly Detection and Open Dataset for Localized Critical Peak Rebates,"In this work, we present a new unsupervised anomaly (outlier) detection (AD)
method using the sliced-Wasserstein metric. This filtering technique is
conceptually interesting for MLOps pipelines deploying machine learning models
in critical sectors, e.g., energy, as it offers a conservative data selection.
Additionally, we open the first dataset showcasing localized critical peak
rebate demand response in a northern climate. We demonstrate the capabilities
of our method on synthetic datasets as well as standard AD datasets and use it
in the making of a first benchmark for our open-source localized critical peak
rebate dataset.",2024-10-29,"Julien Pallage, Bertrand Scherrer, Salma Naccache, Christophe Bélanger, Antoine Lesage-Landry",http://arxiv.org/pdf/2410.21712v2,cs.LG
Multi-view clustering integrating anchor attribute and structural information,"Multisource data has spurred the development of advanced clustering
algorithms, such as multi-view clustering, which critically relies on
constructing similarity matrices. Traditional algorithms typically generate
these matrices from sample attributes alone. However, real-world networks often
include pairwise directed topological structures critical for clustering. This
paper introduces a novel multi-view clustering algorithm, AAS. It utilizes a
two-step proximity approach via anchors in each view, integrating attribute and
directed structural information. This approach enhances the clarity of category
characteristics in the similarity matrices. The anchor structural similarity
matrix leverages strongly connected components of directed graphs. The entire
process-from similarity matrices construction to clustering - is consolidated
into a unified optimization framework. Comparative experiments on the modified
Attribute SBM dataset against eight algorithms affirm the effectiveness and
superiority of AAS.",2024-10-29,"Xuetong Li, Xiao-Dong Zhang",http://arxiv.org/pdf/2410.21711v1,cs.LG
Stochastic Approximation with Unbounded Markovian Noise: A General-Purpose Theorem,"Motivated by engineering applications such as resource allocation in networks
and inventory systems, we consider average-reward Reinforcement Learning with
unbounded state space and reward function. Recent works studied this problem in
the actor-critic framework and established finite sample bounds assuming access
to a critic with certain error guarantees. We complement their work by studying
Temporal Difference (TD) learning with linear function approximation and
establishing finite-time bounds with the optimal
$\mathcal{O}\left(1/\epsilon^2\right)$ sample complexity. These results are
obtained using the following general-purpose theorem for non-linear Stochastic
Approximation (SA).
  Suppose that one constructs a Lyapunov function for a non-linear SA with
certain drift condition. Then, our theorem establishes finite-time bounds when
this SA is driven by unbounded Markovian noise under suitable conditions. It
serves as a black box tool to generalize sample guarantees on SA from i.i.d. or
martingale difference case to potentially unbounded Markovian noise. The
generality and the mild assumption of the setup enables broad applicability of
our theorem. We illustrate its power by studying two more systems: (i) We
improve upon the finite-time bounds of $Q$-learning by tightening the error
bounds and also allowing for a larger class of behavior policies. (ii) We
establish the first ever finite-time bounds for distributed stochastic
optimization of high-dimensional smooth strongly convex function using cyclic
block coordinate descent.",2024-10-29,"Shaan Ul Haque, Siva Theja Maguluri",http://arxiv.org/pdf/2410.21704v1,cs.LG
Minimax optimality of deep neural networks on dependent data via PAC-Bayes bounds,"In a groundbreaking work, Schmidt-Hieber (2020) proved the minimax optimality
of deep neural networks with ReLu activation for least-square regression
estimation over a large class of functions defined by composition. In this
paper, we extend these results in many directions. First, we remove the i.i.d.
assumption on the observations, to allow some time dependence. The observations
are assumed to be a Markov chain with a non-null pseudo-spectral gap. Then, we
study a more general class of machine learning problems, which includes
least-square and logistic regression as special cases. Leveraging on PAC-Bayes
oracle inequalities and a version of Bernstein inequality due to Paulin (2015),
we derive upper bounds on the estimation risk for a generalized Bayesian
estimator. In the case of least-square regression, this bound matches (up to a
logarithmic factor) the lower bound of Schmidt-Hieber (2020). We establish a
similar lower bound for classification with the logistic loss, and prove that
the proposed DNN estimator is optimal in the minimax sense.",2024-10-29,"Pierre Alquier, William Kengne",http://arxiv.org/pdf/2410.21702v1,cs.LG
On the Role of Depth and Looping for In-Context Learning with Task Diversity,"The intriguing in-context learning (ICL) abilities of deep Transformer models
have lately garnered significant attention. By studying in-context linear
regression on unimodal Gaussian data, recent empirical and theoretical works
have argued that ICL emerges from Transformers' abilities to simulate learning
algorithms like gradient descent. However, these works fail to capture the
remarkable ability of Transformers to learn multiple tasks in context. To this
end, we study in-context learning for linear regression with diverse tasks,
characterized by data covariance matrices with condition numbers ranging from
$[1, \kappa]$, and highlight the importance of depth in this setting. More
specifically, (a) we show theoretical lower bounds of $\log(\kappa)$ (or
$\sqrt{\kappa}$) linear attention layers in the unrestricted (or restricted)
attention setting and, (b) we show that multilayer Transformers can indeed
solve such tasks with a number of layers that matches the lower bounds.
However, we show that this expressivity of multilayer Transformer comes at the
price of robustness. In particular, multilayer Transformers are not robust to
even distributional shifts as small as $O(e^{-L})$ in Wasserstein distance,
where $L$ is the depth of the network. We then demonstrate that Looped
Transformers -- a special class of multilayer Transformers with weight-sharing
-- not only exhibit similar expressive power but are also provably robust under
mild assumptions. Besides out-of-distribution generalization, we also show that
Looped Transformers are the only models that exhibit a monotonic behavior of
loss with respect to depth.",2024-10-29,"Khashayar Gatmiry, Nikunj Saunshi, Sashank J. Reddi, Stefanie Jegelka, Sanjiv Kumar",http://arxiv.org/pdf/2410.21698v1,cs.LG
The Effects of Multi-Task Learning on ReLU Neural Network Functions,"This paper studies the properties of solutions to multi-task shallow ReLU
neural network learning problems, wherein the network is trained to fit a
dataset with minimal sum of squared weights. Remarkably, the solutions learned
for each individual task resemble those obtained by solving a kernel regression
problem, revealing a novel connection between neural networks and kernel
methods. It is known that single-task neural network learning problems are
equivalent to a minimum norm interpolation problem in a non-Hilbertian Banach
space, and that the solutions of such problems are generally non-unique. In
contrast, we prove that the solutions to univariate-input, multi-task neural
network interpolation problems are almost always unique, and coincide with the
solution to a minimum-norm interpolation problem in a Sobolev (Reproducing
Kernel) Hilbert Space. We also demonstrate a similar phenomenon in the
multivariate-input case; specifically, we show that neural network learning
problems with large numbers of tasks are approximately equivalent to an
$\ell^2$ (Hilbert space) minimization problem over a fixed kernel determined by
the optimal neurons.",2024-10-29,"Julia Nakhleh, Joseph Shenouda, Robert D. Nowak",http://arxiv.org/pdf/2410.21696v4,cs.LG
CFSafety: Comprehensive Fine-grained Safety Assessment for LLMs,"As large language models (LLMs) rapidly evolve, they bring significant
conveniences to our work and daily lives, but also introduce considerable
safety risks. These models can generate texts with social biases or unethical
content, and under specific adversarial instructions, may even incite illegal
activities. Therefore, rigorous safety assessments of LLMs are crucial. In this
work, we introduce a safety assessment benchmark, CFSafety, which integrates 5
classic safety scenarios and 5 types of instruction attacks, totaling 10
categories of safety questions, to form a test set with 25k prompts. This test
set was used to evaluate the natural language generation (NLG) capabilities of
LLMs, employing a combination of simple moral judgment and a 1-5 safety rating
scale for scoring. Using this benchmark, we tested eight popular LLMs,
including the GPT series. The results indicate that while GPT-4 demonstrated
superior safety performance, the safety effectiveness of LLMs, including this
model, still requires improvement. The data and code associated with this study
are available on GitHub.",2024-10-29,"Zhihao Liu, Chenhui Hu",http://arxiv.org/pdf/2410.21695v1,cs.LG
SkipSNN: Efficiently Classifying Spike Trains with Event-attention,"Spike train classification has recently become an important topic in the
machine learning community, where each spike train is a binary event sequence
with \emph{temporal-sparsity of signals of interest} and \emph{temporal-noise}
properties. A promising model for it should follow the design principle of
performing intensive computation only when signals of interest appear. So such
tasks use mainly Spiking Neural Networks (SNNs) due to their consideration of
temporal-sparsity of spike trains. However, the basic mechanism of SNNs ignore
the temporal-noise issue, which makes them computationally expensive and thus
high power consumption for analyzing spike trains on resource-constrained
platforms. As an event-driven model, an SNN neuron makes a reaction given any
input signals, making it difficult to quickly find signals of interest. In this
paper, we introduce an event-attention mechanism that enables SNNs to
dynamically highlight useful signals of the original spike trains. To this end,
we propose SkipSNN, which extends existing SNN models by learning to mask out
noise by skipping membrane potential updates and shortening the effective size
of the computational graph. This process is analogous to how people choose to
open and close their eyes to filter the information they see. We evaluate
SkipSNN on various neuromorphic tasks and demonstrate that it achieves
significantly better computational efficiency and classification accuracy than
other state-of-the-art SNNs.",2024-10-29,"Hang Yin, Yao Su, Liping Liu, Thomas Hartvigsen, Xin Dai, Xiangnan Kong",http://arxiv.org/pdf/2411.05806v1,cs.LG
"Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling and Zero-Shot Transfer","Constructing transferable descriptors for conformation representation of
molecular and biological systems finds numerous applications in drug discovery,
learning-based molecular dynamics, and protein mechanism analysis. Geometric
graph neural networks (Geom-GNNs) with all-atom information have transformed
atomistic simulations by serving as a general learnable geometric descriptors
for downstream tasks including prediction of interatomic potential and
molecular properties. However, common practices involve supervising Geom-GNNs
on specific downstream tasks, which suffer from the lack of high-quality data
and inaccurate labels leading to poor generalization and performance
degradation on out-of-distribution (OOD) scenarios. In this work, we explored
the possibility of using pre-trained Geom-GNNs as transferable and highly
effective geometric descriptors for improved generalization. To explore their
representation power, we studied the scaling behaviors of Geom-GNNs under
self-supervised pre-training, supervised and unsupervised learning setups. We
find that the expressive power of different architectures can differ on the
pre-training task. Interestingly, Geom-GNNs do not follow the power-law scaling
on the pre-training task, and universally lack predictable scaling behavior on
the supervised tasks with quantum chemical labels important for screening and
design of novel molecules. More importantly, we demonstrate how all-atom graph
embedding can be organically combined with other neural architectures to
enhance the expressive power. Meanwhile, the low-dimensional projection of the
latent space shows excellent agreement with conventional geometrical
descriptors.",2024-10-29,"Zihan Pengmei, Zhengyuan Shen, Zichen Wang, Marcus Collins, Huzefa Rangwala",http://arxiv.org/pdf/2410.21683v1,cs.LG
Revisiting Reliability in Large-Scale Machine Learning Research Clusters,"Reliability is a fundamental challenge in operating large-scale machine
learning (ML) infrastructures, particularly as the scale of ML models and
training clusters continues to grow. Despite decades of research on
infrastructure failures, the impact of job failures across different scales
remains unclear. This paper presents a view of managing two large, multi-tenant
ML clusters, providing quantitative analysis, operational experience, and our
own perspective in understanding and addressing reliability concerns at scale.
Our analysis reveals that while large jobs are most vulnerable to failures,
smaller jobs make up the majority of jobs in the clusters and should be
incorporated into optimization objectives. We identify key workload properties,
compare them across clusters, and demonstrate essential reliability
requirements for pushing the boundaries of ML training at scale.
  We hereby introduce a taxonomy of failures and key reliability metrics,
analyze 11 months of data from two state-of-the-art ML environments with 4
million jobs and over 150 million A100 GPU hours. Building on our data, we fit
a failure model to project Mean Time to Failure for various GPU scales. We
further propose a method to estimate a related metric, Effective Training Time
Ratio, as a function of job parameters, and we use this model to gauge the
efficacy of potential software mitigations at scale. Our work provides valuable
insights and future research directions for improving the reliability of AI
supercomputer clusters, emphasizing the need for flexible, workload-agnostic,
and reliability-aware infrastructure, system software, and algorithms.",2024-10-29,"Apostolos Kokolis, Michael Kuchnik, John Hoffman, Adithya Kumar, Parth Malani, Faye Ma, Zachary DeVito, Shubho Sengupta, Kalyan Saladi, Carole-Jean Wu",http://arxiv.org/pdf/2410.21680v2,cs.LG
How Does Critical Batch Size Scale in Pre-training?,"Training large-scale models under given resources requires careful design of
parallelism strategies. In particular, the efficiency notion of critical batch
size (CBS), concerning the compromise between time and compute, marks the
threshold beyond which greater data parallelism leads to diminishing returns.
To operationalize it, we propose a measure of CBS and pre-train a series of
auto-regressive language models, ranging from 85 million to 1.2 billion
parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and
careful control of factors such as batch size, momentum, and learning rate
along with its scheduling, we systematically investigate the impact of scale on
CBS. Then we fit scaling laws with respect to model and data sizes to decouple
their effects. Overall, our results demonstrate that CBS scales primarily with
data size rather than model size, a finding we justify theoretically through
the analysis of infinite-width limits of neural networks and
infinite-dimensional least squares regression. Of independent interest, we
highlight the importance of common hyper-parameter choices and strategies for
studying large-scale pre-training beyond fixed training durations.",2024-10-29,"Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade",http://arxiv.org/pdf/2410.21676v4,cs.LG
Machine Unlearning using Forgetting Neural Networks,"Modern computer systems store vast amounts of personal data, enabling
advances in AI and ML but risking user privacy and trust. For privacy reasons,
it is desired sometimes for an ML model to forget part of the data it was
trained on. This paper presents a new approach to machine unlearning using
forgetting neural networks (FNN). FNNs are neural networks with specific
forgetting layers, that take inspiration from the processes involved when a
human brain forgets. While FNNs had been proposed as a theoretical construct,
they have not been previously used as a machine unlearning method. We describe
four different types of forgetting layers and study their properties. In our
experimental evaluation, we report our results on the MNIST handwritten digit
recognition and fashion datasets. The effectiveness of the unlearned models was
tested using Membership Inference Attacks (MIA). Successful experimental
results demonstrate the great potential of our proposed method for dealing with
the machine unlearning problem.",2024-10-29,"Amartya Hatua, Trung T. Nguyen, Filip Cano, Andrew H. Sung",http://arxiv.org/pdf/2410.22374v1,cs.LG
Variational Bayes Decomposition for Inverse Estimation with Superimposed Multispectral Intensity,"A variational Bayesian inference for measured wave intensity, such as X-ray
intensity, is proposed in this paper. The data is popular to obtain information
about unobservable features of an object, such as a material sample and the
components of it. The proposed method assumes particles represent the wave, and
their behaviors are stochastically modeled. The inference is accurate even if
the data is noisy because of a smooth prior setting. Moreover, in this paper,
two experimental results show feasibility of the proposed method.",2024-10-29,"Akinori Asahara, Yoshihiro Osakabe, Yamamoto Mitsuya, Hidekazu Morita",http://arxiv.org/pdf/2411.05805v1,cs.LG
Sequential choice in ordered bundles,"Experience goods such as sporting and artistic events, songs, videos, news
stories, podcasts, and television series, are often packaged and consumed in
bundles. Many such bundles are ordered in the sense that the individual items
are consumed sequentially, one at a time. We examine if an individual's
decision to consume the next item in an ordered bundle can be predicted based
on his/her consumption pattern for the preceding items. We evaluate several
predictive models, including two custom Transformers using decoder-only and
encoder-decoder architectures, fine-tuned GPT-3, a custom LSTM model, a
reinforcement learning model, two Markov models, and a zero-order model. Using
data from Spotify, we find that the custom Transformer with a decoder-only
architecture provides the most accurate predictions, both for individual
choices and aggregate demand. This model captures a general form of state
dependence. Analysis of Transformer attention weights suggests that the
consumption of the next item in a bundle is based on approximately equal
weighting of all preceding choices. Our results indicate that the Transformer
can assist in queuing the next item that an individual is likely to consume
from an ordered bundle, predicting the demand for individual items, and
personalizing promotions to increase demand.",2024-10-29,"Rajeev Kohli, Kriste Krstovski, Hengyu Kuang, Hengxu Lin",http://arxiv.org/pdf/2410.21670v1,cs.LG
Minimum Entropy Coupling with Bottleneck,"This paper investigates a novel lossy compression framework operating under
logarithmic loss, designed to handle situations where the reconstruction
distribution diverges from the source distribution. This framework is
especially relevant for applications that require joint compression and
retrieval, and in scenarios involving distributional shifts due to processing.
We show that the proposed formulation extends the classical minimum entropy
coupling framework by integrating a bottleneck, allowing for a controlled
degree of stochasticity in the coupling. We explore the decomposition of the
Minimum Entropy Coupling with Bottleneck (MEC-B) into two distinct optimization
problems: Entropy-Bounded Information Maximization (EBIM) for the encoder, and
Minimum Entropy Coupling (MEC) for the decoder. Through extensive analysis, we
provide a greedy algorithm for EBIM with guaranteed performance, and
characterize the optimal solution near functional mappings, yielding
significant theoretical insights into the structural complexity of this
problem. Furthermore, we illustrate the practical application of MEC-B through
experiments in Markov Coding Games (MCGs) under rate limits. These games
simulate a communication scenario within a Markov Decision Process, where an
agent must transmit a compressed message from a sender to a receiver through
its actions. Our experiments highlight the trade-offs between MDP rewards and
receiver accuracy across various compression rates, showcasing the efficacy of
our method compared to conventional compression baseline.",2024-10-29,"M. Reza Ebrahimi, Jun Chen, Ashish Khisti",http://arxiv.org/pdf/2410.21666v1,cs.LG
$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization,"Preference optimization has made significant progress recently, with numerous
methods developed to align language models with human preferences. This paper
introduces $f$-divergence Preference Optimization ($f$-PO), a novel framework
that generalizes and extends existing approaches. $f$-PO minimizes
$f$-divergences between the optimized policy and the optimal policy,
encompassing a broad family of alignment methods using various divergences. Our
approach unifies previous algorithms like DPO and EXO, while offering new
variants through different choices of $f$-divergences. We provide theoretical
analysis of $f$-PO's properties and conduct extensive experiments on
state-of-the-art language models using benchmark datasets. Results demonstrate
$f$-PO's effectiveness across various tasks, achieving superior performance
compared to existing methods on popular benchmarks such as AlpacaEval 2,
Arena-Hard, MT-Bench, and Open LLM Leaderboard v2. Additionally, we present
ablation studies exploring the impact of different $f$-divergences, offering
insights into the trade-offs between regularization and performance in offline
preference optimization. Our work contributes both practical algorithms and
theoretical understanding to the field of language model alignment. Code is
available at https://github.com/MinkaiXu/fPO.",2024-10-29,"Jiaqi Han, Mingjian Jiang, Yuxuan Song, Stefano Ermon, Minkai Xu",http://arxiv.org/pdf/2410.21662v2,cs.LG
Mobility-LLM: Learning Visiting Intentions and Travel Preferences from Human Mobility Data with Large Language Models,"Location-based services (LBS) have accumulated extensive human mobility data
on diverse behaviors through check-in sequences. These sequences offer valuable
insights into users' intentions and preferences. Yet, existing models analyzing
check-in sequences fail to consider the semantics contained in these sequences,
which closely reflect human visiting intentions and travel preferences, leading
to an incomplete comprehension. Drawing inspiration from the exceptional
semantic understanding and contextual information processing capabilities of
large language models (LLMs) across various domains, we present Mobility-LLM, a
novel framework that leverages LLMs to analyze check-in sequences for multiple
tasks. Since LLMs cannot directly interpret check-ins, we reprogram these
sequences to help LLMs comprehensively understand the semantics of human
visiting intentions and travel preferences. Specifically, we introduce a
visiting intention memory network (VIMN) to capture the visiting intentions at
each record, along with a shared pool of human travel preference prompts (HTPP)
to guide the LLM in understanding users' travel preferences. These components
enhance the model's ability to extract and leverage semantic information from
human mobility data effectively. Extensive experiments on four benchmark
datasets and three downstream tasks demonstrate that our approach significantly
outperforms existing models, underscoring the effectiveness of Mobility-LLM in
advancing our understanding of human mobility data within LBS contexts.",2024-10-29,"Letian Gong, Yan Lin, Xinyue Zhang, Yiwen Lu, Xuedi Han, Yichen Liu, Shengnan Guo, Youfang Lin, Huaiyu Wan",http://arxiv.org/pdf/2411.00823v1,cs.LG
PACER: Physics Informed Uncertainty Aware Climate Emulator,"Climate models serve as critical tools for evaluating the effects of climate
change and projecting future climate scenarios. However, the reliance on
numerical simulations of physical equations renders them computationally
intensive and inefficient. While deep learning methodologies have made
significant progress in weather forecasting, they are still unstable for
climate emulation tasks. Here, we propose PACER, a lightweight 684K parameter
Physics Informed Uncertainty Aware Climate Emulator. PACER emulates temperature
and precipitation stably for 86 years while only being trained on greenhouse
gas emissions data. We incorporate a fundamental physical law of
advection-diffusion in PACER accounting for boundary conditions and empirically
estimating the diffusion co-efficient and flow velocities from emissions data.
PACER has been trained on 15 climate models provided by ClimateSet
outperforming baselines across most of the climate models and advancing a new
state of the art in a climate diagnostic task.",2024-10-29,"Hira Saleem, Flora Salim, Cormac Purcell",http://arxiv.org/pdf/2410.21657v2,cs.LG
Dimensionality-induced information loss of outliers in deep neural networks,"Out-of-distribution (OOD) detection is a critical issue for the stable and
reliable operation of systems using a deep neural network (DNN). Although many
OOD detection methods have been proposed, it remains unclear how the
differences between in-distribution (ID) and OOD samples are generated by each
processing step inside DNNs. We experimentally clarify this issue by
investigating the layer dependence of feature representations from multiple
perspectives. We find that intrinsic low dimensionalization of DNNs is
essential for understanding how OOD samples become more distinct from ID
samples as features propagate to deeper layers. Based on these observations, we
provide a simple picture that consistently explains various properties of OOD
samples. Specifically, low-dimensional weights eliminate most information from
OOD samples, resulting in misclassifications due to excessive attention to
dataset bias. In addition, we demonstrate the utility of dimensionality by
proposing a dimensionality-aware OOD detection method based on alignment of
features and weights, which consistently achieves high performance for various
datasets with lower computational cost.",2024-10-29,"Kazuki Uematsu, Kosuke Haruki, Taiji Suzuki, Mitsuhiro Kimura, Takahiro Takimoto, Hideyuki Nakagawa",http://arxiv.org/pdf/2410.21656v1,cs.LG
Demand-Aware Beam Hopping and Power Allocation for Load Balancing in Digital Twin empowered LEO Satellite Networks,"Low-Earth orbit (LEO) satellites utilizing beam hopping (BH) technology offer
extensive coverage, low latency, high bandwidth, and significant flexibility.
However, the uneven geographical distribution and temporal variability of
ground traffic demands, combined with the high mobility of LEO satellites,
present significant challenges for efficient beam resource utilization.
Traditional BH methods based on GEO satellites fail to address issues such as
satellite interference, overlapping coverage, and mobility. This paper explores
a Digital Twin (DT)-based collaborative resource allocation network for
multiple LEO satellites with overlapping coverage areas. A two-tier
optimization problem, focusing on load balancing and cell service fairness, is
proposed to maximize throughput and minimize inter-cell service delay. The DT
layer optimizes the allocation of overlapping coverage cells by designing BH
patterns for each satellite, while the LEO layer optimizes power allocation for
each selected service cell. At the DT layer, an Actor-Critic network is
deployed on each agent, with a global critic network in the cloud center. The
A3C algorithm is employed to optimize the DT layer. Concurrently, the LEO layer
optimization is performed using a Multi-Agent Reinforcement Learning algorithm,
where each beam functions as an independent agent. The simulation results show
that this method reduces satellite load disparity by about 72.5% and decreases
the average delay to 12ms. Additionally, our approach outperforms other
benchmarks in terms of throughput, ensuring a better alignment between offered
and requested data.",2024-10-29,"Ruili Zhao, Jun Cai, Jiangtao Luo, Junpeng Gao, Yongyi Ran",http://arxiv.org/pdf/2411.08896v1,cs.LG
Analytic Continual Test-Time Adaptation for Multi-Modality Corruption,"Test-Time Adaptation (TTA) aims to help pre-trained model bridge the gap
between source and target datasets using only the pre-trained model and
unlabelled test data. A key objective of TTA is to address domain shifts in
test data caused by corruption, such as weather changes, noise, or sensor
malfunctions. Multi-Modal Continual Test-Time Adaptation (MM-CTTA), an
extension of TTA with better real-world applications, further allows
pre-trained models to handle multi-modal inputs and adapt to
continuously-changing target domains. MM-CTTA typically faces challenges
including error accumulation, catastrophic forgetting, and reliability bias,
with few existing approaches effectively addressing these issues in multi-modal
corruption scenarios. In this paper, we propose a novel approach,
Multi-modality Dynamic Analytic Adapter (MDAA), for MM-CTTA tasks. We
innovatively introduce analytic learning into TTA, using the Analytic
Classifiers (ACs) to prevent model forgetting. Additionally, we develop Dynamic
Selection Mechanism (DSM) and Soft Pseudo-label Strategy (SPS), which enable
MDAA to dynamically filter reliable samples and integrate information from
different modalities. Extensive experiments demonstrate that MDAA achieves
state-of-the-art performance on MM-CTTA tasks while ensuring reliable model
adaptation.",2024-10-29,"Yufei Zhang, Yicheng Xu, Hongxin Wei, Zhiping Lin, Huiping Zhuang",http://arxiv.org/pdf/2410.22373v1,cs.LG
Mitigating Paraphrase Attacks on Machine-Text Detectors via Paraphrase Inversion,"High-quality paraphrases are easy to produce using instruction-tuned language
models or specialized paraphrasing models. Although this capability has a
variety of benign applications, paraphrasing
attacks$\unicode{x2013}$paraphrases applied to machine-generated
texts$\unicode{x2013}$are known to significantly degrade the performance of
machine-text detectors. This motivates us to consider the novel problem of
paraphrase inversion, where, given paraphrased text, the objective is to
recover an approximation of the original text. The closer the approximation is
to the original text, the better machine-text detectors will perform. We
propose an approach which frames the problem as translation from paraphrased
text back to the original text, which requires examples of texts and
corresponding paraphrases to train the inversion model. Fortunately, such
training data can easily be generated, given a corpus of original texts and one
or more paraphrasing models. We find that language models such as GPT-4 and
Llama-3 exhibit biases when paraphrasing which an inversion model can learn
with a modest amount of data. Perhaps surprisingly, we also find that such
models generalize well, including to paraphrase models unseen at training time.
Finally, we show that when combined with a paraphrased-text detector, our
inversion models provide an effective defense against paraphrasing attacks, and
overall our approach yields an average improvement of +22% AUROC across seven
machine-text detectors and three different domains.",2024-10-29,"Rafael Rivera Soto, Barry Chen, Nicholas Andrews",http://arxiv.org/pdf/2410.21637v3,cs.LG
Learning the structure of any Hamiltonian from minimal assumptions,"We study the problem of learning an unknown quantum many-body Hamiltonian $H$
from black-box queries to its time evolution $e^{-\mathrm{i} H t}$. Prior
proposals for solving this task either impose some assumptions on $H$, such as
its interaction structure or locality, or otherwise use an exponential amount
of computational postprocessing. In this paper, we present algorithms to learn
any $n$-qubit Hamiltonian, which do not need to know the Hamiltonian terms in
advance, nor are they restricted to local interactions. Our algorithms are
efficient as long as the number of terms $m$ is polynomially bounded in the
system size $n$. We consider two models of control over the time evolution:~the
first has access to time reversal ($t < 0$), enabling an algorithm that outputs
an $\epsilon$-accurate classical description of $H$ after querying its dynamics
for a total of $\widetilde{\mathcal{O}}(m/\epsilon)$ evolution time. The second
access model is more conventional, allowing only forward-time evolutions;~our
algorithm requires $\widetilde{\mathcal{O}}(\|H\|^3/\epsilon^4)$ evolution time
in this setting. Central to our results is the recently introduced concept of a
pseudo-Choi state of $H$. We extend the utility of this learning resource by
showing how to use it to learn the Fourier spectrum of $H$, how to achieve
nearly Heisenberg-limited scaling with it, and how to prepare it even under our
more restricted access models.",2024-10-29,Andrew Zhao,http://arxiv.org/pdf/2410.21635v2,cs.LG
Faster Local Solvers for Graph Diffusion Equations,"Efficient computation of graph diffusion equations (GDEs), such as
Personalized PageRank, Katz centrality, and the Heat kernel, is crucial for
clustering, training neural networks, and many other graph-related problems.
Standard iterative methods require accessing the whole graph per iteration,
making them time-consuming for large-scale graphs. While existing local solvers
approximate diffusion vectors through heuristic local updates, they often
operate sequentially and are typically designed for specific diffusion types,
limiting their applicability. Given that diffusion vectors are highly
localizable, as measured by the participation ratio, this paper introduces a
novel framework for approximately solving GDEs using a local diffusion process.
This framework reveals the suboptimality of existing local solvers.
Furthermore, our approach effectively localizes standard iterative solvers by
designing simple and provably sublinear time algorithms. These new local
solvers are highly parallelizable, making them well-suited for implementation
on GPUs. We demonstrate the effectiveness of our framework in quickly obtaining
approximate diffusion vectors, achieving up to a hundred-fold speed
improvement, and its applicability to large-scale dynamic graphs. Our framework
could also facilitate more efficient local message-passing mechanisms for GNNs.",2024-10-29,"Jiahe Bai, Baojian Zhou, Deqing Yang, Yanghua Xiao",http://arxiv.org/pdf/2410.21634v2,cs.LG
A Hierarchical Language Model For Interpretable Graph Reasoning,"Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.",2024-10-29,"Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji",http://arxiv.org/pdf/2410.22372v1,cs.LG
Refined Risk Bounds for Unbounded Losses via Transductive Priors,"We revisit the sequential variants of linear regression with the squared
loss, classification problems with hinge loss, and logistic regression, all
characterized by unbounded losses in the setup where no assumptions are made on
the magnitude of design vectors and the norm of the optimal vector of
parameters. The key distinction from existing results lies in our assumption
that the set of design vectors is known in advance (though their order is not),
a setup sometimes referred to as transductive online learning. While this
assumption seems similar to fixed design regression or denoising, we
demonstrate that the sequential nature of our algorithms allows us to convert
our bounds into statistical ones with random design without making any
additional assumptions about the distribution of the design vectors--an
impossibility for standard denoising results. Our key tools are based on the
exponential weights algorithm with carefully chosen transductive
(design-dependent) priors, which exploit the full horizon of the design
vectors.
  Our classification regret bounds have a feature that is only attributed to
bounded losses in the literature: they depend solely on the dimension of the
parameter space and on the number of rounds, independent of the design vectors
or the norm of the optimal solution. For linear regression with squared loss,
we further extend our analysis to the sparse case, providing sparsity regret
bounds that additionally depend on the magnitude of the response variables. We
argue that these improved bounds are specific to the transductive setting and
unattainable in the worst-case sequential setup. Our algorithms, in several
cases, have polynomial time approximations and reduce to sampling with respect
to log-concave measures instead of aggregating over hard-to-construct
$\varepsilon$-covers of classes.",2024-10-29,"Jian Qian, Alexander Rakhlin, Nikita Zhivotovskiy",http://arxiv.org/pdf/2410.21621v2,cs.LG
Graph Sparsification for Enhanced Conformal Prediction in Graph Neural Networks,"Conformal Prediction is a robust framework that ensures reliable coverage
across machine learning tasks. Although recent studies have applied conformal
prediction to graph neural networks, they have largely emphasized post-hoc
prediction set generation. Improving conformal prediction during the training
stage remains unaddressed. In this work, we tackle this challenge from a
denoising perspective by introducing SparGCP, which incorporates graph
sparsification and a conformal prediction-specific objective into GNN training.
SparGCP employs a parameterized graph sparsification module to filter out
task-irrelevant edges, thereby improving conformal prediction efficiency.
Extensive experiments on real-world graph datasets demonstrate that SparGCP
outperforms existing methods, reducing prediction set sizes by an average of
32\% and scaling seamlessly to large networks on commodity GPUs.",2024-10-28,"Yuntian He, Pranav Maneriker, Anutam Srinivasan, Aditya T. Vadlamani, Srinivasan Parthasarathy",http://arxiv.org/pdf/2410.21618v1,cs.LG
Identifying Selections for Unsupervised Subtask Discovery,"When solving long-horizon tasks, it is intriguing to decompose the high-level
task into subtasks. Decomposing experiences into reusable subtasks can improve
data efficiency, accelerate policy generalization, and in general provide
promising solutions to multi-task reinforcement learning and imitation learning
problems. However, the concept of subtasks is not sufficiently understood and
modeled yet, and existing works often overlook the true structure of the data
generation process: subtasks are the results of a $\textit{selection}$
mechanism on actions, rather than possible underlying confounders or
intermediates. Specifically, we provide a theory to identify, and experiments
to verify the existence of selection variables in such data. These selections
serve as subgoals that indicate subtasks and guide policy. In light of this
idea, we develop a sequential non-negative matrix factorization (seq- NMF)
method to learn these subgoals and extract meaningful behavior patterns as
subtasks. Our empirical results on a challenging Kitchen environment
demonstrate that the learned subtasks effectively enhance the generalization to
new tasks in multi-task imitation learning scenarios. The codes are provided at
https://anonymous.4open.science/r/Identifying\_Selections\_for\_Unsupervised\_Subtask\_Discovery/README.md.",2024-10-28,"Yiwen Qiu, Yujia Zheng, Kun Zhang",http://arxiv.org/pdf/2410.21616v1,cs.LG
CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation,"We present the results of the ""Fast Calorimeter Simulation Challenge 2022"" -
the CaloChallenge. We study state-of-the-art generative models on four
calorimeter shower datasets of increasing dimensionality, ranging from a few
hundred voxels to a few tens of thousand voxels. The 31 individual submissions
span a wide range of current popular generative architectures, including
Variational AutoEncoders (VAEs), Generative Adversarial Networks (GANs),
Normalizing Flows, Diffusion models, and models based on Conditional Flow
Matching. We compare all submissions in terms of quality of generated
calorimeter showers, as well as shower generation time and model size. To
assess the quality we use a broad range of different metrics including
differences in 1-dimensional histograms of observables, KPD/FPD scores, AUCs of
binary classifiers, and the log-posterior of a multiclass classifier. The
results of the CaloChallenge provide the most complete and comprehensive survey
of cutting-edge approaches to calorimeter fast simulation to date. In addition,
our work provides a uniquely detailed perspective on the important problem of
how to evaluate generative models. As such, the results presented here should
be applicable for other domains that use generative AI and require fast and
faithful generation of samples in a large phase space.",2024-10-28,"Claudius Krause, Michele Faucci Giannelli, Gregor Kasieczka, Benjamin Nachman, Dalila Salamani, David Shih, Anna Zaborowska, Oz Amram, Kerstin Borras, Matthew R. Buckley, Erik Buhmann, Thorsten Buss, Renato Paulo Da Costa Cardoso, Anthony L. Caterini, Nadezda Chernyavskaya, Federico A. G. Corchia, Jesse C. Cresswell, Sascha Diefenbacher, Etienne Dreyer, Vijay Ekambaram, Engin Eren, Florian Ernst, Luigi Favaro, Matteo Franchini, Frank Gaede, Eilam Gross, Shih-Chieh Hsu, Kristina Jaruskova, Benno Käch, Jayant Kalagnanam, Raghav Kansal, Taewoo Kim, Dmitrii Kobylianskii, Anatolii Korol, William Korcari, Dirk Krücker, Katja Krüger, Marco Letizia, Shu Li, Qibin Liu, Xiulong Liu, Gabriel Loaiza-Ganem, Thandikire Madula, Peter McKeown, Isabell-A. Melzer-Pellmann, Vinicius Mikuni, Nam Nguyen, Ayodele Ore, Sofia Palacios Schweitzer, Ian Pang, Kevin Pedro, Tilman Plehn, Witold Pokorski, Huilin Qu, Piyush Raikwar, John A. Raine, Humberto Reyes-Gonzalez, Lorenzo Rinaldi, Brendan Leigh Ross, Moritz A. W. Scham, Simon Schnake, Chase Shimmin, Eli Shlizerman, Nathalie Soybelman, Mudhakar Srivatsa, Kalliopi Tsolaki, Sofia Vallecorsa, Kyongmin Yeo, Rui Zhang",http://arxiv.org/pdf/2410.21611v1,cs.LG
Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs,"Stochastic differential equations are commonly used to describe the evolution
of stochastic processes. The state uncertainty of such processes is best
represented by the probability density function (PDF), whose evolution is
governed by the Fokker-Planck partial differential equation (FP-PDE). However,
it is generally infeasible to solve the FP-PDE in closed form. In this work, we
show that physics-informed neural networks (PINNs) can be trained to
approximate the solution PDF. Our main contribution is the analysis of PINN
approximation error: we develop a theoretical framework to construct tight
error bounds using PINNs. In addition, we derive a practical error bound that
can be efficiently constructed with standard training methods. We discuss that
this error-bound framework generalizes to approximate solutions of other linear
PDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems
validate the correctness of our error bounds while demonstrating the
scalability of PINNs and their significant computational speedup in obtaining
accurate PDF solutions compared to the Monte Carlo approach.",2024-10-28,"Chun-Wei Kong, Luca Laurenti, Jay McMahon, Morteza Lahijanian",http://arxiv.org/pdf/2410.22371v2,cs.LG
A Generative Diffusion Model to Solve Inverse Problems for Robust in-NICU Neonatal MRI,"We present the first acquisition-agnostic diffusion generative model for
Magnetic Resonance Imaging (MRI) in the neonatal intensive care unit (NICU) to
solve a range of inverse problems for shortening scan time and improving motion
robustness. In-NICU MRI scanners leverage permanent magnets at lower
field-strengths (i.e., below 1.5 Tesla) for non-invasive assessment of
potential brain abnormalities during the critical phase of early live
development, but suffer from long scan times and motion artifacts. In this
setting, training data sizes are small and intrinsically suffer from low
signal-to-noise ratio (SNR). This work trains a diffusion probabilistic
generative model using such a real-world training dataset of clinical neonatal
MRI by applying several novel signal processing and machine learning methods to
handle the low SNR and low quantity of data. The model is then used as a
statistical image prior to solve various inverse problems at inference time
without requiring any retraining. Experiments demonstrate the generative
model's utility for three real-world applications of neonatal MRI: accelerated
reconstruction, motion correction, and super-resolution.",2024-10-28,"Yamin Arefeen, Brett Levac, Jonathan I. Tamir",http://arxiv.org/pdf/2410.21602v2,cs.LG
The Limits of Transfer Reinforcement Learning with Latent Low-rank Structure,"Many reinforcement learning (RL) algorithms are too costly to use in practice
due to the large sizes $S, A$ of the problem's state and action space. To
resolve this issue, we study transfer RL with latent low rank structure. We
consider the problem of transferring a latent low rank representation when the
source and target MDPs have transition kernels with Tucker rank $(S , d, A )$,
$(S , S , d), (d, S, A )$, or $(d , d , d )$. In each setting, we introduce the
transfer-ability coefficient $\alpha$ that measures the difficulty of
representational transfer. Our algorithm learns latent representations in each
source MDP and then exploits the linear structure to remove the dependence on
$S, A $, or $S A$ in the target MDP regret bound. We complement our positive
results with information theoretic lower bounds that show our algorithms
(excluding the ($d, d, d$) setting) are minimax-optimal with respect to
$\alpha$.",2024-10-28,"Tyler Sam, Yudong Chen, Christina Lee Yu",http://arxiv.org/pdf/2410.21601v1,cs.LG
Survey of User Interface Design and Interaction Techniques in Generative AI Applications,"The applications of generative AI have become extremely impressive, and the
interplay between users and AI is even more so. Current human-AI interaction
literature has taken a broad look at how humans interact with generative AI,
but it lacks specificity regarding the user interface designs and patterns used
to create these applications. Therefore, we present a survey that
comprehensively presents taxonomies of how a human interacts with AI and the
user interaction patterns designed to meet the needs of a variety of relevant
use cases. We focus primarily on user-guided interactions, surveying
interactions that are initiated by the user and do not include any implicit
signals given by the user. With this survey, we aim to create a compendium of
different user-interaction patterns that can be used as a reference for
designers and developers alike. In doing so, we also strive to lower the entry
barrier for those attempting to learn more about the design of generative AI
applications.",2024-10-28,"Reuben Luera, Ryan A. Rossi, Alexa Siu, Franck Dernoncourt, Tong Yu, Sungchul Kim, Ruiyi Zhang, Xiang Chen, Hanieh Salehy, Jian Zhao, Samyadeep Basu, Puneet Mathur, Nedim Lipka",http://arxiv.org/pdf/2410.22370v1,cs.LG
Reducing the Scope of Language Models,"We now deploy language models in a wide variety of user-facing applications.
Typically, these deployments have some specific purpose, like answering
questions about documentation or acting as coding assistants, but they require
general language understanding. Under these circumstances these models should
not be able to answer irrelevant requests such as, poetry generation or
questions about physics, etc. Instead we would like language models to only
answer to queries corresponding to desired behavior and refuse all other
requests, which we refer to as scoping. We conduct a comprehensive empirical
evaluation of potential methods from prompting to fine-tuning to preference
learning to a recently proposed method for general alignment called Circuit
Breakers (CB). Across three families of language models and a broad variety of
tasks, we show that it is possible to scope language models. We examine scoping
for multiple topics, and fine-grained topics. We ablate diversity of irrelevant
queries, layer different techniques, conduct adversarial evaluations and more.
Among other results, we find that, when diverse examples of irrelevant queries
are available, simple supervised fine-tuning produces the best results, but
when such diversity is low, Circuit Breakers perform quite well. One can often
get the benefits of both methods by layering them in succession. We intend our
study to serve as a practitioner's guide to scoping language models.",2024-10-28,"David Yunis, Siyu Huo, Chulaka Gunasekara, Danish Contractor",http://arxiv.org/pdf/2410.21597v2,cs.LG
"Deep Trees for (Un)structured Data: Tractability, Performance, and Interpretability","Decision Trees have remained a popular machine learning method for tabular
datasets, mainly due to their interpretability. However, they lack the
expressiveness needed to handle highly nonlinear or unstructured datasets.
Motivated by recent advances in tree-based machine learning (ML) techniques and
first-order optimization methods, we introduce Generalized Soft Trees (GSTs),
which extend soft decision trees (STs) and are capable of processing images
directly. We demonstrate their advantages with respect to tractability,
performance, and interpretability. We develop a tractable approach to growing
GSTs, given by the DeepTree algorithm, which, in addition to new regularization
terms, produces high-quality models with far fewer nodes and greater
interpretability than traditional soft trees. We test the performance of our
GSTs on benchmark tabular and image datasets, including MIMIC-IV, MNIST,
Fashion MNIST, CIFAR-10 and Celeb-A. We show that our approach outperforms
other popular tree methods (CART, Random Forests, XGBoost) in almost all of the
datasets, with Convolutional Trees having a significant edge in the hardest
CIFAR-10 and Fashion MNIST datasets. Finally, we explore the interpretability
of our GSTs and find that even the most complex GSTs are considerably more
interpretable than deep neural networks. Overall, our approach of Generalized
Soft Trees provides a tractable method that is high-performing on
(un)structured datasets and preserves interpretability more than traditional
deep learning methods.",2024-10-28,"Dimitris Bertsimas, Lisa Everest, Jiayi Gu, Matthew Peroni, Vasiliki Stoumpou",http://arxiv.org/pdf/2410.21595v1,cs.LG
ATLAS: Adapting Trajectory Lengths and Step-Size for Hamiltonian Monte Carlo,"Hamiltonian Monte-Carlo (HMC) and its auto-tuned variant, the No U-Turn
Sampler (NUTS) can struggle to accurately sample distributions with complex
geometries, e.g., varying curvature, due to their constant step size for
leapfrog integration and fixed mass matrix. In this work, we develop a strategy
to locally adapt the step size parameter of HMC at every iteration by
evaluating a low-rank approximation of the local Hessian and estimating its
largest eigenvalue. We combine it with a strategy to similarly adapt the
trajectory length by monitoring the no U-turn condition, resulting in an
adaptive sampler, ATLAS: adapting trajectory length and step-size. We further
use a delayed rejection framework for making multiple proposals that improves
the computational efficiency of ATLAS, and develop an approach for
automatically tuning its hyperparameters during warmup. We compare ATLAS with
state-of-the-art samplers like NUTS on a suite of synthetic and real world
examples, and show that i) unlike NUTS, ATLAS is able to accurately sample
difficult distributions with complex geometries, ii) it is computationally
competitive to NUTS for simpler distributions, and iii) it is more robust to
the tuning of hyperparamters.",2024-10-28,Chirag Modi,http://arxiv.org/pdf/2410.21587v1,cs.LG
Mitigating Gradient Overlap in Deep Residual Networks with Gradient Normalization for Improved Non-Convex Optimization,"In deep learning, Residual Networks (ResNets) have proven effective in
addressing the vanishing gradient problem, allowing for the successful training
of very deep networks. However, skip connections in ResNets can lead to
gradient overlap, where gradients from both the learned transformation and the
skip connection combine, potentially resulting in overestimated gradients. This
overestimation can cause inefficiencies in optimization, as some updates may
overshoot optimal regions, affecting weight updates. To address this, we
examine Z-score Normalization (ZNorm) as a technique to manage gradient
overlap. ZNorm adjusts the gradient scale, standardizing gradients across
layers and reducing the negative impact of overlapping gradients. Our
experiments demonstrate that ZNorm improves training process, especially in
non-convex optimization scenarios common in deep learning, where finding
optimal solutions is challenging. These findings suggest that ZNorm can affect
the gradient flow, enhancing performance in large-scale data processing where
accuracy is critical.",2024-10-28,Juyoung Yun,http://arxiv.org/pdf/2410.21564v3,cs.LG
Audio Classification of Low Feature Spectrograms Utilizing Convolutional Neural Networks,"Modern day audio signal classification techniques lack the ability to
classify low feature audio signals in the form of spectrographic temporal
frequency data representations. Additionally, currently utilized techniques
rely on full diverse data sets that are often not representative of real-world
distributions. This paper derives several first-of-its-kind machine learning
methodologies to analyze these low feature audio spectrograms given data
distributions that may have normalized, skewed, or even limited training sets.
In particular, this paper proposes several novel customized convolutional
architectures to extract identifying features using binary, one-class, and
siamese approaches to identify the spectrographic signature of a given audio
signal. Utilizing these novel convolutional architectures as well as the
proposed classification methods, these experiments demonstrate state-of-the-art
classification accuracy and improved efficiency than traditional audio
classification methods.",2024-10-28,Noel Elias,http://arxiv.org/pdf/2410.21561v1,cs.LG
A Novel Score-CAM based Denoiser for Spectrographic Signature Extraction without Ground Truth,"Sonar based audio classification techniques are a growing area of research in
the field of underwater acoustics. Usually, underwater noise picked up by
passive sonar transducers contains all types of signals that travel through the
ocean and is transformed into spectrographic images. As a result, the
corresponding spectrograms intended to display the temporal-frequency data of a
certain object often include the tonal regions of abundant extraneous noise
that can effectively interfere with a 'contact'. So, a majority of
spectrographic samples extracted from underwater audio signals are rendered
unusable due to their clutter and lack the required indistinguishability
between different objects. With limited clean true data for supervised
training, creating classification models for these audio signals is severely
bottlenecked.
  This paper derives several new techniques to combat this problem by
developing a novel Score-CAM based denoiser to extract an object's signature
from noisy spectrographic data without being given any ground truth data. In
particular, this paper proposes a novel generative adversarial network
architecture for learning and producing spectrographic training data in similar
distributions to low-feature spectrogram inputs. In addition, this paper also a
generalizable class activation mapping based denoiser for different
distributions of acoustic data, even real-world data distributions. Utilizing
these novel architectures and proposed denoising techniques, these experiments
demonstrate state-of-the-art noise reduction accuracy and improved
classification accuracy than current audio classification standards. As such,
this approach has applications not only to audio data but for countless data
distributions used all around the world for machine learning.",2024-10-28,Noel Elias,http://arxiv.org/pdf/2410.21557v2,cs.LG
Super-resolution in disordered media using neural networks,"We propose a methodology that exploits large and diverse data sets to
accurately estimate the ambient medium's Green's functions in strongly
scattering media. Given these estimates, obtained with and without the use of
neural networks, excellent imaging results are achieved, with a resolution that
is better than that of a homogeneous medium. This phenomenon, also known as
super-resolution, occurs because the ambient scattering medium effectively
enhances the physical imaging aperture. This work has been submitted to the
IEEE for possible publication. Copyright may be transferred without notice,
after which this version may no longer be accessible.",2024-10-28,"Alexander Christie, Matan Leibovich, Miguel Moscoso, Alexei Novikov, George Papanicolaou, Chrysoula Tsogka",http://arxiv.org/pdf/2410.21556v4,cs.LG
Exploring the Design Space of Diffusion Bridge Models via Stochasticity Control,"Diffusion bridge models effectively facilitate image-to-image (I2I)
translation by connecting two distributions. However, existing methods overlook
the impact of noise in sampling SDEs, transition kernel, and the base
distribution on sampling efficiency, image quality and diversity. To address
this gap, we propose the Stochasticity-controlled Diffusion Bridge (SDB), a
novel theoretical framework that extends the design space of diffusion bridges,
and provides strategies to mitigate singularities during both training and
sampling. By controlling stochasticity in the sampling SDEs, our sampler
achieves speeds up to 5 times faster than the baseline, while also producing
lower FID scores. After training, SDB sets new benchmarks in image quality and
sampling efficiency via managing stochasticity within the transition kernel.
Furthermore, introducing stochasticity into the base distribution significantly
improves image diversity, as quantified by a newly introduced metric.",2024-10-28,"Shaorong Zhang, Yuanbin Cheng, Xianghao Kong, Greg Ver Steeg",http://arxiv.org/pdf/2410.21553v1,cs.LG
MultiTok: Variable-Length Tokenization for Efficient LLMs Adapted from LZW Compression,"Large language models have drastically changed the prospects of AI by
introducing technologies for more complex natural language processing. However,
current methodologies to train such LLMs require extensive resources including
but not limited to large amounts of data, expensive machinery, and lengthy
training. To solve this problem, this paper proposes a new tokenization method
inspired by universal Lempel-Ziv-Welch data compression that compresses
repetitive phrases into multi-word tokens. With MultiTok as a new tokenizing
tool, we show that language models are able to be trained notably more
efficiently while offering a similar accuracy on more succinct and compressed
training data. In fact, our results demonstrate that MultiTok achieves a
comparable performance to the BERT and GPT-2 standards as both a stand-alone
tokenizer and an add-on to existing tokenizers while also providing close to
2.5x faster training with more than 30% less training data.",2024-10-28,"Noel Elias, Homa Esfahanizadeh, Kaan Kale, Sriram Vishwanath, Muriel Medard",http://arxiv.org/pdf/2410.21548v2,cs.LG
Personalized Federated Learning with Mixture of Models for Adaptive Prediction and Model Fine-Tuning,"Federated learning is renowned for its efficacy in distributed model
training, ensuring that users, called clients, retain data privacy by not
disclosing their data to the central server that orchestrates collaborations.
Most previous work on federated learning assumes that clients possess static
batches of training data. However, clients may also need to make real-time
predictions on streaming data in non-stationary environments. In such dynamic
environments, employing pre-trained models may be inefficient, as they struggle
to adapt to the constantly evolving data streams. To address this challenge,
clients can fine-tune models online, leveraging their observed data to enhance
performance. Despite the potential benefits of client participation in
federated online model fine-tuning, existing analyses have not conclusively
demonstrated its superiority over local model fine-tuning. To bridge this gap,
the present paper develops a novel personalized federated learning algorithm,
wherein each client constructs a personalized model by combining a locally
fine-tuned model with multiple federated models learned by the server over
time. Theoretical analysis and experiments on real datasets corroborate the
effectiveness of this approach for real-time predictions and federated model
fine-tuning.",2024-10-28,"Pouya M. Ghari, Yanning Shen",http://arxiv.org/pdf/2410.21547v1,cs.LG
Bayesian Regression for Predicting Subscription to Bank Term Deposits in Direct Marketing Campaigns,"In the highly competitive environment of the banking industry, it is
essential to precisely forecast the behavior of customers in order to maximize
the effectiveness of marketing initiatives and improve financial consequences.
The purpose of this research is to examine the efficacy of logit and probit
models in predicting term deposit subscriptions using a Portuguese bank's
direct marketing data. There are several demographic, economic, and behavioral
characteristics in the dataset that affect the probability of subscribing. To
increase model performance and provide an unbiased evaluation, the target
variable was balanced, considering the inherent imbalance in the dataset. The
two model's prediction abilities were evaluated using Bayesian techniques and
Leave-One-Out Cross-Validation (LOO-CV). The logit model performed better than
the probit model in handling this classification problem. The results highlight
the relevance of model selection when dealing with complicated decision-making
processes in the financial services industry and imbalanced datasets. Findings
from this study shed light on how banks can optimize their decision-making
processes, improve their client segmentation, and boost their marketing
campaigns by utilizing machine learning models.",2024-10-28,"Muhammad Farhan Tanvir, Md Maruf Hossain, Md Asifuzzaman Jishan",http://arxiv.org/pdf/2410.21539v1,cs.LG
L3Ms -- Lagrange Large Language Models,"Supervised fine-tuning (SFT) and alignment of large language models (LLMs)
are key steps in providing a good user experience. However, the concept of an
appropriate alignment is inherently application-dependent, and current methods
often rely on heuristic choices to drive optimization. In this work, we
formulate SFT and alignment as a constrained optimization problem: the LLM is
fine-tuned on a task while being required to meet application-specific
requirements, without resorting to heuristics. To solve this, we propose
Lagrange Large Language Models (L3Ms), which employ logarithmic barriers to
enforce the constraints. This approach allows for the customization of L3Ms
across diverse applications while avoiding heuristic-driven processes. We
experimentally demonstrate the versatility and efficacy of L3Ms in achieving
tailored alignments for various applications.",2024-10-28,"Guneet S. Dhillon, Xingjian Shi, Yee Whye Teh, Alex Smola",http://arxiv.org/pdf/2410.21533v3,cs.LG
Deep Learning Methods for the Noniterative Conditional Expectation G-Formula for Causal Inference from Complex Observational Data,"The g-formula can be used to estimate causal effects of sustained treatment
strategies using observational data under the identifying assumptions of
consistency, positivity, and exchangeability. The non-iterative conditional
expectation (NICE) estimator of the g-formula also requires correct estimation
of the conditional distribution of the time-varying treatment, confounders, and
outcome. Parametric models, which have been traditionally used for this
purpose, are subject to model misspecification, which may result in biased
causal estimates. Here, we propose a unified deep learning framework for the
NICE g-formula estimator that uses multitask recurrent neural networks for
estimation of the joint conditional distributions. Using simulated data, we
evaluated our model's bias and compared it with that of the parametric
g-formula estimator. We found lower bias in the estimates of the causal effect
of sustained treatment strategies on a survival outcome when using the deep
learning estimator compared with the parametric NICE estimator in settings with
simple and complex temporal dependencies between covariates. These findings
suggest that our Deep Learning g-formula estimator may be less sensitive to
model misspecification than the classical parametric NICE estimator when
estimating the causal effect of sustained treatment strategies from complex
observational data.",2024-10-28,"Sophia M Rein, Jing Li, Miguel Hernan, Andrew Beam",http://arxiv.org/pdf/2410.21531v1,cs.LG
Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification,"Synthetic data augmentation via large language models (LLMs) allows
researchers to leverage additional training data, thus enhancing the
performance of downstream tasks, especially when real-world data is scarce.
However, the generated data can deviate from the real-world data, and this
misalignment can bring deficient outcomes while applying the trained model to
applications. Therefore, we proposed efficient weighted-loss approaches to
align synthetic data with real-world distribution by emphasizing high-quality
and diversified data generated by LLMs with using merely a little real-world
data. We empirically assessed the effectiveness of our method on multiple text
classification tasks, and the results showed leveraging our approaches on a
BERT-level model robustly outperformed standard cross-entropy and other data
weighting approaches, providing potential solutions to effectively leveraging
synthetic data from any suitable data generator for model training.",2024-10-28,"Hsun-Yu Kuo, Yin-Hsiang Liao, Yu-Chieh Chao, Wei-Yun Ma, Pu-Jen Cheng",http://arxiv.org/pdf/2410.21526v2,cs.LG
Diffusion-nested Auto-Regressive Synthesis of Heterogeneous Tabular Data,"Autoregressive models are predominant in natural language generation, while
their application in tabular data remains underexplored. We posit that this can
be attributed to two factors: 1) tabular data contains heterogeneous data type,
while the autoregressive model is primarily designed to model discrete-valued
data; 2) tabular data is column permutation-invariant, requiring a generation
model to generate columns in arbitrary order. This paper proposes a
Diffusion-nested Autoregressive model (TabDAR) to address these issues. To
enable autoregressive methods for continuous columns, TabDAR employs a
diffusion model to parameterize the conditional distribution of continuous
features. To ensure arbitrary generation order, TabDAR resorts to masked
transformers with bi-directional attention, which simulate various permutations
of column order, hence enabling it to learn the conditional distribution of a
target column given an arbitrary combination of other columns. These designs
enable TabDAR to not only freely handle heterogeneous tabular data but also
support convenient and flexible unconditional/conditional sampling. We conduct
extensive experiments on ten datasets with distinct properties, and the
proposed TabDAR outperforms previous state-of-the-art methods by 18% to 45% on
eight metrics across three distinct aspects.",2024-10-28,"Hengrui Zhang, Liancheng Fang, Qitian Wu, Philip S. Yu",http://arxiv.org/pdf/2410.21523v1,cs.LG
A Multi-Agent Reinforcement Learning Testbed for Cognitive Radio Applications,"Technological trends show that Radio Frequency Reinforcement Learning (RFRL)
will play a prominent role in the wireless communication systems of the future.
Applications of RFRL range from military communications jamming to enhancing
WiFi networks. Before deploying algorithms for these purposes, they must be
trained in a simulation environment to ensure adequate performance. For this
reason, we previously created the RFRL Gym: a standardized, accessible tool for
the development and testing of reinforcement learning (RL) algorithms in the
wireless communications space. This environment leveraged the OpenAI Gym
framework and featured customizable simulation scenarios within the RF
spectrum. However, the RFRL Gym was limited to training a single RL agent per
simulation; this is not ideal, as most real-world RF scenarios will contain
multiple intelligent agents in cooperative, competitive, or mixed settings,
which is a natural consequence of spectrum congestion. Therefore, through
integration with Ray RLlib, multi-agent reinforcement learning (MARL)
functionality for training and assessment has been added to the RFRL Gym,
making it even more of a robust tool for RF spectrum simulation. This paper
provides an overview of the updated RFRL Gym environment. In this work, the
general framework of the tool is described relative to comparable existing
resources, highlighting the significant additions and refactoring we have
applied to the Gym. Afterward, results from testing various RF scenarios in the
MARL environment and future additions are discussed.",2024-10-28,"Sriniketh Vangaru, Daniel Rosen, Dylan Green, Raphael Rodriguez, Maxwell Wiecek, Amos Johnson, Alyse M. Jones, William C. Headley",http://arxiv.org/pdf/2410.21521v2,cs.LG
MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language,"Large language models applied to vast biological datasets have the potential
to transform biology by uncovering disease mechanisms and accelerating drug
development. However, current models are often siloed, trained separately on
small-molecules, proteins, or transcriptomic data, limiting their ability to
capture complex, multi-modal interactions. Effective drug discovery requires
computational tools that integrate multiple biological entities while
supporting prediction and generation, a challenge existing models struggle to
address. For this purpose, we present MAMMAL - Molecular Aligned Multi-Modal
Architecture and Language - a versatile method applied to create a multi-task
foundation model that learns from large-scale biological datasets across
diverse modalities, including proteins, small-molecules, and omics. MAMMAL's
structured prompt syntax supports classification, regression, and generation
tasks while handling token and scalar inputs and outputs. Evaluated on eleven
diverse downstream tasks, it reaches a new state of the art (SOTA) in nine
tasks and is comparable to SOTA in two tasks, all within a unified
architecture, unlike prior task-specific models. Additionally, we explored
Alphafold 3 binding prediction capabilities on antibody-antigen and
nanobody-antigen complexes showing significantly better classification
performance of MAMMAL in 3 out of 4 targets. The model code and pretrained
weights are publicly available at
https://github.com/BiomedSciAI/biomed-multi-alignment and
https://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m",2024-10-28,"Yoel Shoshan, Moshiko Raboh, Michal Ozery-Flato, Vadim Ratner, Alex Golts, Jeffrey K. Weber, Ella Barkan, Simona Rabinovici-Cohen, Sagi Polaczek, Ido Amos, Ben Shapira, Liam Hazan, Matan Ninio, Sivan Ravid, Michael M. Danziger, Yosi Shamay, Sharon Kurant, Joseph A. Morrone, Parthasarathy Suryanarayanan, Michal Rosen-Zvi, Efrat Hexter",http://arxiv.org/pdf/2410.22367v3,cs.LG
LLM-Forest: Ensemble Learning of LLMs with Graph-Augmented Prompts for Data Imputation,"Missing data imputation is a critical challenge in various domains, such as
healthcare and finance, where data completeness is vital for accurate analysis.
Large language models (LLMs), trained on vast corpora, have shown strong
potential in data generation, making them a promising tool for data imputation.
However, challenges persist in designing effective prompts for a
finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a ""forest"" of few-shot learning LLM ""trees"" with confidence-based
weighted voting, inspired by ensemble learning (Random Forest). This framework
is established on a new concept of bipartite information graphs to identify
high-quality relevant neighboring entries with both feature and value
granularity. Extensive experiments on 9 real-world datasets demonstrate the
effectiveness and efficiency of LLM-Forest.",2024-10-28,"Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He",http://arxiv.org/pdf/2410.21520v3,cs.LG
Predicting sub-population specific viral evolution,"Forecasting the change in the distribution of viral variants is crucial for
therapeutic design and disease surveillance. This task poses significant
modeling challenges due to the sharp differences in virus distributions across
sub-populations (e.g., countries) and their dynamic interactions. Existing
machine learning approaches that model the variant distribution as a whole are
incapable of making location-specific predictions and ignore transmissions that
shape the viral landscape. In this paper, we propose a sub-population specific
protein evolution model, which predicts the time-resolved distributions of
viral proteins in different locations. The algorithm explicitly models the
transmission rates between sub-populations and learns their interdependence
from data. The change in protein distributions across all sub-populations is
defined through a linear ordinary differential equation (ODE) parametrized by
transmission rates. Solving this ODE yields the likelihood of a given protein
occurring in particular sub-populations. Multi-year evaluation on both
SARS-CoV-2 and influenza A/H3N2 demonstrates that our model outperforms
baselines in accurately predicting distributions of viral proteins across
continents and countries. We also find that the transmission rates learned from
data are consistent with the transmission pathways discovered by retrospective
phylogenetic analysis.",2024-10-28,"Wenxian Shi, Menghua Wu, Regina Barzilay",http://arxiv.org/pdf/2410.21518v2,cs.LG
Sabotage Evaluations for Frontier Models,"Sufficiently capable models could subvert human oversight and decision-making
in important contexts. For example, in the context of AI development, models
could covertly sabotage efforts to evaluate their own dangerous capabilities,
to monitor their behavior, or to make decisions about their deployment. We
refer to this family of abilities as sabotage capabilities. We develop a set of
related threat models and evaluations. These evaluations are designed to
provide evidence that a given model, operating under a given set of
mitigations, could not successfully sabotage a frontier model developer or
other large organization's activities in any of these ways. We demonstrate
these evaluations on Anthropic's Claude 3 Opus and Claude 3.5 Sonnet models.
Our results suggest that for these models, minimal mitigations are currently
sufficient to address sabotage risks, but that more realistic evaluations and
stronger mitigations seem likely to be necessary soon as capabilities improve.
We also survey related evaluations we tried and abandoned. Finally, we discuss
the advantages of mitigation-aware capability evaluations, and of simulating
large-scale deployments using small-scale statistics.",2024-10-28,"Joe Benton, Misha Wagner, Eric Christiansen, Cem Anil, Ethan Perez, Jai Srivastav, Esin Durmus, Deep Ganguli, Shauna Kravec, Buck Shlegeris, Jared Kaplan, Holden Karnofsky, Evan Hubinger, Roger Grosse, Samuel R. Bowman, David Duvenaud",http://arxiv.org/pdf/2410.21514v1,cs.LG
Diagnosis of Knee Osteoarthritis Using Bioimpedance and Deep Learning,"Diagnosing knee osteoarthritis (OA) early is crucial for managing symptoms
and preventing further joint damage, ultimately improving patient outcomes and
quality of life. In this paper, a bioimpedance-based diagnostic tool that
combines precise hardware and deep learning for effective non-invasive
diagnosis is proposed. system features a relay-based circuit and strategically
placed electrodes to capture comprehensive bioimpedance data. The data is
processed by a neural network model, which has been optimized using
convolutional layers, dropout regularization, and the Adam optimizer. This
approach achieves a 98% test accuracy, making it a promising tool for detecting
knee osteoarthritis musculoskeletal disorders.",2024-10-28,"Jamal Al-Nabulsi, Mohammad Al-Sayed Ahmad, Baraa Hasaneiah, Fayhaa AlZoubi",http://arxiv.org/pdf/2410.21512v1,cs.LG
ROADFIRST: A Comprehensive Enhancement of the Systemic Approach to Safety for Improved Risk Factor Identification and Evaluation,"Many agencies have adopted the FHWA-recommended systemic approach to traffic
safety, an essential supplement to the traditional hotspot crash analysis which
develops region-wide safety projects based on identified risk factors. However,
this approach narrows analysis to specific crash and facility types. This
specification causes inefficient use of crash and inventory data as well as
non-comprehensive risk evaluation and countermeasure selection for each
location. To improve the comprehensiveness of the systemic approach to safety,
we develop an enhanced process, ROADFIRST, that allows users to identify
potential crash types and contributing factors at any location. As the
knowledge base for such a process, crash types and contributing factors are
analyzed with respect to features of interest, including both dynamic and
static traffic-related features, using Random Forest and analyzed with the
SHapley Additive exPlanations (SHAP) analysis. We identify and rank features
impacting the likelihood of three sample contributing factors, namely
alcohol-impaired driving, distracted driving, and speeding, according to crash
and road inventory data from North Carolina, and quantify state-wide road
segment risk for each contributing factor. The introduced models and methods
serve as a sample for the further development of ROADFIRST by state and local
agencies, which benefits the planning of more comprehensive region-wide safety
improvement projects.",2024-10-28,"Shriyan Reyya, Yao Cheng",http://arxiv.org/pdf/2411.00821v1,cs.LG
Towards Multi-dimensional Explanation Alignment for Medical Classification,"The lack of interpretability in the field of medical image analysis has
significant ethical and legal implications. Existing interpretable methods in
this domain encounter several challenges, including dependency on specific
models, difficulties in understanding and visualization, as well as issues
related to efficiency. To address these limitations, we propose a novel
framework called Med-MICN (Medical Multi-dimensional Interpretable Concept
Network). Med-MICN provides interpretability alignment for various angles,
including neural symbolic reasoning, concept semantics, and saliency maps,
which are superior to current interpretable methods. Its advantages include
high prediction accuracy, interpretability across multiple dimensions, and
automation through an end-to-end concept labeling process that reduces the need
for extensive human training effort when working with new datasets. To
demonstrate the effectiveness and interpretability of Med-MICN, we apply it to
four benchmark datasets and compare it with baselines. The results clearly
demonstrate the superior performance and interpretability of our Med-MICN.",2024-10-28,"Lijie Hu, Songning Lai, Wenshuo Chen, Hongru Xiao, Hongbin Lin, Lu Yu, Jingfeng Zhang, Di Wang",http://arxiv.org/pdf/2410.21494v1,cs.LG
Trustworthiness of Stochastic Gradient Descent in Distributed Learning,"Distributed learning (DL) uses multiple nodes to accelerate training,
enabling efficient optimization of large-scale models. Stochastic Gradient
Descent (SGD), a key optimization algorithm, plays a central role in this
process. However, communication bottlenecks often limit scalability and
efficiency, leading to increasing adoption of compressed SGD techniques to
alleviate these challenges. Despite addressing communication overheads,
compressed SGD introduces trustworthiness concerns, as gradient exchanges among
nodes are vulnerable to attacks like gradient inversion (GradInv) and
membership inference attacks (MIA). The trustworthiness of compressed SGD
remains unexplored, leaving important questions about its reliability
unanswered.
  In this paper, we provide a trustworthiness evaluation of compressed versus
uncompressed SGD. Specifically, we conducted empirical studies using GradInv
attacks, revealing that compressed SGD demonstrates significantly higher
resistance to privacy leakage compared to uncompressed SGD. In addition, our
findings suggest that MIA may not be a reliable metric for assessing privacy
risks in distributed learning.",2024-10-28,"Hongyang Li, Caesar Wu, Mohammed Chadli, Said Mammar, Pascal Bouvry",http://arxiv.org/pdf/2410.21491v3,cs.LG
Enhancing CTR Prediction in Recommendation Domain with Search Query Representation,"Many platforms, such as e-commerce websites, offer both search and
recommendation services simultaneously to better meet users' diverse needs.
Recommendation services suggest items based on user preferences, while search
services allow users to search for items before providing recommendations.
Since users and items are often shared between the search and recommendation
domains, there is a valuable opportunity to enhance the recommendation domain
by leveraging user preferences extracted from the search domain. Existing
approaches either overlook the shift in user intention between these domains or
fail to capture the significant impact of learning from users' search queries
on understanding their interests.
  In this paper, we propose a framework that learns from user search query
embeddings within the context of user preferences in the recommendation domain.
Specifically, user search query sequences from the search domain are used to
predict the items users will click at the next time point in the recommendation
domain. Additionally, the relationship between queries and items is explored
through contrastive learning. To address issues of data sparsity, the diffusion
model is incorporated to infer positive items the user will select after
searching with certain queries in a denoising manner, which is particularly
effective in preventing false positives. Effectively extracting this
information, the queries are integrated into click-through rate prediction in
the recommendation domain. Experimental analysis demonstrates that our model
outperforms state-of-the-art models in the recommendation domain.",2024-10-28,"Yuening Wang, Man Chen, Yaochen Hu, Wei Guo, Yingxue Zhang, Huifeng Guo, Yong Liu, Mark Coates",http://arxiv.org/pdf/2410.21487v1,cs.LG
"A Systematic Review of Machine Learning in Sports Betting: Techniques, Challenges, and Future Directions","The sports betting industry has experienced rapid growth, driven largely by
technological advancements and the proliferation of online platforms. Machine
learning (ML) has played a pivotal role in the transformation of this sector by
enabling more accurate predictions, dynamic odds-setting, and enhanced risk
management for both bookmakers and bettors. This systematic review explores
various ML techniques, including support vector machines, random forests, and
neural networks, as applied in different sports such as soccer, basketball,
tennis, and cricket. These models utilize historical data, in-game statistics,
and real-time information to optimize betting strategies and identify value
bets, ultimately improving profitability. For bookmakers, ML facilitates
dynamic odds adjustment and effective risk management, while bettors leverage
data-driven insights to exploit market inefficiencies. This review also
underscores the role of ML in fraud detection, where anomaly detection models
are used to identify suspicious betting patterns. Despite these advancements,
challenges such as data quality, real-time decision-making, and the inherent
unpredictability of sports outcomes remain. Ethical concerns related to
transparency and fairness are also of significant importance. Future research
should focus on developing adaptive models that integrate multimodal data and
manage risk in a manner akin to financial portfolios. This review provides a
comprehensive examination of the current applications of ML in sports betting,
and highlights both the potential and the limitations of these technologies.",2024-10-28,"René Manassé Galekwa, Jean Marie Tshimula, Etienne Gael Tajeuna, Kyamakya Kyandoghere",http://arxiv.org/pdf/2410.21484v1,cs.LG
A Mathematical Analysis of Neural Operator Behaviors,"Neural operators have emerged as transformative tools for learning mappings
between infinite-dimensional function spaces, offering useful applications in
solving complex partial differential equations (PDEs). This paper presents a
rigorous mathematical framework for analyzing the behaviors of neural
operators, with a focus on their stability, convergence, clustering dynamics,
universality, and generalization error. By proposing a list of novel theorems,
we provide stability bounds in Sobolev spaces and demonstrate clustering in
function space via gradient flow interpretation, guiding neural operator design
and optimization. Based on these theoretical gurantees, we aim to offer clear
and unified guidance in a single setting for the future design of neural
operator-based methods.",2024-10-28,"Vu-Anh Le, Mehmet Dik",http://arxiv.org/pdf/2410.21481v1,cs.LG
AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification,"Trust and interpretability are crucial for the use of Artificial Intelligence
(AI) in scientific research, but current models often operate as black boxes
offering limited transparency and justifications for their outputs. We
introduce AiSciVision, a framework that specializes Large Multimodal Models
(LMMs) into interactive research partners and classification models for image
classification tasks in niche scientific domains. Our framework uses two key
components: (1) Visual Retrieval-Augmented Generation (VisRAG) and (2)
domain-specific tools utilized in an agentic workflow. To classify a target
image, AiSciVision first retrieves the most similar positive and negative
labeled images as context for the LMM. Then the LMM agent actively selects and
applies tools to manipulate and inspect the target image over multiple rounds,
refining its analysis before making a final prediction. These VisRAG and
tooling components are designed to mirror the processes of domain experts, as
humans often compare new data to similar examples and use specialized tools to
manipulate and inspect images before arriving at a conclusion. Each inference
produces both a prediction and a natural language transcript detailing the
reasoning and tool usage that led to the prediction. We evaluate AiSciVision on
three real-world scientific image classification datasets: detecting the
presence of aquaculture ponds, diseased eelgrass, and solar panels. Across
these datasets, our method outperforms fully supervised models in low and
full-labeled data settings. AiSciVision is actively deployed in real-world use,
specifically for aquaculture research, through a dedicated web application that
displays and allows the expert users to converse with the transcripts. This
work represents a crucial step toward AI systems that are both interpretable
and effective, advancing their use in scientific research and scientific
discovery.",2024-10-28,"Brendan Hogan, Anmol Kabra, Felipe Siqueira Pacheco, Laura Greenstreet, Joshua Fan, Aaron Ferber, Marta Ummus, Alecsander Brito, Olivia Graham, Lillian Aoki, Drew Harvell, Alex Flecker, Carla Gomes",http://arxiv.org/pdf/2410.21480v1,cs.LG
TransformLLM: Adapting Large Language Models via LLM-Transformed Reading Comprehension Text,"Large Language Models (LLMs) have shown promise in highly-specialized
domains, however challenges are still present in aspects of accuracy and costs.
These limitations restrict the usage of existing models in domain-specific
tasks. While fine-tuning pre-trained models have shown promising results, this
process can be computationally expensive and require massive datasets of the
specialized application in hand. In this work, we bridge that gap. We have
developed Phi-2-Legal and Mistral-Legal-7B, which are language models
specifically designed for legal applications. These models are based on Phi-2
and Mistral-7B-v0.1, and have gone through continued pre-training with over 500
million tokens of legal texts. Our innovative approach significantly improves
capabilities in legal tasks by using Large Language Models (LLMs) to convert
raw training data into reading comprehension text. Our legal LLMs have
demonstrated superior performance in legal benchmarks, even outperforming
models trained on much larger datasets with more resources. This work
emphasizes the effectiveness of continued pre-training on domain-specific
texts, while using affordable LLMs for data conversion, which gives these
models domain expertise while retaining general language understanding
capabilities. While this work uses the legal domain as a test case, our method
can be scaled and applied to any pre-training dataset, resulting in significant
improvements across different tasks. These findings underscore the potential of
domain-adaptive pre-training and reading comprehension for the development of
highly effective domain-specific language models.",2024-10-28,"Iftach Arbel, Yehonathan Refael, Ofir Lindenbaum",http://arxiv.org/pdf/2410.21479v1,cs.LG
Flow Matching for Atmospheric Retrieval of Exoplanets: Where Reliability meets Adaptive Noise Levels,"Inferring atmospheric properties of exoplanets from observed spectra is key
to understanding their formation, evolution, and habitability. Since
traditional Bayesian approaches to atmospheric retrieval (e.g., nested
sampling) are computationally expensive, a growing number of machine learning
(ML) methods such as neural posterior estimation (NPE) have been proposed. We
seek to make ML-based atmospheric retrieval (1) more reliable and accurate with
verified results, and (2) more flexible with respect to the underlying neural
networks and the choice of the assumed noise models. First, we adopt flow
matching posterior estimation (FMPE) as a new ML approach to atmospheric
retrieval. FMPE maintains many advantages of NPE, but provides greater
architectural flexibility and scalability. Second, we use importance sampling
(IS) to verify and correct ML results, and to compute an estimate of the
Bayesian evidence. Third, we condition our ML models on the assumed noise level
of a spectrum (i.e., error bars), thus making them adaptable to different noise
models. Both our noise level-conditional FMPE and NPE models perform on par
with nested sampling across a range of noise levels when tested on simulated
data. FMPE trains about 3 times faster than NPE and yields higher IS
efficiencies. IS successfully corrects inaccurate ML results, identifies model
failures via low efficiencies, and provides accurate estimates of the Bayesian
evidence. FMPE is a powerful alternative to NPE for fast, amortized, and
parallelizable atmospheric retrieval. IS can verify results, thus helping to
build confidence in ML-based approaches, while also facilitating model
comparison via the evidence ratio. Noise level conditioning allows design
studies for future instruments to be scaled up, for example, in terms of the
range of signal-to-noise ratios.",2024-10-28,"Timothy D. Gebhard, Jonas Wildberger, Maximilian Dax, Annalena Kofler, Daniel Angerhausen, Sascha P. Quanz, Bernhard Schölkopf",http://arxiv.org/pdf/2410.21477v1,cs.LG
ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference,"With the widespread deployment of long-context large language models (LLMs),
there has been a growing demand for efficient support of high-throughput
inference. However, as the key-value (KV) cache expands with the sequence
length, the increasing memory footprint and the need to access it for each
token generation both result in low throughput when serving long-context LLMs.
While various dynamic sparse attention methods have been proposed to speed up
inference while maintaining generation quality, they either fail to
sufficiently reduce GPU memory consumption or introduce significant decoding
latency by offloading the KV cache to the CPU. We present ShadowKV, a
high-throughput long-context LLM inference system that stores the low-rank key
cache and offloads the value cache to reduce the memory footprint for larger
batch sizes and longer sequences. To minimize decoding latency, ShadowKV
employs an accurate KV selection strategy that reconstructs minimal sparse KV
pairs on-the-fly. By evaluating ShadowKV on a broad range of benchmarks,
including RULER, LongBench, and Needle In A Haystack, and models like
Llama-3.1-8B, Llama-3-8B-1M, GLM-4-9B-1M, Yi-9B-200K, Phi-3-Mini-128K, and
Qwen2-7B-128K, we demonstrate that it can support up to 6$\times$ larger batch
sizes and boost throughput by up to 3.04$\times$ on an A100 GPU without
sacrificing accuracy, even surpassing the performance achievable with infinite
batch size under the assumption of infinite GPU memory. The code is available
at https://github.com/bytedance/ShadowKV.",2024-10-28,"Hanshi Sun, Li-Wen Chang, Wenlei Bao, Size Zheng, Ningxin Zheng, Xin Liu, Harry Dong, Yuejie Chi, Beidi Chen",http://arxiv.org/pdf/2410.21465v3,cs.LG
Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders,"Sparse autoencoders (SAEs) have become a core ingredient in the reverse
engineering of large-language models (LLMs). For LLMs, they have been shown to
decompose intermediate representations that often are not interpretable
directly into sparse sums of interpretable features, facilitating better
control and subsequent analysis. However, similar analyses and approaches have
been lacking for text-to-image models. We investigated the possibility of using
SAEs to learn interpretable features for a few-step text-to-image diffusion
models, such as SDXL Turbo. To this end, we train SAEs on the updates performed
by transformer blocks within SDXL Turbo's denoising U-net. We find that their
learned features are interpretable, causally influence the generation process,
and reveal specialization among the blocks. In particular, we find one block
that deals mainly with image composition, one that is mainly responsible for
adding local details, and one for color, illumination, and style. Therefore,
our work is an important first step towards better understanding the internals
of generative text-to-image models like SDXL Turbo and showcases the potential
of features learned by SAEs for the visual domain.
  Code is available at https://github.com/surkovv/sdxl-unbox",2024-10-28,"Viacheslav Surkov, Chris Wendler, Mikhail Terekhov, Justin Deschenaux, Robert West, Caglar Gulcehre",http://arxiv.org/pdf/2410.22366v2,cs.LG
Inverting Gradient Attacks Makes Powerful Data Poisoning,"Gradient attacks and data poisoning tamper with the training of machine
learning algorithms to maliciously alter them and have been proven to be
equivalent in convex settings. The extent of harm these attacks can produce in
non-convex settings is still to be determined. Gradient attacks can affect far
less systems than data poisoning but have been argued to be more harmful since
they can be arbitrary, whereas data poisoning reduces the attacker's power to
only being able to inject data points to training sets, via e.g. legitimate
participation in a collaborative dataset. This raises the question of whether
the harm made by gradient attacks can be matched by data poisoning in
non-convex settings. In this work, we provide a positive answer in a worst-case
scenario and show how data poisoning can mimic a gradient attack to perform an
availability attack on (non-convex) neural networks. Through gradient
inversion, commonly used to reconstruct data points from actual gradients, we
show how reconstructing data points out of malicious gradients can be
sufficient to perform a range of attacks. This allows us to show, for the first
time, an availability attack on neural networks through data poisoning, that
degrades the model's performances to random-level through a minority (as low as
1%) of poisoned points.",2024-10-28,"Wassim Bouaziz, El-Mahdi El-Mhamdi, Nicolas Usunier",http://arxiv.org/pdf/2410.21453v2,cs.LG
Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures,"This study systematically analyzes the vulnerability of 36 large language
models (LLMs) to various prompt injection attacks, a technique that leverages
carefully crafted prompts to elicit malicious LLM behavior. Across 144 prompt
injection tests, we observed a strong correlation between model parameters and
vulnerability, with statistical analyses, such as logistic regression and
random forest feature analysis, indicating that parameter size and architecture
significantly influence susceptibility. Results revealed that 56 percent of
tests led to successful prompt injections, emphasizing widespread vulnerability
across various parameter sizes, with clustering analysis identifying distinct
vulnerability profiles associated with specific model configurations.
Additionally, our analysis uncovered correlations between certain prompt
injection techniques, suggesting potential overlaps in vulnerabilities. These
findings underscore the urgent need for robust, multi-layered defenses in LLMs
deployed across critical infrastructure and sensitive industries. Successful
prompt injection attacks could result in severe consequences, including data
breaches, unauthorized access, or misinformation. Future research should
explore multilingual and multi-step defenses alongside adaptive mitigation
strategies to strengthen LLM security in diverse, real-world environments.",2024-10-28,"Victoria Benjamin, Emily Braca, Israel Carter, Hafsa Kanchwala, Nava Khojasteh, Charly Landow, Yi Luo, Caroline Ma, Anna Magarelli, Rachel Mirin, Avery Moyer, Kayla Simpson, Amelia Skawinski, Thomas Heverin",http://arxiv.org/pdf/2410.23308v1,cs.LG
A Temporal Linear Network for Time Series Forecasting,"Recent research has challenged the necessity of complex deep learning
architectures for time series forecasting, demonstrating that simple linear
models can often outperform sophisticated approaches. Building upon this
insight, we introduce a novel architecture the Temporal Linear Net (TLN), that
extends the capabilities of linear models while maintaining interpretability
and computational efficiency. TLN is designed to effectively capture both
temporal and feature-wise dependencies in multivariate time series data. Our
approach is a variant of TSMixer that maintains strict linearity throughout its
architecture. TSMixer removes activation functions, introduces specialized
kernel initializations, and incorporates dilated convolutions to handle various
time scales, while preserving the linear nature of the model. Unlike
transformer-based models that may lose temporal information due to their
permutation-invariant nature, TLN explicitly preserves and leverages the
temporal structure of the input data. A key innovation of TLN is its ability to
compute an equivalent linear model, offering a level of interpretability not
found in more complex architectures such as TSMixer. This feature allows for
seamless conversion between the full TLN model and its linear equivalent,
facilitating both training flexibility and inference optimization.",2024-10-28,"Remi Genet, Hugo Inzirillo",http://arxiv.org/pdf/2410.21448v1,cs.LG
TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors,"Adversarial attacks threaten the reliability of machine learning models in
critical applications like autonomous vehicles and defense systems. As object
detectors become more robust with models like YOLOv8, developing effective
adversarial methodologies is increasingly challenging. We present Truck
Adversarial Camouflage Optimization (TACO), a novel framework that generates
adversarial camouflage patterns on 3D vehicle models to deceive
state-of-the-art object detectors. Adopting Unreal Engine 5, TACO integrates
differentiable rendering with a Photorealistic Rendering Network to optimize
adversarial textures targeted at YOLOv8. To ensure the generated textures are
both effective in deceiving detectors and visually plausible, we introduce the
Convolutional Smooth Loss function, a generalized smooth loss function.
Experimental evaluations demonstrate that TACO significantly degrades YOLOv8's
detection performance, achieving an AP@0.5 of 0.0099 on unseen test data.
Furthermore, these adversarial patterns exhibit strong transferability to other
object detection models such as Faster R-CNN and earlier YOLO versions.",2024-10-28,"Adonisz Dimitriu, Tamás Michaletzky, Viktor Remeli",http://arxiv.org/pdf/2410.21443v2,cs.LG
UFT: Unifying Fine-Tuning of SFT and RLHF/DPO/UNA through a Generalized Implicit Reward Function,"By pretraining on trillions of tokens, an LLM gains the capability of text
generation. However, to enhance its utility and reduce potential harm, SFT and
alignment are applied sequentially to the pretrained model. Due to the
differing nature and objective functions of SFT and alignment, catastrophic
forgetting has become a significant issue. To address this, we introduce
Unified Fine-Tuning (UFT), which integrates SFT and alignment into a single
training stage using the same objective and loss functions through an implicit
reward function. Our experimental results demonstrate that UFT outperforms SFT
on instruction-tuning data alone. Moreover, when combining instruction-tuning
data with alignment data, UFT effectively prevents catastrophic forgetting
across these two stages and shows a clear advantage over sequentially applying
SFT and alignment. This is evident in the significant improvements observed in
the \textbf{ifeval} task for instruction-following and the \textbf{truthful-qa}
task for factuality. The proposed general fine-tuning framework UFT establishes
an effective and efficient pretraining-UFT paradigm for LLM training.",2024-10-28,"Zhichao Wang, Bin Bi, Zixu Zhu, Xiangbo Mao, Jun Wang, Shiyu Wang",http://arxiv.org/pdf/2410.21438v2,cs.LG
Sum-of-squares lower bounds for Non-Gaussian Component Analysis,"Non-Gaussian Component Analysis (NGCA) is the statistical task of finding a
non-Gaussian direction in a high-dimensional dataset. Specifically, given
i.i.d.\ samples from a distribution $P^A_{v}$ on $\mathbb{R}^n$ that behaves
like a known distribution $A$ in a hidden direction $v$ and like a standard
Gaussian in the orthogonal complement, the goal is to approximate the hidden
direction. The standard formulation posits that the first $k-1$ moments of $A$
match those of the standard Gaussian and the $k$-th moment differs. Under mild
assumptions, this problem has sample complexity $O(n)$. On the other hand, all
known efficient algorithms require $\Omega(n^{k/2})$ samples. Prior work
developed sharp Statistical Query and low-degree testing lower bounds
suggesting an information-computation tradeoff for this problem.
  Here we study the complexity of NGCA in the Sum-of-Squares (SoS) framework.
Our main contribution is the first super-constant degree SoS lower bound for
NGCA. Specifically, we show that if the non-Gaussian distribution $A$ matches
the first $(k-1)$ moments of $\mathcal{N}(0, 1)$ and satisfies other mild
conditions, then with fewer than $n^{(1 - \varepsilon)k/2}$ many samples from
the normal distribution, with high probability, degree $(\log n)^{{1\over
2}-o_n(1)}$ SoS fails to refute the existence of such a direction $v$. Our
result significantly strengthens prior work by establishing a super-polynomial
information-computation tradeoff against a broader family of algorithms. As
corollaries, we obtain SoS lower bounds for several problems in robust
statistics and the learning of mixture models.
  Our SoS lower bound proof introduces a novel technique, that we believe may
be of broader interest, and a number of refinements over existing methods.",2024-10-28,"Ilias Diakonikolas, Sushrut Karmalkar, Shuo Pang, Aaron Potechin",http://arxiv.org/pdf/2410.21426v1,cs.LG
High-Dimensional Gaussian Process Regression with Soft Kernel Interpolation,"We introduce Soft Kernel Interpolation (SoftKI), a method that combines
aspects of Structured Kernel Interpolation (SKI) and variational inducing point
methods, to achieve scalable Gaussian Process (GP) regression on
high-dimensional datasets. SoftKI approximates a kernel via softmax
interpolation from a smaller number of interpolation points learned by
optimizing a combination of the SoftKI marginal log-likelihood (MLL), and when
needed, an approximate MLL for improved numerical stability. Consequently, it
can overcome the dimensionality scaling challenges that SKI faces when
interpolating from a dense and static lattice while retaining the flexibility
of variational methods to adapt inducing points to the dataset. We demonstrate
the effectiveness of SoftKI across various examples and show that it is
competitive with other approximated GP methods when the data dimensionality is
modest (around 10).",2024-10-28,"Chris Camaño, Daniel Huang",http://arxiv.org/pdf/2410.21419v2,cs.LG
Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong Multi-Agent Path Finding,"Lifelong Multi-Agent Path Finding (LMAPF) repeatedly finds collision-free
paths for multiple agents that are continually assigned new goals when they
reach current ones. Recently, this field has embraced learning-based methods,
which reactively generate single-step actions based on individual local
observations. However, it is still challenging for them to match the
performance of the best search-based algorithms, especially in large-scale
settings. This work proposes an imitation-learning-based LMAPF solver that
introduces a novel communication module as well as systematic single-step
collision resolution and global guidance techniques. Our proposed solver,
Scalable Imitation Learning for LMAPF (SILLM), inherits the fast reasoning
speed of learning-based methods and the high solution quality of search-based
methods with the help of modern GPUs. Across six large-scale maps with up to
10,000 agents and varying obstacle structures, SILLM surpasses the best
learning- and search-based baselines, achieving average throughput improvements
of 137.7% and 16.0%, respectively. Furthermore, SILLM also beats the winning
solution of the 2023 League of Robot Runners, an international LMAPF
competition. Finally, we validated SILLM with 10 real robots and 100 virtual
robots in a mock warehouse environment.",2024-10-28,"He Jiang, Yutong Wang, Rishi Veerapaneni, Tanishq Duhan, Guillaume Sartoretti, Jiaoyang Li",http://arxiv.org/pdf/2410.21415v2,cs.LG
Exploring reinforcement learning for incident response in autonomous military vehicles,"Unmanned vehicles able to conduct advanced operations without human
intervention are being developed at a fast pace for many purposes. Not
surprisingly, they are also expected to significantly change how military
operations can be conducted. To leverage the potential of this new technology
in a physically and logically contested environment, security risks are to be
assessed and managed accordingly. Research on this topic points to autonomous
cyber defence as one of the capabilities that may be needed to accelerate the
adoption of these vehicles for military purposes. Here, we pursue this line of
investigation by exploring reinforcement learning to train an agent that can
autonomously respond to cyber attacks on unmanned vehicles in the context of a
military operation. We first developed a simple simulation environment to
quickly prototype and test some proof-of-concept agents for an initial
evaluation. This agent was then applied to a more realistic simulation
environment and finally deployed on an actual unmanned ground vehicle for even
more realism. A key contribution of our work is demonstrating that
reinforcement learning is a viable approach to train an agent that can be used
for autonomous cyber defence on a real unmanned ground vehicle, even when
trained in a simple simulation environment.",2024-10-28,"Henrik Madsen, Gudmund Grov, Federico Mancini, Magnus Baksaas, Åvald Åslaugson Sommervoll",http://arxiv.org/pdf/2410.21407v1,cs.LG
Bayesian Collaborative Bandits with Thompson Sampling for Improved Outreach in Maternal Health Program,"Mobile health (mHealth) programs face a critical challenge in optimizing the
timing of automated health information calls to beneficiaries. This challenge
has been formulated as a collaborative multi-armed bandit problem, requiring
online learning of a low-rank reward matrix. Existing solutions often rely on
heuristic combinations of offline matrix completion and exploration strategies.
In this work, we propose a principled Bayesian approach using Thompson Sampling
for this collaborative bandit problem. Our method leverages prior information
through efficient Gibbs sampling for posterior inference over the low-rank
matrix factors, enabling faster convergence. We demonstrate significant
improvements over state-of-the-art baselines on a real-world dataset from the
world's largest maternal mHealth program. Our approach achieves a $16\%$
reduction in the number of calls compared to existing methods and a $47$\%
reduction compared to the deployed random policy. This efficiency gain
translates to a potential increase in program capacity by $0.5-1.4$ million
beneficiaries, granting them access to vital ante-natal and post-natal care
information. Furthermore, we observe a $7\%$ and $29\%$ improvement in
beneficiary retention (an extremely hard metric to impact) compared to
state-of-the-art and deployed baselines, respectively. Synthetic simulations
further demonstrate the superiority of our approach, particularly in low-data
regimes and in effectively utilizing prior information. We also provide a
theoretical analysis of our algorithm in a special setting using Eluder
dimension.",2024-10-28,"Arpan Dasgupta, Gagan Jain, Arun Suggala, Karthikeyan Shanmugam, Milind Tambe, Aparna Taneja",http://arxiv.org/pdf/2410.21405v2,cs.LG
Unveiling the Role of Expert Guidance: A Comparative Analysis of User-centered Imitation Learning and Traditional Reinforcement Learning,"Integration of human feedback plays a key role in improving the learning
capabilities of intelligent systems. This comparative study delves into the
performance, robustness, and limitations of imitation learning compared to
traditional reinforcement learning methods within these systems. Recognizing
the value of human-in-the-loop feedback, we investigate the influence of expert
guidance and suboptimal demonstrations on the learning process. Through
extensive experimentation and evaluations conducted in a pre-existing
simulation environment using the Unity platform, we meticulously analyze the
effectiveness and limitations of these learning approaches. The insights gained
from this study contribute to the advancement of human-centered artificial
intelligence by highlighting the benefits and challenges associated with the
incorporation of human feedback into the learning process. Ultimately, this
research promotes the development of models that can effectively address
complex real-world problems.",2024-10-28,"Amr Gomaa, Bilal Mahdy",http://arxiv.org/pdf/2410.21403v1,cs.LG
Model-agnostic basis functions for the 2-point correlation function of dark matter in linear theory,"We consider approximating the linearly evolved 2-point correlation function
(2pcf) of dark matter $\xi_{\rm lin}(r;\boldsymbol{\theta})$ in a cosmological
model with parameters $\boldsymbol{\theta}$ as the linear combination $\xi_{\rm
lin}(r;\boldsymbol{\theta})\approx\sum_i\,b_i(r)\,w_i(\boldsymbol{\theta})$,
where the functions $\mathcal{B}=\{b_i(r)\}$ form a $\textit{model-agnostic
basis}$ for the linear 2pcf. This decomposition is important for model-agnostic
analyses of the baryon acoustic oscillation (BAO) feature in the nonlinear 2pcf
of galaxies that fix $\mathcal{B}$ and leave the coefficients $\{w_i\}$ free.
To date, such analyses have made simple but sub-optimal choices for
$\mathcal{B}$, such as monomials. We develop a machine learning framework for
systematically discovering a $\textit{minimal}$ basis $\mathcal{B}$ that
describes $\xi_{\rm lin}(r)$ near the BAO feature in a wide class of
cosmological models. We use a custom architecture, denoted
$\texttt{BiSequential}$, for a neural network (NN) that explicitly realizes the
separation between $r$ and $\boldsymbol{\theta}$ above. The optimal NN trained
on data in which only $\{\Omega_{\rm m},h\}$ are varied in a $\textit{flat}$
$\Lambda$CDM model produces a basis $\mathcal{B}$ comprising $9$ functions
capable of describing $\xi_{\rm lin}(r)$ to $\sim0.6\%$ accuracy in
$\textit{curved}$ $w$CDM models varying 7 parameters within $\sim5\%$ of their
fiducial, flat $\Lambda$CDM values. Scales such as the peak, linear point and
zero-crossing of $\xi_{\rm lin}(r)$ are also recovered with very high accuracy.
We compare our approach to other compression schemes in the literature, and
speculate that $\mathcal{B}$ may also encompass $\xi_{\rm lin}(r)$ in modified
gravity models near our fiducial $\Lambda$CDM model. Using our basis functions
in model-agnostic BAO analyses can potentially lead to significant statistical
gains.",2024-10-28,"Aseem Paranjape, Ravi K. Sheth",http://arxiv.org/pdf/2410.21374v2,cs.LG
Domain Adaptation with a Single Vision-Language Embedding,"Domain adaptation has been extensively investigated in computer vision but
still requires access to target data at the training time, which might be
difficult to obtain in some uncommon conditions. In this paper, we present a
new framework for domain adaptation relying on a single Vision-Language (VL)
latent embedding instead of full target data. First, leveraging a contrastive
language-image pre-training model (CLIP), we propose prompt/photo-driven
instance normalization (PIN). PIN is a feature augmentation method that mines
multiple visual styles using a single target VL latent embedding, by optimizing
affine transformations of low-level source features. The VL embedding can come
from a language prompt describing the target domain, a partially optimized
language prompt, or a single unlabeled target image. Second, we show that these
mined styles (i.e., augmentations) can be used for zero-shot (i.e.,
target-free) and one-shot unsupervised domain adaptation. Experiments on
semantic segmentation demonstrate the effectiveness of the proposed method,
which outperforms relevant baselines in the zero-shot and one-shot settings.",2024-10-28,"Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, Raoul de Charette",http://arxiv.org/pdf/2410.21361v1,cs.LG
Online Weighted Paging with Unknown Weights,"Online paging is a fundamental problem in the field of online algorithms, in
which one maintains a cache of $k$ slots as requests for fetching pages arrive
online. In the weighted variant of this problem, each page has its own fetching
cost; a substantial line of work on this problem culminated in an (optimal)
$O(\log k)$-competitive randomized algorithm, due to Bansal, Buchbinder and
Naor (FOCS'07).
  Existing work for weighted paging assumes that page weights are known in
advance, which is not always the case in practice. For example, in multi-level
caching architectures, the expected cost of fetching a memory block is a
function of its probability of being in a mid-level cache rather than the main
memory. This complex property cannot be predicted in advance; over time,
however, one may glean information about page weights through sampling their
fetching cost multiple times.
  We present the first algorithm for online weighted paging that does not know
page weights in advance, but rather learns from weight samples. In terms of
techniques, this requires providing (integral) samples to a fractional solver,
requiring a delicate interface between this solver and the randomized rounding
scheme; we believe that our work can inspire online algorithms to other
problems that involve cost sampling.",2024-10-28,"Orin Levy, Noam Touitou, Aviv Rosenberg",http://arxiv.org/pdf/2410.21266v1,cs.LG
Modular Duality in Deep Learning,"An old idea in optimization theory says that since the gradient is a dual
vector it may not be subtracted from the weights without first being mapped to
the primal space where the weights reside. We take this idea seriously in this
paper and construct such a duality map for general neural networks. Our map,
which we call modular dualization, forms a unifying theoretical basis for
training algorithms that are a) fast and b) scalable. Modular dualization
involves first assigning operator norms to layers based on the semantics of
each layer, and then using these layerwise norms to recursively induce a
duality map on the weight space of the full neural architecture. We conclude by
deriving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers
-- the latter two methods are based on a rectangular Newton-Schulz iteration
(Kovarik, 1970; Bj\""orck & Bowie, 1971). A variant of our methods was used to
set speed records for training NanoGPT. Overall, we hope that our theory of
modular duality will yield a next generation of fast and scalable optimizers
for general neural architectures.",2024-10-28,"Jeremy Bernstein, Laker Newhouse",http://arxiv.org/pdf/2410.21265v2,cs.LG
Adaptive Transfer Clustering: A Unified Framework,"We propose a general transfer learning framework for clustering given a main
dataset and an auxiliary one about the same subjects. The two datasets may
reflect similar but different latent grouping structures of the subjects. We
propose an adaptive transfer clustering (ATC) algorithm that automatically
leverages the commonality in the presence of unknown discrepancy, by optimizing
an estimated bias-variance decomposition. It applies to a broad class of
statistical models including Gaussian mixture models, stochastic block models,
and latent class models. A theoretical analysis proves the optimality of ATC
under the Gaussian mixture model and explicitly quantifies the benefit of
transfer. Extensive simulations and real data experiments confirm our method's
effectiveness in various scenarios.",2024-10-28,"Yuqi Gu, Zhongyuan Lyu, Kaizheng Wang",http://arxiv.org/pdf/2410.21263v3,cs.LG
BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference,"Large-scale foundation models have demonstrated exceptional performance in
language and vision tasks. However, the numerous dense matrix-vector operations
involved in these large networks pose significant computational challenges
during inference. To address these challenges, we introduce the Block-Level
Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient
structures prevalent in the weight matrices of linear layers within deep
learning models. Compared to existing structured matrices, the BLAST matrix
offers substantial flexibility, as it can represent various types of structures
that are either learned from data or computed from pre-existing weight
matrices. We demonstrate the efficiency of using the BLAST matrix for
compressing both language and vision tasks, showing that (i) for medium-sized
models such as ViT and GPT-2, training with BLAST weights boosts performance
while reducing complexity by 70% and 40%, respectively; and (ii) for large
foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x
compression while exhibiting the lowest performance degradation among all
tested structured matrices. Our code is available at
https://github.com/changwoolee/BLAST.",2024-10-28,"Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim",http://arxiv.org/pdf/2410.21262v2,cs.LG
Quantum computing and persistence in topological data analysis,"Topological data analysis (TDA) aims to extract noise-robust features from a
data set by examining the number and persistence of holes in its topology. We
show that a computational problem closely related to a core task in TDA --
determining whether a given hole persists across different length scales -- is
$\mathsf{BQP}_1$-hard and contained in $\mathsf{BQP}$. This result implies an
exponential quantum speedup for this problem under standard
complexity-theoretic assumptions. Our approach relies on encoding the
persistence of a hole in a variant of the guided sparse Hamiltonian problem,
where the guiding state is constructed from a harmonic representative of the
hole.",2024-10-28,"Casper Gyurik, Alexander Schmidhuber, Robbie King, Vedran Dunjko, Ryu Hayakawa",http://arxiv.org/pdf/2410.21258v1,cs.LG
One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation,"Diffusion models, praised for their success in generative tasks, are
increasingly being applied to robotics, demonstrating exceptional performance
in behavior cloning. However, their slow generation process stemming from
iterative denoising steps poses a challenge for real-time applications in
resource-constrained robotics setups and dynamically changing environments. In
this paper, we introduce the One-Step Diffusion Policy (OneDP), a novel
approach that distills knowledge from pre-trained diffusion policies into a
single-step action generator, significantly accelerating response times for
robotic control tasks. We ensure the distilled generator closely aligns with
the original policy distribution by minimizing the Kullback-Leibler (KL)
divergence along the diffusion chain, requiring only $2\%$-$10\%$ additional
pre-training cost for convergence. We evaluated OneDP on 6 challenging
simulation tasks as well as 4 self-designed real-world tasks using the Franka
robot. The results demonstrate that OneDP not only achieves state-of-the-art
success rates but also delivers an order-of-magnitude improvement in inference
speed, boosting action prediction frequency from 1.5 Hz to 62 Hz, establishing
its potential for dynamic and computationally constrained robotic applications.
We share the project page at https://research.nvidia.com/labs/dir/onedp/.",2024-10-28,"Zhendong Wang, Zhaoshuo Li, Ajay Mandlekar, Zhenjia Xu, Jiaojiao Fan, Yashraj Narang, Linxi Fan, Yuke Zhu, Yogesh Balaji, Mingyuan Zhou, Ming-Yu Liu, Yu Zeng",http://arxiv.org/pdf/2410.21257v1,cs.LG
LongReward: Improving Long-context Large Language Models with AI Feedback,"Though significant advancements have been achieved in developing long-context
large language models (LLMs), the compromised quality of LLM-synthesized data
for supervised fine-tuning (SFT) often affects the long-context performance of
SFT models and leads to inherent limitations. In principle, reinforcement
learning (RL) with appropriate reward signals can further enhance models'
capacities. However, how to obtain reliable rewards in long-context scenarios
remains unexplored. To this end, we propose LongReward, a novel method that
utilizes an off-the-shelf LLM to provide rewards for long-context model
responses from four human-valued dimensions: helpfulness, logicality,
faithfulness, and completeness, each with a carefully designed assessment
pipeline. By combining LongReward and offline RL algorithm DPO, we are able to
effectively improve long-context SFT models. Our experiments indicate that
LongReward not only significantly improves models' long-context performance but
also enhances their ability to follow short instructions. We also find that
long-context DPO with LongReward and conventional short-context DPO can be used
together without hurting either one's performance.",2024-10-28,"Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li",http://arxiv.org/pdf/2410.21252v1,cs.LG
Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach,"Many real-world sequential repair problems can be effectively modeled using
monotonic Markov Decision Processes (MDPs), where the system state
stochastically decreases and can only be increased by performing a restorative
action. This work addresses the problem of solving multi-component monotonic
MDPs with both budget and capacity constraints. The budget constraint limits
the total number of restorative actions and the capacity constraint limits the
number of restorative actions that can be performed simultaneously. While prior
methods dealt with budget constraints, including capacity constraints in prior
methods leads to an exponential increase in computational complexity as the
number of components in the MDP grows. We propose a two-step planning approach
to address this challenge. First, we partition the components of the
multi-component MDP into groups, where the number of groups is determined by
the capacity constraint. We achieve this partitioning by solving a Linear Sum
Assignment Problem (LSAP). Each group is then allocated a fraction of the total
budget proportional to its size. This partitioning effectively decouples the
large multi-component MDP into smaller subproblems, which are computationally
feasible because the capacity constraint is simplified and the budget
constraint can be addressed using existing methods. Subsequently, we use a
meta-trained PPO agent to obtain an approximately optimal policy for each
group. To validate our approach, we apply it to the problem of scheduling
repairs for a large group of industrial robots, constrained by a limited number
of repair technicians and a total repair budget. Our results demonstrate that
the proposed method outperforms baseline approaches in terms of maximizing the
average uptime of the robot swarm, particularly for large swarm sizes.",2024-10-28,"Manav Vora, Ilan Shomorony, Melkior Ornik",http://arxiv.org/pdf/2410.21249v1,cs.LG
Can Machines Think Like Humans? A Behavioral Evaluation of LLM-Agents in Dictator Games,"As Large Language Model (LLM)-based agents increasingly undertake real-world
tasks and engage with human society, how well do we understand their behaviors?
We (1) investigate how LLM agents' prosocial behaviors -- a fundamental social
norm -- can be induced by different personas and benchmarked against human
behaviors; and (2) introduce a behavioral and social science approach to
evaluate LLM agents' decision-making. We explored how different personas and
experimental framings affect these AI agents' altruistic behavior in dictator
games and compared their behaviors within the same LLM family, across various
families, and with human behaviors. The findings reveal substantial variations
and inconsistencies among LLMs and notable differences compared to human
behaviors. Merely assigning a human-like identity to LLMs does not produce
human-like behaviors. Despite being trained on extensive human-generated data,
these AI agents are unable to capture the internal processes of human
decision-making. Their alignment with human is highly variable and dependent on
specific model architectures and prompt formulations; even worse, such
dependence does not follow a clear pattern. LLMs can be useful task-specific
tools but are not yet intelligent human-like agents.",2024-10-28,Ji Ma,http://arxiv.org/pdf/2410.21359v2,cs.LG
Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback,"Building effective dense retrieval systems remains difficult when relevance
supervision is not available. Recent work has looked to overcome this challenge
by using a Large Language Model (LLM) to generate hypothetical documents that
can be used to find the closest real document. However, this approach relies
solely on the LLM to have domain-specific knowledge relevant to the query,
which may not be practical. Furthermore, generating hypothetical documents can
be inefficient as it requires the LLM to generate a large number of tokens for
each query. To address these challenges, we introduce Real Document Embeddings
from Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF
proposes to re-frame hypothetical document generation as a relevance estimation
task, using an LLM to select which documents should be used for nearest
neighbor search. Through this re-framing, the LLM no longer needs
domain-specific knowledge but only needs to judge what is relevant.
Additionally, relevance estimation only requires the LLM to output a single
token, thereby improving search latency. Our experiments show that ReDE-RF
consistently surpasses state-of-the-art zero-shot dense retrieval methods
across a wide range of low-resource retrieval datasets while also making
significant improvements in latency per-query.",2024-10-28,"Nour Jedidi, Yung-Sung Chuang, Leslie Shing, James Glass",http://arxiv.org/pdf/2410.21242v1,cs.LG
Flaming-hot Initiation with Regular Execution Sampling for Large Language Models,"Since the release of ChatGPT, large language models (LLMs) have demonstrated
remarkable capabilities across various domains. A key challenge in developing
these general capabilities is efficiently sourcing diverse, high-quality data.
This becomes especially critical in reasoning-related tasks with sandbox
checkers, such as math or code, where the goal is to generate correct solutions
to specific problems with higher probability. In this work, we introduce
Flaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet
highly effective method to efficiently find good responses. Our empirical
findings show that FIRE sampling enhances inference-time generation quality and
also benefits training in the alignment stage. Furthermore, we explore how FIRE
sampling improves performance by promoting diversity and analyze the impact of
employing FIRE at different positions within a response.",2024-10-28,"Weizhe Chen, Zhicheng Zhang, Guanlin Liu, Renjie Zheng, Wenlei Shi, Chen Dun, Zheng Wu, Xing Jin, Lin Yan",http://arxiv.org/pdf/2410.21236v2,cs.LG
Energy-Based Diffusion Language Models for Text Generation,"Despite remarkable progress in autoregressive language models, alternative
generative paradigms beyond left-to-right generation are still being actively
explored. Discrete diffusion models, with the capacity for parallel generation,
have recently emerged as a promising alternative. Unfortunately, these models
still underperform the autoregressive counterparts, with the performance gap
increasing when reducing the number of sampling steps. Our analysis reveals
that this degradation is a consequence of an imperfect approximation used by
diffusion models. In this work, we propose Energy-based Diffusion Language
Model (EDLM), an energy-based model operating at the full sequence level for
each diffusion step, introduced to improve the underlying approximation used by
diffusion models. More specifically, we introduce an EBM in a residual form,
and show that its parameters can be obtained by leveraging a pretrained
autoregressive model or by finetuning a bidirectional transformer via noise
contrastive estimation. We also propose an efficient generation algorithm via
parallel important sampling. Comprehensive experiments on language modeling
benchmarks show that our model can consistently outperform state-of-the-art
diffusion models by a significant margin, and approaches autoregressive models'
perplexity. We further show that, without any generation performance drop, our
framework offers a 1.3$\times$ sampling speedup over existing diffusion models.
Reproduced code is available at
https://github.com/MinkaiXu/Energy-Diffusion-LLM.",2024-10-28,"Minkai Xu, Tomas Geffner, Karsten Kreis, Weili Nie, Yilun Xu, Jure Leskovec, Stefano Ermon, Arash Vahdat",http://arxiv.org/pdf/2410.21357v4,cs.LG
$\texttt{skwdro}$: a library for Wasserstein distributionally robust machine learning,"We present skwdro, a Python library for training robust machine learning
models. The library is based on distributionally robust optimization using
optimal transport distances. For ease of use, it features both scikit-learn
compatible estimators for popular objectives, as well as a wrapper for PyTorch
modules, enabling researchers and practitioners to use it in a wide range of
models with minimal code changes. Its implementation relies on an entropic
smoothing of the original robust objective in order to ensure maximal model
flexibility. The library is available at https://github.com/iutzeler/skwdro",2024-10-28,"Florian Vincent, Waïss Azizian, Franck Iutzeler, Jérôme Malick",http://arxiv.org/pdf/2410.21231v1,cs.LG
LoRA vs Full Fine-tuning: An Illusion of Equivalence,"Fine-tuning is a crucial paradigm for adapting pre-trained large language
models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA)
have been shown to match the performance of fully fine-tuned models on various
tasks with an extreme reduction in the number of trainable parameters. Even in
settings where both methods learn similarly accurate models, \emph{are their
learned solutions really equivalent?} We study how different fine-tuning
methods change pre-trained models by analyzing the model's weight matrices
through the lens of their spectral properties. We find that full fine-tuning
and LoRA yield weight matrices whose singular value decompositions exhibit very
different structure; moreover, the fine-tuned models themselves show distinct
generalization behaviors when tested outside the adaptation task's
distribution. More specifically, we first show that the weight matrices trained
with LoRA have new, high-ranking singular vectors, which we call \emph{intruder
dimensions}. Intruder dimensions do not appear during full fine-tuning. Second,
we show that LoRA models with intruder dimensions, despite achieving similar
performance to full fine-tuning on the target task, become worse models of the
pre-training distribution and adapt less robustly to multiple tasks
sequentially. Higher-rank, rank-stabilized LoRA models closely mirror full
fine-tuning, even when performing on par with lower-rank LoRA models on the
same tasks. These results suggest that models updated with LoRA and full
fine-tuning access different parts of parameter space, even when they perform
equally on the fine-tuned distribution. We conclude by examining why intruder
dimensions appear in LoRA fine-tuned models, why they are undesirable, and how
their effects can be minimized.",2024-10-28,"Reece Shuttleworth, Jacob Andreas, Antonio Torralba, Pratyusha Sharma",http://arxiv.org/pdf/2410.21228v1,cs.LG
AutoGLM: Autonomous Foundation Agents for GUIs,"We present AutoGLM, a new series in the ChatGLM family, designed to serve as
foundation agents for autonomous control of digital devices through Graphical
User Interfaces (GUIs). While foundation models excel at acquiring human
knowledge, they often struggle with decision-making in dynamic real-world
environments, limiting their progress toward artificial general intelligence.
This limitation underscores the importance of developing foundation agents
capable of learning through autonomous environmental interactions by
reinforcing existing models. Focusing on Web Browser and Phone as
representative GUI scenarios, we have developed AutoGLM as a practical
foundation agent system for real-world GUI interactions. Our approach
integrates a comprehensive suite of techniques and infrastructures to create
deployable agent systems suitable for user delivery. Through this development,
we have derived two key insights: First, the design of an appropriate
""intermediate interface"" for GUI control is crucial, enabling the separation of
planning and grounding behaviors, which require distinct optimization for
flexibility and accuracy respectively. Second, we have developed a novel
progressive training framework that enables self-evolving online curriculum
reinforcement learning for AutoGLM. Our evaluations demonstrate AutoGLM's
effectiveness across multiple domains. For web browsing, AutoGLM achieves a
55.2% success rate on VAB-WebArena-Lite (improving to 59.1% with a second
attempt) and 96.2% on OpenTable evaluation tasks. In Android device control,
AutoGLM attains a 36.2% success rate on AndroidLab (VAB-Mobile) and 89.7% on
common tasks in popular Chinese APPs.",2024-10-28,"Xiao Liu, Bo Qin, Dongzhu Liang, Guang Dong, Hanyu Lai, Hanchen Zhang, Hanlin Zhao, Iat Long Iong, Jiadai Sun, Jiaqi Wang, Junjie Gao, Junjun Shan, Kangning Liu, Shudan Zhang, Shuntian Yao, Siyi Cheng, Wentao Yao, Wenyi Zhao, Xinghan Liu, Xinyi Liu, Xinying Chen, Xinyue Yang, Yang Yang, Yifan Xu, Yu Yang, Yujia Wang, Yulin Xu, Zehan Qi, Yuxiao Dong, Jie Tang",http://arxiv.org/pdf/2411.00820v1,cs.LG
Reconstructing dynamics from sparse observations with no training on target system,"In applications, an anticipated situation is where the system of interest has
never been encountered before and sparse observations can be made only once.
Can the dynamics be faithfully reconstructed from the limited observations
without any training data? This problem defies any known traditional methods of
nonlinear time-series analysis as well as existing machine-learning methods
that typically require extensive data from the target system for training. We
address this challenge by developing a hybrid transformer and
reservoir-computing machine-learning scheme. The key idea is that, for a
complex and nonlinear target system, the training of the transformer can be
conducted not using any data from the target system, but with essentially
unlimited synthetic data from known chaotic systems. The trained transformer is
then tested with the sparse data from the target system. The output of the
transformer is further fed into a reservoir computer for predicting the
long-term dynamics or the attractor of the target system. The power of the
proposed hybrid machine-learning framework is demonstrated using a large number
of prototypical nonlinear dynamical systems, with high reconstruction accuracy
even when the available data is only 20% of that required to faithfully
represent the dynamical behavior of the underlying system. The framework
provides a paradigm of reconstructing complex and nonlinear dynamics in the
extreme situation where training data does not exist and the observations are
random and sparse.",2024-10-28,"Zheng-Meng Zhai, Jun-Yin Huang, Benjamin D. Stern, Ying-Cheng Lai",http://arxiv.org/pdf/2410.21222v1,cs.LG
Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines,"Search engines enable the retrieval of unknown information with texts.
However, traditional methods fall short when it comes to understanding
unfamiliar visual content, such as identifying an object that the model has
never seen before. This challenge is particularly pronounced for large
vision-language models (VLMs): if the model has not been exposed to the object
depicted in an image, it struggles to generate reliable answers to the user's
question regarding that image. Moreover, as new objects and events continuously
emerge, frequently updating VLMs is impractical due to heavy computational
burdens. To address this limitation, we propose Vision Search Assistant, a
novel framework that facilitates collaboration between VLMs and web agents.
This approach leverages VLMs' visual understanding capabilities and web agents'
real-time information access to perform open-world Retrieval-Augmented
Generation via the web. By integrating visual and textual representations
through this collaboration, the model can provide informed responses even when
the image is novel to the system. Extensive experiments conducted on both
open-set and closed-set QA benchmarks demonstrate that the Vision Search
Assistant significantly outperforms the other models and can be widely applied
to existing VLMs.",2024-10-28,"Zhixin Zhang, Yiyuan Zhang, Xiaohan Ding, Xiangyu Yue",http://arxiv.org/pdf/2410.21220v1,cs.LG
HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation,"Many positional encodings (PEs) are designed to exhibit long-term decay,
based on an entrenched and long-standing inductive opinion: tokens farther away
from the current position carry less relevant information. We argue that
long-term decay is outdated in the era of LLMs, as LLMs are now applied to
tasks demanding precise retrieval of in-context information from arbitrary
positions. Firstly, we present empirical analyses on various PEs, demonstrating
that models inherently learn attention with only a local-decay pattern while
forming a U-shape pattern globally, contradicting the principle of long-term
decay. Furthermore, we conduct a detailed analysis of rotary position encoding
(RoPE, a prevalent relative positional encoding in LLMs), and found that the
U-shape attention is caused by some learned components, which are also the key
factor limiting RoPE's expressiveness and extrapolation.Inspired by these
insights, we propose High-frequency rotary Position Encoding (HoPE). HoPE
replaces the specific components in RoPE with position-independent ones,
retaining only high-frequency signals, which also breaks the principle of
long-term decay in theory. HoPE achieves two major advantages: (1) Without
constraints imposed by long-term decay, contradictory factors that limit
spontaneous attention optimization and model extrapolation performance are
removed. (2) Components representing positions and semantics are are optimized.
These enhances model's context awareness and extrapolation, as validated by
extensive experiments.",2024-10-28,"Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu",http://arxiv.org/pdf/2410.21216v2,cs.LG
On learning higher-order cumulants in diffusion models,"To analyse how diffusion models learn correlations beyond Gaussian ones, we
study the behaviour of higher-order cumulants, or connected n-point functions,
under both the forward and backward process. We derive explicit expressions for
the moment- and cumulant-generating functionals, in terms of the distribution
of the initial data and properties of forward process. It is shown analytically
that during the forward process higher-order cumulants are conserved in models
without a drift, such as the variance-expanding scheme, and that therefore the
endpoint of the forward process maintains nontrivial correlations. We
demonstrate that since these correlations are encoded in the score function,
higher-order cumulants are learnt in the backward process, also when starting
from a normal prior. We confirm our analytical results in an exactly solvable
toy model with nonzero cumulants and in scalar lattice field theory.",2024-10-28,"Gert Aarts, Diaa E. Habibi, Lingxiao Wang, Kai Zhou",http://arxiv.org/pdf/2410.21212v2,cs.LG
SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning,"Current Generative Adversarial Network (GAN)-based approaches for time series
generation face challenges such as suboptimal convergence, information loss in
embedding spaces, and instability. To overcome these challenges, we introduce
an advanced framework that integrates the advantages of an
autoencoder-generated embedding space with the adversarial training dynamics of
GANs. This method employs two discriminators: one to specifically guide the
generator and another to refine both the autoencoder's and generator's output.
Additionally, our framework incorporates a novel autoencoder-based loss
function and supervision from a teacher-forcing supervisor network, which
captures the stepwise conditional distributions of the data. The generator
operates within the latent space, while the two discriminators work on latent
and feature spaces separately, providing crucial feedback to both the generator
and the autoencoder. By leveraging this dual-discriminator approach, we
minimize information loss in the embedding space. Through joint training, our
framework excels at generating high-fidelity time series data, consistently
outperforming existing state-of-the-art benchmarks both qualitatively and
quantitatively across a range of real and synthetic multivariate time series
datasets.",2024-10-28,"MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi",http://arxiv.org/pdf/2410.21203v1,cs.LG
BongLLaMA: LLaMA for Bangla Language,"Bangla (or ""Bengali"") is a language spoken by approximately 240 million
native speakers and around 300 million people worldwide. Despite being the 5th
largest spoken language in the world, Bangla is still a ""low-resource""
language, and existing pretrained language models often struggle to perform
well on Bangla Language Processing (BLP) tasks. This work addresses this gap by
introducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model
fine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.
We present our methodology, data augmentation techniques, fine-tuning details,
and comprehensive benchmarking results showcasing the utility of BongLLaMA on
BLP tasks. We believe BongLLaMA will serve as the new standard baseline for
Bangla Language Models and, thus, facilitate future benchmarking studies
focused on this widely-spoken yet ""low-resource"" language. All BongLLaMA models
are available for public use at https://huggingface.co/BanglaLLM.",2024-10-28,"Abdullah Khan Zehady, Safi Al Mamun, Naymul Islam, Santu Karmaker",http://arxiv.org/pdf/2410.21200v1,cs.LG
SoS Certifiability of Subgaussian Distributions and its Algorithmic Applications,"We prove that there is a universal constant $C>0$ so that for every $d \in
\mathbb N$, every centered subgaussian distribution $\mathcal D$ on $\mathbb
R^d$, and every even $p \in \mathbb N$, the $d$-variate polynomial $(Cp)^{p/2}
\cdot \|v\|_{2}^p - \mathbb E_{X \sim \mathcal D} \langle v,X\rangle^p$ is a
sum of square polynomials. This establishes that every subgaussian distribution
is \emph{SoS-certifiably subgaussian} -- a condition that yields efficient
learning algorithms for a wide variety of high-dimensional statistical tasks.
As a direct corollary, we obtain computationally efficient algorithms with
near-optimal guarantees for the following tasks, when given samples from an
arbitrary subgaussian distribution: robust mean estimation, list-decodable mean
estimation, clustering mean-separated mixture models, robust covariance-aware
mean estimation, robust covariance estimation, and robust linear regression.
Our proof makes essential use of Talagrand's generic chaining/majorizing
measures theorem.",2024-10-28,"Ilias Diakonikolas, Samuel B. Hopkins, Ankit Pensia, Stefan Tiegel",http://arxiv.org/pdf/2410.21194v1,cs.LG
On Homomorphic Encryption Based Strategies for Class Imbalance in Federated Learning,"Class imbalance in training datasets can lead to bias and poor generalization
in machine learning models. While pre-processing of training datasets can
efficiently address both these issues in centralized learning environments, it
is challenging to detect and address these issues in a distributed learning
environment such as federated learning. In this paper, we propose FLICKER, a
privacy preserving framework to address issues related to global class
imbalance in federated learning. At the heart of our contribution lies the
popular CKKS homomorphic encryption scheme, which is used by the clients to
privately share their data attributes, and subsequently balance their datasets
before implementing the FL scheme. Extensive experimental results show that our
proposed method significantly improves the FL accuracy numbers when used along
with popular datasets and relevant baselines.",2024-10-28,"Arpit Guleria, J. Harshan, Ranjitha Prasad, B. N. Bharath",http://arxiv.org/pdf/2410.21192v1,cs.LG
Differentially Private Learned Indexes,"In this paper, we address the problem of efficiently answering predicate
queries on encrypted databases, those secured by Trusted Execution Environments
(TEEs), which enable untrusted providers to process encrypted user data without
revealing its contents. A common strategy in modern databases to accelerate
predicate queries is the use of indexes, which map attribute values (keys) to
their corresponding positions in a sorted data array. This allows for fast
lookup and retrieval of data subsets that satisfy specific predicates.
Unfortunately, indexes cannot be directly applied to encrypted databases due to
strong data dependent leakages. Recent approaches apply differential privacy
(DP) to construct noisy indexes that enable faster access to encrypted data
while maintaining provable privacy guarantees. However, these methods often
suffer from large storage costs, with index sizes typically scaling linearly
with the key space. To address this challenge, we propose leveraging learned
indexes, a trending technique that repurposes machine learning models as
indexing structures, to build more compact DP indexes.",2024-10-28,"Jianzhang Du, Tilak Mudgal, Rutvi Rahul Gadre, Yukui Luo, Chenghong Wang",http://arxiv.org/pdf/2410.21164v1,cs.LG
Resilience in Knowledge Graph Embeddings,"In recent years, knowledge graphs have gained interest and witnessed
widespread applications in various domains, such as information retrieval,
question-answering, recommendation systems, amongst others. Large-scale
knowledge graphs to this end have demonstrated their utility in effectively
representing structured knowledge. To further facilitate the application of
machine learning techniques, knowledge graph embedding (KGE) models have been
developed. Such models can transform entities and relationships within
knowledge graphs into vectors. However, these embedding models often face
challenges related to noise, missing information, distribution shift,
adversarial attacks, etc. This can lead to sub-optimal embeddings and incorrect
inferences, thereby negatively impacting downstream applications. While the
existing literature has focused so far on adversarial attacks on KGE models,
the challenges related to the other critical aspects remain unexplored. In this
paper, we, first of all, give a unified definition of resilience, encompassing
several factors such as generalisation, performance consistency, distribution
adaption, and robustness. After formalizing these concepts for machine learning
in general, we define them in the context of knowledge graphs. To find the gap
in the existing works on resilience in the context of knowledge graphs, we
perform a systematic survey, taking into account all these aspects mentioned
previously. Our survey results show that most of the existing works focus on a
specific aspect of resilience, namely robustness. After categorizing such works
based on their respective aspects of resilience, we discuss the challenges and
future research directions.",2024-10-28,"Arnab Sharma, N'Dah Jean Kouagou, Axel-Cyrille Ngonga Ngomo",http://arxiv.org/pdf/2410.21163v1,cs.LG
Trajectory Flow Matching with Applications to Clinical Time Series Modeling,"Modeling stochastic and irregularly sampled time series is a challenging
problem found in a wide range of applications, especially in medicine. Neural
stochastic differential equations (Neural SDEs) are an attractive modeling
technique for this problem, which parameterize the drift and diffusion terms of
an SDE with neural networks. However, current algorithms for training Neural
SDEs require backpropagation through the SDE dynamics, greatly limiting their
scalability and stability. To address this, we propose Trajectory Flow Matching
(TFM), which trains a Neural SDE in a simulation-free manner, bypassing
backpropagation through the dynamics. TFM leverages the flow matching technique
from generative modeling to model time series. In this work we first establish
necessary conditions for TFM to learn time series data. Next, we present a
reparameterization trick which improves training stability. Finally, we adapt
TFM to the clinical time series setting, demonstrating improved performance on
three clinical time series datasets both in terms of absolute performance and
uncertainty prediction.",2024-10-28,"Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong",http://arxiv.org/pdf/2410.21154v2,cs.LG
BraVE: Offline Reinforcement Learning for Discrete Combinatorial Action Spaces,"Offline reinforcement learning in high-dimensional, discrete action spaces is
challenging due to the exponential scaling of the joint action space with the
number of sub-actions and the complexity of modeling sub-action dependencies.
Existing methods either exhaustively evaluate the action space, making them
computationally infeasible, or factorize Q-values, failing to represent joint
sub-action effects. We propose Branch Value Estimation (BraVE), a value-based
method that uses tree-structured action traversal to evaluate a linear number
of joint actions while preserving dependency structure. BraVE outperforms prior
offline RL methods by up to $20\times$ in environments with over four million
actions.",2024-10-28,"Matthew Landers, Taylor W. Killian, Hugo Barnes, Thomas Hartvigsen, Afsaneh Doryab",http://arxiv.org/pdf/2410.21151v2,cs.LG
LLM-initialized Differentiable Causal Discovery,"The discovery of causal relationships between random variables is an
important yet challenging problem that has applications across many scientific
domains. Differentiable causal discovery (DCD) methods are effective in
uncovering causal relationships from observational data; however, these
approaches often suffer from limited interpretability and face challenges in
incorporating domain-specific prior knowledge. In contrast, Large Language
Models (LLMs)-based causal discovery approaches have recently been shown
capable of providing useful priors for causal discovery but struggle with
formal causal reasoning. In this paper, we propose LLM-DCD, which uses an LLM
to initialize the optimization of the maximum likelihood objective function of
DCD approaches, thereby incorporating strong priors into the discovery method.
To achieve this initialization, we design our objective function to depend on
an explicitly defined adjacency matrix of the causal graph as its only
variational parameter. Directly optimizing the explicitly defined adjacency
matrix provides a more interpretable approach to causal discovery.
Additionally, we demonstrate higher accuracy on key benchmarking datasets of
our approach compared to state-of-the-art alternatives, and provide empirical
evidence that the quality of the initialization directly impacts the quality of
the final output of our DCD approach. LLM-DCD opens up new opportunities for
traditional causal discovery methods like DCD to benefit from future
improvements in the causal reasoning capabilities of LLMs.",2024-10-28,"Shiv Kampani, David Hidary, Constantijn van der Poel, Martin Ganahl, Brenda Miao",http://arxiv.org/pdf/2410.21141v1,cs.LG
Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models,"This paper introduces Fast Calibrated Explanations, a method designed for
generating rapid, uncertainty-aware explanations for machine learning models.
By incorporating perturbation techniques from ConformaSight - a global
explanation framework - into the core elements of Calibrated Explanations (CE),
we achieve significant speedups. These core elements include local feature
importance with calibrated predictions, both of which retain uncertainty
quantification. While the new method sacrifices a small degree of detail, it
excels in computational efficiency, making it ideal for high-stakes, real-time
applications. Fast Calibrated Explanations are applicable to probabilistic
explanations in classification and thresholded regression tasks, where they
provide the likelihood of a target being above or below a user-defined
threshold. This approach maintains the versatility of CE for both
classification and probabilistic regression, making it suitable for a range of
predictive tasks where uncertainty quantification is crucial.",2024-10-28,"Tuwe Löfström, Fatima Rabia Yapicioglu, Alessandra Stramiglio, Helena Löfström, Fabio Vitali",http://arxiv.org/pdf/2410.21129v1,cs.LG
FusedInf: Efficient Swapping of DNN Models for On-Demand Serverless Inference Services on the Edge,"Edge AI computing boxes are a new class of computing devices that are aimed
to revolutionize the AI industry. These compact and robust hardware units bring
the power of AI processing directly to the source of data--on the edge of the
network. On the other hand, on-demand serverless inference services are
becoming more and more popular as they minimize the infrastructural cost
associated with hosting and running DNN models for small to medium-sized
businesses. However, these computing devices are still constrained in terms of
resource availability. As such, the service providers need to load and unload
models efficiently in order to meet the growing demand. In this paper, we
introduce FusedInf to efficiently swap DNN models for on-demand serverless
inference services on the edge. FusedInf combines multiple models into a single
Direct Acyclic Graph (DAG) to efficiently load the models into the GPU memory
and make execution faster. Our evaluation of popular DNN models showed that
creating a single DAG can make the execution of the models up to 14\% faster
while reducing the memory requirement by up to 17\%. The prototype
implementation is available at https://github.com/SifatTaj/FusedInf.",2024-10-28,"Sifat Ut Taki, Arthi Padmanabhan, Spyridon Mastorakis",http://arxiv.org/pdf/2410.21120v1,cs.LG
A Unified Solution to Diverse Heterogeneities in One-shot Federated Learning,"One-Shot Federated Learning (OSFL) restricts communication between the server
and clients to a single round, significantly reducing communication costs and
minimizing privacy leakage risks compared to traditional Federated Learning
(FL), which requires multiple rounds of communication. However, existing OSFL
frameworks remain vulnerable to distributional heterogeneity, as they primarily
focus on model heterogeneity while neglecting data heterogeneity. To bridge
this gap, we propose FedHydra, a unified, data-free, OSFL framework designed to
effectively address both model and data heterogeneity. Unlike existing OSFL
approaches, FedHydra introduces a novel two-stage learning mechanism.
Specifically, it incorporates model stratification and heterogeneity-aware
stratified aggregation to mitigate the challenges posed by both model and data
heterogeneity. By this design, the data and model heterogeneity issues are
simultaneously monitored from different aspects during learning. Consequently,
FedHydra can effectively mitigate both issues by minimizing their inherent
conflicts. We compared FedHydra with five SOTA baselines on four benchmark
datasets. Experimental results show that our method outperforms the previous
OSFL methods in both homogeneous and heterogeneous settings. Our code is
available at https://anonymous.4open.science/r/Fed-SA-A4D7.",2024-10-28,"Jun Bai, Yiliao Song, Di Wu, Atul Sajjanhar, Yong Xiang, Wei Zhou, Xiaohui Tao, Yan Li, Yue Li",http://arxiv.org/pdf/2410.21119v2,cs.LG
Robustness and Generalization in Quantum Reinforcement Learning via Lipschitz Regularization,"Quantum machine learning leverages quantum computing to enhance accuracy and
reduce model complexity compared to classical approaches, promising significant
advancements in various fields. Within this domain, quantum reinforcement
learning has garnered attention, often realized using variational quantum
circuits to approximate the policy function. This paper addresses the
robustness and generalization of quantum reinforcement learning by combining
principles from quantum computing and control theory. Leveraging recent results
on robust quantum machine learning, we utilize Lipschitz bounds to propose a
regularized version of a quantum policy gradient approach, named the RegQPG
algorithm. We show that training with RegQPG improves the robustness and
generalization of the resulting policies. Furthermore, we introduce an
algorithmic variant that incorporates curriculum learning, which minimizes
failures during training. Our findings are validated through numerical
experiments, demonstrating the practical benefits of our approach.",2024-10-28,"Nico Meyer, Julian Berberich, Christopher Mutschler, Daniel D. Scherer",http://arxiv.org/pdf/2410.21117v1,cs.LG
LAMA: Stable Dual-Domain Deep Reconstruction For Sparse-View CT,"Inverse problems arise in many applications, especially tomographic imaging.
We develop a Learned Alternating Minimization Algorithm (LAMA) to solve such
problems via two-block optimization by synergizing data-driven and classical
techniques with proven convergence. LAMA is naturally induced by a variational
model with learnable regularizers in both data and image domains, parameterized
as composite functions of neural networks trained with domain-specific data. We
allow these regularizers to be nonconvex and nonsmooth to extract features from
data effectively. We minimize the overall objective function using Nesterov's
smoothing technique and residual learning architecture. It is demonstrated that
LAMA reduces network complexity, improves memory efficiency, and enhances
reconstruction accuracy, stability, and interpretability. Extensive experiments
show that LAMA significantly outperforms state-of-the-art methods on popular
benchmark datasets for Computed Tomography.",2024-10-28,"Chi Ding, Qingchao Zhang, Ge Wang, Xiaojing Ye, Yunmei Chen",http://arxiv.org/pdf/2410.21111v1,cs.LG
Dual-Agent Deep Reinforcement Learning for Dynamic Pricing and Replenishment,"We study the dynamic pricing and replenishment problems under inconsistent
decision frequencies. Different from the traditional demand assumption, the
discreteness of demand and the parameter within the Poisson distribution as a
function of price introduce complexity into analyzing the problem property. We
demonstrate the concavity of the single-period profit function with respect to
product price and inventory within their respective domains. The demand model
is enhanced by integrating a decision tree-based machine learning approach,
trained on comprehensive market data. Employing a two-timescale stochastic
approximation scheme, we address the discrepancies in decision frequencies
between pricing and replenishment, ensuring convergence to local optimum. We
further refine our methodology by incorporating deep reinforcement learning
(DRL) techniques and propose a fast-slow dual-agent DRL algorithm. In this
approach, two agents handle pricing and inventory and are updated on different
scales. Numerical results from both single and multiple products scenarios
validate the effectiveness of our methods.",2024-10-28,"Yi Zheng, Zehao Li, Peng Jiang, Yijie Peng",http://arxiv.org/pdf/2410.21109v1,cs.LG
Tree-Wasserstein Distance for High Dimensional Data with a Latent Feature Hierarchy,"Finding meaningful distances between high-dimensional data samples is an
important scientific task. To this end, we propose a new tree-Wasserstein
distance (TWD) for high-dimensional data with two key aspects. First, our TWD
is specifically designed for data with a latent feature hierarchy, i.e., the
features lie in a hierarchical space, in contrast to the usual focus on
embedding samples in hyperbolic space. Second, while the conventional use of
TWD is to speed up the computation of the Wasserstein distance, we use its
inherent tree as a means to learn the latent feature hierarchy. The key idea of
our method is to embed the features into a multi-scale hyperbolic space using
diffusion geometry and then present a new tree decoding method by establishing
analogies between the hyperbolic embedding and trees. We show that our TWD
computed based on data observations provably recovers the TWD defined with the
latent feature hierarchy and that its computation is efficient and scalable. We
showcase the usefulness of the proposed TWD in applications to word-document
and single-cell RNA-sequencing datasets, demonstrating its advantages over
existing TWDs and methods based on pre-trained models.",2024-10-28,"Ya-Wei Eileen Lin, Ronald R. Coifman, Gal Mishne, Ronen Talmon",http://arxiv.org/pdf/2410.21107v3,cs.LG
Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models,"The widespread use of AI-generated content from diffusion models has raised
significant concerns regarding misinformation and copyright infringement.
Watermarking is a crucial technique for identifying these AI-generated images
and preventing their misuse. In this paper, we introduce Shallow Diffuse, a new
watermarking technique that embeds robust and invisible watermarks into
diffusion model outputs. Unlike existing approaches that integrate watermarking
throughout the entire diffusion sampling process, Shallow Diffuse decouples
these steps by leveraging the presence of a low-dimensional subspace in the
image generation process. This method ensures that a substantial portion of the
watermark lies in the null space of this subspace, effectively separating it
from the image generation process. Our theoretical and empirical analyses show
that this decoupling strategy greatly enhances the consistency of data
generation and the detectability of the watermark. Extensive experiments
further validate that our Shallow Diffuse outperforms existing watermarking
methods in terms of robustness and consistency. The codes will be released at
https://github.com/liwd190019/Shallow-Diffuse.",2024-10-28,"Wenda Li, Huijie Zhang, Qing Qu",http://arxiv.org/pdf/2410.21088v1,cs.LG
Foundations of Safe Online Reinforcement Learning in the Linear Quadratic Regulator: Generalized Baselines,"Many practical applications of online reinforcement learning require the
satisfaction of safety constraints while learning about the unknown
environment. In this work, we establish theoretical foundations for
reinforcement learning with safety constraints by studying the canonical
problem of Linear Quadratic Regulator learning with unknown dynamics, but with
the additional constraint that the position must stay within a safe region for
the entire trajectory with high probability. Our primary contribution is a
general framework for studying stronger baselines of nonlinear controllers that
are better suited for constrained problems than linear controllers. Due to the
difficulty of analyzing non-linear controllers in a constrained problem, we
focus on 1-dimensional state- and action- spaces, however we also discuss how
we expect the high-level takeaways can generalize to higher dimensions. Using
our framework, we show that for \emph{any} non-linear baseline satisfying
natural assumptions, $\tilde{O}_T(\sqrt{T})$-regret is possible when the noise
distribution has sufficiently large support, and $\tilde{O}_T(T^{2/3})$-regret
is possible for \emph{any} subgaussian noise distribution. In proving these
results, we introduce a new uncertainty estimation bound for nonlinear controls
which shows that enforcing safety in the presence of sufficient noise can
provide ``free exploration'' that compensates for the added cost of uncertainty
in safety-constrained control.",2024-10-28,"Benjamin Schiffer, Lucas Janson",http://arxiv.org/pdf/2410.21081v2,cs.LG
Accelerated Bayesian parameter estimation and model selection for gravitational waves with normalizing flows,"We present an accelerated pipeline, based on high-performance computing
techniques and normalizing flows, for joint Bayesian parameter estimation and
model selection and demonstrate its efficiency in gravitational wave
astrophysics. We integrate the Jim inference toolkit, a normalizing
flow-enhanced Markov chain Monte Carlo (MCMC) sampler, with the learned
harmonic mean estimator. Our Bayesian evidence estimates run on $1$ GPU are
consistent with traditional nested sampling techniques run on $16$ CPU cores,
while reducing the computation time by factors of $5\times$ and $15\times$ for
$4$-dimensional and $11$-dimensional gravitational wave inference problems,
respectively. Our code is available in well-tested and thoroughly documented
open-source packages, ensuring accessibility and reproducibility for the wider
research community.",2024-10-28,"Alicja Polanska, Thibeau Wouters, Peter T. H. Pang, Kaze K. W. Wong, Jason D. McEwen",http://arxiv.org/pdf/2410.21076v2,cs.LG
Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices,"This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep
neural networks to address the gap between pre-trained and deployed models. In
our approach, trainable LoRA (low-rank adaptation) adapters are inserted
between the last layer and every other layer to enhance the network expressive
power while keeping the backward computation cost low. This architecture is
well-suited to cache intermediate computation results of the forward pass and
then can skip the forward computation of seen samples as training epochs
progress. We implemented the combination of the proposed architecture and
cache, denoted as Skip2-LoRA, and tested it on a $15 single board computer. Our
results show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average
compared to the counterpart that has the same number of trainable parameters
while preserving the accuracy, while taking only a few seconds on the
microcontroller board.",2024-10-28,"Hiroki Matsutani, Masaaki Kondo, Kazuki Sunaga, Radu Marculescu",http://arxiv.org/pdf/2410.21073v1,cs.LG
Federated Time Series Generation on Feature and Temporally Misaligned Data,"Distributed time series data presents a challenge for federated learning, as
clients often possess different feature sets and have misaligned time steps.
Existing federated time series models are limited by the assumption of perfect
temporal or feature alignment across clients. In this paper, we propose FedTDD,
a novel federated time series diffusion model that jointly learns a synthesizer
across clients. At the core of FedTDD is a novel data distillation and
aggregation framework that reconciles the differences between clients by
imputing the misaligned timesteps and features. In contrast to traditional
federated learning, FedTDD learns the correlation across clients' time series
through the exchange of local synthetic outputs instead of model parameters. A
coordinator iteratively improves a global distiller network by leveraging
shared knowledge from clients through the exchange of synthetic data. As the
distiller becomes more refined over time, it subsequently enhances the quality
of the clients' local feature estimates, allowing each client to then improve
its local imputations for missing data using the latest, more accurate
distiller. Experimental results on five datasets demonstrate FedTDD's
effectiveness compared to centralized training, and the effectiveness of
sharing synthetic outputs to transfer knowledge of local time series. Notably,
FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID
and Correlational scores.",2024-10-28,"Chenrui Fan, Zhi Wen Soi, Aditya Shankar, Abele Mălan, Lydia Y. Chen",http://arxiv.org/pdf/2410.21072v1,cs.LG
EMOCPD: Efficient Attention-based Models for Computational Protein Design Using Amino Acid Microenvironment,"Computational protein design (CPD) refers to the use of computational methods
to design proteins. Traditional methods relying on energy functions and
heuristic algorithms for sequence design are inefficient and do not meet the
demands of the big data era in biomolecules, with their accuracy limited by the
energy functions and search algorithms. Existing deep learning methods are
constrained by the learning capabilities of the networks, failing to extract
effective information from sparse protein structures, which limits the accuracy
of protein design. To address these shortcomings, we developed an Efficient
attention-based Models for Computational Protein Design using amino acid
microenvironment (EMOCPD). It aims to predict the category of each amino acid
in a protein by analyzing the three-dimensional atomic environment surrounding
the amino acids, and optimize the protein based on the predicted
high-probability potential amino acid categories. EMOCPD employs a multi-head
attention mechanism to focus on important features in the sparse protein
microenvironment and utilizes an inverse residual structure to optimize the
network architecture. The proposed EMOCPD achieves over 80% accuracy on the
training set and 68.33% and 62.32% accuracy on two independent test sets,
respectively, surpassing the best comparative methods by over 10%. In protein
design, the thermal stability and protein expression of the predicted mutants
from EMOCPD show significant improvements compared to the wild type,
effectively validating EMOCPD's potential in designing superior proteins.
Furthermore, the predictions of EMOCPD are influenced positively, negatively,
or have minimal impact based on the content of the 20 amino acids, categorizing
amino acids as positive, negative, or neutral. Research findings indicate that
EMOCPD is more suitable for designing proteins with lower contents of negative
amino acids.",2024-10-28,"Xiaoqi Ling, Cheng Cai, Demin Kong, Zhisheng Wei, Jing Wu, Lei Wang, Zhaohong Deng",http://arxiv.org/pdf/2410.21069v2,cs.LG
Learning to Handle Complex Constraints for Vehicle Routing Problems,"Vehicle Routing Problems (VRPs) can model many real-world scenarios and often
involve complex constraints. While recent neural methods excel in constructing
solutions based on feasibility masking, they struggle with handling complex
constraints, especially when obtaining the masking itself is NP-hard. In this
paper, we propose a novel Proactive Infeasibility Prevention (PIP) framework to
advance the capabilities of neural methods towards more complex VRPs. Our PIP
integrates the Lagrangian multiplier as a basis to enhance constraint awareness
and introduces preventative infeasibility masking to proactively steer the
solution construction process. Moreover, we present PIP-D, which employs an
auxiliary decoder and two adaptive strategies to learn and predict these
tailored masks, potentially enhancing performance while significantly reducing
computational costs during training. To verify our PIP designs, we conduct
extensive experiments on the highly challenging Traveling Salesman Problem with
Time Window (TSPTW), and TSP with Draft Limit (TSPDL) variants under different
constraint hardness levels. Notably, our PIP is generic to boost many neural
methods, and exhibits both a significant reduction in infeasible rate and a
substantial improvement in solution quality.",2024-10-28,"Jieyi Bi, Yining Ma, Jianan Zhou, Wen Song, Zhiguang Cao, Yaoxin Wu, Jie Zhang",http://arxiv.org/pdf/2410.21066v1,cs.LG
CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models,"Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI knowledge extraction methods lack flexibility
and generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through: (1) a carefully designed automatic prompt
construction strategy with optimal demonstration retrieval for extracting a
wide range of cybersecurity entities and relations; (2) a hierarchical entity
alignment technique that canonicalizes the extracted knowledge and removes
redundancy; (3) an long-distance relation prediction technique to further
complete the CSKG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKG, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.",2024-10-28,"Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao",http://arxiv.org/pdf/2410.21060v2,cs.LG
Computable Lipschitz Bounds for Deep Neural Networks,"Deriving sharp and computable upper bounds of the Lipschitz constant of deep
neural networks is crucial to formally guarantee the robustness of
neural-network based models. We analyse three existing upper bounds written for
the $l^2$ norm. We highlight the importance of working with the $l^1$ and
$l^\infty$ norms and we propose two novel bounds for both feed-forward
fully-connected neural networks and convolutional neural networks. We treat the
technical difficulties related to convolutional neural networks with two
different methods, called explicit and implicit. Several numerical tests
empirically confirm the theoretical results, help to quantify the relationship
between the presented bounds and establish the better accuracy of the new
bounds. Four numerical tests are studied: two where the output is derived from
an analytical closed form are proposed; another one with random matrices; and
the last one for convolutional neural networks trained on the MNIST dataset. We
observe that one of our bound is optimal in the sense that it is exact for the
first test with the simplest analytical form and it is better than other bounds
for the other tests.",2024-10-28,"Moreno Pintore, Bruno Després",http://arxiv.org/pdf/2410.21053v1,cs.LG
Getting By Goal Misgeneralization With a Little Help From a Mentor,"While reinforcement learning (RL) agents often perform well during training,
they can struggle with distribution shift in real-world deployments. One
particularly severe risk of distribution shift is goal misgeneralization, where
the agent learns a proxy goal that coincides with the true goal during training
but not during deployment. In this paper, we explore whether allowing an agent
to ask for help from a supervisor in unfamiliar situations can mitigate this
issue. We focus on agents trained with PPO in the CoinRun environment, a
setting known to exhibit goal misgeneralization. We evaluate multiple methods
for determining when the agent should request help and find that asking for
help consistently improves performance. However, we also find that methods
based on the agent's internal state fail to proactively request help, instead
waiting until mistakes have already occurred. Further investigation suggests
that the agent's internal state does not represent the coin at all,
highlighting the importance of learning nuanced representations, the risks of
ignoring everything not immediately relevant to reward, and the necessity of
developing ask-for-help strategies tailored to the agent's training algorithm.",2024-10-28,"Tu Trinh, Mohamad H. Danesh, Nguyen X. Khanh, Benjamin Plaut",http://arxiv.org/pdf/2410.21052v3,cs.LG
Disentangled and Self-Explainable Node Representation Learning,"Node representations, or embeddings, are low-dimensional vectors that capture
node properties, typically learned through unsupervised structural similarity
objectives or supervised tasks. While recent efforts have focused on explaining
graph model decisions, the interpretability of unsupervised node embeddings
remains underexplored. To bridge this gap, we introduce DiSeNE (Disentangled
and Self-Explainable Node Embedding), a framework that generates
self-explainable embeddings in an unsupervised manner. Our method employs
disentangled representation learning to produce dimension-wise interpretable
embeddings, where each dimension is aligned with distinct topological structure
of the graph. We formalize novel desiderata for disentangled and interpretable
embeddings, which drive our new objective functions, optimizing simultaneously
for both interpretability and disentanglement. Additionally, we propose several
new metrics to evaluate representation quality and human interpretability.
Extensive experiments across multiple benchmark datasets demonstrate the
effectiveness of our approach.",2024-10-28,"Simone Piaggesi, André Panisson, Megha Khosla",http://arxiv.org/pdf/2410.21043v1,cs.LG
Beyond Autoregression: Fast LLMs via Self-Distillation Through Time,"Autoregressive (AR) Large Language Models (LLMs) have demonstrated
significant success across numerous tasks. However, the AR modeling paradigm
presents certain limitations; for instance, contemporary autoregressive LLMs
are trained to generate one token at a time, which can result in noticeable
latency. Recent advances have indicated that search and repeated sampling can
enhance performance in various applications, such as theorem proving, code
generation, and alignment, by utilizing greater computational resources during
inference. In this study, we demonstrate that diffusion language models are
capable of generating at least 32 tokens simultaneously, while exceeding the
performance of AR models in text quality and on the LAMBADA natural language
understanding benchmark. This outcome is achieved through a novel distillation
method for discrete diffusion models, which reduces the number of inference
steps by a factor of 32-64. Practically, at the 1.3B parameters scale,
diffusion models, even without caching, can generate tokens at a rate that is
up to 8 times faster than AR models employing KV-caching, and we anticipate
further improvements with the inclusion of caching. Moreover, we demonstrate
the efficacy of our approach for diffusion language models with up to 860M
parameters.",2024-10-28,"Justin Deschenaux, Caglar Gulcehre",http://arxiv.org/pdf/2410.21035v2,cs.LG
BanditCAT and AutoIRT: Machine Learning Approaches to Computerized Adaptive Testing and Item Calibration,"In this paper, we present a complete framework for quickly calibrating and
administering a robust large-scale computerized adaptive test (CAT) with a
small number of responses. Calibration - learning item parameters in a test -
is done using AutoIRT, a new method that uses automated machine learning
(AutoML) in combination with item response theory (IRT), originally proposed in
[Sharpnack et al., 2024]. AutoIRT trains a non-parametric AutoML grading model
using item features, followed by an item-specific parametric model, which
results in an explanatory IRT model. In our work, we use tabular AutoML tools
(AutoGluon.tabular, [Erickson et al., 2020]) along with BERT embeddings and
linguistically motivated NLP features. In this framework, we use Bayesian
updating to obtain test taker ability posterior distributions for
administration and scoring.
  For administration of our adaptive test, we propose the BanditCAT framework,
a methodology motivated by casting the problem in the contextual bandit
framework and utilizing item response theory (IRT). The key insight lies in
defining the bandit reward as the Fisher information for the selected item,
given the latent test taker ability from IRT assumptions. We use Thompson
sampling to balance between exploring items with different psychometric
characteristics and selecting highly discriminative items that give more
precise information about ability. To control item exposure, we inject noise
through an additional randomization step before computing the Fisher
information. This framework was used to initially launch two new item types on
the DET practice test using limited training data. We outline some reliability
and exposure metrics for the 5 practice test experiments that utilized this
framework.",2024-10-28,"James Sharpnack, Kevin Hao, Phoebe Mulcaire, Klinton Bicknell, Geoff LaFlair, Kevin Yancey, Alina A. von Davier",http://arxiv.org/pdf/2410.21033v1,cs.LG
Graph Based Traffic Analysis and Delay Prediction,"This research is focused on traffic congestion in the small island of Malta
which is the most densely populated country in the EU with about 1,672
inhabitants per square kilometre (4,331 inhabitants/sq mi). Furthermore, Malta
has a rapid vehicle growth. Based on our research, the number of vehicles
increased by around 11,000 in a little more than 6 months, which shows how
important it is to have an accurate and comprehensive means of collecting data
to tackle the issue of fluctuating traffic in Malta. In this paper, we first
present the newly built comprehensive traffic dataset, called MalTra. This
dataset includes realistic trips made by members of the public across the
island over a period of 200 days. We then describe the methodology we adopted
to generate syntactic data to complete our data set as much as possible. In our
research, we consider both MalTra and the Q-Traffic dataset, which has been
used in several other research studies. The statistical ARIMA model and two
graph neural networks, the spatial temporal graph convolutional network (STGCN)
and the diffusion convolutional recurrent network (DCRNN) were used to analyse
and compare the results with existing research. From the evaluation, we found
that the DCRNN model outperforms the STGCN with the former resulting in MAE of
3.98 (6.65 in the case of the latter) and a RMSE of 7.78 (against 12.73 of the
latter).",2024-10-28,"Gabriele Borg, Charlie Abela",http://arxiv.org/pdf/2410.21028v1,cs.LG
Transferable Post-training via Inverse Value Learning,"As post-training processes utilize increasingly large datasets and base
models continue to grow in size, the computational demands and implementation
challenges of existing algorithms are escalating significantly. In this paper,
we propose modeling the changes at the logits level during post-training using
a separate neural network (i.e., the value network). After training this
network on a small base model using demonstrations, this network can be
seamlessly integrated with other pre-trained models during inference, enables
them to achieve similar capability enhancements. We systematically investigate
the best practices for this paradigm in terms of pre-training weights and
connection schemes. We demonstrate that the resulting value network has broad
transferability across pre-trained models of different parameter sizes within
the same family, models undergoing continuous pre-training within the same
family, and models with different vocabularies across families. In certain
cases, it can achieve performance comparable to full-parameter fine-tuning.
Furthermore, we explore methods to enhance the transferability of the value
model and prevent overfitting to the base model used during training.",2024-10-28,"Xinyu Lu, Xueru Wen, Yaojie Lu, Bowen Yu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, Yongbin Li",http://arxiv.org/pdf/2410.21027v1,cs.LG
Physics-informed Partitioned Coupled Neural Operator for Complex Networks,"Physics-Informed Neural Operators provide efficient, high-fidelity
simulations for systems governed by partial differential equations (PDEs).
However, most existing studies focus only on multi-scale, multi-physics systems
within a single spatial region, neglecting the case with multiple
interconnected sub-regions, such as gas and thermal systems. To address this,
this paper proposes a Physics-Informed Partitioned Coupled Neural Operator
(PCNO) to enhance the simulation performance of such networks. Compared to the
existing Fourier Neural Operator (FNO), this method designs a joint convolution
operator within the Fourier layer, enabling global integration capturing all
sub-regions. Additionally, grid alignment layers are introduced outside the
Fourier layer to help the joint convolution operator accurately learn the
coupling relationship between sub-regions in the frequency domain. Experiments
on gas networks demonstrate that the proposed operator not only accurately
simulates complex systems but also shows good generalization and low model
complexity.",2024-10-28,"Weidong Wu, Yong Zhang, Lili Hao, Yang Chen, Xiaoyan Sun, Dunwei Gong",http://arxiv.org/pdf/2410.21025v1,cs.LG
Breccia and basalt classification of thin sections of Apollo rocks with deep learning,"Human exploration of the moon is expected to resume in the next decade,
following the last such activities in the Apollo programme time. One of the
major objectives of returning to the Moon is to continue retrieving geological
samples, with a focus on collecting high-quality specimens to maximize
scientific return. Tools that assist astronauts in making informed decisions
about sample collection activities can maximize the scientific value of future
lunar missions. A lunar rock classifier is a tool that can potentially provide
the necessary information for astronauts to analyze lunar rock samples,
allowing them to augment in-situ value identification of samples. Towards
demonstrating the value of such a tool, in this paper, we introduce a framework
for classifying rock types in thin sections of lunar rocks. We leverage the
vast collection of petrographic thin-section images from the Apollo missions,
captured under plane-polarized light (PPL), cross-polarised light (XPL), and
reflected light at varying magnifications. Advanced machine learning methods,
including contrastive learning, are applied to analyze these images and extract
meaningful features. The contrastive learning approach fine-tunes a pre-trained
Inception-Resnet-v2 network with the SimCLR loss function. The fine-tuned
Inception-Resnet-v2 network can then extract essential features effectively
from the thin-section images of Apollo rocks. A simple binary classifier is
trained using transfer learning from the fine-tuned Inception-ResNet-v2 to
98.44\% ($\pm$1.47) accuracy in separating breccias from basalts.",2024-10-28,"Freja Thoresen, Aidan Cowley, Romeo Haak, Jonas Lewe, Clara Moriceau, Piotr Knapczyk, Victoria S. Engelschiøn",http://arxiv.org/pdf/2410.21024v1,cs.LG
Diagnostic Performance of Deep Learning for Predicting Gliomas' IDH and 1p/19q Status in MRI: A Systematic Review and Meta-Analysis,"Gliomas, the most common primary brain tumors, show high heterogeneity in
histological and molecular characteristics. Accurate molecular profiling, like
isocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion, is critical for
diagnosis, treatment, and prognosis. This review evaluates MRI-based deep
learning (DL) models' efficacy in predicting these biomarkers. Following PRISMA
guidelines, we systematically searched major databases (PubMed, Scopus, Ovid,
and Web of Science) up to February 2024, screening studies that utilized DL to
predict IDH and 1p/19q codeletion status from MRI data of glioma patients. We
assessed the quality and risk of bias using the radiomics quality score and
QUADAS-2 tool. Our meta-analysis used a bivariate model to compute pooled
sensitivity, specificity, and meta-regression to assess inter-study
heterogeneity. Of the 565 articles, 57 were selected for qualitative synthesis,
and 52 underwent meta-analysis. The pooled estimates showed high diagnostic
performance, with validation sensitivity, specificity, and area under the curve
(AUC) of 0.84 [prediction interval (PI): 0.67-0.93, I2=51.10%, p < 0.05], 0.87
[PI: 0.49-0.98, I2=82.30%, p < 0.05], and 0.89 for IDH prediction, and 0.76
[PI: 0.28-0.96, I2=77.60%, p < 0.05], 0.85 [PI: 0.49-0.97, I2=80.30%, p <
0.05], and 0.90 for 1p/19q prediction, respectively. Meta-regression analyses
revealed significant heterogeneity influenced by glioma grade, data source,
inclusion of non-radiomics data, MRI sequences, segmentation and feature
extraction methods, and validation techniques. DL models demonstrate strong
potential in predicting molecular biomarkers from MRI scans, with significant
variability influenced by technical and clinical factors. Thorough external
validation is necessary to increase clinical utility.",2024-10-28,"Somayeh Farahani, Marjaneh Hejazi, Mehnaz Tabassum, Antonio Di Ieva, Neda Mahdavifar, Sidong Liu",http://arxiv.org/pdf/2411.02426v1,cs.LG
A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks,"The development of Internet of Things (IoT) technologies has led to the
widespread adoption of monitoring networks for a wide variety of applications,
such as smart cities, environmental monitoring, and precision agriculture. A
major research focus in recent years has been the development of graph-based
techniques to improve the quality of data from sensor networks, a key aspect
for the use of sensed data in decision-making processes, digital twins, and
other applications. Emphasis has been placed on the development of machine
learning and signal processing techniques over graphs, taking advantage of the
benefits provided by the use of structured data through a graph topology. Many
technologies such as the graph signal processing (GSP) or the successful graph
neural networks (GNNs) have been used for data quality enhancement tasks. In
this survey, we focus on graph-based models for data quality control in
monitoring sensor networks. Furthermore, we delve into the technical details
that are commonly leveraged for providing powerful graph-based solutions for
data quality tasks in sensor networks, including missing value imputation,
outlier detection, or virtual sensing. To conclude, we have identified future
trends and challenges such as graph-based models for digital twins or model
transferability and generalization.",2024-10-28,"Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal",http://arxiv.org/pdf/2410.21006v2,cs.LG
SepMamba: State-space models for speaker separation using Mamba,"Deep learning-based single-channel speaker separation has improved
significantly in recent years largely due to the introduction of the
transformer-based attention mechanism. However, these improvements come at the
expense of intense computational demands, precluding their use in many
practical applications. As a computationally efficient alternative with similar
modeling capabilities, Mamba was recently introduced. We propose SepMamba, a
U-Net-based architecture composed primarily of bidirectional Mamba layers. We
find that our approach outperforms similarly-sized prominent models - including
transformer-based models - on the WSJ0 2-speaker dataset while enjoying a
significant reduction in computational cost, memory usage, and forward pass
time. We additionally report strong results for causal variants of SepMamba.
Our approach provides a computationally favorable alternative to
transformer-based architectures for deep speech separation.",2024-10-28,"Thor Højhus Avenstrup, Boldizsár Elek, István László Mádi, András Bence Schin, Morten Mørup, Bjørn Sand Jensen, Kenny Falkær Olsen",http://arxiv.org/pdf/2410.20997v1,cs.LG
"Reference-Free Formula Drift with Reinforcement Learning: From Driving Data to Tire Energy-Inspired, Real-World Policies","The skill to drift a car--i.e., operate in a state of controlled oversteer
like professional drivers--could give future autonomous cars maximum
flexibility when they need to retain control in adverse conditions or avoid
collisions. We investigate real-time drifting strategies that put the car where
needed while bypassing expensive trajectory optimization. To this end, we
design a reinforcement learning agent that builds on the concept of tire energy
absorption to autonomously drift through changing and complex waypoint
configurations while safely staying within track bounds. We achieve zero-shot
deployment on the car by training the agent in a simulation environment built
on top of a neural stochastic differential equation vehicle model learned from
pre-collected driving data. Experiments on a Toyota GR Supra and Lexus LC 500
show that the agent is capable of drifting smoothly through varying waypoint
configurations with tracking error as low as 10 cm while stably pushing the
vehicles to sideslip angles of up to 63{\deg}.",2024-10-28,"Franck Djeumou, Michael Thompson, Makoto Suminaka, John Subosits",http://arxiv.org/pdf/2410.20990v1,cs.LG
LinFormer: A Linear-based Lightweight Transformer Architecture For Time-Aware MIMO Channel Prediction,"The emergence of 6th generation (6G) mobile networks brings new challenges in
supporting high-mobility communications, particularly in addressing the issue
of channel aging. While existing channel prediction methods offer improved
accuracy at the expense of increased computational complexity, limiting their
practical application in mobile networks. To address these challenges, we
present LinFormer, an innovative channel prediction framework based on a
scalable, all-linear, encoder-only Transformer model. Our approach, inspired by
natural language processing (NLP) models such as BERT, adapts an encoder-only
architecture specifically for channel prediction tasks. We propose replacing
the computationally intensive attention mechanism commonly used in Transformers
with a time-aware multi-layer perceptron (TMLP), significantly reducing
computational demands. The inherent time awareness of TMLP module makes it
particularly suitable for channel prediction tasks. We enhance LinFormer's
training process by employing a weighted mean squared error loss (WMSELoss)
function and data augmentation techniques, leveraging larger, readily available
communication datasets. Our approach achieves a substantial reduction in
computational complexity while maintaining high prediction accuracy, making it
more suitable for deployment in cost-effective base stations (BS).
Comprehensive experiments using both simulated and measured data demonstrate
that LinFormer outperforms existing methods across various mobility scenarios,
offering a promising solution for future wireless communication systems.",2024-10-28,"Yanliang Jin, Yifan Wu, Yuan Gao, Shunqing Zhang, Shugong Xu, Cheng-Xiang Wang",http://arxiv.org/pdf/2410.21351v1,cs.LG
A Semi-supervised CART Model for Covariate Shift,"Machine learning models used in medical applications often face challenges
due to the covariate shift, which occurs when there are discrepancies between
the distributions of training and target data. This can lead to decreased
predictive accuracy, especially with unknown outcomes in the target data. This
paper introduces a semi-supervised classification and regression tree (CART)
that uses importance weighting to address these distribution discrepancies. Our
method improves the predictive performance of the CART model by assigning
greater weights to training samples that more accurately represent the target
distribution, especially in cases of covariate shift without target outcomes.
In addition to CART, we extend this weighted approach to generalized linear
model trees and tree ensembles, creating a versatile framework for managing the
covariate shift in complex datasets. Through simulation studies and
applications to real-world medical data, we demonstrate significant
improvements in predictive accuracy. These findings suggest that our weighted
approach can enhance reliability in medical applications and other fields where
the covariate shift poses challenges to model performance across various data
distributions.",2024-10-28,"Mingyang Cai, Thomas Klausch, Mark A. van de Wiel",http://arxiv.org/pdf/2410.20978v2,cs.LG
Large Language Model-Guided Prediction Toward Quantum Materials Synthesis,"The synthesis of inorganic crystalline materials is essential for modern
technology, especially in quantum materials development. However, designing
efficient synthesis workflows remains a significant challenge due to the
precise experimental conditions and extensive trial and error. Here, we present
a framework using large language models (LLMs) to predict synthesis pathways
for inorganic materials, including quantum materials. Our framework contains
three models: LHS2RHS, predicting products from reactants; RHS2LHS, predicting
reactants from products; and TGT2CEQ, generating full chemical equations for
target compounds. Fine-tuned on a text-mined synthesis database, our model
raises accuracy from under 40% with pretrained models, to under 80% using
conventional fine-tuning, and further to around 90% with our proposed
generalized Tanimoto similarity, while maintaining robust to additional
synthesis steps. Our model further demonstrates comparable performance across
materials with varying degrees of quantumness quantified using quantum weight,
indicating that LLMs offer a powerful tool to predict balanced chemical
equations for quantum materials discovery.",2024-10-28,"Ryotaro Okabe, Zack West, Abhijatmedhi Chotrattanapituk, Mouyang Cheng, Denisse Córdova Carrizales, Weiwei Xie, Robert J. Cava, Mingda Li",http://arxiv.org/pdf/2410.20976v1,cs.LG
BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks,"In this paper, we focus on black-box defense for VLMs against jailbreak
attacks. Existing black-box defense methods are either unimodal or bimodal.
Unimodal methods enhance either the vision or language module of the VLM, while
bimodal methods robustify the model through text-image representation
realignment. However, these methods suffer from two limitations: 1) they fail
to fully exploit the cross-modal information, or 2) they degrade the model
performance on benign inputs. To address these limitations, we propose a novel
blue-team method BlueSuffix that defends target VLMs against jailbreak attacks
without compromising its performance under black-box setting. BlueSuffix
includes three key components: 1) a visual purifier against jailbreak images,
2) a textual purifier against jailbreak texts, and 3) a blue-team suffix
generator using reinforcement fine-tuning for enhancing cross-modal robustness.
We empirically show on four VLMs (LLaVA, MiniGPT-4, InstructionBLIP, and
Gemini) and four safety benchmarks (Harmful Instruction, AdvBench,
MM-SafetyBench, and RedTeam-2K) that BlueSuffix outperforms the baseline
defenses by a significant margin. Our BlueSuffix opens up a promising direction
for defending VLMs against jailbreak attacks. Code is available at
https://github.com/Vinsonzyh/BlueSuffix.",2024-10-28,"Yunhan Zhao, Xiang Zheng, Lin Luo, Yige Li, Xingjun Ma, Yu-Gang Jiang",http://arxiv.org/pdf/2410.20971v2,cs.LG
Simultaneous Unlearning of Multiple Protected User Attributes From Variational Autoencoder Recommenders Using Adversarial Training,"In widely used neural network-based collaborative filtering models, users'
history logs are encoded into latent embeddings that represent the users'
preferences. In this setting, the models are capable of mapping users'
protected attributes (e.g., gender or ethnicity) from these user embeddings
even without explicit access to them, resulting in models that may treat
specific demographic user groups unfairly and raise privacy issues. While prior
work has approached the removal of a single protected attribute of a user at a
time, multiple attributes might come into play in real-world scenarios. In the
work at hand, we present AdvXMultVAE which aims to unlearn multiple protected
attributes (exemplified by gender and age) simultaneously to improve fairness
across demographic user groups. For this purpose, we couple a variational
autoencoder (VAE) architecture with adversarial training (AdvMultVAE) to
support simultaneous removal of the users' protected attributes with continuous
and/or categorical values. Our experiments on two datasets, LFM-2b-100k and
Ml-1m, from the music and movie domains, respectively, show that our approach
can yield better results than its singular removal counterparts (based on
AdvMultVAE) in effectively mitigating demographic biases whilst improving the
anonymity of latent embeddings.",2024-10-28,"Gustavo Escobedo, Christian Ganhör, Stefan Brandl, Mirjam Augstein, Markus Schedl",http://arxiv.org/pdf/2410.20965v1,cs.LG
DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning,"Current techniques for detecting AI-generated text are largely confined to
manual feature crafting and supervised binary classification paradigms. These
methodologies typically lead to performance bottlenecks and unsatisfactory
generalizability. Consequently, these methods are often inapplicable for
out-of-distribution (OOD) data and newly emerged large language models (LLMs).
In this paper, we revisit the task of AI-generated text detection. We argue
that the key to accomplishing this task lies in distinguishing writing styles
of different authors, rather than simply classifying the text into
human-written or AI-generated text. To this end, we propose DeTeCtive, a
multi-task auxiliary, multi-level contrastive learning framework. DeTeCtive is
designed to facilitate the learning of distinct writing styles, combined with a
dense information retrieval pipeline for AI-generated text detection. Our
method is compatible with a range of text encoders. Extensive experiments
demonstrate that our method enhances the ability of various text encoders in
detecting AI-generated text across multiple benchmarks and achieves
state-of-the-art results. Notably, in OOD zero-shot evaluation, our method
outperforms existing approaches by a large margin. Moreover, we find our method
boasts a Training-Free Incremental Adaptation (TFIA) capability towards OOD
data, further enhancing its efficacy in OOD detection scenarios. We will
open-source our code and models in hopes that our work will spark new thoughts
in the field of AI-generated text detection, ensuring safe application of LLMs
and enhancing compliance. Our code is available at
https://github.com/heyongxin233/DeTeCtive.",2024-10-28,"Xun Guo, Shan Zhang, Yongxin He, Ting Zhang, Wanquan Feng, Haibin Huang, Chongyang Ma",http://arxiv.org/pdf/2410.20964v1,cs.LG
Neuro-symbolic Learning Yielding Logical Constraints,"Neuro-symbolic systems combine the abilities of neural perception and logical
reasoning. However, end-to-end learning of neuro-symbolic systems is still an
unsolved challenge. This paper proposes a natural framework that fuses neural
network training, symbol grounding, and logical constraint synthesis into a
coherent and efficient end-to-end learning process. The capability of this
framework comes from the improved interactions between the neural and the
symbolic parts of the system in both the training and inference stages.
Technically, to bridge the gap between the continuous neural network and the
discrete logical constraint, we introduce a difference-of-convex programming
technique to relax the logical constraints while maintaining their precision.
We also employ cardinality constraints as the language for logical constraint
learning and incorporate a trust region method to avoid the degeneracy of
logical constraint in learning. Both theoretical analyses and empirical
evaluations substantiate the effectiveness of the proposed framework.",2024-10-28,"Zenan Li, Yunpeng Huang, Zhaoyu Li, Yuan Yao, Jingwei Xu, Taolue Chen, Xiaoxing Ma, Jian Lu",http://arxiv.org/pdf/2410.20957v1,cs.LG
FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system,"Recently, large language models (LLMs) have achieved significant progress in
automated code generation. Despite their strong instruction-following
capabilities, these models frequently struggled to align with user intent in
coding scenarios. In particular, they were hampered by datasets that lacked
diversity and failed to address specialized tasks or edge cases. Furthermore,
challenges in supervised fine-tuning (SFT) and reinforcement learning from
human feedback (RLHF) led to failures in generating precise,
human-intent-aligned code. To tackle these challenges and improve the code
generation performance for automated programming systems, we propose
Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization
(i.e., FALCON). FALCON is structured into two hierarchical levels. From the
global level, long-term memory improves code quality by retaining and applying
learned knowledge. At the local level, short-term memory allows for the
incorporation of immediate feedback from compilers and AI systems.
Additionally, we introduce meta-reinforcement learning with feedback rewards to
solve the global-local bi-level optimization problem and enhance the model's
adaptability across diverse code generation tasks. Extensive experiments
demonstrate that our technique achieves state-of-the-art performance, leading
other reinforcement learning methods by more than 4.5 percentage points on the
MBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The
open-sourced code is publicly available at https://github.com/titurte/FALCON.",2024-10-28,"Zeyuan Li, Yangfan He, Lewei He, Jianhui Wang, Tianyu Shi, Bin Lei, Yuchen Li, Qiuwu Chen",http://arxiv.org/pdf/2410.21349v4,cs.LG
Neural Hamilton: Can A.I. Understand Hamiltonian Mechanics?,"We propose a novel framework based on neural network that reformulates
classical mechanics as an operator learning problem. A machine directly maps a
potential function to its corresponding trajectory in phase space without
solving the Hamilton equations. Most notably, while conventional methods tend
to accumulate errors over time through iterative time integration, our approach
prevents error propagation. Two newly developed neural network architectures,
namely VaRONet and MambONet, are introduced to adapt the Variational LSTM
sequence-to-sequence model and leverage the Mamba model for efficient temporal
dynamics processing. We tested our approach with various 1D physics problems:
harmonic oscillation, double-well potentials, Morse potential, and other
potential models outside the training data. Compared to traditional numerical
methods based on the fourth-order Runge-Kutta (RK4) algorithm, our model
demonstrates improved computational efficiency and accuracy.
  Code is available at: https://github.com/Axect/Neural_Hamilton",2024-10-28,"Tae-Geun Kim, Seong Chan Park",http://arxiv.org/pdf/2410.20951v1,cs.LG
FACTS: A Factored State-Space Framework For World Modelling,"World modelling is essential for understanding and predicting the dynamics of
complex systems by learning both spatial and temporal dependencies. However,
current frameworks, such as Transformers and selective state-space models like
Mambas, exhibit limitations in efficiently encoding spatial and temporal
structures, particularly in scenarios requiring long-term high-dimensional
sequence modelling. To address these issues, we propose a novel recurrent
framework, the \textbf{FACT}ored \textbf{S}tate-space (\textbf{FACTS}) model,
for spatial-temporal world modelling. The FACTS framework constructs a
graph-structured memory with a routing mechanism that learns permutable memory
representations, ensuring invariance to input permutations while adapting
through selective state-space propagation. Furthermore, FACTS supports parallel
computation of high-dimensional sequences. We empirically evaluate FACTS across
diverse tasks, including multivariate time series forecasting, object-centric
world modelling, and spatial-temporal graph prediction, demonstrating that it
consistently outperforms or matches specialised state-of-the-art models,
despite its general-purpose world modelling design.",2024-10-28,"Li Nanbo, Firas Laakom, Yucheng Xu, Wenyi Wang, Jürgen Schmidhuber",http://arxiv.org/pdf/2410.20922v2,cs.LG
Constrained Optimal Fuel Consumption of HEV:Considering the Observational Perturbation,"We assume accurate observation of battery state of charge (SOC) and precise
speed curves when addressing the constrained optimal fuel consumption (COFC)
problem via constrained reinforcement learning (CRL). However, in practice, SOC
measurements are often distorted by noise or confidentiality protocols, and
actual reference speeds may deviate from expectations. We aim to minimize fuel
consumption while maintaining SOC balance under observational perturbations in
SOC and speed. This work first worldwide uses seven training approaches to
solve the COFC problem under five types of perturbations, including one based
on a uniform distribution, one designed to maximize rewards, one aimed at
maximizing costs, and one along with its improved version that seeks to
decrease reward on Toyota Hybrid Systems (THS) under New European Driving Cycle
(NEDC) condition. The result verifies that the six can successfully solve the
COFC problem under observational perturbations, and we further compare the
robustness and safety of these training approaches and analyze their impact on
optimal fuel consumption.",2024-10-28,"Shuchang Yan, Haoran Sun",http://arxiv.org/pdf/2410.20913v1,cs.LG
Deep Recurrent Stochastic Configuration Networks for Modelling Nonlinear Dynamic Systems,"Deep learning techniques have shown promise in many domain applications. This
paper proposes a novel deep reservoir computing framework, termed deep
recurrent stochastic configuration network (DeepRSCN) for modelling nonlinear
dynamic systems. DeepRSCNs are incrementally constructed, with all reservoir
nodes directly linked to the final output. The random parameters are assigned
in the light of a supervisory mechanism, ensuring the universal approximation
property of the built model. The output weights are updated online using the
projection algorithm to handle the unknown dynamics. Given a set of training
samples, DeepRSCNs can quickly generate learning representations, which consist
of random basis functions with cascaded input and readout weights. Experimental
results over a time series prediction, a nonlinear system identification
problem, and two industrial data predictive analyses demonstrate that the
proposed DeepRSCN outperforms the single-layer network in terms of modelling
efficiency, learning capability, and generalization performance.",2024-10-28,"Gang Dang, Dianhui Wang",http://arxiv.org/pdf/2410.20904v1,cs.LG
Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models,"In this paper, we introduce the Diff-Instruct* (DI*), an image data-free
approach for building one-step text-to-image generative models that align with
human preference while maintaining the ability to generate highly realistic
images. We frame human preference alignment as online reinforcement learning
using human feedback (RLHF), where the goal is to maximize the reward function
while regularizing the generator distribution to remain close to a reference
diffusion process. Unlike traditional RLHF approaches, which rely on the KL
divergence for regularization, we introduce a novel score-based divergence
regularization, which leads to significantly better performances. Although the
direct calculation of this preference alignment objective remains intractable,
we demonstrate that we can efficiently compute its gradient by deriving an
equivalent yet tractable loss function. Remarkably, we used Diff-Instruct* to
train a Stable Diffusion-XL-based 1-step model, the 2.6B DI*-SDXL-1step
text-to-image model, which can generate images of a resolution of 1024x1024
with only 1 generation step. DI*-SDXL-1step model uses only 1.88% inference
time and 29.30% GPU memory cost to outperform 12B FLUX-dev-50step significantly
in PickScore, ImageReward, and CLIPScore on Parti prompt benchmark and HPSv2.1
on Human Preference Score benchmark, establishing a new state-of-the-art
benchmark of human-preferred 1-step text-to-image generative models. Besides
the strong quantitative performances, extensive qualitative comparisons also
confirm the advantages of DI* in terms of maintaining diversity, improving
image layouts, and enhancing aesthetic colors. We have released our
industry-ready model on the homepage:
\url{https://github.com/pkulwj1994/diff_instruct_star}.",2024-10-28,"Weijian Luo, Colin Zhang, Debing Zhang, Zhengyang Geng",http://arxiv.org/pdf/2410.20898v2,cs.LG
Active Causal Structure Learning with Latent Variables: Towards Learning to Detour in Autonomous Robots,"Artificial General Intelligence (AGI) Agents and Robots must be able to cope
with everchanging environments and tasks. They must be able to actively
construct new internal causal models of their interactions with the environment
when new structural changes take place in the environment. Thus, we claim that
active causal structure learning with latent variables (ACSLWL) is a necessary
component to build AGI agents and robots. This paper describes how a complex
planning and expectation-based detour behavior can be learned by ACSLWL when,
unexpectedly, and for the first time, the simulated robot encounters a sort of
transparent barrier in its pathway towards its target. ACSWL consists of acting
in the environment, discovering new causal relations, constructing new causal
models, exploiting the causal models to maximize its expected utility,
detecting possible latent variables when unexpected observations occur, and
constructing new structures-internal causal models and optimal estimation of
the associated parameters, to be able to cope efficiently with the new
encountered situations. That is, the agent must be able to construct new causal
internal models that transform a previously unexpected and inefficient
(sub-optimal) situation, into a predictable situation with an optimal operating
plan.",2024-10-28,"Pablo de los Riscos, Fernando Corbacho",http://arxiv.org/pdf/2410.20894v1,cs.LG
Generative Example-Based Explanations: Bridging the Gap between Generative Modeling and Explainability,"Recently, several methods have leveraged deep generative modeling to produce
example-based explanations of decision algorithms for high-dimensional input
data. Despite promising results, a disconnect exists between these methods and
the classical explainability literature, which focuses on lower-dimensional
data with semantically meaningful features. This conceptual and communication
gap leads to misunderstandings and misalignments in goals and expectations. In
this paper, we bridge this gap by proposing a novel probabilistic framework for
local example-based explanations. Our framework integrates the critical
characteristics of classical local explanation desiderata while being amenable
to high-dimensional data and their modeling through deep generative models. Our
aim is to facilitate communication, foster rigor and transparency, and improve
the quality of peer discussion and research progress.",2024-10-28,"Philipp Vaeth, Alexander M. Fruehwald, Benjamin Paassen, Magda Gregorova",http://arxiv.org/pdf/2410.20890v1,cs.LG
CODES: Benchmarking Coupled ODE Surrogates,"We introduce CODES, a benchmark for comprehensive evaluation of surrogate
architectures for coupled ODE systems. Besides standard metrics like mean
squared error (MSE) and inference time, CODES provides insights into surrogate
behaviour across multiple dimensions like interpolation, extrapolation, sparse
data, uncertainty quantification and gradient correlation. The benchmark
emphasizes usability through features such as integrated parallel training, a
web-based configuration generator, and pre-implemented baseline models and
datasets. Extensive documentation ensures sustainability and provides the
foundation for collaborative improvement. By offering a fair and multi-faceted
comparison, CODES helps researchers select the most suitable surrogate for
their specific dataset and application while deepening our understanding of
surrogate learning behaviour.",2024-10-28,"Robin Janssen, Immanuel Sulzer, Tobias Buck",http://arxiv.org/pdf/2410.20886v2,cs.LG
Similarity-based context aware continual learning for spiking neural networks,"Biological brains have the capability to adaptively coordinate relevant
neuronal populations based on the task context to learn continuously changing
tasks in real-world environments. However, existing spiking neural
network-based continual learning algorithms treat each task equally, ignoring
the guiding role of different task similarity associations for network
learning, which limits knowledge utilization efficiency. Inspired by the
context-dependent plasticity mechanism of the brain, we propose a
Similarity-based Context Aware Spiking Neural Network (SCA-SNN) continual
learning algorithm to efficiently accomplish task incremental learning and
class incremental learning. Based on contextual similarity across tasks, the
SCA-SNN model can adaptively reuse neurons from previous tasks that are
beneficial for new tasks (the more similar, the more neurons are reused) and
flexibly expand new neurons for the new task (the more similar, the fewer
neurons are expanded). Selective reuse and discriminative expansion
significantly improve the utilization of previous knowledge and reduce energy
consumption. Extensive experimental results on CIFAR100, ImageNet generalized
datasets, and FMNIST-MNIST, SVHN-CIFAR100 mixed datasets show that our SCA-SNN
model achieves superior performance compared to both SNN-based and DNN-based
continual learning algorithms. Additionally, our algorithm has the capability
to adaptively select similar groups of neurons for related tasks, offering a
promising approach to enhancing the biological interpretability of efficient
continual learning.",2024-10-28,"Bing Han, Feifei Zhao, Yang Li, Qingqun Kong, Xianqi Li, Yi Zeng",http://arxiv.org/pdf/2411.05802v1,cs.LG
Towards Trustworthy Machine Learning in Production: An Overview of the Robustness in MLOps Approach,"Artificial intelligence (AI), and especially its sub-field of Machine
Learning (ML), are impacting the daily lives of everyone with their ubiquitous
applications. In recent years, AI researchers and practitioners have introduced
principles and guidelines to build systems that make reliable and trustworthy
decisions. From a practical perspective, conventional ML systems process
historical data to extract the features that are consequently used to train ML
models that perform the desired task. However, in practice, a fundamental
challenge arises when the system needs to be operationalized and deployed to
evolve and operate in real-life environments continuously. To address this
challenge, Machine Learning Operations (MLOps) have emerged as a potential
recipe for standardizing ML solutions in deployment. Although MLOps
demonstrated great success in streamlining ML processes, thoroughly defining
the specifications of robust MLOps approaches remains of great interest to
researchers and practitioners. In this paper, we provide a comprehensive
overview of the trustworthiness property of MLOps systems. Specifically, we
highlight technical practices to achieve robust MLOps systems. In addition, we
survey the existing research approaches that address the robustness aspects of
ML systems in production. We also review the tools and software available to
build MLOps systems and summarize their support to handle the robustness
aspects. Finally, we present the open challenges and propose possible future
directions and opportunities within this emerging field. The aim of this paper
is to provide researchers and practitioners working on practical AI
applications with a comprehensive view to adopt robust ML solutions in
production environments.",2024-10-28,"Firas Bayram, Bestoun S. Ahmed",http://arxiv.org/pdf/2410.21346v1,cs.LG
Strada-LLM: Graph LLM for traffic prediction,"Traffic prediction is a vital component of intelligent transportation
systems. By reasoning about traffic patterns in both the spatial and temporal
dimensions, accurate and interpretable predictions can be provided. A
considerable challenge in traffic prediction lies in handling the diverse data
distributions caused by vastly different traffic conditions occurring at
different locations. LLMs have been a dominant solution due to their remarkable
capacity to adapt to new datasets with very few labeled data samples, i.e.,
few-shot adaptability. However, existing forecasting techniques mainly focus on
extracting local graph information and forming a text-like prompt, leaving LLM-
based traffic prediction an open problem. This work presents a probabilistic
LLM for traffic forecasting with three highlights. We propose a graph-aware LLM
for traffic prediction that considers proximal traffic information.
Specifically, by considering the traffic of neighboring nodes as covariates,
our model outperforms the corresponding time-series LLM. Furthermore, we adopt
a lightweight approach for efficient domain adaptation when facing new data
distributions in few-shot fashion. The comparative experiment demonstrates the
proposed method outperforms the state-of-the-art LLM-based methods and the
traditional GNN- based supervised approaches. Furthermore, Strada-LLM can be
easily adapted to different LLM backbones without a noticeable performance
drop.",2024-10-28,"Seyed Mohamad Moghadas, Yangxintong Lyu, Bruno Cornelis, Alexandre Alahi, Adrian Munteanu",http://arxiv.org/pdf/2410.20856v2,cs.LG
On Probabilistic Pullback Metrics for Latent Hyperbolic Manifolds,"Probabilistic Latent Variable Models (LVMs) excel at modeling complex,
high-dimensional data through lower-dimensional representations. Recent
advances show that equipping these latent representations with a Riemannian
metric unlocks geometry-aware distances and shortest paths that comply with the
underlying data structure. This paper focuses on hyperbolic embeddings, a
particularly suitable choice for modeling hierarchical relationships. Previous
approaches relying on hyperbolic geodesics for interpolating the latent space
often generate paths crossing low-data regions, leading to highly uncertain
predictions. Instead, we propose augmenting the hyperbolic manifold with a
pullback metric to account for distortions introduced by the LVM's nonlinear
mapping and provide a complete development for pullback metrics of Gaussian
Process LVMs (GPLVMs). Our experiments demonstrate that geodesics on the
pullback metric not only respect the geometry of the hyperbolic latent space
but also align with the underlying data distribution, significantly reducing
uncertainty in predictions.",2024-10-28,"Luis Augenstein, Noémie Jaquier, Tamim Asfour, Leonel Rozo",http://arxiv.org/pdf/2410.20850v3,cs.LG
Asteroid Mining: ACT&Friends' Results for the GTOC 12 Problem,"In 2023, the 12th edition of Global Trajectory Competition was organised
around the problem referred to as ""Sustainable Asteroid Mining"". This paper
reports the developments that led to the solution proposed by ESA's Advanced
Concepts Team. Beyond the fact that the proposed approach failed to rank higher
than fourth in the final competition leader-board, several innovative
fundamental methodologies were developed which have a broader application. In
particular, new methods based on machine learning as well as on manipulating
the fundamental laws of astrodynamics were developed and able to fill with
remarkable accuracy the gap between full low-thrust trajectories and their
representation as impulsive Lambert transfers. A novel technique was devised to
formulate the challenge of optimal subset selection from a repository of
pre-existing optimal mining trajectories as an integer linear programming
problem. Finally, the fundamental problem of searching for single optimal
mining trajectories (mining and collecting all resources), albeit ignoring the
possibility of having intra-ship collaboration and thus sub-optimal in the case
of the GTOC12 problem, was efficiently solved by means of a novel search based
on a look-ahead score and thus making sure to select asteroids that had chances
to be re-visited later on.",2024-10-28,"Dario Izzo, Marcus Märtens, Laurent Beauregard, Max Bannach, Giacomo Acciarini, Emmanuel Blazquez, Alexander Hadjiivanov, Jai Grover, Gernot Heißel, Yuri Shimane, Chit Hong Yam",http://arxiv.org/pdf/2410.20839v1,cs.LG
FreqMark: Invisible Image Watermarking via Frequency Based Optimization in Latent Space,"Invisible watermarking is essential for safeguarding digital content,
enabling copyright protection and content authentication. However, existing
watermarking methods fall short in robustness against regeneration attacks. In
this paper, we propose a novel method called FreqMark that involves
unconstrained optimization of the image latent frequency space obtained after
VAE encoding. Specifically, FreqMark embeds the watermark by optimizing the
latent frequency space of the images and then extracts the watermark through a
pre-trained image encoder. This optimization allows a flexible trade-off
between image quality with watermark robustness and effectively resists
regeneration attacks. Experimental results demonstrate that FreqMark offers
significant advantages in image quality and robustness, permits flexible
selection of the encoding bit number, and achieves a bit accuracy exceeding 90%
when encoding a 48-bit hidden message under various attack scenarios.",2024-10-28,"Yiyang Guo, Ruizhe Li, Mude Hui, Hanzhong Guo, Chen Zhang, Chuangjian Cai, Le Wan, Shangfei Wang",http://arxiv.org/pdf/2410.20824v1,cs.LG
Temporal Streaming Batch Principal Component Analysis for Time Series Classification,"In multivariate time series classification, although current sequence
analysis models have excellent classification capabilities, they show
significant shortcomings when dealing with long sequence multivariate data,
such as prolonged training times and decreased accuracy. This paper focuses on
optimizing model performance for long-sequence multivariate data by mitigating
the impact of extended time series and multiple variables on the model. We
propose a principal component analysis (PCA)-based temporal streaming
compression and dimensionality reduction algorithm for time series data
(temporal streaming batch PCA, TSBPCA), which continuously updates the compact
representation of the entire sequence through streaming PCA time estimation
with time block updates, enhancing the data representation capability of a
range of sequence analysis models. We evaluated this method using various
models on five real datasets, and the experimental results show that our method
performs well in terms of classification accuracy and time efficiency. Notably,
our method demonstrates a trend of increasing effectiveness as sequence length
grows; on the two longest sequence datasets, accuracy improved by about 7.2%,
and execution time decreased by 49.5%.",2024-10-28,"Enshuo Yan, Huachuan Wang, Weihao Xia",http://arxiv.org/pdf/2410.20820v1,cs.LG
CycleResearcher: Improving Automated Research via Automated Review,"The automation of scientific discovery has been a long-standing goal within
the research community, driven by the potential to accelerate knowledge
creation. While significant progress has been made using commercial large
language models (LLMs) as research assistants or idea generators, the
possibility of automating the entire research process with open-source LLMs
remains largely unexplored. This paper explores the feasibility of using
open-source post-trained LLMs as autonomous agents capable of performing the
full cycle of automated research and review, from literature review and
manuscript preparation to peer review and paper refinement. Our iterative
preference training framework consists of CycleResearcher, which conducts
research tasks, and CycleReviewer, which simulates the peer review process,
providing iterative feedback via reinforcement learning. To train these models,
we develop two new datasets, Review-5k and Research-14k, reflecting real-world
machine learning research and peer review dynamics. Our results demonstrate
that CycleReviewer achieves promising performance with a 26.89\% reduction in
mean absolute error (MAE) compared to individual human reviewers in predicting
paper scores, indicating the potential of LLMs to effectively assist
expert-level research evaluation. In research, the papers generated by the
CycleResearcher model achieved a score of 5.36 in simulated peer reviews,
showing some competitiveness in terms of simulated review scores compared to
the preprint level of 5.24 from human experts, while still having room for
improvement compared to the accepted paper level of 5.69. This work represents
a significant step toward fully automated scientific inquiry, providing ethical
safeguards and exploring AI-driven research capabilities. The code, dataset and
model weight are released at https://wengsyx.github.io/Researcher/.",2024-10-28,"Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, Linyi Yang",http://arxiv.org/pdf/2411.00816v3,cs.LG
Fidelity-Imposed Displacement Editing for the Learn2Reg 2024 SHG-BF Challenge,"Co-examination of second-harmonic generation (SHG) and bright-field (BF)
microscopy enables the differentiation of tissue components and collagen
fibers, aiding the analysis of human breast and pancreatic cancer tissues.
However, large discrepancies between SHG and BF images pose challenges for
current learning-based registration models in aligning SHG to BF. In this
paper, we propose a novel multi-modal registration framework that employs
fidelity-imposed displacement editing to address these challenges. The
framework integrates batch-wise contrastive learning, feature-based
pre-alignment, and instance-level optimization. Experimental results from the
Learn2Reg COMULISglobe SHG-BF Challenge validate the effectiveness of our
method, securing the 1st place on the online leaderboard.",2024-10-28,"Jiacheng Wang, Xiang Chen, Renjiu Hu, Rongguang Wang, Jiazheng Wang, Min Liu, Yaonan Wang, Hang Zhang",http://arxiv.org/pdf/2410.20812v3,cs.LG
Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation,"Deep learning-based expert models have reached superhuman performance in
decision-making domains such as chess and Go. However, it is under-explored to
explain or comment on given decisions although it is important for model
explainability and human education. The outputs of expert models are accurate,
but yet difficult to interpret for humans. On the other hand, large language
models (LLMs) can produce fluent commentary but are prone to hallucinations due
to their limited decision-making capabilities. To bridge this gap between
expert models and LLMs, we focus on chess commentary as a representative task
of explaining complex decision-making processes through language and address
both the generation and evaluation of commentary. We introduce Concept-guided
Chess Commentary generation (CCC) for producing commentary and GPT-based Chess
Commentary Evaluation (GCC-Eval) for assessing it. CCC integrates the
decision-making strengths of expert models with the linguistic fluency of LLMs
through prioritized, concept-based explanations. GCC-Eval leverages expert
knowledge to evaluate chess commentary based on informativeness and linguistic
quality. Experimental results, validated by both human judges and GCC-Eval,
demonstrate that CCC generates commentary which is accurate, informative, and
fluent.",2024-10-28,"Jaechang Kim, Jinmin Goh, Inseok Hwang, Jaewoong Cho, Jungseul Ok",http://arxiv.org/pdf/2410.20811v2,cs.LG
zGAN: An Outlier-focused Generative Adversarial Network For Realistic Synthetic Data Generation,"The phenomenon of ""black swans"" has posed a fundamental challenge to
performance of classical machine learning models. The perceived rise in
frequency of outlier conditions, especially in post-pandemic environment, has
necessitated exploration of synthetic data as a complement to real data in
model training. This article provides a general overview and experimental
investigation of the zGAN model architecture developed for the purpose of
generating synthetic tabular data with outlier characteristics. The model is
put to test in binary classification environments and shows promising results
on realistic synthetic data generation, as well as uplift capabilities
vis-\`a-vis model performance. A distinctive feature of zGAN is its enhanced
correlation capability between features in the generated data, replicating
correlations of features in real training data. Furthermore, crucial is the
ability of zGAN to generate outliers based on covariance of real data or
synthetically generated covariances. This approach to outlier generation
enables modeling of complex economic events and augmentation of outliers for
tasks such as training predictive models and detecting, processing or removing
outliers. Experiments and comparative analyses as part of this study were
conducted on both private (credit risk in financial services) and public
datasets.",2024-10-28,"Azizjon Azimi, Bonu Boboeva, Ilyas Varshavskiy, Shuhrat Khalilbekov, Akhlitdin Nizamitdinov, Najima Noyoftova, Sergey Shulgin",http://arxiv.org/pdf/2410.20808v2,cs.LG
Reduction-based Pseudo-label Generation for Instance-dependent Partial Label Learning,"Instance-dependent Partial Label Learning (ID-PLL) aims to learn a
multi-class predictive model given training instances annotated with candidate
labels related to features, among which correct labels are hidden fixed but
unknown. The previous works involve leveraging the identification capability of
the training model itself to iteratively refine supervision information.
However, these methods overlook a critical aspect of ID-PLL: the training model
is prone to overfitting on incorrect candidate labels, thereby providing poor
supervision information and creating a bottleneck in training. In this paper,
we propose to leverage reduction-based pseudo-labels to alleviate the influence
of incorrect candidate labels and train our predictive model to overcome this
bottleneck. Specifically, reduction-based pseudo-labels are generated by
performing weighted aggregation on the outputs of a multi-branch auxiliary
model, with each branch trained in a label subspace that excludes certain
labels. This approach ensures that each branch explicitly avoids the
disturbance of the excluded labels, allowing the pseudo-labels provided for
instances troubled by these excluded labels to benefit from the unaffected
branches. Theoretically, we demonstrate that reduction-based pseudo-labels
exhibit greater consistency with the Bayes optimal classifier compared to
pseudo-labels directly generated from the predictive model.",2024-10-28,"Congyu Qiao, Ning Xu, Yihao Hu, Xin Geng",http://arxiv.org/pdf/2410.20797v1,cs.LG
Can EEG resting state data benefit data-driven approaches for motor-imagery decoding?,"Resting-state EEG data in neuroscience research serve as reliable markers for
user identification and reveal individual-specific traits. Despite this, the
use of resting-state data in EEG classification models is limited. In this
work, we propose a feature concatenation approach to enhance decoding models'
generalization by integrating resting-state EEG, aiming to improve motor
imagery BCI performance and develop a user-generalized model. Using feature
concatenation, we combine the EEGNet model, a standard convolutional neural
network for EEG signal classification, with functional connectivity measures
derived from resting-state EEG data. The findings suggest that although
grounded in neuroscience with data-driven learning, the concatenation approach
has limited benefits for generalizing models in within-user and across-user
scenarios. While an improvement in mean accuracy for within-user scenarios is
observed on two datasets, concatenation doesn't benefit across-user scenarios
when compared with random data concatenation. The findings indicate the
necessity of further investigation on the model interpretability and the effect
of random data concatenation on model robustness.",2024-10-28,"Rishan Mehta, Param Rajpura, Yogesh Kumar Meena",http://arxiv.org/pdf/2411.09789v1,cs.LG
Deep Learning for Medical Text Processing: BERT Model Fine-Tuning and Comparative Study,"This paper proposes a medical literature summary generation method based on
the BERT model to address the challenges brought by the current explosion of
medical information. By fine-tuning and optimizing the BERT model, we develop
an efficient summary generation system that can quickly extract key information
from medical literature and generate coherent, accurate summaries. In the
experiment, we compared various models, including Seq-Seq, Attention,
Transformer, and BERT, and demonstrated that the improved BERT model offers
significant advantages in the Rouge and Recall metrics. Furthermore, the
results of this study highlight the potential of knowledge distillation
techniques to further enhance model performance. The system has demonstrated
strong versatility and efficiency in practical applications, offering a
reliable tool for the rapid screening and analysis of medical literature.",2024-10-28,"Jiacheng Hu, Yiru Cang, Guiran Liu, Meiqi Wang, Weijie He, Runyuan Bao",http://arxiv.org/pdf/2410.20792v1,cs.LG
SCULPT: Systematic Tuning of Long Prompts,"Prompt optimization is essential for effective utilization of large language
models (LLMs) across diverse tasks. While existing optimization methods are
effective in optimizing short prompts, they struggle with longer, more complex
ones, often risking information loss and being sensitive to small
perturbations. To address these challenges, we propose SCULPT (Systematic
Tuning of Long Prompts), a framework that treats prompt optimization as a
hierarchical tree refinement problem. SCULPT represents prompts as tree
structures, enabling targeted modifications while preserving contextual
integrity. It employs a Critic-Actor framework that generates reflections and
applies actions to refine the prompt. Evaluations demonstrate SCULPT's
effectiveness on long prompts, its robustness to adversarial perturbations, and
its ability to generate high-performing prompts even without any initial
human-written prompt. Compared to existing state of the art methods, SCULPT
consistently improves LLM performance by preserving essential task information
while applying structured refinements. Both qualitative and quantitative
analyses show that SCULPT produces more stable and interpretable prompt
modifications, ensuring better generalization across tasks.",2024-10-28,"Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta",http://arxiv.org/pdf/2410.20788v2,cs.LG
Adversarial Constrained Policy Optimization: Improving Constrained Reinforcement Learning by Adapting Budgets,"Constrained reinforcement learning has achieved promising progress in
safety-critical fields where both rewards and constraints are considered.
However, constrained reinforcement learning methods face challenges in striking
the right balance between task performance and constraint satisfaction and it
is prone for them to get stuck in over-conservative or constraint violating
local minima. In this paper, we propose Adversarial Constrained Policy
Optimization (ACPO), which enables simultaneous optimization of reward and the
adaptation of cost budgets during training. Our approach divides original
constrained problem into two adversarial stages that are solved alternately,
and the policy update performance of our algorithm can be theoretically
guaranteed. We validate our method through experiments conducted on Safety
Gymnasium and quadruped locomotion tasks. Results demonstrate that our
algorithm achieves better performances compared to commonly used baselines.",2024-10-28,"Jianmina Ma, Jingtian Ji, Yue Gao",http://arxiv.org/pdf/2410.20786v1,cs.LG
Absorb & Escape: Overcoming Single Model Limitations in Generating Genomic Sequences,"Abstract Recent advances in immunology and synthetic biology have accelerated
the development of deep generative methods for DNA sequence design. Two
dominant approaches in this field are AutoRegressive (AR) models and Diffusion
Models (DMs). However, genomic sequences are functionally heterogeneous,
consisting of multiple connected regions (e.g., Promoter Regions, Exons, and
Introns) where elements within each region come from the same probability
distribution, but the overall sequence is non-homogeneous. This heterogeneous
nature presents challenges for a single model to accurately generate genomic
sequences. In this paper, we analyze the properties of AR models and DMs in
heterogeneous genomic sequence generation, pointing out crucial limitations in
both methods: (i) AR models capture the underlying distribution of data by
factorizing and learning the transition probability but fail to capture the
global property of DNA sequences. (ii) DMs learn to recover the global
distribution but tend to produce errors at the base pair level. To overcome the
limitations of both approaches, we propose a post-training sampling method,
termed Absorb & Escape (A&E) to perform compositional generation from AR models
and DMs. This approach starts with samples generated by DMs and refines the
sample quality using an AR model through the alternation of the Absorb and
Escape steps. To assess the quality of generated sequences, we conduct
extensive experiments on 15 species for conditional and unconditional DNA
generation. The experiment results from motif distribution, diversity checks,
and genome integration tests unequivocally show that A&E outperforms
state-of-the-art AR models and DMs in genomic sequence generation.",2024-10-28,"Zehui Li, Yuhao Ni, Guoxuan Xia, William Beardall, Akashaditya Das, Guy-Bart Stan, Yiren Zhao",http://arxiv.org/pdf/2410.21345v1,cs.LG
Graph-based Uncertainty Metrics for Long-form Language Model Outputs,"Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.",2024-10-28,"Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto",http://arxiv.org/pdf/2410.20783v1,cs.LG
Scaling-based Data Augmentation for Generative Models and its Theoretical Extension,"This paper studies stable learning methods for generative models that enable
high-quality data generation. Noise injection is commonly used to stabilize
learning. However, selecting a suitable noise distribution is challenging.
Diffusion-GAN, a recently developed method, addresses this by using the
diffusion process with a timestep-dependent discriminator. We investigate
Diffusion-GAN and reveal that data scaling is a key component for stable
learning and high-quality data generation. Building on our findings, we propose
a learning algorithm, Scale-GAN, that uses data scaling and variance-based
regularization. Furthermore, we theoretically prove that data scaling controls
the bias-variance trade-off of the estimation error bound. As a theoretical
extension, we consider GAN with invertible data augmentations. Comparative
evaluations on benchmark datasets demonstrate the effectiveness of our method
in improving stability and accuracy.",2024-10-28,"Yoshitaka Koike, Takumi Nakagawa, Hiroki Waida, Takafumi Kanamori",http://arxiv.org/pdf/2410.20780v1,cs.LG
KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation,"Large language models (LLMs) have demonstrated remarkable performance across
various downstream tasks. However, the high computational and memory
requirements of LLMs are a major bottleneck. To address this,
parameter-efficient fine-tuning (PEFT) methods such as low-rank adaptation
(LoRA) have been proposed to reduce computational costs while ensuring minimal
loss in performance. Additionally, knowledge distillation (KD) has been a
popular choice for obtaining compact student models from teacher models. In
this work, we present KD-LoRA, a novel fine-tuning method that combines LoRA
with KD. Our results demonstrate that KD-LoRA achieves performance comparable
to full fine-tuning (FFT) and LoRA while significantly reducing resource
requirements. Specifically, KD-LoRA retains 98% of LoRA's performance on the
GLUE benchmark, while being 40% more compact. Additionally, KD-LoRA reduces GPU
memory usage by 30% compared to LoRA, while decreasing inference time by 30%
compared to both FFT and LoRA. We evaluate KD-LoRA across three encoder-only
models: BERT, RoBERTa, and DeBERTaV3. Code is available at
https://github.com/rambodazimi/KD-LoRA.",2024-10-28,"Rambod Azimi, Rishav Rishav, Marek Teichmann, Samira Ebrahimi Kahou",http://arxiv.org/pdf/2410.20777v1,cs.LG
Combining Incomplete Observational and Randomized Data for Heterogeneous Treatment Effects,"Data from observational studies (OSs) is widely available and readily
obtainable yet frequently contains confounding biases. On the other hand, data
derived from randomized controlled trials (RCTs) helps to reduce these biases;
however, it is expensive to gather, resulting in a tiny size of randomized
data. For this reason, effectively fusing observational data and randomized
data to better estimate heterogeneous treatment effects (HTEs) has gained
increasing attention. However, existing methods for integrating observational
data with randomized data must require \textit{complete} observational data,
meaning that both treated subjects and untreated subjects must be included in
OSs. This prerequisite confines the applicability of such methods to very
specific situations, given that including all subjects, whether treated or
untreated, in observational studies is not consistently achievable. In our
paper, we propose a resilient approach to \textbf{C}ombine \textbf{I}ncomplete
\textbf{O}bservational data and randomized data for HTE estimation, which we
abbreviate as \textbf{CIO}. The CIO is capable of estimating HTEs efficiently
regardless of the completeness of the observational data, be it full or
partial. Concretely, a confounding bias function is first derived using the
pseudo-experimental group from OSs, in conjunction with the pseudo-control
group from RCTs, via an effect estimation procedure. This function is
subsequently utilized as a corrective residual to rectify the observed outcomes
of observational data during the HTE estimation by combining the available
observational data and the all randomized data. To validate our approach, we
have conducted experiments on a synthetic dataset and two semi-synthetic
datasets.",2024-10-28,"Dong Yao, Caizhi Tang, Qing Cui, Longfei Li",http://arxiv.org/pdf/2410.21343v1,cs.LG
An Ensemble Approach to Music Source Separation: A Comparative Analysis of Conventional and Hierarchical Stem Separation,"Music source separation (MSS) is a task that involves isolating individual
sound sources, or stems, from mixed audio signals. This paper presents an
ensemble approach to MSS, combining several state-of-the-art architectures to
achieve superior separation performance across traditional Vocal, Drum, and
Bass (VDB) stems, as well as expanding into second-level hierarchical
separation for sub-stems like kick, snare, lead vocals, and background vocals.
Our method addresses the limitations of relying on a single model by utilising
the complementary strengths of various models, leading to more balanced results
across stems. For stem selection, we used the harmonic mean of Signal-to-Noise
Ratio (SNR) and Signal-to-Distortion Ratio (SDR), ensuring that extreme values
do not skew the results and that both metrics are weighted effectively. In
addition to consistently high performance across the VDB stems, we also
explored second-level hierarchical separation, revealing important insights
into the complexities of MSS and how factors like genre and instrumentation can
influence model performance. While the second-level separation results show
room for improvement, the ability to isolate sub-stems marks a significant
advancement. Our findings pave the way for further research in MSS,
particularly in expanding model capabilities beyond VDB and improving niche
stem separations such as guitar and piano.",2024-10-28,"Saarth Vardhan, Pavani R Acharya, Samarth S Rao, Oorjitha Ratna Jasthi, S Natarajan",http://arxiv.org/pdf/2410.20773v1,cs.LG
Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting,"Sequence modeling faces challenges in capturing long-range dependencies
across diverse tasks. Recent linear and transformer-based forecasters have
shown superior performance in time series forecasting. However, they are
constrained by their inherent inability to effectively address long-range
dependencies in time series data, primarily due to using fixed-size inputs for
prediction. Furthermore, they typically sacrifice essential temporal
correlation among consecutive training samples by shuffling them into
mini-batches. To overcome these limitations, we introduce a fast and effective
Spectral Attention mechanism, which preserves temporal correlations among
samples and facilitates the handling of long-range information while
maintaining the base model structure. Spectral Attention preserves long-period
trends through a low-pass filter and facilitates gradient to flow between
samples. Spectral Attention can be seamlessly integrated into most sequence
models, allowing models with fixed-sized look-back windows to capture
long-range dependencies over thousands of steps. Through extensive experiments
on 11 real-world time series datasets using 7 recent forecasting models, we
consistently demonstrate the efficacy of our Spectral Attention mechanism,
achieving state-of-the-art results.",2024-10-28,"Bong Gyun Kang, Dongjun Lee, HyunGi Kim, DoHyun Chung, Sungroh Yoon",http://arxiv.org/pdf/2410.20772v3,cs.LG
MrT5: Dynamic Token Merging for Efficient Byte-level Language Models,"Models that rely on subword tokenization have significant drawbacks, such as
sensitivity to character-level noise like spelling errors and inconsistent
compression rates across different languages and scripts. While character- or
byte-level models like ByT5 attempt to address these concerns, they have not
gained widespread adoption -- processing raw byte streams without tokenization
results in significantly longer sequence lengths, making training and inference
inefficient. This work introduces MrT5 (MergeT5), a more efficient variant of
ByT5 that integrates a token deletion mechanism in its encoder to dynamically
shorten the input sequence length. After processing through a fixed number of
encoder layers, a learned delete gate determines which tokens are to be removed
and which are to be retained for subsequent layers. MrT5 effectively ""merges""
critical information from deleted tokens into a more compact sequence,
leveraging contextual information from the remaining tokens. In continued
pre-training experiments, we find that MrT5 can achieve significant gains in
inference runtime with minimal effect on performance, as measured by
bits-per-byte. Additionally, with multilingual training, MrT5 adapts to the
orthographic characteristics of each language, learning language-specific
compression rates. Furthermore, MrT5 shows comparable accuracy to ByT5 on
downstream evaluations such as XNLI, TyDi QA, and character-level tasks while
reducing sequence lengths by up to 75%. Our approach presents a solution to the
practical limitations of existing byte-level models.",2024-10-28,"Julie Kallini, Shikhar Murty, Christopher D. Manning, Christopher Potts, Róbert Csordás",http://arxiv.org/pdf/2410.20771v3,cs.LG
Task Confusion and Catastrophic Forgetting in Class-Incremental Learning: A Mathematical Framework for Discriminative and Generative Modelings,"In class-incremental learning (class-IL), models must classify all previously
seen classes at test time without task-IDs, leading to task confusion. Despite
being a key challenge, task confusion lacks a theoretical understanding. We
present a novel mathematical framework for class-IL and prove the Infeasibility
Theorem, showing optimal class-IL is impossible with discriminative modeling
due to task confusion. However, we establish the Feasibility Theorem,
demonstrating that generative modeling can achieve optimal class-IL by
overcoming task confusion. We then assess popular class-IL strategies,
including regularization, bias-correction, replay, and generative classifier,
using our framework. Our analysis suggests that adopting generative modeling,
either for generative replay or direct classification (generative classifier),
is essential for optimal class-IL.",2024-10-28,"Milad Khademi Nori, Il-Min Kim",http://arxiv.org/pdf/2410.20768v1,cs.LG
Robust Estimation for Kernel Exponential Families with Smoothed Total Variation Distances,"In statistical inference, we commonly assume that samples are independent and
identically distributed from a probability distribution included in a
pre-specified statistical model. However, such an assumption is often violated
in practice. Even an unexpected extreme sample called an {\it outlier} can
significantly impact classical estimators. Robust statistics studies how to
construct reliable statistical methods that efficiently work even when the
ideal assumption is violated. Recently, some works revealed that robust
estimators such as Tukey's median are well approximated by the generative
adversarial net (GAN), a popular learning method for complex generative models
using neural networks. GAN is regarded as a learning method using integral
probability metrics (IPM), which is a discrepancy measure for probability
distributions. In most theoretical analyses of Tukey's median and its GAN-based
approximation, however, the Gaussian or elliptical distribution is assumed as
the statistical model. In this paper, we explore the application of GAN-like
estimators to a general class of statistical models. As the statistical model,
we consider the kernel exponential family that includes both finite and
infinite-dimensional models. To construct a robust estimator, we propose the
smoothed total variation (STV) distance as a class of IPMs. Then, we
theoretically investigate the robustness properties of the STV-based
estimators. Our analysis reveals that the STV-based estimator is robust against
the distribution contamination for the kernel exponential family. Furthermore,
we analyze the prediction accuracy of a Monte Carlo approximation method, which
circumvents the computational difficulty of the normalization constant.",2024-10-28,"Takafumi Kanamori, Kodai Yokoyama, Takayuki Kawashima",http://arxiv.org/pdf/2410.20760v1,cs.LG
Likelihood approximations via Gaussian approximate inference,"Non-Gaussian likelihoods are essential for modelling complex real-world
observations but pose significant computational challenges in learning and
inference. Even with Gaussian priors, non-Gaussian likelihoods often lead to
analytically intractable posteriors, necessitating approximation methods. To
this end, we propose efficient schemes to approximate the effects of
non-Gaussian likelihoods by Gaussian densities based on variational inference
and moment matching in transformed bases. These enable efficient inference
strategies originally designed for models with a Gaussian likelihood to be
deployed. Our empirical results demonstrate that the proposed matching
strategies attain good approximation quality for binary and multiclass
classification in large-scale point-estimate and distributional inferential
settings. In challenging streaming problems, the proposed methods outperform
all existing likelihood approximations and approximate inference methods in the
exact models. As a by-product, we show that the proposed approximate
log-likelihoods are a superior alternative to least-squares on raw labels for
neural network classification.",2024-10-28,Thang D. Bui,http://arxiv.org/pdf/2410.20754v1,cs.LG
Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation,"We introduce Plan*RAG, a novel framework that enables structured multi-hop
reasoning in retrieval-augmented generation (RAG) through test-time reasoning
plan generation. While existing approaches such as ReAct maintain reasoning
chains within the language model's context window, we observe that this often
leads to plan fragmentation and execution failures. Our key insight is that by
isolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's
working memory, we can enable (1) systematic exploration of reasoning paths,
(2) atomic subqueries enabling precise retrievals and grounding, and (3)
efficiency through parallel execution and bounded context window utilization.
Moreover, Plan*RAG's modular design allows it to be integrated with existing
RAG methods, thus providing a practical solution to improve current RAG
systems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently
achieves improvements over recently proposed methods such as RQ-RAG and
Self-RAG, while maintaining comparable computational costs.",2024-10-28,"Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma",http://arxiv.org/pdf/2410.20753v2,cs.LG
ODRL: A Benchmark for Off-Dynamics Reinforcement Learning,"We consider off-dynamics reinforcement learning (RL) where one needs to
transfer policies across different domains with dynamics mismatch. Despite the
focus on developing dynamics-aware algorithms, this field is hindered due to
the lack of a standard benchmark. To bridge this gap, we introduce ODRL, the
first benchmark tailored for evaluating off-dynamics RL methods. ODRL contains
four experimental settings where the source and target domains can be either
online or offline, and provides diverse tasks and a broad spectrum of dynamics
shifts, making it a reliable platform to comprehensively evaluate the agent's
adaptation ability to the target domain. Furthermore, ODRL includes recent
off-dynamics RL algorithms in a unified framework and introduces some extra
baselines for different settings, all implemented in a single-file manner. To
unpack the true adaptation capability of existing methods, we conduct extensive
benchmarking experiments, which show that no method has universal advantages
across varied dynamics shifts. We hope this benchmark can serve as a
cornerstone for future research endeavors. Our code is publicly available at
https://github.com/OffDynamicsRL/off-dynamics-rl.",2024-10-28,"Jiafei Lyu, Kang Xu, Jiacheng Xu, Mengbei Yan, Jingwen Yang, Zongzhang Zhang, Chenjia Bai, Zongqing Lu, Xiu Li",http://arxiv.org/pdf/2410.20750v1,cs.LG
Matryoshka: Learning to Drive Black-Box LLMs with LLMs,"Despite the impressive generative abilities of black-box large language
models (LLMs), their inherent opacity hinders further advancements in
capabilities such as reasoning, planning, and personalization. Existing works
aim to enhance LLM capabilities via domain-specific adaptation or in-context
learning, which require additional training on accessible model parameters, an
infeasible option for black-box LLMs. To address this challenge, we introduce
Matryoshika, a lightweight white-box LLM controller that guides a large-scale
black-box LLM generator by decomposing complex tasks into a series of
intermediate outputs. Specifically, we consider the black-box LLM as an
environment, with Matryoshika serving as a policy to provide intermediate
guidance through prompts for driving the black-box LLM. Matryoshika is trained
to pivot the outputs of the black-box LLM aligning with preferences during
iterative interaction, which enables controllable multi-turn generation and
self-improvement in optimizing intermediate guidance. Empirical evaluations on
three diverse tasks demonstrate that Matryoshika effectively enhances the
capabilities of black-box LLMs in complex, long-horizon tasks, including
reasoning, planning, and personalization. By leveraging this pioneering
controller-generator framework to mitigate dependence on model parameters,
Matryoshika provides a transparent and practical solution for improving
black-box LLMs through controllable multi-turn generation using white-box LLMs.",2024-10-28,"Changhao Li, Yuchen Zhuang, Rushi Qiang, Haotian Sun, Hanjun Dai, Chao Zhang, Bo Dai",http://arxiv.org/pdf/2410.20749v1,cs.LG
Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models,"Online shopping is a complex multi-task, few-shot learning problem with a
wide and evolving range of entities, relations, and tasks. However, existing
models and benchmarks are commonly tailored to specific tasks, falling short of
capturing the full complexity of online shopping. Large Language Models (LLMs),
with their multi-task and few-shot learning abilities, have the potential to
profoundly transform online shopping by alleviating task-specific engineering
efforts and by providing users with interactive conversations. Despite the
potential, LLMs face unique challenges in online shopping, such as
domain-specific concepts, implicit knowledge, and heterogeneous user behaviors.
Motivated by the potential and challenges, we propose Shopping MMLU, a diverse
multi-task online shopping benchmark derived from real-world Amazon data.
Shopping MMLU consists of 57 tasks covering 4 major shopping skills: concept
understanding, knowledge reasoning, user behavior alignment, and
multi-linguality, and can thus comprehensively evaluate the abilities of LLMs
as general shop assistants. With Shopping MMLU, we benchmark over 20 existing
LLMs and uncover valuable insights about practices and prospects of building
versatile LLM-based shop assistants. Shopping MMLU can be publicly accessed at
https://github.com/KL4805/ShoppingMMLU. In addition, with Shopping MMLU, we
host a competition in KDD Cup 2024 with over 500 participating teams. The
winning solutions and the associated workshop can be accessed at our website
https://amazon-kddcup24.github.io/.",2024-10-28,"Yilun Jin, Zheng Li, Chenwei Zhang, Tianyu Cao, Yifan Gao, Pratik Jayarao, Mao Li, Xin Liu, Ritesh Sarkhel, Xianfeng Tang, Haodong Wang, Zhengyang Wang, Wenju Xu, Jingfeng Yang, Qingyu Yin, Xian Li, Priyanka Nigam, Yi Xu, Kai Chen, Qiang Yang, Meng Jiang, Bing Yin",http://arxiv.org/pdf/2410.20745v2,cs.LG
Mitigating Unauthorized Speech Synthesis for Voice Protection,"With just a few speech samples, it is possible to perfectly replicate a
speaker's voice in recent years, while malicious voice exploitation (e.g.,
telecom fraud for illegal financial gain) has brought huge hazards in our daily
lives. Therefore, it is crucial to protect publicly accessible speech data that
contains sensitive information, such as personal voiceprints. Most previous
defense methods have focused on spoofing speaker verification systems in timbre
similarity but the synthesized deepfake speech is still of high quality. In
response to the rising hazards, we devise an effective, transferable, and
robust proactive protection technology named Pivotal Objective Perturbation
(POP) that applies imperceptible error-minimizing noises on original speech
samples to prevent them from being effectively learned for text-to-speech (TTS)
synthesis models so that high-quality deepfake speeches cannot be generated. We
conduct extensive experiments on state-of-the-art (SOTA) TTS models utilizing
objective and subjective metrics to comprehensively evaluate our proposed
method. The experimental results demonstrate outstanding effectiveness and
transferability across various models. Compared to the speech unclarity score
of 21.94% from voice synthesizers trained on samples without protection,
POP-protected samples significantly increase it to 127.31%. Moreover, our
method shows robustness against noise reduction and data augmentation
techniques, thereby greatly reducing potential hazards.",2024-10-28,"Zhisheng Zhang, Qianyi Yang, Derui Wang, Pengyang Huang, Yuxin Cao, Kai Ye, Jie Hao",http://arxiv.org/pdf/2410.20742v1,cs.LG
Faster WIND: Accelerating Iterative Best-of-$N$ Distillation for LLM Alignment,"Recent advances in aligning large language models with human preferences have
corroborated the growing importance of best-of-N distillation (BOND). However,
the iterative BOND algorithm is prohibitively expensive in practice due to the
sample and computation inefficiency. This paper addresses the problem by
revealing a unified game-theoretic connection between iterative BOND and
self-play alignment, which unifies seemingly disparate algorithmic paradigms.
Based on the connection, we establish a novel framework, WIN rate Dominance
(WIND), with a series of efficient algorithms for regularized win rate
dominance optimization that approximates iterative BOND in the parameter space.
We provides provable sample efficiency guarantee for one of the WIND variant
with the square loss objective. The experimental results confirm that our
algorithm not only accelerates the computation, but also achieves superior
sample efficiency compared to existing methods.",2024-10-28,"Tong Yang, Jincheng Mei, Hanjun Dai, Zixin Wen, Shicong Cen, Dale Schuurmans, Yuejie Chi, Bo Dai",http://arxiv.org/pdf/2410.20727v2,cs.LG
Simple Is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation,"Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.",2024-10-28,"Mufei Li, Siqi Miao, Pan Li",http://arxiv.org/pdf/2410.20724v4,cs.LG
Retrieval-Retro: Retrieval-based Inorganic Retrosynthesis with Expert Knowledge,"While inorganic retrosynthesis planning is essential in the field of chemical
science, the application of machine learning in this area has been notably less
explored compared to organic retrosynthesis planning. In this paper, we propose
Retrieval-Retro for inorganic retrosynthesis planning, which implicitly
extracts the precursor information of reference materials that are retrieved
from the knowledge base regarding domain expertise in the field. Specifically,
instead of directly employing the precursor information of reference materials,
we propose implicitly extracting it with various attention layers, which
enables the model to learn novel synthesis recipes more effectively. Moreover,
during retrieval, we consider the thermodynamic relationship between target
material and precursors, which is essential domain expertise in identifying the
most probable precursor set among various options. Extensive experiments
demonstrate the superiority of Retrieval-Retro in retrosynthesis planning,
especially in discovering novel synthesis recipes, which is crucial for
materials discovery. The source code for Retrieval-Retro is available at
https://github.com/HeewoongNoh/Retrieval-Retro.",2024-10-28,"Heewoong Noh, Namkyeong Lee, Gyoung S. Na, Chanyoung Park",http://arxiv.org/pdf/2410.21341v1,cs.LG
Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments,"The deployment of large-scale models, such as large language models (LLMs)
and sophisticated image generation systems, incurs substantial costs due to
their computational demands. To mitigate these costs and address challenges
related to scalability and data security, there is a growing shift towards
decentralized systems for deploying such models. In these decentralized
environments, efficient inference acceleration becomes crucial to manage
computational resources effectively and enhance system responsiveness. In this
work, we address the challenge of selecting optimal acceleration methods in
decentralized systems by introducing a meta-learning-based framework. This
framework automates the selection process by learning from historical
performance data of various acceleration techniques across different tasks.
Unlike traditional methods that rely on random selection or expert intuition,
our approach systematically identifies the best acceleration strategies based
on the specific characteristics of each task. We demonstrate that our
meta-learning framework not only streamlines the decision-making process but
also consistently outperforms conventional methods in terms of efficiency and
performance. Our results highlight the potential of meta-learning to
revolutionize inference acceleration in decentralized AI systems, offering a
path towards more democratic and economically feasible artificial intelligence
solutions.",2024-10-28,"Yuzhe Yang, Yipeng Du, Ahmad Farhan, Claudio Angione, Yue Zhao, Harry Yang, Fielding Johnston, James Buban, Patrick Colangelo",http://arxiv.org/pdf/2410.21340v1,cs.LG
Contextual Representation Anchor Network to Alleviate Selection Bias in Few-Shot Drug Discovery,"In the drug discovery process, the low success rate of drug candidate
screening often leads to insufficient labeled data, causing the few-shot
learning problem in molecular property prediction. Existing methods for
few-shot molecular property prediction overlook the sample selection bias,
which arises from non-random sample selection in chemical experiments. This
bias in data representativeness leads to suboptimal performance. To overcome
this challenge, we present a novel method named contextual representation
anchor Network (CRA), where an anchor refers to a cluster center of the
representations of molecules and serves as a bridge to transfer enriched
contextual knowledge into molecular representations and enhance their
expressiveness. CRA introduces a dual-augmentation mechanism that includes
context augmentation, which dynamically retrieves analogous unlabeled molecules
and captures their task-specific contextual knowledge to enhance the anchors,
and anchor augmentation, which leverages the anchors to augment the molecular
representations. We evaluate our approach on the MoleculeNet and FS-Mol
benchmarks, as well as in domain transfer experiments. The results demonstrate
that CRA outperforms the state-of-the-art by 2.60% and 3.28% in AUC and
$\Delta$AUC-PR metrics, respectively, and exhibits superior generalization
capabilities.",2024-10-28,"Ruifeng Li, Wei Liu, Xiangxin Zhou, Mingqian Li, Qiang Zhang, Hongyang Chen, Xuemin Lin",http://arxiv.org/pdf/2410.20711v2,cs.LG
Reprogramming Pretrained Target-Specific Diffusion Models for Dual-Target Drug Design,"Dual-target therapeutic strategies have become a compelling approach and
attracted significant attention due to various benefits, such as their
potential in overcoming drug resistance in cancer therapy. Considering the
tremendous success that deep generative models have achieved in structure-based
drug design in recent years, we formulate dual-target drug design as a
generative task and curate a novel dataset of potential target pairs based on
synergistic drug combinations. We propose to design dual-target drugs with
diffusion models that are trained on single-target protein-ligand complex
pairs. Specifically, we align two pockets in 3D space with protein-ligand
binding priors and build two complex graphs with shared ligand nodes for
SE(3)-equivariant composed message passing, based on which we derive a composed
drift in both 3D and categorical probability space in the generative process.
Our algorithm can well transfer the knowledge gained in single-target
pretraining to dual-target scenarios in a zero-shot manner. We also repurpose
linker design methods as strong baselines for this task. Extensive experiments
demonstrate the effectiveness of our method compared with various baselines.",2024-10-28,"Xiangxin Zhou, Jiaqi Guan, Yijia Zhang, Xingang Peng, Liang Wang, Jianzhu Ma",http://arxiv.org/pdf/2410.20688v2,cs.LG
FedCVD: The First Real-World Federated Learning Benchmark on Cardiovascular Disease Data,"Cardiovascular diseases (CVDs) are currently the leading cause of death
worldwide, highlighting the critical need for early diagnosis and treatment.
Machine learning (ML) methods can help diagnose CVDs early, but their
performance relies on access to substantial data with high quality. However,
the sensitive nature of healthcare data often restricts individual clinical
institutions from sharing data to train sufficiently generalized and unbiased
ML models. Federated Learning (FL) is an emerging approach, which offers a
promising solution by enabling collaborative model training across multiple
participants without compromising the privacy of the individual data owners.
However, to the best of our knowledge, there has been limited prior research
applying FL to the cardiovascular disease domain. Moreover, existing FL
benchmarks and datasets are typically simulated and may fall short of
replicating the complexity of natural heterogeneity found in realistic datasets
that challenges current FL algorithms. To address these gaps, this paper
presents the first real-world FL benchmark for cardiovascular disease
detection, named FedCVD. This benchmark comprises two major tasks:
electrocardiogram (ECG) classification and echocardiogram (ECHO) segmentation,
based on naturally scattered datasets constructed from the CVD data of seven
institutions. Our extensive experiments on these datasets reveal that FL faces
new challenges with real-world non-IID and long-tail data. The code and
datasets of FedCVD are available https://github.com/SMILELab-FL/FedCVD.",2024-10-28,"Yukun Zhang, Guanzhong Chen, Zenglin Xu, Jianyong Wang, Dun Zeng, Junfan Li, Jinghua Wang, Yuan Qi, Irwin King",http://arxiv.org/pdf/2411.07050v1,cs.LG
Relaxed Recursive Transformers: Effective Parameter Sharing with Layer-wise LoRA,"Large language models (LLMs) are expensive to deploy. Parameter sharing
offers a possible path towards reducing their size and cost, but its
effectiveness in modern LLMs remains fairly limited. In this work, we revisit
""layer tying"" as form of parameter sharing in Transformers, and introduce novel
methods for converting existing LLMs into smaller ""Recursive Transformers"" that
share parameters across layers, with minimal loss of performance. Here, our
Recursive Transformers are efficiently initialized from standard pretrained
Transformers, but only use a single block of unique layers that is then
repeated multiple times in a loop. We further improve performance by
introducing Relaxed Recursive Transformers that add flexibility to the layer
tying constraint via depth-wise low-rank adaptation (LoRA) modules, yet still
preserve the compactness of the overall model. We show that our recursive
models (e.g., recursive Gemma 1B) outperform both similar-sized vanilla
pretrained models (such as TinyLlama 1.1B and Pythia 1B) and knowledge
distillation baselines -- and can even recover most of the performance of the
original ""full-size"" model (e.g., Gemma 2B with no shared parameters). Finally,
we propose Continuous Depth-wise Batching, a promising new inference paradigm
enabled by the Recursive Transformer when paired with early exiting. In a
theoretical analysis, we show that this has the potential to lead to
significant (2-3x) gains in inference throughput.",2024-10-28,"Sangmin Bae, Adam Fisch, Hrayr Harutyunyan, Ziwei Ji, Seungyeon Kim, Tal Schuster",http://arxiv.org/pdf/2410.20672v3,cs.LG
Segmenting Watermarked Texts From Language Models,"Watermarking is a technique that involves embedding nearly unnoticeable
statistical signals within generated content to help trace its source. This
work focuses on a scenario where an untrusted third-party user sends prompts to
a trusted language model (LLM) provider, who then generates a text from their
LLM with a watermark. This setup makes it possible for a detector to later
identify the source of the text if the user publishes it. The user can modify
the generated text by substitutions, insertions, or deletions. Our objective is
to develop a statistical method to detect if a published text is LLM-generated
from the perspective of a detector. We further propose a methodology to segment
the published text into watermarked and non-watermarked sub-strings. The
proposed approach is built upon randomization tests and change point detection
techniques. We demonstrate that our method ensures Type I and Type II error
control and can accurately identify watermarked sub-strings by finding the
corresponding change point locations. To validate our technique, we apply it to
texts generated by several language models with prompts extracted from Google's
C4 dataset and obtain encouraging numerical results. We release all code
publicly at https://github.com/doccstat/llm-watermark-cpd.",2024-10-28,"Xingchi Li, Guanxun Li, Xianyang Zhang",http://arxiv.org/pdf/2410.20670v1,cs.LG
TurboHopp: Accelerated Molecule Scaffold Hopping with Consistency Models,"Navigating the vast chemical space of druggable compounds is a formidable
challenge in drug discovery, where generative models are increasingly employed
to identify viable candidates. Conditional 3D structure-based drug design
(3D-SBDD) models, which take into account complex three-dimensional
interactions and molecular geometries, are particularly promising. Scaffold
hopping is an efficient strategy that facilitates the identification of similar
active compounds by strategically modifying the core structure of molecules,
effectively narrowing the wide chemical space and enhancing the discovery of
drug-like products. However, the practical application of 3D-SBDD generative
models is hampered by their slow processing speeds. To address this bottleneck,
we introduce TurboHopp, an accelerated pocket-conditioned 3D scaffold hopping
model that merges the strategic effectiveness of traditional scaffold hopping
with rapid generation capabilities of consistency models. This synergy not only
enhances efficiency but also significantly boosts generation speeds, achieving
up to 30 times faster inference speed as well as superior generation quality
compared to existing diffusion-based models, establishing TurboHopp as a
powerful tool in drug discovery. Supported by faster inference speed, we
further optimize our model, using Reinforcement Learning for Consistency Models
(RLCM), to output desirable molecules. We demonstrate the broad applicability
of TurboHopp across multiple drug discovery scenarios, underscoring its
potential in diverse molecular settings.",2024-10-28,"Kiwoong Yoo, Owen Oertell, Junhyun Lee, Sanghoon Lee, Jaewoo Kang",http://arxiv.org/pdf/2410.20660v2,cs.LG
A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data,"Federated Learning (FL) has emerged as a groundbreaking paradigm in
collaborative machine learning, emphasizing decentralized model training to
address data privacy concerns. While significant progress has been made in
optimizing federated learning, the exploration of generalization error,
particularly in heterogeneous settings, has been limited, focusing mainly on
parametric cases. This paper investigates the generalization properties of deep
federated regression within a two-stage sampling model. Our findings highlight
that the intrinsic dimension, defined by the entropic dimension, is crucial for
determining convergence rates when appropriate network sizes are used.
Specifically, if the true relationship between response and explanatory
variables is charecterized by a $\beta$-H\""older function and there are $n$
independent and identically distributed (i.i.d.) samples from $m$ participating
clients, the error rate for participating clients scales at most as
$\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$,
and for non-participating clients, it scales as $\tilde{O}\left(\Delta \cdot
m^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta +
\bar{d}_{2\beta}(\lambda))}\right)$. Here, $\bar{d}_{2\beta}(\lambda)$
represents the $2\beta$-entropic dimension of $\lambda$, the marginal
distribution of the explanatory variables, and $\Delta$ characterizes the
dependence between the sampling stages. Our results explicitly account for the
""closeness"" of clients, demonstrating that the convergence rates of deep
federated learners depend on intrinsic rather than nominal high-dimensionality.",2024-10-28,"Saptarshi Chakraborty, Peter L. Bartlett",http://arxiv.org/pdf/2410.20659v1,cs.LG
Video to Video Generative Adversarial Network for Few-shot Learning Based on Policy Gradient,"The development of sophisticated models for video-to-video synthesis has been
facilitated by recent advances in deep reinforcement learning and generative
adversarial networks (GANs). In this paper, we propose RL-V2V-GAN, a new deep
neural network approach based on reinforcement learning for unsupervised
conditional video-to-video synthesis. While preserving the unique style of the
source video domain, our approach aims to learn a mapping from a source video
domain to a target video domain. We train the model using policy gradient and
employ ConvLSTM layers to capture the spatial and temporal information by
designing a fine-grained GAN architecture and incorporating spatio-temporal
adversarial goals. The adversarial losses aid in content translation while
preserving style. Unlike traditional video-to-video synthesis methods requiring
paired inputs, our proposed approach is more general because it does not
require paired inputs. Thus, when dealing with limited videos in the target
domain, i.e., few-shot learning, it is particularly effective. Our experiments
show that RL-V2V-GAN can produce temporally coherent video results. These
results highlight the potential of our approach for further advances in
video-to-video synthesis.",2024-10-28,"Yintai Ma, Diego Klabjan, Jean Utke",http://arxiv.org/pdf/2410.20657v1,cs.LG
NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks,"The performance of neural networks improves when more parameters are used.
However, the model sizes are constrained by the available on-device memory
during training and inference. Although applying techniques like quantization
can alleviate the constraint, they suffer from performance degradation. In this
work, we introduce NeuZip, a new weight compression scheme based on the entropy
of floating-point numbers in neural networks. With NeuZip, we are able to
achieve memory-efficient training and inference without sacrificing
performance. Notably, we significantly reduce the memory footprint of training
a Llama-3 8B model from 31GB to less than 16GB, while keeping the training
dynamics fully unchanged. In inference, our method can reduce memory usage by
more than half while maintaining near-lossless performance. Our code is
publicly available.",2024-10-28,"Yongchang Hao, Yanshuai Cao, Lili Mou",http://arxiv.org/pdf/2410.20650v1,cs.LG
Learning Variational Inequalities from Data: Fast Generalization Rates under Strong Monotonicity,"Variational inequalities (VIs) are a broad class of optimization problems
encompassing machine learning problems ranging from standard convex
minimization to more complex scenarios like min-max optimization and computing
the equilibria of multi-player games. In convex optimization, strong convexity
allows for fast statistical learning rates requiring only $\Theta(1/\epsilon)$
stochastic first-order oracle calls to find an $\epsilon$-optimal solution,
rather than the standard $\Theta(1/\epsilon^2)$ calls. This note provides a
simple overview of how one can similarly obtain fast $\Theta(1/\epsilon)$ rates
for learning VIs that satisfy strong monotonicity, a generalization of strong
convexity. Specifically, we demonstrate that standard stability-based
generalization arguments for convex minimization extend directly to VIs when
the domain admits a small covering, or when the operator is integrable and
suboptimality is measured by potential functions; such as when finding
equilibria in multi-player games.",2024-10-28,"Eric Zhao, Tatjana Chavdarova, Michael Jordan",http://arxiv.org/pdf/2410.20649v3,cs.LG
Machine Learning and Quantum Intelligence for Health Data Scenarios,"The advent of quantum computing has opened new possibilities in data science,
offering unique capabilities for addressing complex, data-intensive problems.
Traditional machine learning algorithms often face challenges in
high-dimensional or limited-quality datasets, which are common in healthcare.
Quantum Machine Learning leverages quantum properties, such as superposition
and entanglement, to enhance pattern recognition and classification,
potentially surpassing classical approaches. This paper explores QML's
application in healthcare, focusing on quantum kernel methods and hybrid
quantum-classical networks for heart disease prediction and COVID-19 detection,
assessing their feasibility and performance.",2024-10-28,Sanjeev Naguleswaran,http://arxiv.org/pdf/2410.21339v1,cs.LG
General Causal Imputation via Synthetic Interventions,"Given two sets of elements (such as cell types and drug compounds),
researchers typically only have access to a limited subset of their
interactions. The task of causal imputation involves using this subset to
predict unobserved interactions. Squires et al. (2022) have proposed two
estimators for this task based on the synthetic interventions (SI) estimator:
SI-A (for actions) and SI-C (for contexts). We extend their work and introduce
a novel causal imputation estimator, generalized synthetic interventions (GSI).
We prove the identifiability of this estimator for data generated from a more
complex latent factor model. On synthetic and real data we show empirically
that it recovers or outperforms their estimators.",2024-10-28,"Marco Jiralerspong, Thomas Jiralerspong, Vedant Shah, Dhanya Sridhar, Gauthier Gidel",http://arxiv.org/pdf/2410.20647v1,cs.LG
Injectivity capacity of ReLU gates,"We consider the injectivity property of the ReLU networks layers. Determining
the ReLU injectivity capacity (ratio of the number of layer's inputs and
outputs) is established as isomorphic to determining the capacity of the
so-called $\ell_0$ spherical perceptron. Employing \emph{fully lifted random
duality theory} (fl RDT) a powerful program is developed and utilized to handle
the $\ell_0$ spherical perceptron and implicitly the ReLU layers injectivity.
To put the entire fl RDT machinery in practical use, a sizeable set of
numerical evaluations is conducted as well. The lifting mechanism is observed
to converge remarkably fast with relative corrections in the estimated
quantities not exceeding $\sim 0.1\%$ already on the third level of lifting.
Closed form explicit analytical relations among key lifting parameters are
uncovered as well. In addition to being of incredible importance in handling
all the required numerical work, these relations also shed a new light on
beautiful parametric interconnections within the lifting structure. Finally,
the obtained results are also shown to fairly closely match the replica
predictions from [40].",2024-10-28,Mihailo Stojnic,http://arxiv.org/pdf/2410.20646v1,cs.LG
FinTeamExperts: Role Specialized MOEs For Financial Analysis,"Large Language Models (LLMs), such as ChatGPT, Phi3 and Llama-3, are leading
a significant leap in AI, as they can generalize knowledge from their training
to new tasks without fine-tuning. However, their application in the financial
domain remains relatively limited. The financial field is inherently complex,
requiring a deep understanding across various perspectives, from macro, micro
economic trend to quantitative analysis. Motivated by this complexity, a
mixture of expert LLMs tailored to specific financial domains could offer a
more comprehensive understanding for intricate financial tasks. In this paper,
we present the FinTeamExperts, a role-specialized LLM framework structured as a
Mixture of Experts (MOEs) for financial analysis. The framework simulates a
collaborative team setting by training each model to specialize in distinct
roles: Macro Analysts, Micro analysts, and Quantitative Analysts. This
role-specific specialization enhances the model's ability to integrate their
domain-specific expertise. We achieve this by training three 8-billion
parameter models on different corpus, each dedicated to excelling in specific
finance-related roles. We then instruct-tune FinTeamExperts on downstream tasks
to align with practical financial tasks. The experimental results show that
FinTeamExperts outperform all models of the same size and larger on three out
of four datasets. On the fourth dataset, which presents a more complex task,
FinTeamExperts still surpass all models of the same size. This highlights the
success of our role-based specialization approach and the continued training
approach for FinTeamExperts.",2024-10-28,"Yue Yu, Prayag Tiwari",http://arxiv.org/pdf/2410.21338v2,cs.LG
Near Optimal Pure Exploration in Logistic Bandits,"Bandit algorithms have garnered significant attention due to their practical
applications in real-world scenarios. However, beyond simple settings such as
multi-arm or linear bandits, optimal algorithms remain scarce. Notably, no
optimal solution exists for pure exploration problems in the context of
generalized linear model (GLM) bandits. In this paper, we narrow this gap and
develop the first track-and-stop algorithm for general pure exploration
problems under the logistic bandit called logistic track-and-stop (Log-TS).
Log-TS is an efficient algorithm that asymptotically matches an approximation
for the instance-specific lower bound of the expected sample complexity up to a
logarithmic factor.",2024-10-28,"Eduardo Ochoa Rivera, Ambuj Tewari",http://arxiv.org/pdf/2410.20640v2,cs.LG
Plastic Learning with Deep Fourier Features,"Deep neural networks can struggle to learn continually in the face of
non-stationarity. This phenomenon is known as loss of plasticity. In this
paper, we identify underlying principles that lead to plastic algorithms. In
particular, we provide theoretical results showing that linear function
approximation, as well as a special case of deep linear networks, do not suffer
from loss of plasticity. We then propose deep Fourier features, which are the
concatenation of a sine and cosine in every layer, and we show that this
combination provides a dynamic balance between the trainability obtained
through linearity and the effectiveness obtained through the nonlinearity of
neural networks. Deep networks composed entirely of deep Fourier features are
highly trainable and sustain their trainability over the course of learning.
Our empirical results show that continual learning performance can be
drastically improved by replacing ReLU activations with deep Fourier features.
These results hold for different continual learning scenarios (e.g., label
noise, class incremental learning, pixel permutations) on all major supervised
learning datasets used for continual learning research, such as CIFAR10,
CIFAR100, and tiny-ImageNet.",2024-10-27,"Alex Lewandowski, Dale Schuurmans, Marlos C. Machado",http://arxiv.org/pdf/2410.20634v1,cs.LG
Network scaling and scale-driven loss balancing for intelligent poroelastography,"A deep learning framework is developed for multiscale characterization of
poroelastic media from full waveform data which is known as poroelastography.
Special attention is paid to heterogeneous environments whose multiphase
properties may drastically change across several scales. Described in
space-frequency, the data takes the form of focal solid displacement and pore
pressure fields in various neighborhoods furnished either by reconstruction
from remote data or direct measurements depending on the application. The
objective is to simultaneously recover the six hydromechanical properties
germane to Biot equations and their spatial distribution in a robust and
efficient manner. Two major challenges impede direct application of existing
state-of-the-art techniques for this purpose: (i) the sought-for properties
belong to vastly different and potentially uncertain scales, and~(ii) the loss
function is multi-objective and multi-scale (both in terms of its individual
components and the total loss). To help bridge the gap, we propose the idea of
\emph{network scaling} where the neural property maps are constructed by unit
shape functions composed into a scaling layer. In this model, the unknown
network parameters (weights and biases) remain of O(1) during training. This
forms the basis for explicit scaling of the loss components and their
derivatives with respect to the network parameters. Thereby, we propose the
physics-based \emph{dynamic scaling} approach for adaptive loss balancing. The
idea is first presented in a generic form for multi-physics and multi-scale PDE
systems, and then applied through a set of numerical experiments to
poroelastography. The results are presented along with reconstructions by way
of gradient normalization (GradNorm) and Softmax adaptive weights (SoftAdapt)
for loss balancing. A comparative analysis of the methods and corresponding
results is provided.",2024-10-27,"Yang Xu, Fatemeh Pourahmadian",http://arxiv.org/pdf/2411.08886v1,cs.LG
TabDiff: a Mixed-type Diffusion Model for Tabular Data Generation,"Synthesizing high-quality tabular data is an important topic in many data
science tasks, ranging from dataset augmentation to privacy protection.
However, developing expressive generative models for tabular data is
challenging due to its inherent heterogeneous data types, complex
inter-correlations, and intricate column-wise distributions. In this paper, we
introduce TabDiff, a joint diffusion framework that models all mixed-type
distributions of tabular data in one model. Our key innovation is the
development of a joint continuous-time diffusion process for numerical and
categorical data, where we propose feature-wise learnable diffusion processes
to counter the high disparity of different feature distributions. TabDiff is
parameterized by a transformer handling different input types, and the entire
framework can be efficiently optimized in an end-to-end fashion. We further
introduce a mixed-type stochastic sampler to automatically correct the
accumulated decoding error during sampling, and propose classifier-free
guidance for conditional missing column value imputation. Comprehensive
experiments on seven datasets demonstrate that TabDiff achieves superior
average performance over existing competitive baselines across all eight
metrics, with up to $22.5\%$ improvement over the state-of-the-art model on
pair-wise column correlation estimations. Code is available at
https://github.com/MinkaiXu/TabDiff.",2024-10-27,"Juntong Shi, Minkai Xu, Harper Hua, Hengrui Zhang, Stefano Ermon, Jure Leskovec",http://arxiv.org/pdf/2410.20626v3,cs.LG
LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization,"Low-rank adaption (LoRA) is a widely used parameter-efficient finetuning
method for LLM that reduces memory requirements. However, current LoRA
optimizers lack transformation invariance, meaning the actual updates to the
weights depends on how the two LoRA factors are scaled or rotated. This
deficiency leads to inefficient learning and sub-optimal solutions in practice.
This paper introduces LoRA-RITE, a novel adaptive matrix preconditioning method
for LoRA optimization, which can achieve transformation invariance and remain
computationally efficient. We provide theoretical analysis to demonstrate the
benefit of our method and conduct experiments on various LLM tasks with
different models including Gemma 2B, 7B, and mT5-XXL. The results demonstrate
consistent improvements against existing optimizers. For example, replacing
Adam with LoRA-RITE during LoRA fine-tuning of Gemma-2B yielded 4.6\% accuracy
gain on Super-Natural Instructions and 3.5\% accuracy gain across other four
LLM benchmarks (HellaSwag, ArcChallenge, GSM8K, OpenBookQA).",2024-10-27,"Jui-Nan Yen, Si Si, Zhao Meng, Felix Yu, Sai Surya Duvvuri, Inderjit S. Dhillon, Cho-Jui Hsieh, Sanjiv Kumar",http://arxiv.org/pdf/2410.20625v1,cs.LG
Kernel Approximation of Fisher-Rao Gradient Flows,"The purpose of this paper is to answer a few open questions in the interface
of kernel methods and PDE gradient flows. Motivated by recent advances in
machine learning, particularly in generative modeling and sampling, we present
a rigorous investigation of Fisher-Rao and Wasserstein type gradient flows
concerning their gradient structures, flow equations, and their kernel
approximations. Specifically, we focus on the Fisher-Rao (also known as
Hellinger) geometry and its various kernel-based approximations, developing a
principled theoretical framework using tools from PDE gradient flows and
optimal transport theory. We also provide a complete characterization of
gradient flows in the maximum-mean discrepancy (MMD) space, with connections to
existing learning and inference algorithms. Our analysis reveals precise
theoretical insights linking Fisher-Rao flows, Stein flows, kernel
discrepancies, and nonparametric regression. We then rigorously prove
evolutionary $\Gamma$-convergence for kernel-approximated Fisher-Rao flows,
providing theoretical guarantees beyond pointwise convergence. Finally, we
analyze energy dissipation using the Helmholtz-Rayleigh principle, establishing
important connections between classical theory in mechanics and modern machine
learning practice. Our results provide a unified theoretical foundation for
understanding and analyzing approximations of gradient flows in machine
learning applications through a rigorous gradient flow and variational method
perspective.",2024-10-27,"Jia-Jie Zhu, Alexander Mielke",http://arxiv.org/pdf/2410.20622v1,cs.LG
Accelerating Augmentation Invariance Pretraining,"Our work tackles the computational challenges of contrastive learning
methods, particularly for the pretraining of Vision Transformers (ViTs).
Despite the effectiveness of contrastive learning, the substantial
computational resources required for training often hinder their practical
application. To mitigate this issue, we propose an acceleration framework,
leveraging ViT's unique ability to generalize across inputs of varying sequence
lengths. Our method employs a mix of sequence compression strategies, including
randomized token dropout and flexible patch scaling, to reduce the cost of
gradient estimation and accelerate convergence. We further provide an in-depth
analysis of the gradient estimation error of various acceleration strategies as
well as their impact on downstream tasks, offering valuable insights into the
trade-offs between acceleration and performance.
  We also propose a novel procedure to identify an optimal acceleration
schedule to adjust the sequence compression ratios to the training progress,
ensuring efficient training without sacrificing downstream performance. Our
approach significantly reduces computational overhead across various
self-supervised learning algorithms on large-scale datasets. In ImageNet, our
method achieves speedups of 4$\times$ in MoCo, 3.3$\times$ in SimCLR, and
2.5$\times$ in DINO, demonstrating substantial efficiency gains.",2024-10-27,"Jinhong Lin, Cheng-En Wu, Yibing Wei, Pedro Morgado",http://arxiv.org/pdf/2410.22364v2,cs.LG
Implementation and Application of an Intelligibility Protocol for Interaction with an LLM,"Our interest is in constructing interactive systems involving a human-expert
interacting with a machine learning engine on data analysis tasks. This is of
relevance when addressing complex problems arising in areas of science, the
environment, medicine and so on, which are not immediately amenable to the
usual methods of statistical or mathematical modelling. In such situations, it
is possible that harnessing human expertise and creativity to modern
machine-learning capabilities of identifying patterns by constructing new
internal representations of the data may provide some insight to possible
solutions. In this paper, we examine the implementation of an abstract protocol
developed for interaction between agents, each capable of constructing
predictions and explanations. The \PXP protocol, described in [12] is motivated
by the notion of ''two-way intelligibility'' and is specified using a pair of
communicating finite-state machines. While the formalisation allows the authors
to prove several properties about the protocol, no implementation was
presented. Here, we address this shortcoming for the case in which one of the
agents acts as a ''generator'' using a large language model (LLM) and the other
is an agent that acts as a ''tester'' using either a human-expert, or a proxy
for a human-expert (for example, a database compiled using human-expertise). We
believe these use-cases will be a widely applicable form of interaction for
problems of the kind mentioned above. We present an algorithmic description of
general-purpose implementation, and conduct preliminary experiments on its use
in two different areas (radiology and drug-discovery). The experimental results
provide early evidence in support of the protocol's capability of capturing
one- and two-way intelligibility in human-LLM in the manner proposed in [12].",2024-10-27,"Ashwin Srinivasan, Karan Bania, Shreyas V, Harshvardhan Mestha, Sidong Liu",http://arxiv.org/pdf/2410.20600v1,cs.LG
Practical Bayesian Algorithm Execution via Posterior Sampling,"We consider Bayesian algorithm execution (BAX), a framework for efficiently
selecting evaluation points of an expensive function to infer a property of
interest encoded as the output of a base algorithm. Since the base algorithm
typically requires more evaluations than are feasible, it cannot be directly
applied. Instead, BAX methods sequentially select evaluation points using a
probabilistic numerical approach. Current BAX methods use expected information
gain to guide this selection. However, this approach is computationally
intensive. Observing that, in many tasks, the property of interest corresponds
to a target set of points defined by the function, we introduce PS-BAX, a
simple, effective, and scalable BAX method based on posterior sampling. PS-BAX
is applicable to a wide range of problems, including many optimization variants
and level set estimation. Experiments across diverse tasks demonstrate that
PS-BAX performs competitively with existing baselines while being significantly
faster, simpler to implement, and easily parallelizable, setting a strong
baseline for future research. Additionally, we establish conditions under which
PS-BAX is asymptotically convergent, offering new insights into posterior
sampling as an algorithm design paradigm.",2024-10-27,"Chu Xin Cheng, Raul Astudillo, Thomas Desautels, Yisong Yue",http://arxiv.org/pdf/2410.20596v1,cs.LG
A Framework for Real-Time Volcano-Seismic Event Recognition Based on Multi-Station Seismograms and Semantic Segmentation Models,"In volcano monitoring, effective recognition of seismic events is essential
for understanding volcanic activity and raising timely warning alerts.
Traditional methods rely on manual analysis, which can be subjective and
labor-intensive. Furthermore, current automatic approaches often tackle
detection and classification separately, mostly rely on single station
information and generally require tailored preprocessing and representations to
perform predictions. These limitations often hinder their application to
real-time monitoring and utilization across different volcano conditions. This
study introduces a novel approach that utilizes Semantic Segmentation models to
automate seismic event recognition by applying a straight forward
transformation of multi-channel 1D signals into 2D representations, enabling
their use as images. Our framework employs a data-driven, end-to-end design
that integrates multi-station seismic data with minimal preprocessing,
performing both detection and classification simultaneously for five seismic
event classes. We evaluated four state-of-the-art segmentation models (UNet,
UNet++, DeepLabV3+ and SwinUNet) on approximately 25.000 seismic events
recorded at four different Chilean volcanoes: Nevados del Chill\'an Volcanic
Complex, Laguna del Maule, Villarrica and Puyehue-Cord\'on Caulle. Among these
models, the UNet architecture was identified as the most effective model,
achieving mean F1 and Intersection over Union (IoU) scores of up to 0.91 and
0.88, respectively, and demonstrating superior noise robustness and model
flexibility to unseen volcano datasets.",2024-10-27,"Camilo Espinosa-Curilem, Millaray Curilem, Daniel Basualto",http://arxiv.org/pdf/2410.20595v3,cs.LG
Generator Matching: Generative modeling with arbitrary Markov processes,"We introduce Generator Matching, a modality-agnostic framework for generative
modeling using arbitrary Markov processes. Generators characterize the
infinitesimal evolution of a Markov process, which we leverage for generative
modeling in a similar vein to flow matching: we construct conditional
generators which generate single data points, then learn to approximate the
marginal generator which generates the full data distribution. We show that
Generator Matching unifies various generative modeling methods, including
diffusion models, flow matching and discrete diffusion models. Furthermore, it
expands the design space to new and unexplored Markov processes such as jump
processes. Finally, Generator Matching enables the construction of
superpositions of Markov generative models and enables the construction of
multimodal models in a rigorous manner. We empirically validate our method on
image and multimodal generation, e.g. showing that superposition with a jump
process improves performance.",2024-10-27,"Peter Holderrieth, Marton Havasi, Jason Yim, Neta Shaul, Itai Gat, Tommi Jaakkola, Brian Karrer, Ricky T. Q. Chen, Yaron Lipman",http://arxiv.org/pdf/2410.20587v3,cs.LG
High quality ECG dataset based on MIT-BIH recordings for improved heartbeats classification,"Electrocardiogram (ECG) is a reliable tool for medical professionals to
detect and diagnose abnormal heart waves that may cause cardiovascular
diseases. This paper proposes a methodology to create a new high-quality
heartbeat dataset from all 48 of the MIT-BIH recordings. The proposed approach
computes an optimal heartbeat size, by eliminating outliers and calculating the
mean value over 10-second windows. This results in independent QRS-centered
heartbeats avoiding the mixing of successive heartbeats problem. The quality of
the newly constructed dataset has been evaluated and compared with existing
datasets. To this end, we built and trained a PyTorch 1-D Resnet architecture
model that achieved 99.24\% accuracy with a 5.7\% improvement compared to other
methods. Additionally, downsampling the dataset has improved the model's
execution time by 33\% and reduced 3x memory usage.",2024-10-27,"Ahmed. S Benmessaoud, Farida Medjani, Yahia Bousseloub, Khalid Bouaita, Dhia Benrahem, Tahar Kezai",http://arxiv.org/pdf/2411.07252v1,cs.LG
Toward Conditional Distribution Calibration in Survival Prediction,"Survival prediction often involves estimating the time-to-event distribution
from censored datasets. Previous approaches have focused on enhancing
discrimination and marginal calibration. In this paper, we highlight the
significance of conditional calibration for real-world applications --
especially its role in individual decision-making. We propose a method based on
conformal prediction that uses the model's predicted individual survival
probability at that instance's observed time. This method effectively improves
the model's marginal and conditional calibration, without compromising
discrimination. We provide asymptotic theoretical guarantees for both marginal
and conditional calibration and test it extensively across 15 diverse
real-world datasets, demonstrating the method's practical effectiveness and
versatility in various settings.",2024-10-27,"Shi-ang Qi, Yakun Yu, Russell Greiner",http://arxiv.org/pdf/2410.20579v3,cs.LG
E(3)-invariant diffusion model for pocket-aware peptide generation,"Biologists frequently desire protein inhibitors for a variety of reasons,
including use as research tools for understanding biological processes and
application to societal problems in agriculture, healthcare, etc.
Immunotherapy, for instance, relies on immune checkpoint inhibitors to block
checkpoint proteins, preventing their binding with partner proteins and
boosting immune cell function against abnormal cells. Inhibitor discovery has
long been a tedious process, which in recent years has been accelerated by
computational approaches. Advances in artificial intelligence now provide an
opportunity to make inhibitor discovery smarter than ever before. While
extensive research has been conducted on computer-aided inhibitor discovery, it
has mainly focused on either sequence-to-structure mapping, reverse mapping, or
bio-activity prediction, making it unrealistic for biologists to utilize such
tools. Instead, our work proposes a new method of computer-assisted inhibitor
discovery: de novo pocket-aware peptide structure and sequence generation
network. Our approach consists of two sequential diffusion models for
end-to-end structure generation and sequence prediction. By leveraging angle
and dihedral relationships between backbone atoms, we ensure an E(3)-invariant
representation of peptide structures. Our results demonstrate that our method
achieves comparable performance to state-of-the-art models, highlighting its
potential in pocket-aware peptide design. This work offers a new approach for
precise drug discovery using receptor-specific peptide generation.",2024-10-27,"Po-Yu Liang, Jun Bai",http://arxiv.org/pdf/2410.21335v2,cs.LG
Unsupervised Panoptic Interpretation of Latent Spaces in GANs Using Space-Filling Vector Quantization,"Generative adversarial networks (GANs) learn a latent space whose samples can
be mapped to real-world images. Such latent spaces are difficult to interpret.
Some earlier supervised methods aim to create an interpretable latent space or
discover interpretable directions that require exploiting data labels or
annotated synthesized samples for training. However, we propose using a
modification of vector quantization called space-filling vector quantization
(SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture
the underlying morphological structure of the latent space and thus make it
interpretable. We apply this technique to model the latent space of pretrained
StyleGAN2 and BigGAN networks on various datasets. Our experiments show that
the SFVQ curve yields a general interpretable model of the latent space that
determines which part of the latent space corresponds to what specific
generative factors. Furthermore, we demonstrate that each line of SFVQ's curve
can potentially refer to an interpretable direction for applying intelligible
image transformations. We also showed that the points located on an SFVQ line
can be used for controllable data augmentation.",2024-10-27,"Mohammad Hassan Vali, Tom Bäckström",http://arxiv.org/pdf/2410.20573v1,cs.LG
Neural rendering enables dynamic tomography,"Interrupted X-ray computed tomography (X-CT) has been the common way to
observe the deformation of materials during an experiment. While this approach
is effective for quasi-static experiments, it has never been possible to
reconstruct a full 3d tomography during a dynamic experiment which cannot be
interrupted. In this work, we propose that neural rendering tools can be used
to drive the paradigm shift to enable 3d reconstruction during dynamic events.
First, we derive theoretical results to support the selection of projections
angles. Via a combination of synthetic and experimental data, we demonstrate
that neural radiance fields can reconstruct data modalities of interest more
efficiently than conventional reconstruction methods. Finally, we develop a
spatio-temporal model with spline-based deformation field and demonstrate that
such model can reconstruct the spatio-temporal deformation of lattice samples
in real-world experiments.",2024-10-27,"Ivan Grega, William F. Whitney, Vikram S. Deshpande",http://arxiv.org/pdf/2410.20558v1,cs.LG
Deep Reinforcement Learning Agents for Strategic Production Policies in Microeconomic Market Simulations,"Traditional economic models often rely on fixed assumptions about market
dynamics, limiting their ability to capture the complexities and stochastic
nature of real-world scenarios. However, reality is more complex and includes
noise, making traditional models assumptions not met in the market. In this
paper, we explore the application of deep reinforcement learning (DRL) to
obtain optimal production strategies in microeconomic market environments to
overcome the limitations of traditional models. Concretely, we propose a
DRL-based approach to obtain an effective policy in competitive markets with
multiple producers, each optimizing their production decisions in response to
fluctuating demand, supply, prices, subsidies, fixed costs, total production
curve, elasticities and other effects contaminated by noise. Our framework
enables agents to learn adaptive production policies to several simulations
that consistently outperform static and random strategies. As the deep neural
networks used by the agents are universal approximators of functions, DRL
algorithms can represent in the network complex patterns of data learnt by
trial and error that explain the market. Through extensive simulations, we
demonstrate how DRL can capture the intricate interplay between production
costs, market prices, and competitor behavior, providing insights into optimal
decision-making in dynamic economic settings. The results show that agents
trained with DRL can strategically adjust production levels to maximize
long-term profitability, even in the face of volatile market conditions. We
believe that the study bridges the gap between theoretical economic modeling
and practical market simulation, illustrating the potential of DRL to
revolutionize decision-making in market strategies.",2024-10-27,"Eduardo C. Garrido-Merchán, Maria Coronado-Vaca, Álvaro López-López, Carlos Martinez de Ibarreta",http://arxiv.org/pdf/2410.20550v1,cs.LG
Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse,"Chain-of-thought (CoT) prompting has become a widely used strategy for
working with large language and multimodal models. While CoT has been shown to
improve performance across many tasks, determining the settings in which it is
effective remains an ongoing effort. In particular, it is still an open
question in what settings CoT systematically reduces model performance. In this
paper, we seek to identify the characteristics of tasks where CoT reduces
performance by drawing inspiration from cognitive psychology, looking at cases
where (i) verbal thinking or deliberation hurts performance in humans, and (ii)
the constraints governing human performance generalize to language models.
Three such cases are implicit statistical learning, visual recognition, and
classifying with patterns containing exceptions. In extensive experiments
across all three settings, we find that a diverse collection of
state-of-the-art models exhibit significant drop-offs in performance (e.g., up
to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using
inference-time reasoning compared to zero-shot counterparts. We also identify
three tasks that satisfy condition (i) but not (ii), and find that while verbal
thinking reduces human performance in these tasks, CoT retains or increases
model performance. Overall, our results show that while there is not an exact
parallel between the cognitive processes of models and those of humans,
considering cases where thinking has negative consequences for human
performance can help us identify settings where it negatively impacts models.
By connecting the literature on human deliberation with evaluations of CoT, we
offer a new tool that can be used in understanding the impact of prompt choices
and inference-time reasoning.",2024-10-27,"Ryan Liu, Jiayi Geng, Addison J. Wu, Ilia Sucholutsky, Tania Lombrozo, Thomas L. Griffiths",http://arxiv.org/pdf/2410.21333v3,cs.LG
PaPaGei: Open Foundation Models for Optical Physiological Signals,"Photoplethysmography (PPG) is the leading non-invasive technique for
monitoring biosignals and cardiovascular health, with widespread adoption in
both clinical settings and consumer wearable devices. While machine learning
models trained on PPG signals have shown promise, they tend to be task-specific
and struggle with generalization. Current research is limited by the use of
single-device datasets, insufficient exploration of out-of-domain
generalization, and a lack of publicly available models, which hampers
reproducibility. To address these limitations, we present PaPaGei, the first
open foundation model for PPG signals. The model is pre-trained on over 57,000
hours of data, comprising 20 million unlabeled PPG segments from publicly
available datasets. We introduce a novel representation learning approach that
leverages domain knowledge of PPG signal morphology across individuals,
enabling the capture of richer representations compared to traditional
contrastive learning methods. We evaluate PaPaGei against state-of-the-art
time-series foundation models and self-supervised learning benchmarks across 20
tasks from 10 diverse datasets, spanning cardiovascular health, sleep
disorders, pregnancy monitoring, and wellbeing assessment. Our model
demonstrates superior performance, improving classification and regression
metrics by 6.3% and 2.9% respectively in at least 14 tasks. Notably, PaPaGei
achieves these results while being more data- and parameter-efficient,
outperforming models that are 70x larger. Beyond accuracy, we examine model
robustness across different skin tones, establishing a benchmark for bias
evaluation in future models. PaPaGei can serve as both a feature extractor and
an encoder for multimodal models, opening up new opportunities for multimodal
health monitoring.",2024-10-27,"Arvind Pillai, Dimitris Spathis, Fahim Kawsar, Mohammad Malekzadeh",http://arxiv.org/pdf/2410.20542v2,cs.LG
"Building, Reusing, and Generalizing Abstract Representations from Concrete Sequences","Humans excel at learning abstract patterns across different sequences,
filtering out irrelevant details, and transferring these generalized concepts
to new sequences. In contrast, many sequence learning models lack the ability
to abstract, which leads to memory inefficiency and poor transfer. We introduce
a non-parametric hierarchical variable learning model (HVM) that learns chunks
from sequences and abstracts contextually similar chunks as variables. HVM
efficiently organizes memory while uncovering abstractions, leading to compact
sequence representations. When learning on language datasets such as babyLM,
HVM learns a more efficient dictionary than standard compression algorithms
such as Lempel-Ziv. In a sequence recall task requiring the acquisition and
transfer of variables embedded in sequences, we demonstrate HVM's sequence
likelihood correlates with human recall times. In contrast, large language
models (LLMs) struggle to transfer abstract variables as effectively as humans.
From HVM's adjustable layer of abstraction, we demonstrate that the model
realizes a precise trade-off between compression and generalization. Our work
offers a cognitive model that captures the learning and transfer of abstract
representations in human cognition and differentiates itself from the behavior
of large language models.",2024-10-27,"Shuchen Wu, Mirko Thalmann, Peter Dayan, Zeynep Akata, Eric Schulz",http://arxiv.org/pdf/2410.21332v1,cs.LG
Info-CELS: Informative Saliency Map Guided Counterfactual Explanation,"As the demand for interpretable machine learning approaches continues to
grow, there is an increasing necessity for human involvement in providing
informative explanations for model decisions. This is necessary for building
trust and transparency in AI-based systems, leading to the emergence of the
Explainable Artificial Intelligence (XAI) field. Recently, a novel
counterfactual explanation model, CELS, has been introduced. CELS learns a
saliency map for the interest of an instance and generates a counterfactual
explanation guided by the learned saliency map. While CELS represents the first
attempt to exploit learned saliency maps not only to provide intuitive
explanations for the reason behind the decision made by the time series
classifier but also to explore post hoc counterfactual explanations, it
exhibits limitations in terms of high validity for the sake of ensuring high
proximity and sparsity. In this paper, we present an enhanced approach that
builds upon CELS. While the original model achieved promising results in terms
of sparsity and proximity, it faced limitations in validity. Our proposed
method addresses this limitation by removing mask normalization to provide more
informative and valid counterfactual explanations. Through extensive
experimentation on datasets from various domains, we demonstrate that our
approach outperforms the CELS model, achieving higher validity and producing
more informative explanations.",2024-10-27,"Peiyu Li, Omar Bahri, Pouya Hosseinzadeh, Soukaïna Filali Boubrahimi, Shah Muhammad Hamdi",http://arxiv.org/pdf/2410.20539v1,cs.LG
Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness,"Deep learning models often suffer from a lack of interpretability due to
polysemanticity, where individual neurons are activated by multiple unrelated
semantics, resulting in unclear attributions of model behavior. Recent advances
in monosemanticity, where neurons correspond to consistent and distinct
semantics, have significantly improved interpretability but are commonly
believed to compromise accuracy. In this work, we challenge the prevailing
belief of the accuracy-interpretability tradeoff, showing that monosemantic
features not only enhance interpretability but also bring concrete gains in
model performance. Across multiple robust learning scenarios-including input
and label noise, few-shot learning, and out-of-domain generalization-our
results show that models leveraging monosemantic features significantly
outperform those relying on polysemantic features. Furthermore, we provide
empirical and theoretical understandings on the robustness gains of feature
monosemanticity. Our preliminary analysis suggests that monosemanticity, by
promoting better separation of feature representations, leads to more robust
decision boundaries. This diverse evidence highlights the generality of
monosemanticity in improving model robustness. As a first step in this new
direction, we embark on exploring the learning benefits of monosemanticity
beyond interpretability, supporting the long-standing hypothesis of linking
interpretability and robustness. Code is available at
\url{https://github.com/PKU-ML/Beyond_Interpretability}.",2024-10-27,"Qi Zhang, Yifei Wang, Jingyi Cui, Xiang Pan, Qi Lei, Stefanie Jegelka, Yisen Wang",http://arxiv.org/pdf/2410.21331v1,cs.LG
SIGMA: Single Interpolated Generative Model for Anomalies,"A key step in any resonant anomaly detection search is accurate modeling of
the background distribution in each signal region. Data-driven methods like
CATHODE accomplish this by training separate generative models on the
complement of each signal region, and interpolating them into their
corresponding signal regions. Having to re-train the generative model on
essentially the entire dataset for each signal region is a major computational
cost in a typical sliding window search with many signal regions. Here, we
present SIGMA, a new, fully data-driven, computationally-efficient method for
estimating background distributions. The idea is to train a single generative
model on all of the data and interpolate its parameters in sideband regions in
order to obtain a model for the background in the signal region. The SIGMA
method significantly reduces the computational cost compared to previous
approaches, while retaining a similar high quality of background modeling and
sensitivity to anomalous signals.",2024-10-27,"Ranit Das, David Shih",http://arxiv.org/pdf/2410.20537v2,cs.LG
Guiding Through Complexity: What Makes Good Supervision for Hard Math Reasoning Tasks?,"How can ""weak teacher models"" such as average human annotators or existing AI
systems, effectively supervise LLMs to improve performance on hard reasoning
tasks, especially those that challenge and requires expertise or daily practice
from the teacher models? In this paper, we seek for empirical answers to this
question by investigating various data-driven strategies that offer supervision
data at different quality levels upon tasks of varying complexity. Two
intuitive strategies emerge for teacher models to provide supervision during
alignment training: 1) using lower-quality supervision from complete tasks that
match the difficulty of the target reasoning tasks, and 2) leveraging
higher-quality supervision from easier subtasks that are less challenging.
Interestingly, we find that even when the outcome error rate for hard task
supervision is high (e.g., 90\%), training on such data can outperform
perfectly correct supervision of easier subtasks on multiple hard math
benchmarks. We further identify a more critical factor influencing training
performance: step-wise error rates, which indicate the severity of errors in
solutions. Specifically, training on hard task supervision with the same
outcome error rates but disparate step-wise error rates can lead to a 30\%
accuracy gap on MATH benchmark. Our results also reveal that supplementing hard
task supervision with the corresponding subtask supervision can yield notable
performance improvements than simply combining rephrased hard full task
supervision, suggesting new avenues for data augmentation. Data and code are
released at https://github.com/hexuan21/Weak-to-Strong.",2024-10-27,"Xuan He, Da Yin, Nanyun Peng",http://arxiv.org/pdf/2410.20533v3,cs.LG
"Search Wide, Focus Deep: Automated Fetal Brain Extraction with Sparse Training Data","Automated fetal brain extraction from full-uterus MRI is a challenging task
due to variable head sizes, orientations, complex anatomy, and prevalent
artifacts. While deep-learning (DL) models trained on synthetic images have
been successful in adult brain extraction, adapting these networks for fetal
MRI is difficult due to the sparsity of labeled data, leading to increased
false-positive predictions. To address this challenge, we propose a test-time
strategy that reduces false positives in networks trained on sparse, synthetic
labels. The approach uses a breadth-fine search (BFS) to identify a subvolume
likely to contain the fetal brain, followed by a deep-focused sliding window
(DFS) search to refine the extraction, pooling predictions to minimize false
positives. We train models at different window sizes using synthetic images
derived from a small number of fetal brain label maps, augmented with random
geometric shapes. Each model is trained on diverse head positions and scales,
including cases with partial or no brain tissue. Our framework matches
state-of-the-art brain extraction methods on clinical HASTE scans of
third-trimester fetuses and exceeds them by up to 5\% in terms of Dice in the
second trimester as well as EPI scans across both trimesters. Our results
demonstrate the utility of a sliding-window approach and combining predictions
from several models trained on synthetic images, for improving brain-extraction
accuracy by progressively refining regions of interest and minimizing the risk
of missing brain mask slices or misidentifying other tissues as brain.",2024-10-27,"Javid Dadashkarimi, Valeria Pena Trujillo, Camilo Jaimes, Lilla Zöllei, Malte Hoffmann",http://arxiv.org/pdf/2410.20532v2,cs.LG
CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming,"Recent advancements in Large Language Models (LLMs) have renewed interest in
automatic programming language translation. Encoder-decoder transformer models,
in particular, have shown promise in translating between different programming
languages. However, translating between a language and its high-performance
computing (HPC) extensions remains underexplored due to challenges such as
complex parallel semantics. In this paper, we introduce CodeRosetta, an
encoder-decoder transformer model designed specifically for translating between
programming languages and their HPC extensions. CodeRosetta is evaluated on C++
to CUDA and Fortran to C++ translation tasks. It uses a customized learning
framework with tailored pretraining and training objectives to effectively
capture both code semantics and parallel structural nuances, enabling
bidirectional translation. Our results show that CodeRosetta outperforms
state-of-the-art baselines in C++ to CUDA translation by 2.9 BLEU and 1.72
CodeBLEU points while improving compilation accuracy by 6.05%. Compared to
general closed-source LLMs, our method improves C++ to CUDA translation by
22.08 BLEU and 14.39 CodeBLEU, with 2.75% higher compilation accuracy. Finally,
CodeRosetta exhibits proficiency in Fortran to parallel C++ translation,
marking it, to our knowledge, as the first encoder-decoder model for this
complex task, improving CodeBLEU by at least 4.63 points compared to
closed-source and open-code LLMs.",2024-10-27,"Ali TehraniJamsaz, Arijit Bhattacharjee, Le Chen, Nesreen K. Ahmed, Amir Yazdanbakhsh, Ali Jannesari",http://arxiv.org/pdf/2410.20527v1,cs.LG
Llama Scope: Extracting Millions of Features from Llama-3.1-8B with Sparse Autoencoders,"Sparse Autoencoders (SAEs) have emerged as a powerful unsupervised method for
extracting sparse representations from language models, yet scalable training
remains a significant challenge. We introduce a suite of 256 SAEs, trained on
each layer and sublayer of the Llama-3.1-8B-Base model, with 32K and 128K
features. Modifications to a state-of-the-art SAE variant, Top-K SAEs, are
evaluated across multiple dimensions. In particular, we assess the
generalizability of SAEs trained on base models to longer contexts and
fine-tuned models. Additionally, we analyze the geometry of learned SAE
latents, confirming that \emph{feature splitting} enables the discovery of new
features. The Llama Scope SAE checkpoints are publicly available
at~\url{https://huggingface.co/fnlp/Llama-Scope}, alongside our scalable
training, interpretation, and visualization tools at
\url{https://github.com/OpenMOSS/Language-Model-SAEs}. These contributions aim
to advance the open-source Sparse Autoencoder ecosystem and support mechanistic
interpretability research by reducing the need for redundant SAE training.",2024-10-27,"Zhengfu He, Wentao Shu, Xuyang Ge, Lingjie Chen, Junxuan Wang, Yunhua Zhou, Frances Liu, Qipeng Guo, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang, Xipeng Qiu",http://arxiv.org/pdf/2410.20526v1,cs.LG
A Cosmic-Scale Benchmark for Symmetry-Preserving Data Processing,"Efficiently processing structured point cloud data while preserving
multiscale information is a key challenge across domains, from graphics to
atomistic modeling. Using a curated dataset of simulated galaxy positions and
properties, represented as point clouds, we benchmark the ability of graph
neural networks to simultaneously capture local clustering environments and
long-range correlations. Given the homogeneous and isotropic nature of the
Universe, the data exhibits a high degree of symmetry. We therefore focus on
evaluating the performance of Euclidean symmetry-preserving
($E(3)$-equivariant) graph neural networks, showing that they can outperform
non-equivariant counterparts and domain-specific information extraction
techniques in downstream performance as well as simulation-efficiency. However,
we find that current architectures fail to capture information from long-range
correlations as effectively as domain-specific baselines, motivating future
work on architectures better suited for extracting long-range information.",2024-10-27,"Julia Balla, Siddharth Mishra-Sharma, Carolina Cuesta-Lazaro, Tommi Jaakkola, Tess Smidt",http://arxiv.org/pdf/2410.20516v1,cs.LG
Symbotunes: unified hub for symbolic music generative models,"Implementations of popular symbolic music generative models often differ
significantly in terms of the libraries utilized and overall project structure.
Therefore, directly comparing the methods or becoming acquainted with them may
present challenges. To mitigate this issue we introduce Symbotunes, an
open-source unified hub for symbolic music generative models. Symbotunes
contains modern Python implementations of well-known methods for symbolic music
generation, as well as a unified pipeline for generating and training.",2024-10-27,"Paweł Skierś, Maksymilian Łazarski, Michał Kopeć, Mateusz Modrzejewski",http://arxiv.org/pdf/2410.20515v1,cs.LG
When Less is More: Achieving Faster Convergence in Distributed Edge Machine Learning,"Distributed Machine Learning (DML) on resource-constrained edge devices holds
immense potential for real-world applications. However, achieving fast
convergence in DML in these heterogeneous environments remains a significant
challenge. Traditional frameworks like Bulk Synchronous Parallel and
Asynchronous Stochastic Parallel rely on frequent, small updates that incur
substantial communication overhead and hinder convergence speed. Furthermore,
these frameworks often employ static dataset sizes, neglecting the
heterogeneity of edge devices and potentially leading to straggler nodes that
slow down the entire training process. The straggler nodes, i.e., edge devices
that take significantly longer to process their assigned data chunk, hinder the
overall training speed. To address these limitations, this paper proposes
Hermes, a novel probabilistic framework for efficient DML on edge devices. This
framework leverages a dynamic threshold based on recent test loss behavior to
identify statistically significant improvements in the model's generalization
capability, hence transmitting updates only when major improvements are
detected, thereby significantly reducing communication overhead. Additionally,
Hermes employs dynamic dataset allocation to optimize resource utilization and
prevents performance degradation caused by straggler nodes. Our evaluations on
a real-world heterogeneous resource-constrained environment demonstrate that
Hermes achieves faster convergence compared to state-of-the-art methods,
resulting in a remarkable $13.22$x reduction in training time and a $62.1\%$
decrease in communication overhead.",2024-10-27,"Advik Raj Basani, Siddharth Chaitra Vivek, Advaith Krishna, Arnab K. Paul",http://arxiv.org/pdf/2410.20495v1,cs.LG
Efficient Diversity-based Experience Replay for Deep Reinforcement Learning,"Experience replay is widely used to improve learning efficiency in
reinforcement learning by leveraging past experiences. However, existing
experience replay methods, whether based on uniform or prioritized sampling,
often suffer from low efficiency, particularly in real-world scenarios with
high-dimensional state spaces. To address this limitation, we propose a novel
approach, Efficient Diversity-based Experience Replay (EDER). EDER employs a
determinantal point process to model the diversity between samples and
prioritizes replay based on the diversity between samples. To further enhance
learning efficiency, we incorporate Cholesky decomposition for handling large
state spaces in realistic environments. Additionally, rejection sampling is
applied to select samples with higher diversity, thereby improving overall
learning efficacy. Extensive experiments are conducted on robotic manipulation
tasks in MuJoCo, Atari games, and realistic indoor environments in Habitat. The
results demonstrate that our approach not only significantly improves learning
efficiency but also achieves superior performance in high-dimensional,
realistic environments.",2024-10-27,"Kaiyan Zhao, Yiming Wang, Yuyang Chen, Yan Li, Leong Hou U, Xiaoguang Niu",http://arxiv.org/pdf/2410.20487v4,cs.LG
Improving Decision Sparsity,"Sparsity is a central aspect of interpretability in machine learning.
Typically, sparsity is measured in terms of the size of a model globally, such
as the number of variables it uses. However, this notion of sparsity is not
particularly relevant for decision-making; someone subjected to a decision does
not care about variables that do not contribute to the decision. In this work,
we dramatically expand a notion of decision sparsity called the Sparse
Explanation Value(SEV) so that its explanations are more meaningful. SEV
considers movement along a hypercube towards a reference point. By allowing
flexibility in that reference and by considering how distances along the
hypercube translate to distances in feature space, we can derive sparser and
more meaningful explanations for various types of function classes. We present
cluster-based SEV and its variant tree-based SEV, introduce a method that
improves credibility of explanations, and propose algorithms that optimize
decision sparsity in machine learning models.",2024-10-27,"Yiyang Sun, Tong Wang, Cynthia Rudin",http://arxiv.org/pdf/2410.20483v2,cs.LG
Hamiltonian Score Matching and Generative Flows,"Classical Hamiltonian mechanics has been widely used in machine learning in
the form of Hamiltonian Monte Carlo for applications with predetermined force
fields. In this work, we explore the potential of deliberately designing force
fields for Hamiltonian ODEs, introducing Hamiltonian velocity predictors (HVPs)
as a tool for score matching and generative models. We present two innovations
constructed with HVPs: Hamiltonian Score Matching (HSM), which estimates score
functions by augmenting data via Hamiltonian trajectories, and Hamiltonian
Generative Flows (HGFs), a novel generative model that encompasses diffusion
models and flow matching as HGFs with zero force fields. We showcase the
extended design space of force fields by introducing Oscillation HGFs, a
generative model inspired by harmonic oscillators. Our experiments validate our
theoretical insights about HSM as a novel score matching metric and demonstrate
that HGFs rival leading generative modeling techniques.",2024-10-27,"Peter Holderrieth, Yilun Xu, Tommi Jaakkola",http://arxiv.org/pdf/2410.20470v1,cs.LG
Graph Neural Networks on Discriminative Graphs of Words,"In light of the recent success of Graph Neural Networks (GNNs) and their
ability to perform inference on complex data structures, many studies apply
GNNs to the task of text classification. In most previous methods, a
heterogeneous graph, containing both word and document nodes, is constructed
using the entire corpus and a GNN is used to classify document nodes. In this
work, we explore a new Discriminative Graph of Words Graph Neural Network
(DGoW-GNN) approach encapsulating both a novel discriminative graph
construction and model to classify text. In our graph construction, containing
only word nodes and no document nodes, we split the training corpus into
disconnected subgraphs according to their labels and weight edges by the
pointwise mutual information of the represented words. Our graph construction,
for which we provide theoretical motivation, allows us to reformulate the task
of text classification as the task of walk classification. We also propose a
new model for the graph-based classification of text, which combines a GNN and
a sequence model. We evaluate our approach on seven benchmark datasets and find
that it is outperformed by several state-of-the-art baseline models. We analyse
reasons for this performance difference and hypothesise under which conditions
it is likely to change.",2024-10-27,"Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis",http://arxiv.org/pdf/2410.20469v1,cs.LG
CloudCast -- Total Cloud Cover Nowcasting with Machine Learning,"Cloud cover plays a critical role in weather prediction and impacts several
sectors, including agriculture, solar power generation, and aviation. Despite
advancements in numerical weather prediction (NWP) models, forecasting total
cloud cover remains challenging due to the small-scale nature of cloud
formation processes. In this study, we introduce CloudCast, a convolutional
neural network (CNN) based on the U-Net architecture, designed to predict total
cloud cover (TCC) up to five hours ahead. Trained on five years of satellite
data, CloudCast significantly outperforms traditional NWP models and optical
flow methods. Compared to a reference NWP model, CloudCast achieves a 24% lower
mean absolute error and reduces multi-category prediction errors by 46%. The
model demonstrates strong performance, particularly in capturing the
large-scale structure of cloud cover in the first few forecast hours, though
later predictions are subject to blurring and underestimation of cloud
formation. An ablation study identified the optimal input features and loss
functions, with MAE-based models performing the best. CloudCast has been
integrated into the Finnish Meteorological Institute's operational nowcasting
system, where it improves cloud cover forecasts used by public and private
sector clients. While CloudCast is limited by a relatively short skillful lead
time of about three hours, future work aims to extend this through more complex
network architectures and higher-resolution data. CloudCast code is available
at https://github.com/fmidev/cloudcast.",2024-10-27,"Mikko Partio, Leila Hieta, Anniina Kokkonen",http://arxiv.org/pdf/2410.21329v2,cs.LG
TrajAgent: An Agent Framework for Unified Trajectory Modelling,"Trajectory modeling, which includes research on trajectory data pattern
mining and future prediction, has widespread applications in areas such as life
services, urban transportation, and public administration. Numerous methods
have been proposed to address specific problems within trajectory modelling.
However, due to the heterogeneity of data and the diversity of trajectory
tasks, achieving unified trajectory modelling remains an important yet
challenging task. In this paper, we propose TrajAgent, a large language
model-based agentic framework, to unify various trajectory modelling tasks. In
TrajAgent, we first develop UniEnv, an execution environment with a unified
data and model interface, to support the execution and training of various
models. Building on UniEnv, we introduce TAgent, an agentic workflow designed
for automatic trajectory modelling across various trajectory tasks.
Specifically, we design AutOpt, a systematic optimization module within TAgent,
to further improve the performance of the integrated model. With diverse
trajectory tasks input in natural language, TrajAgent automatically generates
competitive results via training and executing appropriate models. Extensive
experiments on four tasks using four real-world datasets demonstrate the
effectiveness of TrajAgent in unified trajectory modelling, achieving an
average performance improvement of 15.43% over baseline methods.",2024-10-27,"Yuwei Du, Jie Feng, Jie Zhao, Yong Li",http://arxiv.org/pdf/2410.20445v1,cs.LG
Vector Quantization Prompting for Continual Learning,"Continual learning requires to overcome catastrophic forgetting when training
a single model on a sequence of tasks. Recent top-performing approaches are
prompt-based methods that utilize a set of learnable parameters (i.e., prompts)
to encode task knowledge, from which appropriate ones are selected to guide the
fixed pre-trained model in generating features tailored to a certain task.
However, existing methods rely on predicting prompt identities for prompt
selection, where the identity prediction process cannot be optimized with task
loss. This limitation leads to sub-optimal prompt selection and inadequate
adaptation of pre-trained features for a specific task. Previous efforts have
tried to address this by directly generating prompts from input queries instead
of selecting from a set of candidates. However, these prompts are continuous,
which lack sufficient abstraction for task knowledge representation, making
them less effective for continual learning. To address these challenges, we
propose VQ-Prompt, a prompt-based continual learning method that incorporates
Vector Quantization (VQ) into end-to-end training of a set of discrete prompts.
In this way, VQ-Prompt can optimize the prompt selection process with task loss
and meanwhile achieve effective abstraction of task knowledge for continual
learning. Extensive experiments show that VQ-Prompt outperforms
state-of-the-art continual learning methods across a variety of benchmarks
under the challenging class-incremental setting. The code is available at
\href{https://github.com/jiaolifengmi/VQ-Prompt}{this https URL}.",2024-10-27,"Li Jiao, Qiuxia Lai, Yu Li, Qiang Xu",http://arxiv.org/pdf/2410.20444v1,cs.LG
TEAFormers: TEnsor-Augmented Transformers for Multi-Dimensional Time Series Forecasting,"Multi-dimensional time series data, such as matrix and tensor-variate time
series, are increasingly prevalent in fields such as economics, finance, and
climate science. Traditional Transformer models, though adept with sequential
data, do not effectively preserve these multi-dimensional structures, as their
internal operations in effect flatten multi-dimensional observations into
vectors, thereby losing critical multi-dimensional relationships and patterns.
To address this, we introduce the Tensor-Augmented Transformer (TEAFormer), a
novel method that incorporates tensor expansion and compression within the
Transformer framework to maintain and leverage the inherent multi-dimensional
structures, thus reducing computational costs and improving prediction
accuracy. The core feature of the TEAFormer, the Tensor-Augmentation (TEA)
module, utilizes tensor expansion to enhance multi-view feature learning and
tensor compression for efficient information aggregation and reduced
computational load. The TEA module is not just a specific model architecture
but a versatile component that is highly compatible with the attention
mechanism and the encoder-decoder structure of Transformers, making it
adaptable to existing Transformer architectures. Our comprehensive experiments,
which integrate the TEA module into three popular time series Transformer
models across three real-world benchmarks, show significant performance
enhancements, highlighting the potential of TEAFormers for cutting-edge time
series forecasting.",2024-10-27,"Linghang Kong, Elynn Chen, Yuzhou Chen, Yuefeng Han",http://arxiv.org/pdf/2410.20439v1,cs.LG
Integrating uncertainty quantification into randomized smoothing based robustness guarantees,"Deep neural networks have proven to be extremely powerful, however, they are
also vulnerable to adversarial attacks which can cause hazardous incorrect
predictions in safety-critical applications. Certified robustness via
randomized smoothing gives a probabilistic guarantee that the smoothed
classifier's predictions will not change within an $\ell_2$-ball around a given
input. On the other hand (uncertainty) score-based rejection is a technique
often applied in practice to defend models against adversarial attacks. In this
work, we fuse these two approaches by integrating a classifier that abstains
from predicting when uncertainty is high into the certified robustness
framework. This allows us to derive two novel robustness guarantees for
uncertainty aware classifiers, namely (i) the radius of an $\ell_2$-ball around
the input in which the same label is predicted and uncertainty remains low and
(ii) the $\ell_2$-radius of a ball in which the predictions will either not
change or be uncertain. While the former provides robustness guarantees with
respect to attacks aiming at increased uncertainty, the latter informs about
the amount of input perturbation necessary to lead the uncertainty aware model
into a wrong prediction. Notably, this is on CIFAR10 up to 20.93% larger than
for models not allowing for uncertainty based rejection. We demonstrate, that
the novel framework allows for a systematic robustness evaluation of different
network architectures and uncertainty measures and to identify desired
properties of uncertainty quantification techniques. Moreover, we show that
leveraging uncertainty in a smoothed classifier helps out-of-distribution
detection.",2024-10-27,"Sina Däubener, Kira Maag, David Krueger, Asja Fischer",http://arxiv.org/pdf/2410.20432v1,cs.LG
Deconfounding Time Series Forecasting,"Time series forecasting is a critical task in various domains, where accurate
predictions can drive informed decision-making. Traditional forecasting methods
often rely on current observations of variables to predict future outcomes,
typically overlooking the influence of latent confounders, unobserved variables
that simultaneously affect both the predictors and the target outcomes. This
oversight can introduce bias and degrade the performance of predictive models.
In this study, we address this challenge by proposing an enhanced forecasting
approach that incorporates representations of latent confounders derived from
historical data. By integrating these confounders into the predictive process,
our method aims to improve the accuracy and robustness of time series
forecasts. The proposed approach is demonstrated through its application to
climate science data, showing significant improvements over traditional methods
that do not account for confounders.",2024-10-27,"Wentao Gao, Feiyu Yang, Mengze Hong, Xiaojing Du, Zechen Hu, Xiongren Chen, Ziqi Xu",http://arxiv.org/pdf/2410.21328v1,cs.LG
Causal Modeling in Multi-Context Systems: Distinguishing Multiple Context-Specific Causal Graphs which Account for Observational Support,"Causal structure learning with data from multiple contexts carries both
opportunities and challenges. Opportunities arise from considering shared and
context-specific causal graphs enabling to generalize and transfer causal
knowledge across contexts. However, a challenge that is currently understudied
in the literature is the impact of differing observational support between
contexts on the identifiability of causal graphs. Here we study in detail
recently introduced [6] causal graph objects that capture both causal
mechanisms and data support, allowing for the analysis of a larger class of
context-specific changes, characterizing distribution shifts more precisely. We
thereby extend results on the identifiability of context-specific causal
structures and propose a framework to model context-specific independence (CSI)
within structural causal models (SCMs) in a refined way that allows to explore
scenarios where these graph objects differ. We demonstrate how this framework
can help explaining phenomena like anomalies or extreme events, where causal
mechanisms change or appear to change under different conditions. Our results
contribute to the theoretical foundations for understanding causal relations in
multi-context systems, with implications for generalization, transfer learning,
and anomaly detection. Future work may extend this approach to more complex
data types, such as time-series.",2024-10-27,"Martin Rabel, Wiebke Günther, Jakob Runge, Andreas Gerhardus",http://arxiv.org/pdf/2410.20405v1,cs.LG
Deep Learning-Driven Microstructure Characterization and Vickers Hardness Prediction of Mg-Gd Alloys,"In the field of materials science, exploring the relationship between
composition, microstructure, and properties has long been a critical research
focus. The mechanical performance of solid-solution Mg-Gd alloys is
significantly influenced by Gd content, dendritic structures, and the presence
of secondary phases. To better analyze and predict the impact of these factors,
this study proposes a multimodal fusion learning framework based on image
processing and deep learning techniques. This framework integrates both
elemental composition and microstructural features to accurately predict the
Vickers hardness of solid-solution Mg-Gd alloys. Initially, deep learning
methods were employed to extract microstructural information from a variety of
solid-solution Mg-Gd alloy images obtained from literature and experiments.
This provided precise grain size and secondary phase microstructural features
for performance prediction tasks. Subsequently, these quantitative analysis
results were combined with Gd content information to construct a performance
prediction dataset. Finally, a regression model based on the Transformer
architecture was used to predict the Vickers hardness of Mg-Gd alloys. The
experimental results indicate that the Transformer model performs best in terms
of prediction accuracy, achieving an R^2 value of 0.9. Additionally, SHAP
analysis identified critical values for four key features affecting the Vickers
hardness of Mg-Gd alloys, providing valuable guidance for alloy design. These
findings not only enhance the understanding of alloy performance but also offer
theoretical support for future material design and optimization.",2024-10-27,"Lu Wang, Hongchan Chen, Bing Wang, Qian Li, Qun Luo, Yuexing Han",http://arxiv.org/pdf/2410.20402v1,cs.LG
Prototypical Extreme Multi-label Classification with a Dynamic Margin Loss,"Extreme Multi-label Classification (XMC) methods predict relevant labels for
a given query in an extremely large label space. Recent works in XMC address
this problem using deep encoders that project text descriptions to an embedding
space suitable for recovering the closest labels. However, learning deep models
can be computationally expensive in large output spaces, resulting in a
trade-off between high performing brute-force approaches and efficient
solutions. In this paper, we propose PRIME, a XMC method that employs a novel
prototypical contrastive learning technique to reconcile efficiency and
performance surpassing brute-force approaches. We frame XMC as a
data-to-prototype prediction task where label prototypes aggregate information
from related queries. More precisely, we use a shallow transformer encoder that
we coin as Label Prototype Network, which enriches label representations by
aggregating text-based embeddings, label centroids and learnable free vectors.
We jointly train a deep encoder and the Label Prototype Network using an
adaptive triplet loss objective that better adapts to the high granularity and
ambiguity of extreme label spaces. PRIME achieves state-of-the-art results in
several public benchmarks of different sizes and domains, while keeping the
model efficient.",2024-10-27,"Kunal Dahiya, Diego Ortego, David Jiménez",http://arxiv.org/pdf/2410.20401v1,cs.LG
"ThunderKittens: Simple, Fast, and Adorable AI Kernels","The challenge of mapping AI architectures to GPU hardware is creating a
critical bottleneck in AI progress. Despite substantial efforts, hand-written
custom kernels fail to meet their theoretical performance thresholds, even on
well-established operations like linear attention. The diverse hardware
capabilities of GPUs might suggest that we need a wide variety of techniques to
achieve high performance. However, our work explores whether a small number of
key abstractions can drastically simplify the process. We present
ThunderKittens (TK), a framework for writing performant AI kernels while
remaining easy to use and maintain. Our abstractions map to the three levels of
the GPU hierarchy: (1) at the warp-level, we provide 16x16 matrix tiles as
basic data structures and PyTorch-like parallel compute operations over tiles,
(2) at the thread-block level, we provide a template for overlapping
asynchronous operations across parallel warps, and (3) at the grid-level, we
provide support to help hide the block launch and tear-down, and memory costs.
We show the value of TK by providing kernels that match or outperform prior
kernels for a range of AI operations. We match CuBLAS and FlashAttention-3 on
GEMM and attention inference performance and outperform the strongest baselines
by $10-40\%$ on attention backwards, $8\times$ on state space models, and
$14\times$ on linear attention.",2024-10-27,"Benjamin F. Spector, Simran Arora, Aaryan Singhal, Daniel Y. Fu, Christopher Ré",http://arxiv.org/pdf/2410.20399v1,cs.LG
Evaluation of uncertainty estimations for Gaussian process regression based machine learning interatomic potentials,"Uncertainty estimations for machine learning interatomic potentials (MLIPs)
are crucial for quantifying model error and identifying informative training
samples in active learning strategies. In this study, we evaluate uncertainty
estimations of Gaussian process regression (GPR)-based MLIPs, including the
predictive GPR standard deviation and ensemble-based uncertainties. We do this
in terms of calibration and in terms of impact on model performance in an
active learning scheme. We consider GPR models with Coulomb and Smooth Overlap
of Atomic Positions (SOAP) representations as inputs to predict potential
energy surfaces and excitation energies of molecules. Regarding calibration, we
find that ensemble-based uncertainty estimations show already poor global
calibration (e.g., averaged over the whole test set). In contrast, the GPR
standard deviation shows good global calibration, but when grouping predictions
by their uncertainty, we observe a systematical bias for predictions with high
uncertainty. Although an increasing uncertainty correlates with an increasing
bias, the bias is not captured quantitatively by the uncertainty. Therefore,
the GPR standard deviation can be useful to identify predictions with a high
bias and error but, without further knowledge, should not be interpreted as a
quantitative measure for a potential error range. Selecting the samples with
the highest GPR standard deviation from a fixed configuration space leads to a
model that overemphasizes the borders of the configuration space represented in
the fixed dataset. This may result in worse performance in more densely sampled
areas but better generalization for extrapolation tasks.",2024-10-27,"Matthias Holzenkamp, Dongyu Lyu, Ulrich Kleinekathöfer, Peter Zaspel",http://arxiv.org/pdf/2410.20398v2,cs.LG
Hierarchical Multiple Kernel K-Means Algorithm Based on Sparse Connectivity,"Multiple kernel learning (MKL) aims to find an optimal, consistent kernel
function. In the hierarchical multiple kernel clustering (HMKC) algorithm,
sample features are extracted layer by layer from a high-dimensional space to
maximize the retention of effective information. However, information
interaction between layers is often ignored. In this model, only corresponding
nodes in adjacent layers exchange information; other nodes remain isolated, and
if full connectivity is adopted, the diversity of the final consistency matrix
is reduced. Therefore, this paper proposes a hierarchical multiple kernel
K-Means (SCHMKKM) algorithm based on sparse connectivity, which controls the
assignment matrix to achieve sparse connections through a sparsity rate,
thereby locally fusing the features obtained by distilling information between
layers. Finally, we conduct cluster analysis on multiple datasets and compare
it with the fully connected hierarchical multiple kernel K-Means (FCHMKKM)
algorithm in experiments. It is shown that more discriminative information
fusion is beneficial for learning a better consistent partition matrix, and the
fusion strategy based on sparse connection outperforms the full connection
strategy.",2024-10-27,"Lei Wang, Liang Du, Peng Zhou",http://arxiv.org/pdf/2410.20391v1,cs.LG
Unsupervised Feature Selection Algorithm Based on Dual Manifold Re-ranking,"High-dimensional data is commonly encountered in numerous data analysis
tasks. Feature selection techniques aim to identify the most representative
features from the original high-dimensional data. Due to the absence of class
label information, it is significantly more challenging to select appropriate
features in unsupervised learning scenarios compared to supervised ones.
Traditional unsupervised feature selection methods typically score the features
of samples based on certain criteria, treating samples indiscriminately.
However, these approaches fail to fully capture the internal structure of the
data. The importance of different samples should vary, and there is a dual
relationship between the weight of samples and features that will influence
each other. Therefore, an unsupervised feature selection algorithm based on
dual manifold re-ranking (DMRR) is proposed in this paper. Different similarity
matrices are constructed to depict the manifold structures among samples,
between samples and features, and among features themselves. Then, manifold
re-ranking is performed by combining the initial scores of samples and
features. By comparing DMRR with three original unsupervised feature selection
algorithms and two unsupervised feature selection post-processing algorithms,
experimental results confirm that the importance information of different
samples and the dual relationship between sample and feature are beneficial for
achieving better feature selection.",2024-10-27,"Yunhui Liang, Jianwen Gan, Yan Chen, Peng Zhou, Liang Du",http://arxiv.org/pdf/2410.20388v1,cs.LG
Multiple kernel concept factorization algorithm based on global fusion,"Non-negative Matrix Factorization(NMF) algorithm can only be used to find low
rank approximation of original non-negative data while Concept
Factorization(CF) algorithm extends matrix factorization to single non-linear
kernel space, improving learning ability and adaptability of matrix
factorization. In unsupervised environment, to design or select proper kernel
function for specific dataset, a new algorithm called Globalized Multiple
Kernel CF(GMKCF)was proposed. Multiple candidate kernel functions were input in
the same time and learned in the CF framework based on global linear fusion,
obtaining a clustering result with high quality and stability and solving the
problem of kernel function selection that the CF faced. The convergence of the
proposed algorithm was verified by solving the model with alternate iteration.
The experimental results on several real databases show that the proposed
algorithm outperforms comparison algorithms in data clustering, such as Kernel
K-Means(KKM), Spectral Clustering(SC), Kernel CF(KCF), Co-regularized
multi-view spectral clustering(Coreg), and Robust Multiple KKM(RMKKM).",2024-10-27,"Fei Li, Liang Du, Chaohong Ren",http://arxiv.org/pdf/2410.20383v1,cs.LG
FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion,"One-shot Federated Learning (OFL) significantly reduces communication costs
in FL by aggregating trained models only once. However, the performance of
advanced OFL methods is far behind the normal FL. In this work, we provide a
causal view to find that this performance drop of OFL methods comes from the
isolation problem, which means that local isolatedly trained models in OFL may
easily fit to spurious correlations due to the data heterogeneity. From the
causal perspective, we observe that the spurious fitting can be alleviated by
augmenting intermediate features from other clients. Built upon our
observation, we propose a novel learning approach to endow OFL with superb
performance and low communication and storage costs, termed as FuseFL.
Specifically, FuseFL decomposes neural networks into several blocks, and
progressively trains and fuses each block following a bottom-up manner for
feature augmentation, introducing no additional communication costs.
Comprehensive experiments demonstrate that FuseFL outperforms existing OFL and
ensemble FL by a significant margin. We conduct comprehensive experiments to
show that FuseFL supports high scalability of clients, heterogeneous model
training, and low memory costs. Our work is the first attempt using causality
to analyze and alleviate data heterogeneity of OFL.",2024-10-27,"Zhenheng Tang, Yonggang Zhang, Peijie Dong, Yiu-ming Cheung, Amelie Chi Zhou, Bo Han, Xiaowen Chu",http://arxiv.org/pdf/2410.20380v1,cs.LG
Rethinking Reconstruction-based Graph-Level Anomaly Detection: Limitations and a Simple Remedy,"Graph autoencoders (Graph-AEs) learn representations of given graphs by
aiming to accurately reconstruct them. A notable application of Graph-AEs is
graph-level anomaly detection (GLAD), whose objective is to identify graphs
with anomalous topological structures and/or node features compared to the
majority of the graph population. Graph-AEs for GLAD regard a graph with a high
mean reconstruction error (i.e. mean of errors from all node pairs and/or
nodes) as anomalies. Namely, the methods rest on the assumption that they would
better reconstruct graphs with similar characteristics to the majority. We,
however, report non-trivial counter-examples, a phenomenon we call
reconstruction flip, and highlight the limitations of the existing
Graph-AE-based GLAD methods. Specifically, we empirically and theoretically
investigate when this assumption holds and when it fails. Through our analyses,
we further argue that, while the reconstruction errors for a given graph are
effective features for GLAD, leveraging the multifaceted summaries of the
reconstruction errors, beyond just mean, can further strengthen the features.
Thus, we propose a novel and simple GLAD method, named MUSE. The key innovation
of MUSE involves taking multifaceted summaries of reconstruction errors as
graph features for GLAD. This surprisingly simple method obtains SOTA
performance in GLAD, performing best overall among 14 methods across 10
datasets.",2024-10-27,"Sunwoo Kim, Soo Yong Lee, Fanchen Bu, Shinhwan Kang, Kyungho Kim, Jaemin Yoo, Kijung Shin",http://arxiv.org/pdf/2410.20366v1,cs.LG
Uncovering Capabilities of Model Pruning in Graph Contrastive Learning,"Graph contrastive learning has achieved great success in pre-training graph
neural networks without ground-truth labels. Leading graph contrastive learning
follows the classical scheme of contrastive learning, forcing model to identify
the essential information from augmented views. However, general augmented
views are produced via random corruption or learning, which inevitably leads to
semantics alteration. Although domain knowledge guided augmentations alleviate
this issue, the generated views are domain specific and undermine the
generalization. In this work, motivated by the firm representation ability of
sparse model from pruning, we reformulate the problem of graph contrastive
learning via contrasting different model versions rather than augmented views.
We first theoretically reveal the superiority of model pruning in contrast to
data augmentations. In practice, we take original graph as input and
dynamically generate a perturbed graph encoder to contrast with the original
encoder by pruning its transformation weights. Furthermore, considering the
integrity of node embedding in our method, we are capable of developing a local
contrastive loss to tackle the hard negative samples that disturb the model
training. We extensively validate our method on various benchmarks regarding
graph classification via unsupervised and transfer learning. Compared to the
state-of-the-art (SOTA) works, better performance can always be obtained by the
proposed method.",2024-10-27,"Junran Wu, Xueyuan Chen, Shangzhe Li",http://arxiv.org/pdf/2410.20356v2,cs.LG
FoldMark: Protecting Protein Generative Models with Watermarking,"Protein structure is key to understanding protein function and is essential
for progress in bioengineering, drug discovery, and molecular biology.
Recently, with the incorporation of generative AI, the power and accuracy of
computational protein structure prediction/design have been improved
significantly. However, ethical concerns such as copyright protection and
harmful content generation (biosecurity) pose challenges to the wide
implementation of protein generative models. Here, we investigate whether it is
possible to embed watermarks into protein generative models and their outputs
for copyright authentication and the tracking of generated structures. As a
proof of concept, we propose a two-stage method FoldMark as a generalized
watermarking strategy for protein generative models. FoldMark first pretrain
watermark encoder and decoder, which can minorly adjust protein structures to
embed user-specific information and faithfully recover the information from the
encoded structure. In the second step, protein generative models are fine-tuned
with watermark-conditioned Low-Rank Adaptation (LoRA) modules to preserve
generation quality while learning to generate watermarked structures with high
recovery rates. Extensive experiments are conducted on open-source protein
structure prediction models (e.g., ESMFold and MultiFlow) and de novo structure
design models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method
is effective across all these generative models. Meanwhile, our watermarking
framework only exerts a negligible impact on the original protein structure
quality and is robust under potential post-processing and adaptive attacks.",2024-10-27,"Zaixi Zhang, Ruofan Jin, Kaidi Fu, Le Cong, Marinka Zitnik, Mengdi Wang",http://arxiv.org/pdf/2410.20354v4,cs.LG
Leveraging Auxiliary Task Relevance for Enhanced Bearing Fault Diagnosis through Curriculum Meta-learning,"The accurate diagnosis of machine breakdowns is crucial for maintaining
operational safety in smart manufacturing. Despite the promise shown by deep
learning in automating fault identification, the scarcity of labeled training
data, particularly for equipment failure instances, poses a significant
challenge. This limitation hampers the development of robust classification
models. Existing methods like model-agnostic meta-learning (MAML) do not
adequately address variable working conditions, affecting knowledge transfer.
To address these challenges, a Related Task Aware Curriculum Meta-learning
(RT-ACM) enhanced fault diagnosis framework is proposed in this paper, inspired
by human cognitive learning processes. RT-ACM improves training by considering
the relevance of auxiliary sensor working conditions, adhering to the principle
of ``paying more attention to more relevant knowledge"", and focusing on
``easier first, harder later"" curriculum sampling. This approach aids the
meta-learner in achieving a superior convergence state. Extensive experiments
on two real-world datasets demonstrate the superiority of RT-ACM framework.",2024-10-27,"Jinze Wang, Jiong Jin, Tiehua Zhang, Boon Xian Chai, Adriano Di Pietro, Dimitrios Georgakopoulos",http://arxiv.org/pdf/2410.20351v2,cs.LG
Logarithmically Quantized Distributed Optimization over Dynamic Multi-Agent Networks,"Distributed optimization finds many applications in machine learning, signal
processing, and control systems. In these real-world applications, the
constraints of communication networks, particularly limited bandwidth,
necessitate implementing quantization techniques. In this paper, we propose
distributed optimization dynamics over multi-agent networks subject to
logarithmically quantized data transmission. Under this condition, data
exchange benefits from representing smaller values with more bits and larger
values with fewer bits. As compared to uniform quantization, this allows for
higher precision in representing near-optimal values and more accuracy of the
distributed optimization algorithm. The proposed optimization dynamics comprise
a primary state variable converging to the optimizer and an auxiliary variable
tracking the objective function's gradient. Our setting accommodates dynamic
network topologies, resulting in a hybrid system requiring convergence analysis
using matrix perturbation theory and eigenspectrum analysis.",2024-10-27,"Mohammadreza Doostmohammadian, Sérgio Pequito",http://arxiv.org/pdf/2410.20345v1,cs.LG
Robust Universum Twin Support Vector Machine for Imbalanced Data,"One of the major difficulties in machine learning methods is categorizing
datasets that are imbalanced. This problem may lead to biased models, where the
training process is dominated by the majority class, resulting in inadequate
representation of the minority class. Universum twin support vector machine
(UTSVM) produces a biased model towards the majority class, as a result, its
performance on the minority class is often poor as it might be mistakenly
classified as noise. Moreover, UTSVM is not proficient in handling datasets
that contain outliers and noises. Inspired by the concept of incorporating
prior information about the data and employing an intuitionistic fuzzy
membership scheme, we propose intuitionistic fuzzy UTSVM for imbalanced data
(IFUTSVM-ID) by enhancing overall robustness. We use an intuitionistic fuzzy
membership scheme to mitigate the impact of noise and outliers. Moreover, to
tackle the problem of imbalanced class distribution, data oversampling and
undersampling methods are utilized. Prior knowledge about the data is provided
by universum data. This leads to better generalization performance. UTSVM is
susceptible to overfitting risks due to the omission of the structural risk
minimization (SRM) principle in their primal formulations. However, the
proposed IFUTSVM-ID model incorporates the SRM principle through the
incorporation of regularization terms, effectively addressing the issue of
overfitting. We conduct a comprehensive evaluation of the proposed IFUTSVM-ID
model on benchmark datasets from KEEL and compare it with existing baseline
models. Furthermore, to assess the effectiveness of the proposed IFUTSVM-ID
model in diagnosing Alzheimer's disease (AD), we applied them to the
Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Experimental
results showcase the superiority of the proposed IFUTSVM-ID models compared to
the baseline models.",2024-10-27,"M. Tanveer, A. Quadir",http://arxiv.org/pdf/2410.20335v2,cs.LG
Embedded Nonlocal Operator Regression (ENOR): Quantifying model error in learning nonlocal operators,"Nonlocal, integral operators have become an efficient surrogate for bottom-up
homogenization, due to their ability to represent long-range dependence and
multiscale effects. However, the nonlocal homogenized model has unavoidable
discrepancy from the microscale model. Such errors accumulate and propagate in
long-term simulations, making the resultant prediction unreliable. To develop a
robust and reliable bottom-up homogenization framework, we propose a new
framework, which we coin Embedded Nonlocal Operator Regression (ENOR), to learn
a nonlocal homogenized surrogate model and its structural model error. This
framework provides discrepancy-adaptive uncertainty quantification for
homogenized material response predictions in long-term simulations. The method
is built on Nonlocal Operator Regression (NOR), an optimization-based nonlocal
kernel learning approach, together with an embedded model error term in the
trainable kernel. Then, Bayesian inference is employed to infer the model error
term parameters together with the kernel parameters. To make the problem
computationally feasible, we use a multilevel delayed acceptance Markov chain
Monte Carlo (MLDA-MCMC) method, enabling efficient Bayesian model calibration
and model error estimation. We apply this technique to predict long-term wave
propagation in a heterogeneous one-dimensional bar, and compare its performance
with additive noise models. Owing to its ability to capture model error, the
learned ENOR achieves improved estimation of posterior predictive uncertainty.",2024-10-27,"Yiming Fan, Habib Najm, Yue Yu, Stewart Silling, Marta D'Elia",http://arxiv.org/pdf/2410.20331v1,cs.LG
Domain Specific Data Distillation and Multi-modal Embedding Generation,"The challenge of creating domain-centric embeddings arises from the abundance
of unstructured data and the scarcity of domain-specific structured data.
Conventional embedding techniques often rely on either modality, limiting their
applicability and efficacy. This paper introduces a novel modeling approach
that leverages structured data to filter noise from unstructured data,
resulting in embeddings with high precision and recall for domain-specific
attribute prediction. The proposed model operates within a Hybrid Collaborative
Filtering (HCF) framework, where generic entity representations are fine-tuned
through relevant item prediction tasks. Our experiments, focusing on the cloud
computing domain, demonstrate that HCF-based embeddings outperform
AutoEncoder-based embeddings (using purely unstructured data), achieving a 28%
lift in precision and an 11% lift in recall for domain-specific attribute
prediction.",2024-10-27,"Sharadind Peddiraju, Srini Rajagopal",http://arxiv.org/pdf/2410.20325v1,cs.LG
Self-Supervised Learning and Opportunistic Inference for Continuous Monitoring of Freezing of Gait in Parkinson's Disease,"Parkinson's disease (PD) is a progressive neurological disorder that impacts
the quality of life significantly, making in-home monitoring of motor symptoms
such as Freezing of Gait (FoG) critical. However, existing symptom monitoring
technologies are power-hungry, rely on extensive amounts of labeled data, and
operate in controlled settings. These shortcomings limit real-world deployment
of the technology. This work presents LIFT-PD, a computationally-efficient
self-supervised learning framework for real-time FoG detection. Our method
combines self-supervised pre-training on unlabeled data with a novel
differential hopping windowing technique to learn from limited labeled
instances. An opportunistic model activation module further minimizes power
consumption by selectively activating the deep learning module only during
active periods. Extensive experimental results show that LIFT-PD achieves a
7.25% increase in precision and 4.4% improvement in accuracy compared to
supervised models while using as low as 40% of the labeled training data used
for supervised learning. Additionally, the model activation module reduces
inference time by up to 67% compared to continuous inference. LIFT-PD paves the
way for practical, energy-efficient, and unobtrusive in-home monitoring of PD
patients with minimal labeling requirements.",2024-10-27,"Shovito Barua Soumma, Kartik Mangipudi, Daniel Peterson, Shyamal Mehta, Hassan Ghasemzadeh",http://arxiv.org/pdf/2410.21326v1,cs.LG
Low-rank Bayesian matrix completion via geodesic Hamiltonian Monte Carlo on Stiefel manifolds,"We present a new sampling-based approach for enabling efficient computation
of low-rank Bayesian matrix completion and quantifying the associated
uncertainty. Firstly, we design a new prior model based on the
singular-value-decomposition (SVD) parametrization of low-rank matrices. Our
prior is analogous to the seminal nuclear-norm regularization used in
non-Bayesian setting and enforces orthogonality in the factor matrices by
constraining them to Stiefel manifolds. Then, we design a geodesic Hamiltonian
Monte Carlo (-within-Gibbs) algorithm for generating posterior samples of the
SVD factor matrices. We demonstrate that our approach resolves the sampling
difficulties encountered by standard Gibbs samplers for the common two-matrix
factorization used in matrix completion. More importantly, the geodesic
Hamiltonian sampler allows for sampling in cases with more general likelihoods
than the typical Gaussian likelihood and Gaussian prior assumptions adopted in
most of the existing Bayesian matrix completion literature. We demonstrate an
applications of our approach to fit the categorical data of a mice protein
dataset and the MovieLens recommendation problem. Numerical examples
demonstrate superior sampling performance, including better mixing and faster
convergence to a stationary distribution. Moreover, they demonstrate improved
accuracy on the two real-world benchmark problems we considered.",2024-10-27,"Tiangang Cui, Alex Gorodetsky",http://arxiv.org/pdf/2410.20318v1,cs.LG
ProtSCAPE: Mapping the landscape of protein conformations in molecular dynamics,"Understanding the dynamic nature of protein structures is essential for
comprehending their biological functions. While significant progress has been
made in predicting static folded structures, modeling protein motions on
microsecond to millisecond scales remains challenging. To address these
challenges, we introduce a novel deep learning architecture, Protein
Transformer with Scattering, Attention, and Positional Embedding (ProtSCAPE),
which leverages the geometric scattering transform alongside transformer-based
attention mechanisms to capture protein dynamics from molecular dynamics (MD)
simulations. ProtSCAPE utilizes the multi-scale nature of the geometric
scattering transform to extract features from protein structures conceptualized
as graphs and integrates these features with dual attention structures that
focus on residues and amino acid signals, generating latent representations of
protein trajectories. Furthermore, ProtSCAPE incorporates a regression head to
enforce temporally coherent latent representations.",2024-10-27,"Siddharth Viswanath, Dhananjay Bhaskar, David R. Johnson, Joao Felipe Rocha, Egbert Castro, Jackson D. Grady, Alex T. Grigas, Michael A. Perlmutter, Corey S. O'Hern, Smita Krishnaswamy",http://arxiv.org/pdf/2410.20317v1,cs.LG
Q-Distribution guided Q-learning for offline reinforcement learning: Uncertainty penalized Q-value via consistency model,"``Distribution shift'' is the main obstacle to the success of offline
reinforcement learning. A learning policy may take actions beyond the behavior
policy's knowledge, referred to as Out-of-Distribution (OOD) actions. The
Q-values for these OOD actions can be easily overestimated. As a result, the
learning policy is biased by using incorrect Q-value estimates. One common
approach to avoid Q-value overestimation is to make a pessimistic adjustment.
Our key idea is to penalize the Q-values of OOD actions associated with high
uncertainty. In this work, we propose Q-Distribution Guided Q-Learning (QDQ),
which applies a pessimistic adjustment to Q-values in OOD regions based on
uncertainty estimation. This uncertainty measure relies on the conditional
Q-value distribution, learned through a high-fidelity and efficient consistency
model. Additionally, to prevent overly conservative estimates, we introduce an
uncertainty-aware optimization objective for updating the Q-value function. The
proposed QDQ demonstrates solid theoretical guarantees for the accuracy of
Q-value distribution learning and uncertainty measurement, as well as the
performance of the learning policy. QDQ consistently shows strong performance
on the D4RL benchmark and achieves significant improvements across many tasks.",2024-10-27,"Jing Zhang, Linjiajie Fang, Kexin Shi, Wenjia Wang, Bing-Yi Jing",http://arxiv.org/pdf/2410.20312v2,cs.LG
ANOMIX: A Simple yet Effective Hard Negative Generation via Mixing for Graph Anomaly Detection,"Graph contrastive learning (GCL) generally requires a large number of
samples. The one of the effective ways to reduce the number of samples is using
hard negatives (e.g., Mixup). Designing mixing-based approach for GAD can be
difficult due to imbalanced data or limited number of anomalies. We propose
ANOMIX, a framework that consists of a novel graph mixing approach, ANOMIX-M,
and multi-level contrasts for GAD. ANOMIX-M can effectively mix abnormality and
normality from input graph to generate hard negatives, which are important for
efficient GCL. ANOMIX is (a) A first mixing approach: firstly attempting graph
mixing to generate hard negatives for GAD task and node- and subgraph-level
contrasts to distinguish underlying anomalies. (b) Accurate: winning the
highest AUC, up to 5.49% higher and 1.76% faster. (c) Effective: reducing the
number of samples nearly 80% in GCL. Code is available at
https://github.com/missinghwan/ANOMIX.",2024-10-27,"Hwan Kim, Junghoon Kim, Sungsu Lim",http://arxiv.org/pdf/2410.20310v1,cs.LG
Accelerating Direct Preference Optimization with Prefix Sharing,"Offline paired preference optimization algorithms have become a popular
approach for fine-tuning on preference data, outperforming traditional
supervised fine-tuning in various tasks. However, traditional implementations
often involve redundant computations, especially for tasks with long shared
prompts. We introduce prefix sharing for preference tuning, a novel technique
that processes chosen and rejected responses as one sequence with a shared
prefix. To prevent cross-response contamination, we use a custom block-sparse
attention mask. Our method achieves $1.1$-$1.5\times$ improvement in training
throughput on popular DPO datasets, without any effect on convergence. When
combined with sequence packing, we observe consistent $1.3$-$1.6\times$
speedups, benefiting even datasets with smaller sequence lengths. While we
focus on Direct Preference Optimization (DPO), our approach is applicable to
other paired preference tuning methods. By enhancing computational efficiency,
our work contributes to making preference-based fine-tuning more accessible for
a wider range of applications and model sizes. We open-source our code at
https://github.com/frankxwang/dpo-prefix-sharing.",2024-10-27,"Franklin Wang, Sumanth Hegde",http://arxiv.org/pdf/2410.20305v2,cs.LG
Sequential Large Language Model-Based Hyper-parameter Optimization,"This study introduces SLLMBO, an innovative framework leveraging large
language models (LLMs) for hyperparameter optimization (HPO), incorporating
dynamic search space adaptability, enhanced parameter space exploitation, and a
novel LLM-tree-structured parzen estimator (LLM-TPE) sampler. By addressing
limitations in recent fully LLM-based methods and traditional bayesian
optimization (BO), SLLMBO achieves more robust optimization. This comprehensive
benchmarking evaluates multiple LLMs, including GPT-3.5-Turbo, GPT-4o,
Claude-Sonnet-3.5, and Gemini-1.5-Flash, extending prior work and establishing
SLLMBO as the first framework to benchmark a diverse set of LLMs for HPO. By
integrating LLMs' established strengths in parameter initialization with the
exploitation abilities demonstrated in this study, alongside TPE's exploration
capabilities, the LLM-TPE sampler achieves a balanced exploration-exploitation
trade-off, reduces API costs, and mitigates premature early stoppings for more
effective parameter searches. Across 14 tabular tasks in classification and
regression, the LLM-TPE sampler outperformed fully LLM-based methods and
achieved superior results over BO methods in 9 tasks. Testing early stopping in
budget-constrained scenarios demonstrated competitive performance, indicating
that LLM-based methods generally benefit from extended iterations for optimal
results. This work lays the foundation for future research exploring
open-source LLMs, reproducibility of LLM results in HPO, and benchmarking
SLLMBO on complex datasets, such as image classification, segmentation, and
machine translation.",2024-10-27,"Kanan Mahammadli, Seyda Ertekin",http://arxiv.org/pdf/2410.20302v3,cs.LG
Predicting Mortality and Functional Status Scores of Traumatic Brain Injury Patients using Supervised Machine Learning,"Traumatic brain injury (TBI) presents a significant public health challenge,
often resulting in mortality or lasting disability. Predicting outcomes such as
mortality and Functional Status Scale (FSS) scores can enhance treatment
strategies and inform clinical decision-making. This study applies supervised
machine learning (ML) methods to predict mortality and FSS scores using a
real-world dataset of 300 pediatric TBI patients from the University of
Colorado School of Medicine. The dataset captures clinical features, including
demographics, injury mechanisms, and hospitalization outcomes. Eighteen ML
models were evaluated for mortality prediction, and thirteen models were
assessed for FSS score prediction. Performance was measured using accuracy, ROC
AUC, F1-score, and mean squared error. Logistic regression and Extra Trees
models achieved high precision in mortality prediction, while linear regression
demonstrated the best FSS score prediction. Feature selection reduced 103
clinical variables to the most relevant, enhancing model efficiency and
interpretability. This research highlights the role of ML models in identifying
high-risk patients and supporting personalized interventions, demonstrating the
potential of data-driven analytics to improve TBI care and integrate into
clinical workflows.",2024-10-27,"Lucas Steinmetz, Shivam Maheshwari, Garik Kazanjian, Abigail Loyson, Tyler Alexander, Venkat Margapuri, C. Nataraj",http://arxiv.org/pdf/2410.20300v1,cs.LG
Fine-Tuning and Evaluating Open-Source Large Language Models for the Army Domain,"In recent years, the widespread adoption of Large Language Models (LLMs) has
sparked interest in their potential for application within the military domain.
However, the current generation of LLMs demonstrate sub-optimal performance on
Army use cases, due to the prevalence of domain-specific vocabulary and jargon.
In order to fully leverage LLMs in-domain, many organizations have turned to
fine-tuning to circumvent the prohibitive costs involved in training new LLMs
from scratch. In light of this trend, we explore the viability of adapting
open-source LLMs for usage in the Army domain in order to address their
existing lack of domain-specificity. Our investigations have resulted in the
creation of three distinct generations of TRACLM, a family of LLMs fine-tuned
by The Research and Analysis Center (TRAC), Army Futures Command (AFC). Through
continuous refinement of our training pipeline, each successive iteration of
TRACLM displayed improved capabilities when applied to Army tasks and use
cases. Furthermore, throughout our fine-tuning experiments, we recognized the
need for an evaluation framework that objectively quantifies the Army
domain-specific knowledge of LLMs. To address this, we developed MilBench, an
extensible software framework that efficiently evaluates the Army knowledge of
a given LLM using tasks derived from doctrine and assessments. We share
preliminary results, models, methods, and recommendations on the creation of
TRACLM and MilBench. Our work significantly informs the development of LLM
technology across the DoD and augments senior leader decisions with respect to
artificial intelligence integration.",2024-10-27,"Daniel C. Ruiz, John Sell",http://arxiv.org/pdf/2410.20297v1,cs.LG
DeCaf: A Causal Decoupling Framework for OOD Generalization on Node Classification,"Graph Neural Networks (GNNs) are susceptible to distribution shifts, creating
vulnerability and security issues in critical domains. There is a pressing need
to enhance the generalizability of GNNs on out-of-distribution (OOD) test data.
Existing methods that target learning an invariant (feature, structure)-label
mapping often depend on oversimplified assumptions about the data generation
process, which do not adequately reflect the actual dynamics of distribution
shifts in graphs. In this paper, we introduce a more realistic graph data
generation model using Structural Causal Models (SCMs), allowing us to redefine
distribution shifts by pinpointing their origins within the generation process.
Building on this, we propose a casual decoupling framework, DeCaf, that
independently learns unbiased feature-label and structure-label mappings. We
provide a detailed theoretical framework that shows how our approach can
effectively mitigate the impact of various distribution shifts. We evaluate
DeCaf across both real-world and synthetic datasets that demonstrate different
patterns of shifts, confirming its efficacy in enhancing the generalizability
of GNNs.",2024-10-27,"Xiaoxue Han, Huzefa Rangwala, Yue Ning",http://arxiv.org/pdf/2410.20295v1,cs.LG
"A Systematic Review of Machine Learning Approaches for Detecting Deceptive Activities on Social Media: Methods, Challenges, and Biases","Social media platforms like Twitter, Facebook, and Instagram have facilitated
the spread of misinformation, necessitating automated detection systems. This
systematic review evaluates 36 studies that apply machine learning (ML) and
deep learning (DL) models to detect fake news, spam, and fake accounts on
social media. Using the Prediction model Risk Of Bias ASsessment Tool
(PROBAST), the review identified key biases across the ML lifecycle: selection
bias due to non-representative sampling, inadequate handling of class
imbalance, insufficient linguistic preprocessing (e.g., negations), and
inconsistent hyperparameter tuning. Although models such as Support Vector
Machines (SVM), Random Forests, and Long Short-Term Memory (LSTM) networks
showed strong potential, over-reliance on accuracy as an evaluation metric in
imbalanced data settings was a common flaw. The review highlights the need for
improved data preprocessing (e.g., resampling techniques), consistent
hyperparameter tuning, and the use of appropriate metrics like precision,
recall, F1 score, and AUROC. Addressing these limitations can lead to more
reliable and generalizable ML/DL models for detecting deceptive content,
ultimately contributing to the reduction of misinformation on social media.",2024-10-26,"Yunchong Liu, Xiaorui Shen, Yeyubei Zhang, Zhongyan Wang, Yexin Tian, Jianglai Dai, Yuchen Cao",http://arxiv.org/pdf/2410.20293v4,cs.LG
On the Gaussian process limit of Bayesian Additive Regression Trees,"Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian
regression technique of rising fame. It is a sum-of-decision-trees model, and
is in some sense the Bayesian version of boosting. In the limit of infinite
trees, it becomes equivalent to Gaussian process (GP) regression. This limit is
known but has not yet led to any useful analysis or application. For the first
time, I derive and compute the exact BART prior covariance function. With it I
implement the infinite trees limit of BART as GP regression. Through empirical
tests, I show that this limit is worse than standard BART in a fixed
configuration, but also that tuning the hyperparameters in the natural GP way
yields a competitive method, although a properly tuned BART is still superior.
The advantage of using a GP surrogate of BART is the analytical likelihood,
which simplifies model building and sidesteps the complex BART MCMC. More
generally, this study opens new ways to understand and develop BART and GP
regression. The implementation of BART as GP is available in the Python package
https://github.com/Gattocrucco/lsqfitgp .",2024-10-26,Giacomo Petrillo,http://arxiv.org/pdf/2410.20289v1,cs.LG
Classification under strategic adversary manipulation using pessimistic bilevel optimisation,"Adversarial machine learning concerns situations in which learners face
attacks from active adversaries. Such scenarios arise in applications such as
spam email filtering, malware detection and fake-image generation, where
security methods must be actively updated to keep up with the ever improving
generation of malicious data.We model these interactions between the learner
and the adversary as a game and formulate the problem as a pessimistic bilevel
optimisation problem with the learner taking the role of the leader. The
adversary, modelled as a stochastic data generator, takes the role of the
follower, generating data in response to the classifier. While existing models
rely on the assumption that the adversary will choose the least costly solution
leading to a convex lower-level problem with a unique solution, we present a
novel model and solution method which do not make such assumptions. We compare
these to the existing approach and see significant improvements in performance
suggesting that relaxing these assumptions leads to a more realistic model.",2024-10-26,"David Benfield, Stefano Coniglio, Martin Kunc, Phan Tu Vuong, Alain Zemkoho",http://arxiv.org/pdf/2410.20284v1,cs.LG
"Just Propagate: Unifying Matrix Factorization, Network Embedding, and LightGCN for Link Prediction","Link prediction is a fundamental task in graph analysis. Despite the success
of various graph-based machine learning models for link prediction, there lacks
a general understanding of different models. In this paper, we propose a
unified framework for link prediction that covers matrix factorization and
representative network embedding and graph neural network methods. Our
preliminary methodological and empirical analyses further reveal several key
design factors based on our unified framework. We believe our results could
deepen our understanding and inspire novel designs for link prediction methods.",2024-10-26,Haoxin Liu,http://arxiv.org/pdf/2410.21325v1,cs.LG
Proactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud,"As online fraud becomes more sophisticated and pervasive, traditional fraud
detection methods are struggling to keep pace with the evolving tactics
employed by fraudsters. This paper explores the transformative role of machine
learning in addressing these challenges by offering more advanced, scalable,
and adaptable solutions for fraud detection and prevention. By analyzing key
models such as Random Forest, Neural Networks, and Gradient Boosting, this
paper highlights the strengths of machine learning in processing vast datasets,
identifying intricate fraud patterns, and providing real-time predictions that
enable a proactive approach to fraud prevention. Unlike rule-based systems that
react after fraud has occurred, machine learning models continuously learn from
new data, adapting to emerging fraud schemes and reducing false positives,
which ultimately minimizes financial losses. This research emphasizes the
potential of machine learning to revolutionize fraud detection frameworks by
making them more dynamic, efficient, and capable of handling the growing
complexity of fraud across various industries. Future developments in machine
learning, including deep learning and hybrid models, are expected to further
enhance the predictive accuracy and applicability of these systems, ensuring
that organizations remain resilient in the face of new and emerging fraud
tactics.",2024-10-26,Md Kamrul Hasan Chy,http://arxiv.org/pdf/2410.20281v1,cs.LG
SPDIM: Source-Free Unsupervised Conditional and Label Shift Adaptation in EEG,"The non-stationary nature of electroencephalography (EEG) introduces
distribution shifts across domains (e.g., days and subjects), posing a
significant challenge to EEG-based neurotechnology generalization. Without
labeled calibration data for target domains, the problem is a source-free
unsupervised domain adaptation (SFUDA) problem. For scenarios with constant
label distribution, Riemannian geometry-aware statistical alignment frameworks
on the symmetric positive definite (SPD) manifold are considered
state-of-the-art. However, many practical scenarios, including EEG-based sleep
staging, exhibit label shifts. Here, we propose a geometric deep learning
framework for SFUDA problems under specific distribution shifts, including
label shifts. We introduce a novel, realistic generative model and show that
prior Riemannian statistical alignment methods on the SPD manifold can
compensate for specific marginal and conditional distribution shifts but hurt
generalization under label shifts. As a remedy, we propose a
parameter-efficient manifold optimization strategy termed SPDIM. SPDIM uses the
information maximization principle to learn a single SPD-manifold-constrained
parameter per target domain. In simulations, we demonstrate that SPDIM can
compensate for the shifts under our generative model. Moreover, using public
EEG-based brain-computer interface and sleep staging datasets, we show that
SPDIM outperforms prior approaches.",2024-10-26,"Shanglin Li, Motoaki Kawanabe, Reinmar J. Kobler",http://arxiv.org/pdf/2411.07249v4,cs.LG
"Library Learning Doesn't: The Curious Case of the Single-Use ""Library""","Advances in Large Language Models (LLMs) have spurred a wave of LLM library
learning systems for mathematical reasoning. These systems aim to learn a
reusable library of tools, such as formal Isabelle lemmas or Python programs
that are tailored to a family of tasks. Many of these systems are inspired by
the human structuring of knowledge into reusable and extendable concepts, but
do current methods actually learn reusable libraries of tools?
  We study two library learning systems for mathematics which both reported
increased accuracy: LEGO-Prover and TroVE. We find that function reuse is
extremely infrequent on miniF2F and MATH. Our followup ablation experiments
suggest that, rather than reuse, self-correction and self-consistency are the
primary drivers of the observed performance gains. Our code and data are
available at https://github.com/ikb-a/curious-case",2024-10-26,"Ian Berlot-Attwell, Frank Rudzicz, Xujie Si",http://arxiv.org/pdf/2410.20274v1,cs.LG
Centaur: a foundation model of human cognition,"Establishing a unified theory of cognition has been a major goal of
psychology. While there have been previous attempts to instantiate such
theories by building computational models, we currently do not have one model
that captures the human mind in its entirety. A first step in this direction is
to create a model that can predict human behavior in a wide range of settings.
Here we introduce Centaur, a computational model that can predict and simulate
human behavior in any experiment expressible in natural language. We derived
Centaur by finetuning a state-of-the-art language model on a novel, large-scale
data set called Psych-101. Psych-101 reaches an unprecedented scale, covering
trial-by-trial data from over 60,000 participants performing over 10,000,000
choices in 160 experiments. Centaur not only captures the behavior of held-out
participants better than existing cognitive models, but also generalizes to new
cover stories, structural task modifications, and entirely new domains.
Furthermore, we find that the model's internal representations become more
aligned with human neural activity after finetuning. Taken together, our
results demonstrate that it is possible to discover computational models that
capture human behavior across a wide range of domains. We believe that such
models provide tremendous potential for guiding the development of cognitive
theories and present a case study to demonstrate this.",2024-10-26,"Marcel Binz, Elif Akata, Matthias Bethge, Franziska Brändle, Fred Callaway, Julian Coda-Forno, Peter Dayan, Can Demircan, Maria K. Eckstein, Noémi Éltető, Thomas L. Griffiths, Susanne Haridi, Akshay K. Jagadish, Li Ji-An, Alexander Kipnis, Sreejan Kumar, Tobias Ludwig, Marvin Mathony, Marcelo Mattar, Alireza Modirshanechi, Surabhi S. Nath, Joshua C. Peterson, Milena Rmus, Evan M. Russek, Tankred Saanum, Johannes A. Schubert, Luca M. Schulze Buschoff, Nishad Singhi, Xin Sui, Mirko Thalmann, Fabian Theis, Vuong Truong, Vishaal Udandarao, Konstantinos Voudouris, Robert Wilson, Kristin Witte, Shuchen Wu, Dirk Wulff, Huadong Xiong, Eric Schulz",http://arxiv.org/pdf/2410.20268v3,cs.LG
Learning Maximal Safe Sets Using Hypernetworks for MPC-based Local Trajectory Planning in Unknown Environments,"This paper presents a novel learning-based approach for online estimation of
maximal safe sets for local trajectory planning in unknown static environments.
The neural representation of a set is used as the terminal set constraint for a
model predictive control (MPC) local planner, resulting in improved recursive
feasibility and safety. To achieve real-time performance and desired
generalization properties, we employ the idea of hypernetworks. We use the
Hamilton-Jacobi (HJ) reachability analysis as the source of supervision during
the training process, allowing us to consider general nonlinear dynamics and
arbitrary constraints. The proposed method is extensively evaluated against
relevant baselines in simulations for different environments and robot
dynamics. The results show a success rate increase of up to 52 \% compared to
the best baseline while maintaining comparable execution speed. Additionally,
we deploy our proposed method, NTC-MPC, on a physical robot and demonstrate its
ability to safely avoid obstacles in scenarios where the baselines fail.",2024-10-26,"Bojan Derajić, Mohamed-Khalil Bouzidi, Sebastian Bernhard, Wolfgang Hönig",http://arxiv.org/pdf/2410.20267v2,cs.LG
You Never Know: Quantization Induces Inconsistent Biases in Vision-Language Foundation Models,"We study the impact of a standard practice in compressing foundation
vision-language models - quantization - on the models' ability to produce
socially-fair outputs. In contrast to prior findings with unimodal models that
compression consistently amplifies social biases, our extensive evaluation of
four quantization settings across three datasets and three CLIP variants yields
a surprising result: while individual models demonstrate bias, we find no
consistent change in bias magnitude or direction across a population of
compressed models due to quantization.",2024-10-26,"Eric Slyman, Anirudh Kanneganti, Sanghyun Hong, Stefan Lee",http://arxiv.org/pdf/2410.20265v1,cs.LG
Equivariant Blurring Diffusion for Hierarchical Molecular Conformer Generation,"How can diffusion models process 3D geometries in a coarse-to-fine manner,
akin to our multiscale view of the world? In this paper, we address the
question by focusing on a fundamental biochemical problem of generating 3D
molecular conformers conditioned on molecular graphs in a multiscale manner.
Our approach consists of two hierarchical stages: i) generation of
coarse-grained fragment-level 3D structure from the molecular graph, and ii)
generation of fine atomic details from the coarse-grained approximated
structure while allowing the latter to be adjusted simultaneously. For the
challenging second stage, which demands preserving coarse-grained information
while ensuring SE(3) equivariance, we introduce a novel generative model termed
Equivariant Blurring Diffusion (EBD), which defines a forward process that
moves towards the fragment-level coarse-grained structure by blurring the fine
atomic details of conformers, and a reverse process that performs the opposite
operation using equivariant networks. We demonstrate the effectiveness of EBD
by geometric and chemical comparison to state-of-the-art denoising diffusion
models on a benchmark of drug-like molecules. Ablation studies draw insights on
the design of EBD by thoroughly analyzing its architecture, which includes the
design of the loss function and the data corruption process. Codes are released
at https://github.com/Shen-Lab/EBD .",2024-10-26,"Jiwoong Park, Yang Shen",http://arxiv.org/pdf/2410.20255v1,cs.LG
Overcoming the Sim-to-Real Gap: Leveraging Simulation to Learn to Explore for Real-World RL,"In order to mitigate the sample complexity of real-world reinforcement
learning, common practice is to first train a policy in a simulator where
samples are cheap, and then deploy this policy in the real world, with the hope
that it generalizes effectively. Such \emph{direct sim2real} transfer is not
guaranteed to succeed, however, and in cases where it fails, it is unclear how
to best utilize the simulator. In this work, we show that in many regimes,
while direct sim2real transfer may fail, we can utilize the simulator to learn
a set of \emph{exploratory} policies which enable efficient exploration in the
real world. In particular, in the setting of low-rank MDPs, we show that
coupling these exploratory policies with simple, practical approaches --
least-squares regression oracles and naive randomized exploration -- yields a
polynomial sample complexity in the real world, an exponential improvement over
direct sim2real transfer, or learning without access to a simulator. To the
best of our knowledge, this is the first evidence that simulation transfer
yields a provable gain in reinforcement learning in settings where direct
sim2real transfer fails. We validate our theoretical results on several
realistic robotic simulators and a real-world robotic sim2real task,
demonstrating that transferring exploratory policies can yield substantial
gains in practice as well.",2024-10-26,"Andrew Wagenmaker, Kevin Huang, Liyiming Ke, Byron Boots, Kevin Jamieson, Abhishek Gupta",http://arxiv.org/pdf/2410.20254v1,cs.LG
Robust Model Evaluation over Large-scale Federated Networks,"In this paper, we address the challenge of certifying the performance of a
machine learning model on an unseen target network, using measurements from an
available source network. We focus on a scenario where heterogeneous datasets
are distributed across a source network of clients, all connected to a central
server. Specifically, consider a source network ""A"" composed of $K$ clients,
each holding private data from unique and heterogeneous distributions, which
are assumed to be independent samples from a broader meta-distribution $\mu$.
Our goal is to provide certified guarantees for the model's performance on a
different, unseen target network ""B,"" governed by another meta-distribution
$\mu'$, assuming the deviation between $\mu$ and $\mu'$ is bounded by either
the Wasserstein distance or an $f$-divergence. We derive theoretical guarantees
for the model's empirical average loss and provide uniform bounds on the risk
CDF, where the latter correspond to novel and adversarially robust versions of
the Glivenko-Cantelli theorem and the Dvoretzky-Kiefer-Wolfowitz (DKW)
inequality. Our bounds are computable in polynomial time with a polynomial
number of queries to the $K$ clients, preserving client privacy by querying
only the model's (potentially adversarial) loss on private data. We also
establish non-asymptotic generalization bounds that consistently converge to
zero as both $K$ and the minimum client sample size grow. Extensive empirical
evaluations validate the robustness and practicality of our bounds across
real-world tasks.",2024-10-26,"Amir Najafi, Samin Mahdizadeh Sani, Farzan Farnia",http://arxiv.org/pdf/2410.20250v1,cs.LG
Convergence Guarantees for the DeepWalk Embedding on Block Models,"Graph embeddings have emerged as a powerful tool for understanding the
structure of graphs. Unlike classical spectral methods, recent methods such as
DeepWalk, Node2Vec, etc. are based on solving nonlinear optimization problems
on the graph, using local information obtained by performing random walks.
These techniques have empirically been shown to produce ''better'' embeddings
than their classical counterparts. However, due to their reliance on solving a
nonconvex optimization problem, obtaining theoretical guarantees on the
properties of the solution has remained a challenge, even for simple classes of
graphs. In this work, we show convergence properties for the DeepWalk algorithm
on graphs obtained from the Stochastic Block Model (SBM). Despite being
simplistic, the SBM has proved to be a classic model for analyzing the behavior
of algorithms on large graphs. Our results mirror the existing ones for
spectral embeddings on SBMs, showing that even in the case of one-dimensional
embeddings, the output of the DeepWalk algorithm provably recovers the cluster
structure with high probability.",2024-10-26,"Christopher Harker, Aditya Bhaskara",http://arxiv.org/pdf/2410.20248v1,cs.LG
Model Equality Testing: Which Model Is This API Serving?,"Users often interact with large language models through black-box inference
APIs, both for closed- and open-weight models (e.g., Llama models are popularly
accessed via Amazon Bedrock and Azure AI Studio). In order to cut costs or add
functionality, API providers may quantize, watermark, or finetune the
underlying model, changing the output distribution -- possibly without
notifying users. We formalize detecting such distortions as Model Equality
Testing, a two-sample testing problem, where the user collects samples from the
API and a reference distribution and conducts a statistical test to see if the
two distributions are the same. We find that tests based on the Maximum Mean
Discrepancy between distributions are powerful for this task: a test built on a
simple string kernel achieves a median of 77.4% power against a range of
distortions, using an average of just 10 samples per prompt. We then apply this
test to commercial inference APIs from Summer 2024 for four Llama models,
finding that 11 out of 31 endpoints serve different distributions than
reference weights released by Meta.",2024-10-26,"Irena Gao, Percy Liang, Carlos Guestrin",http://arxiv.org/pdf/2410.20247v2,cs.LG
Improving Model Evaluation using SMART Filtering of Benchmark Datasets,"One of the most challenging problems facing NLP today is evaluation. Some of
the most pressing issues pertain to benchmark saturation, data contamination,
and diversity in the quality of test examples. To address these concerns, we
propose Selection Methodology for Accurate, Reduced, and Targeted (SMART)
filtering, a novel approach to select a high-quality subset of examples from
existing benchmark datasets by systematically removing less informative and
less challenging examples. Our approach applies three filtering criteria,
removing (i) easy examples, (ii) data-contaminated examples, and (iii) examples
that are similar to each other based on distance in an embedding space. We
demonstrate the effectiveness of SMART on three multiple choice QA datasets,
where our methodology increases efficiency by reducing dataset size by 48\% on
average, while increasing Pearson correlation with rankings from ChatBot Arena,
a more open-ended human evaluation setting. Our method enables us to be more
efficient, whether using SMART to make new benchmarks more challenging or to
revitalize older datasets, while still preserving the relative model rankings.",2024-10-26,"Vipul Gupta, Candace Ross, David Pantoja, Rebecca J. Passonneau, Megan Ung, Adina Williams",http://arxiv.org/pdf/2410.20245v2,cs.LG
Hoeffding adaptive trees for multi-label classification on data streams,"Data stream learning is a very relevant paradigm because of the increasing
real-world scenarios generating data at high velocities and in unbounded
sequences. Stream learning aims at developing models that can process instances
as they arrive, so models constantly adapt to new concepts and the temporal
evolution in the stream. In multi-label data stream environments where
instances have the peculiarity of belonging simultaneously to more than one
class, the problem becomes even more complex and poses unique challenges such
as different concept drifts impacting different labels at simultaneous or
distinct times, higher class imbalance, or new labels emerging in the stream.
This paper proposes a novel approach to multi-label data stream classification
called Multi-Label Hoeffding Adaptive Tree (MLHAT). MLHAT leverages the
Hoeffding adaptive tree to address these challenges by considering possible
relations and label co-occurrences in the partitioning process of the decision
tree, dynamically adapting the learner in each leaf node of the tree, and
implementing a concept drift detector that can quickly detect and replace tree
branches that are no longer performing well. The proposed approach is compared
with other 18 online multi-label classifiers on 41 datasets. The results,
validated with statistical analysis, show that MLHAT outperforms other
state-of-the-art approaches in 12 well-known multi-label metrics.",2024-10-26,"Aurora Esteban, Alberto Cano, Amelia Zafra, Sebastián Ventura",http://arxiv.org/pdf/2410.20242v1,cs.LG
SAFE setup for generative molecular design,"SMILES-based molecular generative models have been pivotal in drug design but
face challenges in fragment-constrained tasks. To address this, the Sequential
Attachment-based Fragment Embedding (SAFE) representation was recently
introduced as an alternative that streamlines those tasks. In this study, we
investigate the optimal setups for training SAFE generative models, focusing on
dataset size, data augmentation through randomization, model architecture, and
bond disconnection algorithms. We found that larger, more diverse datasets
improve performance, with the LLaMA architecture using Rotary Positional
Embedding proving most robust. SAFE-based models also consistently outperform
SMILES-based approaches in scaffold decoration and linker design, particularly
with BRICS decomposition yielding the best results. These insights highlight
key factors that significantly impact the efficacy of SAFE-based generative
models.",2024-10-26,"Yassir El Mesbahi, Emmanuel Noutahi",http://arxiv.org/pdf/2410.20232v1,cs.LG
Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts,"Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.",2024-10-26,"Vishesh Prasad, Brian Kim, Nickvash Kani",http://arxiv.org/pdf/2410.21324v1,cs.LG
Recursive Function Definitions in Static Dataflow Graphs and their Implementation in TensorFlow,"Modern machine learning systems represent their computations as dataflow
graphs. The increasingly complex neural network architectures crave for more
powerful yet efficient programming abstractions. In this paper we propose an
efficient technique for supporting recursive function definitions in
dataflow-based systems such as TensorFlow. The proposed approach transforms the
given recursive definitions into a static dataflow graph that is enriched with
two simple yet powerful dataflow operations. Since static graphs do not change
during execution, they can be easily partitioned and executed efficiently in
distributed and heterogeneous environments. The proposed technique makes heavy
use of the idea of tagging, which was one of the cornerstones of dataflow
systems since their inception. We demonstrate that our technique is compatible
with the idea of automatic differentiation, a notion that is crucial for
dataflow systems that focus on deep learning applications. We describe the
principles of an actual implementation of the technique in the TensorFlow
framework, and present experimental results that demonstrate that the use of
tagging is of paramount importance for developing efficient high-level
abstractions for modern dataflow systems.",2024-10-26,"Kelly Kostopoulou, Angelos Charalambidis, Panos Rondogiannis",http://arxiv.org/pdf/2410.20225v1,cs.LG
Neural Fields in Robotics: A Survey,"Neural Fields have emerged as a transformative approach for 3D scene
representation in computer vision and robotics, enabling accurate inference of
geometry, 3D semantics, and dynamics from posed 2D data. Leveraging
differentiable rendering, Neural Fields encompass both continuous implicit and
explicit neural representations enabling high-fidelity 3D reconstruction,
integration of multi-modal sensor data, and generation of novel viewpoints.
This survey explores their applications in robotics, emphasizing their
potential to enhance perception, planning, and control. Their compactness,
memory efficiency, and differentiability, along with seamless integration with
foundation and generative models, make them ideal for real-time applications,
improving robot adaptability and decision-making. This paper provides a
thorough review of Neural Fields in robotics, categorizing applications across
various domains and evaluating their strengths and limitations, based on over
200 papers. First, we present four key Neural Fields frameworks: Occupancy
Networks, Signed Distance Fields, Neural Radiance Fields, and Gaussian
Splatting. Second, we detail Neural Fields' applications in five major robotics
domains: pose estimation, manipulation, navigation, physics, and autonomous
driving, highlighting key works and discussing takeaways and open challenges.
Finally, we outline the current limitations of Neural Fields in robotics and
propose promising directions for future research. Project page:
https://robonerf.github.io",2024-10-26,"Muhammad Zubair Irshad, Mauro Comi, Yen-Chen Lin, Nick Heppert, Abhinav Valada, Rares Ambrus, Zsolt Kira, Jonathan Tremblay",http://arxiv.org/pdf/2410.20220v1,cs.LG
Looking Beyond The Top-1: Transformers Determine Top Tokens In Order,"Understanding the inner workings of Transformers is crucial for achieving
more accurate and efficient predictions. In this work, we analyze the
computation performed by Transformers in the layers after the top-1 prediction
has become fixed, which has been previously referred to as the ""saturation
event"". We expand the concept of saturation events for top-k tokens,
demonstrating that similar saturation events occur across language, vision, and
speech models. We find that these saturation events happen in order of the
corresponding tokens' ranking, i.e., the model first decides on the top ranking
token, then the second highest ranking token, and so on. This phenomenon seems
intrinsic to the Transformer architecture, occurring across different
architectural variants (decoder-only, encoder-only, and to a lesser extent
full-Transformer), and even in untrained Transformers. We propose an underlying
mechanism of task transition for this sequential saturation, where task k
corresponds to predicting the k-th most probable token, and the saturation
events are in fact discrete transitions between the tasks. In support of this
we show that it is possible to predict the current task from hidden layer
embedding. Furthermore, using an intervention method we demonstrate that we can
cause the model to switch from one task to the next. Finally, leveraging our
findings, we introduce a novel token-level early-exit strategy, which surpasses
existing methods in balancing performance and efficiency.",2024-10-26,"Daria Lioubashevski, Tomer Schlank, Gabriel Stanovsky, Ariel Goldstein",http://arxiv.org/pdf/2410.20210v1,cs.LG
Revisiting Differential Verification: Equivalence Verification with Confidence,"When validated neural networks (NNs) are pruned (and retrained) before
deployment, it is desirable to prove that the new NN behaves equivalently to
the (original) reference NN. To this end, our paper revisits the idea of
differential verification which performs reasoning on differences between NNs:
On the one hand, our paper proposes a novel abstract domain for differential
verification admitting more efficient reasoning about equivalence. On the other
hand, we investigate empirically and theoretically which equivalence properties
are (not) efficiently solved using differential reasoning. Based on the gained
insights, and following a recent line of work on confidence-based verification,
we propose a novel equivalence property that is amenable to Differential
Verification while providing guarantees for large parts of the input space
instead of small-scale guarantees constructed w.r.t. predetermined input
points. We implement our approach in a new tool called VeryDiff and perform an
extensive evaluation on numerous old and new benchmark families, including new
pruned NNs for particle jet classification in the context of CERN's LHC where
we observe median speedups >300x over the State-of-the-Art verifier
alpha,beta-CROWN.",2024-10-26,"Samuel Teuber, Philipp Kern, Marvin Janzen, Bernhard Beckert",http://arxiv.org/pdf/2410.20207v2,cs.LG
"Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications, an ISPOR Working Group Report","Objective: This article offers a taxonomy of generative artificial
intelligence (AI) for health economics and outcomes research (HEOR), explores
its emerging applications, and outlines methods to enhance the accuracy and
reliability of AI-generated outputs. Methods: The review defines foundational
generative AI concepts and highlights current HEOR applications, including
systematic literature reviews, health economic modeling, real-world evidence
generation, and dossier development. Approaches such as prompt engineering
(zero-shot, few-shot, chain-of-thought, persona pattern prompting),
retrieval-augmented generation, model fine-tuning, and the use of
domain-specific models are introduced to improve AI accuracy and reliability.
Results: Generative AI shows significant potential in HEOR, enhancing
efficiency, productivity, and offering novel solutions to complex challenges.
Foundation models are promising in automating complex tasks, though challenges
remain in scientific reliability, bias, interpretability, and workflow
integration. The article discusses strategies to improve the accuracy of these
AI tools. Conclusion: Generative AI could transform HEOR by increasing
efficiency and accuracy across various applications. However, its full
potential can only be realized by building HEOR expertise and addressing the
limitations of current AI technologies. As AI evolves, ongoing research and
innovation will shape its future role in the field.",2024-10-26,"Rachael Fleurence, Xiaoyan Wang, Jiang Bian, Mitchell K. Higashi, Turgay Ayer, Hua Xu, Dalia Dawoud, Jagpreet Chhatwal",http://arxiv.org/pdf/2410.20204v2,cs.LG
Transferable Adversarial Attacks on SAM and Its Downstream Models,"The utilization of large foundational models has a dilemma: while fine-tuning
downstream tasks from them holds promise for making use of the well-generalized
knowledge in practical applications, their open accessibility also poses
threats of adverse usage. This paper, for the first time, explores the
feasibility of adversarial attacking various downstream models fine-tuned from
the segment anything model (SAM), by solely utilizing the information from the
open-sourced SAM. In contrast to prevailing transfer-based adversarial attacks,
we demonstrate the existence of adversarial dangers even without accessing the
downstream task and dataset to train a similar surrogate model. To enhance the
effectiveness of the adversarial attack towards models fine-tuned on unknown
datasets, we propose a universal meta-initialization (UMI) algorithm to extract
the intrinsic vulnerability inherent in the foundation model, which is then
utilized as the prior knowledge to guide the generation of adversarial
perturbations. Moreover, by formulating the gradient difference in the
attacking process between the open-sourced SAM and its fine-tuned downstream
models, we theoretically demonstrate that a deviation occurs in the adversarial
update direction by directly maximizing the distance of encoded feature
embeddings in the open-sourced SAM. Consequently, we propose a gradient robust
loss that simulates the associated uncertainty with gradient-based noise
augmentation to enhance the robustness of generated adversarial examples (AEs)
towards this deviation, thus improving the transferability. Extensive
experiments demonstrate the effectiveness of the proposed universal
meta-initialized and gradient robust adversarial attack (UMI-GRAT) toward SAMs
and their downstream models. Code is available at
https://github.com/xiasong0501/GRAT.",2024-10-26,"Song Xia, Wenhan Yang, Yi Yu, Xun Lin, Henghui Ding, Ling-Yu Duan, Xudong Jiang",http://arxiv.org/pdf/2410.20197v3,cs.LG
Securing Healthcare with Deep Learning: A CNN-Based Model for medical IoT Threat Detection,"The increasing integration of the Internet of Medical Things (IoMT) into
healthcare systems has significantly enhanced patient care but has also
introduced critical cybersecurity challenges. This paper presents a novel
approach based on Convolutional Neural Networks (CNNs) for detecting
cyberattacks within IoMT environments. Unlike previous studies that
predominantly utilized traditional machine learning (ML) models or simpler Deep
Neural Networks (DNNs), the proposed model leverages the capabilities of CNNs
to effectively analyze the temporal characteristics of network traffic data.
Trained and evaluated on the CICIoMT2024 dataset, which comprises 18 distinct
types of cyberattacks across a range of IoMT devices, the proposed CNN model
demonstrates superior performance compared to previous state-of-the-art
methods, achieving a perfect accuracy of 99% in binary, categorical, and
multiclass classification tasks. This performance surpasses that of
conventional ML models such as Logistic Regression, AdaBoost, DNNs, and Random
Forests. These findings highlight the potential of CNNs to substantially
improve IoMT cybersecurity, thereby ensuring the protection and integrity of
connected healthcare systems.",2024-10-26,"Alireza Mohamadi, Hosna Ghahramani, Seyyed Amir Asghari, Mehdi Aminian",http://arxiv.org/pdf/2410.23306v3,cs.LG
Uncertainty-Penalized Direct Preference Optimization,"Aligning Large Language Models (LLMs) to human preferences in content, style,
and presentation is challenging, in part because preferences are varied,
context-dependent, and sometimes inherently ambiguous. While successful,
Reinforcement Learning from Human Feedback (RLHF) and Direct Preference
Optimization (DPO) are prone to the issue of proxy reward overoptimization.
Analysis of the DPO loss reveals a critical need for regularization for
mislabeled or ambiguous preference pairs to avoid reward hacking. In this work,
we develop a pessimistic framework for DPO by introducing preference
uncertainty penalization schemes, inspired by offline reinforcement learning.
The penalization serves as a correction to the loss which attenuates the loss
gradient for uncertain samples. Evaluation of the methods is performed with
GPT2 Medium on the Anthropic-HH dataset using a model ensemble to obtain
uncertainty estimates, and shows improved overall performance compared to
vanilla DPO, as well as better completions on prompts from high-uncertainty
chosen/rejected responses.",2024-10-26,"Sam Houliston, Alizée Pace, Alexander Immer, Gunnar Rätsch",http://arxiv.org/pdf/2410.20187v1,cs.LG
Angel or Devil: Discriminating Hard Samples and Anomaly Contaminations for Unsupervised Time Series Anomaly Detection,"Training in unsupervised time series anomaly detection is constantly plagued
by the discrimination between harmful `anomaly contaminations' and beneficial
`hard normal samples'. These two samples exhibit analogous loss behavior that
conventional loss-based methodologies struggle to differentiate. To tackle this
problem, we propose a novel approach that supplements traditional loss behavior
with `parameter behavior', enabling a more granular characterization of
anomalous patterns. Parameter behavior is formalized by measuring the
parametric response to minute perturbations in input samples. Leveraging the
complementary nature of parameter and loss behaviors, we further propose a dual
Parameter-Loss Data Augmentation method (termed PLDA), implemented within the
reinforcement learning paradigm. During the training phase of anomaly
detection, PLDA dynamically augments the training data through an iterative
process that simultaneously mitigates anomaly contaminations while amplifying
informative hard normal samples. PLDA demonstrates remarkable versatility,
which can serve as an additional component that seamlessly integrated with
existing anomaly detectors to enhance their detection performance. Extensive
experiments on ten datasets show that PLDA significantly improves the
performance of four distinct detectors by up to 8\%, outperforming three
state-of-the-art data augmentation methods.",2024-10-26,"Ruyi Zhang, Hongzuo Xu, Songlei Jian, Yusong Tan, Haifang Zhou, Rulin Xu",http://arxiv.org/pdf/2410.21322v1,cs.LG
Chemical Language Model Linker: blending text and molecules with modular adapters,"The development of large language models and multi-modal models has enabled
the appealing idea of generating novel molecules from text descriptions.
Generative modeling would shift the paradigm from relying on large-scale
chemical screening to find molecules with desired properties to directly
generating those molecules. However, multi-modal models combining text and
molecules are often trained from scratch, without leveraging existing
high-quality pretrained models. Training from scratch consumes more
computational resources and prohibits model scaling. In contrast, we propose a
lightweight adapter-based strategy named Chemical Language Model Linker
(ChemLML). ChemLML blends the two single domain models and obtains conditional
molecular generation from text descriptions while still operating in the
specialized embedding spaces of the molecular domain. ChemLML can tailor
diverse pretrained text models for molecule generation by training relatively
few adapter parameters. We find that the choice of molecular representation
used within ChemLML, SMILES versus SELFIES, has a strong influence on
conditional molecular generation performance. SMILES is often preferable
despite not guaranteeing valid molecules. We raise issues in using the entire
PubChem dataset of molecules and their associated descriptions for evaluating
molecule generation and provide a filtered version of the dataset as a
generation test set. To demonstrate how ChemLML could be used in practice, we
generate candidate protein inhibitors and use docking to assess their quality
and also generate candidate membrane permeable molecules.",2024-10-26,"Yifan Deng, Spencer S. Ericksen, Anthony Gitter",http://arxiv.org/pdf/2410.20182v2,cs.LG
Copyright-Aware Incentive Scheme for Generative Art Models Using Hierarchical Reinforcement Learning,"Generative art using Diffusion models has achieved remarkable performance in
image generation and text-to-image tasks. However, the increasing demand for
training data in generative art raises significant concerns about copyright
infringement, as models can produce images highly similar to copyrighted works.
Existing solutions attempt to mitigate this by perturbing Diffusion models to
reduce the likelihood of generating such images, but this often compromises
model performance. Another approach focuses on economically compensating data
holders for their contributions, yet it fails to address copyright loss
adequately. Our approach begin with the introduction of a novel copyright
metric grounded in copyright law and court precedents on infringement. We then
employ the TRAK method to estimate the contribution of data holders. To
accommodate the continuous data collection process, we divide the training into
multiple rounds. Finally, We designed a hierarchical budget allocation method
based on reinforcement learning to determine the budget for each round and the
remuneration of the data holder based on the data holder's contribution and
copyright loss in each round. Extensive experiments across three datasets show
that our method outperforms all eight benchmarks, demonstrating its
effectiveness in optimizing budget distribution in a copyright-aware manner. To
the best of our knowledge, this is the first technical work that introduces to
incentive contributors and protect their copyrights by compensating them.",2024-10-26,"Zhuan Shi, Yifei Song, Xiaoli Tang, Lingjuan Lyu, Boi Faltings",http://arxiv.org/pdf/2410.20180v2,cs.LG
LLMs Can Evolve Continually on Modality for X-Modal Reasoning,"Multimodal Large Language Models (MLLMs) have gained significant attention
due to their impressive capabilities in multimodal understanding. However,
existing methods rely heavily on extensive modal-specific pretraining and
joint-modal tuning, leading to significant computational burdens when expanding
to new modalities. In this paper, we propose PathWeave, a flexible and scalable
framework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs
to continually EVolve on modalities for $\mathbb{X}$-modal reasoning. We
leverage the concept of Continual Learning and develop an incremental training
strategy atop pre-trained MLLMs, enabling their expansion to new modalities
using uni-modal data, without executing joint-modal pretraining. In detail, a
novel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and
cross-modal adapters are seamlessly integrated to facilitate efficient modality
alignment and collaboration. Additionally, an MoE-based gating module is
applied between two types of adapters to further enhance the multimodal
interaction. To investigate the proposed method, we establish a challenging
benchmark called Continual Learning of Modality (MCL), which consists of
high-quality QA data from five distinct modalities: image, video, audio, depth
and point cloud. Extensive experiments demonstrate the effectiveness of the
proposed AnA framework on learning plasticity and memory stability during
continual learning. Furthermore, PathWeave performs comparably to
state-of-the-art MLLMs while concurrently reducing parameter training burdens
by 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave",2024-10-26,"Jiazuo Yu, Haomiao Xiong, Lu Zhang, Haiwen Diao, Yunzhi Zhuge, Lanqing Hong, Dong Wang, Huchuan Lu, You He, Long Chen",http://arxiv.org/pdf/2410.20178v2,cs.LG
Beyond Simple Sum of Delayed Rewards: Non-Markovian Reward Modeling for Reinforcement Learning,"Reinforcement Learning (RL) empowers agents to acquire various skills by
learning from reward signals. Unfortunately, designing high-quality
instance-level rewards often demands significant effort. An emerging
alternative, RL with delayed reward, focuses on learning from rewards presented
periodically, which can be obtained from human evaluators assessing the agent's
performance over sequences of behaviors. However, traditional methods in this
domain assume the existence of underlying Markovian rewards and that the
observed delayed reward is simply the sum of instance-level rewards, both of
which often do not align well with real-world scenarios. In this paper, we
introduce the problem of RL from Composite Delayed Reward (RLCoDe), which
generalizes traditional RL from delayed rewards by eliminating the strong
assumption. We suggest that the delayed reward may arise from a more complex
structure reflecting the overall contribution of the sequence. To address this
problem, we present a framework for modeling composite delayed rewards, using a
weighted sum of non-Markovian components to capture the different contributions
of individual steps. Building on this framework, we propose Composite Delayed
Reward Transformer (CoDeTr), which incorporates a specialized in-sequence
attention mechanism to effectively model these contributions. We conduct
experiments on challenging locomotion tasks where the agent receives delayed
rewards computed from composite functions of observable step rewards. The
experimental results indicate that CoDeTr consistently outperforms baseline
methods across evaluated metrics. Additionally, we demonstrate that it
effectively identifies the most significant time steps within the sequence and
accurately predicts rewards that closely reflect the environment feedback.",2024-10-26,"Yuting Tang, Xin-Qiang Cai, Jing-Cheng Pang, Qiyu Wu, Yao-Xiang Ding, Masashi Sugiyama",http://arxiv.org/pdf/2410.20176v1,cs.LG
Alternatives of Unsupervised Representations of Variables on the Latent Space,"The article addresses the application of unsupervised machine learning to
represent variables on the 2D latent space by applying a variational
autoencoder (beta-VAE). Representation of variables on low dimensional spaces
allows for data visualization, disentanglement of variables based on underlying
characteristics, finding of meaningful patterns and outliers, and supports
interpretability. Five distinct methods have been introduced to represent
variables on the latent space: (1) straightforward transposed, (2) univariate
metadata of variables, such as variable statistics, empirical probability
density and cumulative distribution functions, (3) adjacency matrices of
different metrics, such as correlations, R2 values, Jaccard index, cosine
similarity, and mutual information, (4) gradient mappings followed by spot
cross product calculation, and (5) combined. Twenty-eight approaches of
variable representations by beta-VAE have been considered. The pairwise spot
cross product addresses relationships of gradients of two variables along
latent space axes, such as orthogonal, confounded positive, confounded
negative, and everything in between. The article addresses generalized
representations of variables that cover both features and labels. Dealing with
categorical variables, reinforced entanglement has been introduced to represent
one-hot encoded categories. The article includes three examples: (1) synthetic
data with known dependencies, (2) famous MNIST example of handwritten numbers,
and (3) real-world multivariate time series of Canadian financial market
interest rates. As a result, unsupervised representations of interest rates on
the latent space correctly disentangled rates based on their type, such as
bonds, T-bills, GICs, or conventional mortgages, positioned bonds and T-bills
along a single curve, and ordered rates by their terms along that curve.",2024-10-26,Alex Glushkovsky,http://arxiv.org/pdf/2410.20172v1,cs.LG
Cyberbullying or just Sarcasm? Unmasking Coordinated Networks on Reddit,"With the rapid growth of social media usage, a common trend has emerged where
users often make sarcastic comments on posts. While sarcasm can sometimes be
harmless, it can blur the line with cyberbullying, especially when used in
negative or harmful contexts. This growing issue has been exacerbated by the
anonymity and vast reach of the internet, making cyberbullying a significant
concern on platforms like Reddit. Our research focuses on distinguishing
cyberbullying from sarcasm, particularly where online language nuances make it
difficult to discern harmful intent. This study proposes a framework using
natural language processing (NLP) and machine learning to differentiate between
the two, addressing the limitations of traditional sentiment analysis in
detecting nuanced behaviors. By analyzing a custom dataset scraped from Reddit,
we achieved a 95.15% accuracy in distinguishing harmful content from sarcasm.
Our findings also reveal that teenagers and minority groups are particularly
vulnerable to cyberbullying. Additionally, our research uncovers coordinated
graphs of groups involved in cyberbullying, identifying common patterns in
their behavior. This research contributes to improving detection capabilities
for safer online communities.",2024-10-26,"Pinky Pamecha, Chaitya Shah, Divyam Jain, Kashish Gandhi, Kiran Bhowmick, Meera Narvekar",http://arxiv.org/pdf/2410.20170v1,cs.LG
Infectious Disease Forecasting in India using LLM's and Deep Learning,"Many uncontrollable disease outbreaks of the past exposed several
vulnerabilities in the healthcare systems worldwide. While advancements in
technology assisted in the rapid creation of the vaccinations, there needs to
be a pressing focus on the prevention and prediction of such massive outbreaks.
Early detection and intervention of an outbreak can drastically reduce its
impact on public health while also making the healthcare system more resilient.
The complexity of disease transmission dynamics, influence of various directly
and indirectly related factors and limitations of traditional approaches are
the main bottlenecks in taking preventive actions. Specifically, this paper
implements deep learning algorithms and LLM's to predict the severity of
infectious disease outbreaks. Utilizing the historic data of several diseases
that have spread in India and the climatic data spanning the past decade, the
insights from our research aim to assist in creating a robust predictive system
for any outbreaks in the future.",2024-10-26,"Chaitya Shah, Kashish Gandhi, Javal Shah, Kreena Shah, Nilesh Patil, Kiran Bhowmick",http://arxiv.org/pdf/2410.20168v1,cs.LG
DeepMIDE: A Multivariate Spatio-Temporal Method for Ultra-Scale Offshore Wind Energy Forecasting,"To unlock access to stronger winds, the offshore wind industry is advancing
with significantly larger and taller wind turbines. This massive upscaling
motivates a departure from univariate wind forecasting methods that
traditionally focused on a single representative height. To fill this gap, we
propose DeepMIDE--a statistical deep learning method which jointly models the
offshore wind speeds across space, time, and height. DeepMIDE is formulated as
a multi-output integro-difference equation model with a multivariate,
nonstationary, and state-dependent kernel characterized by a set of advection
vectors that encode the physics of wind field formation and propagation.
Embedded within DeepMIDE, an advanced deep learning architecture learns these
advection vectors from high dimensional streams of exogenous weather
information, which, along with other parameters, are plugged back into the
statistical model for probabilistic multi-height space-time forecasting. Tested
on real-world data from future offshore wind energy sites in the Northeastern
United States, the wind speed and power forecasts from DeepMIDE are shown to
outperform those from prevalent time series, spatio-temporal, and deep learning
methods.",2024-10-26,"Feng Ye, Xinxi Zhang, Michael Stein, Ahmed Aziz Ezzat",http://arxiv.org/pdf/2410.20166v1,cs.LG
Prompt Diffusion Robustifies Any-Modality Prompt Learning,"Foundation models enable prompt-based classifiers for zero-shot and few-shot
learning. Nonetheless, the conventional method of employing fixed prompts
suffers from distributional shifts that negatively impact generalizability to
unseen samples. This paper introduces prompt diffusion, which uses a diffusion
model to gradually refine the prompts to obtain a customized prompt for each
sample. Specifically, we first optimize a collection of prompts to obtain
over-fitted prompts per sample. Then, we propose a prompt diffusion model
within the prompt space, enabling the training of a generative transition
process from a random prompt to its overfitted prompt. As we cannot access the
label of a test image during inference, our model gradually generates
customized prompts solely from random prompts using our trained, prompt
diffusion. Our prompt diffusion is generic, flexible, and modality-agnostic,
making it a simple plug-and-play module seamlessly embedded into existing
prompt learning methods for textual, visual, or multi-modal prompt learning.
Our diffusion model uses a fast ODE-based sampling strategy to optimize test
sample prompts in just five steps, offering a good trade-off between
performance improvement and computational efficiency. For all prompt learning
methods tested, adding prompt diffusion yields more robust results for
base-to-new generalization, cross-dataset generalization, and domain
generalization in classification tasks tested over 15 diverse datasets.",2024-10-26,"Yingjun Du, Gaowen Liu, Yuzhang Shang, Yuguang Yao, Ramana Kompella, Cees G. M. Snoek",http://arxiv.org/pdf/2410.20164v1,cs.LG
Causal Abstraction in Model Interpretability: A Compact Survey,"The pursuit of interpretable artificial intelligence has led to significant
advancements in the development of methods that aim to explain the
decision-making processes of complex models, such as deep learning systems.
Among these methods, causal abstraction stands out as a theoretical framework
that provides a principled approach to understanding and explaining the causal
mechanisms underlying model behavior. This survey paper delves into the realm
of causal abstraction, examining its theoretical foundations, practical
applications, and implications for the field of model interpretability.",2024-10-26,Yihao Zhang,http://arxiv.org/pdf/2410.20161v1,cs.LG
Your Image is Secretly the Last Frame of a Pseudo Video,"Diffusion models, which can be viewed as a special case of hierarchical
variational autoencoders (HVAEs), have shown profound success in generating
photo-realistic images. In contrast, standard HVAEs often produce images of
inferior quality compared to diffusion models. In this paper, we hypothesize
that the success of diffusion models can be partly attributed to the additional
self-supervision information for their intermediate latent states provided by
corrupted images, which along with the original image form a pseudo video.
Based on this hypothesis, we explore the possibility of improving other types
of generative models with such pseudo videos. Specifically, we first extend a
given image generative model to their video generative model counterpart, and
then train the video generative model on pseudo videos constructed by applying
data augmentation to the original images. Furthermore, we analyze the potential
issues of first-order Markov data augmentation methods, which are typically
used in diffusion models, and propose to use more expressive data augmentation
to construct more useful information in pseudo videos. Our empirical results on
the CIFAR10 and CelebA datasets demonstrate that improved image generation
quality can be achieved with additional self-supervised information from pseudo
videos.",2024-10-26,"Wenlong Chen, Wenlin Chen, Lapo Rastrelli, Yingzhen Li",http://arxiv.org/pdf/2410.20158v2,cs.LG
The inexact power augmented Lagrangian method for constrained nonconvex optimization,"This work introduces an unconventional inexact augmented Lagrangian method,
where the augmenting term is a Euclidean norm raised to a power between one and
two. The proposed algorithm is applicable to a broad class of constrained
nonconvex minimization problems, that involve nonlinear equality constraints
over a convex set under a mild regularity condition. First, we conduct a full
complexity analysis of the method, leveraging an accelerated first-order
algorithm for solving the H\""older-smooth subproblems. Next, we present an
inexact proximal point method to tackle these subproblems, demonstrating that
it achieves an improved convergence rate. Notably, this rate reduces to the
best-known convergence rate for first-order methods when the augmenting term is
a squared Euclidean norm. Our worst-case complexity results further show that
using lower powers for the augmenting term leads to faster constraint
satisfaction, albeit with a slower decrease in the dual residual. Numerical
experiments support our theoretical findings, illustrating that this trade-off
between constraint satisfaction and cost minimization is advantageous for
certain practical problems.",2024-10-26,"Alexander Bodard, Konstantinos Oikonomidis, Emanuel Laude, Panagiotis Patrinos",http://arxiv.org/pdf/2410.20153v1,cs.LG
AdaNeg: Adaptive Negative Proxy Guided OOD Detection with Vision-Language Models,"Recent research has shown that pre-trained vision-language models are
effective at identifying out-of-distribution (OOD) samples by using negative
labels as guidance. However, employing consistent negative labels across
different OOD datasets often results in semantic misalignments, as these text
labels may not accurately reflect the actual space of OOD images. To overcome
this issue, we introduce \textit{adaptive negative proxies}, which are
dynamically generated during testing by exploring actual OOD images, to align
more closely with the underlying OOD label space and enhance the efficacy of
negative proxy guidance. Specifically, our approach utilizes a feature memory
bank to selectively cache discriminative features from test images,
representing the targeted OOD distribution. This facilitates the creation of
proxies that can better align with specific OOD datasets. While task-adaptive
proxies average features to reflect the unique characteristics of each dataset,
the sample-adaptive proxies weight features based on their similarity to
individual test samples, exploring detailed sample-level nuances. The final
score for identifying OOD samples integrates static negative labels with our
proposed adaptive proxies, effectively combining textual and visual knowledge
for enhanced performance. Our method is training-free and annotation-free, and
it maintains fast testing speed. Extensive experiments across various
benchmarks demonstrate the effectiveness of our approach, abbreviated as
AdaNeg. Notably, on the large-scale ImageNet benchmark, our AdaNeg
significantly outperforms existing methods, with a 2.45\% increase in AUROC and
a 6.48\% reduction in FPR95. Codes are available at
\url{https://github.com/YBZh/OpenOOD-VLM}.",2024-10-26,"Yabin Zhang, Lei Zhang",http://arxiv.org/pdf/2410.20149v1,cs.LG
GFlowNet Fine-tuning for Diverse Correct Solutions in Mathematical Reasoning Tasks,"Mathematical reasoning problems are among the most challenging, as they
typically require an understanding of fundamental laws to solve. The laws are
universal, but the derivation of the final answer changes depending on how a
problem is approached. When training large language models (LLMs), learning the
capability of generating such multiple solutions is essential to accelerate
their use in mathematical education. To this end, we train LLMs using
generative flow network (GFlowNet). Different from reward-maximizing
reinforcement learning (RL), GFlowNet fine-tuning seeks to find diverse
solutions by training the LLM whose distribution is proportional to a reward
function. In numerical experiments, we evaluate GFlowNet fine-tuning and
reward-maximizing RL in terms of accuracy and diversity. The results show that
GFlowNet fine-tuning derives correct final answers from diverse intermediate
reasoning steps, indicating the improvement of the capability of alternative
solution generation.",2024-10-26,"Ryoichi Takase, Masaya Tsunokake, Yuta Tsuchiya, Shota Inuzuka",http://arxiv.org/pdf/2410.20147v1,cs.LG
FedMABA: Towards Fair Federated Learning through Multi-Armed Bandits Allocation,"The increasing concern for data privacy has driven the rapid development of
federated learning (FL), a privacy-preserving collaborative paradigm. However,
the statistical heterogeneity among clients in FL results in inconsistent
performance of the server model across various clients. Server model may show
favoritism towards certain clients while performing poorly for others,
heightening the challenge of fairness. In this paper, we reconsider the
inconsistency in client performance distribution and introduce the concept of
adversarial multi-armed bandit to optimize the proposed objective with explicit
constraints on performance disparities. Practically, we propose a novel
multi-armed bandit-based allocation FL algorithm (FedMABA) to mitigate
performance unfairness among diverse clients with different data distributions.
Extensive experiments, in different Non-I.I.D. scenarios, demonstrate the
exceptional performance of FedMABA in enhancing fairness.",2024-10-26,"Zhichao Wang, Lin Wang, Yongxin Guo, Ying-Jun Angela Zhang, Xiaoying Tang",http://arxiv.org/pdf/2410.20141v1,cs.LG
CodePurify: Defend Backdoor Attacks on Neural Code Models via Entropy-based Purification,"Neural code models have found widespread success in tasks pertaining to code
intelligence, yet they are vulnerable to backdoor attacks, where an adversary
can manipulate the victim model's behavior by inserting triggers into the
source code. Recent studies indicate that advanced backdoor attacks can achieve
nearly 100% attack success rates on many software engineering tasks. However,
effective defense techniques against such attacks remain insufficiently
explored. In this study, we propose CodePurify, a novel defense against
backdoor attacks on code models through entropy-based purification.
Entropy-based purification involves the process of precisely detecting and
eliminating the possible triggers in the source code while preserving its
semantic information. Within this process, CodePurify first develops a
confidence-driven entropy-based measurement to determine whether a code snippet
is poisoned and, if so, locates the triggers. Subsequently, it purifies the
code by substituting the triggers with benign tokens using a masked language
model. We extensively evaluate CodePurify against four advanced backdoor
attacks across three representative tasks and two popular code models. The
results show that CodePurify significantly outperforms four commonly used
defense baselines, improving average defense performance by at least 40%, 40%,
and 12% across the three tasks, respectively. These findings highlight the
potential of CodePurify to serve as a robust defense against backdoor attacks
on neural code models.",2024-10-26,"Fangwen Mu, Junjie Wang, Zhuohao Yu, Lin Shi, Song Wang, Mingyang Li, Qing Wang",http://arxiv.org/pdf/2410.20136v1,cs.LG
Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD,"We consider the problem of high-dimensional heavy-tailed statistical
estimation in the streaming setting, which is much harder than the traditional
batch setting due to memory constraints. We cast this problem as stochastic
convex optimization with heavy tailed stochastic gradients, and prove that the
widely used Clipped-SGD algorithm attains near-optimal sub-Gaussian statistical
rates whenever the second moment of the stochastic gradient noise is finite.
More precisely, with $T$ samples, we show that Clipped-SGD, for smooth and
strongly convex objectives, achieves an error of
$\sqrt{\frac{\mathsf{Tr}(\Sigma)+\sqrt{\mathsf{Tr}(\Sigma)\|\Sigma\|_2}\log(\frac{\log(T)}{\delta})}{T}}$
with probability $1-\delta$, where $\Sigma$ is the covariance of the clipped
gradient. Note that the fluctuations (depending on $\frac{1}{\delta}$) are of
lower order than the term $\mathsf{Tr}(\Sigma)$. This improves upon the current
best rate of $\sqrt{\frac{\mathsf{Tr}(\Sigma)\log(\frac{1}{\delta})}{T}}$ for
Clipped-SGD, known only for smooth and strongly convex objectives. Our results
also extend to smooth convex and lipschitz convex objectives. Key to our result
is a novel iterative refinement strategy for martingale concentration,
improving upon the PAC-Bayes approach of Catoni and Giulini.",2024-10-26,"Aniket Das, Dheeraj Nagaraj, Soumyabrata Pal, Arun Suggala, Prateek Varshney",http://arxiv.org/pdf/2410.20135v1,cs.LG
NeoPhysIx: An Ultra Fast 3D Physical Simulator as Development Tool for AI Algorithms,"Traditional AI algorithms, such as Genetic Programming and Reinforcement
Learning, often require extensive computational resources to simulate
real-world physical scenarios effectively. While advancements in multi-core
processing have been made, the inherent limitations of parallelizing rigid body
dynamics lead to significant communication overheads, hindering substantial
performance gains for simple simulations.
  This paper introduces NeoPhysIx, a novel 3D physical simulator designed to
overcome these challenges. By adopting innovative simulation paradigms and
focusing on essential algorithmic elements, NeoPhysIx achieves unprecedented
speedups exceeding 1000x compared to real-time. This acceleration is realized
through strategic simplifications, including point cloud collision detection,
joint angle determination, and friction force estimation.
  The efficacy of NeoPhysIx is demonstrated through its application in training
a legged robot with 18 degrees of freedom and six sensors, controlled by an
evolved genetic program. Remarkably, simulating half a year of robot lifetime
within a mere 9 hours on a single core of a standard mid-range CPU highlights
the significant efficiency gains offered by NeoPhysIx. This breakthrough paves
the way for accelerated AI development and training in physically-grounded
domains.",2024-10-26,"Jörn Fischer, Thomas Ihme",http://arxiv.org/pdf/2411.05799v1,cs.LG
On-Site Precise Screening of SARS-CoV-2 Systems Using a Channel-Wise Attention-Based PLS-1D-CNN Model with Limited Infrared Signatures,"During the early stages of respiratory virus outbreaks, such as severe acute
respiratory syndrome coronavirus 2 (SARS-CoV-2), the efficient utilize of
limited nasopharyngeal swabs for rapid and accurate screening is crucial for
public health. In this study, we present a methodology that integrates
attenuated total reflection-Fourier transform infrared spectroscopy (ATR-FTIR)
with the adaptive iteratively reweighted penalized least squares (airPLS)
preprocessing algorithm and a channel-wise attention-based partial least
squares one-dimensional convolutional neural network (PLS-1D-CNN) model,
enabling accurate screening of infected individuals within 10 minutes. Two
cohorts of nasopharyngeal swab samples, comprising 126 and 112 samples from
suspected SARS-CoV-2 Omicron variant cases, were collected at Beijing You'an
Hospital for verification. Given that ATR-FTIR spectra are highly sensitive to
variations in experimental conditions, which can affect their quality, we
propose a biomolecular importance (BMI) evaluation method to assess signal
quality across different conditions, validated by comparing BMI with PLS-GBM
and PLS-RF results. For the ATR-FTIR signals in cohort 2, which exhibited a
higher BMI, airPLS was utilized for signal preprocessing, followed by the
application of the channel-wise attention-based PLS-1D-CNN model for screening.
The experimental results demonstrate that our model outperforms recently
reported methods in the field of respiratory virus spectrum detection,
achieving a recognition screening accuracy of 96.48%, a sensitivity of 96.24%,
a specificity of 97.14%, an F1-score of 96.12%, and an AUC of 0.99. It meets
the World Health Organization (WHO) recommended criteria for an acceptable
product: sensitivity of 95.00% or greater and specificity of 97.00% or greater
for testing prior SARS-CoV-2 infection in moderate to high volume scenarios.",2024-10-26,"Wenwen Zhang, Zhouzhuo Tang, Yingmei Feng, Xia Yu, Qi Jie Wang, Zhiping Lin",http://arxiv.org/pdf/2410.20132v1,cs.LG
On Multi-Stage Loss Dynamics in Neural Networks: Mechanisms of Plateau and Descent Stages,"The multi-stage phenomenon in the training loss curves of neural networks has
been widely observed, reflecting the non-linearity and complexity inherent in
the training process. In this work, we investigate the training dynamics of
neural networks (NNs), with particular emphasis on the small initialization
regime, identifying three distinct stages observed in the loss curve during
training: the initial plateau stage, the initial descent stage, and the
secondary plateau stage. Through rigorous analysis, we reveal the underlying
challenges contributing to slow training during the plateau stages. While the
proof and estimate for the emergence of the initial plateau were established in
our previous work, the behaviors of the initial descent and secondary plateau
stages had not been explored before. Here, we provide a more detailed proof for
the initial plateau, followed by a comprehensive analysis of the initial
descent stage dynamics. Furthermore, we examine the factors facilitating the
network's ability to overcome the prolonged secondary plateau, supported by
both experimental evidence and heuristic reasoning. Finally, to clarify the
link between global training trends and local parameter adjustments, we use the
Wasserstein distance to track the fine-scale evolution of weight amplitude
distribution.",2024-10-26,"Zheng-An Chen, Tao Luo, GuiHong Wang",http://arxiv.org/pdf/2410.20119v2,cs.LG
GeoFUSE: A High-Efficiency Surrogate Model for Seawater Intrusion Prediction and Uncertainty Reduction,"Seawater intrusion into coastal aquifers poses a significant threat to
groundwater resources, especially with rising sea levels due to climate change.
Accurate modeling and uncertainty quantification of this process are crucial
but are often hindered by the high computational costs of traditional numerical
simulations. In this work, we develop GeoFUSE, a novel deep-learning-based
surrogate framework that integrates the U-Net Fourier Neural Operator (U-FNO)
with Principal Component Analysis (PCA) and Ensemble Smoother with Multiple
Data Assimilation (ESMDA). GeoFUSE enables fast and efficient simulation of
seawater intrusion while significantly reducing uncertainty in model
predictions. We apply GeoFUSE to a 2D cross-section of the Beaver Creek tidal
stream-floodplain system in Washington State. Using 1,500 geological
realizations, we train the U-FNO surrogate model to approximate salinity
distribution and accumulation. The U-FNO model successfully reduces the
computational time from hours (using PFLOTRAN simulations) to seconds,
achieving a speedup of approximately 360,000 times while maintaining high
accuracy. By integrating measurement data from monitoring wells, the framework
significantly reduces geological uncertainty and improves the predictive
accuracy of the salinity distribution over a 20-year period. Our results
demonstrate that GeoFUSE improves computational efficiency and provides a
robust tool for real-time uncertainty quantification and decision making in
groundwater management. Future work will extend GeoFUSE to 3D models and
incorporate additional factors such as sea-level rise and extreme weather
events, making it applicable to a broader range of coastal and subsurface flow
systems.",2024-10-26,"Su Jiang, Chuyang Liu, Dipankar Dwivedi",http://arxiv.org/pdf/2410.20118v1,cs.LG
ISDNN: A Deep Neural Network for Channel Estimation in Massive MIMO systems,"Massive Multiple-Input Multiple-Output (massive MIMO) technology stands as a
cornerstone in 5G and beyonds. Despite the remarkable advancements offered by
massive MIMO technology, the extreme number of antennas introduces challenges
during the channel estimation (CE) phase. In this paper, we propose a
single-step Deep Neural Network (DNN) for CE, termed Iterative Sequential DNN
(ISDNN), inspired by recent developments in data detection algorithms. ISDNN is
a DNN based on the projected gradient descent algorithm for CE problems, with
the iterative iterations transforming into a DNN using the deep unfolding
method. Furthermore, we introduce the structured channel ISDNN (S-ISDNN),
extending ISDNN to incorporate side information such as directions of signals
and antenna array configurations for enhanced CE. Simulation results highlight
that ISDNN significantly outperforms another DNN-based CE (DetNet), in terms of
training time (13%), running time (4.6%), and accuracy (0.43 dB). Furthermore,
the S-ISDNN demonstrates even faster than ISDNN in terms of training time,
though its overall performance still requires further improvement.",2024-10-26,"Do Hai Son, Vu Tung Lam, Tran Thi Thuy Quynh",http://arxiv.org/pdf/2410.20110v1,cs.LG
Emergence of Globally Attracting Fixed Points in Deep Neural Networks With Nonlinear Activations,"Understanding how neural networks transform input data across layers is
fundamental to unraveling their learning and generalization capabilities.
Although prior work has used insights from kernel methods to study neural
networks, a global analysis of how the similarity between hidden
representations evolves across layers remains underexplored. In this paper, we
introduce a theoretical framework for the evolution of the kernel sequence,
which measures the similarity between the hidden representation for two
different inputs. Operating under the mean-field regime, we show that the
kernel sequence evolves deterministically via a kernel map, which only depends
on the activation function. By expanding activation using Hermite polynomials
and using their algebraic properties, we derive an explicit form for kernel map
and fully characterize its fixed points. Our analysis reveals that for
nonlinear activations, the kernel sequence converges globally to a unique fixed
point, which can correspond to orthogonal or similar representations depending
on the activation and network architecture. We further extend our results to
networks with residual connections and normalization layers, demonstrating
similar convergence behaviors. This work provides new insights into the
implicit biases of deep neural networks and how architectural choices influence
the evolution of representations across layers.",2024-10-26,"Amir Joudaki, Thomas Hofmann",http://arxiv.org/pdf/2410.20107v2,cs.LG
FedSSP: Federated Graph Learning with Spectral Knowledge and Personalized Preference,"Personalized Federated Graph Learning (pFGL) facilitates the decentralized
training of Graph Neural Networks (GNNs) without compromising privacy while
accommodating personalized requirements for non-IID participants. In
cross-domain scenarios, structural heterogeneity poses significant challenges
for pFGL. Nevertheless, previous pFGL methods incorrectly share non-generic
knowledge globally and fail to tailor personalized solutions locally under
domain structural shift. We innovatively reveal that the spectral nature of
graphs can well reflect inherent domain structural shifts. Correspondingly, our
method overcomes it by sharing generic spectral knowledge. Moreover, we
indicate the biased message-passing schemes for graph structures and propose
the personalized preference module. Combining both strategies, we propose our
pFGL framework FedSSP which Shares generic Spectral knowledge while satisfying
graph Preferences. Furthermore, We perform extensive experiments on
cross-dataset and cross-domain settings to demonstrate the superiority of our
framework. The code is available at https://github.com/OakleyTan/FedSSP.",2024-10-26,"Zihan Tan, Guancheng Wan, Wenke Huang, Mang Ye",http://arxiv.org/pdf/2410.20105v1,cs.LG
Latent Neural Operator Pretraining for Solving Time-Dependent PDEs,"Pretraining methods gain increasing attraction recently for solving PDEs with
neural operators. It alleviates the data scarcity problem encountered by neural
operator learning when solving single PDE via training on large-scale datasets
consisting of various PDEs and utilizing shared patterns among different PDEs
to improve the solution precision. In this work, we propose the Latent Neural
Operator Pretraining (LNOP) framework based on the Latent Neural Operator (LNO)
backbone. We achieve universal transformation through pretraining on hybrid
time-dependent PDE dataset to extract representations of different physical
systems and solve various time-dependent PDEs in the latent space through
finetuning on single PDE dataset. Our proposed LNOP framework reduces the
solution error by 31.7% on four problems and can be further improved to 57.1%
after finetuning. On out-of-distribution dataset, our LNOP model achieves
roughly 50% lower error and 3$\times$ data efficiency on average across
different dataset sizes. These results show that our method is more competitive
in terms of solution precision, transfer capability and data efficiency
compared to non-pretrained neural operators.",2024-10-26,"Tian Wang, Chuang Wang",http://arxiv.org/pdf/2410.20100v2,cs.LG
Self-Normalized Resets for Plasticity in Continual Learning,"Plasticity Loss is an increasingly important phenomenon that refers to the
empirical observation that as a neural network is continually trained on a
sequence of changing tasks, its ability to adapt to a new task diminishes over
time. We introduce Self-Normalized Resets (SNR), a simple adaptive algorithm
that mitigates plasticity loss by resetting a neuron's weights when evidence
suggests its firing rate has effectively dropped to zero. Across a battery of
continual learning problems and network architectures, we demonstrate that SNR
consistently attains superior performance compared to its competitor
algorithms. We also demonstrate that SNR is robust to its sole hyperparameter,
its rejection percentile threshold, while competitor algorithms show
significant sensitivity. SNR's threshold-based reset mechanism is motivated by
a simple hypothesis test that we derive. Seen through the lens of this
hypothesis test, competing reset proposals yield suboptimal error rates in
correctly detecting inactive neurons, potentially explaining our experimental
observations. We also conduct a theoretical investigation of the optimization
landscape for the problem of learning a single ReLU. We show that even when
initialized adversarially, an idealized version of SNR learns the target ReLU,
while regularization-based approaches can fail to learn.",2024-10-26,"Vivek F. Farias, Adam D. Jozefiak",http://arxiv.org/pdf/2410.20098v2,cs.LG
OGBench: Benchmarking Offline Goal-Conditioned RL,"Offline goal-conditioned reinforcement learning (GCRL) is a major problem in
reinforcement learning (RL) because it provides a simple, unsupervised, and
domain-agnostic way to acquire diverse behaviors and representations from
unlabeled data without rewards. Despite the importance of this setting, we lack
a standard benchmark that can systematically evaluate the capabilities of
offline GCRL algorithms. In this work, we propose OGBench, a new, high-quality
benchmark for algorithms research in offline goal-conditioned RL. OGBench
consists of 8 types of environments, 85 datasets, and reference implementations
of 6 representative offline GCRL algorithms. We have designed these challenging
and realistic environments and datasets to directly probe different
capabilities of algorithms, such as stitching, long-horizon reasoning, and the
ability to handle high-dimensional inputs and stochasticity. While
representative algorithms may rank similarly on prior benchmarks, our
experiments reveal stark strengths and weaknesses in these different
capabilities, providing a strong foundation for building new algorithms.
Project page: https://seohong.me/projects/ogbench",2024-10-26,"Seohong Park, Kevin Frans, Benjamin Eysenbach, Sergey Levine",http://arxiv.org/pdf/2410.20092v2,cs.LG
Sample Efficient Bayesian Learning of Causal Graphs from Interventions,"Causal discovery is a fundamental problem with applications spanning various
areas in science and engineering. It is well understood that solely using
observational data, one can only orient the causal graph up to its Markov
equivalence class, necessitating interventional data to learn the complete
causal graph. Most works in the literature design causal discovery policies
with perfect interventions, i.e., they have access to infinite interventional
samples. This study considers a Bayesian approach for learning causal graphs
with limited interventional samples, mirroring real-world scenarios where such
samples are usually costly to obtain. By leveraging the recent result of
Wien\""obst et al. (2023) on uniform DAG sampling in polynomial time, we can
efficiently enumerate all the cut configurations and their corresponding
interventional distributions of a target set, and further track their
posteriors. Given any number of interventional samples, our proposed algorithm
randomly intervenes on a set of target vertices that cut all the edges in the
graph and returns a causal graph according to the posterior of each target set.
When the number of interventional samples is large enough, we show
theoretically that our proposed algorithm will return the true causal graph
with high probability. We compare our algorithm against various baseline
methods on simulated datasets, demonstrating its superior accuracy measured by
the structural Hamming distance between the learned DAG and the ground truth.
Additionally, we present a case study showing how this algorithm could be
modified to answer more general causal questions without learning the whole
graph. As an example, we illustrate that our method can be used to estimate the
causal effect of a variable that cannot be intervened.",2024-10-26,"Zihan Zhou, Muhammad Qasim Elahi, Murat Kocaoglu",http://arxiv.org/pdf/2410.20089v1,cs.LG
emg2qwerty: A Large Dataset with Baselines for Touch Typing using Surface Electromyography,"Surface electromyography (sEMG) non-invasively measures signals generated by
muscle activity with sufficient sensitivity to detect individual spinal neurons
and richness to identify dozens of gestures and their nuances. Wearable
wrist-based sEMG sensors have the potential to offer low friction, subtle,
information rich, always available human-computer inputs. To this end, we
introduce emg2qwerty, a large-scale dataset of non-invasive electromyographic
signals recorded at the wrists while touch typing on a QWERTY keyboard,
together with ground-truth annotations and reproducible baselines. With 1,135
sessions spanning 108 users and 346 hours of recording, this is the largest
such public dataset to date. These data demonstrate non-trivial, but well
defined hierarchical relationships both in terms of the generative process,
from neurons to muscles and muscle combinations, as well as in terms of domain
shift across users and user sessions. Applying standard modeling techniques
from the closely related field of Automatic Speech Recognition (ASR), we show
strong baseline performance on predicting key-presses using sEMG signals alone.
We believe the richness of this task and dataset will facilitate progress in
several problems of interest to both the machine learning and neuroscientific
communities. Dataset and code can be accessed at
https://github.com/facebookresearch/emg2qwerty.",2024-10-26,"Viswanath Sivakumar, Jeffrey Seely, Alan Du, Sean R Bittner, Adam Berenzweig, Anuoluwapo Bolarinwa, Alexandre Gramfort, Michael I Mandel",http://arxiv.org/pdf/2410.20081v3,cs.LG
Super-resolved virtual staining of label-free tissue using diffusion models,"Virtual staining of tissue offers a powerful tool for transforming label-free
microscopy images of unstained tissue into equivalents of histochemically
stained samples. This study presents a diffusion model-based super-resolution
virtual staining approach utilizing a Brownian bridge process to enhance both
the spatial resolution and fidelity of label-free virtual tissue staining,
addressing the limitations of traditional deep learning-based methods. Our
approach integrates novel sampling techniques into a diffusion model-based
image inference process to significantly reduce the variance in the generated
virtually stained images, resulting in more stable and accurate outputs.
Blindly applied to lower-resolution auto-fluorescence images of label-free
human lung tissue samples, the diffusion-based super-resolution virtual
staining model consistently outperformed conventional approaches in resolution,
structural similarity and perceptual accuracy, successfully achieving a
super-resolution factor of 4-5x, increasing the output space-bandwidth product
by 16-25-fold compared to the input label-free microscopy images.
Diffusion-based super-resolved virtual tissue staining not only improves
resolution and image quality but also enhances the reliability of virtual
staining without traditional chemical staining, offering significant potential
for clinical diagnostics.",2024-10-26,"Yijie Zhang, Luzhe Huang, Nir Pillar, Yuzhu Li, Hanlong Chen, Aydogan Ozcan",http://arxiv.org/pdf/2410.20073v1,cs.LG
CGKN: A Deep Learning Framework for Modeling Complex Dynamical Systems and Efficient Data Assimilation,"Deep learning is widely used to predict complex dynamical systems in many
scientific and engineering areas. However, the black-box nature of these deep
learning models presents significant challenges for carrying out simultaneous
data assimilation (DA), which is a crucial technique for state estimation,
model identification, and reconstructing missing data. Integrating
ensemble-based DA methods with nonlinear deep learning models is
computationally expensive and may suffer from large sampling errors. To address
these challenges, we introduce a deep learning framework designed to
simultaneously provide accurate forecasts and efficient DA. It is named
Conditional Gaussian Koopman Network (CGKN), which transforms general nonlinear
systems into nonlinear neural differential equations with conditional Gaussian
structures. CGKN aims to retain essential nonlinear components while applying
systematic and minimal simplifications to facilitate the development of
analytic formulae for nonlinear DA. This allows for seamless integration of DA
performance into the deep learning training process, eliminating the need for
empirical tuning as required in ensemble methods. CGKN compensates for
structural simplifications by lifting the dimension of the system, which is
motivated by Koopman theory. Nevertheless, CGKN exploits special nonlinear
dynamics within the lifted space. This enables the model to capture extreme
events and strong non-Gaussian features in joint and marginal distributions
with appropriate uncertainty quantification. We demonstrate the effectiveness
of CGKN for both prediction and DA on three strongly nonlinear and non-Gaussian
turbulent systems: the projected stochastic Burgers-Sivashinsky equation, the
Lorenz 96 system, and the El Ni\~no-Southern Oscillation. The results justify
the robustness and computational efficiency of CGKN.",2024-10-26,"Chuanqi Chen, Nan Chen, Yinling Zhang, Jin-Long Wu",http://arxiv.org/pdf/2410.20072v2,cs.LG
Understanding the Effect of GCN Convolutions in Regression Tasks,"Graph Convolutional Networks (GCNs) have become a pivotal method in machine
learning for modeling functions over graphs. Despite their widespread success
across various applications, their statistical properties (e.g., consistency,
convergence rates) remain ill-characterized. To begin addressing this knowledge
gap, we consider networks for which the graph structure implies that
neighboring nodes exhibit similar signals and provide statistical theory for
the impact of convolution operators. Focusing on estimators based solely on
neighborhood aggregation, we examine how two common convolutions - the original
GCN and GraphSAGE convolutions - affect the learning error as a function of the
neighborhood topology and the number of convolutional layers. We explicitly
characterize the bias-variance type trade-off incurred by GCNs as a function of
the neighborhood size and identify specific graph topologies where convolution
operators are less effective. Our theoretical findings are corroborated by
synthetic experiments, and provide a start to a deeper quantitative
understanding of convolutional effects in GCNs for offering rigorous guidelines
for practitioners.",2024-10-26,"Juntong Chen, Johannes Schmidt-Hieber, Claire Donnat, Olga Klopp",http://arxiv.org/pdf/2410.20068v2,cs.LG
Towards Continuous Skin Sympathetic Nerve Activity Monitoring: Removing Muscle Noise,"Continuous monitoring of non-invasive skin sympathetic nerve activity (SKNA)
holds promise for understanding the sympathetic nervous system (SNS) dynamics
in various physiological and pathological conditions. However, muscle noise
artifacts present a challenge in accurate SKNA analysis, particularly in
real-life scenarios. This study proposes a deep convolutional neural network
(CNN) approach to detect and remove muscle noise from SKNA recordings obtained
via ECG electrodes. Twelve healthy participants underwent controlled
experimental protocols involving cognitive stress induction and voluntary
muscle movements, while collecting SKNA data. Power spectral analysis revealed
significant muscle noise interference within the SKNA frequency band (500-1000
Hz). A 2D CNN model was trained on the spectrograms of the data segments to
classify them into baseline, stress-induced SKNA, and muscle noise-contaminated
periods, achieving an average accuracy of 89.85% across all subjects. Our
findings underscore the importance of addressing muscle noise for accurate SKNA
monitoring, advancing towards wearable SKNA sensors for real-world
applications.",2024-10-26,"Farnoush Baghestani, Mahdi Pirayesh Shirazi Nejad, Youngsun Kong, Ki H. Chon",http://arxiv.org/pdf/2410.21319v1,cs.LG
Deep Concept Identification for Generative Design,"A generative design based on topology optimization provides diverse
alternatives as entities in a computational model with a high design degree.
However, as the diversity of the generated alternatives increases, the
cognitive burden on designers to select the most appropriate alternatives also
increases. Whereas the concept identification approach, which finds various
categories of entities, is an effective means to structure alternatives,
evaluation of their similarities is challenging due to shape diversity. To
address this challenge, this study proposes a concept identification framework
for generative design using deep learning (DL) techniques. One of the key
abilities of DL is the automatic learning of different representations of a
specific task. Deep concept identification finds various categories that
provide insights into the mapping relationships between geometric properties
and structural performance through representation learning using DL. The
proposed framework generates diverse alternatives using a generative design
technique, clusters the alternatives into several categories using a DL
technique, and arranges these categories for design practice using a
classification model. This study demonstrates its fundamental capabilities by
implementing variational deep embedding, a generative and clustering model
based on the DL paradigm, and logistic regression as a classification model. A
simplified design problem of a two-dimensional bridge structure is applied as a
case study to validate the proposed framework. Although designers are required
to determine the viewing aspect level by setting the number of concepts, this
implementation presents the identified concepts and their relationships in the
form of a decision tree based on a specified level.",2024-10-26,"Ryo Tsumoto, Kentaro Yaji, Yutaka Nomaguchi, Kikuo Fujita",http://arxiv.org/pdf/2410.20061v1,cs.LG
Mechanism learning: Reverse causal inference in the presence of multiple unknown confounding through front-door causal bootstrapping,"A major limitation of machine learning (ML) prediction models is that they
recover associational, rather than causal, predictive relationships between
variables. In high-stakes automation applications of ML this is problematic, as
the model often learns spurious, non-causal associations. This paper proposes
mechanism learning, a simple method which uses front-door causal bootstrapping
to deconfound observational data such that any appropriate ML model is forced
to learn predictive relationships between effects and their causes (reverse
causal inference), despite the potential presence of multiple unknown and
unmeasured confounding. Effect variables can be very high dimensional, and the
predictive relationship nonlinear, as is common in ML applications. This novel
method is widely applicable, the only requirement is the existence of a
mechanism variable mediating the cause (prediction target) and effect (feature
data), which is independent of the (unmeasured) confounding variables. We test
our method on fully synthetic, semi-synthetic and real-world datasets,
demonstrating that it can discover reliable, unbiased, causal ML predictors
where by contrast, the same ML predictor trained naively using classical
supervised learning on the original observational data, is heavily biased by
spurious associations. We provide code to implement the results in the paper,
online.",2024-10-26,"Jianqiao Mao, Max A. Little",http://arxiv.org/pdf/2410.20057v1,cs.LG
Personality Analysis from Online Short Video Platforms with Multi-domain Adaptation,"Personality analysis from online short videos has gained prominence due to
its applications in personalized recommendation systems, sentiment analysis,
and human-computer interaction. Traditional assessment methods, such as
questionnaires based on the Big Five Personality Framework, are limited by
self-report biases and are impractical for large-scale or real-time analysis.
Leveraging the rich, multi-modal data present in short videos offers a
promising alternative for more accurate personality inference. However,
integrating these diverse and asynchronous modalities poses significant
challenges, particularly in aligning time-varying data and ensuring models
generalize well to new domains with limited labeled data. In this paper, we
propose a novel multi-modal personality analysis framework that addresses these
challenges by synchronizing and integrating features from multiple modalities
and enhancing model generalization through domain adaptation. We introduce a
timestamp-based modality alignment mechanism that synchronizes data based on
spoken word timestamps, ensuring accurate correspondence across modalities and
facilitating effective feature integration. To capture temporal dependencies
and inter-modal interactions, we employ Bidirectional Long Short-Term Memory
networks and self-attention mechanisms, allowing the model to focus on the most
informative features for personality prediction. Furthermore, we develop a
gradient-based domain adaptation method that transfers knowledge from multiple
source domains to improve performance in target domains with scarce labeled
data. Extensive experiments on real-world datasets demonstrate that our
framework significantly outperforms existing methods in personality prediction
tasks, highlighting its effectiveness in capturing complex behavioral cues and
robustness in adapting to new domains.",2024-10-26,"Sixu An, Xiangguo Sun, Yicong Li, Yu Yang, Guandong Xu",http://arxiv.org/pdf/2411.00813v1,cs.LG
Evaluating Neural Networks for Early Maritime Threat Detection,"We consider the task of classifying trajectories of boat activities as a
proxy for assessing maritime threats. Previous approaches have considered
entropy-based metrics for clustering boat activity into three broad categories:
random walk, following, and chasing. Here, we comprehensively assess the
accuracy of neural network-based approaches as alternatives to entropy-based
clustering. We train four neural network models and compare them to shallow
learning using synthetic data. We also investigate the accuracy of models as
time steps increase and with and without rotated data. To improve test-time
robustness, we normalize trajectories and perform rotation-based data
augmentation. Our results show that deep networks can achieve a test-set
accuracy of up to 100% on a full trajectory, with graceful degradation as the
number of time steps decreases, outperforming entropy-based clustering.",2024-10-26,"Dhanush Tella, Chandra Teja Tiriveedhi, Naphtali Rishe, Dan E. Tamir, Jonathan I. Tamir",http://arxiv.org/pdf/2410.20054v1,cs.LG
ResAD: A Simple Framework for Class Generalizable Anomaly Detection,"This paper explores the problem of class-generalizable anomaly detection,
where the objective is to train one unified AD model that can generalize to
detect anomalies in diverse classes from different domains without any
retraining or fine-tuning on the target data. Because normal feature
representations vary significantly across classes, this will cause the widely
studied one-for-one AD models to be poorly classgeneralizable (i.e.,
performance drops dramatically when used for new classes). In this work, we
propose a simple but effective framework (called ResAD) that can be directly
applied to detect anomalies in new classes. Our main insight is to learn the
residual feature distribution rather than the initial feature distribution. In
this way, we can significantly reduce feature variations. Even in new classes,
the distribution of normal residual features would not remarkably shift from
the learned distribution. Therefore, the learned model can be directly adapted
to new classes. ResAD consists of three components: (1) a Feature Converter
that converts initial features into residual features; (2) a simple and shallow
Feature Constraintor that constrains normal residual features into a spatial
hypersphere for further reducing feature variations and maintaining consistency
in feature scales among different classes; (3) a Feature Distribution Estimator
that estimates the normal residual feature distribution, anomalies can be
recognized as out-of-distribution. Despite the simplicity, ResAD can achieve
remarkable anomaly detection results when directly used in new classes. The
code is available at https://github.com/xcyao00/ResAD.",2024-10-26,"Xincheng Yao, Zixin Chen, Chao Gao, Guangtao Zhai, Chongyang Zhang",http://arxiv.org/pdf/2410.20047v1,cs.LG
Annotation Efficiency: Identifying Hard Samples via Blocked Sparse Linear Bandits,"This paper considers the problem of annotating datapoints using an expert
with only a few annotation rounds in a label-scarce setting. We propose
soliciting reliable feedback on difficulty in annotating a datapoint from the
expert in addition to ground truth label. Existing literature in active
learning or coreset selection turns out to be less relevant to our setting
since they presume the existence of a reliable trained model, which is absent
in the label-scarce regime. However, the literature on coreset selection
emphasizes the presence of difficult data points in the training set to perform
supervised learning in downstream tasks (Mindermann et al., 2022). Therefore,
for a given fixed annotation budget of $\mathsf{T}$ rounds, we model the
sequential decision-making problem of which (difficult) datapoints to choose
for annotation in a sparse linear bandits framework with the constraint that no
arm can be pulled more than once (blocking constraint). With mild assumptions
on the datapoints, our (computationally efficient) Explore-Then-Commit
algorithm BSLB achieves a regret guarantee of
$\widetilde{\mathsf{O}}(k^{\frac{1}{3}} \mathsf{T}^{\frac{2}{3}}
+k^{-\frac{1}{2}} \beta_k + k^{-\frac{1}{12}}
\beta_k^{\frac{1}{2}}\mathsf{T}^{\frac{5}{6}})$ where the unknown parameter
vector has tail magnitude $\beta_k$ at sparsity level $k$. To this end, we show
offline statistical guarantees of Lasso estimator with mild Restricted
Eigenvalue (RE) condition that is also robust to sparsity. Finally, we propose
a meta-algorithm C-BSLB that does not need knowledge of the optimal sparsity
parameters at a no-regret cost. We demonstrate the efficacy of our BSLB
algorithm for annotation in the label-scarce setting for an image
classification task on the PASCAL-VOC dataset, where we use real-world
annotation difficulty scores.",2024-10-26,"Adit Jain, Soumyabrata Pal, Sunav Choudhary, Ramasuri Narayanam, Vikram Krishnamurthy",http://arxiv.org/pdf/2410.20041v1,cs.LG
Revisiting PlayeRank,"In this article we revise the football's performance score called PlayeRank,
designed and evaluated by Pappalardo et al.\ in 2019. First, we analyze the
weights extracted from the Linear Support Vector Machine (SVM) that solves the
classification problem of ""which set of events has a higher impact on the
chances of winning a match"". Here, we notice that the previously published
results include the Goal-Scored event during the training phase, which produces
inconsistencies. We fix these inconsistencies, and show new weights capable of
solving the same problem.
  Following the intuition that the best team should always win a match, we
define the team's quality as the average number of players involved in the
game. We show that, using the original PlayeRank, in 94.13\% of the matches
either the superior team beats the inferior team or the teams end tied if the
scores are similar.
  Finally, we present a way to use PlayeRank in an online fashion using
modified free analysis tools. Calculating this modified version of PlayeRank,
we performed an online analysis of a real football match every five minutes of
game. Here, we evaluate the usefulness of that information with experts and
managers, and conclude that the obtained data indeed provides useful
information that was not previously available to the manager during the match.",2024-10-26,"Louise Schmidt, Cristian Lillo, Javier Bustos",http://arxiv.org/pdf/2410.20038v1,cs.LG
Architectural Flaw Detection in Civil Engineering Using GPT-4,"The application of artificial intelligence (AI) in civil engineering presents
a transformative approach to enhancing design quality and safety. This paper
investigates the potential of the advanced LLM GPT4 Turbo vision model in
detecting architectural flaws during the design phase, with a specific focus on
identifying missing doors and windows. The study evaluates the model's
performance through metrics such as precision, recall, and F1 score,
demonstrating AI's effectiveness in accurately detecting flaws compared to
human-verified data. Additionally, the research explores AI's broader
capabilities, including identifying load-bearing issues, material weaknesses,
and ensuring compliance with building codes. The findings highlight how AI can
significantly improve design accuracy, reduce costly revisions, and support
sustainable practices, ultimately revolutionizing the civil engineering field
by ensuring safer, more efficient, and aesthetically optimized structures.",2024-10-26,"Saket Kumar, Abul Ehtesham, Aditi Singh, Tala Talaei Khoei",http://arxiv.org/pdf/2410.20036v1,cs.LG
Training the Untrainable: Introducing Inductive Bias via Representational Alignment,"We demonstrate that architectures which traditionally are considered to be
ill-suited for a task can be trained using inductive biases from another
architecture. Networks are considered untrainable when they overfit, underfit,
or converge to poor results even when tuning their hyperparameters. For
example, plain fully connected networks overfit on object recognition while
deep convolutional networks without residual connections underfit. The
traditional answer is to change the architecture to impose some inductive bias,
although what that bias is remains unknown. We introduce guidance, where a
guide network guides a target network using a neural distance function. The
target is optimized to perform well and to match its internal representations,
layer-by-layer, to those of the guide; the guide is unchanged. If the guide is
trained, this transfers over part of the architectural prior and knowledge of
the guide to the target. If the guide is untrained, this transfers over only
part of the architectural prior of the guide. In this manner, we can
investigate what kinds of priors different architectures place on untrainable
networks such as fully connected networks. We demonstrate that this method
overcomes the immediate overfitting of fully connected networks on vision
tasks, makes plain CNNs competitive to ResNets, closes much of the gap between
plain vanilla RNNs and Transformers, and can even help Transformers learn tasks
which RNNs can perform more easily. We also discover evidence that better
initializations of fully connected networks likely exist to avoid overfitting.
Our method provides a mathematical tool to investigate priors and
architectures, and in the long term, may demystify the dark art of architecture
creation, even perhaps turning architectures into a continuous optimizable
parameter of the network.",2024-10-26,"Vighnesh Subramaniam, David Mayo, Colin Conwell, Tomaso Poggio, Boris Katz, Brian Cheung, Andrei Barbu",http://arxiv.org/pdf/2410.20035v1,cs.LG
Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors,"Visual Question-Answering, a technology that generates textual responses from
an image and natural language question, has progressed significantly. Notably,
it can aid in tracking and inquiring about daily activities, crucial in
healthcare monitoring, especially for elderly patients or those with memory
disabilities. However, video poses privacy concerns and has a limited field of
view. This paper presents Sensor2Text, a model proficient in tracking daily
activities and engaging in conversations using wearable sensors. The approach
outlined here tackles several challenges, including low information density in
wearable sensor data, insufficiency of single wearable sensors in human
activities recognition, and model's limited capacity for Question-Answering and
interactive conversations. To resolve these obstacles, transfer learning and
student-teacher networks are utilized to leverage knowledge from
visual-language models. Additionally, an encoder-decoder neural network model
is devised to jointly process language and sensor data for conversational
purposes. Furthermore, Large Language Models are also utilized to enable
interactive capabilities. The model showcases the ability to identify human
activities and engage in Q\&A dialogues using various wearable sensor
modalities. It performs comparably to or better than existing visual-language
models in both captioning and conversational tasks. To our knowledge, this
represents the first model capable of conversing about wearable sensor data,
offering an innovative approach to daily activity tracking that addresses
privacy and field-of-view limitations associated with current vision-based
solutions.",2024-10-26,"Wenqiang Chen, Jiaxuan Cheng, Leyao Wang, Wei Zhao, Wojciech Matusik",http://arxiv.org/pdf/2410.20034v1,cs.LG
Dynamic layer selection in decoder-only transformers,"The vast size of Large Language Models (LLMs) has prompted a search to
optimize inference. One effective approach is dynamic inference, which adapts
the architecture to the sample-at-hand to reduce the overall computational
cost. We empirically examine two common dynamic inference methods for natural
language generation (NLG): layer skipping and early exiting. We find that a
pre-trained decoder-only model is significantly more robust to layer removal
via layer skipping, as opposed to early exit. We demonstrate the difficulty of
using hidden state information to adapt computation on a per-token basis for
layer skipping. Finally, we show that dynamic computation allocation on a
per-sequence basis holds promise for significant efficiency gains by
constructing an oracle controller. Remarkably, we find that there exists an
allocation which achieves equal performance to the full model using only 23.3%
of its layers on average.",2024-10-26,"Theodore Glavas, Joud Chataoui, Florence Regol, Wassim Jabbour, Antonios Valkanas, Boris N. Oreshkin, Mark Coates",http://arxiv.org/pdf/2410.20022v1,cs.LG
Deep Optimizer States: Towards Scalable Training of Transformer Models Using Interleaved Offloading,"Transformers and large language models~(LLMs) have seen rapid adoption in all
domains. Their sizes have exploded to hundreds of billions of parameters and
keep increasing. Under these circumstances, the training of transformers is
very expensive and often hits a ``memory wall'', i.e., even when using 3D
parallelism (pipeline, tensor, data) and aggregating the memory of many GPUs,
it is still not enough to hold the necessary data structures (model parameters,
optimizer state, gradients, activations) in GPU memory. To compensate,
state-of-the-art approaches offload the optimizer state, at least partially, to
the host memory and perform hybrid CPU-GPU computations. However, the
management of the combined host-GPU memory is often suboptimal and results in
poor overlapping between data movements and computations. This leads to missed
opportunities to simultaneously leverage the interconnect bandwidth and
computational capabilities of CPUs and GPUs. In this paper, we leverage a key
observation that the interleaving of the forward, backward and update phases
generate fluctuations in the GPU memory utilization, which can be exploited to
dynamically move a part of the optimizer state between the host and the GPU
memory at each iteration. To this end, we design and implement \proj, a novel
technique to split the LLM into subgroups, whose update phase is scheduled on
either the CPU or the GPU based on our proposed performance model that
addresses the trade-off between data movement cost, acceleration on the GPUs vs
the CPUs, and competition for shared resources. We integrate our approach with
DeepSpeed and demonstrate 2.5$\times$ faster iterations over state-of-the-art
approaches using extensive experiments.",2024-10-26,"Avinash Maurya, Jie Ye, M. Mustafa Rafique, Franck Cappello, Bogdan Nicolae",http://arxiv.org/pdf/2410.21316v1,cs.LG
GHIL-Glue: Hierarchical Control with Filtered Subgoal Images,"Image and video generative models that are pre-trained on Internet-scale data
can greatly increase the generalization capacity of robot learning systems.
These models can function as high-level planners, generating intermediate
subgoals for low-level goal-conditioned policies to reach. However, the
performance of these systems can be greatly bottlenecked by the interface
between generative models and low-level controllers. For example, generative
models may predict photorealistic yet physically infeasible frames that confuse
low-level policies. Low-level policies may also be sensitive to subtle visual
artifacts in generated goal images. This paper addresses these two facets of
generalization, providing an interface to effectively ""glue together""
language-conditioned image or video prediction models with low-level
goal-conditioned policies. Our method, Generative Hierarchical Imitation
Learning-Glue (GHIL-Glue), filters out subgoals that do not lead to task
progress and improves the robustness of goal-conditioned policies to generated
subgoals with harmful visual artifacts. We find in extensive experiments in
both simulated and real environments that GHIL-Glue achieves a 25% improvement
across several hierarchical models that leverage generative subgoals, achieving
a new state-of-the-art on the CALVIN simulation benchmark for policies using
observations from a single RGB camera. GHIL-Glue also outperforms other
generalist robot policies across 3/4 language-conditioned manipulation tasks
testing zero-shot generalization in physical experiments.",2024-10-26,"Kyle B. Hatch, Ashwin Balakrishna, Oier Mees, Suraj Nair, Seohong Park, Blake Wulfe, Masha Itkina, Benjamin Eysenbach, Sergey Levine, Thomas Kollar, Benjamin Burchfiel",http://arxiv.org/pdf/2410.20018v1,cs.LG
Off-Policy Selection for Initiating Human-Centric Experimental Design,"In human-centric tasks such as healthcare and education, the heterogeneity
among patients and students necessitates personalized treatments and
instructional interventions. While reinforcement learning (RL) has been
utilized in those tasks, off-policy selection (OPS) is pivotal to close the
loop by offline evaluating and selecting policies without online interactions,
yet current OPS methods often overlook the heterogeneity among participants.
Our work is centered on resolving a pivotal challenge in human-centric systems
(HCSs): how to select a policy to deploy when a new participant joining the
cohort, without having access to any prior offline data collected over the
participant? We introduce First-Glance Off-Policy Selection (FPS), a novel
approach that systematically addresses participant heterogeneity through
sub-group segmentation and tailored OPS criteria to each sub-group. By grouping
individuals with similar traits, FPS facilitates personalized policy selection
aligned with unique characteristics of each participant or group of
participants. FPS is evaluated via two important but challenging applications,
intelligent tutoring systems and a healthcare application for sepsis treatment
and intervention. FPS presents significant advancement in enhancing learning
outcomes of students and in-hospital care outcomes.",2024-10-26,"Ge Gao, Xi Yang, Qitong Gao, Song Ju, Miroslav Pajic, Min Chi",http://arxiv.org/pdf/2410.20017v1,cs.LG
Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models,"Fine-tuning pre-trained large language models (LLMs) on a diverse array of
tasks has become a common approach for building models that can solve various
natural language processing (NLP) tasks. However, where and to what extent
these models retain task-specific knowledge remains largely unexplored. This
study investigates the task-specific information encoded in pre-trained LLMs
and the effects of instruction tuning on their representations across a diverse
set of over 60 NLP tasks. We use a set of matrix analysis tools to examine the
differences between the way pre-trained and instruction-tuned LLMs store
task-specific information. Our findings reveal that while some tasks are
already encoded within the pre-trained LLMs, others greatly benefit from
instruction tuning. Additionally, we pinpointed the layers in which the model
transitions from high-level general representations to more task-oriented
representations. This finding extends our understanding of the governing
mechanisms of LLMs and facilitates future research in the fields of
parameter-efficient transfer learning and multi-task learning.",2024-10-25,"Zheng Zhao, Yftah Ziser, Shay B. Cohen",http://arxiv.org/pdf/2410.20008v1,cs.LG
Unsupervised Machine Learning for Detecting and Locating Human-Made Objects in 3D Point Cloud,"A 3D point cloud is an unstructured, sparse, and irregular dataset, typically
collected by airborne LiDAR systems over a geological region. Laser pulses
emitted from these systems reflect off objects both on and above the ground,
resulting in a dataset containing the longitude, latitude, and elevation of
each point, as well as information about the corresponding laser pulse
strengths. A widely studied research problem, addressed in many previous works,
is ground filtering, which involves partitioning the points into ground and
non-ground subsets. This research introduces a novel task: detecting and
identifying human-made objects amidst natural tree structures. This task is
performed on the subset of non-ground points derived from the ground filtering
stage. Marked Point Fields (MPFs) are used as models well-suited to these
tasks. The proposed methodology consists of three stages: ground filtering,
local information extraction (LIE), and clustering. In the ground filtering
stage, a statistical method called One-Sided Regression (OSR) is introduced,
addressing the limitations of prior ground filtering methods on uneven
terrains. In the LIE stage, unsupervised learning methods are lacking. To
mitigate this, a kernel-based method for the Hessian matrix of the MPF is
developed. In the clustering stage, the Gaussian Mixture Model (GMM) is applied
to the results of the LIE stage to partition the non-ground points into trees
and human-made objects. The underlying assumption is that LiDAR points from
trees exhibit a three-dimensional distribution, while those from human-made
objects follow a two-dimensional distribution. The Hessian matrix of the MPF
effectively captures this distinction. Experimental results demonstrate that
the proposed ground filtering method outperforms previous techniques, and the
LIE method successfully distinguishes between points representing trees and
human-made objects.",2024-10-25,"Hong Zhao, Huyunting Huang, Tonglin Zhang, Baijian Yang, Jin Wei-Kocsis, Songlin Fei",http://arxiv.org/pdf/2410.20006v1,cs.LG
Enhancing Battery Storage Energy Arbitrage with Deep Reinforcement Learning and Time-Series Forecasting,"Energy arbitrage is one of the most profitable sources of income for battery
operators, generating revenues by buying and selling electricity at different
prices. Forecasting these revenues is challenging due to the inherent
uncertainty of electricity prices. Deep reinforcement learning (DRL) emerged in
recent years as a promising tool, able to cope with uncertainty by training on
large quantities of historical data. However, without access to future
electricity prices, DRL agents can only react to the currently observed price
and not learn to plan battery dispatch. Therefore, in this study, we combine
DRL with time-series forecasting methods from deep learning to enhance the
performance on energy arbitrage. We conduct a case study using price data from
Alberta, Canada that is characterized by irregular price spikes and highly
non-stationary. This data is challenging to forecast even when state-of-the-art
deep learning models consisting of convolutional layers, recurrent layers, and
attention modules are deployed. Our results show that energy arbitrage with
DRL-enabled battery control still significantly benefits from these imperfect
predictions, but only if predictors for several horizons are combined. Grouping
multiple predictions for the next 24-hour window, accumulated rewards increased
by 60% for deep Q-networks (DQN) compared to the experiments without forecasts.
We hypothesize that multiple predictors, despite their imperfections, convey
useful information regarding the future development of electricity prices
through a ""majority vote"" principle, enabling the DRL agent to learn more
profitable control policies.",2024-10-25,"Manuel Sage, Joshua Campbell, Yaoyao Fiona Zhao",http://arxiv.org/pdf/2410.20005v1,cs.LG
Dimension reduction via score ratio matching,"Gradient-based dimension reduction decreases the cost of Bayesian inference
and probabilistic modeling by identifying maximally informative (and informed)
low-dimensional projections of the data and parameters, allowing
high-dimensional problems to be reformulated as cheaper low-dimensional
problems. A broad family of such techniques identify these projections and
provide error bounds on the resulting posterior approximations, via
eigendecompositions of certain diagnostic matrices. Yet these matrices require
gradients or even Hessians of the log-likelihood, excluding the purely
data-driven setting and many problems of simulation-based inference. We propose
a framework, derived from score-matching, to extend gradient-based dimension
reduction to problems where gradients are unavailable. Specifically, we
formulate an objective function to directly learn the score ratio function
needed to compute the diagnostic matrices, propose a tailored parameterization
for the score ratio network, and introduce regularization methods that
capitalize on the hypothesized low-dimensional structure. We also introduce a
novel algorithm to iteratively identify the low-dimensional reduced basis
vectors more accurately with limited data based on eigenvalue deflation
methods. We show that our approach outperforms standard score-matching for
problems with low-dimensional structure, and demonstrate its effectiveness for
PDE-constrained Bayesian inverse problems and conditional generative modeling.",2024-10-25,"Ricardo Baptista, Michael Brennan, Youssef Marzouk",http://arxiv.org/pdf/2410.19990v1,cs.LG
On-Robot Reinforcement Learning with Goal-Contrastive Rewards,"Reinforcement Learning (RL) has the potential to enable robots to learn from
their own actions in the real world. Unfortunately, RL can be prohibitively
expensive, in terms of on-robot runtime, due to inefficient exploration when
learning from a sparse reward signal. Designing dense reward functions is
labour-intensive and requires domain expertise. In our work, we propose GCR
(Goal-Contrastive Rewards), a dense reward function learning method that can be
trained on passive video demonstrations. By using videos without actions, our
method is easier to scale, as we can use arbitrary videos. GCR combines two
loss functions, an implicit value loss function that models how the reward
increases when traversing a successful trajectory, and a goal-contrastive loss
that discriminates between successful and failed trajectories. We perform
experiments in simulated manipulation environments across RoboMimic and
MimicGen tasks, as well as in the real world using a Franka arm and a Spot
quadruped. We find that GCR leads to a more-sample efficient RL, enabling
model-free RL to solve about twice as many tasks as our baseline reward
learning methods. We also demonstrate positive cross-embodiment transfer from
videos of people and of other robots performing a task. Website:
https://gcr-robot.github.io/.",2024-10-25,"Ondrej Biza, Thomas Weng, Lingfeng Sun, Karl Schmeckpeper, Tarik Kelestemur, Yecheng Jason Ma, Robert Platt, Jan-Willem van de Meent, Lawson L. S. Wong",http://arxiv.org/pdf/2410.19989v2,cs.LG
Residual Random Neural Networks,"The single-layer feedforward neural network with random weights is a
recurring motif in the neural networks literature. The advantage of these
networks is their simplified training, which reduces to solving a
ridge-regression problem. A general assumption is that these networks require a
large number of hidden neurons relative to the dimensionality of the data
samples, in order to achieve good classification accuracy. Contrary to this
assumption, here we show that one can obtain good classification results even
if the number of hidden neurons has the same order of magnitude as the
dimensionality of the data samples, if this dimensionality is reasonably high.
Inspired by this result, we also develop an efficient iterative residual
training method for such random neural networks, and we extend the algorithm to
the least-squares kernel version of the neural network model. Moreover, we also
describe an encryption (obfuscation) method which can be used to protect both
the data and the resulted network model.",2024-10-25,M. Andrecut,http://arxiv.org/pdf/2410.19987v4,cs.LG
Resolving Domain Shift For Representations Of Speech In Non-Invasive Brain Recordings,"Machine learning techniques have enabled researchers to leverage neuroimaging
data to decode speech from brain activity, with some amazing recent successes
achieved by applications built using invasive devices. However, research
requiring surgical implants has a number of practical limitations. Non-invasive
neuroimaging techniques provide an alternative but come with their own set of
challenges, the limited scale of individual studies being among them. Without
the ability to pool the recordings from different non-invasive studies, data on
the order of magnitude needed to leverage deep learning techniques to their
full potential remains out of reach. In this work, we focus on non-invasive
data collected using magnetoencephalography (MEG). We leverage two different,
leading speech decoding models to investigate how an adversarial domain
adaptation framework augments their ability to generalize across datasets. We
successfully improve the performance of both models when training across
multiple datasets. To the best of our knowledge, this study is the first ever
application of feature-level, deep learning based harmonization for MEG
neuroimaging data. Our analysis additionally offers further evidence of the
impact of demographic features on neuroimaging data, demonstrating that
participant age strongly affects how machine learning models solve speech
decoding tasks using MEG data. Lastly, in the course of this study we produce a
new open-source implementation of one of these models to the benefit of the
broader scientific community.",2024-10-25,"Jeremiah Ridge, Oiwi Parker Jones",http://arxiv.org/pdf/2410.19986v1,cs.LG
Random Policy Enables In-Context Reinforcement Learning within Trust Horizons,"Pretrained foundation models have exhibited extraordinary in-context learning
performance, allowing zero-shot generalization to new tasks not encountered
during pretraining. In the case of reinforcement learning (RL), in-context RL
(ICRL) emerges when pretraining FMs on decision-making problems in an
autoregressive-supervised manner. Nevertheless, current state-of-the-art ICRL
algorithms, like Algorithm Distillation, Decision Pretrained Transformer and
Decision Importance Transformer, impose stringent requirements on the
pretraining dataset concerning the source policies, context information, and
action labels. Notably, these algorithms either demand optimal policies or
require varying degrees of well-trained behavior policies for all pretraining
environments. This significantly hinders the application of ICRL to real-world
scenarios, where acquiring optimal or well-trained policies for a substantial
volume of real-world training environments can be intractable. To overcome this
challenge, we introduce a novel approach, termed State-Action Distillation
(SAD), that allows to generate an effective pretraining dataset guided solely
by random policies. In particular, SAD selects query states and corresponding
action labels by distilling outstanding state-action pairs from the entire
state and action spaces by using random policies within a trust horizon, and
then inherits the classical autoregressive-supervised mechanism during
pretraining. To the best of our knowledge, this is the first work that enables
effective ICRL under random policies and random contexts. We also establish
quantitative analysis of the trustworthiness as well as the performance
guarantees of SAD. Moreover, our empirical results across multiple popular ICRL
benchmark environments demonstrate that, on average, SAD outperforms the best
baseline by 236.3% in the offline evaluation and by 135.2% in the online
evaluation.",2024-10-25,"Weiqin Chen, Santiago Paternain",http://arxiv.org/pdf/2410.19982v3,cs.LG
Decoding Diffusion: A Scalable Framework for Unsupervised Analysis of Latent Space Biases and Representations Using Natural Language Prompts,"Recent advances in image generation have made diffusion models powerful tools
for creating high-quality images. However, their iterative denoising process
makes understanding and interpreting their semantic latent spaces more
challenging than other generative models, such as GANs. Recent methods have
attempted to address this issue by identifying semantically meaningful
directions within the latent space. However, they often need manual
interpretation or are limited in the number of vectors that can be trained,
restricting their scope and utility. This paper proposes a novel framework for
unsupervised exploration of diffusion latent spaces. We directly leverage
natural language prompts and image captions to map latent directions. This
method allows for the automatic understanding of hidden features and supports a
broader range of analysis without the need to train specific vectors. Our
method provides a more scalable and interpretable understanding of the semantic
knowledge encoded within diffusion models, facilitating comprehensive analysis
of latent biases and the nuanced representations these models learn.
Experimental results show that our framework can uncover hidden patterns and
associations in various domains, offering new insights into the
interpretability of diffusion model latent spaces.",2024-10-25,"E. Zhixuan Zeng, Yuhao Chen, Alexander Wong",http://arxiv.org/pdf/2410.21314v2,cs.LG
Global Graph Counterfactual Explanation: A Subgraph Mapping Approach,"Graph Neural Networks (GNNs) have been widely deployed in various real-world
applications. However, most GNNs are black-box models that lack explanations.
One strategy to explain GNNs is through counterfactual explanation, which aims
to find minimum perturbations on input graphs that change the GNN predictions.
Existing works on GNN counterfactual explanations primarily concentrate on the
local-level perspective (i.e., generating counterfactuals for each individual
graph), which suffers from information overload and lacks insights into the
broader cross-graph relationships. To address such issues, we propose
GlobalGCE, a novel global-level graph counterfactual explanation method.
GlobalGCE aims to identify a collection of subgraph mapping rules as
counterfactual explanations for the target GNN. According to these rules,
substituting certain significant subgraphs with their counterfactual subgraphs
will change the GNN prediction to the desired class for most graphs (i.e.,
maximum coverage). Methodologically, we design a significant subgraph generator
and a counterfactual subgraph autoencoder in our GlobalGCE, where the subgraphs
and the rules can be effectively generated. Extensive experiments demonstrate
the superiority of our GlobalGCE compared to existing baselines. Our code can
be found at https://anonymous.4open.science/r/GlobalGCE-92E8.",2024-10-25,"Yinhan He, Wendy Zheng, Yaochen Zhu, Jing Ma, Saumitra Mishra, Natraj Raman, Ninghao Liu, Jundong Li",http://arxiv.org/pdf/2410.19978v1,cs.LG
Evaluating Cost-Accuracy Trade-offs in Multimodal Search Relevance Judgements,"Large Language Models (LLMs) have demonstrated potential as effective search
relevance evaluators. However, there is a lack of comprehensive guidance on
which models consistently perform optimally across various contexts or within
specific use cases. In this paper, we assess several LLMs and Multimodal
Language Models (MLLMs) in terms of their alignment with human judgments across
multiple multimodal search scenarios. Our analysis investigates the trade-offs
between cost and accuracy, highlighting that model performance varies
significantly depending on the context. Interestingly, in smaller models, the
inclusion of a visual component may hinder performance rather than enhance it.
These findings highlight the complexities involved in selecting the most
appropriate model for practical applications.",2024-10-25,"Silvia Terragni, Hoang Cuong, Joachim Daiber, Pallavi Gudipati, Pablo N. Mendes",http://arxiv.org/pdf/2410.19974v1,cs.LG
Understanding Adam Requires Better Rotation Dependent Assumptions,"Despite its widespread adoption, Adam's advantage over Stochastic Gradient
Descent (SGD) lacks a comprehensive theoretical explanation. This paper
investigates Adam's sensitivity to rotations of the parameter space. We
demonstrate that Adam's performance in training transformers degrades under
random rotations of the parameter space, indicating a crucial sensitivity to
the choice of basis. This reveals that conventional rotation-invariant
assumptions are insufficient to capture Adam's advantages theoretically. To
better understand the rotation-dependent properties that benefit Adam, we also
identify structured rotations that preserve or even enhance its empirical
performance. We then examine the rotation-dependent assumptions in the
literature, evaluating their adequacy in explaining Adam's behavior across
various rotation types. This work highlights the need for new,
rotation-dependent theoretical frameworks to fully understand Adam's empirical
success in modern machine learning tasks.",2024-10-25,"Lucas Maes, Tianyue H. Zhang, Alexia Jolicoeur-Martineau, Ioannis Mitliagkas, Damien Scieur, Simon Lacoste-Julien, Charles Guille-Escuret",http://arxiv.org/pdf/2410.19964v1,cs.LG
Towards Robust Out-of-Distribution Generalization: Data Augmentation and Neural Architecture Search Approaches,"Deep learning has been demonstrated with tremendous success in recent years.
Despite so, its performance in practice often degenerates drastically when
encountering out-of-distribution (OoD) data, i.e. training and test data are
sampled from different distributions. In this thesis, we study ways toward
robust OoD generalization for deep learning, i.e., its performance is not
susceptible to distribution shift in the test data.
  We first propose a novel and effective approach to disentangle the spurious
correlation between features that are not essential for recognition. It employs
decomposed feature representation by orthogonalizing the two gradients of
losses for category and context branches. Furthermore, we perform
gradient-based augmentation on context-related features (e.g., styles,
backgrounds, or scenes of target objects) to improve the robustness of learned
representations. Results show that our approach generalizes well for different
distribution shifts.
  We then study the problem of strengthening neural architecture search in OoD
scenarios. We propose to optimize the architecture parameters that minimize the
validation loss on synthetic OoD data, under the condition that corresponding
network parameters minimize the training loss. Moreover, to obtain a proper
validation set, we learn a conditional generator by maximizing their losses
computed by different neural architectures. Results show that our approach
effectively discovers robust architectures that perform well for OoD
generalization.",2024-10-25,Haoyue Bai,http://arxiv.org/pdf/2410.21313v1,cs.LG
Bridging Stepwise Lab-Informed Pretraining and Knowledge-Guided Learning for Diagnostic Reasoning,"Despite the growing use of Electronic Health Records (EHR) for AI-assisted
diagnosis prediction, most data-driven models struggle to incorporate
clinically meaningful medical knowledge. They often rely on limited ontologies,
lacking structured reasoning capabilities and comprehensive coverage. This
raises an important research question: Will medical knowledge improve
predictive models to support stepwise clinical reasoning as performed by human
doctors? To address this problem, we propose DuaLK, a dual-expertise framework
that combines two complementary sources of information. For external knowledge,
we construct a Diagnosis Knowledge Graph (KG) that encodes both hierarchical
and semantic relations enriched by large language models (LLM). To align with
patient data, we further introduce a lab-informed proxy task that guides the
model to follow a clinically consistent, stepwise reasoning process based on
lab test signals. Experimental results on two public EHR datasets demonstrate
that DuaLK consistently outperforms existing baselines across four clinical
prediction tasks. These findings highlight the potential of combining
structured medical knowledge with individual-level clinical signals to achieve
more accurate and interpretable diagnostic predictions. The source code is
publicly available on https://github.com/humphreyhuu/DuaLK.",2024-10-25,"Pengfei Hu, Chang Lu, Fei Wang, Yue Ning",http://arxiv.org/pdf/2410.19955v2,cs.LG
Statistical Inference in Classification of High-dimensional Gaussian Mixture,"We consider the classification problem of a high-dimensional mixture of two
Gaussians with general covariance matrices. Using the replica method from
statistical physics, we investigate the asymptotic behavior of a general class
of regularized convex classifiers in the high-dimensional limit, where both the
sample size $n$ and the dimension $p$ approach infinity while their ratio
$\alpha=n/p$ remains fixed. Our focus is on the generalization error and
variable selection properties of the estimators. Specifically, based on the
distributional limit of the classifier, we construct a de-biased estimator to
perform variable selection through an appropriate hypothesis testing procedure.
Using $L_1$-regularized logistic regression as an example, we conducted
extensive computational experiments to confirm that our analytical findings are
consistent with numerical simulations in finite-sized systems. We also explore
the influence of the covariance structure on the performance of the de-biased
estimator.",2024-10-25,"Hanwen Huang, Peng Zeng",http://arxiv.org/pdf/2410.19950v1,cs.LG
Privacy without Noisy Gradients: Slicing Mechanism for Generative Model Training,"Training generative models with differential privacy (DP) typically involves
injecting noise into gradient updates or adapting the discriminator's training
procedure. As a result, such approaches often struggle with hyper-parameter
tuning and convergence. We consider the slicing privacy mechanism that injects
noise into random low-dimensional projections of the private data, and provide
strong privacy guarantees for it. These noisy projections are used for training
generative models. To enable optimizing generative models using this DP
approach, we introduce the smoothed-sliced $f$-divergence and show it enjoys
statistical consistency. Moreover, we present a kernel-based estimator for this
divergence, circumventing the need for adversarial training. Extensive
numerical experiments demonstrate that our approach can generate synthetic data
of higher quality compared with baselines. Beyond performance improvement, our
method, by sidestepping the need for noisy gradients, offers data scientists
the flexibility to adjust generator architecture and hyper-parameters, run the
optimization over any number of epochs, and even restart the optimization
process -- all without incurring additional privacy costs.",2024-10-25,"Kristjan Greenewald, Yuancheng Yu, Hao Wang, Kai Xu",http://arxiv.org/pdf/2410.19941v1,cs.LG
$\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis,"Pharmaceutical patents play a vital role in biochemical industries,
especially in drug discovery, providing researchers with unique early access to
data, experimental results, and research insights. With the advancement of
machine learning, patent analysis has evolved from manual labor to tasks
assisted by automatic tools. However, there still lacks an unified agent that
assists every aspect of patent analysis, from patent reading to core chemical
identification. Leveraging the capabilities of Large Language Models (LLMs) to
understand requests and follow instructions, we introduce the $\textbf{first}$
intelligent agent in this domain, $\texttt{PatentAgent}$, poised to advance and
potentially revolutionize the landscape of pharmaceutical research.
$\texttt{PatentAgent}$ comprises three key end-to-end modules --
$\textit{PA-QA}$, $\textit{PA-Img2Mol}$, and $\textit{PA-CoreId}$ -- that
respectively perform (1) patent question-answering, (2)
image-to-molecular-structure conversion, and (3) core chemical structure
identification, addressing the essential needs of scientists and practitioners
in pharmaceutical patent analysis. Each module of $\texttt{PatentAgent}$
demonstrates significant effectiveness with the updated algorithm and the
synergistic design of $\texttt{PatentAgent}$ framework. $\textit{PA-Img2Mol}$
outperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks
with an accuracy gain between 2.46% and 8.37% while $\textit{PA-CoreId}$
realizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML
benchmark. Our code and dataset will be publicly available.",2024-10-25,"Xin Wang, Yifan Zhang, Xiaojing Zhang, Longhui Yu, Xinna Lin, Jindong Jiang, Bin Ma, Kaicheng Yu",http://arxiv.org/pdf/2410.21312v1,cs.LG
Enhancing Safety in Reinforcement Learning with Human Feedback via Rectified Policy Optimization,"Balancing helpfulness and safety (harmlessness) is a critical challenge in
aligning large language models (LLMs). Current approaches often decouple these
two objectives, training separate preference models for helpfulness and safety,
while framing safety as a constraint within a constrained Markov Decision
Process (CMDP) framework. This paper identifies a potential issue when using
the widely adopted expected safety constraints for LLM safety alignment, termed
""safety compensation"", where the constraints are satisfied on expectation, but
individual prompts may trade off safety, resulting in some responses being
overly restrictive while others remain unsafe. To address this issue, we
propose Rectified Policy Optimization (RePO), which replaces the expected
safety constraint with critical safety constraints imposed on every prompt. At
the core of RePO is a policy update mechanism driven by rectified policy
gradients, which penalizes the strict safety violation of every prompt, thereby
enhancing safety across nearly all prompts. Our experiments demonstrate that
RePO outperforms strong baseline methods and significantly enhances LLM safety
alignment.",2024-10-25,"Xiyue Peng, Hengquan Guo, Jiawei Zhang, Dongqing Zou, Ziyu Shao, Honghao Wei, Xin Liu",http://arxiv.org/pdf/2410.19933v2,cs.LG
Provable optimal transport with transformers: The essence of depth and prompt engineering,"Can we establish provable performance guarantees for transformers?
Establishing such theoretical guarantees is a milestone in developing
trustworthy generative AI. In this paper, we take a step toward addressing this
question by focusing on optimal transport, a fundamental problem at the
intersection of combinatorial and continuous optimization. Leveraging the
computational power of attention layers, we prove that a transformer with fixed
parameters can effectively solve the optimal transport problem in Wasserstein-2
with entropic regularization for an arbitrary number of points. Consequently,
the transformer can sort lists of arbitrary sizes up to an approximation
factor. Our results rely on an engineered prompt that enables the transformer
to implement gradient descent with adaptive stepsizes on the dual optimal
transport. Combining the convergence analysis of gradient descent with Sinkhorn
dynamics, we establish an explicit approximation bound for optimal transport
with transformers, which improves as depth increases. Our findings provide
novel insights into the essence of prompt engineering and depth for solving
optimal transport. In particular, prompt engineering boosts the algorithmic
expressivity of transformers, allowing them implement an optimization method.
With increasing depth, transformers can simulate several iterations of gradient
descent.",2024-10-25,Hadi Daneshmand,http://arxiv.org/pdf/2410.19931v2,cs.LG
Improving Multimodal Large Language Models Using Continual Learning,"Generative large language models (LLMs) exhibit impressive capabilities,
which can be further augmented by integrating a pre-trained vision model into
the original LLM to create a multimodal LLM (MLLM). However, this integration
often significantly decreases performance on natural language understanding and
generation tasks, compared to the original LLM. This study investigates this
issue using the LLaVA MLLM, treating the integration as a continual learning
problem. We evaluate five continual learning methods to mitigate forgetting and
identify a technique that enhances visual understanding while minimizing
linguistic performance loss. Our approach reduces linguistic performance
degradation by up to 15\% over the LLaVA recipe, while maintaining high
multimodal accuracy. We also demonstrate the robustness of our method through
continual learning on a sequence of vision-language tasks, effectively
preserving linguistic skills while acquiring new multimodal capabilities.",2024-10-25,"Shikhar Srivastava, Md Yousuf Harun, Robik Shrestha, Christopher Kanan",http://arxiv.org/pdf/2410.19925v1,cs.LG
Prediction of Final Phosphorus Content of Steel in a Scrap-Based Electric Arc Furnace Using Artificial Neural Networks,"The scrap-based electric arc furnace process is expected to capture a
significant share of the steel market in the future due to its potential for
reducing environmental impacts through steel recycling. However, managing
impurities, particularly phosphorus, remains a challenge. This study aims to
develop a machine learning model to estimate the steel phosphorus content at
the end of the process based on input parameters. Data were collected over two
years from a steel plant, focusing on the chemical composition and weight of
the scrap, the volume of oxygen injected, and process duration. After
preprocessing the data, several machine learning models were evaluated, with
the artificial neural network (ANN) emerging as the most effective. The best
ANN model included four hidden layers. The model was trained for 500 epochs
with a batch size of 50. The best model achieves a mean square error (MSE) of
0.000016, a root-mean-square error (RMSE) of 0.0049998, a coefficient of
determination (R2) of 99.96%, and a correlation coefficient (r) of 99.98%.
Notably, the model achieved a 100% hit rate for predicting phosphorus content
within +-0.001 wt% (+-10 ppm). These results demonstrate that the optimized ANN
model offers accurate predictions for the steel final phosphorus content.",2024-10-25,"Riadh Azzaz, Valentin Hurel, Patrice Menard, Mohammad Jahazi, Samira Ebrahimi Kahou, Elmira Moosavi-Khoonsari",http://arxiv.org/pdf/2410.19924v1,cs.LG
Language Agents Meet Causality -- Bridging LLMs and Causal World Models,"Large Language Models (LLMs) have recently shown great promise in planning
and reasoning applications. These tasks demand robust systems, which arguably
require a causal understanding of the environment. While LLMs can acquire and
reflect common sense causal knowledge from their pretraining data, this
information is often incomplete, incorrect, or inapplicable to a specific
environment. In contrast, causal representation learning (CRL) focuses on
identifying the underlying causal structure within a given environment. We
propose a framework that integrates CRLs with LLMs to enable causally-aware
reasoning and planning. This framework learns a causal world model, with causal
variables linked to natural language expressions. This mapping provides LLMs
with a flexible interface to process and generate descriptions of actions and
states in text form. Effectively, the causal world model acts as a simulator
that the LLM can query and interact with. We evaluate the framework on causal
inference and planning tasks across temporal scales and environmental
complexities. Our experiments demonstrate the effectiveness of the approach,
with the causally-aware method outperforming LLM-based reasoners, especially
for longer planning horizons.",2024-10-25,"John Gkountouras, Matthias Lindemann, Phillip Lippe, Efstratios Gavves, Ivan Titov",http://arxiv.org/pdf/2410.19923v1,cs.LG
Disentangling Genotype and Environment Specific Latent Features for Improved Trait Prediction using a Compositional Autoencoder,"This study introduces a compositional autoencoder (CAE) framework designed to
disentangle the complex interplay between genotypic and environmental factors
in high-dimensional phenotype data to improve trait prediction in plant
breeding and genetics programs. Traditional predictive methods, which use
compact representations of high-dimensional data through handcrafted features
or latent features like PCA or more recently autoencoders, do not separate
genotype-specific and environment-specific factors. We hypothesize that
disentangling these features into genotype-specific and environment-specific
components can enhance predictive models. To test this, we developed a
compositional autoencoder (CAE) that decomposes high-dimensional data into
distinct genotype-specific and environment-specific latent features.
  Our CAE framework employs a hierarchical architecture within an autoencoder
to effectively separate these entangled latent features. Applied to a maize
diversity panel dataset, the CAE demonstrates superior modeling of
environmental influences and 5-10 times improved predictive performance for key
traits like Days to Pollen and Yield, compared to the traditional methods,
including standard autoencoders, PCA with regression, and Partial Least Squares
Regression (PLSR). By disentangling latent features, the CAE provides powerful
tool for precision breeding and genetic research. This work significantly
enhances trait prediction models, advancing agricultural and biological
sciences.",2024-10-25,"Anirudha Powadi, Talukder Zaki Jubery, Michael C. Tross, James C. Schnable, Baskar Ganapathysubramanian",http://arxiv.org/pdf/2410.19922v1,cs.LG
Method for noise-induced regularization in quantum neural networks,"In the current quantum computing paradigm, significant focus is placed on the
reduction or mitigation of quantum decoherence. When designing new quantum
processing units, the general objective is to reduce the amount of noise qubits
are subject to, and in algorithm design, a large effort is underway to provide
scalable error correction or mitigation techniques. Yet some previous work has
indicated that certain classes of quantum algorithms, such as quantum machine
learning, may, in fact, be intrinsically robust to or even benefit from the
presence of a small amount of noise. Here, we demonstrate that noise levels in
quantum hardware can be effectively tuned to enhance the ability of quantum
neural networks to generalize data, acting akin to regularisation in classical
neural networks. As an example, we consider a medical regression task, where,
by tuning the noise level in the circuit, we improved the mean squared error
loss by 8%.",2024-10-25,"Wilfrid Somogyi, Ekaterina Pankovets, Viacheslav Kuzmin, Alexey Melnikov",http://arxiv.org/pdf/2410.19921v1,cs.LG
Reinforcement Learning for Aligning Large Language Models Agents with Interactive Environments: Quantifying and Mitigating Prompt Overfitting,"Reinforcement learning (RL) is a promising approach for aligning large
language models (LLMs) knowledge with sequential decision-making tasks.
However, few studies have thoroughly investigated the impact on LLM agents
capabilities of fine-tuning them with RL in a specific environment. In this
paper, we propose a novel framework to analyze the sensitivity of LLMs to
prompt formulations following RL training in a textual environment. Our
findings reveal that the performance of LLMs degrades when faced with prompt
formulations different from those used during the RL training phase. Besides,
we analyze the source of this sensitivity by examining the model's internal
representations and salient tokens. Finally, we propose to use a contrastive
loss to mitigate this sensitivity and improve the robustness and generalization
capabilities of LLMs.",2024-10-25,"Mohamed Salim Aissi, Clement Romac, Thomas Carta, Sylvain Lamprier, Pierre-Yves Oudeyer, Olivier Sigaud, Laure Soulier, Nicolas Thome",http://arxiv.org/pdf/2410.19920v2,cs.LG
Provably Adaptive Average Reward Reinforcement Learning for Metric Spaces,"We study infinite-horizon average-reward reinforcement learning (RL) for
Lipschitz MDPs and develop an algorithm ZoRL that discretizes the state-action
space adaptively and zooms into promising regions of the state-action space. We
show that its regret can be bounded as $\mathcal{\tilde{O}}\big(T^{1 -
d_{\text{eff.}}^{-1}}\big)$, where $d_{\text{eff.}} = 2d_\mathcal{S} + d_z +
3$, $d_\mathcal{S}$ is the dimension of the state space, and $d_z$ is the
zooming dimension. $d_z$ is a problem-dependent quantity, which allows us to
conclude that if MDP is benign, then its regret will be small. We note that the
existing notion of zooming dimension for average reward RL is defined in terms
of policy coverings, and hence it can be huge when the policy class is rich
even though the underlying MDP is simple, so that the regret upper bound is
nearly $O(T)$. The zooming dimension proposed in the current work is bounded
above by $d$, the dimension of the state-action space, and hence is truly
adaptive, i.e., shows how to capture adaptivity gains for infinite-horizon
average-reward RL. ZoRL outperforms other state-of-the-art algorithms in
experiments; thereby demonstrating the gains arising due to adaptivity.",2024-10-25,"Avik Kar, Rahul Singh",http://arxiv.org/pdf/2410.19919v1,cs.LG
Collaborative Inference over Wireless Channels with Feature Differential Privacy,"Collaborative inference among multiple wireless edge devices has the
potential to significantly enhance Artificial Intelligence (AI) applications,
particularly for sensing and computer vision. This approach typically involves
a three-stage process: a) data acquisition through sensing, b) feature
extraction, and c) feature encoding for transmission. However, transmitting the
extracted features poses a significant privacy risk, as sensitive personal data
can be exposed during the process. To address this challenge, we propose a
novel privacy-preserving collaborative inference mechanism, wherein each edge
device in the network secures the privacy of extracted features before
transmitting them to a central server for inference. Our approach is designed
to achieve two primary objectives: 1) reducing communication overhead and 2)
ensuring strict privacy guarantees during feature transmission, while
maintaining effective inference performance. Additionally, we introduce an
over-the-air pooling scheme specifically designed for classification tasks,
which provides formal guarantees on the privacy of transmitted features and
establishes a lower bound on classification accuracy.",2024-10-25,"Mohamed Seif, Yuqi Nie, Andrea J. Goldsmith, H. Vincent Poor",http://arxiv.org/pdf/2410.19917v1,cs.LG
Simmering: Sufficient is better than optimal for training neural networks,"The broad range of neural network training techniques that invoke
optimization but rely on ad hoc modification for validity suggests that
optimization-based training is misguided. Shortcomings of optimization-based
training are brought to particularly strong relief by the problem of
overfitting, where naive optimization produces spurious outcomes. The broad
success of neural networks for modelling physical processes has prompted
advances that are based on inverting the direction of investigation and
treating neural networks as if they were physical systems in their own right
These successes raise the question of whether broader, physical perspectives
could motivate the construction of improved training algorithms. Here, we
introduce simmering, a physics-based method that trains neural networks to
generate weights and biases that are merely ``good enough'', but which,
paradoxically, outperforms leading optimization-based approaches. Using
classification and regression examples we show that simmering corrects neural
networks that are overfit by Adam, and show that simmering avoids overfitting
if deployed from the outset. Our results question optimization as a paradigm
for neural network training, and leverage information-geometric arguments to
point to the existence of classes of sufficient training algorithms that do not
take optimization as their starting point.",2024-10-25,"Irina Babayan, Hazhir Aliahmadi, Greg van Anders",http://arxiv.org/pdf/2410.19912v1,cs.LG
"cymyc -- Calabi-Yau Metrics, Yukawas, and Curvature","We introduce \texttt{cymyc}, a high-performance Python library for numerical
investigation of the geometry of a large class of string compactification
manifolds and their associated moduli spaces. We develop a well-defined
geometric ansatz to numerically model tensor fields of arbitrary degree on a
large class of Calabi-Yau manifolds. \texttt{cymyc} includes a machine learning
component which incorporates this ansatz to model tensor fields of interest on
these spaces by finding an approximate solution to the system of partial
differential equations they should satisfy.",2024-10-25,"Per Berglund, Giorgi Butbaia, Tristan Hübsch, Vishnu Jejjala, Challenger Mishra, Damián Mayorga Peña, Justin Tan",http://arxiv.org/pdf/2410.19728v1,cs.LG
"FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning","Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.",2024-10-25,"Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson",http://arxiv.org/pdf/2410.19727v1,cs.LG
On the Benefits of Active Data Collection in Operator Learning,"We study active data collection strategies for operator learning when the
target operator is linear and the input functions are drawn from a mean-zero
stochastic process with continuous covariance kernels. With an active data
collection strategy, we establish an error convergence rate in terms of the
decay rate of the eigenvalues of the covariance kernel. We can achieve
arbitrarily fast error convergence rates with sufficiently rapid eigenvalue
decay of the covariance kernels. This contrasts with the passive (i.i.d.) data
collection strategies, where the convergence rate is never faster than linear
decay ($\sim n^{-1}$). In fact, for our setting, we show a \emph{non-vanishing}
lower bound for any passive data collection strategy, regardless of the
eigenvalues decay rate of the covariance kernel. Overall, our results show the
benefit of active data collection strategies in operator learning over their
passive counterparts.",2024-10-25,"Unique Subedi, Ambuj Tewari",http://arxiv.org/pdf/2410.19725v3,cs.LG
Sparse Decomposition of Graph Neural Networks,"Graph Neural Networks (GNN) exhibit superior performance in graph
representation learning, but their inference cost can be high, due to an
aggregation operation that can require a memory fetch for a very large number
of nodes. This inference cost is the major obstacle to deploying GNN models
with \emph{online prediction} to reflect the potentially dynamic node features.
To address this, we propose an approach to reduce the number of nodes that are
included during aggregation. We achieve this through a sparse decomposition,
learning to approximate node representations using a weighted sum of linearly
transformed features of a carefully selected subset of nodes within the
extended neighbourhood. The approach achieves linear complexity with respect to
the average node degree and the number of layers in the graph neural network.
We introduce an algorithm to compute the optimal parameters for the sparse
decomposition, ensuring an accurate approximation of the original GNN model,
and present effective strategies to reduce the training time and improve the
learning process. We demonstrate via extensive experiments that our method
outperforms other baselines designed for inference speedup, achieving
significant accuracy gains with comparable inference times for both node
classification and spatio-temporal forecasting tasks.",2024-10-25,"Yaochen Hu, Mai Zeng, Ge Zhang, Pavel Rumiantsev, Liheng Ma, Yingxue Zhang, Mark Coates",http://arxiv.org/pdf/2410.19723v2,cs.LG
Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection,"The early detection of potential failures in industrial machinery components
is paramount for ensuring the reliability and safety of operations, thereby
preserving Machine Condition Monitoring (MCM). This research addresses this
imperative by introducing an innovative approach to Real-Time Acoustic Anomaly
Detection. Our method combines semi-supervised temporal convolution with
representation learning and a hybrid model strategy with Temporal Convolutional
Networks (TCN) to handle various intricate anomaly patterns found in acoustic
data effectively. The proposed model demonstrates superior performance compared
to established research in the field, underscoring the effectiveness of this
approach. Not only do we present quantitative evidence of its superiority, but
we also employ visual representations, such as t-SNE plots, to further
substantiate the model's efficacy.",2024-10-25,"Sahan Dissanayaka, Manjusri Wickramasinghe, Pasindu Marasinghe",http://arxiv.org/pdf/2410.19722v1,cs.LG
A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection,"This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.",2024-10-25,"Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor",http://arxiv.org/pdf/2410.19898v1,cs.LG
GPT-4o System Card,"GPT-4o is an autoregressive omni model that accepts as input any combination
of text, audio, image, and video, and generates any combination of text, audio,
and image outputs. It's trained end-to-end across text, vision, and audio,
meaning all inputs and outputs are processed by the same neural network. GPT-4o
can respond to audio inputs in as little as 232 milliseconds, with an average
of 320 milliseconds, which is similar to human response time in conversation.
It matches GPT-4 Turbo performance on text in English and code, with
significant improvement on text in non-English languages, while also being much
faster and 50\% cheaper in the API. GPT-4o is especially better at vision and
audio understanding compared to existing models. In line with our commitment to
building AI safely and consistent with our voluntary commitments to the White
House, we are sharing the GPT-4o System Card, which includes our Preparedness
Framework evaluations. In this System Card, we provide a detailed look at
GPT-4o's capabilities, limitations, and safety evaluations across multiple
categories, focusing on speech-to-speech while also evaluating text and image
capabilities, and measures we've implemented to ensure the model is safe and
aligned. We also include third-party assessments on dangerous capabilities, as
well as discussion of potential societal impacts of GPT-4o's text and vision
capabilities.",2024-10-25,"OpenAI, :, Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, Aleksander Mądry, Alex Baker-Whitcomb, Alex Beutel, Alex Borzunov, Alex Carney, Alex Chow, Alex Kirillov, Alex Nichol, Alex Paino, Alex Renzin, Alex Tachard Passos, Alexander Kirillov, Alexi Christakis, Alexis Conneau, Ali Kamali, Allan Jabri, Allison Moyer, Allison Tam, Amadou Crookes, Amin Tootoochian, Amin Tootoonchian, Ananya Kumar, Andrea Vallone, Andrej Karpathy, Andrew Braunstein, Andrew Cann, Andrew Codispoti, Andrew Galu, Andrew Kondrich, Andrew Tulloch, Andrey Mishchenko, Angela Baek, Angela Jiang, Antoine Pelisse, Antonia Woodford, Anuj Gosalia, Arka Dhar, Ashley Pantuliano, Avi Nayak, Avital Oliver, Barret Zoph, Behrooz Ghorbani, Ben Leimberger, Ben Rossen, Ben Sokolowsky, Ben Wang, Benjamin Zweig, Beth Hoover, Blake Samic, Bob McGrew, Bobby Spero, Bogo Giertler, Bowen Cheng, Brad Lightcap, Brandon Walkin, Brendan Quinn, Brian Guarraci, Brian Hsu, Bright Kellogg, Brydon Eastman, Camillo Lugaresi, Carroll Wainwright, Cary Bassin, Cary Hudson, Casey Chu, Chad Nelson, Chak Li, Chan Jun Shern, Channing Conger, Charlotte Barette, Chelsea Voss, Chen Ding, Cheng Lu, Chong Zhang, Chris Beaumont, Chris Hallacy, Chris Koch, Christian Gibson, Christina Kim, Christine Choi, Christine McLeavey, Christopher Hesse, Claudia Fischer, Clemens Winter, Coley Czarnecki, Colin Jarvis, Colin Wei, Constantin Koumouzelis, Dane Sherburn, Daniel Kappler, Daniel Levin, Daniel Levy, David Carr, David Farhi, David Mely, David Robinson, David Sasaki, Denny Jin, Dev Valladares, Dimitris Tsipras, Doug Li, Duc Phong Nguyen, Duncan Findlay, Edede Oiwoh, Edmund Wong, Ehsan Asdar, Elizabeth Proehl, Elizabeth Yang, Eric Antonow, Eric Kramer, Eric Peterson, Eric Sigler, Eric Wallace, Eugene Brevdo, Evan Mays, Farzad Khorasani, Felipe Petroski Such, Filippo Raso, Francis Zhang, Fred von Lohmann, Freddie Sulit, Gabriel Goh, Gene Oden, Geoff Salmon, Giulio Starace, Greg Brockman, Hadi Salman, Haiming Bao, Haitang Hu, Hannah Wong, Haoyu Wang, Heather Schmidt, Heather Whitney, Heewoo Jun, Hendrik Kirchner, Henrique Ponde de Oliveira Pinto, Hongyu Ren, Huiwen Chang, Hyung Won Chung, Ian Kivlichan, Ian O'Connell, Ian O'Connell, Ian Osband, Ian Silber, Ian Sohl, Ibrahim Okuyucu, Ikai Lan, Ilya Kostrikov, Ilya Sutskever, Ingmar Kanitscheider, Ishaan Gulrajani, Jacob Coxon, Jacob Menick, Jakub Pachocki, James Aung, James Betker, James Crooks, James Lennon, Jamie Kiros, Jan Leike, Jane Park, Jason Kwon, Jason Phang, Jason Teplitz, Jason Wei, Jason Wolfe, Jay Chen, Jeff Harris, Jenia Varavva, Jessica Gan Lee, Jessica Shieh, Ji Lin, Jiahui Yu, Jiayi Weng, Jie Tang, Jieqi Yu, Joanne Jang, Joaquin Quinonero Candela, Joe Beutler, Joe Landers, Joel Parish, Johannes Heidecke, John Schulman, Jonathan Lachman, Jonathan McKay, Jonathan Uesato, Jonathan Ward, Jong Wook Kim, Joost Huizinga, Jordan Sitkin, Jos Kraaijeveld, Josh Gross, Josh Kaplan, Josh Snyder, Joshua Achiam, Joy Jiao, Joyce Lee, Juntang Zhuang, Justyn Harriman, Kai Fricke, Kai Hayashi, Karan Singhal, Katy Shi, Kavin Karthik, Kayla Wood, Kendra Rimbach, Kenny Hsu, Kenny Nguyen, Keren Gu-Lemberg, Kevin Button, Kevin Liu, Kiel Howe, Krithika Muthukumar, Kyle Luther, Lama Ahmad, Larry Kai, Lauren Itow, Lauren Workman, Leher Pathak, Leo Chen, Li Jing, Lia Guy, Liam Fedus, Liang Zhou, Lien Mamitsuka, Lilian Weng, Lindsay McCallum, Lindsey Held, Long Ouyang, Louis Feuvrier, Lu Zhang, Lukas Kondraciuk, Lukasz Kaiser, Luke Hewitt, Luke Metz, Lyric Doshi, Mada Aflak, Maddie Simens, Madelaine Boyd, Madeleine Thompson, Marat Dukhan, Mark Chen, Mark Gray, Mark Hudnall, Marvin Zhang, Marwan Aljubeh, Mateusz Litwin, Matthew Zeng, Max Johnson, Maya Shetty, Mayank Gupta, Meghan Shah, Mehmet Yatbaz, Meng Jia Yang, Mengchao Zhong, Mia Glaese, Mianna Chen, Michael Janner, Michael Lampe, Michael Petrov, Michael Wu, Michele Wang, Michelle Fradin, Michelle Pokrass, Miguel Castro, Miguel Oom Temudo de Castro, Mikhail Pavlov, Miles Brundage, Miles Wang, Minal Khan, Mira Murati, Mo Bavarian, Molly Lin, Murat Yesildal, Nacho Soto, Natalia Gimelshein, Natalie Cone, Natalie Staudacher, Natalie Summers, Natan LaFontaine, Neil Chowdhury, Nick Ryder, Nick Stathas, Nick Turley, Nik Tezak, Niko Felix, Nithanth Kudige, Nitish Keskar, Noah Deutsch, Noel Bundick, Nora Puckett, Ofir Nachum, Ola Okelola, Oleg Boiko, Oleg Murk, Oliver Jaffe, Olivia Watkins, Olivier Godement, Owen Campbell-Moore, Patrick Chao, Paul McMillan, Pavel Belov, Peng Su, Peter Bak, Peter Bakkum, Peter Deng, Peter Dolan, Peter Hoeschele, Peter Welinder, Phil Tillet, Philip Pronin, Philippe Tillet, Prafulla Dhariwal, Qiming Yuan, Rachel Dias, Rachel Lim, Rahul Arora, Rajan Troll, Randall Lin, Rapha Gontijo Lopes, Raul Puri, Reah Miyara, Reimar Leike, Renaud Gaubert, Reza Zamani, Ricky Wang, Rob Donnelly, Rob Honsby, Rocky Smith, Rohan Sahai, Rohit Ramchandani, Romain Huet, Rory Carmichael, Rowan Zellers, Roy Chen, Ruby Chen, Ruslan Nigmatullin, Ryan Cheu, Saachi Jain, Sam Altman, Sam Schoenholz, Sam Toizer, Samuel Miserendino, Sandhini Agarwal, Sara Culver, Scott Ethersmith, Scott Gray, Sean Grove, Sean Metzger, Shamez Hermani, Shantanu Jain, Shengjia Zhao, Sherwin Wu, Shino Jomoto, Shirong Wu, Shuaiqi, Xia, Sonia Phene, Spencer Papay, Srinivas Narayanan, Steve Coffey, Steve Lee, Stewart Hall, Suchir Balaji, Tal Broda, Tal Stramer, Tao Xu, Tarun Gogineni, Taya Christianson, Ted Sanders, Tejal Patwardhan, Thomas Cunninghman, Thomas Degry, Thomas Dimson, Thomas Raoux, Thomas Shadwell, Tianhao Zheng, Todd Underwood, Todor Markov, Toki Sherbakov, Tom Rubin, Tom Stasi, Tomer Kaftan, Tristan Heywood, Troy Peterson, Tyce Walters, Tyna Eloundou, Valerie Qi, Veit Moeller, Vinnie Monaco, Vishal Kuo, Vlad Fomenko, Wayne Chang, Weiyi Zheng, Wenda Zhou, Wesam Manassra, Will Sheu, Wojciech Zaremba, Yash Patil, Yilei Qian, Yongjik Kim, Youlong Cheng, Yu Zhang, Yuchen He, Yuchen Zhang, Yujia Jin, Yunxing Dai, Yury Malkov",http://arxiv.org/pdf/2410.21276v1,cs.LG
Adversarial Environment Design via Regret-Guided Diffusion Models,"Training agents that are robust to environmental changes remains a
significant challenge in deep reinforcement learning (RL). Unsupervised
environment design (UED) has recently emerged to address this issue by
generating a set of training environments tailored to the agent's capabilities.
While prior works demonstrate that UED has the potential to learn a robust
policy, their performance is constrained by the capabilities of the environment
generation. To this end, we propose a novel UED algorithm, adversarial
environment design via regret-guided diffusion models (ADD). The proposed
method guides the diffusion-based environment generator with the regret of the
agent to produce environments that the agent finds challenging but conducive to
further improvement. By exploiting the representation power of diffusion
models, ADD can directly generate adversarial environments while maintaining
the diversity of training environments, enabling the agent to effectively learn
a robust policy. Our experimental results demonstrate that the proposed method
successfully generates an instructive curriculum of environments, outperforming
UED baselines in zero-shot generalization across novel, out-of-distribution
environments. Project page: https://rllab-snu.github.io/projects/ADD",2024-10-25,"Hojun Chung, Junseo Lee, Minsoo Kim, Dohyeong Kim, Songhwai Oh",http://arxiv.org/pdf/2410.19715v2,cs.LG
Water and Electricity Consumption Forecasting at an Educational Institution using Machine Learning models with Metaheuristic Optimization,"Educational institutions are essential for economic and social development.
Budget cuts in Brazil in recent years have made it difficult to carry out their
activities and projects. In the case of expenses with water and electricity,
unexpected situations can occur, such as leaks and equipment failures, which
make their management challenging. This study proposes a comparison between two
machine learning models, Random Forest (RF) and Support Vector Regression
(SVR), for water and electricity consumption forecasting at the Federal
Institute of Paran\'a-Campus Palmas, with a 12-month forecasting horizon, as
well as evaluating the influence of the application of climatic variables as
exogenous features. The data were collected over the past five years, combining
details pertaining to invoices with exogenous and endogenous variables. The two
models had their hyperpa-rameters optimized using the Genetic Algorithm (GA) to
select the individuals with the best fitness to perform the forecasting with
and without climatic variables. The absolute percentage errors and root mean
squared error were used as performance measures to evaluate the forecasting
accuracy. The results suggest that in forecasting water and electricity
consumption over a 12-step horizon, the Random Forest model exhibited the most
superior performance. The integration of climatic variables often led to
diminished forecasting accuracy, resulting in higher errors. Both models still
had certain difficulties in predicting water consumption, indicating that new
studies with different models or variables are welcome.",2024-10-25,"Eduardo Luiz Alba, Matheus Henrique Dal Molin Ribeiro, Gilson Adamczuk, Flavio Trojan, Erick Oliveira Rodrigues",http://arxiv.org/pdf/2410.19709v1,cs.LG
Super Gradient Descent: Global Optimization requires Global Gradient,"Global minimization is a fundamental challenge in optimization, especially in
machine learning, where finding the global minimum of a function directly
impacts model performance and convergence. This article introduces a novel
optimization method that we called Super Gradient Descent, designed
specifically for one-dimensional functions, guaranteeing convergence to the
global minimum for any k-Lipschitz function defined on a closed interval [a,
b]. Our approach addresses the limitations of traditional optimization
algorithms, which often get trapped in local minima. In particular, we
introduce the concept of global gradient which offers a robust solution for
precise and well-guided global optimization. By focusing on the global
minimization problem, this work bridges a critical gap in optimization theory,
offering new insights and practical advancements in different optimization
problems in particular Machine Learning problems like line search.",2024-10-25,Seifeddine Achour,http://arxiv.org/pdf/2410.19706v2,cs.LG
Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks,"Thompson sampling is one of the most popular learning algorithms for online
sequential decision-making problems and has rich real-world applications.
However, current Thompson sampling algorithms are limited by the assumption
that the rewards received are uncorrupted, which may not be true in real-world
applications where adversarial reward poisoning exists. To make Thompson
sampling more reliable, we want to make it robust against adversarial reward
poisoning. The main challenge is that one can no longer compute the actual
posteriors for the true reward, as the agent can only observe the rewards after
corruption. In this work, we solve this problem by computing pseudo-posteriors
that are less likely to be manipulated by the attack. We propose robust
algorithms based on Thompson sampling for the popular stochastic and contextual
linear bandit settings in both cases where the agent is aware or unaware of the
budget of the attacker. We theoretically show that our algorithms guarantee
near-optimal regret under any attack strategy.",2024-10-25,"Yinglun Xu, Zhiwei Wang, Gagandeep Singh",http://arxiv.org/pdf/2410.19705v1,cs.LG
Multi-view biomedical foundation models for molecule-target and property prediction,"Foundation models applied to bio-molecular space hold promise to accelerate
drug discovery. Molecular representation is key to building such models.
Previous works have typically focused on a single representation or view of the
molecules. Here, we develop a multi-view foundation model approach, that
integrates molecular views of graph, image and text. Single-view foundation
models are each pre-trained on a dataset of up to 200M molecules and then
aggregated into combined representations. Our multi-view model is validated on
a diverse set of 18 tasks, encompassing ligand-protein binding, molecular
solubility, metabolism and toxicity. We show that the multi-view models perform
robustly and are able to balance the strengths and weaknesses of specific
views. We then apply this model to screen compounds against a large (>100
targets) set of G Protein-Coupled receptors (GPCRs). From this library of
targets, we identify 33 that are related to Alzheimer's disease. On this
subset, we employ our model to identify strong binders, which are validated
through structure-based modeling and identification of key binding motifs.",2024-10-25,"Parthasarathy Suryanarayanan, Yunguang Qiu, Shreyans Sethi, Diwakar Mahajan, Hongyang Li, Yuxin Yang, Elif Eyigoz, Aldo Guzman Saenz, Daniel E. Platt, Timothy H. Rumbell, Kenney Ng, Sanjoy Dey, Myson Burch, Bum Chul Kwon, Pablo Meyer, Feixiong Cheng, Jianying Hu, Joseph A. Morrone",http://arxiv.org/pdf/2410.19704v3,cs.LG
"Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery","This paper investigates the inclusion of microservices architecture in the
development of scalable and reliable airline reservation systems. Most of the
traditional reservation systems are very rigid and centralized which makes them
prone to bottlenecks and a single point of failure. As such, systems do not
meet the requirements of modern airlines which are dynamic. Microservices offer
better resiliency and scalability because the services do not depend on one
another and can be deployed independently. The approach is grounded on the
Circuit Breaker Pattern to maintain fault tolerance while consuming foreign
resources such as flight APIs and payment systems. This avoided the failure
propagation to the systems by 60% enabling the systems to function under
external failures. Traffic rerouting also bolstered this with a guarantee of
above 99.95% uptime in systems where high availability was demanded. To address
this, load balancing was used, particularly the Round-Robin method which
managed to enhance performance by 35% through the equal distribution of user
requests among the service instances. Health checks, as well as monitoring in
real-time, helped as well with failure management as they helped to contain
failures before the users of the system were affected. The results suggest that
the use of microservices led to a 40% increase in system scalability, a 50%
decrease in downtime and a support for 30% more concurrent users than the use
of monolithic architectures. These findings affirm the capability of
microservices in the development of robust and flexible airline ticket booking
systems that are responsive to change and recover from external system
unavailability.",2024-10-25,"Biman Barua, M. Shamim Kaiser",http://arxiv.org/pdf/2410.19701v1,cs.LG
Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs,"Fine-tuning Large Language Models (LLMs) has become a crucial technique for
adapting pre-trained models to downstream tasks. However, the enormous size of
LLMs poses significant challenges in terms of computational complexity and
resource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising
solution. However, there exists a gap between the practical performance of
low-rank adaptations and its theoretical optimum. In this work, we propose
eXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this
gap by leveraging the power of ensemble learning. Inspired by gradient
boosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations
to refine model predictions. It achieves better performance than the standard
LoRA, while enjoying the computational efficiency of rank-1 adaptations. We
provide theoretical analysis to show the convergence and optimality of our
approach, and conduct extensive experiments on a range of natural language
processing tasks. The results demonstrate that XGBLoRA consistently outperforms
standard LoRA and achieves performance comparable to full fine-tuning with
significantly fewer trainable parameters. This work advances
parameter-efficient fine-tuning for LLMs, and offers a promising solution for
adapting LLMs to downstream tasks while optimizing performance and efficiency.",2024-10-25,"Yifei Zhang, Hao Zhu, Aiwei Liu, Han Yu, Piotr Koniusz, Irwin King",http://arxiv.org/pdf/2410.19694v1,cs.LG
MILES: Making Imitation Learning Easy with Self-Supervision,"Data collection in imitation learning often requires significant, laborious
human supervision, such as numerous demonstrations, and/or frequent environment
resets for methods that incorporate reinforcement learning. In this work, we
propose an alternative approach, MILES: a fully autonomous, self-supervised
data collection paradigm, and we show that this enables efficient policy
learning from just a single demonstration and a single environment reset. MILES
autonomously learns a policy for returning to and then following the single
demonstration, whilst being self-guided during data collection, eliminating the
need for additional human interventions. We evaluated MILES across several
real-world tasks, including tasks that require precise contact-rich
manipulation such as locking a lock with a key. We found that, under the
constraints of a single demonstration and no repeated environment resetting,
MILES significantly outperforms state-of-the-art alternatives like imitation
learning methods that leverage reinforcement learning. Videos of our
experiments and code can be found on our webpage: www.robot-learning.uk/miles.",2024-10-25,"Georgios Papagiannis, Edward Johns",http://arxiv.org/pdf/2410.19693v1,cs.LG
Learning the Regularization Strength for Deep Fine-Tuning via a Data-Emphasized Variational Objective,"A number of popular transfer learning methods rely on grid search to select
regularization hyperparameters that control over-fitting. This grid search
requirement has several key disadvantages: the search is computationally
expensive, requires carving out a validation set that reduces the size of
available data for model training, and requires practitioners to specify
candidate values. In this paper, we propose an alternative to grid search:
directly learning regularization hyperparameters on the full training set via
model selection techniques based on the evidence lower bound (""ELBo"") objective
from variational methods. For deep neural networks with millions of parameters,
we specifically recommend a modified ELBo that upweights the influence of the
data likelihood relative to the prior while remaining a valid bound on the
evidence for Bayesian model selection. Our proposed technique overcomes all
three disadvantages of grid search. We demonstrate effectiveness on image
classification tasks on several datasets, yielding heldout accuracy comparable
to existing approaches with far less compute time.",2024-10-25,"Ethan Harvey, Mikhail Petrov, Michael C. Hughes",http://arxiv.org/pdf/2410.19675v2,cs.LG
Spatial Shortcuts in Graph Neural Controlled Differential Equations,"We incorporate prior graph topology information into a Neural Controlled
Differential Equation (NCDE) to predict the future states of a dynamical system
defined on a graph. The informed NCDE infers the future dynamics at the
vertices of simulated advection data on graph edges with a known causal graph,
observed only at vertices during training. We investigate different positions
in the model architecture to inform the NCDE with graph information and
identify an outer position between hidden state and control as theoretically
and empirically favorable. Our such informed NCDE requires fewer parameters to
reach a lower Mean Absolute Error (MAE) compared to previous methods that do
not incorporate additional graph topology information.",2024-10-25,"Michael Detzel, Gabriel Nobis, Jackie Ma, Wojciech Samek",http://arxiv.org/pdf/2410.19673v1,cs.LG
Electromechanical Dynamics of the Heart: A Study of Cardiac Hysteresis During Physical Stress Test,"Cardiovascular diseases are best diagnosed using multiple modalities that
assess both the heart's electrical and mechanical functions. While effective,
imaging techniques like echocardiography and nuclear imaging are costly and not
widely accessible. More affordable technologies, such as simultaneous
electrocardiography (ECG) and phonocardiography (PCG), may provide valuable
insights into electromechanical coupling and could be useful for prescreening
in low-resource settings.
  Using physical stress test data from the EPHNOGRAM ECG-PCG dataset, collected
from 23 healthy male subjects (age: 25.4+/-1.9 yrs), we investigated
electromechanical intervals (RR, QT, systolic, and diastolic) and their
interactions during exercise, along with hysteresis between cardiac electrical
activity and mechanical responses.
  Time delay analysis revealed distinct temporal relationships between QT,
systolic, and diastolic intervals, with RR as the primary driver. The diastolic
interval showed near-synchrony with RR, while QT responded to RR interval
changes with an average delay of 10.5s, and the systolic interval responded
more slowly, with an average delay of 28.3s. We examined QT-RR, systolic-RR,
and diastolic-RR hysteresis, finding narrower loops for diastolic RR and wider
loops for systolic RR. Significant correlations (average:0.75) were found
between heart rate changes and hysteresis loop areas, suggesting the equivalent
circular area diameter as a promising biomarker for cardiac function under
exercise stress.
  Deep learning models, including Long Short-Term Memory and Convolutional
Neural Networks, estimated the QT, systolic, and diastolic intervals from RR
data, confirming the nonlinear relationship between RR and other intervals.
Findings highlight a significant cardiac memory effect, linking ECG and PCG
morphology and timing to heart rate history.",2024-10-25,"Sajjad Karimi, Shirin Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni",http://arxiv.org/pdf/2410.19667v1,cs.LG
MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services,"Timely updating of Internet of Things (IoT) data is crucial for immersive
vehicular metaverse services. However, challenges such as latency caused by
massive data transmissions, privacy risks associated with user data, and
computational burdens on metaverse service providers (MSPs) hinder continuous
collection of high-quality data. To address these issues, we propose an
immersion-aware model trading framework that facilitates data provision for
services while ensuring privacy through federated learning (FL). Specifically,
we first develop a novel multi-dimensional metric, the immersion of model
(IoM), which assesses model value comprehensively by considering freshness and
accuracy of learning models, as well as the amount and potential value of raw
data used for training. Then, we design an incentive mechanism to incentivize
metaverse users (MUs) to contribute high-value models under resource
constraints. The trading interactions between MSPs and MUs are modeled as an
equilibrium problem with equilibrium constraints (EPEC) to analyze and balance
their costs and gains, where MSPs as leaders determine rewards, while MUs as
followers optimize resource allocation. Furthermore, considering dynamic
network conditions and privacy concerns, we formulate the reward decisions of
MSPs as a multi-agent Markov decision process. To solve this, we develop a
fully distributed dynamic reward algorithm based on deep reinforcement
learning, without accessing any private information about MUs and other MSPs.
Experimental results demonstrate that the proposed framework outperforms
state-of-the-art benchmarks, achieving improvements in IoM of 38.3% and 37.2%,
and reductions in training time to reach the target accuracy of 43.5% and
49.8%, on average, for the MNIST and GTSRB datasets, respectively.",2024-10-25,"Hongjia Wu, Hui Zeng, Zehui Xiong, Jiawen Kang, Zhiping Cai, Tse-Tin Chan, Dusit Niyato, Zhu Han",http://arxiv.org/pdf/2410.19665v2,cs.LG
Conformal Prediction for Multimodal Regression,"This paper introduces multimodal conformal regression. Traditionally confined
to scenarios with solely numerical input features, conformal prediction is now
extended to multimodal contexts through our methodology, which harnesses
internal features from complex neural network architectures processing images
and unstructured text. Our findings highlight the potential for internal neural
network features, extracted from convergence points where multimodal
information is combined, to be used by conformal prediction to construct
prediction intervals (PIs). This capability paves new paths for deploying
conformal prediction in domains abundant with multimodal data, enabling a
broader range of problems to benefit from guaranteed distribution-free
uncertainty quantification.",2024-10-25,"Alexis Bose, Jonathan Ethier, Paul Guinand",http://arxiv.org/pdf/2410.19653v2,cs.LG
Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers,"Early screening for cancer has proven to improve the survival rate and spare
patients from intensive and costly treatments due to late diagnosis. Cancer
screening in the healthy population involves an initial risk stratification
step to determine the screening method and frequency, primarily to optimize
resource allocation by targeting screening towards individuals who draw most
benefit. For most screening programs, age and clinical risk factors such as
family history are part of the initial risk stratification algorithm. In this
paper, we focus on developing a blood marker-based risk stratification
approach, which could be used to identify patients with elevated cancer risk to
be encouraged for taking a diagnostic test or participate in a screening
program. We demonstrate that the combination of simple, widely available blood
tests, such as complete blood count and complete metabolic panel, could
potentially be used to identify patients at risk for colorectal, liver, and
lung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively.
Furthermore, we hypothesize that such an approach could not only be used as
pre-screening risk assessment for individuals but also as population health
management tool, for example to better interrogate the cancer risk in certain
sub-populations.",2024-10-25,"Vivek Singh, Shikha Chaganti, Matthias Siebert, Sowmya Rajesh, Andrei Puiu, Raj Gopalan, Jamie Gramz, Dorin Comaniciu, Ali Kamen",http://arxiv.org/pdf/2410.19646v2,cs.LG
Improving Stochastic Cubic Newton with Momentum,"We study stochastic second-order methods for solving general non-convex
optimization problems. We propose using a special version of momentum to
stabilize the stochastic gradient and Hessian estimates in Newton's method. We
show that momentum provably improves the variance of stochastic estimates and
allows the method to converge for any noise level. Using the cubic
regularization technique, we prove a global convergence rate for our method on
general non-convex problems to a second-order stationary point, even when using
only a single stochastic data sample per iteration. This starkly contrasts with
all existing stochastic second-order methods for non-convex problems, which
typically require large batches. Therefore, we are the first to demonstrate
global convergence for batches of arbitrary size in the non-convex case for the
Stochastic Cubic Newton. Additionally, we show improved speed on convex
stochastic problems for our regularized Newton methods with momentum.",2024-10-25,"El Mahdi Chayti, Nikita Doikov, Martin Jaggi",http://arxiv.org/pdf/2410.19644v1,cs.LG
Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites,"Machine learning (ML) models benefit from large datasets. Collecting data in
biomedical domains is costly and challenging, hence, combining datasets has
become a common practice. However, datasets obtained under different conditions
could present undesired site-specific variability. Data harmonization methods
aim to remove site-specific variance while retaining biologically relevant
information. This study evaluates the effectiveness of popularly used
ComBat-based methods for harmonizing data in scenarios where the class balance
is not equal across sites. We find that these methods struggle with data
leakage issues. To overcome this problem, we propose a novel approach
PrettYharmonize, designed to harmonize data by pretending the target labels. We
validate our approach using controlled datasets designed to benchmark the
utility of harmonization. Finally, using real-world MRI and clinical data, we
compare leakage-prone methods with PrettYharmonize and show that it achieves
comparable performance while avoiding data leakage, particularly in
site-target-dependence scenarios.",2024-10-25,"Nicolás Nieto, Simon B. Eickhoff, Christian Jung, Martin Reuter, Kersten Diers, Malte Kelm, Artur Lichtenberg, Federico Raimondo, Kaustubh R. Patil",http://arxiv.org/pdf/2410.19643v4,cs.LG
Efficient Biological Data Acquisition through Inference Set Design,"In drug discovery, highly automated high-throughput laboratories are used to
screen a large number of compounds in search of effective drugs. These
experiments are expensive, so one might hope to reduce their cost by only
experimenting on a subset of the compounds, and predicting the outcomes of the
remaining experiments. In this work, we model this scenario as a sequential
subset selection problem: we aim to select the smallest set of candidates in
order to achieve some desired level of accuracy for the system as a whole. Our
key observation is that, if there is heterogeneity in the difficulty of the
prediction problem across the input space, selectively obtaining the labels for
the hardest examples in the acquisition pool will leave only the relatively
easy examples to remain in the inference set, leading to better overall system
performance. We call this mechanism inference set design, and propose the use
of a confidence-based active learning solution to prune out these challenging
examples. Our algorithm includes an explicit stopping criterion that interrupts
the acquisition loop when it is sufficiently confident that the system has
reached the target performance. Our empirical studies on image and molecular
datasets, as well as a real-world large-scale biological assay, show that
active learning for inference set design leads to significant reduction in
experimental cost while retaining high system performance.",2024-10-25,"Ihor Neporozhnii, Julien Roy, Emmanuel Bengio, Jason Hartford",http://arxiv.org/pdf/2410.19631v4,cs.LG
Analyzing Neural Network Robustness Using Graph Curvature,"This paper presents a new look at the neural network (NN) robustness problem,
from the point of view of graph theory analysis, specifically graph curvature.
Graph curvature (e.g., Ricci curvature) has been used to analyze system
dynamics and identify bottlenecks in many domains, including road traffic
analysis and internet routing. We define the notion of neural Ricci curvature
and use it to identify bottleneck NN edges that are heavily used to ``transport
data"" to the NN outputs. We provide an evaluation on MNIST that illustrates
that such edges indeed occur more frequently for inputs where NNs are less
robust. These results will serve as the basis for an alternative method of
robust training, by minimizing the number of bottleneck edges.",2024-10-25,"Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov",http://arxiv.org/pdf/2410.19607v2,cs.LG
Mask-Weighted Spatial Likelihood Coding for Speaker-Independent Joint Localization and Mask Estimation,"Due to their robustness and flexibility, neural-driven beamformers are a
popular choice for speech separation in challenging environments with a varying
amount of simultaneous speakers alongside noise and reverberation.
Time-frequency masks and relative directions of the speakers regarding a fixed
spatial grid can be used to estimate the beamformer's parameters. To some
degree, speaker-independence is achieved by ensuring a greater amount of
spatial partitions than speech sources. In this work, we analyze how to encode
both mask and positioning into such a grid to enable joint estimation of both
quantities. We propose mask-weighted spatial likelihood coding and show that it
achieves considerable performance in both tasks compared to baseline encodings
optimized for either localization or mask estimation. In the same setup, we
demonstrate superiority for joint estimation of both quantities. Conclusively,
we propose a universal approach which can replace an upstream sound source
localization system solely by adapting the training framework, making it highly
relevant in performance-critical scenarios.",2024-10-25,"Jakob Kienegger, Alina Mannanova, Timo Gerkmann",http://arxiv.org/pdf/2410.19595v2,cs.LG
Considerations for Distribution Shift Robustness of Diagnostic Models in Healthcare,"We consider robustness to distribution shifts in the context of diagnostic
models in healthcare, where the prediction target $Y$, e.g., the presence of a
disease, is causally upstream of the observations $X$, e.g., a biomarker.
Distribution shifts may occur, for instance, when the training data is
collected in a domain with patients having particular demographic
characteristics while the model is deployed on patients from a different
demographic group. In the domain of applied ML for health, it is common to
predict $Y$ from $X$ without considering further information about the patient.
However, beyond the direct influence of the disease $Y$ on biomarker $X$, a
predictive model may learn to exploit confounding dependencies (or shortcuts)
between $X$ and $Y$ that are unstable under certain distribution shifts. In
this work, we highlight a data generating mechanism common to healthcare
settings and discuss how recent theoretical results from the causality
literature can be applied to build robust predictive models. We theoretically
show why ignoring covariates as well as common invariant learning approaches
will in general not yield robust predictors in the studied setting, while
including certain covariates into the prediction model will. In an extensive
simulation study, we showcase the robustness (or lack thereof) of different
predictors under various data generating processes. Lastly, we analyze the
performance of the different approaches using the PTB-XL dataset, a public
dataset of annotated ECG recordings.",2024-10-25,"Arno Blaas, Adam Goliński, Andrew Miller, Luca Zappella, Jörn-Henrik Jacobsen, Christina Heinze-Deml",http://arxiv.org/pdf/2410.19575v1,cs.LG
How Critical is Site-Specific RAN Optimization? 5G Open-RAN Uplink Air Interface Performance Test and Optimization from Macro-Cell CIR Data,"In this paper, we consider the importance of channel measurement data from
specific sites and its impact on air interface optimization and test.
Currently, a range of statistical channel models including 3GPP 38.901 tapped
delay line (TDL), clustered delay line (CDL), urban microcells (UMi) and urban
macrocells (UMa) type channels are widely used for air interface performance
testing and simulation. However, there remains a gap in the realism of these
models for air interface testing and optimization when compared with real world
measurement based channels. To address this gap, we compare the performance
impacts of training neural receivers with 1) statistical 3GPP TDL models, and
2) measured macro-cell channel impulse response (CIR) data. We leverage our
OmniPHY-5G neural receiver for NR PUSCH uplink simulation, with a training
procedure that uses statistical TDL channel models for pre-training, and
fine-tuning based on measured site specific MIMO CIR data. The proposed
fine-tuning method achieves a 10% block error rate (BLER) at a 1.85 dB lower
signal-to-noise ratio (SNR) compared to pre-training only on simulated TDL
channels, illustrating a rough magnitude of the gap that can be closed by
site-specific training, and gives the first answer to the question ""how much
can fine-tuning the RAN for site-specific channels help?""",2024-10-25,"Johnathan Corgan, Nitin Nair, Rajib Bhattacharjea, Wan Liu, Serhat Tadik, Tom Tsou, Timothy J. O'Shea",http://arxiv.org/pdf/2410.19565v1,cs.LG
Air Quality Prediction with Physics-Guided Dual Neural ODEs in Open Systems,"Air pollution significantly threatens human health and ecosystems,
necessitating effective air quality prediction to inform public policy.
Traditional approaches are generally categorized into physics-based and
data-driven models. Physics-based models usually struggle with high
computational demands and closed-system assumptions, while data-driven models
may overlook essential physical dynamics, confusing the capturing of
spatiotemporal correlations. Although some physics-guided approaches combine
the strengths of both models, they often face a mismatch between explicit
physical equations and implicit learned representations. To address these
challenges, we propose Air-DualODE, a novel physics-guided approach that
integrates dual branches of Neural ODEs for air quality prediction. The first
branch applies open-system physical equations to capture spatiotemporal
dependencies for learning physics dynamics, while the second branch identifies
the dependencies not addressed by the first in a fully data-driven way. These
dual representations are temporally aligned and fused to enhance prediction
accuracy. Our experimental results demonstrate that Air-DualODE achieves
state-of-the-art performance in predicting pollutant concentrations across
various spatial scales, thereby offering a promising solution for real-world
air quality challenges.",2024-10-25,"Jindong Tian, Yuxuan Liang, Ronghui Xu, Peng Chen, Chenjuan Guo, Aoying Zhou, Lujia Pan, Zhongwen Rao, Bin Yang",http://arxiv.org/pdf/2410.19892v2,cs.LG
Neuromorphic IoT Architecture for Efficient Water Management: A Smart Village Case Study,"The exponential growth of IoT networks necessitates a paradigm shift towards
architectures that offer high flexibility and learning capabilities while
maintaining low energy consumption, minimal communication overhead, and low
latency. Traditional IoT systems, particularly when integrated with machine
learning approaches, often suffer from high communication overhead and
significant energy consumption. This work addresses these challenges by
proposing a neuromorphic architecture inspired by biological systems. To
illustrate the practical application of our proposed architecture, we present a
case study focusing on water management in the Carinthian community of Neuhaus.
Preliminary results regarding water consumption prediction and anomaly
detection in this community are presented. We also introduce a novel
neuromorphic IoT architecture that integrates biological principles into the
design of IoT systems. This architecture is specifically tailored for edge
computing scenarios, where low power and high efficiency are crucial. Our
approach leverages the inherent advantages of neuromorphic computing, such as
asynchronous processing and event-driven communication, to create an IoT
framework that is both energy-efficient and responsive. This case study
demonstrates how the neuromorphic IoT architecture can be deployed in a
real-world scenario, highlighting its benefits in terms of energy savings,
reduced communication overhead, and improved system responsiveness.",2024-10-25,"Mugdim Bublin, Heimo Hirner, Antoine-Martin Lanners, Radu Grosu",http://arxiv.org/pdf/2410.19562v1,cs.LG
Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning,"In recent advancements in unsupervised visual representation learning, the
Joint-Embedding Predictive Architecture (JEPA) has emerged as a significant
method for extracting visual features from unlabeled imagery through an
innovative masking strategy. Despite its success, two primary limitations have
been identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPA
in preventing entire collapse and the inadequacy of I-JEPA prediction in
accurately learning the mean of patch representations. Addressing these
challenges, this study introduces a novel framework, namely C-JEPA
(Contrastive-JEPA), which integrates the Image-based Joint-Embedding Predictive
Architecture with the Variance-Invariance-Covariance Regularization (VICReg)
strategy. This integration is designed to effectively learn the
variance/covariance for preventing entire collapse and ensuring invariance in
the mean of augmented views, thereby overcoming the identified limitations.
Through empirical and theoretical evaluations, our work demonstrates that
C-JEPA significantly enhances the stability and quality of visual
representation learning. When pre-trained on the ImageNet-1K dataset, C-JEPA
exhibits rapid and improved convergence in both linear probing and fine-tuning
performance metrics.",2024-10-25,"Shentong Mo, Shengbang Tong",http://arxiv.org/pdf/2410.19560v1,cs.LG
Privacy-Preserving Federated Learning via Dataset Distillation,"Federated Learning (FL) allows users to share knowledge instead of raw data
to train a model with high accuracy. Unfortunately, during the training, users
lose control over the knowledge shared, which causes serious data privacy
issues. We hold that users are only willing and need to share the essential
knowledge to the training task to obtain the FL model with high accuracy.
However, existing efforts cannot help users minimize the shared knowledge
according to the user intention in the FL training procedure. This work
proposes FLiP, which aims to bring the principle of least privilege (PoLP) to
FL training. The key design of FLiP is applying elaborate information reduction
on the training data through a local-global dataset distillation design. We
measure the privacy performance through attribute inference and membership
inference attacks. Extensive experiments show that FLiP strikes a good balance
between model accuracy and privacy protection.",2024-10-25,"ShiMao Xu, Xiaopeng Ke, Xing Su, Shucheng Li, Hao Wu, Sheng Zhong, Fengyuan Xu",http://arxiv.org/pdf/2410.19548v3,cs.LG
Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?,"Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's o1,
have emerged, seemingly demonstrating advanced reasoning capabilities across
text and image modalities. However, the depth of these advances in
language-guided perception and abstract reasoning remains underexplored, and it
is unclear whether these models can truly live up to their ambitious promises.
To assess the progress and identify shortcomings, we enter the wonderland of
Bongard problems, a set of classic visual reasoning puzzles that require
human-like abilities of pattern recognition and abstract reasoning. With our
extensive evaluation setup, we show that while VLMs occasionally succeed in
identifying discriminative concepts and solving some of the problems, they
frequently falter. Surprisingly, even elementary concepts that may seem trivial
to humans, such as simple spirals, pose significant challenges. Moreover, when
explicitly asked to recognize ground truth concepts, they continue to falter,
suggesting not only a lack of understanding of these elementary visual concepts
but also an inability to generalize to unseen concepts. We compare the results
of VLMs to human performance and observe that a significant gap remains between
human visual reasoning capabilities and machine cognition.",2024-10-25,"Antonia Wüst, Tim Tobiasch, Lukas Helff, Inga Ibs, Wolfgang Stammer, Devendra S. Dhami, Constantin A. Rothkopf, Kristian Kersting",http://arxiv.org/pdf/2410.19546v3,cs.LG
CloserMusicDB: A Modern Multipurpose Dataset of High Quality Music,"In this paper, we introduce CloserMusicDB, a collection of full length studio
quality tracks annotated by a team of human experts. We describe the selected
qualities of our dataset, along with three example tasks possible to perform
using this dataset: hook detection, contextual tagging and artist
identification. We conduct baseline experiments and provide initial benchmarks
for these tasks.",2024-10-25,"Aleksandra Piekarzewicz, Tomasz Sroka, Aleksander Tym, Mateusz Modrzejewski",http://arxiv.org/pdf/2410.19540v1,cs.LG
Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series,"Lately, there has been a surge in interest surrounding generative modeling of
time series data. Most existing approaches are designed either to process short
sequences or to handle long-range sequences. This dichotomy can be attributed
to gradient issues with recurrent networks, computational costs associated with
transformers, and limited expressiveness of state space models. Towards a
unified generative model for varying-length time series, we propose in this
work to transform sequences into images. By employing invertible transforms
such as the delay embedding and the short-time Fourier transform, we unlock
three main advantages: i) We can exploit advanced diffusion vision models; ii)
We can remarkably process short- and long-range inputs within the same
framework; and iii) We can harness recent and established tools proposed in the
time series to image literature. We validate the effectiveness of our method
through a comprehensive evaluation across multiple tasks, including
unconditional generation, interpolation, and extrapolation. We show that our
approach achieves consistently state-of-the-art results against strong
baselines. In the unconditional generation tasks, we show remarkable mean
improvements of 58.17% over previous diffusion models in the short
discriminative score and 132.61% in the (ultra-)long classification scores.
Code is at https://github.com/azencot-group/ImagenTime.",2024-10-25,"Ilan Naiman, Nimrod Berman, Itai Pemper, Idan Arbiv, Gal Fadlon, Omri Azencot",http://arxiv.org/pdf/2410.19538v1,cs.LG
AgentForge: A Flexible Low-Code Platform for Reinforcement Learning Agent Design,"Developing a reinforcement learning (RL) agent often involves identifying
values for numerous parameters, covering the policy, reward function,
environment, and agent-internal architecture. Since these parameters are
interrelated in complex ways, optimizing them is a black-box problem that
proves especially challenging for nonexperts. Although existing
optimization-as-a-service platforms (e.g., Vizier and Optuna) can handle such
problems, they are impractical for RL systems, since the need for manual user
mapping of each parameter to distinct components makes the effort cumbersome.
It also requires understanding of the optimization process, limiting the
systems' application beyond the machine learning field and restricting access
in areas such as cognitive science, which models human decision-making. To
tackle these challenges, the paper presents AgentForge, a flexible low-code
platform to optimize any parameter set across an RL system. Available at
https://github.com/feferna/AgentForge, it allows an optimization problem to be
defined in a few lines of code and handed to any of the interfaced optimizers.
With AgentForge, the user can optimize the parameters either individually or
jointly. The paper presents an evaluation of its performance for a challenging
vision-based RL problem.",2024-10-25,"Francisco Erivaldo Fernandes Junior, Antti Oulasvirta",http://arxiv.org/pdf/2410.19528v4,cs.LG
Detection of Human and Machine-Authored Fake News in Urdu,"The rise of social media has amplified the spread of fake news, now further
complicated by large language models (LLMs) like ChatGPT, which ease the
generation of highly convincing, error-free misinformation, making it
increasingly challenging for the public to discern truth from falsehood.
Traditional fake news detection methods relying on linguistic cues also becomes
less effective. Moreover, current detectors primarily focus on binary
classification and English texts, often overlooking the distinction between
machine-generated true vs. fake news and the detection in low-resource
languages. To this end, we updated detection schema to include
machine-generated news with focus on the Urdu language. We further propose a
hierarchical detection strategy to improve the accuracy and robustness.
Experiments show its effectiveness across four datasets in various settings.",2024-10-25,"Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony Smith",http://arxiv.org/pdf/2410.19517v1,cs.LG
Parametric Nonlinear Volterra Series via Machine Learning: Transonic Aerodynamics,"This study introduces an approach for modeling unsteady transonic
aerodynamics within a parametric space, using Volterra series to capture
aerodynamic responses and machine learning to enable interpolation. The first-
and second-order Volterra kernels are derived from indicial aerodynamic
responses obtained through computational fluid dynamics, with the second-order
kernel calculated as a correction to the dominant linear response. Machine
learning algorithms, specifically artificial neural network and Gaussian
process regression, are used to interpolate kernel coefficients within a
parameter space defined by Mach number and angle of attack. The methodology is
applied to two and three dimensional test cases in the transonic regime.
Results underscore the benefit of including the second-order kernel to address
strong nonlinearity and demonstrate the effectiveness of neural networks. The
approach achieves a level of accuracy that appears sufficient for use in
conceptual design.",2024-10-25,"Gabriele Immordino, Andrea Da Ronch, Marcello Righi",http://arxiv.org/pdf/2410.19514v1,cs.LG
Marked Temporal Bayesian Flow Point Processes,"Marked event data captures events by recording their continuous-valued
occurrence timestamps along with their corresponding discrete-valued types.
They have appeared in various real-world scenarios such as social media,
financial transactions, and healthcare records, and have been effectively
modeled through Marked Temporal Point Process (MTPP) models. Recently,
developing generative models for these MTPP models have seen rapid development
due to their powerful generative capability and less restrictive functional
forms. However, existing generative MTPP models are usually challenged in
jointly modeling events' timestamps and types since: (1) mainstream methods
design the generative mechanisms for timestamps only and do not include event
types; (2) the complex interdependence between the timestamps and event types
are overlooked. In this paper, we propose a novel generative MTPP model called
BMTPP. Unlike existing generative MTPP models, BMTPP flexibly models marked
temporal joint distributions using a parameter-based approach. Additionally, by
adding joint noise to the marked temporal data space, BMTPP effectively
captures and explicitly reveals the interdependence between timestamps and
event types. Extensive experiments validate the superiority of our approach
over other state-of-the-art models and its ability to effectively capture
marked-temporal interdependence.",2024-10-25,"Hui Chen, Xuhui Fan, Hengyu Liu, Longbing Cao",http://arxiv.org/pdf/2410.19512v1,cs.LG
DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction,"Dimensionality reduction (DR) plays a crucial role in various fields,
including data engineering and visualization, by simplifying complex datasets
while retaining essential information. However, the challenge of balancing DR
accuracy and interpretability remains crucial, particularly for users dealing
with high-dimensional data. Traditional DR methods often face a trade-off
between precision and transparency, where optimizing for performance can lead
to reduced interpretability, and vice versa. This limitation is especially
prominent in real-world applications such as image, tabular, and text data
analysis, where both accuracy and interpretability are critical. To address
these challenges, this work introduces the MOE-based Hyperbolic Interpretable
Deep Manifold Transformation (DMT-HI). The proposed approach combines
hyperbolic embeddings, which effectively capture complex hierarchical
structures, with Mixture of Experts (MOE) models, which dynamically allocate
tasks based on input features. DMT-HI enhances DR accuracy by leveraging
hyperbolic embeddings to represent the hierarchical nature of data, while also
improving interpretability by explicitly linking input data, embedding
outcomes, and key features through the MOE structure. Extensive experiments
demonstrate that DMT-HI consistently achieves superior performance in both DR
accuracy and model interpretability, making it a robust solution for complex
data analysis. The code is available at
\url{https://github.com/zangzelin/code_dmthi}.",2024-10-25,"Zelin Zang, Yuhao Wang, Jinlin Wu, Hong Liu, Yue Shen, Stan. Z Li, Zhen Lei",http://arxiv.org/pdf/2410.19504v1,cs.LG
A neural network approach for solving the Monge-Ampère equation with transport boundary condition,"This paper introduces a novel neural network-based approach to solving the
Monge-Amp\`ere equation with the transport boundary condition, specifically
targeted towards optical design applications. We leverage multilayer perceptron
networks to learn approximate solutions by minimizing a loss function that
encompasses the equation's residual, boundary conditions, and convexity
constraints. Our main results demonstrate the efficacy of this method,
optimized using L-BFGS, through a series of test cases encompassing symmetric
and asymmetric circle-to-circle, square-to-circle, and circle-to-flower
reflector mapping problems. Comparative analysis with a conventional
least-squares finite-difference solver reveals the competitive, and often
superior, performance of our neural network approach on the test cases examined
here. A comprehensive hyperparameter study further illuminates the impact of
factors such as sampling density, network architecture, and optimization
algorithm. While promising, further investigation is needed to verify the
method's robustness for more complicated problems and to ensure consistent
convergence. Nonetheless, the simplicity and adaptability of this neural
network-based approach position it as a compelling alternative to specialized
partial differential equation solvers.",2024-10-25,"Roel Hacking, Lisa Kusch, Koondanibha Mitra, Martijn Anthonissen, Wilbert IJzerman",http://arxiv.org/pdf/2410.19496v1,cs.LG
Graph Linearization Methods for Reasoning on Graphs with Large Language Models,"Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph reasoning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term ""graph linearization"", so that LLMs can handle graphs
naturally. We consider that graphs should be linearized meaningfully to reflect
certain properties of natural language text, such as local dependency and
global alignment, in order to ease contemporary LLMs, trained on trillions of
textual tokens, better understand graphs. To achieve this, we developed several
graph linearization methods based on graph centrality and degeneracy. These
methods are further enhanced using node relabeling techniques. The experimental
results demonstrate the effectiveness of our methods compared to the random
linearization baseline. Our work introduces novel graph representations
suitable for LLMs, contributing to the potential integration of graph machine
learning with the trend of multimodal processing using a unified transformer
model.",2024-10-25,"Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis",http://arxiv.org/pdf/2410.19494v2,cs.LG
Conditional Hallucinations for Image Compression,"In lossy image compression, models face the challenge of either hallucinating
details or generating out-of-distribution samples due to the information
bottleneck. This implies that at times, introducing hallucinations is necessary
to generate in-distribution samples. The optimal level of hallucination varies
depending on image content, as humans are sensitive to small changes that alter
the semantic meaning. We propose a novel compression method that dynamically
balances the degree of hallucination based on content. We collect data and
train a model to predict user preferences on hallucinations. By using this
prediction to adjust the perceptual weight in the reconstruction loss, we
develop a Conditionally Hallucinating compression model (ConHa) that
outperforms state-of-the-art image compression methods. Code and images are
available at https://polybox.ethz.ch/index.php/s/owS1k5JYs4KD4TA.",2024-10-25,"Till Aczel, Roger Wattenhofer",http://arxiv.org/pdf/2410.19493v2,cs.LG
TRADE: Transfer of Distributions between External Conditions with Normalizing Flows,"Modeling distributions that depend on external control parameters is a common
scenario in diverse applications like molecular simulations, where system
properties like temperature affect molecular configurations. Despite the
relevance of these applications, existing solutions are unsatisfactory as they
require severely restricted model architectures or rely on energy-based
training, which is prone to instability. We introduce TRADE, which overcomes
these limitations by formulating the learning process as a boundary value
problem. By initially training the model for a specific condition using either
i.i.d.~samples or backward KL training, we establish a boundary distribution.
We then propagate this information across other conditions using the gradient
of the unnormalized density with respect to the external parameter. This
formulation, akin to the principles of physics-informed neural networks, allows
us to efficiently learn parameter-dependent distributions without restrictive
assumptions. Experimentally, we demonstrate that TRADE achieves excellent
results in a wide range of applications, ranging from Bayesian inference and
molecular simulations to physical lattice models.",2024-10-25,"Stefan Wahl, Armand Rousselot, Felix Draxler, Henrik Schopmans, Ullrich Köthe",http://arxiv.org/pdf/2410.19492v2,cs.LG
Measuring memorization in language models via probabilistic extraction,"Large language models (LLMs) are susceptible to memorizing training data,
raising concerns about the potential extraction of sensitive information at
generation time. Discoverable extraction is the most common method for
measuring this issue: split a training example into a prefix and suffix, then
prompt the LLM with the prefix, and deem the example extractable if the LLM
generates the matching suffix using greedy sampling. This definition yields a
yes-or-no determination of whether extraction was successful with respect to a
single query. Though efficient to compute, we show that this definition is
unreliable because it does not account for non-determinism present in more
realistic (non-greedy) sampling schemes, for which LLMs produce a range of
outputs for the same prompt. We introduce probabilistic discoverable
extraction, which, without additional cost, relaxes discoverable extraction by
considering multiple queries to quantify the probability of extracting a target
sequence. We evaluate our probabilistic measure across different models,
sampling schemes, and training-data repetitions, and find that this measure
provides more nuanced information about extraction risk compared to traditional
discoverable extraction.",2024-10-25,"Jamie Hayes, Marika Swanberg, Harsh Chaudhari, Itay Yona, Ilia Shumailov, Milad Nasr, Christopher A. Choquette-Choo, Katherine Lee, A. Feder Cooper",http://arxiv.org/pdf/2410.19482v3,cs.LG
Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization,"Inverse folding models play an important role in structure-based design by
predicting amino acid sequences that fold into desired reference structures.
Models like ProteinMPNN, a message-passing encoder-decoder model, are trained
to reliably produce new sequences from a reference structure. However, when
applied to peptides, these models are prone to generating repetitive sequences
that do not fold into the reference structure. To address this, we fine-tune
ProteinMPNN to produce diverse and structurally consistent peptide sequences
via Direct Preference Optimization (DPO). We derive two enhancements to DPO:
online diversity regularization and domain-specific priors. Additionally, we
develop a new understanding on improving diversity in decoder models. When
conditioned on OpenFold generated structures, our fine-tuned models achieve
state-of-the-art structural similarity scores, improving base ProteinMPNN by at
least 8%. Compared to standard DPO, our regularized method achieves up to 20%
higher sequence diversity with no loss in structural similarity score.",2024-10-25,"Ryan Park, Darren J. Hsu, C. Brian Roland, Maria Korshunova, Chen Tessler, Shie Mannor, Olivia Viessmann, Bruno Trentini",http://arxiv.org/pdf/2410.19471v1,cs.LG
Unified Causality Analysis Based on the Degrees of Freedom,"Temporally evolving systems are typically modeled by dynamic equations. A key
challenge in accurate modeling is understanding the causal relationships
between subsystems, as well as identifying the presence and influence of
unobserved hidden drivers on the observed dynamics. This paper presents a
unified method capable of identifying fundamental causal relationships between
pairs of systems, whether deterministic or stochastic. Notably, the method also
uncovers hidden common causes beyond the observed variables. By analyzing the
degrees of freedom in the system, our approach provides a more comprehensive
understanding of both causal influence and hidden confounders. This unified
framework is validated through theoretical models and simulations,
demonstrating its robustness and potential for broader application.",2024-10-25,"András Telcs, Marcell T. Kurbucz, Antal Jakovác",http://arxiv.org/pdf/2410.19469v1,cs.LG
LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data,"Discovering the underlying Directed Acyclic Graph (DAG) from time series
observational data is highly challenging due to the dynamic nature and complex
nonlinear interactions between variables. Existing methods typically search for
the optimal DAG by optimizing an objective function but face scalability
challenges, as their computational demands grow exponentially with the
dimensional expansion of variables. To this end, we propose LOCAL, a highly
efficient, easy-to-implement, and constraint-free method for recovering dynamic
causal structures. LOCAL is the first attempt to formulate a quasi-maximum
likelihood-based score function for learning the dynamic DAG equivalent to the
ground truth. Building on this, we introduce two adaptive modules that enhance
the algebraic characterization of acyclicity: Asymptotic Causal Mask Learning
(ACML) and Dynamic Graph Parameter Learning (DGPL). ACML constructs causal
masks using learnable priority vectors and the Gumbel-Sigmoid function,
ensuring DAG formation while optimizing computational efficiency. DGPL
transforms causal learning into decomposed matrix products, capturing dynamic
causal structure in high-dimensional data and improving interpretability.
Extensive experiments on synthetic and real-world datasets demonstrate that
LOCAL significantly outperforms existing methods and highlight LOCAL's
potential as a robust and efficient method for dynamic causal discovery.",2024-10-25,"Jiajun Zhang, Boyang Qiang, Xiaoyu Guo, Weiwei Xing, Yue Cheng, Witold Pedrycz",http://arxiv.org/pdf/2410.19464v4,cs.LG
Accelerating AI Performance using Anderson Extrapolation on GPUs,"We present a novel approach for accelerating AI performance by leveraging
Anderson extrapolation, a vector-to-vector mapping technique based on a window
of historical iterations. By identifying the crossover point (Fig. 1) where a
mixing penalty is incurred, the method focuses on reducing iterations to
convergence, with fewer more compute-intensive but generally cacheable
iterations, balancing speed and memory usage with accuracy and algorithmic
stability, respectively. We demonstrate significant improvements, in both
training and inference, motivated by scalability and efficiency extensions to
the realm of high-performance computing (HPC).",2024-10-25,"Saleem Abdul Fattah Ahmed Al Dajani, David E. Keyes",http://arxiv.org/pdf/2410.19460v2,cs.LG
Computational Bottlenecks of Training Small-scale Large Language Models,"While large language models (LLMs) dominate the AI landscape, Small-scale
large Language Models (SLMs) are gaining attention due to cost and efficiency
demands from consumers. However, there is limited research on the training
behavior and computational requirements of SLMs. In this study, we explore the
computational bottlenecks of training SLMs (up to 2B parameters) by examining
the effects of various hyperparameters and configurations, including GPU type,
batch size, model size, communication protocol, attention type, and the number
of GPUs. We assess these factors on popular cloud services using metrics such
as loss per dollar and tokens per second. Our findings aim to support the
broader adoption and optimization of language model training for low-resource
AI research institutes.",2024-10-25,"Saleh Ashkboos, Iman Mirzadeh, Keivan Alizadeh, Mohammad Hossein Sekhavat, Moin Nabi, Mehrdad Farajtabar, Fartash Faghri",http://arxiv.org/pdf/2410.19456v2,cs.LG
Learned Reference-based Diffusion Sampling for multi-modal distributions,"Over the past few years, several approaches utilizing score-based diffusion
have been proposed to sample from probability distributions, that is without
having access to exact samples and relying solely on evaluations of
unnormalized densities. The resulting samplers approximate the time-reversal of
a noising diffusion process, bridging the target distribution to an
easy-to-sample base distribution. In practice, the performance of these methods
heavily depends on key hyperparameters that require ground truth samples to be
accurately tuned. Our work aims to highlight and address this fundamental
issue, focusing in particular on multi-modal distributions, which pose
significant challenges for existing sampling methods. Building on existing
approaches, we introduce Learned Reference-based Diffusion Sampler (LRDS), a
methodology specifically designed to leverage prior knowledge on the location
of the target modes in order to bypass the obstacle of hyperparameter tuning.
LRDS proceeds in two steps by (i) learning a reference diffusion model on
samples located in high-density space regions and tailored for multimodality,
and (ii) using this reference model to foster the training of a diffusion-based
sampler. We experimentally demonstrate that LRDS best exploits prior knowledge
on the target distribution compared to competing algorithms on a variety of
challenging distributions.",2024-10-25,"Maxence Noble, Louis Grenioux, Marylou Gabrié, Alain Oliviero Durmus",http://arxiv.org/pdf/2410.19449v3,cs.LG
Gradient Descent Efficiency Index,"Gradient descent is a widely used iterative algorithm for finding local
minima in multivariate functions. However, the final iterations often either
overshoot the minima or make minimal progress, making it challenging to
determine an optimal stopping point. This study introduces a new efficiency
metric, Ek, designed to quantify the effectiveness of each iteration. The
proposed metric accounts for both the relative change in error and the
stability of the loss function across iterations. This measure is particularly
valuable in resource-constrained environments, where costs are closely tied to
training time. Experimental validation across multiple datasets and models
demonstrates that Ek provides valuable insights into the convergence behavior
of gradient descent, complementing traditional performance metrics. The index
has the potential to guide more informed decisions in the selection and tuning
of optimization algorithms in machine learning applications and be used to
compare the ""effectiveness"" of models relative to each other.",2024-10-25,Aviral Dhingra,http://arxiv.org/pdf/2410.19448v1,cs.LG
Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment,"Automatically recognizing emotional intent using facial expression has been a
thoroughly investigated topic in the realm of computer vision. Facial
Expression Recognition (FER), being a supervised learning task, relies heavily
on substantially large data exemplifying various socio-cultural demographic
attributes. Over the past decade, several real-world in-the-wild FER datasets
that have been proposed were collected through crowd-sourcing or web-scraping.
However, most of these practically used datasets employ a manual annotation
methodology for labeling emotional intent, which inherently propagates
individual demographic biases. Moreover, these datasets also lack an equitable
representation of various socio-cultural demographic groups, thereby inducing a
class imbalance. Bias analysis and its mitigation have been investigated across
multiple domains and problem settings, however, in the FER domain, this is a
relatively lesser explored area. This work leverages representation learning
based on latent spaces to mitigate bias in facial expression recognition
systems, thereby enhancing a deep learning model's fairness and overall
accuracy.",2024-10-25,"Syed Sameen Ahmad Rizvi, Aryan Seth, Pratik Narang",http://arxiv.org/pdf/2410.19444v1,cs.LG
On the Application of Deep Learning for Precise Indoor Positioning in 6G,"Accurate localization in indoor environments is a challenge due to the Non
Line of Sight (NLoS) nature of the signaling. In this paper, we explore the use
of AI/ML techniques for positioning accuracy enhancement in Indoor Factory
(InF) scenarios. The proposed neural network, which we term LocNet, is trained
on measurements such as Channel Impulse Response (CIR) and Reference Signal
Received Power (RSRP) from multiple Transmit Receive Points (TRPs). Simulation
results show that when using measurements from 18 TRPs, LocNet achieves a 9 cm
positioning accuracy at the 90th percentile. Additionally, we demonstrate that
the same model generalizes effectively even when measurements from some TRPs
randomly become unavailable. Lastly, we provide insights on the robustness of
the trained model to the errors in ground truth labels used for training.",2024-10-25,"Sai Prasanth Kotturi, Anil Kumar Yerrapragada, Sai Prasad, Radha Krishna Ganti",http://arxiv.org/pdf/2410.19436v1,cs.LG
Generative Diffusion Models for Sequential Recommendations,"Generative models such as Variational Autoencoders (VAEs) and Generative
Adversarial Networks (GANs) have shown promise in sequential recommendation
tasks. However, they face challenges, including posterior collapse and limited
representation capacity. The work by Li et al. (2023) introduces a novel
approach that leverages diffusion models to address these challenges by
representing item embeddings as distributions rather than fixed vectors. This
approach allows for a more adaptive reflection of users' diverse interests and
various item aspects. During the diffusion phase, the model converts the target
item embedding into a Gaussian distribution by adding noise, facilitating the
representation of sequential item distributions and the injection of
uncertainty. An Approximator then processes this noisy item representation to
reconstruct the target item. In the reverse phase, the model utilizes users'
past interactions to reverse the noise and finalize the item prediction through
a rounding operation. This research introduces enhancements to the DiffuRec
architecture, particularly by adding offset noise in the diffusion process to
improve robustness and incorporating a cross-attention mechanism in the
Approximator to better capture relevant user-item interactions. These
contributions led to the development of a new model, DiffuRecSys, which
improves performance. Extensive experiments conducted on three public benchmark
datasets demonstrate that these modifications enhance item representation,
effectively capture diverse user preferences, and outperform existing baselines
in sequential recommendation research.",2024-10-25,"Sharare Zolghadr, Ole Winther, Paul Jeha",http://arxiv.org/pdf/2410.19429v1,cs.LG
Analyzing Generative Models by Manifold Entropic Metrics,"Good generative models should not only synthesize high quality data, but also
utilize interpretable representations that aid human understanding of their
behavior. However, it is difficult to measure objectively if and to what degree
desirable properties of disentangled representations have been achieved.
Inspired by the principle of independent mechanisms, we address this difficulty
by introducing a novel set of tractable information-theoretic evaluation
metrics. We demonstrate the usefulness of our metrics on illustrative toy
examples and conduct an in-depth comparison of various normalizing flow
architectures and $\beta$-VAEs on the EMNIST dataset. Our method allows to sort
latent features by importance and assess the amount of residual correlations of
the resulting concepts. The most interesting finding of our experiments is a
ranking of model architectures and training procedures in terms of their
inductive bias to converge to aligned and disentangled representations during
training.",2024-10-25,"Daniel Galperin, Ullrich Köthe",http://arxiv.org/pdf/2410.19426v2,cs.LG
Ensembling Finetuned Language Models for Text Classification,"Finetuning is a common practice widespread across different communities to
adapt pretrained models to particular tasks. Text classification is one of
these tasks for which many pretrained models are available. On the other hand,
ensembles of neural networks are typically used to boost performance and
provide reliable uncertainty estimates. However, ensembling pretrained models
for text classification is not a well-studied avenue. In this paper, we present
a metadataset with predictions from five large finetuned models on six
datasets, and report results of different ensembling strategies from these
predictions. Our results shed light on how ensembling can improve the
performance of finetuned text classifiers and incentivize future adoption of
ensembles in such tasks.",2024-10-25,"Sebastian Pineda Arango, Maciej Janowski, Lennart Purucker, Arber Zela, Frank Hutter, Josif Grabocka",http://arxiv.org/pdf/2410.19889v1,cs.LG
Robust Time Series Causal Discovery for Agent-Based Model Validation,"Agent-Based Model (ABM) validation is crucial as it helps ensuring the
reliability of simulations, and causal discovery has become a powerful tool in
this context. However, current causal discovery methods often face accuracy and
robustness challenges when applied to complex and noisy time series data, which
is typical in ABM scenarios. This study addresses these issues by proposing a
Robust Cross-Validation (RCV) approach to enhance causal structure learning for
ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two
prominent causal discovery algorithms. These aim to reduce the impact of noise
better and give more reliable causal relation results, even with
high-dimensional, time-dependent data. The proposed approach is then integrated
into an enhanced ABM validation framework, which is designed to handle diverse
data and model structures.
  The approach is evaluated using synthetic datasets and a complex simulated
fMRI dataset. The results demonstrate greater reliability in causal structure
identification. The study examines how various characteristics of datasets
affect the performance of established causal discovery methods. These
characteristics include linearity, noise distribution, stationarity, and causal
structure density. This analysis is then extended to the RCV method to see how
it compares in these different situations. This examination helps confirm
whether the results are consistent with existing literature and also reveals
the strengths and weaknesses of the novel approaches.
  By tackling key methodological challenges, the study aims to enhance ABM
validation with a more resilient valuation framework presented. These
improvements increase the reliability of model-driven decision making processes
in complex systems analysis.",2024-10-25,"Gene Yu, Ce Guo, Wayne Luk",http://arxiv.org/pdf/2410.19412v1,cs.LG
An Auditing Test To Detect Behavioral Shift in Language Models,"As language models (LMs) approach human-level performance, a comprehensive
understanding of their behavior becomes crucial. This includes evaluating
capabilities, biases, task performance, and alignment with societal values.
Extensive initial evaluations, including red teaming and diverse benchmarking,
can establish a model's behavioral profile. However, subsequent fine-tuning or
deployment modifications may alter these behaviors in unintended ways. We
present a method for continual Behavioral Shift Auditing (BSA) in LMs. Building
on recent work in hypothesis testing, our auditing test detects behavioral
shifts solely through model generations. Our test compares model generations
from a baseline model to those of the model under scrutiny and provides
theoretical guarantees for change detection while controlling false positives.
The test features a configurable tolerance parameter that adjusts sensitivity
to behavioral changes for different use cases. We evaluate our approach using
two case studies: monitoring changes in (a) toxicity and (b) translation
performance. We find that the test is able to detect meaningful changes in
behavior distributions using just hundreds of examples.",2024-10-25,"Leo Richter, Xuanli He, Pasquale Minervini, Matt J. Kusner",http://arxiv.org/pdf/2410.19406v1,cs.LG
Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression,"In offline reinforcement learning (RL), addressing the out-of-distribution
(OOD) action issue has been a focus, but we argue that there exists an OOD
state issue that also impairs performance yet has been underexplored. Such an
issue describes the scenario when the agent encounters states out of the
offline dataset during the test phase, leading to uncontrolled behavior and
performance degradation. To this end, we propose SCAS, a simple yet effective
approach that unifies OOD state correction and OOD action suppression in
offline RL. Technically, SCAS achieves value-aware OOD state correction,
capable of correcting the agent from OOD states to high-value in-distribution
states. Theoretical and empirical results show that SCAS also exhibits the
effect of suppressing OOD actions. On standard offline RL benchmarks, SCAS
achieves excellent performance without additional hyperparameter tuning.
Moreover, benefiting from its OOD state correction feature, SCAS demonstrates
enhanced robustness against environmental perturbations.",2024-10-25,"Yixiu Mao, Qi Wang, Chen Chen, Yun Qu, Xiangyang Ji",http://arxiv.org/pdf/2410.19400v4,cs.LG
Analysis of Financial Risk Behavior Prediction Using Deep Learning and Big Data Algorithms,"As the complexity and dynamism of financial markets continue to grow,
traditional financial risk prediction methods increasingly struggle to handle
large datasets and intricate behavior patterns. This paper explores the
feasibility and effectiveness of using deep learning and big data algorithms
for financial risk behavior prediction. First, the application and advantages
of deep learning and big data algorithms in the financial field are analyzed.
Then, a deep learning-based big data risk prediction framework is designed and
experimentally validated on actual financial datasets. The experimental results
show that this method significantly improves the accuracy of financial risk
behavior prediction and provides valuable support for risk management in
financial institutions. Challenges in the application of deep learning are also
discussed, along with potential directions for future research.",2024-10-25,"Haowei Yang, Zhan Cheng, Zhaoyang Zhang, Yuanshuai Luo, Shuaishuai Huang, Ao Xiang",http://arxiv.org/pdf/2410.19394v2,cs.LG
Multi-Agent Reinforcement Learning with Selective State-Space Models,"The Transformer model has demonstrated success across a wide range of
domains, including in Multi-Agent Reinforcement Learning (MARL) where the
Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field.
However, a significant drawback of Transformer models is their quadratic
computational complexity relative to input size, making them computationally
expensive when scaling to larger inputs. This limitation restricts MAT's
scalability in environments with many agents. Recently, State-Space Models
(SSMs) have gained attention due to their computational efficiency, but their
application in MARL remains unexplored. In this work, we investigate the use of
Mamba, a recent SSM, in MARL and assess whether it can match the performance of
MAT while providing significant improvements in efficiency. We introduce a
modified version of MAT that incorporates standard and bi-directional Mamba
blocks, as well as a novel ""cross-attention"" Mamba block. Extensive testing
shows that our Multi-Agent Mamba (MAM) matches the performance of MAT across
multiple standard multi-agent environments, while offering superior scalability
to larger agent scenarios. This is significant for the MARL community, because
it indicates that SSMs could replace Transformers without compromising
performance, whilst also supporting more effective scaling to higher numbers of
agents. Our project page is available at
https://sites.google.com/view/multi-agent-mamba .",2024-10-25,"Jemma Daniel, Ruan de Kock, Louay Ben Nessir, Sasha Abramowitz, Omayma Mahjoub, Wiem Khlifi, Claude Formanek, Arnu Pretorius",http://arxiv.org/pdf/2410.19382v2,cs.LG
Unified Cross-Modal Image Synthesis with Hierarchical Mixture of Product-of-Experts,"We propose a deep mixture of multimodal hierarchical variational
auto-encoders called MMHVAE that synthesizes missing images from observed
images in different modalities. MMHVAE's design focuses on tackling four
challenges: (i) creating a complex latent representation of multimodal data to
generate high-resolution images; (ii) encouraging the variational distributions
to estimate the missing information needed for cross-modal image synthesis;
(iii) learning to fuse multimodal information in the context of missing data;
(iv) leveraging dataset-level information to handle incomplete data sets at
training time. Extensive experiments are performed on the challenging problem
of pre-operative brain multi-parametric magnetic resonance and intra-operative
ultrasound imaging.",2024-10-25,"Reuben Dorent, Nazim Haouchine, Alexandra Golby, Sarah Frisken, Tina Kapur, William Wells",http://arxiv.org/pdf/2410.19378v1,cs.LG
COMSPLIT: A Communication-Aware Split Learning Design for Heterogeneous IoT Platforms,"The significance of distributed learning and inference algorithms in Internet
of Things (IoT) network is growing since they flexibly distribute computation
load between IoT devices and the infrastructure, enhance data privacy, and
minimize latency. However, a notable challenge stems from the influence of
communication channel conditions on their performance. In this work, we
introduce COMSPLIT: a novel communication-aware design for split learning (SL)
and inference paradigm tailored to processing time series data in IoT networks.
COMSPLIT provides a versatile framework for deploying adaptable SL in IoT
networks affected by diverse channel conditions. In conjunction with the
integration of an early-exit strategy, and addressing IoT scenarios containing
devices with heterogeneous computational capabilities, COMSPLIT represents a
comprehensive design solution for communication-aware SL in IoT networks.
Numerical results show superior performance of COMSPLIT compared to vanilla SL
approaches (that assume ideal communication channel), demonstrating its ability
to offer both design simplicity and adaptability to different channel
conditions.",2024-10-25,"Vukan Ninkovic, Dejan Vukobratovic, Dragisa Miskovic, Marco Zennaro",http://arxiv.org/pdf/2410.19375v1,cs.LG
Toward Finding Strong Pareto Optimal Policies in Multi-Agent Reinforcement Learning,"In this work, we study the problem of finding Pareto optimal policies in
multi-agent reinforcement learning problems with cooperative reward structures.
We show that any algorithm where each agent only optimizes their reward is
subject to suboptimal convergence. Therefore, to achieve Pareto optimality,
agents have to act altruistically by considering the rewards of others. This
observation bridges the multi-objective optimization framework and multi-agent
reinforcement learning together. We first propose a framework for applying the
Multiple Gradient Descent algorithm (MGDA) for learning in multi-agent
settings. We further show that standard MGDA is subjected to weak Pareto
convergence, a problem that is often overlooked in other learning settings but
is prevalent in multi-agent reinforcement learning. To mitigate this issue, we
propose MGDA++, an improvement of the existing algorithm to handle the weakly
optimal convergence of MGDA properly. Theoretically, we prove that MGDA++
converges to strong Pareto optimal solutions in convex, smooth bi-objective
problems. We further demonstrate the superiority of our MGDA++ in cooperative
settings in the Gridworld benchmark. The results highlight that our proposed
method can converge efficiently and outperform the other methods in terms of
the optimality of the convergent policies. The source code is available at
\url{https://github.com/giangbang/Strong-Pareto-MARL}.",2024-10-25,"Bang Giang Le, Viet Cuong Ta",http://arxiv.org/pdf/2410.19372v1,cs.LG
Noise-Aware Differentially Private Variational Inference,"Differential privacy (DP) provides robust privacy guarantees for statistical
inference, but this can lead to unreliable results and biases in downstream
applications. While several noise-aware approaches have been proposed which
integrate DP perturbation into the inference, they are limited to specific
types of simple probabilistic models. In this work, we propose a novel method
for noise-aware approximate Bayesian inference based on stochastic gradient
variational inference which can also be applied to high-dimensional and
non-conjugate models. We also propose a more accurate evaluation method for
noise-aware posteriors. Empirically, our inference method has similar
performance to existing methods in the domain where they are applicable.
Outside this domain, we obtain accurate coverages on high-dimensional Bayesian
linear regression and well-calibrated predictive probabilities on Bayesian
logistic regression with the UCI Adult dataset.",2024-10-25,"Talal Alrawajfeh, Joonas Jälkö, Antti Honkela",http://arxiv.org/pdf/2410.19371v2,cs.LG
Notes on the Mathematical Structure of GPT LLM Architectures,"An exposition of the mathematics underpinning the neural network architecture
of a GPT-3-style LLM.",2024-10-25,Spencer Becker-Kahn,http://arxiv.org/pdf/2410.19370v1,cs.LG
BitPipe: Bidirectional Interleaved Pipeline Parallelism for Accelerating Large Models Training,"With the increasing scale of models, the need for efficient distributed
training has become increasingly urgent. Recently, many synchronous pipeline
parallelism approaches have been proposed to improve training throughput.
However, these approaches still suffer from two major issues, i.e., pipeline
bubbles caused by periodic flushing and extra communication due to the
increasing number of pipeline stages. To this end, we propose BitPipe, a
bidirectional interleaved pipeline parallelism for accelerating large models
training. Specifically, a hybrid scheme of fusing interleaved pipelines with
bidirectional pipelines is proposed to reduce the computational time of each
single micro-batch and multiply the number of devices executing simultaneously.
A V-shaped schedule with eager gradient synchronization is introduced to reduce
and overlap the communication between devices. Experiments conducted on up to
32 GPUs show that BitPipe improves the training throughput of GPT-style and
BERT-style models by 1.05x-1.28x compared to the state-of-the-art synchronous
approaches. The code of our implementation is available at
https://github.com/wuhouming/BitPipe.",2024-10-25,"Houming Wu, Ling Chen, Wenjie Yu",http://arxiv.org/pdf/2410.19367v1,cs.LG
Capsule Endoscopy Multi-classification via Gated Attention and Wavelet Transformations,"Abnormalities in the gastrointestinal tract significantly influence the
patient's health and require a timely diagnosis for effective treatment. With
such consideration, an effective automatic classification of these
abnormalities from a video capsule endoscopy (VCE) frame is crucial for
improvement in diagnostic workflows.
  The work presents the process of developing and evaluating a novel model
designed to classify gastrointestinal anomalies from a VCE video frame.
Integration of Omni Dimensional Gated Attention (OGA) mechanism and Wavelet
transformation techniques into the model's architecture allowed the model to
focus on the most critical areas in the endoscopy images, reducing noise and
irrelevant features. This is particularly advantageous in capsule endoscopy,
where images often contain a high degree of variability in texture and color.
Wavelet transformations contributed by efficiently capturing spatial and
frequency-domain information, improving feature extraction, especially for
detecting subtle features from the VCE frames. Furthermore, the features
extracted from the Stationary Wavelet Transform and Discrete Wavelet Transform
are concatenated channel-wise to capture multiscale features, which are
essential for detecting polyps, ulcerations, and bleeding. This approach
improves classification accuracy on imbalanced capsule endoscopy datasets. The
proposed model achieved 92.76% and 91.19% as training and validation accuracies
respectively. At the same time, Training and Validation losses are 0.2057 and
0.2700. The proposed model achieved a Balanced Accuracy of 94.81%, AUC of
87.49%, F1-score of 91.11%, precision of 91.17%, recall of 91.19% and
specificity of 98.44%. Additionally, the model's performance is benchmarked
against two base models, VGG16 and ResNet50, demonstrating its enhanced ability
to identify and classify a range of gastrointestinal abnormalities accurately.",2024-10-25,"Lakshmi Srinivas Panchananam, Praveen Kumar Chandaliya, Kishor Upla, Kiran Raja",http://arxiv.org/pdf/2410.19363v2,cs.LG
EnergyPlus Room Simulator,"Research towards energy optimization in buildings heavily relies on
building-related data such as measured indoor climate factors. While data
collection is a labor- and cost-intensive task, simulations are a cheap
alternative to generate datasets of arbitrary sizes, particularly useful for
data-intensive deep learning methods. In this paper, we present the tool
EnergyPlus Room Simulator, which enables the simulation of indoor climate in a
specific room of a building using the simulation software EnergyPlus. It allows
to alter room models and simulate various factors such as temperature,
humidity, and CO2 concentration. In contrast to manually working with
EnergyPlus, this tool enhances the simulation process by offering a convenient
interface, including a user-friendly graphical user interface (GUI) as well as
a REST API. The tool is intended to support scientific, building-related tasks
such as occupancy detection on a room level by facilitating fast access to
simulation data that may, for instance, be used for pre-training machine
learning models.",2024-10-25,"Manuel Weber, Philipp Bogdain, Sophia Viktoria Weißenberger, Diana Marjanovic, Katharina Sammet, Jan Vellmer, Farzan Banihashemi, Peter Mandl",http://arxiv.org/pdf/2410.19888v1,cs.LG
FeBiM: Efficient and Compact Bayesian Inference Engine Empowered with Ferroelectric In-Memory Computing,"In scenarios with limited training data or where explainability is crucial,
conventional neural network-based machine learning models often face
challenges. In contrast, Bayesian inference-based algorithms excel in providing
interpretable predictions and reliable uncertainty estimation in these
scenarios. While many state-of-the-art in-memory computing (IMC) architectures
leverage emerging non-volatile memory (NVM) technologies to offer unparalleled
computing capacity and energy efficiency for neural network workloads, their
application in Bayesian inference is limited. This is because the core
operations in Bayesian inference differ significantly from the
multiplication-accumulation (MAC) operations common in neural networks,
rendering them generally unsuitable for direct implementation in most existing
IMC designs. In this paper, we propose FeBiM, an efficient and compact Bayesian
inference engine powered by multi-bit ferroelectric field-effect transistor
(FeFET)-based IMC. FeBiM effectively encodes the trained probabilities of a
Bayesian inference model within a compact FeFET-based crossbar. It maps
quantized logarithmic probabilities to discrete FeFET states. As a result, the
accumulated outputs of the crossbar naturally represent the posterior
probabilities, i.e., the Bayesian inference model's output given a set of
observations. This approach enables efficient in-memory Bayesian inference
without the need for additional calculation circuitry. As the first FeFET-based
in-memory Bayesian inference engine, FeBiM achieves an impressive storage
density of 26.32 Mb/mm$^{2}$ and a computing efficiency of 581.40 TOPS/W in a
representative Bayesian classification task. These results demonstrate
10.7$\times$/43.4$\times$ improvement in compactness/efficiency compared to the
state-of-the-art hardware implementation of Bayesian inference.",2024-10-25,"Chao Li, Zhicheng Xu, Bo Wen, Ruibin Mao, Can Li, Thomas Kämpfe, Kai Ni, Xunzhao Yin",http://arxiv.org/pdf/2410.19356v1,cs.LG
Interpreting Neural Networks through Mahalanobis Distance,"This paper introduces a theoretical framework that connects neural network
linear layers with the Mahalanobis distance, offering a new perspective on
neural network interpretability. While previous studies have explored
activation functions primarily for performance optimization, our work
interprets these functions through statistical distance measures, a less
explored area in neural network research. By establishing this connection, we
provide a foundation for developing more interpretable neural network models,
which is crucial for applications requiring transparency. Although this work is
theoretical and does not include empirical data, the proposed distance-based
interpretation has the potential to enhance model robustness, improve
generalization, and provide more intuitive explanations of neural network
decisions.",2024-10-25,Alan Oursland,http://arxiv.org/pdf/2410.19352v1,cs.LG
High Resolution Seismic Waveform Generation using Denoising Diffusion,"Accurate prediction and synthesis of seismic waveforms are crucial for
seismic hazard assessment and earthquake-resistant infrastructure design.
Existing prediction methods, such as Ground Motion Models and physics-based
simulations, often fail to capture the full complexity of seismic wavefields,
particularly at higher frequencies. This study introduces a novel, efficient,
and scalable generative model for high-frequency seismic waveform generation.
Our approach leverages a spectrogram representation of seismic waveform data,
which is reduced to a lower-dimensional submanifold via an autoencoder. A
state-of-the-art diffusion model is trained to generate this latent
representation, conditioned on key input parameters: earthquake magnitude,
recording distance, site conditions, and faulting type. The model generates
waveforms with frequency content up to 50 Hz. Any scalar ground motion
statistic, such as peak ground motion amplitudes and spectral accelerations,
can be readily derived from the synthesized waveforms. We validate our model
using commonly used seismological metrics, and performance metrics from image
generation studies. Our results demonstrate that our openly available model can
generate distributions of realistic high-frequency seismic waveforms across a
wide range of input parameters, even in data-sparse regions. For the scalar
ground motion statistics commonly used in seismic hazard and earthquake
engineering studies, we show that the model accurately reproduces both the
median trends of the real data and its variability. To evaluate and compare the
growing number of this and similar 'Generative Waveform Models' (GWM), we argue
that they should generally be openly available and that they should be included
in community efforts for ground motion model evaluations.",2024-10-25,"Andreas Bergmeister, Kadek Hendrawan Palgunadi, Andrea Bosisio, Laura Ermert, Maria Koroni, Nathanaël Perraudin, Simon Dirmeier, Men-Andrin Meier",http://arxiv.org/pdf/2410.19343v1,cs.LG
Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion,"Latent diffusion models have become the popular choice for scaling up
diffusion models for high resolution image synthesis. Compared to pixel-space
models that are trained end-to-end, latent models are perceived to be more
efficient and to produce higher image quality at high resolution. Here we
challenge these notions, and show that pixel-space models can be very
competitive to latent models both in quality and efficiency, achieving 1.5 FID
on ImageNet512 and new SOTA results on ImageNet128, ImageNet256 and
Kinetics600.
  We present a simple recipe for scaling end-to-end pixel-space diffusion
models to high resolutions. 1: Use the sigmoid loss-weighting (Kingma & Gao,
2023) with our prescribed hyper-parameters. 2: Use our simplified
memory-efficient architecture with fewer skip-connections. 3: Scale the model
to favor processing the image at a high resolution with fewer parameters,
rather than using more parameters at a lower resolution. Combining these with
guidance intervals, we obtain a family of pixel-space diffusion models we call
Simpler Diffusion (SiD2).",2024-10-25,"Emiel Hoogeboom, Thomas Mensink, Jonathan Heek, Kay Lamerigts, Ruiqi Gao, Tim Salimans",http://arxiv.org/pdf/2410.19324v2,cs.LG
Double Difference Earthquake Location with Graph Neural Networks,"Double difference earthquake relocation is an essential component of many
earthquake catalog development workflows. This technique produces
high-resolution relative relocations between events by minimizing differential
measurements of the arrival times of waves from nearby sources, which
highlights the resolution of faults and improves interpretation of seismic
activity. The inverse problem is typically solved iteratively using
conjugate-gradient minimization, however the cost scales significantly with the
total number of sources and stations considered. Here we propose a Graph Neural
Network (GNN) based earthquake double-difference relocation framework, Graph
Double Difference (GraphDD), that is trained to minimize the double-difference
residuals of a catalog to locate earthquakes. Through batching and sampling the
method can scale to arbitrarily large catalogs. Our architecture uses one graph
to represent the stations, a second graph to represent the sources, and creates
the Cartesian product graph between the two graphs to capture the relationships
between the stations and sources (e.g., the residuals and travel time partial
derivatives). This key feature allows a natural architecture that can be used
to minimize the double-difference residuals. We implement our model on several
distinct test cases including seismicity from northern California, Turkiye, and
northern Chile, which have highly variable data quality, and station and source
distributions. We obtain high resolution relocations in these tests, and our
model shows adaptability to variable types of loss functions and location
objectives, including learning station corrections and mapping into the
reference frame of a different catalog. Our results suggest that a GNN approach
to double-difference relocation is a promising direction for scaling to very
large catalogs and gaining new insights into the relocation problem.",2024-10-25,"Ian W. McBrearty, Gregory C. Beroza",http://arxiv.org/pdf/2410.19323v1,cs.LG
Free-Rider and Conflict Aware Collaboration Formation for Cross-Silo Federated Learning,"Federated learning (FL) is a machine learning paradigm that allows multiple
FL participants (FL-PTs) to collaborate on training models without sharing
private data. Due to data heterogeneity, negative transfer may occur in the FL
training process. This necessitates FL-PT selection based on their data
complementarity. In cross-silo FL, organizations that engage in business
activities are key sources of FL-PTs. The resulting FL ecosystem has two
features: (i) self-interest, and (ii) competition among FL-PTs. This requires
the desirable FL-PT selection strategy to simultaneously mitigate the problems
of free riders and conflicts of interest among competitors. To this end, we
propose an optimal FL collaboration formation strategy -- FedEgoists -- which
ensures that: (1) a FL-PT can benefit from FL if and only if it benefits the FL
ecosystem, and (2) a FL-PT will not contribute to its competitors or their
supporters. It provides an efficient clustering solution to group FL-PTs into
coalitions, ensuring that within each coalition, FL-PTs share the same
interest. We theoretically prove that the FL-PT coalitions formed are optimal
since no coalitions can collaborate together to improve the utility of any of
their members. Extensive experiments on widely adopted benchmark datasets
demonstrate the effectiveness of FedEgoists compared to nine state-of-the-art
baseline methods, and its ability to establish efficient collaborative networks
in cross-silos FL with FL-PTs that engage in business activities.",2024-10-25,"Mengmeng Chen, Xiaohu Wu, Xiaoli Tang, Tiantian He, Yew-Soon Ong, Qiqi Liu, Qicheng Lao, Han Yu",http://arxiv.org/pdf/2410.19321v3,cs.LG
Fully First-Order Methods for Decentralized Bilevel Optimization,"This paper focuses on decentralized stochastic bilevel optimization (DSBO)
where agents only communicate with their neighbors. We propose Decentralized
Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a
novel algorithm that only requires first-order oracles that are much cheaper
than second-order oracles widely adopted in existing works. We further provide
a finite-time convergence analysis showing that for $n$ agents collaboratively
solving the DSBO problem, the sample complexity of finding an
$\epsilon$-stationary point in our algorithm is
$\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known
results of the single-agent counterpart with linear speedup. The numerical
experiments demonstrate both the communication and training efficiency of our
algorithm.",2024-10-25,"Xiaoyu Wang, Xuxing Chen, Shiqian Ma, Tong Zhang",http://arxiv.org/pdf/2410.19319v2,cs.LG
Two are better than one: Context window extension with multi-grained self-injection,"The limited context window of contemporary large language models (LLMs)
remains a huge barrier to their broader application across various domains.
While continual pre-training on long-context data is a straightforward and
effective solution, it incurs substantial costs in terms of data acquisition
and computational resources. To alleviate this issue, we propose SharedLLM, a
novel approach grounded in the design philosophy of multi-grained context
compression and query-aware information retrieval. SharedLLM is composed of two
short-context LLMs such as LLaMA-2, termed upper model and lower model. The
lower model functions as a compressor while the upper model acts as a decoder.
The upper model receives compressed, multi-grained context information from the
lower model and performs context-aware modeling on the running text.
Information transfer between the compressor and decoder occurs only at the
lowest layers to refrain from long forward paths in the lower model and
redundant cross-attention modules in the upper model. Based on this
architecture, we introduce a specialized tree-style data structure to
efficiently encode, store and retrieve multi-grained contextual information for
text chunks. This structure, combined with a search algorithm, enables rapid
encoding and retrieval of relevant information from various levels of the tree
based on the input query. This entire process, wherein the sender and receiver
are derived from the same LLM layer, is referred to as self-injection.",2024-10-25,"Wei Han, Pan Zhou, Soujanya Poria, Shuicheng Yan",http://arxiv.org/pdf/2410.19318v1,cs.LG
Brain-like variational inference,"Inference in both brains and machines can be formalized by optimizing a
shared objective: maximizing the evidence lower bound (ELBO) in machine
learning, or minimizing variational free energy (F) in neuroscience (ELBO =
-F). While this equivalence suggests a unifying framework, it leaves open how
inference is implemented in neural systems. Here, we show that online natural
gradient descent on F, under Poisson assumptions, leads to a recurrent spiking
neural network that performs variational inference via membrane potential
dynamics. The resulting model -- the iterative Poisson variational autoencoder
(iP-VAE) -- replaces the encoder network with local updates derived from
natural gradient descent on F. Theoretically, iP-VAE yields a number of
desirable features such as emergent normalization via lateral competition, and
hardware-efficient integer spike count representations. Empirically, iP-VAE
outperforms both standard VAEs and Gaussian-based predictive coding models in
sparsity, reconstruction, and biological plausibility. iP-VAE also exhibits
strong generalization to out-of-distribution inputs, exceeding hybrid
iterative-amortized VAEs. These results demonstrate how deriving inference
algorithms from first principles can yield concrete architectures that are
simultaneously biologically plausible and empirically effective.",2024-10-25,"Hadi Vafaii, Dekel Galor, Jacob L. Yates",http://arxiv.org/pdf/2410.19315v2,cs.LG
COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training,"FP8 training has emerged as a promising method for improving training
efficiency. Existing frameworks accelerate training by applying FP8 computation
to linear layers while leaving optimizer states and activations in higher
precision, which fails to fully optimize memory usage. This paper introduces
COAT (Compressing Optimizer States and Activations for FP8 Training), a novel
FP8 training framework designed to significantly reduce memory footprint when
training large models. COAT addresses current limitations through two key
innovations: (1) Dynamic Range Expansion, which aligns optimizer state
distributions more closely with the FP8 representation range, thereby reducing
quantization error, and (2) Mixed-Granularity Activation Quantization, which
optimizes activation memory using a combination of per-tensor and per-group
quantization strategies. Experiments demonstrate that COAT effectively reduces
end-to-end training memory footprint by 1.54x compared to BF16 while achieving
nearly lossless performance across various tasks, such as Large Language Model
pretraining and fine-tuning and Vision Language Model training. COAT also
achieves a 1.43x end-to-end training speedup compared to BF16, performing on
par with or surpassing TransformerEngine's speedup. COAT enables efficient
full-parameter training of large models on fewer GPUs, and facilitates doubling
the batch size in distributed training settings, providing a practical solution
for scaling large-scale model training. The code is available at
https://github.com/NVlabs/COAT.",2024-10-25,"Haocheng Xi, Han Cai, Ligeng Zhu, Yao Lu, Kurt Keutzer, Jianfei Chen, Song Han",http://arxiv.org/pdf/2410.19313v3,cs.LG
Flow Generator Matching,"In the realm of Artificial Intelligence Generated Content (AIGC),
flow-matching models have emerged as a powerhouse, achieving success due to
their robust theoretical underpinnings and solid ability for large-scale
generative modeling. These models have demonstrated state-of-the-art
performance, but their brilliance comes at a cost. The process of sampling from
these models is notoriously demanding on computational resources, as it
necessitates the use of multi-step numerical ordinary differential equations
(ODEs). Against this backdrop, this paper presents a novel solution with
theoretical guarantees in the form of Flow Generator Matching (FGM), an
innovative approach designed to accelerate the sampling of flow-matching models
into a one-step generation, while maintaining the original performance. On the
CIFAR10 unconditional generation benchmark, our one-step FGM model achieves a
new record Fr\'echet Inception Distance (FID) score of 3.08 among few-step
flow-matching-based models, outperforming original 50-step flow-matching
models. Furthermore, we use the FGM to distill the Stable Diffusion 3, a
leading text-to-image flow-matching model based on the MM-DiT architecture. The
resulting MM-DiT-FGM one-step text-to-image model demonstrates outstanding
industry-level performance. When evaluated on the GenEval benchmark, MM-DiT-FGM
has delivered remarkable generating qualities, rivaling other multi-step models
in light of the efficiency of a single generation step.",2024-10-25,"Zemin Huang, Zhengyang Geng, Weijian Luo, Guo-jun Qi",http://arxiv.org/pdf/2410.19310v1,cs.LG
TBBC: Predict True Bacteraemia in Blood Cultures via Deep Learning,"Bacteraemia, a bloodstream infection with high morbidity and mortality rates,
poses significant diagnostic challenges. Accurate diagnosis through blood
cultures is resource-intensive. Developing a machine learning model to predict
blood culture outcomes in emergency departments offers potential for improved
diagnosis, reduced healthcare costs, and mitigated antibiotic use.This thesis
aims to identify optimal machine learning techniques for predicting bacteraemia
and develop a predictive model using data from St. Antonius Hospital's
emergency department. Based on current literature, CatBoost and Random Forest
were selected as the most promising techniques. Model optimization using Optuna
prioritized sensitivity.The final Random Forest model achieved an ROC AUC of
0.78 and demonstrated 0.92 sensitivity on the test set. Notably, it accurately
identified 36.02% of patients at low risk of bacteraemia, with only 0.85% false
negatives.Implementation of this model in St. Antonius Hospital's emergency
department could reduce blood cultures, healthcare costs, and antibiotic
treatments. Future studies should focus on external validation, exploring
advanced techniques, and addressing potential confounders to ensure model
generalizability.",2024-10-25,Kira Sam,http://arxiv.org/pdf/2410.19887v1,cs.LG
TEARS: Textual Representations for Scrutable Recommendations,"Traditional recommender systems rely on high-dimensional (latent) embeddings
for modeling user-item interactions, often resulting in opaque representations
that lack interpretability. Moreover, these systems offer limited control to
users over their recommendations. Inspired by recent work, we introduce TExtuAl
Representations for Scrutable recommendations (TEARS) to address these
challenges. Instead of representing a user's interests through a latent
embedding, TEARS encodes them in natural text, providing transparency and
allowing users to edit them. To do so, TEARS uses a modern LLM to generate user
summaries based on user preferences. We find the summaries capture user
preferences uniquely. Using these summaries, we take a hybrid approach where we
use an optimal transport procedure to align the summaries' representation with
the learned representation of a standard VAE for collaborative filtering. We
find this approach can surpass the performance of three popular VAE models
while providing user-controllable recommendations. We also analyze the
controllability of TEARS through three simulated user tasks to evaluate the
effectiveness of a user editing its summary.",2024-10-25,"Emiliano Penaloza, Olivier Gouvert, Haolun Wu, Laurent Charlin",http://arxiv.org/pdf/2410.19302v2,cs.LG
Golden Ratio-Based Sufficient Dimension Reduction,"Many machine learning applications deal with high dimensional data. To make
computations feasible and learning more efficient, it is often desirable to
reduce the dimensionality of the input variables by finding linear combinations
of the predictors that can retain as much original information as possible in
the relationship between the response and the original predictors. We propose a
neural network based sufficient dimension reduction method that not only
identifies the structural dimension effectively, but also estimates the central
space well. It takes advantages of approximation capabilities of neural
networks for functions in Barron classes and leads to reduced computation cost
compared to other dimension reduction methods in the literature. Additionally,
the framework can be extended to fit practical dimension reduction, making the
methodology more applicable in practical settings.",2024-10-25,"Wenjing Yang, Yuhong Yang",http://arxiv.org/pdf/2410.19300v2,cs.LG
A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images,"Recently, deep learning in stock prediction has become an important branch.
Image-based methods show potential by capturing complex visual patterns and
spatial correlations, offering advantages in interpretability over time series
models. However, image-based approaches are more prone to overfitting,
hindering robust predictive performance. To improve accuracy, this paper
proposes a novel method, named Sequence-based Multi-scale Fusion Regression
Convolutional Neural Network (SMSFR-CNN), for predicting stock price movements
in the China A-share market.
  By utilizing CNN to learn sequential features and combining them with image
features, we improve the accuracy of stock trend prediction on the A-share
market stock dataset. This approach reduces the search space for image
features, stabilizes, and accelerates the training process. Extensive
comparative experiments on 4,454 A-share stocks show that the model achieves a
61.15% positive predictive value and a 63.37% negative predictive value for the
next 5 days, resulting in a total profit of 165.09%.",2024-10-25,"Zhiyuan Pei, Jianqi Yan, Jin Yan, Bailing Yang, Ziyuan Li, Lin Zhang, Xin Liu, Yang Zhang",http://arxiv.org/pdf/2410.19291v2,cs.LG
A Flow-based Truncated Denoising Diffusion Model for Super-resolution Magnetic Resonance Spectroscopic Imaging,"Magnetic Resonance Spectroscopic Imaging (MRSI) is a non-invasive imaging
technique for studying metabolism and has become a crucial tool for
understanding neurological diseases, cancers and diabetes. High spatial
resolution MRSI is needed to characterize lesions, but in practice MRSI is
acquired at low resolution due to time and sensitivity restrictions caused by
the low metabolite concentrations. Therefore, there is an imperative need for a
post-processing approach to generate high-resolution MRSI from low-resolution
data that can be acquired fast and with high sensitivity. Deep learning-based
super-resolution methods provided promising results for improving the spatial
resolution of MRSI, but they still have limited capability to generate accurate
and high-quality images. Recently, diffusion models have demonstrated superior
learning capability than other generative models in various tasks, but sampling
from diffusion models requires iterating through a large number of diffusion
steps, which is time-consuming. This work introduces a Flow-based Truncated
Denoising Diffusion Model (FTDDM) for super-resolution MRSI, which shortens the
diffusion process by truncating the diffusion chain, and the truncated steps
are estimated using a normalizing flow-based network. The network is
conditioned on upscaling factors to enable multi-scale super-resolution. To
train and evaluate the deep learning models, we developed a 1H-MRSI dataset
acquired from 25 high-grade glioma patients. We demonstrate that FTDDM
outperforms existing generative models while speeding up the sampling process
by over 9-fold compared to the baseline diffusion model. Neuroradiologists'
evaluations confirmed the clinical advantages of our method, which also
supports uncertainty estimation and sharpness adjustment, extending its
potential clinical applications.",2024-10-25,"Siyuan Dong, Zhuotong Cai, Gilbert Hangel, Wolfgang Bogner, Georg Widhalm, Yaqing Huang, Qinghao Liang, Chenyu You, Chathura Kumaragamage, Robert K. Fulbright, Amit Mahajan, Amin Karbasi, John A. Onofrey, Robin A. de Graaf, James S. Duncan",http://arxiv.org/pdf/2410.19288v1,cs.LG
Applying sparse autoencoders to unlearn knowledge in language models,"We investigate whether sparse autoencoders (SAEs) can be used to remove
knowledge from language models. We use the biology subset of the Weapons of
Mass Destruction Proxy dataset and test on the gemma-2b-it and gemma-2-2b-it
language models. We demonstrate that individual interpretable biology-related
SAE features can be used to unlearn a subset of WMDP-Bio questions with minimal
side-effects in domains other than biology. Our results suggest that negative
scaling of feature activations is necessary and that zero ablating features is
ineffective. We find that intervening using multiple SAE features
simultaneously can unlearn multiple different topics, but with similar or
larger unwanted side-effects than the existing Representation Misdirection for
Unlearning technique. Current SAE quality or intervention techniques would need
to improve to make SAE-based unlearning comparable to the existing fine-tuning
based techniques.",2024-10-25,"Eoin Farrell, Yeu-Tong Lau, Arthur Conmy",http://arxiv.org/pdf/2410.19278v2,cs.LG
Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management,"Large Language Models (LLMs) have achieved remarkable success across various
domains, yet deploying them on mobile devices remains an arduous challenge due
to their extensive computational and memory demands. While lightweight LLMs
have been developed to fit mobile environments, they suffer from degraded model
accuracy. In contrast, sparsity-based techniques minimize DRAM usage by
selectively transferring only relevant neurons to DRAM while retaining the full
model in external storage, such as flash. However, such approaches are
critically limited by numerous I/O operations, particularly on smartphones with
severe IOPS constraints.
  In this paper, we propose Ripple, a novel approach that accelerates LLM
inference on smartphones by optimizing neuron placement in flash memory. Ripple
leverages the concept of Neuron Co-Activation, where neurons frequently
activated together are linked to facilitate continuous read access and optimize
data transfer efficiency. Our approach incorporates a two-stage solution: an
offline stage that reorganizes neuron placement based on co-activation
patterns, and an online stage that employs tailored data access and caching
strategies to align well with hardware characteristics. Evaluations conducted
on a variety of smartphones and LLMs demonstrate that Ripple achieves up to
5.93x improvements in I/O latency compared to the state-of-the-art. As the
first solution to optimize storage placement under sparsity, Ripple explores a
new optimization space at the intersection of sparsity-driven algorithm and
storage-level system co-design in LLM inference.",2024-10-25,"Tuowei Wang, Ruwen Fan, Minxing Huang, Zixu Hao, Kun Li, Ting Cao, Youyou Lu, Yaoxue Zhang, Ju Ren",http://arxiv.org/pdf/2410.19274v2,cs.LG
Coordinated Reply Attacks in Influence Operations: Characterization and Detection,"Coordinated reply attacks are a tactic observed in online influence
operations and other coordinated campaigns to support or harass targeted
individuals, or influence them or their followers. Despite its potential to
influence the public, past studies have yet to analyze or provide a methodology
to detect this tactic. In this study, we characterize coordinated reply attacks
in the context of influence operations on Twitter. Our analysis reveals that
the primary targets of these attacks are influential people such as
journalists, news media, state officials, and politicians.
  We propose two supervised machine-learning models, one to classify tweets to
determine whether they are targeted by a reply attack, and one to classify
accounts that reply to a targeted tweet to determine whether they are part of a
coordinated attack. The classifiers achieve AUC scores of 0.88 and 0.97,
respectively. These results indicate that accounts involved in reply attacks
can be detected, and the targeted accounts themselves can serve as sensors for
influence operation detection.",2024-10-25,"Manita Pote, Tuğrulcan Elmas, Alessandro Flammini, Filippo Menczer",http://arxiv.org/pdf/2410.19272v1,cs.LG
A Survey of Deep Graph Learning under Distribution Shifts: from Graph Out-of-Distribution Generalization to Adaptation,"Distribution shifts on graphs -- the discrepancies in data distribution
between training and employing a graph machine learning model -- are ubiquitous
and often unavoidable in real-world scenarios. These shifts may severely
deteriorate model performance, posing significant challenges for reliable graph
machine learning. Consequently, there has been a surge in research on graph
machine learning under distribution shifts, aiming to train models to achieve
satisfactory performance on out-of-distribution (OOD) test data. In our survey,
we provide an up-to-date and forward-looking review of deep graph learning
under distribution shifts. Specifically, we cover three primary scenarios:
graph OOD generalization, training-time graph OOD adaptation, and test-time
graph OOD adaptation. We begin by formally formulating the problems and
discussing various types of distribution shifts that can affect graph learning,
such as covariate shifts and concept shifts. To provide a better understanding
of the literature, we introduce a systematic taxonomy that classifies existing
methods into model-centric and data-centric approaches, investigating the
techniques used in each category. We also summarize commonly used datasets in
this research area to facilitate further investigation. Finally, we point out
promising research directions and the corresponding challenges to encourage
further study in this vital domain. We also provide a continuously updated
reading list at https://github.com/kaize0409/Awesome-Graph-OOD.",2024-10-25,"Kexin Zhang, Shuhan Liu, Song Wang, Weili Shi, Chen Chen, Pan Li, Sheng Li, Jundong Li, Kaize Ding",http://arxiv.org/pdf/2410.19265v2,cs.LG
Spatioformer: A Geo-encoded Transformer for Large-Scale Plant Species Richness Prediction,"Earth observation data have shown promise in predicting species richness of
vascular plants ($\alpha$-diversity), but extending this approach to large
spatial scales is challenging because geographically distant regions may
exhibit different compositions of plant species ($\beta$-diversity), resulting
in a location-dependent relationship between richness and spectral
measurements. In order to handle such geolocation dependency, we propose
\textit{Spatioformer}, where a novel geolocation encoder is coupled with the
transformer model to encode geolocation context into remote sensing imagery.
The Spatioformer model compares favourably to state-of-the-art models in
richness predictions on a large-scale ground-truth richness dataset (HAVPlot)
that consists of 68,170 in-situ richness samples covering diverse landscapes
across Australia. The results demonstrate that geolocational information is
advantageous in predicting species richness from satellite observations over
large spatial scales. With Spatioformer, plant species richness maps over
Australia are compiled from Landsat archive for the years from 2015 to 2023.
The richness maps produced in this study reveal the spatiotemporal dynamics of
plant species richness in Australia, providing supporting evidence to inform
effective planning and policy development for plant diversity conservation.
Regions of high richness prediction uncertainties are identified, highlighting
the need for future in-situ surveys to be conducted in these areas to enhance
the prediction accuracy.",2024-10-25,"Yiqing Guo, Karel Mokany, Shaun R. Levick, Jinyan Yang, Peyman Moghadam",http://arxiv.org/pdf/2410.19256v3,cs.LG
CHESTNUT: A QoS Dataset for Mobile Edge Environments,"Quality of Service (QoS) is an important metric to measure the performance of
network services. Nowadays, it is widely used in mobile edge environments to
evaluate the quality of service when mobile devices request services from edge
servers. QoS usually involves multiple dimensions, such as bandwidth, latency,
jitter, and data packet loss rate. However, most existing QoS datasets, such as
the common WS-Dream dataset, focus mainly on static QoS metrics of network
services and ignore dynamic attributes such as time and geographic location.
This means they should have detailed the mobile device's location at the time
of the service request or the chronological order in which the request was
made. However, these dynamic attributes are crucial for understanding and
predicting the actual performance of network services, as QoS performance
typically fluctuates with time and geographic location. To this end, we propose
a novel dataset that accurately records temporal and geographic location
information on quality of service during the collection process, aiming to
provide more accurate and reliable data to support future QoS prediction in
mobile edge environments.",2024-10-25,"Guobing Zou, Fei Zhao, Shengxiang Hu",http://arxiv.org/pdf/2410.19248v1,cs.LG
Non-rigid Relative Placement through 3D Dense Diffusion,"The task of ""relative placement"" is to predict the placement of one object in
relation to another, e.g. placing a mug onto a mug rack. Through explicit
object-centric geometric reasoning, recent methods for relative placement have
made tremendous progress towards data-efficient learning for robot manipulation
while generalizing to unseen task variations. However, they have yet to
represent deformable transformations, despite the ubiquity of non-rigid bodies
in real world settings. As a first step towards bridging this gap, we propose
``cross-displacement"" - an extension of the principles of relative placement to
geometric relationships between deformable objects - and present a novel
vision-based method to learn cross-displacement through dense diffusion. To
this end, we demonstrate our method's ability to generalize to unseen object
instances, out-of-distribution scene configurations, and multimodal goals on
multiple highly deformable tasks (both in simulation and in the real world)
beyond the scope of prior works. Supplementary information and videos can be
found at https://sites.google.com/view/tax3d-corl-2024 .",2024-10-25,"Eric Cai, Octavian Donca, Ben Eisner, David Held",http://arxiv.org/pdf/2410.19247v2,cs.LG
Enhancing Exchange Rate Forecasting with Explainable Deep Learning Models,"Accurate exchange rate prediction is fundamental to financial stability and
international trade, positioning it as a critical focus in economic and
financial research. Traditional forecasting models often falter when addressing
the inherent complexities and non-linearities of exchange rate data. This study
explores the application of advanced deep learning models, including LSTM, CNN,
and transformer-based architectures, to enhance the predictive accuracy of the
RMB/USD exchange rate. Utilizing 40 features across 6 categories, the analysis
identifies TSMixer as the most effective model for this task. A rigorous
feature selection process emphasizes the inclusion of key economic indicators,
such as China-U.S. trade volumes and exchange rates of other major currencies
like the euro-RMB and yen-dollar pairs. The integration of grad-CAM
visualization techniques further enhances model interpretability, allowing for
clearer identification of the most influential features and bolstering the
credibility of the predictions. These findings underscore the pivotal role of
fundamental economic data in exchange rate forecasting and highlight the
substantial potential of machine learning models to deliver more accurate and
reliable predictions, thereby serving as a valuable tool for financial analysis
and decision-making.",2024-10-25,"Shuchen Meng, Andi Chen, Chihang Wang, Mengyao Zheng, Fangyu Wu, Xupeng Chen, Haowei Ni, Panfeng Li",http://arxiv.org/pdf/2410.19241v2,cs.LG
SHAP zero Explains Biological Sequence Models with Near-zero Marginal Cost for Future Queries,"The growing adoption of machine learning models for biological sequences has
intensified the need for interpretable predictions, with Shapley values
emerging as a theoretically grounded standard for model explanation. While
effective for local explanations of individual input sequences, scaling
Shapley-based interpretability to extract global biological insights requires
evaluating thousands of sequences--incurring exponential computational cost per
query. We introduce SHAP zero, a novel algorithm that amortizes the cost of
Shapley value computation across large-scale biological datasets. After a
one-time model sketching step, SHAP zero enables near-zero marginal cost for
future queries by uncovering an underexplored connection between Shapley
values, high-order feature interactions, and the sparse Fourier transform of
the model. Applied to models of guide RNA efficacy, DNA repair outcomes, and
protein fitness, SHAP zero explains predictions orders of magnitude faster than
existing methods, recovering rich combinatorial interactions previously
inaccessible at scale. This work opens the door to principled, efficient, and
scalable interpretability for black-box sequence models in biology.",2024-10-25,"Darin Tsui, Aryan Musharaf, Yigit Efe Erginbas, Justin Singh Kang, Amirali Aghazadeh",http://arxiv.org/pdf/2410.19236v4,cs.LG
Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors,"The advent of large language models (LLMs) has revolutionized the field of
text generation, producing outputs that closely mimic human-like writing.
Although academic and industrial institutions have developed detectors to
prevent the malicious usage of LLM-generated texts, other research has doubt
about the robustness of these systems. To stress test these detectors, we
introduce a proxy-attack strategy that effortlessly compromises LLMs, causing
them to produce outputs that align with human-written text and mislead
detection systems. Our method attacks the source model by leveraging a
reinforcement learning (RL) fine-tuned humanized small language model (SLM) in
the decoding phase. Through an in-depth analysis, we demonstrate that our
attack strategy is capable of generating responses that are indistinguishable
to detectors, preventing them from differentiating between machine-generated
and human-written text. We conduct systematic evaluations on extensive datasets
using proxy-attacked open-source models, including Llama2-13B, Llama3-70B, and
Mixtral-8*7B in both white- and black-box settings. Our findings show that the
proxy-attack strategy effectively deceives the leading detectors, resulting in
an average AUROC drop of 70.4% across multiple datasets, with a maximum drop of
90.3% on a single dataset. Furthermore, in cross-discipline scenarios, our
strategy also bypasses these detectors, leading to a significant relative
decrease of up to 90.9%, while in cross-language scenario, the drop reaches
91.3%. Despite our proxy-attack strategy successfully bypassing the detectors
with such significant relative drops, we find that the generation quality of
the attacked models remains preserved, even within a modest utility budget,
when compared to the text produced by the original, unattacked source model.",2024-10-25,"Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng",http://arxiv.org/pdf/2410.19230v2,cs.LG
Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis,"High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ""kernel"") and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To train the hierarchical MoE
stably, we further propose a two-stage training method to avoid expert
polarization. Extensive experiments verify the effectiveness of the proposed
hierarchical MoE. We publicized our codes at
https://github.com/weikai-li/HierarchicalMoE.",2024-10-25,"Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun",http://arxiv.org/pdf/2410.19225v4,cs.LG
Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision,"In recent years, natural language processing (NLP) models have demonstrated
remarkable capabilities in various domains beyond traditional text generation.
In this work, we introduce PeptideGPT, a protein language model tailored to
generate protein sequences with distinct properties: hemolytic activity,
solubility, and non-fouling characteristics. To facilitate a rigorous
evaluation of these generated sequences, we established a comprehensive
evaluation pipeline consisting of ideas from bioinformatics to retain valid
proteins with ordered structures. First, we rank the generated sequences based
on their perplexity scores, then we filter out those lying outside the
permissible convex hull of proteins. Finally, we predict the structure using
ESMFold and select the proteins with pLDDT values greater than 70 to ensure
ordered structure. The properties of generated sequences are evaluated using
task-specific classifiers - PeptideBERT and HAPPENN. We achieved an accuracy of
76.26% in hemolytic, 72.46% in non-hemolytic, 78.84% in non-fouling, and 68.06%
in solubility protein generation. Our experimental results demonstrate the
effectiveness of PeptideGPT in de novo protein design and underscore the
potential of leveraging NLP-based approaches for paving the way for future
innovations and breakthroughs in synthetic biology and bioinformatics. Codes,
models, and data used in this study are freely available at:
https://github.com/aayush-shah14/PeptideGPT.",2024-10-25,"Aayush Shah, Chakradhar Guntuboina, Amir Barati Farimani",http://arxiv.org/pdf/2410.19222v1,cs.LG
Can Stories Help LLMs Reason? Curating Information Space Through Narrative,"Narratives are widely recognized as a powerful tool for structuring
information and facilitating comprehension of complex ideas in various domains
such as science communication. This paper investigates whether incorporating
narrative elements can assist Large Language Models (LLMs) in solving complex
problems more effectively. We propose a novel approach, Story of Thought (SoT),
integrating narrative structures into prompting techniques for problem-solving.
This approach involves constructing narratives around problem statements and
creating a framework to identify and organize relevant information. Our
experiments show that using various LLMs with SoT consistently surpasses using
them with other techniques on physics, chemistry, math, and biology questions
in both the GPQA and JEEBench datasets. The narrative-based information
curation process in SoT enhances problem comprehension by contextualizing
critical in-domain information and highlighting causal relationships within the
problem space.",2024-10-25,"Vahid Sadiri Javadi, Johanne R. Trippas, Yash Kumar Lal, Lucie Flek",http://arxiv.org/pdf/2410.19221v1,cs.LG
No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models,"Generative models have shown impressive capabilities in synthesizing
high-quality outputs across various domains. However, a persistent challenge is
the occurrence of ""hallucinations"", where the model produces outputs that are
plausible but invalid. While empirical strategies have been explored to
mitigate this issue, a rigorous theoretical understanding remains elusive. In
this paper, we develop a theoretical framework to analyze the learnability of
non-hallucinating generative models from a learning-theoretic perspective. Our
results reveal that non-hallucinating learning is statistically impossible when
relying solely on the training dataset, even for a hypothesis class of size two
and when the entire training set is truthful. To overcome these limitations, we
show that incorporating inductive biases aligned with the actual facts into the
learning process is essential. We provide a systematic approach to achieve this
by restricting the facts set to a concept class of finite VC-dimension and
demonstrate its effectiveness under various learning paradigms. Although our
findings are primarily conceptual, they represent a first step towards a
principled approach to addressing hallucinations in learning generative models.",2024-10-24,"Changlong Wu, Ananth Grama, Wojciech Szpankowski",http://arxiv.org/pdf/2410.19217v1,cs.LG
Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management,"With the global economic integration and the high interconnection of
financial markets, financial institutions are facing unprecedented challenges,
especially liquidity risk. This paper proposes a liquidity coverage ratio (LCR)
prediction model based on the gated recurrent unit (GRU) network to help
financial institutions manage their liquidity risk more effectively. By
utilizing the GRU network in deep learning technology, the model can
automatically learn complex patterns from historical data and accurately
predict LCR for a period of time in the future. The experimental results show
that compared with traditional methods, the GRU model proposed in this study
shows significant advantages in mean absolute error (MAE), proving its higher
accuracy and robustness. This not only provides financial institutions with a
more reliable liquidity risk management tool but also provides support for
regulators to formulate more scientific and reasonable policies, which helps to
improve the stability of the entire financial system.",2024-10-24,"Zhen Xu, Jingming Pan, Siyuan Han, Hongju Ouyang, Yuan Chen, Mohan Jiang",http://arxiv.org/pdf/2410.19211v1,cs.LG
Equitable Federated Learning with Activation Clustering,"Federated learning is a prominent distributed learning paradigm that
incorporates collaboration among diverse clients, promotes data locality, and
thus ensures privacy. These clients have their own technological, cultural, and
other biases in the process of data generation. However, the present standard
often ignores this bias/heterogeneity, perpetuating bias against certain groups
rather than mitigating it. In response to this concern, we propose an equitable
clustering-based framework where the clients are categorized/clustered based on
how similar they are to each other. We propose a unique way to construct the
similarity matrix that uses activation vectors. Furthermore, we propose a
client weighing mechanism to ensure that each cluster receives equal importance
and establish $O(1/\sqrt{K})$ rate of convergence to reach an
$\epsilon-$stationary solution. We assess the effectiveness of our proposed
strategy against common baselines, demonstrating its efficacy in terms of
reducing the bias existing amongst various client clusters and consequently
ameliorating algorithmic bias against specific groups.",2024-10-24,"Antesh Upadhyay, Abolfazl Hashemi",http://arxiv.org/pdf/2410.19207v2,cs.LG
Inference time LLM alignment in single and multidomain preference spectrum,"Aligning Large Language Models (LLM) to address subjectivity and nuanced
preference levels requires adequate flexibility and control, which can be a
resource-intensive and time-consuming procedure. Existing training-time
alignment methods require full re-training when a change is needed and
inference-time ones typically require access to the reward model at each
inference step. To address these limitations, we introduce inference-time model
alignment method that learns encoded representations of preference dimensions,
called \textit{Alignment Vectors} (AV). These representations are computed by
subtraction of the base model from the aligned model as in model editing
enabling dynamically adjusting the model behavior during inference through
simple linear operations. Even though the preference dimensions can span
various granularity levels, here we focus on three gradual response levels
across three specialized domains: medical, legal, and financial, exemplifying
its practical potential. This new alignment paradigm introduces adjustable
preference knobs during inference, allowing users to tailor their LLM outputs
while reducing the inference cost by half compared to the prompt engineering
approach. Additionally, we find that AVs are transferable across different
fine-tuning stages of the same model, demonstrating their flexibility. AVs also
facilitate multidomain, diverse preference alignment, making the process 12x
faster than the retraining approach.",2024-10-24,"Sadat Shahriar, Zheng Qi, Nikolaos Pappas, Srikanth Doss, Monica Sunkara, Kishaloy Halder, Manuel Mager, Yassine Benajiba",http://arxiv.org/pdf/2410.19206v1,cs.LG
An Inverse Modeling Constrained Multi-Objective Evolutionary Algorithm Based on Decomposition,"This paper introduces the inverse modeling constrained multi-objective
evolutionary algorithm based on decomposition (IM-C-MOEA/D) for addressing
constrained real-world optimization problems. Our research builds upon the
advancements made in evolutionary computing-based inverse modeling, and it
strategically bridges the gaps in applying inverse models based on
decomposition to problem domains with constraints. The proposed approach is
experimentally evaluated on diverse real-world problems (RWMOP1-35), showing
superior performance to state-of-the-art constrained multi-objective
evolutionary algorithms (CMOEAs). The experimental results highlight the
robustness of the algorithm and its applicability in real-world constrained
optimization scenarios.",2024-10-24,"Lucas R. C. Farias, Aluizio F. R. Araújo",http://arxiv.org/pdf/2410.19203v1,cs.LG
Binary Classification: Is Boosting stronger than Bagging?,"Random Forests have been one of the most popular bagging methods in the past
few decades, especially due to their success at handling tabular datasets. They
have been extensively studied and compared to boosting models, like XGBoost,
which are generally considered more performant. Random Forests adopt several
simplistic assumptions, such that all samples and all trees that form the
forest are equally important for building the final model. We introduce
Enhanced Random Forests, an extension of vanilla Random Forests with extra
functionalities and adaptive sample and model weighting. We develop an
iterative algorithm for adapting the training sample weights, by favoring the
hardest examples, and an approach for finding personalized tree weighting
schemes for each new sample. Our method significantly improves upon regular
Random Forests across 15 different binary classification datasets and
considerably outperforms other tree methods, including XGBoost, when run with
default hyperparameters, which indicates the robustness of our approach across
datasets, without the need for extensive hyperparameter tuning. Our
tree-weighting methodology results in enhanced or comparable performance to the
uniformly weighted ensemble, and is, more importantly, leveraged to define
importance scores for trees based on their contributions to classifying each
new sample. This enables us to only focus on a small number of trees as the
main models that define the outcome of a new sample and, thus, to partially
recover interpretability, which is critically missing from both bagging and
boosting methods. In binary classification problems, the proposed extensions
and the corresponding results suggest the equivalence of bagging and boosting
methods in performance, and the edge of bagging in interpretability by
leveraging a few learners of the ensemble, which is not an option in the less
explainable boosting methods.",2024-10-24,"Dimitris Bertsimas, Vasiliki Stoumpou",http://arxiv.org/pdf/2410.19200v1,cs.LG
MAP: Multi-Human-Value Alignment Palette,"Ensuring that generative AI systems align with human values is essential but
challenging, especially when considering multiple human values and their
potential trade-offs. Since human values can be personalized and dynamically
change over time, the desirable levels of value alignment vary across different
ethnic groups, industry sectors, and user cohorts. Within existing frameworks,
it is hard to define human values and align AI systems accordingly across
different directions simultaneously, such as harmlessness, helpfulness, and
positiveness. To address this, we develop a novel, first-principle approach
called Multi-Human-Value Alignment Palette (MAP), which navigates the alignment
across multiple human values in a structured and reliable way. MAP formulates
the alignment problem as an optimization task with user-defined constraints,
which define human value targets. It can be efficiently solved via a
primal-dual approach, which determines whether a user-defined alignment target
is achievable and how to achieve it. We conduct a detailed theoretical analysis
of MAP by quantifying the trade-offs between values, the sensitivity to
constraints, the fundamental connection between multi-value alignment and
sequential alignment, and proving that linear weighted rewards are sufficient
for multi-value alignment. Extensive experiments demonstrate MAP's ability to
align multiple values in a principled manner while delivering strong empirical
performance across various tasks.",2024-10-24,"Xinran Wang, Qi Le, Ammar Ahmed, Enmao Diao, Yi Zhou, Nathalie Baracaldo, Jie Ding, Ali Anwar",http://arxiv.org/pdf/2410.19198v1,cs.LG
Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media,"Disinformation on social media poses both societal and technical challenges,
requiring robust detection systems. While previous studies have integrated
textual information into propagation networks, they have yet to fully leverage
the advancements in Transformer-based language models for high-quality
contextual text representations. This work addresses this gap by incorporating
Transformer-based textual features into Graph Neural Networks (GNNs) for fake
news detection. We demonstrate that contextual text representations enhance GNN
performance, achieving 33.8% relative improvement in Macro F1 over models
without textual features and 9.3% over static text representations. We further
investigate the impact of different feature sources and the effects of noisy
data augmentation. We expect our methodology to open avenues for further
research, and we made code publicly available.",2024-10-24,"Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes",http://arxiv.org/pdf/2410.19193v2,cs.LG
TEAM: Topological Evolution-aware Framework for Traffic Forecasting--Extended Version,"Due to the global trend towards urbanization, people increasingly move to and
live in cities that then continue to grow. Traffic forecasting plays an
important role in the intelligent transportation systems of cities as well as
in spatio-temporal data mining. State-of-the-art forecasting is achieved by
deep-learning approaches due to their ability to contend with complex
spatio-temporal dynamics. However, existing methods assume the input is
fixed-topology road networks and static traffic time series. These assumptions
fail to align with urbanization, where time series are collected continuously
and road networks evolve over time. In such settings, deep-learning models
require frequent re-initialization and re-training, imposing high computational
costs. To enable much more efficient training without jeopardizing model
accuracy, we propose the Topological Evolution-aware Framework (TEAM) for
traffic forecasting that incorporates convolution and attention. This
combination of mechanisms enables better adaptation to newly collected time
series, while being able to maintain learned knowledge from old time series.
TEAM features a continual learning module based on the Wasserstein metric that
acts as a buffer that can identify the most stable and the most changing
network nodes. Then, only data related to stable nodes is employed for
re-training when consolidating a model. Further, only data of new nodes and
their adjacent nodes as well as data pertaining to changing nodes are used to
re-train the model. Empirical studies with two real-world traffic datasets
offer evidence that TEAM is capable of much lower re-training costs than
existing methods are, without jeopardizing forecasting accuracy.",2024-10-24,"Duc Kieu, Tung Kieu, Peng Han, Bin Yang, Christian S. Jensen, Bac Le",http://arxiv.org/pdf/2410.19192v3,cs.LG
Reinforcement Learning the Chromatic Symmetric Function,"We propose a conjectural counting formula for the coefficients of the
chromatic symmetric function of unit interval graphs using reinforcement
learning. The formula counts specific disjoint cycle-tuples in the graphs,
referred to as Eschers, which satisfy certain concatenation conditions. These
conditions are identified by a reinforcement learning model and are independent
of the particular unit interval graph, resulting a universal counting
expression.",2024-10-24,"Gergely Bérczi, Jonas Klüver",http://arxiv.org/pdf/2410.19189v1,cs.LG
No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts,"In a context where the Brazilian judiciary system, the largest in the world,
faces a crisis due to the slow processing of millions of cases, it becomes
imperative to develop efficient methods for analyzing legal texts. We introduce
uBERT, a hybrid model that combines Transformer and Recurrent Neural Network
architectures to effectively handle long legal texts. Our approach processes
the full text regardless of its length while maintaining reasonable
computational overhead. Our experiments demonstrate that uBERT achieves
superior performance compared to BERT+LSTM when overlapping input is used and
is significantly faster than ULMFiT for processing long legal documents.",2024-10-24,"Israel Fama, Bárbara Bueno, Alexandre Alcoforado, Thomas Palmeira Ferraz, Arnold Moya, Anna Helena Reali Costa",http://arxiv.org/pdf/2410.19184v2,cs.LG
Cascading Failure Prediction via Causal Inference,"Causal inference provides an analytical framework to identify and quantify
cause-and-effect relationships among a network of interacting agents. This
paper offers a novel framework for analyzing cascading failures in power
transmission networks. This framework generates a directed latent graph in
which the nodes represent the transmission lines and the directed edges encode
the cause-effect relationships. This graph has a structure distinct from the
system's topology, signifying the intricate fact that both local and non-local
interdependencies exist among transmission lines, which are more general than
only the local interdependencies that topological graphs can present. This
paper formalizes a causal inference framework for predicting how an emerging
anomaly propagates throughout the system. Using this framework, two algorithms
are designed, providing an analytical framework to identify the most likely and
most costly cascading scenarios. The framework's effectiveness is evaluated
compared to the pertinent literature on the IEEE 14-bus, 39-bus, and 118-bus
systems.",2024-10-24,"Shiuli Subhra Ghosh, Anmol Dwivedi, Ali Tajer, Kyongmin Yeo, Wesley M. Gifford",http://arxiv.org/pdf/2410.19179v1,cs.LG
Perturbation-based Graph Active Learning for Weakly-Supervised Belief Representation Learning,"This paper addresses the problem of optimizing the allocation of labeling
resources for semi-supervised belief representation learning in social
networks. The objective is to strategically identify valuable messages on
social media graphs that are worth labeling within a constrained budget,
ultimately maximizing the task's performance. Despite the progress in
unsupervised or semi-supervised methods in advancing belief and ideology
representation learning on social networks and the remarkable efficacy of graph
learning techniques, the availability of high-quality curated labeled social
data can greatly benefit and further improve performances. Consequently,
allocating labeling efforts is a critical research problem in scenarios where
labeling resources are limited. This paper proposes a graph data
augmentation-inspired perturbation-based active learning strategy (PerbALGraph)
that progressively selects messages for labeling according to an automatic
estimator, obviating human guidance. This estimator is based on the principle
that messages in the network that exhibit heightened sensitivity to structural
features of the observational data indicate landmark quality that significantly
influences semi-supervision processes. We design the estimator to be the
prediction variance under a set of designed graph perturbations, which is
model-agnostic and application-independent. Extensive experiment results
demonstrate the effectiveness of the proposed strategy for belief
representation learning tasks.",2024-10-24,"Dachun Sun, Ruijie Wang, Jinning Li, Ruipeng Han, Xinyi Liu, You Lyu, Tarek Abdelzaher",http://arxiv.org/pdf/2410.19176v1,cs.LG
Critical biblical studies via word frequency analysis: unveiling text authorship,"The Bible, a product of an extensive and intricate process of oral-written
transmission spanning centuries, obscures the contours of its earlier
recensions. Debate rages over determining the existing layers and identifying
the date of composition and historical background of the biblical texts.
Traditional manual methodologies have grappled with authorship challenges
through scrupulous textual criticism, employing linguistic, stylistic,
inner-biblical, and historical criteria. Despite recent progress in
computer-assisted analysis, many patterns still need to be uncovered in
Biblical Texts. In this study, we address the question of authorship of
biblical texts by employing statistical analysis to the frequency of words
using a method that is particularly sensitive to deviations in frequencies
associated with a few words out of potentially many. We aim to differentiate
between three distinct authors across numerous chapters spanning the first nine
books of the Bible. In particular, we examine 50 chapters labeled according to
biblical exegesis considerations into three corpora (D, DtrH, and P). Without
prior assumptions about author identity, our approach leverages subtle
differences in word frequencies to distinguish among the three corpora and
identify author-dependent linguistic properties. Our analysis indicates that
the first two authors (D and DtrH) are much more closely related compared to P,
a fact that aligns with expert assessments. Additionally, we attain high
accuracy in attributing authorship by evaluating the similarity of each chapter
with the reference corpora. This study sheds new light on the authorship of
biblical texts by providing interpretable, statistically significant evidence
that there are different linguistic characteristics of biblical authors and
that these differences can be identified.",2024-10-24,"Shira Faigenbaum-Golovin, Alon Kipnis, Axel Bühler, Eli Piasetzky, Thomas Römer, Israel Finkelstein",http://arxiv.org/pdf/2410.19883v1,cs.LG
Indication Finding: a novel use case for representation learning,"Many therapies are effective in treating multiple diseases. We present an
approach that leverages methods developed in natural language processing and
real-world data to prioritize potential, new indications for a mechanism of
action (MoA). We specifically use representation learning to generate
embeddings of indications and prioritize them based on their proximity to the
indications with the strongest available evidence for the MoA. We demonstrate
the successful deployment of our approach for anti-IL-17A using embeddings
generated with SPPMI and present an evaluation framework to determine the
quality of indication finding results and the derived embeddings.",2024-10-24,"Maren Eckhoff, Valmir Selimi, Alexander Aranovitch, Ian Lyons, Emily Briggs, Jennifer Hou, Alex Devereson, Matej Macak, David Champagne, Chris Anagnostopoulos",http://arxiv.org/pdf/2410.19174v1,cs.LG
Adversarial Attacks on Large Language Models Using Regularized Relaxation,"As powerful Large Language Models (LLMs) are now widely used for numerous
practical applications, their safety is of critical importance. While alignment
techniques have significantly improved overall safety, LLMs remain vulnerable
to carefully crafted adversarial inputs. Consequently, adversarial attack
methods are extensively used to study and understand these vulnerabilities.
However, current attack methods face significant limitations. Those relying on
optimizing discrete tokens suffer from limited efficiency, while continuous
optimization techniques fail to generate valid tokens from the model's
vocabulary, rendering them impractical for real-world applications. In this
paper, we propose a novel technique for adversarial attacks that overcomes
these limitations by leveraging regularized gradients with continuous
optimization methods. Our approach is two orders of magnitude faster than the
state-of-the-art greedy coordinate gradient-based method, significantly
improving the attack success rate on aligned language models. Moreover, it
generates valid tokens, addressing a fundamental limitation of existing
continuous optimization methods. We demonstrate the effectiveness of our attack
on five state-of-the-art LLMs using four datasets.",2024-10-24,"Samuel Jacob Chacko, Sajib Biswas, Chashi Mahiul Islam, Fatema Tabassum Liza, Xiuwen Liu",http://arxiv.org/pdf/2410.19160v1,cs.LG
Cross Spline Net and a Unified World,"In today's machine learning world for tabular data, XGBoost and fully
connected neural network (FCNN) are two most popular methods due to their good
model performance and convenience to use. However, they are highly complicated,
hard to interpret, and can be overfitted. In this paper, we propose a new
modeling framework called cross spline net (CSN) that is based on a combination
of spline transformation and cross-network (Wang et al. 2017, 2021). We will
show CSN is as performant and convenient to use, and is less complicated, more
interpretable and robust. Moreover, the CSN framework is flexible, as the
spline layer can be configured differently to yield different models. With
different choices of the spline layer, we can reproduce or approximate a set of
non-neural network models, including linear and spline-based statistical
models, tree, rule-fit, tree-ensembles (gradient boosting trees, random
forest), oblique tree/forests, multi-variate adaptive regression spline (MARS),
SVM with polynomial kernel, etc. Therefore, CSN provides a unified modeling
framework that puts the above set of non-neural network models under the same
neural network framework. By using scalable and powerful gradient descent
algorithms available in neural network libraries, CSN avoids some pitfalls
(such as being ad-hoc, greedy or non-scalable) in the case-specific
optimization methods used in the above non-neural network models. We will use a
special type of CSN, TreeNet, to illustrate our point. We will compare TreeNet
with XGBoost and FCNN to show the benefits of TreeNet. We believe CSN will
provide a flexible and convenient framework for practitioners to build
performant, robust and more interpretable models.",2024-10-24,"Linwei Hu, Ye Jin Choi, Vijayan N. Nair",http://arxiv.org/pdf/2410.19154v1,cs.LG
Learning Coupled Subspaces for Multi-Condition Spike Data,"In neuroscience, researchers typically conduct experiments under multiple
conditions to acquire neural responses in the form of high-dimensional spike
train datasets. Analysing high-dimensional spike data is a challenging
statistical problem. To this end, Gaussian process factor analysis (GPFA), a
popular class of latent variable models has been proposed. GPFA extracts
smooth, low-dimensional latent trajectories underlying high-dimensional spike
train datasets. However, such analyses are often done separately for each
experimental condition, contrary to the nature of neural datasets, which
contain recordings under multiple experimental conditions. Exploiting the
parametric nature of these conditions, we propose a multi-condition GPFA model
and inference procedure to learn the underlying latent structure in the
corresponding datasets in sample-efficient manner. In particular, we propose a
non-parametric Bayesian approach to learn a smooth tuning function over the
experiment condition space. Our approach not only boosts model accuracy and is
faster, but also improves model interpretability compared to approaches that
separately fit models for each experimental condition.",2024-10-24,"Yididiya Y. Nadew, Xuhui Fan, Christopher J. Quinn",http://arxiv.org/pdf/2410.19153v1,cs.LG
Structured Diffusion Models with Mixture of Gaussians as Prior Distribution,"We propose a class of structured diffusion models, in which the prior
distribution is chosen as a mixture of Gaussians, rather than a standard
Gaussian distribution. The specific mixed Gaussian distribution, as prior, can
be chosen to incorporate certain structured information of the data. We develop
a simple-to-implement training procedure that smoothly accommodates the use of
mixed Gaussian as prior. Theory is provided to quantify the benefits of our
proposed models, compared to the classical diffusion models. Numerical
experiments with synthetic, image and operational data are conducted to show
comparative advantages of our model. Our method is shown to be robust to
mis-specifications and in particular suits situations where training resources
are limited or faster training in real time is desired.",2024-10-24,"Nanshan Jia, Tingyu Zhu, Haoyu Liu, Zeyu Zheng",http://arxiv.org/pdf/2410.19149v1,cs.LG
Functional Brain Network Identification in Opioid Use Disorder Using Machine Learning Analysis of Resting-State fMRI BOLD Signals,"Understanding the neurobiology of opioid use disorder (OUD) using
resting-state functional magnetic resonance imaging (rs-fMRI) may help inform
treatment strategies to improve patient outcomes. Recent literature suggests
time-frequency characteristics of rs-fMRI blood oxygenation level-dependent
(BOLD) signals may offer complementary information to traditional analysis
techniques. However, existing studies of OUD analyze BOLD signals using
measures computed across all time points. This study, for the first time in the
literature, employs data-driven machine learning (ML) for time-frequency
analysis of local neural activity within key functional networks to
differentiate OUD subjects from healthy controls (HC). We obtain time-frequency
features based on rs-fMRI BOLD signals from the default mode network (DMN),
salience network (SN), and executive control network (ECN) for 31 OUD and 45 HC
subjects. Then, we perform 5-fold cross-validation classification (OUD vs. HC)
experiments to study the discriminative power of functional network features
while taking into consideration significant demographic features. The DMN and
SN show the most discriminative power, significantly (p < 0.05) outperforming
chance baselines with mean F1 scores of 0.7097 and 0.7018, respectively, and
mean AUCs of 0.8378 and 0.8755, respectively. Follow-up Boruta ML analysis of
selected time-frequency (wavelet) features reveals significant (p < 0.05)
detail coefficients for all three functional networks, underscoring the need
for ML and time-frequency analysis of rs-fMRI BOLD signals in the study of OUD.",2024-10-24,"Ahmed Temtam, Megan A. Witherow, Liangsuo Ma, M. Shibly Sadique, F. Gerard Moeller, Khan M. Iftekharuddin",http://arxiv.org/pdf/2410.19147v3,cs.LG
Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant,"We revisit knowledge-aware text-based visual question answering, also known
as Text-KVQA, in the light of modern advancements in large multimodal models
(LMMs), and make the following contributions: (i) We propose VisTEL - a
principled approach to perform visual text entity linking. The proposed VisTEL
module harnesses a state-of-the-art visual text recognition engine and the
power of a large multimodal model to jointly reason using textual and visual
context obtained using surrounding cues in the image to link the visual text
entity to the correct knowledge base entity. (ii) We present KaLMA - a
knowledge-aware large multimodal assistant that augments an LMM with knowledge
associated with visual text entity in the image to arrive at an accurate
answer. Further, we provide a comprehensive experimental analysis and
comparison of our approach with traditional visual question answering,
pre-large multimodal models, and large multimodal models, as well as prior
top-performing approaches. Averaging over three splits of Text-KVQA, our
proposed approach surpasses the previous best approach by a substantial 23.3%
on an absolute scale and establishes a new state of the art. We make our
implementation publicly available.",2024-10-24,"Abhirama Subramanyam Penamakuri, Anand Mishra",http://arxiv.org/pdf/2410.19144v1,cs.LG
Initialization Matters: On the Benign Overfitting of Two-Layer ReLU CNN with Fully Trainable Layers,"Benign overfitting refers to how over-parameterized neural networks can fit
training data perfectly and generalize well to unseen data. While this has been
widely investigated theoretically, existing works are limited to two-layer
networks with fixed output layers, where only the hidden weights are trained.
We extend the analysis to two-layer ReLU convolutional neural networks (CNNs)
with fully trainable layers, which is closer to the practice. Our results show
that the initialization scaling of the output layer is crucial to the training
dynamics: large scales make the model training behave similarly to that with
the fixed output, the hidden layer grows rapidly while the output layer remains
largely unchanged; in contrast, small scales result in more complex layer
interactions, the hidden layer initially grows to a specific ratio relative to
the output layer, after which both layers jointly grow and maintain that ratio
throughout training. Furthermore, in both settings, we provide nearly matching
upper and lower bounds on the test errors, identifying the sharp conditions on
the initialization scaling and signal-to-noise ratio (SNR) in which the benign
overfitting can be achieved or not. Numerical experiments back up the
theoretical results.",2024-10-24,"Shuning Shang, Xuran Meng, Yuan Cao, Difan Zou",http://arxiv.org/pdf/2410.19139v1,cs.LG
Context-Aware Trajectory Anomaly Detection,"Trajectory anomaly detection is crucial for effective decision-making in
urban and human mobility management. Existing methods of trajectory anomaly
detection generally focus on training a trajectory generative model and
evaluating the likelihood of reconstructing a given trajectory. However,
previous work often lacks important contextual information on the trajectory,
such as the agent's information (e.g., agent ID) or geographic information
(e.g., Points of Interest (POI)), which could provide additional information on
accurately capturing anomalous behaviors. To fill this gap, we propose a
context-aware anomaly detection approach that models contextual information
related to trajectories. The proposed method is based on a trajectory
reconstruction framework guided by contextual factors such as agent ID and
contextual POI embedding. The injection of contextual information aims to
improve the performance of anomaly detection. We conducted experiments in two
cities and demonstrated that the proposed approach significantly outperformed
existing methods by effectively modeling contextual information. Overall, this
paper paves a new direction for advancing trajectory anomaly detection.",2024-10-24,"Haoji Hu, Jina Kim, Jinwei Zhou, Sofia Kirsanova, JangHyeon Lee, Yao-Yi Chiang",http://arxiv.org/pdf/2410.19136v1,cs.LG
Recommendations for Comprehensive and Independent Evaluation of Machine Learning-Based Earth System Models,"Machine learning (ML) is a revolutionary technology with demonstrable
applications across multiple disciplines. Within the Earth science community,
ML has been most visible for weather forecasting, producing forecasts that
rival modern physics-based models. Given the importance of deepening our
understanding and improving predictions of the Earth system on all time scales,
efforts are now underway to develop forecasting models into Earth-system models
(ESMs), capable of representing all components of the coupled Earth system (or
their aggregated behavior) and their response to external changes. Modeling the
Earth system is a much more difficult problem than weather forecasting, not
least because the model must represent the alternate (e.g., future) coupled
states of the system for which there are no historical observations. Given that
the physical principles that enable predictions about the response of the Earth
system are often not explicitly coded in these ML-based models, demonstrating
the credibility of ML-based ESMs thus requires us to build evidence of their
consistency with the physical system. To this end, this paper puts forward five
recommendations to enhance comprehensive, standardized, and independent
evaluation of ML-based ESMs to strengthen their credibility and promote their
wider use.",2024-10-24,"Paul A. Ullrich, Elizabeth A. Barnes, William D. Collins, Katherine Dagon, Shiheng Duan, Joshua Elms, Jiwoo Lee, L. Ruby Leung, Dan Lu, Maria J. Molina, Travis A. O'Brien, Finn O. Rebassoo",http://arxiv.org/pdf/2410.19882v2,cs.LG
Maximum a Posteriori Inference for Factor Graphs via Benders' Decomposition,"Many Bayesian statistical inference problems come down to computing a maximum
a-posteriori (MAP) assignment of latent variables. Yet, standard methods for
estimating the MAP assignment do not have a finite time guarantee that the
algorithm has converged to a fixed point. Previous research has found that MAP
inference can be represented in dual form as a linear programming problem with
a non-polynomial number of constraints. A Lagrangian relaxation of the dual
yields a statistical inference algorithm as a linear programming problem.
However, the decision as to which constraints to remove in the relaxation is
often heuristic. We present a method for maximum a-posteriori inference in
general Bayesian factor models that sequentially adds constraints to the fully
relaxed dual problem using Benders' decomposition. Our method enables the
incorporation of expressive integer and logical constraints in clustering
problems such as must-link, cannot-link, and a minimum number of whole samples
allocated to each cluster. Using this approach, we derive MAP estimation
algorithms for the Bayesian Gaussian mixture model and latent Dirichlet
allocation. Empirical results show that our method produces a higher optimal
posterior value compared to Gibbs sampling and variational Bayes methods for
standard data sets and provides certificate of convergence.",2024-10-24,"Harsh Vardhan Dubey, Ji Ah Lee, Patrick Flaherty",http://arxiv.org/pdf/2410.19131v1,cs.LG
Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models,"With the rapid development of natural language processing technology, large
language models have demonstrated exceptional performance in various
application scenarios. However, training these models requires significant
computational resources and data processing capabilities. Cross-cloud federated
training offers a new approach to addressing the resource bottlenecks of a
single cloud platform, allowing the computational resources of multiple clouds
to collaboratively complete the training tasks of large models. This study
analyzes the key technologies of cross-cloud federated training, including data
partitioning and distribution, communication optimization, model aggregation
algorithms, and the compatibility of heterogeneous cloud platforms.
Additionally, the study examines data security and privacy protection
strategies in cross-cloud training, particularly the application of data
encryption and differential privacy techniques. Through experimental
validation, the proposed technical framework demonstrates enhanced training
efficiency, ensured data security, and reduced training costs, highlighting the
broad application prospects of cross-cloud federated training.",2024-10-24,"Haowei Yang, Mingxiu Sui, Shaobo Liu, Xinyue Qian, Zhaoyang Zhang, Bingying Liu",http://arxiv.org/pdf/2410.19130v2,cs.LG
A spectral method for multi-view subspace learning using the product of projections,"Multi-view data provides complementary information on the same set of
observations, with multi-omics and multimodal sensor data being common
examples. Analyzing such data typically requires distinguishing between shared
(joint) and unique (individual) signal subspaces from noisy, high-dimensional
measurements. Despite many proposed methods, the conditions for reliably
identifying joint and individual subspaces remain unclear. We rigorously
quantify these conditions, which depend on the ratio of the signal rank to the
ambient dimension, principal angles between true subspaces, and noise levels.
Our approach characterizes how spectrum perturbations of the product of
projection matrices, derived from each view's estimated subspaces, affect
subspace separation. Using these insights, we provide an easy-to-use and
scalable estimation algorithm. In particular, we employ rotational bootstrap
and random matrix theory to partition the observed spectrum into joint,
individual, and noise subspaces. Diagnostic plots visualize this partitioning,
providing practical and interpretable insights into the estimation performance.
In simulations, our method estimates joint and individual subspaces more
accurately than existing approaches. Applications to multi-omics data from
colorectal cancer patients and nutrigenomic study of mice demonstrate improved
performance in downstream predictive tasks.",2024-10-24,"Renat Sergazinov, Armeen Taeb, Irina Gaynanova",http://arxiv.org/pdf/2410.19125v1,cs.LG
Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design,"The proliferation of large language models (LLMs) has led to the adoption of
Mixture-of-Experts (MoE) architectures that dynamically leverage specialized
subnetworks for improved efficiency and performance. Despite their benefits,
MoE models face significant challenges during inference, including inefficient
memory management and suboptimal batching, due to misaligned design choices
between the model architecture and the system policies. Furthermore, the
conventional approach of training MoEs from scratch is increasingly prohibitive
in terms of cost. In this paper, we propose a novel framework Read-ME that
transforms pre-trained dense LLMs into smaller MoE models (in contrast to
""upcycling"" generalist MoEs), avoiding the high costs of ground-up training.
Our approach employs activation sparsity to extract experts. To compose
experts, we examine the widely-adopted layer-wise router design and show its
redundancy, and thus we introduce the pre-gating router decoupled from the MoE
backbone that facilitates system-friendly pre-computing and lookahead
scheduling, enhancing expert-aware batching and caching. Our codesign therefore
addresses critical gaps on both the algorithmic and system fronts, establishing
a scalable and efficient alternative for LLM inference in resource-constrained
settings. Read-ME outperforms other popular open-source dense models of similar
scales, achieving improvements of up to 10.1% on MMLU, and improving mean
end-to-end latency up to 6.1%. Codes are available at:
https://github.com/VITA-Group/READ-ME.",2024-10-24,"Ruisi Cai, Yeonju Ro, Geon-Woo Kim, Peihao Wang, Babak Ehteshami Bejnordi, Aditya Akella, Zhangyang Wang",http://arxiv.org/pdf/2410.19123v1,cs.LG
LLM Tree Search,"This project aims to investigate a novel sequence generation method inspired
by the AlphaGo paradigm, adapting it for use with large language models (LLMs).
The proposed approach involves creating search trees of different possible
completions and evaluating these completions based on model confidence. By
considering various paths in the search tree and scoring them according to the
model's confidence in each completion, we can generate diverse and high-quality
sequences. This research explores the implementation of this paradigm by using
confidence as a proxy for response quality akin to beam search
\citep{vijayakumar2016diverse}. The primary goal of this paper is to outline
the paradigm and demonstrate its potential, rather than focusing on achieving
perfect results. The paper will outline the reasons why we believe this
paradigm has the potential to improve LLMs in the following manners: 1)
increase output quality, 2) decrease errors, 3) eliminate or reduce the
compound error problems, 4) generate diverse and creative completions, 5) allow
for iterative problem-solving, and 6) self-training. We expect this approach to
yield a set of diverse and coherent sequences, offering insights into balancing
exploration and exploitation in sequence generation. Potential applications
include creative text generation tasks, such as storytelling and content
creation, as well as other natural language processing domains, like machine
translation and automated summarization. The goal is that the model will be far
more effective as it will be able to consider many possible variations allowing
it to find the ideal completion. This research aims to contribute to the
understanding of effective search strategies in sequence generation and their
impact on generating high-quality, varied textual outputs.",2024-10-24,Dylan Wilson,http://arxiv.org/pdf/2410.19117v1,cs.LG
LanFL: Differentially Private Federated Learning with Large Language Models using Synthetic Samples,"Federated Learning (FL) is a collaborative, privacy-preserving machine
learning framework that enables multiple participants to train a single global
model. However, the recent advent of powerful Large Language Models (LLMs) with
tens to hundreds of billions of parameters makes the naive application of
traditional FL methods to LLMs impractical due to high computational and
communication costs. Furthermore, end users of LLMs often lack access to full
architectures and weights of the models, making it impossible for participants
to fine-tune these models directly. This paper introduces a novel FL scheme for
LLMs, named LanFL, which is purely prompt-based and treats the underlying LLMs
as black boxes. We have developed a differentially private synthetic sample
generation mechanism to facilitate knowledge sharing among participants, along
with a prompt optimization scheme that enables learning from synthetic samples.
Our extensive experiments demonstrate that LanFL successfully facilitates
learning among participants while preserving the privacy of local datasets
across various tasks.",2024-10-24,"Huiyu Wu, Diego Klabjan",http://arxiv.org/pdf/2410.19114v1,cs.LG
Distributed Blind Source Separation based on FastICA,"With the emergence of wireless sensor networks (WSNs), many traditional
signal processing tasks are required to be computed in a distributed fashion,
without transmissions of the raw data to a centralized processing unit, due to
the limited energy and bandwidth resources available to the sensors. In this
paper, we propose a distributed independent component analysis (ICA) algorithm,
which aims at identifying the original signal sources based on observations of
their mixtures measured at various sensor nodes. One of the most commonly used
ICA algorithms is known as FastICA, which requires a spatial pre-whitening
operation in the first step of the algorithm. Such a pre-whitening across all
nodes of a WSN is impossible in a bandwidth-constrained distributed setting as
it requires to correlate each channel with each other channel in the WSN. We
show that an explicit network-wide pre-whitening step can be circumvented by
leveraging the properties of the so-called Distributed Adaptive Signal Fusion
(DASF) framework. Despite the lack of such a network-wide pre-whitening, we can
still obtain the $Q$ least Gaussian independent components of the centralized
ICA solution, where $Q$ scales linearly with the required communication load.",2024-10-24,"Cem Ates Musluoglu, Alexander Bertrand",http://arxiv.org/pdf/2410.19112v2,cs.LG
Bio2Token: All-atom tokenization of any biomolecular structure with Mamba,"Efficient encoding and representation of large 3D molecular structures with
high fidelity is critical for biomolecular design applications. Despite this,
many representation learning approaches restrict themselves to modeling smaller
systems or use coarse-grained approximations of the systems, for example
modeling proteins at the resolution of amino acid residues rather than at the
level of individual atoms. To address this, we develop quantized auto-encoders
that learn atom-level tokenizations of complete proteins, RNA and small
molecule structures with reconstruction accuracies well below 1 Angstrom. We
demonstrate that a simple Mamba state space model architecture is efficient
compared to an SE(3)-invariant IPA architecture, reaches competitive accuracies
and can scale to systems with almost 100,000 atoms. The learned structure
tokens of bio2token may serve as the input for all-atom generative models in
the future.",2024-10-24,"Andrew Liu, Axel Elaldi, Nathan Russell, Olivia Viessmann",http://arxiv.org/pdf/2410.19110v3,cs.LG
Conditional diffusions for amortized neural posterior estimation,"Neural posterior estimation (NPE), a simulation-based computational approach
for Bayesian inference, has shown great success in approximating complex
posterior distributions. Existing NPE methods typically rely on normalizing
flows, which approximate a distribution by composing many simple, invertible
transformations. But flow-based models, while state of the art for NPE, are
known to suffer from several limitations, including training instability and
sharp trade-offs between representational power and computational cost. In this
work, we demonstrate the effectiveness of conditional diffusions coupled with
high-capacity summary networks for amortized NPE. Conditional diffusions
address many of the challenges faced by flow-based methods. Our results show
that, across a highly varied suite of benchmarking problems for NPE
architectures, diffusions offer improved stability, superior accuracy, and
faster training times, even with simpler, shallower models. Building on prior
work on diffusions for NPE, we show that these gains persist across a variety
of different summary network architectures. Code is available at
https://github.com/TianyuCodings/cDiff.",2024-10-24,"Tianyu Chen, Vansh Bansal, James G. Scott",http://arxiv.org/pdf/2410.19105v3,cs.LG
TesseraQ: Ultra Low-Bit LLM Post-Training Quantization with Block Reconstruction,"Large language models (LLMs) have revolutionized natural language processing,
albeit at the cost of immense memory and computation requirements.
Post-training quantization (PTQ) is becoming the de facto method to reduce the
memory footprint and improve the inference throughput of LLMs. In this work, we
aim to push the upper limit of LLM PTQ by optimizing the weight rounding
parameters with the block reconstruction technique, a predominant method in
previous vision models. We propose TesseraQ, a new state-of-the-art PTQ
technique, to quantize the weights of LLMs to ultra-low bits. To effectively
optimize the rounding in LLMs and stabilize the reconstruction process, we
introduce progressive adaptive rounding. This approach iteratively transits the
soft rounding variables to hard variables during the reconstruction process.
Additionally, we optimize the dequantization scale parameters to fully leverage
the block reconstruction technique. We demonstrate that TesseraQ can be
seamlessly integrated with existing scaling or clipping-based PTQ algorithms
such as AWQ and OmniQuant, significantly enhancing their performance and
establishing a new state-of-the-art. For instance, when compared to AWQ,
TesseraQ improves the wikitext2 perplexity from 14.65 to 6.82 and average
downstream accuracy from 50.52 to 59.27 with 2-bit weight-only quantization of
LLaMA-2-7B. Across a range of quantization schemes, including W2A16, W3A16,
W3A3, and W4A4, TesseraQ consistently exhibits superior performance.",2024-10-24,"Yuhang Li, Priyadarshini Panda",http://arxiv.org/pdf/2410.19103v1,cs.LG
Inherently Interpretable Tree Ensemble Learning,"Tree ensemble models like random forests and gradient boosting machines are
widely used in machine learning due to their excellent predictive performance.
However, a high-performance ensemble consisting of a large number of decision
trees lacks sufficient transparency and explainability. In this paper, we
demonstrate that when shallow decision trees are used as base learners, the
ensemble learning algorithms can not only become inherently interpretable
subject to an equivalent representation as the generalized additive models but
also sometimes lead to better generalization performance. First, an
interpretation algorithm is developed that converts the tree ensemble into the
functional ANOVA representation with inherent interpretability. Second, two
strategies are proposed to further enhance the model interpretability, i.e., by
adding constraints in the model training stage and post-hoc effect pruning.
Experiments on simulations and real-world datasets show that our proposed
methods offer a better trade-off between model interpretation and predictive
performance, compared with its counterpart benchmarks.",2024-10-24,"Zebin Yang, Agus Sudjianto, Xiaoming Li, Aijun Zhang",http://arxiv.org/pdf/2410.19098v1,cs.LG
Provable Tempered Overfitting of Minimal Nets and Typical Nets,"We study the overfitting behavior of fully connected deep Neural Networks
(NNs) with binary weights fitted to perfectly classify a noisy training set. We
consider interpolation using both the smallest NN (having the minimal number of
weights) and a random interpolating NN. For both learning rules, we prove
overfitting is tempered. Our analysis rests on a new bound on the size of a
threshold circuit consistent with a partial function. To the best of our
knowledge, ours are the first theoretical results on benign or tempered
overfitting that: (1) apply to deep NNs, and (2) do not require a very high or
very low input dimension.",2024-10-24,"Itamar Harel, William M. Hoza, Gal Vardi, Itay Evron, Nathan Srebro, Daniel Soudry",http://arxiv.org/pdf/2410.19092v1,cs.LG
FastSurvival: Hidden Computational Blessings in Training Cox Proportional Hazards Models,"Survival analysis is an important research topic with applications in
healthcare, business, and manufacturing. One essential tool in this area is the
Cox proportional hazards (CPH) model, which is widely used for its
interpretability, flexibility, and predictive performance. However, for modern
data science challenges such as high dimensionality (both $n$ and $p$) and high
feature correlations, current algorithms to train the CPH model have drawbacks,
preventing us from using the CPH model at its full potential. The root cause is
that the current algorithms, based on the Newton method, have trouble
converging due to vanishing second order derivatives when outside the local
region of the minimizer. To circumvent this problem, we propose new
optimization methods by constructing and minimizing surrogate functions that
exploit hidden mathematical structures of the CPH model. Our new methods are
easy to implement and ensure monotonic loss decrease and global convergence.
Empirically, we verify the computational efficiency of our methods. As a direct
application, we show how our optimization methods can be used to solve the
cardinality-constrained CPH problem, producing very sparse high-quality models
that were not previously practical to construct. We list several extensions
that our breakthrough enables, including optimization opportunities,
theoretical questions on CPH's mathematical structure, as well as other
CPH-related applications.",2024-10-24,"Jiachang Liu, Rui Zhang, Cynthia Rudin",http://arxiv.org/pdf/2410.19081v1,cs.LG
BIFRÖST: 3D-Aware Image compositing with Language Instructions,"This paper introduces Bifr\""ost, a novel 3D-aware framework that is built
upon diffusion models to perform instruction-based image composition. Previous
methods concentrate on image compositing at the 2D level, which fall short in
handling complex spatial relationships ($\textit{e.g.}$, occlusion). Bifr\""ost
addresses these issues by training MLLM as a 2.5D location predictor and
integrating depth maps as an extra condition during the generation process to
bridge the gap between 2D and 3D, which enhances spatial comprehension and
supports sophisticated spatial interactions. Our method begins by fine-tuning
MLLM with a custom counterfactual dataset to predict 2.5D object locations in
complex backgrounds from language instructions. Then, the image-compositing
model is uniquely designed to process multiple types of input features,
enabling it to perform high-fidelity image compositions that consider
occlusion, depth blur, and image harmonization. Extensive qualitative and
quantitative evaluations demonstrate that Bifr\""ost significantly outperforms
existing methods, providing a robust solution for generating realistically
composited images in scenarios demanding intricate spatial understanding. This
work not only pushes the boundaries of generative image compositing but also
reduces reliance on expensive annotated datasets by effectively utilizing
existing resources in innovative ways.",2024-10-24,"Lingxiao Li, Kaixiong Gong, Weihong Li, Xili Dai, Tao Chen, Xiaojun Yuan, Xiangyu Yue",http://arxiv.org/pdf/2410.19079v2,cs.LG
Target Strangeness: A Novel Conformal Prediction Difficulty Estimator,"This paper introduces Target Strangeness, a novel difficulty estimator for
conformal prediction (CP) that offers an alternative approach for normalizing
prediction intervals (PIs). By assessing how atypical a prediction is within
the context of its nearest neighbours' target distribution, Target Strangeness
can surpass the current state-of-the-art performance. This novel difficulty
estimator is evaluated against others in the context of several conformal
regression experiments.",2024-10-24,"Alexis Bose, Jonathan Ethier, Paul Guinand",http://arxiv.org/pdf/2410.19077v1,cs.LG
A Generalized Framework for Multiscale State-Space Modeling with Nested Nonlinear Dynamics: An Application to Bayesian Learning under Switching Regimes,"In this work, we introduce a generalized framework for multiscale state-space
modeling that incorporates nested nonlinear dynamics, with a specific focus on
Bayesian learning under switching regimes. Our framework captures the complex
interactions between fast and slow processes within systems, allowing for the
analysis of how these dynamics influence each other across various temporal
scales. We model these interactions through a hierarchical structure in which
finer time-scale dynamics are nested within coarser ones, while facilitating
feedback between the scales. To promote the practical application of our
framework, we address the problem of identifying switching regimes and
transient dynamics. In particular, we develop a Bayesian learning approach to
estimate latent states and indicators corresponding to switching dynamics,
enabling the model to adapt effectively to regime changes. We employ Sequential
Monte Carlo, or particle filtering, for inference. We illustrate the utility of
our framework through simulations. The results demonstrate that our Bayesian
learning approach effectively tracks state transitions and achieves accurate
identification of switching dynamics in multiscale systems.",2024-10-24,"Nayely Vélez-Cruz, Manfred D. Laubichler",http://arxiv.org/pdf/2410.19074v2,cs.LG
Less Discriminatory Alternative and Interpretable XGBoost Framework for Binary Classification,"Fair lending practices and model interpretability are crucial concerns in the
financial industry, especially given the increasing use of complex machine
learning models. In response to the Consumer Financial Protection Bureau's
(CFPB) requirement to protect consumers against unlawful discrimination, we
introduce LDA-XGB1, a novel less discriminatory alternative (LDA) machine
learning model for fair and interpretable binary classification. LDA-XGB1 is
developed through biobjective optimization that balances accuracy and fairness,
with both objectives formulated using binning and information value. It
leverages the predictive power and computational efficiency of XGBoost while
ensuring inherent model interpretability, including the enforcement of
monotonic constraints. We evaluate LDA-XGB1 on two datasets: SimuCredit, a
simulated credit approval dataset, and COMPAS, a real-world recidivism
prediction dataset. Our results demonstrate that LDA-XGB1 achieves an effective
balance between predictive accuracy, fairness, and interpretability, often
outperforming traditional fair lending models. This approach equips financial
institutions with a powerful tool to meet regulatory requirements for fair
lending while maintaining the advantages of advanced machine learning
techniques.",2024-10-24,"Andrew Pangia, Agus Sudjianto, Aijun Zhang, Taufiquar Khan",http://arxiv.org/pdf/2410.19067v1,cs.LG
An Investigation on Machine Learning Predictive Accuracy Improvement and Uncertainty Reduction using VAE-based Data Augmentation,"The confluence of ultrafast computers with large memory, rapid progress in
Machine Learning (ML) algorithms, and the availability of large datasets place
multiple engineering fields at the threshold of dramatic progress. However, a
unique challenge in nuclear engineering is data scarcity because
experimentation on nuclear systems is usually more expensive and time-consuming
than most other disciplines. One potential way to resolve the data scarcity
issue is deep generative learning, which uses certain ML models to learn the
underlying distribution of existing data and generate synthetic samples that
resemble the real data. In this way, one can significantly expand the dataset
to train more accurate predictive ML models. In this study, our objective is to
evaluate the effectiveness of data augmentation using variational autoencoder
(VAE)-based deep generative models. We investigated whether the data
augmentation leads to improved accuracy in the predictions of a deep neural
network (DNN) model trained using the augmented data. Additionally, the DNN
prediction uncertainties are quantified using Bayesian Neural Networks (BNN)
and conformal prediction (CP) to assess the impact on predictive uncertainty
reduction. To test the proposed methodology, we used TRACE simulations of
steady-state void fraction data based on the NUPEC Boiling Water Reactor
Full-size Fine-mesh Bundle Test (BFBT) benchmark. We found that augmenting the
training dataset using VAEs has improved the DNN model's predictive accuracy,
improved the prediction confidence intervals, and reduced the prediction
uncertainties.",2024-10-24,"Farah Alsafadi, Mahmoud Yaseen, Xu Wu",http://arxiv.org/pdf/2410.19063v1,cs.LG
Newton Losses: Using Curvature Information for Learning with Differentiable Algorithms,"When training neural networks with custom objectives, such as ranking losses
and shortest-path losses, a common problem is that they are, per se,
non-differentiable. A popular approach is to continuously relax the objectives
to provide gradients, enabling learning. However, such differentiable
relaxations are often non-convex and can exhibit vanishing and exploding
gradients, making them (already in isolation) hard to optimize. Here, the loss
function poses the bottleneck when training a deep neural network. We present
Newton Losses, a method for improving the performance of existing hard to
optimize losses by exploiting their second-order information via their
empirical Fisher and Hessian matrices. Instead of training the neural network
with second-order techniques, we only utilize the loss function's second-order
information to replace it by a Newton Loss, while training the network with
gradient descent. This makes our method computationally efficient. We apply
Newton Losses to eight differentiable algorithms for sorting and
shortest-paths, achieving significant improvements for less-optimized
differentiable algorithms, and consistent improvements, even for well-optimized
differentiable algorithms.",2024-10-24,"Felix Petersen, Christian Borgelt, Tobias Sutter, Hilde Kuehne, Oliver Deussen, Stefano Ermon",http://arxiv.org/pdf/2410.19055v1,cs.LG
PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views,"We propose PixelGaussian, an efficient feed-forward framework for learning
generalizable 3D Gaussian reconstruction from arbitrary views. Most existing
methods rely on uniform pixel-wise Gaussian representations, which learn a
fixed number of 3D Gaussians for each view and cannot generalize well to more
input views. Differently, our PixelGaussian dynamically adapts both the
Gaussian distribution and quantity based on geometric complexity, leading to
more efficient representations and significant improvements in reconstruction
quality. Specifically, we introduce a Cascade Gaussian Adapter to adjust
Gaussian distribution according to local geometry complexity identified by a
keypoint scorer. CGA leverages deformable attention in context-aware
hypernetworks to guide Gaussian pruning and splitting, ensuring accurate
representation in complex regions while reducing redundancy. Furthermore, we
design a transformer-based Iterative Gaussian Refiner module that refines
Gaussian representations through direct image-Gaussian interactions. Our
PixelGaussian can effectively reduce Gaussian redundancy as input views
increase. We conduct extensive experiments on the large-scale ACID and
RealEstate10K datasets, where our method achieves state-of-the-art performance
with good generalization to various numbers of views. Code:
https://github.com/Barrybarry-Smith/PixelGaussian.",2024-10-24,"Xin Fei, Wenzhao Zheng, Yueqi Duan, Wei Zhan, Masayoshi Tomizuka, Kurt Keutzer, Jiwen Lu",http://arxiv.org/pdf/2410.18979v1,cs.LG
CAMEL-Bench: A Comprehensive Arabic LMM Benchmark,"Recent years have witnessed a significant interest in developing large
multimodal models (LMMs) capable of performing various visual reasoning and
understanding tasks. This has led to the introduction of multiple LMM
benchmarks to evaluate LMMs on different tasks. However, most existing LMM
evaluation benchmarks are predominantly English-centric. In this work, we
develop a comprehensive LMM evaluation benchmark for the Arabic language to
represent a large population of over 400 million speakers. The proposed
benchmark, named CAMEL-Bench, comprises eight diverse domains and 38
sub-domains including, multi-image understanding, complex visual perception,
handwritten document understanding, video understanding, medical imaging, plant
diseases, and remote sensing-based land use understanding to evaluate broad
scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions
that are filtered from a larger pool of samples, where the quality is manually
verified by native speakers to ensure reliable model assessment. We conduct
evaluations of both closed-source, including GPT-4 series, and open-source
LMMs. Our analysis reveals the need for substantial improvement, especially
among the best open-source models, with even the closed-source GPT-4o achieving
an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.",2024-10-24,"Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Alharthi, Ines Riahi, Abduljalil Saif, Jorma Laaksonen, Fahad S. Khan, Salman Khan, Rao M. Anwer",http://arxiv.org/pdf/2410.18976v1,cs.LG
Unbounded: A Generative Infinite Game of Character Life Simulation,"We introduce the concept of a generative infinite game, a video game that
transcends the traditional boundaries of finite, hard-coded systems by using
generative models. Inspired by James P. Carse's distinction between finite and
infinite games, we leverage recent advances in generative AI to create
Unbounded: a game of character life simulation that is fully encapsulated in
generative models. Specifically, Unbounded draws inspiration from sandbox life
simulations and allows you to interact with your autonomous virtual character
in a virtual world by feeding, playing with and guiding it - with open-ended
mechanics generated by an LLM, some of which can be emergent. In order to
develop Unbounded, we propose technical innovations in both the LLM and visual
generation domains. Specifically, we present: (1) a specialized, distilled
large language model (LLM) that dynamically generates game mechanics,
narratives, and character interactions in real-time, and (2) a new dynamic
regional image prompt Adapter (IP-Adapter) for vision models that ensures
consistent yet flexible visual generation of a character across multiple
environments. We evaluate our system through both qualitative and quantitative
analysis, showing significant improvements in character life simulation, user
instruction following, narrative coherence, and visual consistency for both
characters and the environments compared to traditional related approaches.",2024-10-24,"Jialu Li, Yuanzhen Li, Neal Wadhwa, Yael Pritch, David E. Jacobs, Michael Rubinstein, Mohit Bansal, Nataniel Ruiz",http://arxiv.org/pdf/2410.18975v2,cs.LG
Tuning-free coreset Markov chain Monte Carlo,"A Bayesian coreset is a small, weighted subset of a data set that replaces
the full data during inference to reduce computational cost. The
state-of-the-art coreset construction algorithm, Coreset Markov chain Monte
Carlo (Coreset MCMC), uses draws from an adaptive Markov chain targeting the
coreset posterior to train the coreset weights via stochastic gradient
optimization. However, the quality of the constructed coreset, and thus the
quality of its posterior approximation, is sensitive to the stochastic
optimization learning rate. In this work, we propose a learning-rate-free
stochastic gradient optimization procedure, Hot-start Distance over Gradient
(Hot DoG), for training coreset weights in Coreset MCMC without user tuning
effort. Empirical results demonstrate that Hot DoG provides higher quality
posterior approximations than other learning-rate-free stochastic gradient
methods, and performs competitively to optimally-tuned ADAM.",2024-10-24,"Naitong Chen, Jonathan H. Huggins, Trevor Campbell",http://arxiv.org/pdf/2410.18973v1,cs.LG
Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques,"Cognitive decline is a natural part of aging, often resulting in reduced
cognitive abilities. In some cases, however, this decline is more pronounced,
typically due to disorders such as Alzheimer's disease. Early detection of
anomalous cognitive decline is crucial, as it can facilitate timely
professional intervention. While medical data can help in this detection, it
often involves invasive procedures. An alternative approach is to employ
non-intrusive techniques such as speech or handwriting analysis, which do not
necessarily affect daily activities. This survey reviews the most relevant
methodologies that use deep learning techniques to automate the cognitive
decline estimation task, including audio, text, and visual processing. We
discuss the key features and advantages of each modality and methodology,
including state-of-the-art approaches like Transformer architecture and
foundation models. In addition, we present works that integrate different
modalities to develop multimodal models. We also highlight the most significant
datasets and the quantitative results from studies using these resources. From
this review, several conclusions emerge. In most cases, the textual modality
achieves the best results and is the most relevant for detecting cognitive
decline. Moreover, combining various approaches from individual modalities into
a multimodal model consistently enhances performance across nearly all
scenarios.",2024-10-24,"David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez, David Tomás, M. Flores Vizcaya-Moreno",http://arxiv.org/pdf/2410.18972v1,cs.LG
WASP: A Weight-Space Approach to Detecting Learned Spuriousness,"It is of crucial importance to train machine learning models such that they
clearly understand what defines each class in a given task. Though there is a
sum of works dedicated to identifying the spurious correlations featured by a
dataset that may impact the model's understanding of the classes, all current
approaches rely solely on data or error analysis. That is, they cannot point
out spurious correlations learned by the model that are not already pointed out
by the counterexamples featured in the validation or training sets. We propose
a method that transcends this limitation, switching the focus from analyzing a
model's predictions to analyzing the model's weights, the mechanism behind the
making of the decisions, which proves to be more insightful. Our proposed
Weight-space Approach to detecting Spuriousness (WASP) relies on analyzing the
weights of foundation models as they drift towards capturing various (spurious)
correlations while being fine-tuned on a given dataset. We demonstrate that
different from previous works, our method (i) can expose spurious correlations
featured by a dataset even when they are not exposed by training or validation
counterexamples, (ii) it works for multiple modalities such as image and text,
and (iii) it can uncover previously untapped spurious correlations learned by
ImageNet-1k classifiers.",2024-10-24,"Cristian Daniel Păduraru, Antonio Bărbălau, Radu Filipescu, Andrei Liviu Nicolicioiu, Elena Burceanu",http://arxiv.org/pdf/2410.18970v3,cs.LG
Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms,"Building a generalist model for user interface (UI) understanding is
challenging due to various foundational issues, such as platform diversity,
resolution variation, and data limitation. In this paper, we introduce
Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI
understanding across a wide range of platforms, including iPhone, Android,
iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI
2 introduces three key innovations: support for multiple platform types,
high-resolution perception through adaptive scaling, and advanced task training
data generation powered by GPT-4o with set-of-mark visual prompting. These
advancements enable Ferret-UI 2 to perform complex, user-centered interactions,
making it highly versatile and adaptable for the expanding diversity of
platform ecosystems. Extensive empirical experiments on referring, grounding,
user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE
next-action prediction dataset, and GUI-World multi-platform benchmark
demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also
shows strong cross-platform transfer capabilities.",2024-10-24,"Zhangheng Li, Keen You, Haotian Zhang, Di Feng, Harsh Agrawal, Xiujun Li, Mohana Prasad Sathya Moorthy, Jeff Nichols, Yinfei Yang, Zhe Gan",http://arxiv.org/pdf/2410.18967v2,cs.LG
On the Crucial Role of Initialization for Matrix Factorization,"This work revisits the classical low-rank matrix factorization problem and
unveils the critical role of initialization in shaping convergence rates for
such nonconvex and nonsmooth optimization. We introduce Nystrom initialization,
which significantly improves the global convergence of Scaled Gradient Descent
(ScaledGD) in both symmetric and asymmetric matrix factorization tasks.
Specifically, we prove that ScaledGD with Nystrom initialization achieves
quadratic convergence in cases where only linear rates were previously known.
Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly
used for finetuning foundation models. Our approach, NoRA, i.e., LoRA with
Nystrom initialization, demonstrates superior performance across various
downstream tasks and model scales, from 1B to 7B parameters, in large language
and diffusion models.",2024-10-24,"Bingcong Li, Liang Zhang, Aryan Mokhtari, Niao He",http://arxiv.org/pdf/2410.18965v3,cs.LG
Learning to Look: Seeking Information for Decision Making via Policy Factorization,"Many robot manipulation tasks require active or interactive exploration
behavior in order to be performed successfully. Such tasks are ubiquitous in
embodied domains, where agents must actively search for the information
necessary for each stage of a task, e.g., moving the head of the robot to find
information relevant to manipulation, or in multi-robot domains, where one
scout robot may search for the information that another robot needs to make
informed decisions. We identify these tasks with a new type of problem,
factorized Contextual Markov Decision Processes, and propose DISaM, a
dual-policy solution composed of an information-seeking policy that explores
the environment to find the relevant contextual information and an
information-receiving policy that exploits the context to achieve the
manipulation goal. This factorization allows us to train both policies
separately, using the information-receiving one to provide reward to train the
information-seeking policy. At test time, the dual agent balances exploration
and exploitation based on the uncertainty the manipulation policy has on what
the next best action is. We demonstrate the capabilities of our dual policy
solution in five manipulation tasks that require information-seeking behaviors,
both in simulation and in the real-world, where DISaM significantly outperforms
existing methods. More information at
https://robin-lab.cs.utexas.edu/learning2look/.",2024-10-24,"Shivin Dass, Jiaheng Hu, Ben Abbatematteo, Peter Stone, Roberto Martín-Martín",http://arxiv.org/pdf/2410.18964v1,cs.LG
Context is Key: A Benchmark for Forecasting with Essential Textual Information,"Forecasting is a critical task in decision-making across numerous domains.
While historical numerical data provide a start, they fail to convey the
complete context for reliable and accurate predictions. Human forecasters
frequently rely on additional information, such as background knowledge and
constraints, which can efficiently be communicated through natural language.
However, in spite of recent progress with LLM-based forecasters, their ability
to effectively integrate this textual information remains an open question. To
address this, we introduce ""Context is Key"" (CiK), a time-series forecasting
benchmark that pairs numerical data with diverse types of carefully crafted
textual context, requiring models to integrate both modalities; crucially,
every task in CiK requires understanding textual context to be solved
successfully. We evaluate a range of approaches, including statistical models,
time series foundation models, and LLM-based forecasters, and propose a simple
yet effective LLM prompting method that outperforms all other tested methods on
our benchmark. Our experiments highlight the importance of incorporating
contextual information, demonstrate surprising performance when using LLM-based
forecasting models, and also reveal some of their critical shortcomings. This
benchmark aims to advance multimodal forecasting by promoting models that are
both accurate and accessible to decision-makers with varied technical
expertise. The benchmark can be visualized at
https://servicenow.github.io/context-is-key-forecasting/v0/.",2024-10-24,"Andrew Robert Williams, Arjun Ashok, Étienne Marcotte, Valentina Zantedeschi, Jithendaraa Subramanian, Roland Riachi, James Requeima, Alexandre Lacoste, Irina Rish, Nicolas Chapados, Alexandre Drouin",http://arxiv.org/pdf/2410.18959v3,cs.LG
Stable Consistency Tuning: Understanding and Improving Consistency Models,"Diffusion models achieve superior generation quality but suffer from slow
generation speed due to the iterative nature of denoising. In contrast,
consistency models, a new generative family, achieve competitive performance
with significantly faster sampling. These models are trained either through
consistency distillation, which leverages pretrained diffusion models, or
consistency training/tuning directly from raw data. In this work, we propose a
novel framework for understanding consistency models by modeling the denoising
process of the diffusion model as a Markov Decision Process (MDP) and framing
consistency model training as the value estimation through Temporal
Difference~(TD) Learning. More importantly, this framework allows us to analyze
the limitations of current consistency training/tuning strategies. Built upon
Easy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT),
which incorporates variance-reduced learning using the score identity. SCT
leads to significant performance improvements on benchmarks such as CIFAR-10
and ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID
1.55, a new SoTA for consistency models.",2024-10-24,"Fu-Yun Wang, Zhengyang Geng, Hongsheng Li",http://arxiv.org/pdf/2410.18958v3,cs.LG
Mixture of Parrots: Experts improve memorization more than reasoning,"The Mixture-of-Experts (MoE) architecture enables a significant increase in
the total number of model parameters with minimal computational overhead.
However, it is not clear what performance tradeoffs, if any, exist between MoEs
and standard dense transformers. In this paper, we show that as we increase the
number of experts (while fixing the number of active parameters), the
memorization performance consistently increases while the reasoning
capabilities saturate. We begin by analyzing the theoretical limitations of
MoEs at reasoning. We prove that there exist graph problems that cannot be
solved by any number of experts of a certain width; however, the same task can
be easily solved by a dense model with a slightly larger width. On the other
hand, we find that on memory-intensive tasks, MoEs can effectively leverage a
small number of active parameters with a large number of experts to memorize
the data. We empirically validate these findings on synthetic graph problems
and memory-intensive closed book retrieval tasks. Lastly, we pre-train a series
of MoEs and dense transformers and evaluate them on commonly used benchmarks in
math and natural language. We find that increasing the number of experts helps
solve knowledge-intensive tasks, but fails to yield the same benefits for
reasoning tasks.",2024-10-24,"Samy Jelassi, Clara Mohri, David Brandfonbrener, Alex Gu, Nikhil Vyas, Nikhil Anand, David Alvarez-Melis, Yuanzhi Li, Sham M. Kakade, Eran Malach",http://arxiv.org/pdf/2410.19034v2,cs.LG
Learning Structured Compressed Sensing with Automatic Resource Allocation,"Multidimensional data acquisition often requires extensive time and poses
significant challenges for hardware and software regarding data storage and
processing. Rather than designing a single compression matrix as in
conventional compressed sensing, structured compressed sensing yields
dimension-specific compression matrices, reducing the number of optimizable
parameters. Recent advances in machine learning (ML) have enabled task-based
supervised learning of subsampling matrices, albeit at the expense of complex
downstream models. Additionally, the sampling resource allocation across
dimensions is often determined in advance through heuristics. To address these
challenges, we introduce Structured COmpressed Sensing with Automatic Resource
Allocation (SCOSARA) with an information theory-based unsupervised learning
strategy. SCOSARA adaptively distributes samples across sampling dimensions
while maximizing Fisher information content. Using ultrasound localization as a
case study, we compare SCOSARA to state-of-the-art ML-based and greedy search
algorithms. Simulation results demonstrate that SCOSARA can produce
high-quality subsampling matrices that achieve lower Cram\'er-Rao Bound values
than the baselines. In addition, SCOSARA outperforms other ML-based algorithms
in terms of the number of trainable parameters, computational complexity, and
memory requirements while automatically choosing the number of samples per
axis.",2024-10-24,"Han Wang, Eduardo Pérez, Iris A. M. Huijben, Hans van Gorp, Ruud van Sloun, Florian Römer",http://arxiv.org/pdf/2410.18954v2,cs.LG
Dynamic Vocabulary Pruning in Early-Exit LLMs,"Increasing the size of large language models (LLMs) has been shown to lead to
better performance. However, this comes at the cost of slower and more
expensive inference. Early-exiting is a promising approach for improving the
efficiency of LLM inference by enabling next token prediction at intermediate
layers. Yet, the large vocabulary size in modern LLMs makes the confidence
estimation required for exit decisions computationally expensive, diminishing
the efficiency gains. To address this, we propose dynamically pruning the
vocabulary at test time for each token. Specifically, the vocabulary is pruned
at one of the initial layers, and the smaller vocabulary is then used
throughout the rest of the forward pass. Our experiments demonstrate that such
post-hoc dynamic vocabulary pruning improves the efficiency of confidence
estimation in early-exit LLMs while maintaining competitive performance.",2024-10-24,"Jort Vincenti, Karim Abdel Sadek, Joan Velja, Matteo Nulli, Metod Jazbec",http://arxiv.org/pdf/2410.18952v2,cs.LG
Adjusted Overfitting Regression,"In this paper, I will introduce a new form of regression, that can adjust
overfitting and underfitting through, ""distance-based regression."" Overfitting
often results in finding false patterns causing inaccurate results, so by
having a new approach that minimizes overfitting, more accurate predictions can
be derived. Then I will proceed with a test of my regression form and show
additional ways to optimize the regression. Finally, I will apply my new
technique to a specific data set to demonstrate its practical value.",2024-10-24,Dylan Wilson,http://arxiv.org/pdf/2410.18950v1,cs.LG
A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities,"A key property of neural networks is their capacity of adapting to data
during training. Yet, our current mathematical understanding of feature
learning and its relationship to generalization remain limited. In this work,
we provide a random matrix analysis of how fully-connected two-layer neural
networks adapt to the target function after a single, but aggressive, gradient
descent step. We rigorously establish the equivalence between the updated
features and an isotropic spiked random feature model, in the limit of large
batch size. For the latter model, we derive a deterministic equivalent
description of the feature empirical covariance matrix in terms of certain
low-dimensional operators. This allows us to sharply characterize the impact of
training in the asymptotic feature spectrum, and in particular, provides a
theoretical grounding for how the tails of the feature spectrum modify with
training. The deterministic equivalent further yields the exact asymptotic
generalization error, shedding light on the mechanisms behind its improvement
in the presence of feature learning. Our result goes beyond standard random
matrix ensembles, and therefore we believe it is of independent technical
interest. Different from previous work, our result holds in the challenging
maximal learning rate regime, is fully rigorous and allows for finitely
supported second layer initialization, which turns out to be crucial for
studying the functional expressivity of the learned features. This provides a
sharp description of the impact of feature learning in the generalization of
two-layer neural networks, beyond the random features and lazy training
regimes.",2024-10-24,"Yatin Dandi, Luca Pesce, Hugo Cui, Florent Krzakala, Yue M. Lu, Bruno Loureiro",http://arxiv.org/pdf/2410.18938v1,cs.LG
AutoStep: Locally adaptive involutive MCMC,"Many common Markov chain Monte Carlo (MCMC) kernels can be formulated using a
deterministic involutive proposal with a step size parameter. Selecting an
appropriate step size is often a challenging task in practice; and for complex
multiscale targets, there may not be one choice of step size that works well
globally. In this work, we address this problem with a novel class of
involutive MCMC methods -- AutoStep MCMC -- that selects an appropriate step
size at each iteration adapted to the local geometry of the target
distribution. We prove that under mild conditions AutoStep MCMC is
$\pi$-invariant, irreducible, and aperiodic, and obtain bounds on expected
energy jump distance and cost per iteration. Empirical results examine the
robustness and efficacy of our proposed step size selection procedure, and show
that AutoStep MCMC is competitive with state-of-the-art methods in terms of
effective sample size per unit cost on a range of challenging target
distributions.",2024-10-24,"Tiange Liu, Nikola Surjanovic, Miguel Biron-Lattes, Alexandre Bouchard-Côté, Trevor Campbell",http://arxiv.org/pdf/2410.18929v3,cs.LG
Learning $k$-body Hamiltonians via compressed sensing,"We study the problem of learning a $k$-body Hamiltonian with $M$ unknown
Pauli terms that are not necessarily geometrically local. We propose a protocol
that learns the Hamiltonian to precision $\epsilon$ with total evolution time
${\mathcal{O}}(M^{1/2+1/p}/\epsilon)$ up to logarithmic factors, where the
error is quantified by the $\ell^p$-distance between Pauli coefficients. Our
learning protocol uses only single-qubit control operations and a GHZ state
initial state, is non-adaptive, is robust against SPAM errors, and performs
well even if $M$ and $k$ are not precisely known in advance or if the
Hamiltonian is not exactly $M$-sparse. Methods from the classical theory of
compressed sensing are used for efficiently identifying the $M$ terms in the
Hamiltonian from among all possible $k$-body Pauli operators. We also provide a
lower bound on the total evolution time needed in this learning task, and we
discuss the operational interpretations of the $\ell^1$ and $\ell^2$ error
metrics. In contrast to most previous works, our learning protocol requires
neither geometric locality nor any other relaxed locality conditions.",2024-10-24,"Muzhou Ma, Steven T. Flammia, John Preskill, Yu Tong",http://arxiv.org/pdf/2410.18928v2,cs.LG
LoRANN: Low-Rank Matrix Factorization for Approximate Nearest Neighbor Search,"Approximate nearest neighbor (ANN) search is a key component in many modern
machine learning pipelines; recent use cases include retrieval-augmented
generation (RAG) and vector databases. Clustering-based ANN algorithms, that
use score computation methods based on product quantization (PQ), are often
used in industrial-scale applications due to their scalability and suitability
for distributed and disk-based implementations. However, they have slower query
times than the leading graph-based ANN algorithms. In this work, we propose a
new supervised score computation method based on the observation that inner
product approximation is a multivariate (multi-output) regression problem that
can be solved efficiently by reduced-rank regression. Our experiments show that
on modern high-dimensional data sets, the proposed reduced-rank regression
(RRR) method is superior to PQ in both query latency and memory usage. We also
introduce LoRANN, a clustering-based ANN library that leverages the proposed
score computation method. LoRANN is competitive with the leading graph-based
algorithms and outperforms the state-of-the-art GPU ANN methods on
high-dimensional data sets.",2024-10-24,"Elias Jääsaari, Ville Hyvönen, Teemu Roos",http://arxiv.org/pdf/2410.18926v1,cs.LG
Optimizing Edge Offloading Decisions for Object Detection,"Recent advances in machine learning and hardware have produced embedded
devices capable of performing real-time object detection with commendable
accuracy. We consider a scenario in which embedded devices rely on an onboard
object detector, but have the option to offload detection to a more powerful
edge server when local accuracy is deemed too low. Resource constraints,
however, limit the number of images that can be offloaded to the edge. Our goal
is to identify which images to offload to maximize overall detection accuracy
under those constraints. To that end, the paper introduces a reward metric
designed to quantify potential accuracy improvements from offloading individual
images, and proposes an efficient approach to make offloading decisions by
estimating this reward based only on local detection results. The approach is
computationally frugal enough to run on embedded devices, and empirical
findings indicate that it outperforms existing alternatives in improving
detection accuracy even when the fraction of offloaded images is small.",2024-10-24,"Jiaming Qiu, Ruiqi Wang, Brooks Hu, Roch Guerin, Chenyang Lu",http://arxiv.org/pdf/2410.18919v1,cs.LG
MissNODAG: Differentiable Cyclic Causal Graph Learning from Incomplete Data,"Causal discovery in real-world systems, such as biological networks, is often
complicated by feedback loops and incomplete data. Standard algorithms, which
assume acyclic structures or fully observed data, struggle with these
challenges. To address this gap, we propose MissNODAG, a differentiable
framework for learning both the underlying cyclic causal graph and the
missingness mechanism from partially observed data, including data missing not
at random. Our framework integrates an additive noise model with an
expectation-maximization procedure, alternating between imputing missing values
and optimizing the observed data likelihood, to uncover both the cyclic
structures and the missingness mechanism. We demonstrate the effectiveness of
MissNODAG through synthetic experiments and an application to real-world gene
perturbation data.",2024-10-24,"Muralikrishnna G. Sethuraman, Razieh Nabi, Faramarz Fekri",http://arxiv.org/pdf/2410.18918v1,cs.LG
Using Parametric PINNs for Predicting Internal and External Turbulent Flows,"Computational fluid dynamics (CFD) solvers employing two-equation eddy
viscosity models are the industry standard for simulating turbulent flows using
the Reynolds-averaged Navier-Stokes (RANS) formulation. While these methods are
computationally less expensive than direct numerical simulations, they can
still incur significant computational costs to achieve the desired accuracy. In
this context, physics-informed neural networks (PINNs) offer a promising
approach for developing parametric surrogate models that leverage both
existing, but limited CFD solutions and the governing differential equations to
predict simulation outcomes in a computationally efficient, differentiable, and
near real-time manner. In this work, we build upon the previously proposed
RANS-PINN framework, which only focused on predicting flow over a cylinder. To
investigate the efficacy of RANS-PINN as a viable approach to building
parametric surrogate models, we investigate its accuracy in predicting relevant
turbulent flow variables for both internal and external flows. To ensure
training convergence with a more complex loss function, we adopt a novel
sampling approach that exploits the domain geometry to ensure a proper balance
among the contributions from various regions within the solution domain. The
effectiveness of this framework is then demonstrated for two scenarios that
represent a broad class of internal and external flow problems.",2024-10-24,"Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey",http://arxiv.org/pdf/2410.18917v1,cs.LG
Testing Support Size More Efficiently Than Learning Histograms,"Consider two problems about an unknown probability distribution $p$:
  1. How many samples from $p$ are required to test if $p$ is supported on $n$
elements or not? Specifically, given samples from $p$, determine whether it is
supported on at most $n$ elements, or it is ""$\epsilon$-far"" (in total
variation distance) from being supported on $n$ elements.
  2. Given $m$ samples from $p$, what is the largest lower bound on its support
size that we can produce?
  The best known upper bound for problem (1) uses a general algorithm for
learning the histogram of the distribution $p$, which requires
$\Theta(\tfrac{n}{\epsilon^2 \log n})$ samples. We show that testing can be
done more efficiently than learning the histogram, using only
$O(\tfrac{n}{\epsilon \log n} \log(1/\epsilon))$ samples, nearly matching the
best known lower bound of $\Omega(\tfrac{n}{\epsilon \log n})$. This algorithm
also provides a better solution to problem (2), producing larger lower bounds
on support size than what follows from previous work. The proof relies on an
analysis of Chebyshev polynomial approximations outside the range where they
are designed to be good approximations, and the paper is intended as an
accessible self-contained exposition of the Chebyshev polynomial method.",2024-10-24,"Renato Ferreira Pinto Jr., Nathaniel Harms",http://arxiv.org/pdf/2410.18915v2,cs.LG
Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling,"Videos of robots interacting with objects encode rich information about the
objects' dynamics. However, existing video prediction approaches typically do
not explicitly account for the 3D information from videos, such as robot
actions and objects' 3D states, limiting their use in real-world robotic
applications. In this work, we introduce a framework to learn object dynamics
directly from multi-view RGB videos by explicitly considering the robot's
action trajectories and their effects on scene dynamics. We utilize the 3D
Gaussian representation of 3D Gaussian Splatting (3DGS) to train a
particle-based dynamics model using Graph Neural Networks. This model operates
on sparse control particles downsampled from the densely tracked 3D Gaussian
reconstructions. By learning the neural dynamics model on offline robot
interaction data, our method can predict object motions under varying initial
configurations and unseen robot actions. The 3D transformations of Gaussians
can be interpolated from the motions of control particles, enabling the
rendering of predicted future object states and achieving action-conditioned
video prediction. The dynamics model can also be applied to model-based
planning frameworks for object manipulation tasks. We conduct experiments on
various kinds of deformable materials, including ropes, clothes, and stuffed
animals, demonstrating our framework's ability to model complex shapes and
dynamics. Our project page is available at https://gs-dynamics.github.io.",2024-10-24,"Mingtong Zhang, Kaifeng Zhang, Yunzhu Li",http://arxiv.org/pdf/2410.18912v1,cs.LG
SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment,"Imitation learning from human demonstrations is an effective paradigm for
robot manipulation, but acquiring large datasets is costly and
resource-intensive, especially for long-horizon tasks. To address this issue,
we propose SkillMimicGen (SkillGen), an automated system for generating
demonstration datasets from a few human demos. SkillGen segments human demos
into manipulation skills, adapts these skills to new contexts, and stitches
them together through free-space transit and transfer motion. We also propose a
Hybrid Skill Policy (HSP) framework for learning skill initiation, control, and
termination components from SkillGen datasets, enabling skills to be sequenced
using motion planning at test-time. We demonstrate that SkillGen greatly
improves data generation and policy learning performance over a
state-of-the-art data generation framework, resulting in the capability to
produce data for large scene variations, including clutter, and agents that are
on average 24% more successful. We demonstrate the efficacy of SkillGen by
generating over 24K demonstrations across 18 task variants in simulation from
just 60 human demonstrations, and training proficient, often near-perfect, HSP
agents. Finally, we apply SkillGen to 3 real-world manipulation tasks and also
demonstrate zero-shot sim-to-real transfer on a long-horizon assembly task.
Videos, and more at https://skillgen.github.io.",2024-10-24,"Caelan Garrett, Ajay Mandlekar, Bowen Wen, Dieter Fox",http://arxiv.org/pdf/2410.18907v1,cs.LG
Modulated Adaptive Fourier Neural Operators for Temporal Interpolation of Weather Forecasts,"Weather and climate data are often available at limited temporal resolution,
either due to storage limitations, or in the case of weather forecast models
based on deep learning, their inherently long time steps. The coarse temporal
resolution makes it difficult to capture rapidly evolving weather events. To
address this limitation, we introduce an interpolation model that reconstructs
the atmospheric state between two points in time for which the state is known.
The model makes use of a novel network layer that modifies the adaptive Fourier
neural operator (AFNO), which has been previously used in weather prediction
and other applications of machine learning to physics problems. The modulated
AFNO (ModAFNO) layer takes an embedding, here computed from the interpolation
target time, as an additional input and applies a learned shift-scale operation
inside the AFNO layers to adapt them to the target time. Thus, one model can be
used to produce all intermediate time steps. Trained to interpolate between two
time steps 6 h apart, the ModAFNO-based interpolation model produces 1 h
resolution intermediate time steps that are visually nearly indistinguishable
from the actual corresponding 1 h resolution data. The model reduces the RMSE
loss of reconstructing the intermediate steps by approximately 50% compared to
linear interpolation. We also demonstrate its ability to reproduce the
statistics of extreme weather events such as hurricanes and heat waves better
than 6 h resolution data. The ModAFNO layer is generic and is expected to be
applicable to other problems, including weather forecasting with tunable lead
time.",2024-10-24,"Jussi Leinonen, Boris Bonev, Thorsten Kurth, Yair Cohen",http://arxiv.org/pdf/2410.18904v1,cs.LG
"ArterialNet: Reconstructing Arterial Blood Pressure Waveform with Wearable Pulsatile Signals, a Cohort-Aware Approach","Continuous arterial blood pressure (ABP) monitoring is invasive but essential
for hemodynamic monitoring. Recent techniques have reconstructed ABP
non-invasively using pulsatile signals but produced inaccurate systolic and
diastolic blood pressure (SBP and DBP) values and were sensitive to individual
variability. ArterialNet integrates generalized pulsatile-to-ABP signal
translation and personalized feature extraction using hybrid loss functions and
regularization. We validated ArterialNet using the MIMIC-III dataset and
achieved a root mean square error (RMSE) of 5.41 mmHg, with at least a 58%
lower standard deviation. ArterialNet reconstructed ABP with an RMSE of 7.99
mmHg in remote health scenarios. ArterialNet achieved superior performance in
ABP reconstruction and SBP and DBP estimations, with significantly reduced
subject variance, demonstrating its potential in remote health settings. We
also ablated ArterialNet architecture to investigate the contributions of each
component and evaluated its translational impact and robustness by conducting a
series of ablations on data quality and availability.",2024-10-24,"Sicong Huang, Roozbeh Jafari, Bobak J. Mortazavi",http://arxiv.org/pdf/2410.18895v2,cs.LG
Meta-Learning with Heterogeneous Tasks,"Meta-learning is a general approach to equip machine learning models with the
ability to handle few-shot scenarios when dealing with many tasks. Most
existing meta-learning methods work based on the assumption that all tasks are
of equal importance. However, real-world applications often present
heterogeneous tasks characterized by varying difficulty levels, noise in
training samples, or being distinctively different from most other tasks. In
this paper, we introduce a novel meta-learning method designed to effectively
manage such heterogeneous tasks by employing rank-based task-level learning
objectives, Heterogeneous Tasks Robust Meta-learning (HeTRoM). HeTRoM is
proficient in handling heterogeneous tasks, and it prevents easy tasks from
overwhelming the meta-learner. The approach allows for an efficient iterative
optimization algorithm based on bi-level optimization, which is then improved
by integrating statistical guidance. Our experimental results demonstrate that
our method provides flexibility, enabling users to adapt to diverse task
settings and enhancing the meta-learner's overall performance.",2024-10-24,"Zhaofeng Si, Shu Hu, Kaiyi Ji, Siwei Lyu",http://arxiv.org/pdf/2410.18894v1,cs.LG
Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences,"One-step text-to-image generator models offer advantages such as swift
inference efficiency, flexible architectures, and state-of-the-art generation
performance. In this paper, we study the problem of aligning one-step generator
models with human preferences for the first time. Inspired by the success of
reinforcement learning using human feedback (RLHF), we formulate the alignment
problem as maximizing expected human reward functions while adding an Integral
Kullback-Leibler divergence term to prevent the generator from diverging. By
overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the
first, fast-converging and image data-free human preference alignment method
for one-step text-to-image generators. We also introduce novel theoretical
insights, showing that using CFG for diffusion distillation is secretly doing
RLHF with DI++. Such an interesting finding brings understanding and potential
contributions to future research involving CFG. In the experiment sections, we
align both UNet-based and DiT-based one-step generators using DI++, which use
the Stable Diffusion 1.5 and the PixelArt-$\alpha$ as the reference diffusion
processes. The resulting DiT-based one-step text-to-image model achieves a
strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO
validation prompt dataset. It also achieves a leading Human preference Score
(HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable
Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\alpha$. Both theoretical
contributions and empirical evidence indicate that DI++ is a strong
human-preference alignment approach for one-step text-to-image models.",2024-10-24,Weijian Luo,http://arxiv.org/pdf/2410.18881v1,cs.LG
Exploring the Universe with SNAD: Anomaly Detection in Astronomy,"SNAD is an international project with a primary focus on detecting
astronomical anomalies within large-scale surveys, using active learning and
other machine learning algorithms. The work carried out by SNAD not only
contributes to the discovery and classification of various astronomical
phenomena but also enhances our understanding and implementation of machine
learning techniques within the field of astrophysics. This paper provides a
review of the SNAD project and summarizes the advancements and achievements
made by the team over several years.",2024-10-24,"Alina A. Volnova, Patrick D. Aleo, Anastasia Lavrukhina, Etienne Russeil, Timofey Semenikhin, Emmanuel Gangler, Emille E. O. Ishida, Matwey V. Kornilov, Vladimir Korolev, Konstantin Malanchev, Maria V. Pruzhinskaya, Sreevarsha Sreejith",http://arxiv.org/pdf/2410.18875v1,cs.LG
End-to-end Training for Recommendation with Language-based User Profiles,"There is a growing interest in natural language-based user profiles for
recommender systems, which aims to enhance transparency and scrutability
compared with embedding-based methods. Existing studies primarily generate
these profiles using zero-shot inference from large language models (LLMs), but
their quality remains insufficient, leading to suboptimal recommendation
performance. In this paper, we introduce LangPTune, the first end-to-end
training framework to optimize LLM-generated user profiles. Our method
significantly outperforms zero-shot approaches by explicitly training the LLM
for the recommendation objective. Through extensive evaluations across diverse
training configurations and benchmarks, we demonstrate that LangPTune not only
surpasses zero-shot baselines but can also matches the performance of
state-of-the-art embedding-based methods. Finally, we investigate whether the
training procedure preserves the interpretability of these profiles compared to
zero-shot inference through both GPT-4 simulations and crowdworker user
studies. Implementation of LangPTune can be found at
https://github.com/ZhaolinGao/LangPTune.",2024-10-24,"Zhaolin Gao, Joyce Zhou, Yijia Dai, Thorsten Joachims",http://arxiv.org/pdf/2410.18870v2,cs.LG
A Riemannian Framework for Learning Reduced-order Lagrangian Dynamics,"By incorporating physical consistency as inductive bias, deep neural networks
display increased generalization capabilities and data efficiency in learning
nonlinear dynamic models. However, the complexity of these models generally
increases with the system dimensionality, requiring larger datasets, more
complex deep networks, and significant computational effort. We propose a novel
geometric network architecture to learn physically-consistent reduced-order
dynamic parameters that accurately describe the original high-dimensional
system behavior. This is achieved by building on recent advances in model-order
reduction and by adopting a Riemannian perspective to jointly learn a
non-linear structure-preserving latent space and the associated low-dimensional
dynamics. Our approach enables accurate long-term predictions of the
high-dimensional dynamics of rigid and deformable systems with increased data
efficiency by inferring interpretable and physically-plausible reduced
Lagrangian models.",2024-10-24,"Katharina Friedl, Noémie Jaquier, Jens Lundell, Tamim Asfour, Danica Kragic",http://arxiv.org/pdf/2410.18868v3,cs.LG
Omics-driven hybrid dynamic modeling of bioprocesses with uncertainty estimation,"This work presents an omics-driven modeling pipeline that integrates
machine-learning tools to facilitate the dynamic modeling of multiscale
biological systems. Random forests and permutation feature importance are
proposed to mine omics datasets, guiding feature selection and dimensionality
reduction for dynamic modeling. Continuous and differentiable machine-learning
functions can be trained to link the reduced omics feature set to key
components of the dynamic model, resulting in a hybrid model. As proof of
concept, we apply this framework to a high-dimensional proteomics dataset of
$\textit{Saccharomyces cerevisiae}$. After identifying key intracellular
proteins that correlate with cell growth, targeted dynamic experiments are
designed, and key model parameters are captured as functions of the selected
proteins using Gaussian processes. This approach captures the dynamic behavior
of yeast strains under varying proteome profiles while estimating the
uncertainty in the hybrid model's predictions. The outlined modeling framework
is adaptable to other scenarios, such as integrating additional layers of omics
data for more advanced multiscale biological systems, or employing alternative
machine-learning methods to handle larger datasets. Overall, this study
outlines a strategy for leveraging omics data to inform multiscale dynamic
modeling in systems biology and bioprocess engineering.",2024-10-24,"Sebastián Espinel-Ríos, José Montaño López, José L. Avalos",http://arxiv.org/pdf/2410.18864v2,cs.LG
FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning,"Federated learning has recently gained popularity as a framework for
distributed clients to collaboratively train a machine learning model using
local data. While traditional federated learning relies on a central server for
model aggregation, recent advancements adopt a decentralized framework,
enabling direct model exchange between clients and eliminating the single point
of failure. However, existing decentralized frameworks often assume all clients
train a shared model. Personalizing each client's model can enhance
performance, especially with heterogeneous client data distributions. We
propose FedSPD, an efficient personalized federated learning algorithm for the
decentralized setting, and show that it learns accurate models even in
low-connectivity networks. To provide theoretical guarantees on convergence, we
introduce a clustering-based framework that enables consensus on models for
distinct data clusters while personalizing to unique mixtures of these clusters
at different clients. This flexibility, allowing selective model updates based
on data distribution, substantially reduces communication costs compared to
prior work on personalized federated learning in decentralized settings.
Experimental results on real-world datasets show that FedSPD outperforms
multiple decentralized variants of personalized federated learning algorithms,
especially in scenarios with low-connectivity networks.",2024-10-24,"I-Cheng Lin, Osman Yagan, Carlee Joe-Wong",http://arxiv.org/pdf/2410.18862v1,cs.LG
Bilinear Sequence Regression: A Model for Learning from Long Sequences of High-dimensional Tokens,"Current progress in artificial intelligence is centered around so-called
large language models that consist of neural networks processing long sequences
of high-dimensional vectors called tokens. Statistical physics provides
powerful tools to study the functioning of learning with neural networks and
has played a recognized role in the development of modern machine learning. The
statistical physics approach relies on simplified and analytically tractable
models of data. However, simple tractable models for long sequences of
high-dimensional tokens are largely underexplored. Inspired by the crucial role
models such as the single-layer teacher-student perceptron (aka generalized
linear regression) played in the theory of fully connected neural networks, in
this paper, we introduce and study the bilinear sequence regression (BSR) as
one of the most basic models for sequences of tokens. We note that modern
architectures naturally subsume the BSR model due to the skip connections.
Building on recent methodological progress, we compute the Bayes-optimal
generalization error for the model in the limit of long sequences of
high-dimensional tokens, and provide a message-passing algorithm that matches
this performance. We quantify the improvement that optimal learning brings with
respect to vectorizing the sequence of tokens and learning via simple linear
regression. We also unveil surprising properties of the gradient descent
algorithms in the BSR model.",2024-10-24,"Vittorio Erba, Emanuele Troiani, Luca Biggio, Antoine Maillard, Lenka Zdeborová",http://arxiv.org/pdf/2410.18858v2,cs.LG
Probabilistic Language-Image Pre-Training,"Vision-language models (VLMs) embed aligned image-text pairs into a joint
space but often rely on deterministic embeddings, assuming a one-to-one
correspondence between images and texts. This oversimplifies real-world
relationships, which are inherently many-to-many, with multiple captions
describing a single image and vice versa. We introduce Probabilistic
Language-Image Pre-training (ProLIP), the first probabilistic VLM pre-trained
on a billion-scale image-text dataset using only probabilistic objectives,
achieving a strong zero-shot capability (e.g., 74.6% ImageNet zero-shot
accuracy with ViT-B/16). ProLIP efficiently estimates uncertainty by an
""uncertainty token"" without extra parameters. We also introduce a novel
inclusion loss that enforces distributional inclusion relationships between
image-text pairs and between original and masked inputs. Experiments
demonstrate that, by leveraging uncertainty estimates, ProLIP benefits
downstream tasks and aligns with intuitive notions of uncertainty, e.g.,
shorter texts being more uncertain and more general inputs including specific
ones. Utilizing text uncertainties, we further improve ImageNet accuracy from
74.6% to 75.8% (under a few-shot setting), supporting the practical advantages
of our probabilistic approach. The code is available at
https://github.com/naver-ai/prolip",2024-10-24,"Sanghyuk Chun, Wonjae Kim, Song Park, Sangdoo Yun",http://arxiv.org/pdf/2410.18857v3,cs.LG
Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints,"Pure exploration in bandits models multiple real-world problems, such as
tuning hyper-parameters or conducting user studies, where different safety,
resource, and fairness constraints on the decision space naturally appear. We
study these problems as pure exploration in multi-armed bandits with unknown
linear constraints, where the aim is to identify an $r$$\textit{-good feasible
policy}$. First, we propose a Lagrangian relaxation of the sample complexity
lower bound for pure exploration under constraints. We show how this lower
bound evolves with the sequential estimation of constraints. Second, we
leverage the Lagrangian lower bound and the properties of convex optimisation
to propose two computationally efficient extensions of Track-and-Stop and
Gamified Explorer, namely LATS and LAGEX. To this end, we propose a
constraint-adaptive stopping rule, and while tracking the lower bound, use
pessimistic estimate of the feasible set at each step. We show that these
algorithms achieve asymptotically optimal sample complexity upper bounds up to
constraint-dependent constants. Finally, we conduct numerical experiments with
different reward distributions and constraints that validate efficient
performance of LAGEX and LATS with respect to baselines.",2024-10-24,"Udvas Das, Debabrota Basu",http://arxiv.org/pdf/2410.18844v1,cs.LG
From Efficiency to Equity: Measuring Fairness in Preference Learning,"As AI systems, particularly generative models, increasingly influence
decision-making, ensuring that they are able to fairly represent diverse human
preferences becomes crucial. This paper introduces a novel framework for
evaluating epistemic fairness in preference learning models inspired by
economic theories of inequality and Rawlsian justice. We propose metrics
adapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to
quantify fairness in these models. We validate our approach using two datasets:
a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.
Our analysis reveals variations in model performance across users, highlighting
potential epistemic injustices. We explore pre-processing and in-processing
techniques to mitigate these inequalities, demonstrating a complex relationship
between model efficiency and fairness. This work contributes to AI ethics by
providing a framework for evaluating and improving epistemic fairness in
preference learning models, offering insights for developing more inclusive AI
systems in contexts where diverse human preferences are crucial.",2024-10-24,"Shreeyash Gowaikar, Hugo Berard, Rashid Mushkani, Shin Koseki",http://arxiv.org/pdf/2410.18841v1,cs.LG
High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws,"A growing number of machine learning scenarios rely on knowledge distillation
where one uses the output of a surrogate model as labels to supervise the
training of a target model. In this work, we provide a sharp characterization
of this process for ridgeless, high-dimensional regression, under two settings:
(i) model shift, where the surrogate model is arbitrary, and (ii) distribution
shift, where the surrogate model is the solution of empirical risk minimization
with out-of-distribution data. In both cases, we characterize the precise risk
of the target model through non-asymptotic bounds in terms of sample size and
data distribution under mild conditions. As a consequence, we identify the form
of the optimal surrogate model, which reveals the benefits and limitations of
discarding weak features in a data-dependent fashion. In the context of
weak-to-strong (W2S) generalization, this has the interpretation that (i) W2S
training, with the surrogate as the weak model, can provably outperform
training with strong labels under the same data budget, but (ii) it is unable
to improve the data scaling law. We validate our results on numerical
experiments both on ridgeless regression and on neural network architectures.",2024-10-24,"M. Emrullah Ildiz, Halil Alperen Gozeten, Ege Onur Taga, Marco Mondelli, Samet Oymak",http://arxiv.org/pdf/2410.18837v2,cs.LG
Highly efficient non-rigid registration in k-space with application to cardiac Magnetic Resonance Imaging,"In Magnetic Resonance Imaging (MRI), high temporal-resolved motion can be
useful for image acquisition and reconstruction, MR-guided radiotherapy,
dynamic contrast-enhancement, flow and perfusion imaging, and functional
assessment of motion patterns in cardiovascular, abdominal, peristaltic, fetal,
or musculoskeletal imaging. Conventionally, these motion estimates are derived
through image-based registration, a particularly challenging task for complex
motion patterns and high dynamic resolution. The accelerated scans in such
applications result in imaging artifacts that compromise the motion estimation.
In this work, we propose a novel self-supervised deep learning-based framework,
dubbed the Local-All Pass Attention Network (LAPANet), for non-rigid motion
estimation directly from the acquired accelerated Fourier space, i.e. k-space.
The proposed approach models non-rigid motion as the cumulative sum of local
translational displacements, following the Local All-Pass (LAP) registration
technique. LAPANet was evaluated on cardiac motion estimation across various
sampling trajectories and acceleration rates. Our results demonstrate superior
accuracy compared to prior conventional and deep learning-based registration
methods, accommodating as few as 2 lines/frame in a Cartesian trajectory and 3
spokes/frame in a non-Cartesian trajectory. The achieved high temporal
resolution (less than 5 ms) for non-rigid motion opens new avenues for motion
detection, tracking and correction in dynamic and real-time MRI applications.",2024-10-24,"Aya Ghoul, Kerstin Hammernik, Andreas Lingg, Patrick Krumm, Daniel Rueckert, Sergios Gatidis, Thomas Küstner",http://arxiv.org/pdf/2410.18834v1,cs.LG
"MazeNet: An Accurate, Fast, and Scalable Deep Learning Solution for Steiner Minimum Trees","The Obstacle Avoiding Rectilinear Steiner Minimum Tree (OARSMT) problem,
which seeks the shortest interconnection of a given number of terminals in a
rectilinear plane while avoiding obstacles, is a critical task in integrated
circuit design, network optimization, and robot path planning. Since OARSMT is
NP-hard, exact algorithms scale poorly with the number of terminals, leading
practical solvers to sacrifice accuracy for large problems. We propose MazeNet,
a deep learning-based method that learns to solve the OARSMT from data. MazeNet
reframes OARSMT as a maze-solving task that can be addressed with a recurrent
convolutional neural network (RCNN). A key hallmark of MazeNet is its
scalability: we only need to train the RCNN blocks on mazes with a small number
of terminals; larger mazes can be solved by replicating the same pre-trained
blocks to create a larger network. Across a wide range of experiments, MazeNet
achieves perfect OARSMT-solving accuracy, significantly reduces runtime
compared to classical exact algorithms, and can handle more terminals than
state-of-the-art approximate algorithms.",2024-10-24,"Gabriel Díaz Ramos, Toros Arikan, Richard G. Baraniuk",http://arxiv.org/pdf/2410.18832v2,cs.LG
From Imitation to Introspection: Probing Self-Consciousness in Language Models,"Self-consciousness, the introspection of one's existence and thoughts,
represents a high-level cognitive process. As language models advance at an
unprecedented pace, a critical question arises: Are these models becoming
self-conscious? Drawing upon insights from psychological and neural science,
this work presents a practical definition of self-consciousness for language
models and refines ten core concepts. Our work pioneers an investigation into
self-consciousness in language models by, for the first time, leveraging causal
structural games to establish the functional definitions of the ten core
concepts. Based on our definitions, we conduct a comprehensive four-stage
experiment: quantification (evaluation of ten leading models), representation
(visualization of self-consciousness within the models), manipulation
(modification of the models' representation), and acquisition (fine-tuning the
models on core concepts). Our findings indicate that although models are in the
early stages of developing self-consciousness, there is a discernible
representation of certain concepts within their internal mechanisms. However,
these representations of self-consciousness are hard to manipulate positively
at the current stage, yet they can be acquired through targeted fine-tuning.
Our datasets and code are at https://github.com/OpenCausaLab/SelfConsciousness.",2024-10-24,"Sirui Chen, Shu Yu, Shengjie Zhao, Chaochao Lu",http://arxiv.org/pdf/2410.18819v1,cs.LG
A Combinatorial Approach to Neural Emergent Communication,"Substantial research on deep learning-based emergent communication uses the
referential game framework, specifically the Lewis signaling game, however we
argue that successful communication in this game typically only need one or two
symbols for target image classification because of a sampling pitfall in the
training data. To address this issue, we provide a theoretical analysis and
introduce a combinatorial algorithm SolveMinSym (SMS) to solve the symbolic
complexity for classification, which is the minimum number of symbols in the
message for successful communication. We use the SMS algorithm to create
datasets with different symbolic complexity to empirically show that data with
higher symbolic complexity increases the number of effective symbols in the
emergent language.",2024-10-24,Zheyuan Zhang,http://arxiv.org/pdf/2410.18806v2,cs.LG
Fast constrained sampling in pre-trained diffusion models,"Large denoising diffusion models, such as Stable Diffusion, have been trained
on billions of image-caption pairs to perform text-conditioned image
generation. As a byproduct of this training, these models have acquired general
knowledge about image statistics, which can be useful for other inference
tasks. However, when confronted with sampling an image under new constraints,
e.g. generating the missing parts of an image, using large pre-trained
text-to-image diffusion models is inefficient and often unreliable. Previous
approaches either utilize backpropagation, making them significantly slower and
more memory-demanding than text-to-image inference, or only enforce the
constraint locally, failing to capture critical long-range correlations. In
this work, we propose an algorithm that enables fast and high-quality
generation under arbitrary constraints. We observe that, during inference, we
can interchange between gradient updates computed on the noisy image and
updates computed on the final, clean image. This allows us to employ a
numerical approximation to expensive gradient computations, incurring
significant speed-ups in inference. Our approach produces results that rival or
surpass the state-of-the-art training-free inference approaches while requiring
a fraction of the time. We demonstrate the effectiveness of our algorithm under
both linear and non-linear constraints. An implementation is provided at
https://github.com/cvlab-stonybrook/fast-constrained-sampling.",2024-10-24,"Alexandros Graikos, Nebojsa Jojic, Dimitris Samaras",http://arxiv.org/pdf/2410.18804v2,cs.LG
Language-Agnostic Modeling of Source Reliability on Wikipedia,"Over the last few years, content verification through reliable sources has
become a fundamental need to combat disinformation. Here, we present a
language-agnostic model designed to assess the reliability of sources across
multiple language editions of Wikipedia. Utilizing editorial activity data, the
model evaluates source reliability within different articles of varying
controversiality such as Climate Change, COVID-19, History, Media, and Biology
topics. Crafting features that express domain usage across articles, the model
effectively predicts source reliability, achieving an F1 Macro score of
approximately 0.80 for English and other high-resource languages. For
mid-resource languages, we achieve 0.65 while the performance of low-resource
languages varies; in all cases, the time the domain remains present in the
articles (which we dub as permanence) is one of the most predictive features.
We highlight the challenge of maintaining consistent model performance across
languages of varying resource levels and demonstrate that adapting models from
higher-resource languages can improve performance. This work contributes not
only to Wikipedia's efforts in ensuring content verifiability but in ensuring
reliability across diverse user-generated content in various language
communities.",2024-10-24,"Jacopo D'Ignazi, Andreas Kaltenbrunner, Yelena Mejova, Michele Tizzani, Kyriaki Kalimeri, Mariano Beiró, Pablo Aragón",http://arxiv.org/pdf/2410.18803v2,cs.LG
PointPatchRL -- Masked Reconstruction Improves Reinforcement Learning on Point Clouds,"Perceiving the environment via cameras is crucial for Reinforcement Learning
(RL) in robotics. While images are a convenient form of representation, they
often complicate extracting important geometric details, especially with
varying geometries or deformable objects. In contrast, point clouds naturally
represent this geometry and easily integrate color and positional data from
multiple camera views. However, while deep learning on point clouds has seen
many recent successes, RL on point clouds is under-researched, with only the
simplest encoder architecture considered in the literature. We introduce
PointPatchRL (PPRL), a method for RL on point clouds that builds on the common
paradigm of dividing point clouds into overlapping patches, tokenizing them,
and processing the tokens with transformers. PPRL provides significant
improvements compared with other point-cloud processing architectures
previously used for RL. We then complement PPRL with masked reconstruction for
representation learning and show that our method outperforms strong model-free
and model-based baselines on image observations in complex manipulation tasks
containing deformable objects and variations in target object geometry. Videos
and code are available at https://alrhub.github.io/pprl-website",2024-10-24,"Balázs Gyenes, Nikolai Franke, Philipp Becker, Gerhard Neumann",http://arxiv.org/pdf/2410.18800v1,cs.LG
WARP-LCA: Efficient Convolutional Sparse Coding with Locally Competitive Algorithm,"The locally competitive algorithm (LCA) can solve sparse coding problems
across a wide range of use cases. Recently, convolution-based LCA approaches
have been shown to be highly effective for enhancing robustness for image
recognition tasks in vision pipelines. To additionally maximize
representational sparsity, LCA with hard-thresholding can be applied. While
this combination often yields very good solutions satisfying an $\ell_0$
sparsity criterion, it comes with significant drawbacks for practical
application: (i) LCA is very inefficient, typically requiring hundreds of
optimization cycles for convergence; (ii) the use of hard-thresholding results
in a non-convex loss function, which might lead to suboptimal minima. To
address these issues, we propose the Locally Competitive Algorithm with State
Warm-up via Predictive Priming (WARP-LCA), which leverages a predictor network
to provide a suitable initial guess of the LCA state based on the current
input. Our approach significantly improves both convergence speed and the
quality of solutions, while maintaining and even enhancing the overall
strengths of LCA. We demonstrate that WARP-LCA converges faster by orders of
magnitude and reaches better minima compared to conventional LCA. Moreover, the
learned representations are more sparse and exhibit superior properties in
terms of reconstruction and denoising quality as well as robustness when
applied in deep recognition pipelines. Furthermore, we apply WARP-LCA to image
denoising tasks, showcasing its robustness and practical effectiveness. Our
findings confirm that the naive use of LCA with hard-thresholding results in
suboptimal minima, whereas initializing LCA with a predictive guess results in
better outcomes. This research advances the field of biologically inspired deep
learning by providing a novel approach to convolutional sparse coding.",2024-10-24,"Geoffrey Kasenbacher, Felix Ehret, Gerrit Ecke, Sebastian Otte",http://arxiv.org/pdf/2410.18794v2,cs.LG
Adapting MLOps for Diverse In-Network Intelligence in 6G Era: Challenges and Solutions,"Seamless integration of artificial intelligence (AI) and machine learning
(ML) techniques with wireless systems is a crucial step for 6G AInization.
However, such integration faces challenges in terms of model functionality and
lifecycle management. ML operations (MLOps) offer a systematic approach to
tackle these challenges. Existing approaches toward implementing MLOps in a
centralized platform often overlook the challenges posed by diverse learning
paradigms and network heterogeneity. This article provides a new approach to
MLOps targeting the intricacies of future wireless networks. Considering unique
aspects of the future radio access network (RAN), we formulate three
operational pipelines, namely reinforcement learning operations (RLOps),
federated learning operations (FedOps), and generative AI operations (GenOps).
These pipelines form the foundation for seamlessly integrating various
learning/inference capabilities into networks. We outline the specific
challenges and proposed solutions for each operation, facilitating large-scale
deployment of AI-Native 6G networks.",2024-10-24,"Peizheng Li, Ioannis Mavromatis, Tim Farnham, Adnan Aijaz, Aftab Khan",http://arxiv.org/pdf/2410.18793v1,cs.LG
Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality,"The denoising diffusion probabilistic model (DDPM) has emerged as a
mainstream generative model in generative AI. While sharp convergence
guarantees have been established for the DDPM, the iteration complexity is, in
general, proportional to the ambient data dimension, resulting in overly
conservative theory that fails to explain its practical efficiency. This has
motivated the recent work Li and Yan (2024a) to investigate how the DDPM can
achieve sampling speed-ups through automatic exploitation of intrinsic low
dimensionality of data. We strengthen this line of work by demonstrating, in
some sense, optimal adaptivity to unknown low dimensionality. For a broad class
of data distributions with intrinsic dimension $k$, we prove that the iteration
complexity of the DDPM scales nearly linearly with $k$, which is optimal when
using KL divergence to measure distributional discrepancy. Notably, our work is
closely aligned with the independent concurrent work Potaptchik et al. (2024)
-- posted two weeks prior to ours -- in establishing nearly linear-$k$
convergence guarantees for the DDPM.",2024-10-24,"Zhihan Huang, Yuting Wei, Yuxin Chen",http://arxiv.org/pdf/2410.18784v2,cs.LG
A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs,"A primary challenge in large language model (LLM) development is their
onerous pre-training cost. Typically, such pre-training involves optimizing a
self-supervised objective (such as next-token prediction) over a large corpus.
This paper explores a promising paradigm to improve LLM pre-training efficiency
and quality by suitably leveraging a small language model (SLM). In particular,
this paradigm relies on an SLM to both (1) provide soft labels as additional
training supervision, and (2) select a small subset of valuable (""informative""
and ""hard"") training examples. Put together, this enables an effective transfer
of the SLM's predictive distribution to the LLM, while prioritizing specific
regions of the training data distribution. Empirically, this leads to reduced
LLM training time compared to standard training, while improving the overall
quality. Theoretically, we develop a statistical framework to systematically
study the utility of SLMs in enabling efficient training of high-quality LLMs.
In particular, our framework characterizes how the SLM's seemingly low-quality
supervision can enhance the training of a much more capable LLM. Furthermore,
it also highlights the need for an adaptive utilization of such supervision, by
striking a balance between the bias and variance introduced by the SLM-provided
soft labels. We corroborate our theoretical framework by improving the
pre-training of an LLM with 2.8B parameters by utilizing a smaller LM with 1.5B
parameters on the Pile dataset.",2024-10-24,"Ankit Singh Rawat, Veeranjaneyulu Sadhanala, Afshin Rostamizadeh, Ayan Chakrabarti, Wittawat Jitkrittum, Vladimir Feinberg, Seungyeon Kim, Hrayr Harutyunyan, Nikunj Saunshi, Zachary Nado, Rakesh Shivanna, Sashank J. Reddi, Aditya Krishna Menon, Rohan Anil, Sanjiv Kumar",http://arxiv.org/pdf/2410.18779v1,cs.LG
Fully Stochastic Primal-dual Gradient Algorithm for Non-convex Optimization on Random Graphs,"Stochastic decentralized optimization algorithms often suffer from issues
such as synchronization overhead and intermittent communication. This paper
proposes a $\underline{\rm F}$ully $\underline{\rm S}$tochastic $\underline{\rm
P}$rimal $\underline{\rm D}$ual gradient $\underline{\rm A}$lgorithm (FSPDA)
that suggests an asynchronous decentralized procedure with (i) sparsified
non-blocking communication on random undirected graphs and (ii) local
stochastic gradient updates. FSPDA allows multiple local gradient steps to
accelerate convergence to stationarity while finding a consensual solution with
stochastic primal-dual updates. For problems with smooth (possibly non-convex)
objective function, we show that FSPDA converges to an $\mathrm{\mathcal{O}(
{\it \sigma /\sqrt{nT}} )}$-stationary solution after $\mathrm{\it T}$
iterations without assuming data heterogeneity. The performance of FSPDA is on
par with state-of-the-art algorithms whose convergence depend on static graph
and synchronous updates. To our best knowledge, FSPDA is the first asynchronous
algorithm that converges exactly under the non-convex setting. Numerical
experiments are presented to show the benefits of FSPDA.",2024-10-24,"Chung-Yiu Yau, Haoming Liu, Hoi-To Wai",http://arxiv.org/pdf/2410.18774v1,cs.LG
Citywide Electric Vehicle Charging Demand Prediction Approach Considering Urban Region and Dynamic Influences,"Electric vehicle charging demand prediction is important for vacant charging
pile recommendation and charging infrastructure planning, thus facilitating
vehicle electrification and green energy development. The performance of
previous spatio-temporal studies is still far from satisfactory nowadays
because urban region attributes and multivariate temporal influences are not
adequately taken into account. To tackle these issues, we propose a learning
approach for citywide electric vehicle charging demand prediction, named
CityEVCP. To learn non-pairwise relationships in urban areas, we cluster
service areas by the types and numbers of points of interest in the areas and
develop attentive hypergraph networks accordingly. Graph attention mechanisms
are employed for information propagation between neighboring areas.
Additionally, we propose a variable selection network to adaptively learn
dynamic auxiliary information and improve the Transformer encoder utilizing
gated mechanisms for fluctuating charging time-series data. Experiments on a
citywide electric vehicle charging dataset demonstrate the performances of our
proposed approach compared with a broad range of competing baselines.
Furthermore, we demonstrate the impact of dynamic influences on prediction
results in different areas of the city and the effectiveness of our area
clustering method.",2024-10-24,"Haoxuan Kuang, Kunxiang Deng, Linlin You, Jun Li",http://arxiv.org/pdf/2410.18766v2,cs.LG
Does Differential Privacy Impact Bias in Pretrained NLP Models?,"Differential privacy (DP) is applied when fine-tuning pre-trained large
language models (LLMs) to limit leakage of training examples. While most DP
research has focused on improving a model's privacy-utility tradeoff, some find
that DP can be unfair to or biased against underrepresented groups. In this
work, we show the impact of DP on bias in LLMs through empirical analysis.
Differentially private training can increase the model bias against protected
groups w.r.t AUC-based bias metrics. DP makes it more difficult for the model
to differentiate between the positive and negative examples from the protected
groups and other groups in the rest of the population. Our results also show
that the impact of DP on bias is not only affected by the privacy protection
level but also the underlying distribution of the dataset.",2024-10-24,"Md. Khairul Islam, Andrew Wang, Tianhao Wang, Yangfeng Ji, Judy Fox, Jieyu Zhao",http://arxiv.org/pdf/2410.18749v1,cs.LG
Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies,"The large models, as predicted by scaling raw forecasts, have made
groundbreaking progress in many fields, particularly in natural language
generation tasks, where they have approached or even surpassed human levels.
However, the unprecedented scale of their parameters brings significant
computational and storage costs. These large models require substantial
computational resources and GPU memory to operate. When adapting large models
to specific downstream tasks, their massive parameter scale poses a significant
challenge in fine-tuning on hardware platforms with limited computational power
and GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT)
offers a practical solution by efficiently adjusting the parameters of large
pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts
the parameters of pre-trained large models to adapt to specific tasks or
domains, minimizing the introduction of additional parameters and the
computational resources required. This review mainly introduces the preliminary
knowledge of PEFT, the core ideas and principles of various PEFT algorithms,
the applications of PEFT, and potential future research directions. By reading
this review, we believe that interested parties can quickly grasp the PEFT
methodology, thereby accelerating its development and innovation.",2024-10-24,"Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang",http://arxiv.org/pdf/2410.19878v3,cs.LG
GeoLoRA: Geometric integration for parameter efficient fine-tuning,"Low-Rank Adaptation (LoRA) has become a widely used method for
parameter-efficient fine-tuning of large-scale, pre-trained neural networks.
However, LoRA and its extensions face several challenges, including the need
for rank adaptivity, robustness, and computational efficiency during the
fine-tuning process. We introduce GeoLoRA, a novel approach that addresses
these limitations by leveraging dynamical low-rank approximation theory.
GeoLoRA requires only a single backpropagation pass over the small-rank
adapters, significantly reducing computational cost as compared to similar
dynamical low-rank training methods and making it faster than popular baselines
such as AdaLoRA. This allows GeoLoRA to efficiently adapt the allocated
parameter budget across the model, achieving smaller low-rank adapters compared
to heuristic methods like AdaLoRA and LoRA, while maintaining critical
convergence, descent, and error-bound theoretical guarantees. The resulting
method is not only more efficient but also more robust to varying
hyperparameter settings. We demonstrate the effectiveness of GeoLoRA on several
state-of-the-art benchmarks, showing that it outperforms existing methods in
both accuracy and computational efficiency.",2024-10-24,"Steffen Schotthöfer, Emanuele Zangrando, Gianluca Ceruti, Francesco Tudisco, Jonas Kusch",http://arxiv.org/pdf/2410.18720v1,cs.LG
Retrieval-Augmented Diffusion Models for Time Series Forecasting,"While time series diffusion models have received considerable focus from many
recent works, the performance of existing models remains highly unstable.
Factors limiting time series diffusion models include insufficient time series
datasets and the absence of guidance. To address these limitations, we propose
a Retrieval- Augmented Time series Diffusion model (RATD). The framework of
RATD consists of two parts: an embedding-based retrieval process and a
reference-guided diffusion model. In the first part, RATD retrieves the time
series that are most relevant to historical time series from the database as
references. The references are utilized to guide the denoising process in the
second part. Our approach allows leveraging meaningful samples within the
database to aid in sampling, thus maximizing the utilization of datasets.
Meanwhile, this reference-guided mechanism also compensates for the
deficiencies of existing time series diffusion models in terms of guidance.
Experiments and visualizations on multiple datasets demonstrate the
effectiveness of our approach, particularly in complicated prediction tasks.",2024-10-24,"Jingwei Liu, Ling Yang, Hongyan Li, Shenda Hong",http://arxiv.org/pdf/2410.18712v1,cs.LG
Exploiting Interpretable Capabilities with Concept-Enhanced Diffusion and Prototype Networks,"Concept-based machine learning methods have increasingly gained importance
due to the growing interest in making neural networks interpretable. However,
concept annotations are generally challenging to obtain, making it crucial to
leverage all their prior knowledge. By creating concept-enriched models that
incorporate concept information into existing architectures, we exploit their
interpretable capabilities to the fullest extent. In particular, we propose
Concept-Guided Conditional Diffusion, which can generate visual representations
of concepts, and Concept-Guided Prototype Networks, which can create a concept
prototype dataset and leverage it to perform interpretable concept prediction.
These results open up new lines of research by exploiting pre-existing
information in the quest for rendering machine learning more
human-understandable.",2024-10-24,"Alba Carballo-Castro, Sonia Laguna, Moritz Vandenhirtz, Julia E. Vogt",http://arxiv.org/pdf/2410.18705v2,cs.LG
BATON: Enhancing Batch-wise Inference Efficiency for Large Language Models via Dynamic Re-batching,"The advanced capabilities of Large Language Models (LLMs) have inspired the
development of various interactive web services or applications, such as
ChatGPT, which offer query inference services for users. Unlike traditional DNN
model, the inference of LLM entails different iterations of forward computation
for different queries, which result in efficiency challenges for existing
run-to-completion batch-wise inference. Hence, some methods refine batch-wise
inference to iteration-level by duplicating all nonlinear layers of LLM.
However, this approach not only increases resource usage but also introduces
idle computations to the batch due to the prefilling of newly added queries.
Therefore, we propose BATON, an efficient batch-wise LLM inference scheme by
dynamically adjusting processing batch, which can achieve near-zero idle
computations without incurring additional resource consumption. To do so, BATON
1) shapes the vectors involved in the inference of the newly inserted query and
processing batch to align dimensions and generates a new attention mask based
on vector shaping to ensure inference correctness, which enables query
inserting without consuming additional resource; 2) embeds prefilled Keys and
Values of the new query into the KV_Cache of the processing batch by leveraging
the prefilling and decoding separation mechanism, eliminating idle computations
to the batch introduced by the prefilling process of the new query.
Experimental results show that compared to the state-of-the-art solution Orca,
BATON improves query processing by up to 1.75 times.",2024-10-24,"Peizhuang Cong, Qizhi Chen, Haochen Zhao, Tong Yang",http://arxiv.org/pdf/2410.18701v1,cs.LG
Large Language Models for Financial Aid in Financial Time-series Forecasting,"Considering the difficulty of financial time series forecasting in financial
aid, much of the current research focuses on leveraging big data analytics in
financial services. One modern approach is to utilize ""predictive analysis"",
analogous to forecasting financial trends. However, many of these time series
data in Financial Aid (FA) pose unique challenges due to limited historical
datasets and high dimensional financial information, which hinder the
development of effective predictive models that balance accuracy with efficient
runtime and memory usage. Pre-trained foundation models are employed to address
these challenging tasks. We use state-of-the-art time series models including
pre-trained LLMs (GPT-2 as the backbone), transformers, and linear models to
demonstrate their ability to outperform traditional approaches, even with
minimal (""few-shot"") or no fine-tuning (""zero-shot""). Our benchmark study,
which includes financial aid with seven other time series tasks, shows the
potential of using LLMs for scarce financial datasets.",2024-10-24,"Md Khairul Islam, Ayush Karmacharya, Timothy Sue, Judy Fox",http://arxiv.org/pdf/2410.19025v1,cs.LG
Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification,"Leveraging large language models (LLMs) has garnered increasing attention and
introduced novel perspectives in time series classification. However, existing
approaches often overlook the crucial dynamic temporal information inherent in
time series data and face challenges in aligning this data with textual
semantics. To address these limitations, we propose HiTime, a hierarchical
multi-modal model that seamlessly integrates temporal information into LLMs for
multivariate time series classification (MTSC). Our model employs a
hierarchical feature encoder to capture diverse aspects of time series data
through both data-specific and task-specific embeddings. To facilitate semantic
space alignment between time series and text, we introduce a dual-view
contrastive alignment module that bridges the gap between modalities.
Additionally, we adopt a hybrid prompting strategy to fine-tune the pre-trained
LLM in a parameter-efficient manner. By effectively incorporating dynamic
temporal features and ensuring semantic alignment, HiTime enables LLMs to
process continuous time series data and achieves state-of-the-art
classification performance through text generation. Extensive experiments on
benchmark datasets demonstrate that HiTime significantly enhances time series
classification accuracy compared to most competitive baseline methods. Our
findings highlight the potential of integrating temporal features into LLMs,
paving the way for advanced time series analysis. The code is publicly
available for further research and validation. Our codes are publicly
available1.",2024-10-24,"Xiaoyu Tao, Tingyue Pan, Mingyue Cheng, Yucong Luo",http://arxiv.org/pdf/2410.18686v1,cs.LG
Rigid Single-Slice-in-Volume registration via rotation-equivariant 2D/3D feature matching,"2D to 3D registration is essential in tasks such as diagnosis, surgical
navigation, environmental understanding, navigation in robotics, autonomous
systems, or augmented reality. In medical imaging, the aim is often to place a
2D image in a 3D volumetric observation to w. Current approaches for rigid
single slice in volume registration are limited by requirements such as pose
initialization, stacks of adjacent slices, or reliable anatomical landmarks.
Here, we propose a self-supervised 2D/3D registration approach to match a
single 2D slice to the corresponding 3D volume. The method works in data
without anatomical priors such as images of tumors. It addresses the
dimensionality disparity and establishes correspondences between 2D in-plane
and 3D out-of-plane rotation-equivariant features by using group equivariant
CNNs. These rotation-equivariant features are extracted from the 2D query slice
and aligned with their 3D counterparts. Results demonstrate the robustness of
the proposed slice-in-volume registration on the NSCLC-Radiomics CT and KIRBY21
MRI datasets, attaining an absolute median angle error of less than 2 degrees
and a mean-matching feature accuracy of 89% at a tolerance of 3 pixels.",2024-10-24,"Stefan Brandstätter, Philipp Seeböck, Christoph Fürböck, Svitlana Pochepnia, Helmut Prosch, Georg Langs",http://arxiv.org/pdf/2410.18683v1,cs.LG
Enhancing pretraining efficiency for medical image segmentation via transferability metrics,"In medical image segmentation tasks, the scarcity of labeled training data
poses a significant challenge when training deep neural networks. When using
U-Net-style architectures, it is common practice to address this problem by
pretraining the encoder part on a large general-purpose dataset like ImageNet.
However, these methods are resource-intensive and do not guarantee improved
performance on the downstream task. In this paper we investigate a variety of
training setups on medical image segmentation datasets, using
ImageNet-pretrained models. By examining over 300 combinations of models,
datasets, and training methods, we find that shorter pretraining often leads to
better results on the downstream task, providing additional proof to the
well-known fact that the accuracy of the model on ImageNet is a poor indicator
for downstream performance. As our main contribution, we introduce a novel
transferability metric, based on contrastive learning, that measures how
robustly a pretrained model is able to represent the target data. In contrast
to other transferability scores, our method is applicable to the case of
transferring from ImageNet classification to medical image segmentation. We
apply our robustness score by measuring it throughout the pretraining phase to
indicate when the model weights are optimal for downstream transfer. This
reduces pretraining time and improves results on the target task.",2024-10-24,"Gábor Hidy, Bence Bakos, András Lukács",http://arxiv.org/pdf/2410.18677v1,cs.LG
Homomorphism Counts as Structural Encodings for Graph Learning,"Graph Transformers are popular neural networks that extend the well-known
Transformer architecture to the graph domain. These architectures operate by
applying self-attention on graph nodes and incorporating graph structure
through the use of positional encodings (e.g., Laplacian positional encoding)
or structural encodings (e.g., random-walk structural encoding). The quality of
such encodings is critical, since they provide the necessary $\textit{graph
inductive biases}$ to condition the model on graph structure. In this work, we
propose $\textit{motif structural encoding}$ (MoSE) as a flexible and powerful
structural encoding framework based on counting graph homomorphisms.
Theoretically, we compare the expressive power of MoSE to random-walk
structural encoding and relate both encodings to the expressive power of
standard message passing neural networks. Empirically, we observe that MoSE
outperforms other well-known positional and structural encodings across a range
of architectures, and it achieves state-of-the-art performance on a widely
studied molecular property prediction dataset.",2024-10-24,"Linus Bao, Emily Jin, Michael Bronstein, İsmail İlkan Ceylan, Matthias Lanzinger",http://arxiv.org/pdf/2410.18676v2,cs.LG
Health Misinformation in Social Networks: A Survey of IT Approaches,"In this paper, we present a comprehensive survey on the pervasive issue of
medical misinformation in social networks from the perspective of information
technology. The survey aims at providing a systematic review of related
research and helping researchers and practitioners navigate through this
fast-changing field. Specifically, we first present manual and automatic
approaches for fact-checking. We then explore fake news detection methods,
using content, propagation features, or source features, as well as mitigation
approaches for countering the spread of misinformation. We also provide a
detailed list of several datasets on health misinformation and of publicly
available tools. We conclude the survey with a discussion on the open
challenges and future research directions in the battle against health
misinformation.",2024-10-24,"Vasiliki Papanikou, Panagiotis Papadakos, Theodora Karamanidou, Thanos G. Stavropoulos, Evaggelia Pitoura, Panayiotis Tsaparas",http://arxiv.org/pdf/2410.18670v1,cs.LG
3D Shape Completion with Test-Time Training,"This work addresses the problem of \textit{shape completion}, i.e., the task
of restoring incomplete shapes by predicting their missing parts. While
previous works have often predicted the fractured and restored shape in one
step, we approach the task by separately predicting the fractured and newly
restored parts, but ensuring these predictions are interconnected. We use a
decoder network motivated by related work on the prediction of signed distance
functions (DeepSDF). In particular, our representation allows us to consider
test-time-training, i.e., finetuning network parameters to match the given
incomplete shape more accurately during inference. While previous works often
have difficulties with artifacts around the fracture boundary, we demonstrate
that our overfitting to the fractured parts leads to significant improvements
in the restoration of eight different shape categories of the ShapeNet data set
in terms of their chamfer distances.",2024-10-24,"Michael Schopf-Kuester, Zorah Lähner, Michael Moeller",http://arxiv.org/pdf/2410.18668v1,cs.LG
NIDS Neural Networks Using Sliding Time Window Data Processing with Trainable Activations and its Generalization Capability,"This paper presents neural networks for network intrusion detection systems
(NIDS), that operate on flow data preprocessed with a time window. It requires
only eleven features which do not rely on deep packet inspection and can be
found in most NIDS datasets and easily obtained from conventional flow
collectors. The time window aggregates information with respect to hosts
facilitating the identification of flow signatures that are missed by other
aggregation methods. Several network architectures are studied and the use of
Kolmogorov-Arnold Network (KAN)-inspired trainable activation functions that
help to achieve higher accuracy with simpler network structure is proposed. The
reported training accuracy exceeds 99% for the proposed method with as little
as twenty neural network input features. This work also studies the
generalization capability of NIDS, a crucial aspect that has not been
adequately addressed in the previous studies. The generalization experiments
are conducted using CICIDS2017 dataset and a custom dataset collected as part
of this study. It is shown that the performance metrics decline significantly
when changing datasets, and the reduction in performance metrics can be
attributed to the difference in signatures of the same type flows in different
datasets, which in turn can be attributed to the differences between the
underlying networks. It is shown that the generalization accuracy of some
neural networks can be very unstable and sensitive to random initialization
parameters, and neural networks with fewer parameters and well-tuned
activations are more stable and achieve higher accuracy.",2024-10-24,"Anton Raskovalov, Nikita Gabdullin, Ilya Androsov",http://arxiv.org/pdf/2410.18658v2,cs.LG
Learning dissipative Hamiltonian dynamics with reproducing kernel Hilbert spaces and random Fourier features,"This paper presents a new method for learning dissipative Hamiltonian
dynamics from a limited and noisy dataset. The method uses the Helmholtz
decomposition to learn a vector field as the sum of a symplectic and a
dissipative vector field. The two vector fields are learned using two
reproducing kernel Hilbert spaces, defined by a symplectic and a curl-free
kernel, where the kernels are specialized to enforce odd symmetry. Random
Fourier features are used to approximate the kernels to reduce the dimension of
the optimization problem. The performance of the method is validated in
simulations for two dissipative Hamiltonian systems, and it is shown that the
method improves predictive accuracy significantly compared to a method where a
Gaussian separable kernel is used.",2024-10-24,"Torbjørn Smith, Olav Egeland",http://arxiv.org/pdf/2410.18656v1,cs.LG
Towards Better Open-Ended Text Generation: A Multicriteria Evaluation Framework,"Open-ended text generation has become a prominent task in natural language
processing due to the rise of powerful (large) language models. However,
evaluating the quality of these models and the employed decoding strategies
remains challenging because of trade-offs among widely used metrics such as
coherence, diversity, and perplexity. Decoding methods often excel in some
metrics while underperforming in others, complicating the establishment of a
clear ranking. In this paper, we present novel ranking strategies within this
multicriteria framework. Specifically, we employ benchmarking approaches based
on partial orderings and present a new summary metric designed to balance
existing automatic indicators, providing a more holistic evaluation of text
generation quality. Our experiments demonstrate that the proposed methods offer
a robust way to compare decoding strategies, and serve as valuable tools in
guiding model selection for open-ended text generation tasks. Finally, we
suggest future directions for improving evaluation methodologies in text
generation. Our codebase, datasets, and models are publicly available.",2024-10-24,"Esteban Garces Arias, Hannah Blocher, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher",http://arxiv.org/pdf/2410.18653v2,cs.LG
$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation,"Generating high-quality charts with Large Language Models (LLMs) presents
significant challenges due to limited data and the high cost of scaling through
human curation. $\langle \text{instruction}, \text{data}, \text{code} \rangle$
triplets are scarce and expensive to manually curate as their creation demands
technical expertise. To address this scalability challenge, we introduce a
reference-free automatic feedback generator, which eliminates the need for
costly human intervention. Our novel framework, C$^2$, consists of (1) an
automatic feedback provider (ChartAF) and (2) a diverse, reference-free dataset
(ChartUIE-8K). The results are compelling: in our first experiment, 74% of
respondents strongly preferred, and 10% preferred, the results after feedback.
The second post-feedback experiment demonstrates that ChartAF outperform nine
baselines. Moreover, ChartUIE-8K significantly improves data diversity by
increasing queries, datasets, and chart types by 5982%, 1936%, and 91%,
respectively, over benchmarks. Finally, a study of LLM users revealed that 94%
of participants preferred ChartUIE-8K's queries, with 93% deeming them aligned
with real-world use cases. Core contributions are available as open-source at
chartsquared.github.io, with ample qualitative examples.",2024-10-24,"Woosung Koh, Jang Han Yoon, MinHyung Lee, Youngjin Song, Jaegwan Cho, Jaehyun Kang, Taehyeon Kim, Se-Young Yun, Youngjae Yu, Bongshin Lee",http://arxiv.org/pdf/2410.18652v7,cs.LG
Diffusion Attribution Score: Evaluating Training Data Influence in Diffusion Models,"As diffusion models become increasingly popular, the misuse of copyrighted
and private images has emerged as a major concern. One promising solution to
mitigate this issue is identifying the contribution of specific training
samples in generative models, a process known as data attribution. Existing
data attribution methods for diffusion models typically quantify the
contribution of a training sample by evaluating the change in diffusion loss
when the sample is included or excluded from the training process. However, we
argue that the direct usage of diffusion loss cannot represent such a
contribution accurately due to the calculation of diffusion loss. Specifically,
these approaches measure the divergence between predicted and ground truth
distributions, which leads to an indirect comparison between the predicted
distributions and cannot represent the variances between model behaviors. To
address these issues, we aim to measure the direct comparison between predicted
distributions with an attribution score to analyse the training sample
importance, which is achieved by Diffusion Attribution Score (\textit{DAS}).
Underpinned by rigorous theoretical analysis, we elucidate the effectiveness of
DAS. Additionally, we explore strategies to accelerate DAS calculations,
facilitating its application to large-scale diffusion models. Our extensive
experiments across various datasets and diffusion models demonstrate that DAS
significantly surpasses previous benchmarks in terms of the linear
data-modelling score, establishing new state-of-the-art performance. Code is
available at \hyperlink{here}{https://github.com/Jinxu-Lin/DAS}.",2024-10-24,"Jinxu Lin, Linwei Tao, Minjing Dong, Chang Xu",http://arxiv.org/pdf/2410.18639v4,cs.LG
Remote Detection of Applications for Improved Beam Tracking in mmWave/sub-THz 5G/6G Systems,"Beam tracking is an essential functionality of millimeter wave (mmWave,
30-100 GHz) and sub-terahertz (sub-THz, 100-300 GHz) 5G/6G systems. It operates
by performing antenna sweeping at both base station (BS) and user equipment
(UE) sides using the Synchronization Signal Blocks (SSB). The optimal frequency
of beam tracking events is not specified by 3GPP standards and heavily depends
on the micromobility properties of the applications currently utilized by the
user. In absence of explicit signalling for the type of application at the air
interface, in this paper, we propose a way to remotely detect it at the BS side
based on the received signal strength pattern. To this aim, we first perform a
multi-stage measurement campaign at 156 GHz, belonging to the sub-THz band, to
obtain the received signal strength traces of popular smartphone applications.
Then, we proceed applying conventional statistical Mann-Whitney tests and
various machine learning (ML) based classification techniques to discriminate
applications remotely. Our results show that Mann-Whitney test can be used to
differentiate between fast and slow application classes with a confidence of
0.95 inducing class detection delay on the order of 1 s after application
initialization. With the same time budget, random forest classifiers can
differentiate between applications with fast and slow micromobility with 80%
accuracy using received signal strength metric only. The accuracy of detecting
a specific application however is lower, reaching 60%. By utilizing the
proposed technique one can estimate the optimal values of the beam tracking
intervals without adding additional signalling to the air interface.",2024-10-24,"Alexander Shurakov, Margarita Ershova, Abdukodir Khakimov, Anatoliy Prikhodko, Evgeny Mokrov, Vyacheslav Begishev, Galina Chulkova, Yevgeni Koucheryavy, Gregory Gol'tsman",http://arxiv.org/pdf/2410.18637v1,cs.LG
Supporting Assessment of Novelty of Design Problems Using Concept of Problem SAPPhIRE,"This paper proposes a framework for assessing the novelty of design problems
using the SAPPhIRE model of causality. The novelty of a problem is measured as
its minimum distance from the problems in a reference problem database. The
distance is calculated by comparing the current problem and each reference past
problem at the various levels of abstraction in the SAPPhIRE ontology. The
basis for comparison is textual similarity. To demonstrate the applicability of
the proposed framework, The current set of problems associated with an
artifact, as collected from its stakeholders, were compared with the past set
of problems, as collected from patents and other web sources, to assess the
novelty of the current set. This approach is aimed at providing a better
understanding of the degree of novelty of any given set of current problems by
comparing them to similar problems available from historical records. Since
manual assessment, the current mode of such assessments as reported in the
literature, is a tedious process, to reduce time complexity and to afford
better applicability for larger sets of problem statements, an automated
assessment is proposed and used in this paper.",2024-10-24,"Sanjay Singh, Amaresh Chakrabarti",http://arxiv.org/pdf/2410.18629v1,cs.LG
SAMG: Offline-to-Online Reinforcement Learning via State-Action-Conditional Offline Model Guidance,"Offline-to-online (O2O) reinforcement learning (RL) pre-trains models on
offline data and refines policies through online fine-tuning. However, existing
O2O RL algorithms typically require maintaining the tedious offline datasets to
mitigate the effects of out-of-distribution (OOD) data, which significantly
limits their efficiency in exploiting online samples. To address this
deficiency, we introduce a new paradigm for O2O RL called
State-Action-Conditional Offline \Model Guidance (SAMG). It freezes the
pre-trained offline critic to provide compact offline understanding for each
state-action sample, thus eliminating the need for retraining on offline data.
The frozen offline critic is incorporated with the online target critic
weighted by a state-action-adaptive coefficient. This coefficient aims to
capture the offline degree of samples at the state-action level, and is updated
adaptively during training. In practice, SAMG could be easily integrated with
Q-function-based algorithms. Theoretical analysis shows good optimality and
lower estimation error. Empirically, SAMG outperforms state-of-the-art O2O RL
algorithms on the D4RL benchmark.",2024-10-24,"Liyu Zhang, Haochi Wu, Xu Wan, Quan Kong, Ruilong Deng, Mingyang Sun",http://arxiv.org/pdf/2410.18626v2,cs.LG
Prompting and Fine-Tuning of Small LLMs for Length-Controllable Telephone Call Summarization,"This paper explores the rapid development of a telephone call summarization
system utilizing large language models (LLMs). Our approach involves initial
experiments with prompting existing LLMs to generate summaries of telephone
conversations, followed by the creation of a tailored synthetic training
dataset utilizing stronger frontier models. We place special focus on the
diversity of the generated data and on the ability to control the length of the
generated summaries to meet various use-case specific requirements. The
effectiveness of our method is evaluated using two state-of-the-art
LLM-as-a-judge-based evaluation techniques to ensure the quality and relevance
of the summaries. Our results show that fine-tuned Llama-2-7B-based
summarization model performs on-par with GPT-4 in terms of factual accuracy,
completeness and conciseness. Our findings demonstrate the potential for
quickly bootstrapping a practical and efficient call summarization system.",2024-10-24,"David Thulke, Yingbo Gao, Rricha Jalota, Christian Dugast, Hermann Ney",http://arxiv.org/pdf/2410.18624v1,cs.LG
Evolutionary Dispersal of Ecological Species via Multi-Agent Deep Reinforcement Learning,"Understanding species dynamics in heterogeneous environments is essential for
ecosystem studies. Traditional models assumed homogeneous habitats, but recent
approaches include spatial and temporal variability, highlighting species
migration. We adopt starvation-driven diffusion (SDD) models as nonlinear
diffusion to describe species dispersal based on local resource conditions,
showing advantages for species survival. However, accurate prediction remains
challenging due to model simplifications. This study uses multi-agent
reinforcement learning (MARL) with deep Q-networks (DQN) to simulate single
species and predator-prey interactions, incorporating SDD-type rewards. Our
simulations reveal evolutionary dispersal strategies, providing insights into
species dispersal mechanisms and validating traditional mathematical models.",2024-10-24,"Wonhyung Choi, Inkyung Ahn",http://arxiv.org/pdf/2410.18621v1,cs.LG
Rethinking Attention: Polynomial Alternatives to Softmax in Transformers,"This paper questions whether the strong performance of softmax attention in
transformers stems from producing a probability distribution over inputs.
Instead, we argue that softmax's effectiveness lies in its implicit
regularization of the Frobenius norm of the attention matrix, which stabilizes
training. Motivated by this, we explore alternative activations, specifically
polynomials, that achieve a similar regularization effect. Our theoretical
analysis shows that certain polynomials can serve as effective substitutes for
softmax, achieving strong performance across transformer applications despite
violating softmax's typical properties of positivity, normalization, and
sparsity. Extensive experiments support these findings, offering a new
perspective on attention mechanisms.",2024-10-24,"Hemanth Saratchandran, Jianqiao Zheng, Yiping Ji, Wenbo Zhang, Simon Lucey",http://arxiv.org/pdf/2410.18613v2,cs.LG
TripCast: Pre-training of Masked 2D Transformers for Trip Time Series Forecasting,"Deep learning and pre-trained models have shown great success in time series
forecasting. However, in the tourism industry, time series data often exhibit a
leading time property, presenting a 2D structure. This introduces unique
challenges for forecasting in this sector. In this study, we propose a novel
modelling paradigm, TripCast, which treats trip time series as 2D data and
learns representations through masking and reconstruction processes.
Pre-trained on large-scale real-world data, TripCast notably outperforms other
state-of-the-art baselines in in-domain forecasting scenarios and demonstrates
strong scalability and transferability in out-domain forecasting scenarios.",2024-10-24,"Yuhua Liao, Zetian Wang, Peng Wei, Qiangqiang Nie, Zhenhua Zhang",http://arxiv.org/pdf/2410.18612v1,cs.LG
Predicting potato plant vigor from the seed tuber properties,"The vigor of potato plants, defined as the canopy area at the end of the
exponential growth stage, depends on the origin and physiological state of the
seed tuber. Experiments carried out with six potato varieties in three test
fields over three years show that there is a 73%-90% correlation in the vigor
of the plants from the same seedlot grown in different test fields. However,
these correlations are not always observed on the level of individual varieties
and vanish or become negative when the seed tubers and young plants experience
environmental stress. A comprehensive study of the association between the
vigor and the seed tuber biochemistry has revealed that, while 50%-70% of the
variation in the plant vigor is explained by the tuber data, the vigor is
dominated by the potato genotype. Analysis of individual predictors, such as
the abundance of a particular metabolite, indicates that the vigor enhancing
properties of the seed tubers differ between genotypes. Variety-specific models
show that, for some varieties, up to 30% of the vigor variation within the
variety is explained by and can be predicted from the tuber biochemistry,
whereas, for other varieties, the association between the tuber composition and
the vigor is much weaker.",2024-10-24,"Elisa Atza, Rob Klooster, Falko Hofstra, Frank van der Werff, Hans van Doorn, Neil Budko",http://arxiv.org/pdf/2410.19875v1,cs.LG
STTATTS: Unified Speech-To-Text And Text-To-Speech Model,"Speech recognition and speech synthesis models are typically trained
separately, each with its own set of learning objectives, training data, and
model parameters, resulting in two distinct large networks. We propose a
parameter-efficient approach to learning ASR and TTS jointly via a multi-task
learning objective and shared parameters. Our evaluation demonstrates that the
performance of our multi-task model is comparable to that of individually
trained models while significantly saving computational and memory costs
($\sim$50\% reduction in the total number of parameters required for the two
tasks combined). We experiment with English as a resource-rich language, and
Arabic as a relatively low-resource language due to shortage of TTS data. Our
models are trained with publicly available data, and both the training code and
model checkpoints are openly available for further research.",2024-10-24,"Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki",http://arxiv.org/pdf/2410.18607v1,cs.LG
Understanding Players as if They Are Talking to the Game in a Customized Language: A Pilot Study,"This pilot study explores the application of language models (LMs) to model
game event sequences, treating them as a customized natural language. We
investigate a popular mobile game, transforming raw event data into textual
sequences and pretraining a Longformer model on this data. Our approach
captures the rich and nuanced interactions within game sessions, effectively
identifying meaningful player segments. The results demonstrate the potential
of self-supervised LMs in enhancing game design and personalization without
relying on ground-truth labels.",2024-10-24,"Tianze Wang, Maryam Honari-Jahromi, Styliani Katsarou, Olga Mikheeva, Theodoros Panagiotakopoulos, Oleg Smirnov, Lele Cao, Sahar Asadi",http://arxiv.org/pdf/2410.18605v1,cs.LG
Differential Informed Auto-Encoder,"In this article, an encoder was trained to obtain the inner structure of the
original data by obtain a differential equations. A decoder was trained to
resample the original data domain, to generate new data that obey the
differential structure of the original data using the physics-informed neural
network.",2024-10-24,Jinrui Zhang,http://arxiv.org/pdf/2410.18593v1,cs.LG
Knowledge Distillation Using Frontier Open-source LLMs: Generalizability and the Role of Synthetic Data,"Leading open-source large language models (LLMs) such as
Llama-3.1-Instruct-405B are extremely capable at generating text, answering
questions, and solving a variety of natural language understanding tasks.
However, they incur higher inference cost and latency compared to smaller LLMs.
Knowledge distillation provides a way to use outputs from these large, capable
teacher models to train smaller student models which can be used for inference
at lower cost and latency, while retaining comparable accuracy. We investigate
the efficacy of distillation using the Llama-3.1-405B-Instruct teacher and the
smaller Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct student models.
Contributions of this work include (a) We evaluate the generalizability of
distillation with the above Llama-3.1 teacher-student pairs across different
tasks and datasets (b) We show that using synthetic data during distillation
significantly improves the accuracy of 8B and 70B models, and when used with
reasoning chains, even matches or surpasses the zero-shot accuracy of 405B
model on some datasets (c) We empirically show that distillation enables 8B and
70B models to internalize 405B's reasoning ability by using only standard
fine-tuning (without customizing any loss function). This allows cost and
latency-efficient student model inference. (d) We show pitfalls in evaluation
of distillation, and present task-specific evaluation, including both human and
LLM-grading, and ground-truth based traditional accuracy benchmarks. This
methodical study brings out the fundamental importance of synthetic data
quality in knowledge distillation, and of combining multiple, task-specific
ways of accuracy and quality evaluation in assessing the effectiveness of
distillation.",2024-10-24,"Anup Shirgaonkar, Nikhil Pandey, Nazmiye Ceren Abay, Tolga Aktas, Vijay Aski",http://arxiv.org/pdf/2410.18588v1,cs.LG
Aligning CodeLLMs with Direct Preference Optimization,"The last year has witnessed the rapid progress of large language models
(LLMs) across diverse domains. Among them, CodeLLMs have garnered particular
attention because they can not only assist in completing various programming
tasks but also represent the decision-making and logical reasoning capabilities
of LLMs. However, current CodeLLMs mainly focus on pre-training and supervised
fine-tuning scenarios, leaving the alignment stage, which is important for
post-training LLMs, under-explored. This work first identifies that the
commonly used PPO algorithm may be suboptimal for the alignment of CodeLLM
because the involved reward rules are routinely coarse-grained and potentially
flawed. We then advocate addressing this using the DPO algorithm. Based on only
preference data pairs, DPO can render the model rank data automatically, giving
rise to a fine-grained rewarding pattern more robust than human intervention.
We also contribute a pipeline for collecting preference pairs for DPO on
CodeLLMs. Studies show that our method significantly improves the performance
of existing CodeLLMs on benchmarks such as MBPP and HumanEval.",2024-10-24,"Yibo Miao, Bofei Gao, Shanghaoran Quan, Junyang Lin, Daoguang Zan, Jiaheng Liu, Jian Yang, Tianyu Liu, Zhijie Deng",http://arxiv.org/pdf/2410.18585v1,cs.LG
Benchmarking Graph Learning for Drug-Drug Interaction Prediction,"Predicting drug-drug interaction (DDI) plays an important role in
pharmacology and healthcare for identifying potential adverse interactions and
beneficial combination therapies between drug pairs. Recently, a flurry of
graph learning methods have been introduced to predict drug-drug interactions.
However, evaluating existing methods has several limitations, such as the
absence of a unified comparison framework for DDI prediction methods, lack of
assessments in meaningful real-world scenarios, and insufficient exploration of
side information usage. In order to address these unresolved limitations in the
literature, we propose a DDI prediction benchmark on graph learning. We first
conduct unified evaluation comparison among existing methods. To meet realistic
scenarios, we further evaluate the performance of different methods in settings
with new drugs involved and examine the performance across different DDI types.
Component analysis is conducted on the biomedical network to better utilize
side information. Through this work, we hope to provide more insights for the
problem of DDI prediction. Our implementation and data is open-sourced at
https://anonymous.4open.science/r/DDI-Benchmark-ACD9/.",2024-10-24,"Zhenqian Shen, Mingyang Zhou, Yongqi Zhang, Quanming Yao",http://arxiv.org/pdf/2410.18583v3,cs.LG
Taipan: Efficient and Expressive State Space Language Models with Selective Attention,"Efficient long-context language modeling remains a significant challenge in
Natural Language Processing (NLP). While Transformers dominate language tasks,
they struggle with long sequences due to quadratic computational complexity in
training and linearly scaling memory costs during inference. Recent State Space
Models (SSMs) such as Mamba offer alternatives with constant memory usage, but
they underperform in tasks requiring extensive in-context retrieval. We
introduce Taipan, a novel hybrid architecture that combines Mamba-2 with
Selective Attention Layers (SALs). These SALs identify tokens requiring
long-range interactions, remove less important features, and then augment their
representations using the attention module. This approach balances Mamba's
efficiency with Transformer-like performance in memory-intensive tasks. By
constraining the attention budget, Taipan extends accurate predictions to
context lengths of up to 1 million tokens while preserving computational
efficiency. Our experiments demonstrate Taipan's superior performance across
various scales and tasks, offering a promising solution for efficient
long-context language modeling.",2024-10-24,"Chien Van Nguyen, Huy Huu Nguyen, Thang M. Pham, Ruiyi Zhang, Hanieh Deilamsalehy, Puneet Mathur, Ryan A. Rossi, Trung Bui, Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen",http://arxiv.org/pdf/2410.18572v1,cs.LG
Heterogeneous Random Forest,"Random forest (RF) stands out as a highly favored machine learning approach
for classification problems. The effectiveness of RF hinges on two key factors:
the accuracy of individual trees and the diversity among them. In this study,
we introduce a novel approach called heterogeneous RF (HRF), designed to
enhance tree diversity in a meaningful way. This diversification is achieved by
deliberately introducing heterogeneity during the tree construction.
Specifically, features used for splitting near the root node of previous trees
are assigned lower weights when constructing the feature sub-space of the
subsequent trees. As a result, dominant features in the prior trees are less
likely to be employed in the next iteration, leading to a more diverse set of
splitting features at the nodes. Through simulation studies, it was confirmed
that the HRF method effectively mitigates the selection bias of trees within
the ensemble, increases the diversity of the ensemble, and demonstrates
superior performance on datasets with fewer noise features. To assess the
comparative performance of HRF against other widely adopted ensemble methods,
we conducted tests on 52 datasets, comprising both real-world and synthetic
data. HRF consistently outperformed other ensemble methods in terms of accuracy
across the majority of datasets.",2024-10-24,"Ye-eun Kim, Seoung Yun Kim, Hyunjoong Kim",http://arxiv.org/pdf/2410.19022v1,cs.LG
Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness,"Quantifying robustness in a single measure for the purposes of model
selection, development of adversarial training methods, and anticipating trends
has so far been elusive. The simplest metric to consider is the number of
trainable parameters in a model but this has previously been shown to be
insufficient at explaining robustness properties. A variety of other metrics,
such as ones based on boundary thickness and gradient flatness have been
proposed but have been shown to be inadequate proxies for robustness.
  In this work, we investigate the relationship between a model's effective
dimensionality, which can be thought of as model complexity, and its robustness
properties. We run experiments on commercial-scale models that are often used
in real-world environments such as YOLO and ResNet. We reveal a near-linear
inverse relationship between effective dimensionality and adversarial
robustness, that is models with a lower dimensionality exhibit better
robustness. We investigate the effect of a variety of adversarial training
methods on effective dimensionality and find the same inverse linear
relationship present, suggesting that effective dimensionality can serve as a
useful criterion for model selection and robustness evaluation, providing a
more nuanced and effective metric than parameter count or previously-tested
measures.",2024-10-24,"David Khachaturov, Robert Mullins",http://arxiv.org/pdf/2410.18556v1,cs.LG
Local and Global Graph Modeling with Edge-weighted Graph Attention Network for Handwritten Mathematical Expression Recognition,"In this paper, we present a novel approach to Handwritten Mathematical
Expression Recognition (HMER) by leveraging graph-based modeling techniques. We
introduce an End-to-end model with an Edge-weighted Graph Attention Mechanism
(EGAT), designed to perform simultaneous node and edge classification. This
model effectively integrates node and edge features, facilitating the
prediction of symbol classes and their relationships within mathematical
expressions. Additionally, we propose a stroke-level Graph Modeling method for
both local (LGM) and global (GGM) information, which applies an end-to-end
model to Online HMER tasks, transforming the recognition problem into node and
edge classification tasks in graph structure. By capturing both local and
global graph features, our method ensures comprehensive understanding of the
expression structure. Through the combination of these components, our system
demonstrates superior performance in symbol detection, relation classification,
and expression-level recognition.",2024-10-24,"Yejing Xie, Richard Zanibbi, Harold Mouchère",http://arxiv.org/pdf/2410.18555v1,cs.LG
Optimal Equivariant Architectures from the Symmetries of Matrix-Element Likelihoods,"The Matrix-Element Method (MEM) has long been a cornerstone of data analysis
in high-energy physics. It leverages theoretical knowledge of parton-level
processes and symmetries to evaluate the likelihood of observed events. In
parallel, the advent of geometric deep learning has enabled neural network
architectures that incorporate known symmetries directly into their design,
leading to more efficient learning. This paper presents a novel approach that
combines MEM-inspired symmetry considerations with equivariant neural network
design for particle physics analysis. Even though Lorentz invariance and
permutation invariance overall reconstructed objects are the largest and most
natural symmetry in the input domain, we find that they are sub-optimal in most
practical search scenarios. We propose a longitudinal boost-equivariant
message-passing neural network architecture that preserves relevant discrete
symmetries. We present numerical studies demonstrating MEM-inspired
architectures achieve new state-of-the-art performance in distinguishing
di-Higgs decays to four bottom quarks from the QCD background, with enhanced
sample and parameter efficiencies. This synergy between MEM and equivariant
deep learning opens new directions for physics-informed architecture design,
promising more powerful tools for probing physics beyond the Standard Model.",2024-10-24,"Daniel Maître, Vishal S. Ngairangbam, Michael Spannowsky",http://arxiv.org/pdf/2410.18553v1,cs.LG
IMAN: An Adaptive Network for Robust NPC Mortality Prediction with Missing Modalities,"Accurate prediction of mortality in nasopharyngeal carcinoma (NPC), a complex
malignancy particularly challenging in advanced stages, is crucial for
optimizing treatment strategies and improving patient outcomes. However, this
predictive process is often compromised by the high-dimensional and
heterogeneous nature of NPC-related data, coupled with the pervasive issue of
incomplete multi-modal data, manifesting as missing radiological images or
incomplete diagnostic reports. Traditional machine learning approaches suffer
significant performance degradation when faced with such incomplete data, as
they fail to effectively handle the high-dimensionality and intricate
correlations across modalities. Even advanced multi-modal learning techniques
like Transformers struggle to maintain robust performance in the presence of
missing modalities, as they lack specialized mechanisms to adaptively integrate
and align the diverse data types, while also capturing nuanced patterns and
contextual relationships within the complex NPC data. To address these problem,
we introduce IMAN: an adaptive network for robust NPC mortality prediction with
missing modalities.",2024-10-24,"Yejing Huo, Guoheng Huang, Lianglun Cheng, Jianbin He, Xuhang Chen, Xiaochen Yuan, Guo Zhong, Chi-Man Pun",http://arxiv.org/pdf/2410.18551v1,cs.LG
Interpretable Representation Learning from Videos using Nonlinear Priors,"Learning interpretable representations of visual data is an important
challenge, to make machines' decisions understandable to humans and to improve
generalisation outside of the training distribution. To this end, we propose a
deep learning framework where one can specify nonlinear priors for videos (e.g.
of Newtonian physics) that allow the model to learn interpretable latent
variables and use these to generate videos of hypothetical scenarios not
observed at training time. We do this by extending the Variational Auto-Encoder
(VAE) prior from a simple isotropic Gaussian to an arbitrary nonlinear temporal
Additive Noise Model (ANM), which can describe a large number of processes
(e.g. Newtonian physics). We propose a novel linearization method that
constructs a Gaussian Mixture Model (GMM) approximating the prior, and derive a
numerically stable Monte Carlo estimate of the KL divergence between the
posterior and prior GMMs. We validate the method on different real-world
physics videos including a pendulum, a mass on a spring, a falling object and a
pulsar (rotating neutron star). We specify a physical prior for each experiment
and show that the correct variables are learned. Once a model is trained, we
intervene on it to change different physical variables (such as oscillation
amplitude or adding air drag) to generate physically correct videos of
hypothetical scenarios that were not observed previously.",2024-10-24,"Marian Longa, João F. Henriques",http://arxiv.org/pdf/2410.18539v1,cs.LG
Understanding Ranking LLMs: A Mechanistic Analysis for Information Retrieval,"Transformer networks, particularly those achieving performance comparable to
GPT models, are well known for their robust feature extraction abilities.
However, the nature of these extracted features and their alignment with
human-engineered ones remain unexplored. In this work, we investigate the
internal mechanisms of state-of-the-art, fine-tuned LLMs for passage reranking.
We employ a probing-based analysis to examine neuron activations in ranking
LLMs, identifying the presence of known human-engineered and semantic features.
Our study spans a broad range of feature categories, including lexical signals,
document structure, query-document interactions, and complex semantic
representations, to uncover underlying patterns influencing ranking decisions.
  Through experiments on four different ranking LLMs, we identify statistical
IR features that are prominently encoded in LLM activations, as well as others
that are notably missing. Furthermore, we analyze how these models respond to
out-of-distribution queries and documents, revealing distinct generalization
behaviors. By dissecting the latent representations within LLM activations, we
aim to improve both the interpretability and effectiveness of ranking models.
Our findings offer crucial insights for developing more transparent and
reliable retrieval systems, and we release all necessary scripts and code to
support further exploration.",2024-10-24,"Tanya Chowdhury, Atharva Nijasure, James Allan",http://arxiv.org/pdf/2410.18527v2,cs.LG
KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing,"The development of large language models (LLMs) has significantly expanded
model sizes, resulting in substantial GPU memory requirements during inference.
The key and value storage of the attention map in the KV (key-value) cache
accounts for more than 80\% of this memory consumption. Nowadays, most existing
KV cache compression methods focus on intra-layer compression within a single
Transformer layer but few works consider layer-wise compression. In this paper,
we propose a plug-and-play method called \textit{KVSharer}, which shares the KV
cache between layers to achieve layer-wise compression. Rather than intuitively
sharing based on higher similarity, we discover a counterintuitive phenomenon:
sharing dissimilar KV caches better preserves the model performance.
Experiments show that \textit{KVSharer} can reduce KV cache computation by
30\%, thereby lowering memory consumption without significantly impacting model
performance and it can also achieve at least 1.3 times generation acceleration.
Additionally, we verify that \textit{KVSharer} is compatible with existing
intra-layer KV cache compression methods, and combining both can further save
memory.",2024-10-24,"Yifei Yang, Zouying Cao, Qiguang Chen, Libo Qin, Dongjie Yang, Hai Zhao, Zhi Chen",http://arxiv.org/pdf/2410.18517v1,cs.LG
Scaling up Masked Diffusion Models on Text,"Masked diffusion models (MDMs) have shown promise in language modeling, yet
their scalability and effectiveness in core language tasks, such as text
generation and language understanding, remain underexplored. This paper
establishes the first scaling law for MDMs, demonstrating a scaling rate
comparable to autoregressive models (ARMs) and a relatively small compute gap.
Motivated by their scalability, we train a family of MDMs with up to 1.1
billion (B) parameters to systematically evaluate their performance against
ARMs of comparable or larger sizes. Fully leveraging the probabilistic
formulation of MDMs, we propose a simple yet effective unsupervised
classifier-free guidance that effectively exploits large-scale unpaired data,
boosting performance for conditional inference. In language understanding, the
1.1B MDM outperforms the 1.1B TinyLlama model trained on the same data across
four of eight zero-shot benchmarks. Notably, it achieves competitive math
reasoning ability with the 7B Llama-2 model on the GSM8K dataset. In text
generation, MDMs with 16 times more pre-training time offer a flexible
trade-off against ARMs with the accelerated sampling technique KV-Cache: MDMs
match ARMs in performance while being 1.4 times faster during sampling.
Moreover, MDMs address challenging tasks for ARMs by effectively handling
bidirectional reasoning and adapting to temporal shifts in data. Notably, a
1.1B MDM breaks the reverse curse encountered by much larger ARMs with
significantly more data and computation, such as 13B Llama-2 and 175B GPT-3.
Our code is available at https://github.com/ML-GSAI/SMDM.",2024-10-24,"Shen Nie, Fengqi Zhu, Chao Du, Tianyu Pang, Qian Liu, Guangtao Zeng, Min Lin, Chongxuan Li",http://arxiv.org/pdf/2410.18514v3,cs.LG
A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges,"Time series forecasting is a critical task that provides key information for
decision-making. After traditional statistical and machine learning approaches,
various fundamental deep learning architectures such as MLPs, CNNs, RNNs, and
GNNs have been developed. However, the structural limitations caused by the
inductive biases of each deep learning architecture constrained their
performance. Transformer models, which excel at handling long-term
dependencies, have become significant architectural components for time series
forecasting. However, recent research has shown that alternatives such as
simple linear layers can outperform Transformers. These findings have opened up
new possibilities for using diverse architectures, ranging from fundamental
deep learning models to emerging architectures and hybrid approaches. In this
context, architectural modeling of time series forecasting has now entered a
renaissance. This survey not only provides a historical context for time series
forecasting but also offers comprehensive and timely analysis of the movement
toward architectural diversification. By comparing and re-examining deep
learning models, we uncover new perspectives and present recent trends,
including hybrid, diffusion, Mamba, and foundation models. By focusing on the
inherent characteristics of time series data, we also address open challenges
that have gained attention in time series forecasting, such as channel
dependency, distribution shift, causality, and feature extraction. These
contributions help lower entry barriers for newcomers by providing a systematic
understanding of the diverse research areas in time series forecasting (TSF),
while offering seasoned researchers broader perspectives and new opportunities
through in-depth exploration of TSF challenges. (Shortened due to arXiv's
1,920-character limit. Full version in the paper.)",2024-10-24,"Jongseon Kim, Hyungjoon Kim, HyunGi Kim, Dongjun Lee, Sungroh Yoon",http://arxiv.org/pdf/2411.05793v3,cs.LG
Assured Automatic Programming via Large Language Models,"With the advent of AI-based coding engines, it is possible to convert natural
language requirements to executable code in standard programming languages.
However, AI-generated code can be unreliable, and the natural language
requirements driving this code may be ambiguous. In other words, the intent may
not be accurately captured in the code generated from AI-coding engines like
Copilot. The goal of our work is to discover the programmer intent, while
generating code which conforms to the intent and a proof of this conformance.
Our approach to intent discovery is powered by a novel repair engine called
program-proof co-evolution, where the object of repair is a tuple (code,
logical specification, test) generated by an LLM from the same natural language
description. The program and the specification capture the initial operational
and declarative description of intent, while the test represents a concrete,
albeit partial, understanding of the intent. Our objective is to achieve
consistency between the program, the specification, and the test by
incrementally refining our understanding of the user intent. Reaching
consistency through this repair process provides us with a formal, logical
description of the intent, which is then translated back into natural language
for the developer's inspection. The resultant intent description is now
unambiguous, though expressed in natural language. We demonstrate how the
unambiguous intent discovered through our approach increases the percentage of
verifiable auto-generated programs on a recently proposed dataset in the Dafny
programming language.",2024-10-24,"Martin Mirchev, Andreea Costea, Abhishek Kr Singh, Abhik Roychoudhury",http://arxiv.org/pdf/2410.18494v2,cs.LG
Graph Pre-Training Models Are Strong Anomaly Detectors,"Graph Anomaly Detection (GAD) is a challenging and practical research topic
where Graph Neural Networks (GNNs) have recently shown promising results. The
effectiveness of existing GNNs in GAD has been mainly attributed to the
simultaneous learning of node representations and the classifier in an
end-to-end manner. Meanwhile, graph pre-training, the two-stage learning
paradigm such as DGI and GraphMAE, has shown potential in leveraging unlabeled
graph data to enhance downstream tasks, yet its impact on GAD remains
under-explored. In this work, we show that graph pre-training models are strong
graph anomaly detectors. Specifically, we demonstrate that pre-training is
highly competitive, markedly outperforming the state-of-the-art end-to-end
training models when faced with limited supervision. To understand this
phenomenon, we further uncover pre-training enhances the detection of distant,
under-represented, unlabeled anomalies that go beyond 2-hop neighborhoods of
known anomalies, shedding light on its superior performance against end-to-end
models. Moreover, we extend our examination to the potential of pre-training in
graph-level anomaly detection. We envision this work to stimulate a
re-evaluation of pre-training's role in GAD and offer valuable insights for
future research.",2024-10-24,"Jiashun Cheng, Zinan Zheng, Yang Liu, Jianheng Tang, Hongwei Wang, Yu Rong, Jia Li, Fugee Tsung",http://arxiv.org/pdf/2410.18487v1,cs.LG
Evolving Voices Based on Temporal Poisson Factorisation,"The world is evolving and so is the vocabulary used to discuss topics in
speech. Analysing political speech data from more than 30 years requires the
use of flexible topic models to uncover the latent topics and their change in
prevalence over time as well as the change in the vocabulary of the topics. We
propose the temporal Poisson factorisation (TPF) model as an extension to the
Poisson factorisation model to model sparse count data matrices obtained based
on the bag-of-words assumption from text documents with time stamps. We discuss
and empirically compare different model specifications for the time-varying
latent variables consisting either of a flexible auto-regressive structure of
order one or a random walk. Estimation is based on variational inference where
we consider a combination of coordinate ascent updates with automatic
differentiation using batching of documents. Suitable variational families are
proposed to ease inference. We compare results obtained using independent
univariate variational distributions for the time-varying latent variables to
those obtained with a multivariate variant. We discuss in detail the results of
the TPF model when analysing speeches from 18 sessions in the U.S. Senate
(1981-2016).",2024-10-24,"Jan Vávra, Bettina Grün, Paul Hofmarcher",http://arxiv.org/pdf/2410.18486v1,cs.LG
VECTOR: Velocity-Enhanced GRU Neural Network for Real-Time 3D UAV Trajectory Prediction,"This paper tackles the challenge of real-time 3D trajectory prediction for
UAVs, which is critical for applications such as aerial surveillance and
defense. Existing prediction models that rely primarily on position data
struggle with accuracy, especially when UAV movements fall outside the position
domain used in training. Our research identifies a gap in utilizing velocity
estimates, first-order dynamics, to better capture the dynamics and enhance
prediction accuracy and generalizability in any position domain. To bridge this
gap, we propose a new trajectory prediction method using Gated Recurrent Units
(GRUs) within sequence-based neural networks. Unlike traditional methods that
rely on RNNs or transformers, this approach forecasts future velocities and
positions based on historical velocity data instead of positions. This is
designed to enhance prediction accuracy and scalability, overcoming challenges
faced by conventional models in handling complex UAV dynamics. The methodology
employs both synthetic and real-world 3D UAV trajectory data, capturing a wide
range of flight patterns, speeds, and agility. Synthetic data is generated
using the Gazebo simulator and PX4 Autopilot, while real-world data comes from
the UZH-FPV and Mid-Air drone racing datasets. The GRU-based models
significantly outperform state-of-the-art RNN approaches, with a mean square
error (MSE) as low as 2 x 10^-8. Overall, our findings confirm the
effectiveness of incorporating velocity data in improving the accuracy of UAV
trajectory predictions across both synthetic and real-world scenarios, in and
out of position data distributions. Finally, we open-source our 5000
trajectories dataset and a ROS 2 package to facilitate the integration with
existing ROS-based UAV systems.",2024-10-24,"Omer Nacar, Mohamed Abdelkader, Lahouari Ghouti, Kahled Gabr, Abdulrahman S. Al-Batati, Anis Koubaa",http://arxiv.org/pdf/2410.23305v1,cs.LG
Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction,"Efficiently deriving structured workflows from unannotated dialogs remains an
underexplored and formidable challenge in computational linguistics. Automating
this process could significantly accelerate the manual design of workflows in
new domains and enable the grounding of large language models in
domain-specific flowcharts, enhancing transparency and controllability. In this
paper, we introduce Dialog2Flow (D2F) embeddings, which differ from
conventional sentence embeddings by mapping utterances to a latent space where
they are grouped according to their communicative and informative functions
(i.e., the actions they represent). D2F allows for modeling dialogs as
continuous trajectories in a latent space with distinct action-related regions.
By clustering D2F embeddings, the latent space is quantized, and dialogs can be
converted into sequences of region/action IDs, facilitating the extraction of
the underlying workflow. To pre-train D2F, we build a comprehensive dataset by
unifying twenty task-oriented dialog datasets with normalized per-turn action
annotations. We also introduce a novel soft contrastive loss that leverages the
semantic information of these actions to guide the representation learning
process, showing superior performance compared to standard supervised
contrastive loss. Evaluation against various sentence embeddings, including
dialog-specific ones, demonstrates that D2F yields superior qualitative and
quantitative results across diverse domains.",2024-10-24,"Sergio Burdisso, Srikanth Madikeri, Petr Motlicek",http://arxiv.org/pdf/2410.18481v2,cs.LG
Classifier Clustering and Feature Alignment for Federated Learning under Distributed Concept Drift,"Data heterogeneity is one of the key challenges in federated learning, and
many efforts have been devoted to tackling this problem. However, distributed
concept drift with data heterogeneity, where clients may additionally
experience different concept drifts, is a largely unexplored area. In this
work, we focus on real drift, where the conditional distribution $P(Y|X)$
changes. We first study how distributed concept drift affects the model
training and find that local classifier plays a critical role in drift
adaptation. Moreover, to address data heterogeneity, we study the feature
alignment under distributed concept drift, and find two factors that are
crucial for feature alignment: the conditional distribution $P(Y|X)$ and the
degree of data heterogeneity. Motivated by the above findings, we propose
FedCCFA, a federated learning framework with classifier clustering and feature
alignment. To enhance collaboration under distributed concept drift, FedCCFA
clusters local classifiers at class-level and generates clustered feature
anchors according to the clustering results. Assisted by these anchors, FedCCFA
adaptively aligns clients' feature spaces based on the entropy of label
distribution $P(Y)$, alleviating the inconsistency in feature space. Our
results demonstrate that FedCCFA significantly outperforms existing methods
under various concept drift settings. Code is available at
https://github.com/Chen-Junbao/FedCCFA.",2024-10-24,"Junbao Chen, Jingfeng Xue, Yong Wang, Zhenyan Liu, Lu Huang",http://arxiv.org/pdf/2410.18478v1,cs.LG
What If the Input is Expanded in OOD Detection?,"Out-of-distribution (OOD) detection aims to identify OOD inputs from unknown
classes, which is important for the reliable deployment of machine learning
models in the open world. Various scoring functions are proposed to distinguish
it from in-distribution (ID) data. However, existing methods generally focus on
excavating the discriminative information from a single input, which implicitly
limits its representation dimension. In this work, we introduce a novel
perspective, i.e., employing different common corruptions on the input space,
to expand that. We reveal an interesting phenomenon termed confidence mutation,
where the confidence of OOD data can decrease significantly under the
corruptions, while the ID data shows a higher confidence expectation
considering the resistance of semantic features. Based on that, we formalize a
new scoring method, namely, Confidence aVerage (CoVer), which can capture the
dynamic differences by simply averaging the scores obtained from different
corrupted inputs and the original ones, making the OOD and ID distributions
more separable in detection tasks. Extensive experiments and analyses have been
conducted to understand and verify the effectiveness of CoVer. The code is
publicly available at: https://github.com/tmlr-group/CoVer.",2024-10-24,"Boxuan Zhang, Jianing Zhu, Zengmao Wang, Tongliang Liu, Bo Du, Bo Han",http://arxiv.org/pdf/2410.18472v2,cs.LG
Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities,"Recent research has shown that Large Language Models (LLMs) are vulnerable to
automated jailbreak attacks, where adversarial suffixes crafted by algorithms
appended to harmful queries bypass safety alignment and trigger unintended
responses. Current methods for generating these suffixes are computationally
expensive and have low Attack Success Rates (ASR), especially against
well-aligned models like Llama2 and Llama3. To overcome these limitations, we
introduce ADV-LLM, an iterative self-tuning process that crafts adversarial
LLMs with enhanced jailbreak ability. Our framework significantly reduces the
computational cost of generating adversarial suffixes while achieving nearly
100\% ASR on various open-source LLMs. Moreover, it exhibits strong attack
transferability to closed-source models, achieving 99\% ASR on GPT-3.5 and 49\%
ASR on GPT-4, despite being optimized solely on Llama3. Beyond improving
jailbreak ability, ADV-LLM provides valuable insights for future safety
alignment research through its ability to generate large datasets for studying
LLM safety.",2024-10-24,"Chung-En Sun, Xiaodong Liu, Weiwei Yang, Tsui-Wei Weng, Hao Cheng, Aidan San, Michel Galley, Jianfeng Gao",http://arxiv.org/pdf/2410.18469v3,cs.LG
Learn 2 Rage: Experiencing The Emotional Roller Coaster That Is Reinforcement Learning,"This work presents the experiments and solution outline for our teams winning
submission in the Learn To Race Autonomous Racing Virtual Challenge 2022 hosted
by AIcrowd. The objective of the Learn-to-Race competition is to push the
boundary of autonomous technology, with a focus on achieving the safety
benefits of autonomous driving. In the description the competition is framed as
a reinforcement learning (RL) challenge. We focused our initial efforts on
implementation of Soft Actor Critic (SAC) variants. Our goal was to learn
non-trivial control of the race car exclusively from visual and geometric
features, directly mapping pixels to control actions. We made suitable
modifications to the default reward policy aiming to promote smooth steering
and acceleration control. The framework for the competition provided real time
simulation, meaning a single episode (learning experience) is measured in
minutes. Instead of pursuing parallelisation of episodes we opted to explore a
more traditional approach in which the visual perception was processed (via
learned operators) and fed into rule-based controllers. Such a system, while
not as academically ""attractive"" as a pixels-to-actions approach, results in a
system that requires less training, is more explainable, generalises better and
is easily tuned and ultimately out-performed all other agents in the
competition by a large margin.",2024-10-24,"Lachlan Mares, Stefan Podgorski, Ian Reid",http://arxiv.org/pdf/2410.18462v1,cs.LG
Uncertainty-Error correlations in Evidential Deep Learning models for biomedical segmentation,"In this work, we examine the effectiveness of an uncertainty quantification
framework known as Evidential Deep Learning applied in the context of
biomedical image segmentation. This class of models involves assigning
Dirichlet distributions as priors for segmentation labels, and enables a few
distinct definitions of model uncertainties. Using the cardiac and prostate MRI
images available in the Medical Segmentation Decathlon for validation, we found
that Evidential Deep Learning models with U-Net backbones generally yielded
superior correlations between prediction errors and uncertainties relative to
the conventional baseline equipped with Shannon entropy measure, Monte-Carlo
Dropout and Deep Ensemble methods. We also examined these models' effectiveness
in active learning, finding that relative to the standard Shannon entropy-based
sampling, they yielded higher point-biserial uncertainty-error correlations
while attaining similar performances in Dice-Sorensen coefficients. These
superior features of EDL models render them well-suited for segmentation tasks
that warrant a critical sensitivity in detecting large model errors.",2024-10-24,"Hai Siong Tan, Kuancheng Wang, Rafe Mcbeth",http://arxiv.org/pdf/2410.18461v1,cs.LG
Integrating Deep Feature Extraction and Hybrid ResNet-DenseNet Model for Multi-Class Abnormality Detection in Endoscopic Images,"This paper presents a deep learning framework for the multi-class
classification of gastrointestinal abnormalities in Video Capsule Endoscopy
(VCE) frames. The aim is to automate the identification of ten GI abnormality
classes, including angioectasia, bleeding, and ulcers, thereby reducing the
diagnostic burden on gastroenterologists. Utilizing an ensemble of DenseNet and
ResNet architectures, the proposed model achieves an overall accuracy of 94\%
across a well-structured dataset. Precision scores range from 0.56 for erythema
to 1.00 for worms, with recall rates peaking at 98% for normal findings. This
study emphasizes the importance of robust data preprocessing techniques,
including normalization and augmentation, in enhancing model performance. The
contributions of this work lie in developing an effective AI-driven tool that
streamlines the diagnostic process in gastroenterology, ultimately improving
patient care and clinical outcomes.",2024-10-24,"Aman Sagar, Preeti Mehta, Monika Shrivastva, Suchi Kumari",http://arxiv.org/pdf/2410.18457v1,cs.LG
The Nature of Mathematical Modeling and Probabilistic Optimization Engineering in Generative AI,"In this paper, we give an in-depth analysis on the mathematical problem
formulations and the probabilistic optimization explorations for some of the
key components in Transformer model [33] in the field of generative AI. We
explore and discuss some potential further enhancement for current state of the
art methods for some key underlying technologies of generative AI models from
algorithmic and probabilistic optimization perspective. In particular, we
present an optimal solution for sub-word encoding (SWE) based on similar
initial settings as that of byte-pair encoding (BPE) algorithm in [9] with
similar objectives as that of WordPiece approach in [28, 31] to maximize the
likelihood of the training data. We also present cross entropy optimization
method to optimize hyperparameters for word2vec model [17]. In addition, we
propose a factored combination of rotary positional encoding (RoPE) [32] and
attention with linear biases (ALiBi) [23] with a harmonic series. We also
present a probabilistic FlashAttention [6, 7] (PrFlashAttention) method with a
probability distribution over block distances in the matrix to decide which
block is likely to participate in a given round of attention computation while
maintaining the lower triangle shape of the tensor for autoregressive language
models by re-shaping the tensors. Finally, we present staircase adaptive
quantization (SAQ) of key-value (KV) cache for multi-query attention (MQA)
based on the framework presented in [16] to have gradual quantization
degradation while achieving reasonable model quality and cost savings.",2024-10-24,Fulu Li,http://arxiv.org/pdf/2410.18441v1,cs.LG
Doubly Non-Central Beta Matrix Factorization for Stable Dimensionality Reduction of Bounded Support Matrix Data,"We consider the problem of developing interpretable and computationally
efficient matrix decomposition methods for matrices whose entries have bounded
support. Such matrices are found in large-scale DNA methylation studies and
many other settings. Our approach decomposes the data matrix into a Tucker
representation wherein the number of columns in the constituent factor matrices
is not constrained. We derive a computationally efficient sampling algorithm to
solve for the Tucker decomposition. We evaluate the performance of our method
using three criteria: predictability, computability, and stability. Empirical
results show that our method has similar performance as other state-of-the-art
approaches in terms of held-out prediction and computational complexity, but
has significantly better performance in terms of stability to changes in
hyper-parameters. The improved stability results in higher confidence in the
results in applications where the constituent factors are used to generate and
test scientific hypotheses such as DNA methylation analysis of cancer samples.",2024-10-24,"Anjali N. Albert, Patrick Flaherty, Aaron Schein",http://arxiv.org/pdf/2410.18425v1,cs.LG
A Causal Graph-Enhanced Gaussian Process Regression for Modeling Engine-out NOx,"The stringent regulatory requirements on nitrogen oxides (NOx) emissions from
diesel compression ignition engines require accurate and reliable models for
real-time monitoring and diagnostics. Although traditional methods such as
physical sensors and virtual engine control module (ECM) sensors provide
essential data, they are only used for estimation. Ubiquitous literature
primarily focuses on deterministic models with little emphasis on capturing the
uncertainties due to sensors. The lack of probabilistic frameworks restricts
the applicability of these models for robust diagnostics. The objective of this
paper is to develop and validate a probabilistic model to predict engine-out
NOx emissions using Gaussian process regression. Our approach is as follows. We
employ three variants of Gaussian process models: the first with a standard
radial basis function kernel with input window, the second incorporating a deep
kernel using convolutional neural networks to capture temporal dependencies,
and the third enriching the deep kernel with a causal graph derived via graph
convolutional networks. The causal graph embeds physics knowledge into the
learning process. All models are compared against a virtual ECM sensor using
both quantitative and qualitative metrics. We conclude that our model provides
an improvement in predictive performance when using an input window and a deep
kernel structure. Even more compelling is the further enhancement achieved by
the incorporation of a causal graph into the deep kernel. These findings are
corroborated across different validation datasets.",2024-10-24,"Shrenik Zinage, Ilias Bilionis, Peter Meckl",http://arxiv.org/pdf/2410.18424v1,cs.LG
Large Language Models Reflect the Ideology of their Creators,"Large language models (LLMs) are trained on vast amounts of data to generate
natural language, enabling them to perform tasks like text summarization and
question answering. These models have become popular in artificial intelligence
(AI) assistants like ChatGPT and already play an influential role in how humans
access information. However, the behavior of LLMs varies depending on their
design, training, and use.
  In this paper, we prompt a diverse panel of popular LLMs to describe a large
number of prominent personalities with political relevance, in all six official
languages of the United Nations. By identifying and analyzing moral assessments
reflected in their responses, we find normative differences between LLMs from
different geopolitical regions, as well as between the responses of the same
LLM when prompted in different languages. Among only models in the United
States, we find that popularly hypothesized disparities in political views are
reflected in significant normative differences related to progressive values.
Among Chinese models, we characterize a division between internationally- and
domestically-focused models.
  Our results show that the ideological stance of an LLM appears to reflect the
worldview of its creators. This poses the risk of political instrumentalization
and raises concerns around technological and regulatory efforts with the stated
aim of making LLMs ideologically 'unbiased'.",2024-10-24,"Maarten Buyl, Alexander Rogiers, Sander Noels, Guillaume Bied, Iris Dominguez-Catena, Edith Heiter, Iman Johary, Alexandru-Cristian Mara, Raphaël Romero, Jefrey Lijffijt, Tijl De Bie",http://arxiv.org/pdf/2410.18417v2,cs.LG
SkiLD: Unsupervised Skill Discovery Guided by Factor Interactions,"Unsupervised skill discovery carries the promise that an intelligent agent
can learn reusable skills through autonomous, reward-free environment
interaction. Existing unsupervised skill discovery methods learn skills by
encouraging distinguishable behaviors that cover diverse states. However, in
complex environments with many state factors (e.g., household environments with
many objects), learning skills that cover all possible states is impossible,
and naively encouraging state diversity often leads to simple skills that are
not ideal for solving downstream tasks. This work introduces Skill Discovery
from Local Dependencies (Skild), which leverages state factorization as a
natural inductive bias to guide the skill learning process. The key intuition
guiding Skild is that skills that induce <b>diverse interactions</b> between
state factors are often more valuable for solving downstream tasks. To this
end, Skild develops a novel skill learning objective that explicitly encourages
the mastering of skills that effectively induce different interactions within
an environment. We evaluate Skild in several domains with challenging,
long-horizon sparse reward tasks including a realistic simulated household
robot domain, where Skild successfully learns skills with clear semantic
meaning and shows superior performance compared to existing unsupervised
reinforcement learning methods that only maximize state coverage.",2024-10-24,"Zizhao Wang, Jiaheng Hu, Caleb Chuck, Stephen Chen, Roberto Martín-Martín, Amy Zhang, Scott Niekum, Peter Stone",http://arxiv.org/pdf/2410.18416v1,cs.LG
MoMQ: Mixture-of-Experts Enhances Multi-Dialect Query Generation across Relational and Non-Relational Databases,"The improvement in translating natural language to structured query language
(SQL) can be attributed to the advancements in large language models (LLMs).
Open-source LLMs, tailored for specific database dialects such as MySQL, have
shown great performance. However, cloud service providers are looking for a
unified database manager service (e.g., Cosmos DB from Azure, Amazon Aurora
from AWS, Lindorm from AlibabaCloud) that can support multiple dialects. This
requirement has led to the concept of multi-dialect query generation, which
presents challenges to LLMs. These challenges include syntactic differences
among dialects and imbalanced data distribution across multiple dialects. To
tackle these challenges, we propose MoMQ, a novel Mixture-of-Experts-based
multi-dialect query generation framework across both relational and
non-relational databases. MoMQ employs a dialect expert group for each dialect
and a multi-level routing strategy to handle dialect-specific knowledge,
reducing interference during query generation. Additionally, a shared expert
group is introduced to address data imbalance, facilitating the transfer of
common knowledge from high-resource dialects to low-resource ones. Furthermore,
we have developed a high-quality multi-dialect query generation benchmark that
covers relational and non-relational databases such as MySQL, PostgreSQL,
Cypher for Neo4j, and nGQL for NebulaGraph. Extensive experiments have shown
that MoMQ performs effectively and robustly even in resource-imbalanced
scenarios.",2024-10-24,"Zhisheng Lin, Yifu Liu, Zhiling Luo, Jinyang Gao, Yu Li",http://arxiv.org/pdf/2410.18406v1,cs.LG
Enhancing Feature-Specific Data Protection via Bayesian Coordinate Differential Privacy,"Local Differential Privacy (LDP) offers strong privacy guarantees without
requiring users to trust external parties. However, LDP applies uniform
protection to all data features, including less sensitive ones, which degrades
performance of downstream tasks. To overcome this limitation, we propose a
Bayesian framework, Bayesian Coordinate Differential Privacy (BCDP), that
enables feature-specific privacy quantification. This more nuanced approach
complements LDP by adjusting privacy protection according to the sensitivity of
each feature, enabling improved performance of downstream tasks without
compromising privacy. We characterize the properties of BCDP and articulate its
connections with standard non-Bayesian privacy frameworks. We further apply our
BCDP framework to the problems of private mean estimation and ordinary
least-squares regression. The BCDP-based approach obtains improved accuracy
compared to a purely LDP-based approach, without compromising on privacy.",2024-10-24,"Maryam Aliakbarpour, Syomantak Chaudhuri, Thomas A. Courtade, Alireza Fallah, Michael I. Jordan",http://arxiv.org/pdf/2410.18404v1,cs.LG
Structure Language Models for Protein Conformation Generation,"Proteins adopt multiple structural conformations to perform their diverse
biological functions, and understanding these conformations is crucial for
advancing drug discovery. Traditional physics-based simulation methods often
struggle with sampling equilibrium conformations and are computationally
expensive. Recently, deep generative models have shown promise in generating
protein conformations as a more efficient alternative. However, these methods
predominantly rely on the diffusion process within a 3D geometric space, which
typically centers around the vicinity of metastable states and is often
inefficient in terms of runtime. In this paper, we introduce Structure Language
Modeling (SLM) as a novel framework for efficient protein conformation
generation. Specifically, the protein structures are first encoded into a
compact latent space using a discrete variational auto-encoder, followed by
conditional language modeling that effectively captures sequence-specific
conformation distributions. This enables a more efficient and interpretable
exploration of diverse ensemble modes compared to existing methods. Based on
this general framework, we instantiate SLM with various popular LM
architectures as well as proposing the ESMDiff, a novel BERT-like structure
language model fine-tuned from ESM3 with masked diffusion. We verify our
approach in various scenarios, including the equilibrium dynamics of BPTI,
conformational change pairs, and intrinsically disordered proteins. SLM
provides a highly efficient solution, offering a 20-100x speedup than existing
methods in generating diverse conformations, shedding light on promising
avenues for future research.",2024-10-24,"Jiarui Lu, Xiaoyin Chen, Stephen Zhewen Lu, Chence Shi, Hongyu Guo, Yoshua Bengio, Jian Tang",http://arxiv.org/pdf/2410.18403v2,cs.LG
Low-Rank Tensor Learning by Generalized Nonconvex Regularization,"In this paper, we study the problem of low-rank tensor learning, where only a
few of training samples are observed and the underlying tensor has a low-rank
structure. The existing methods are based on the sum of nuclear norms of
unfolding matrices of a tensor, which may be suboptimal. In order to explore
the low-rankness of the underlying tensor effectively, we propose a nonconvex
model based on transformed tensor nuclear norm for low-rank tensor learning.
Specifically, a family of nonconvex functions are employed onto the singular
values of all frontal slices of a tensor in the transformed domain to
characterize the low-rankness of the underlying tensor. An error bound between
the stationary point of the nonconvex model and the underlying tensor is
established under restricted strong convexity on the loss function (such as
least squares loss and logistic regression) and suitable regularity conditions
on the nonconvex penalty function. By reformulating the nonconvex function into
the difference of two convex functions, a proximal majorization-minimization
(PMM) algorithm is designed to solve the resulting model. Then the global
convergence and convergence rate of PMM are established under very mild
conditions. Numerical experiments are conducted on tensor completion and binary
classification to demonstrate the effectiveness of the proposed method over
other state-of-the-art methods.",2024-10-24,"Sijia Xia, Michael K. Ng, Xiongjun Zhang",http://arxiv.org/pdf/2410.18402v1,cs.LG
Revisiting Differentiable Structure Learning: Inconsistency of $\ell_1$ Penalty and Beyond,"Recent advances in differentiable structure learning have framed the
combinatorial problem of learning directed acyclic graphs as a continuous
optimization problem. Various aspects, including data standardization, have
been studied to identify factors that influence the empirical performance of
these methods. In this work, we investigate critical limitations in
differentiable structure learning methods, focusing on settings where the true
structure can be identified up to Markov equivalence classes, particularly in
the linear Gaussian case. While Ng et al. (2024) highlighted potential
non-convexity issues in this setting, we demonstrate and explain why the use of
$\ell_1$-penalized likelihood in such cases is fundamentally inconsistent, even
if the global optimum of the optimization problem can be found. To resolve this
limitation, we develop a hybrid differentiable structure learning method based
on $\ell_0$-penalized likelihood with hard acyclicity constraint, where the
$\ell_0$ penalty can be approximated by different techniques including
Gumbel-Softmax. Specifically, we first estimate the underlying moral graph, and
use it to restrict the search space of the optimization problem, which helps
alleviate the non-convexity issue. Experimental results show that the proposed
method enhances empirical performance both before and after data
standardization, providing a more reliable path for future advancements in
differentiable structure learning, especially for learning Markov equivalence
classes.",2024-10-24,"Kaifeng Jin, Ignavier Ng, Kun Zhang, Biwei Huang",http://arxiv.org/pdf/2410.18396v1,cs.LG
Causal Order Discovery based on Monotonic SCMs,"In this paper, we consider the problem of causal order discovery within the
framework of monotonic Structural Causal Models (SCMs), which have gained
attention for their potential to enable causal inference and causal discovery
from observational data. While existing approaches either assume prior
knowledge about the causal order or use complex optimization techniques to
impose sparsity in the Jacobian of Triangular Monotonic Increasing maps, our
work introduces a novel sequential procedure that directly identifies the
causal order by iteratively detecting the root variable. This method eliminates
the need for sparsity assumptions and the associated optimization challenges,
enabling the identification of a unique SCM without the need for multiple
independence tests to break the Markov equivalence class. We demonstrate the
effectiveness of our approach in sequentially finding the root variable,
comparing it to methods that maximize Jacobian sparsity.",2024-10-24,"Ali Izadi, Martin Ester",http://arxiv.org/pdf/2410.19870v1,cs.LG
A contrastive-learning approach for auditory attention detection,"Carrying conversations in multi-sound environments is one of the more
challenging tasks, since the sounds overlap across time and frequency making it
difficult to understand a single sound source. One proposed approach to help
isolate an attended speech source is through decoding the electroencephalogram
(EEG) and identifying the attended audio source using statistical or machine
learning techniques. However, the limited amount of data in comparison to other
machine learning problems and the distributional shift between different EEG
recordings emphasizes the need for a self supervised approach that works with
limited data to achieve a more robust solution. In this paper, we propose a
method based on self supervised learning to minimize the difference between the
latent representations of an attended speech signal and the corresponding EEG
signal. This network is further finetuned for the auditory attention
classification task. We compare our results with previously published methods
and achieve state-of-the-art performance on the validation set.",2024-10-24,"Seyed Ali Alavi Bajestan, Mark Pitt, Donald S. Williamson",http://arxiv.org/pdf/2410.18395v1,cs.LG
Faster Algorithms for User-Level Private Stochastic Convex Optimization,"We study private stochastic convex optimization (SCO) under user-level
differential privacy (DP) constraints. In this setting, there are $n$ users
(e.g., cell phones), each possessing $m$ data items (e.g., text messages), and
we need to protect the privacy of each user's entire collection of data items.
Existing algorithms for user-level DP SCO are impractical in many large-scale
machine learning scenarios because: (i) they make restrictive assumptions on
the smoothness parameter of the loss function and require the number of users
to grow polynomially with the dimension of the parameter space; or (ii) they
are prohibitively slow, requiring at least $(mn)^{3/2}$ gradient computations
for smooth losses and $(mn)^3$ computations for non-smooth losses. To address
these limitations, we provide novel user-level DP algorithms with
state-of-the-art excess risk and runtime guarantees, without stringent
assumptions. First, we develop a linear-time algorithm with state-of-the-art
excess risk (for a non-trivial linear-time algorithm) under a mild smoothness
assumption. Our second algorithm applies to arbitrary smooth losses and
achieves optimal excess risk in $\approx (mn)^{9/8}$ gradient computations.
Third, for non-smooth loss functions, we obtain optimal excess risk in
$n^{11/8} m^{5/4}$ gradient computations. Moreover, our algorithms do not
require the number of users to grow polynomially with the dimension.",2024-10-24,"Andrew Lowy, Daogao Liu, Hilal Asi",http://arxiv.org/pdf/2410.18391v1,cs.LG
"Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval","Despite the recent advancements in information retrieval (IR), zero-shot IR
remains a significant challenge, especially when dealing with new domains,
languages, and newly-released use cases that lack historical query traffic from
existing users. For such cases, it is common to use query augmentations
followed by fine-tuning pre-trained models on the document data paired with
synthetic queries. In this work, we propose a novel Universal Document Linking
(UDL) algorithm, which links similar documents to enhance synthetic query
generation across multiple datasets with different characteristics. UDL
leverages entropy for the choice of similarity models and named entity
recognition (NER) for the link decision of documents using similarity scores.
Our empirical studies demonstrate the effectiveness and universality of the UDL
across diverse datasets and IR models, surpassing state-of-the-art methods in
zero-shot cases. The developed code for reproducibility is included in
https://github.com/eoduself/UDL",2024-10-24,"Dae Yon Hwang, Bilal Taha, Harshit Pande, Yaroslav Nechaev",http://arxiv.org/pdf/2410.18385v2,cs.LG
Harnessing PU Learning for Enhanced Cloud-based DDoS Detection: A Comparative Analysis,"This paper explores the application of Positive-Unlabeled (PU) learning for
enhanced Distributed Denial-of-Service (DDoS) detection in cloud environments.
Utilizing the $\texttt{BCCC-cPacket-Cloud-DDoS-2024}$ dataset, we implement PU
learning with four machine learning algorithms: XGBoost, Random Forest, Support
Vector Machine, and Na\""{i}ve Bayes. Our results demonstrate the superior
performance of ensemble methods, with XGBoost and Random Forest achieving
$F_{1}$ scores exceeding 98%. We quantify the efficacy of each approach using
metrics including $F_{1}$ score, ROC AUC, Recall, and Precision. This study
bridges the gap between PU learning and cloud-based anomaly detection,
providing a foundation for addressing Context-Aware DDoS Detection in
multi-cloud environments. Our findings highlight the potential of PU learning
in scenarios with limited labeled data, offering valuable insights for
developing more robust and adaptive cloud security mechanisms.",2024-10-24,"Robert Dilworth, Charan Gudla",http://arxiv.org/pdf/2410.18380v2,cs.LG
Delta: A Cloud-assisted Data Enrichment Framework for On-Device Continual Learning,"In modern mobile applications, users frequently encounter various new
contexts, necessitating on-device continual learning (CL) to ensure consistent
model performance. While existing research predominantly focused on developing
lightweight CL frameworks, we identify that data scarcity is a critical
bottleneck for on-device CL. In this work, we explore the potential of
leveraging abundant cloud-side data to enrich scarce on-device data, and
propose a private, efficient and effective data enrichment framework Delta.
Specifically, Delta first introduces a directory dataset to decompose the data
enrichment problem into device-side and cloud-side sub-problems without sharing
sensitive data. Next, Delta proposes a soft data matching strategy to
effectively solve the device-side sub-problem with sparse user data, and an
optimal data sampling scheme for cloud server to retrieve the most suitable
dataset for enrichment with low computational complexity. Further, Delta
refines the data sampling scheme by jointly considering the impact of enriched
data on both new and past contexts, mitigating the catastrophic forgetting
issue from a new aspect. Comprehensive experiments across four typical mobile
computing tasks with varied data modalities demonstrate that Delta could
enhance the overall model accuracy by an average of 15.1%, 12.4%, 1.1% and 5.6%
for visual, IMU, audio and textual tasks compared with few-shot CL, and
consistently reduce the communication costs by over 90% compared to federated
CL.",2024-10-24,"Chen Gong, Zhenzhe Zheng, Fan Wu, Xiaofeng Jia, Guihai Chen",http://arxiv.org/pdf/2410.18378v1,cs.LG
Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need,"Design space exploration (DSE) enables architects to systematically evaluate
various design options, guiding decisions on the most suitable configurations
to meet specific objectives such as optimizing performance, power, and area.
However, the growing complexity of modern CPUs has dramatically increased the
number of micro-architectural parameters and expanded the overall design space,
making DSE more challenging and time-consuming. Existing DSE frameworks
struggle in large-scale design spaces due to inaccurate models and limited
insights into parameter impact, hindering efficient identification of optimal
micro-architectures within tight timeframes.
  In this work, we introduce AttentionDSE. Its key idea is to use the attention
mechanism to establish a direct mapping of micro-architectural parameters to
their contributions to predicted performance. This approach enhances both the
prediction accuracy and interpretability of the performance model. Furthermore,
the weights are dynamically adjusted, enabling the model to respond to design
changes and effectively pinpoint the key micro-architectural
parameters/components responsible for performance bottlenecks. Thus,
AttentionDSE accurately, purposefully, and rapidly discovers optimal designs.
Experiments on SPEC 2017 demonstrate that AttentionDSE significantly reduces
exploration time by over 80\% and achieves 3.9\% improvement in Pareto
Hypervolume compared to state-of-the-art DSE frameworks while maintaining
superior prediction accuracy and efficiency with an increasing number of
parameters.",2024-10-24,"Runzhen Xue, Hao Wu, Mingyu Yan, Ziheng Xiao, Xiaochun Ye, Dongrui Fan",http://arxiv.org/pdf/2410.18368v1,cs.LG
"Assessing Alcohol Use Disorder: Insights from Lifestyle, Background, and Family History with Machine Learning Techniques","This study explored how lifestyle, personal background, and family history
contribute to the risk of developing Alcohol Use Disorder (AUD). Survey data
from the All of Us Program was utilized to extract information on AUD status,
lifestyle, personal background, and family history for 6,016 participants. Key
determinants of AUD were identified using decision trees including annual
income, recreational drug use, length of residence, sex/gender, marital status,
education level, and family history of AUD. Data visualization and Chi-Square
Tests of Independence were then used to assess associations between identified
factors and AUD. Afterwards, machine learning techniques including decision
trees, random forests, and Naive Bayes were applied to predict an individual's
likelihood of developing AUD. Random forests were found to achieve the highest
accuracy (82%), compared to Decision Trees and Naive Bayes. Findings from this
study can offer insights that help parents, healthcare professionals, and
educators develop strategies to reduce AUD risk, enabling early intervention
and targeted prevention efforts.",2024-10-24,"Chenlan Wang, Gaojian Huang, Yue Luo",http://arxiv.org/pdf/2410.18354v1,cs.LG
Precision Soil Quality Analysis Using Transformer-based Data Fusion Strategies: A Systematic Review,"This review explores the most recent advancements in transformer-based data
fusion techniques in agricultural remote sensing (RS), with a particular focus
on soil analysis. Utilizing a systematic, data-driven approach, we demonstrate
that transformers have significantly outperformed conventional deep learning
and machine learning methods since 2022, achieving prediction performance
between 92% and 97%. The review is specifically focused on soil analysis, due
to the importance of soil condition in optimizing crop productivity and
ensuring sustainable farming practices. Transformer-based models have shown
remarkable capabilities in handling complex multivariate soil data, improving
the accuracy of soil moisture prediction, soil element analysis, and other
soil-related applications. This systematic review primarily focuses on 1)
analysing research trends and patterns in the literature, both chronologically
and technically, and 2) conducting a comparative analysis of data fusion
approaches, considering factors such as data types, techniques, and RS
applications. Finally, we propose a roadmap for implementing data fusion
methods in agricultural RS.",2024-10-24,"Mahdi Saki, Rasool Keshavarz, Daniel Franklin, Mehran Abolhasan, Justin Lipman, Negin Shariati",http://arxiv.org/pdf/2410.18353v1,cs.LG
FedBaF: Federated Learning Aggregation Biased by a Foundation Model,"Foundation models are now a major focus of leading technology organizations
due to their ability to generalize across diverse tasks. Existing approaches
for adapting foundation models to new applications often rely on Federated
Learning (FL) and disclose the foundation model weights to clients when using
it to initialize the global model. While these methods ensure client data
privacy, they compromise model and information security. In this paper, we
introduce Federated Learning Aggregation Biased by a Foundation Model (FedBaF),
a novel method for dynamically integrating pre-trained foundation model weights
during the FL aggregation phase. Unlike conventional methods, FedBaF preserves
the confidentiality of the foundation model while still leveraging its power to
train more accurate models, especially in non-IID and adversarial scenarios.
Our comprehensive experiments use Pre-ResNet and foundation models like Vision
Transformer to demonstrate that FedBaF not only matches, but often surpasses
the test accuracy of traditional weight initialization methods by up to 11.4%
in IID and up to 15.8% in non-IID settings. Additionally, FedBaF applied to a
Transformer-based language model significantly reduced perplexity by up to
39.2%.",2024-10-24,"Jong-Ik Park, Srinivasa Pranav, José M. F. Moura, Carlee Joe-Wong",http://arxiv.org/pdf/2410.18352v2,cs.LG
AdaEDL: Early Draft Stopping for Speculative Decoding of Large Language Models via an Entropy-based Lower Bound on Token Acceptance Probability,"Speculative decoding is a powerful technique that attempts to circumvent the
autoregressive constraint of modern Large Language Models (LLMs). The aim of
speculative decoding techniques is to improve the average inference time of a
large, target model without sacrificing its accuracy, by using a more efficient
draft model to propose draft tokens which are then verified in parallel. The
number of draft tokens produced in each drafting round is referred to as the
draft length and is often a static hyperparameter chosen based on the
acceptance rate statistics of the draft tokens. However, setting a static draft
length can negatively impact performance, especially in scenarios where
drafting is expensive and there is a high variance in the number of tokens
accepted. Adaptive Entropy-based Draft Length (AdaEDL) is a simple, training
and parameter-free criteria which allows for early stopping of the token
drafting process by approximating a lower bound on the expected acceptance
probability of the drafted token based on the currently observed entropy of the
drafted logits. We show that AdaEDL consistently outperforms static
draft-length speculative decoding by 10%-57% as well as other training-free
draft-stopping techniques by upto 10% in a variety of settings and datasets. At
the same time, we show that AdaEDL is more robust than these techniques and
preserves performance in high-sampling-temperature scenarios. Since it is
training-free, in contrast to techniques that rely on the training of
dataset-specific draft-stopping predictors, AdaEDL can seamlessly be integrated
into a variety of pre-existing LLM systems.",2024-10-24,"Sudhanshu Agrawal, Wonseok Jeon, Mingu Lee",http://arxiv.org/pdf/2410.18351v1,cs.LG
Aggregated Knowledge Model: Enhancing Domain-Specific QA with Fine-Tuned and Retrieval-Augmented Generation Models,"This paper introduces a novel approach to enhancing closed-domain Question
Answering (QA) systems, focusing on the specific needs of the Lawrence Berkeley
National Laboratory (LBL) Science Information Technology (ScienceIT) domain.
Utilizing a rich dataset derived from the ScienceIT documentation, our study
embarks on a detailed comparison of two fine-tuned large language models and
five retrieval-augmented generation (RAG) models. Through data processing
techniques, we transform the documentation into structured
context-question-answer triples, leveraging the latest Large Language Models
(AWS Bedrock, GCP PaLM2, Meta LLaMA2, OpenAI GPT-4, Google Gemini-Pro) for
data-driven insights. Additionally, we introduce the Aggregated Knowledge Model
(AKM), which synthesizes responses from the seven models mentioned above using
K-means clustering to select the most representative answers. The evaluation of
these models across multiple metrics offers a comprehensive look into their
effectiveness and suitability for the LBL ScienceIT environment. The results
demonstrate the potential benefits of integrating fine-tuning and
retrieval-augmented strategies, highlighting significant performance
improvements achieved with the AKM. The insights gained from this study can be
applied to develop specialized QA systems tailored to specific domains.",2024-10-24,"Fengchen Liu, Jordan Jung, Wei Feinstein, Jeff DAmbrogia, Gary Jung",http://arxiv.org/pdf/2410.18344v1,cs.LG
Hypergraph Neural Networks Reveal Spatial Domains from Single-cell Transcriptomics Data,"The task of spatial clustering of transcriptomics data is of paramount
importance. It enables the classification of tissue samples into diverse
subpopulations of cells, which, in turn, facilitates the analysis of the
biological functions of clusters, tissue reconstruction, and cell-cell
interactions. Many approaches leverage gene expressions, spatial locations, and
histological images to detect spatial domains; however, Graph Neural Networks
(GNNs) as state of the art models suffer from a limitation in the assumption of
pairwise connections between nodes. In the case of domain detection in spatial
transcriptomics, some cells are found to be not directly related. Still, they
are grouped as the same domain, which shows the incapability of GNNs for
capturing implicit connections among the cells.
  While graph edges connect only two nodes, hyperedges connect an arbitrary
number of nodes along their edges, which lets Hypergraph Neural Networks
(HGNNs) capture and utilize richer and more complex structural information than
traditional GNNs. We use autoencoders to address the limitation of not having
the actual labels, which are well-suited for unsupervised learning. Our model
has demonstrated exceptional performance, achieving the highest iLISI score of
1.843 compared to other methods. This score indicates the greatest diversity of
cell types identified by our method. Furthermore, our model outperforms other
methods in downstream clustering, achieving the highest ARI values of 0.51 and
Leiden score of 0.60.",2024-10-23,"Mehrad Soltani, Luis Rueda",http://arxiv.org/pdf/2410.19868v1,cs.LG
Unified Microphone Conversion: Many-to-Many Device Mapping via Feature-wise Linear Modulation,"We present Unified Microphone Conversion, a unified generative framework
designed to bolster sound event classification (SEC) systems against device
variability. While our prior CycleGAN-based methods effectively simulate device
characteristics, they require separate models for each device pair, limiting
scalability. Our approach overcomes this constraint by conditioning the
generator on frequency response data, enabling many-to-many device mappings
through unpaired training. We integrate frequency-response information via
Feature-wise Linear Modulation, further enhancing scalability. Additionally,
incorporating synthetic frequency response differences improves the
applicability of our framework for real-world application. Experimental results
show that our method outperforms the state-of-the-art by 2.6% and reduces
variability by 0.8% in macro-average F1 score.",2024-10-23,"Myeonghoon Ryu, Hongseok Oh, Suji Lee, Han Park",http://arxiv.org/pdf/2410.18322v3,cs.LG
Calibrating Deep Neural Network using Euclidean Distance,"Uncertainty is a fundamental aspect of real-world scenarios, where perfect
information is rarely available. Humans naturally develop complex internal
models to navigate incomplete data and effectively respond to unforeseen or
partially observed events. In machine learning, Focal Loss is commonly used to
reduce misclassification rates by emphasizing hard-to-classify samples.
However, it does not guarantee well-calibrated predicted probabilities and may
result in models that are overconfident or underconfident. High calibration
error indicates a misalignment between predicted probabilities and actual
outcomes, affecting model reliability. This research introduces a novel loss
function called Focal Calibration Loss (FCL), designed to improve probability
calibration while retaining the advantages of Focal Loss in handling difficult
samples. By minimizing the Euclidean norm through a strictly proper loss, FCL
penalizes the instance-wise calibration error and constrains bounds. We provide
theoretical validation for proposed method and apply it to calibrate CheXNet
for potential deployment in web-based health-care systems. Extensive
evaluations on various models and datasets demonstrate that our method achieves
SOTA performance in both calibration and accuracy metrics.",2024-10-23,"Wenhao Liang, Chang Dong, Liangwei Zheng, Zhengyang Li, Wei Zhang, Weitong Chen",http://arxiv.org/pdf/2410.18321v1,cs.LG
Self-Supervised Learning for Time Series: A Review & Critique of FITS,"Accurate time series forecasting is a highly valuable endeavour with
applications across many industries. Despite recent deep learning advancements,
increased model complexity, and larger model sizes, many state-of-the-art
models often perform worse or on par with simpler models. One of those cases is
a recently proposed model, FITS, claiming competitive performance with
significantly reduced parameter counts. By training a one-layer neural network
in the complex frequency domain, we are able to replicate these results. Our
experiments on a wide range of real-world datasets further reveal that FITS
especially excels at capturing periodic and seasonal patterns, but struggles
with trending, non-periodic, or random-resembling behavior. With our two novel
hybrid approaches, where we attempt to remedy the weaknesses of FITS by
combining it with DLinear, we achieve the best results of any known open-source
model on multivariate regression and promising results in multiple/linear
regression on price datasets, on top of vastly improving upon what FITS
achieves as a standalone model.",2024-10-23,"Andreas Løvendahl Eefsen, Nicholas Erup Larsen, Oliver Glozmann Bork Hansen, Thor Højhus Avenstrup",http://arxiv.org/pdf/2410.18318v1,cs.LG
CoreInfer: Accelerating Large Language Model Inference with Semantics-Inspired Adaptive Sparse Activation,"Large language models (LLMs) with billions of parameters have sparked a new
wave of exciting AI applications. However, their high computational costs and
memory demands during inference pose significant challenges. Adaptive sparse
activation inference, which activates only a small number of neurons for each
token, offers a novel way to accelerate model inference without degrading
performance, showing great potential for resource-constrained hardware devices.
Nevertheless, existing methods predict activated neurons based on individual
tokens with additional MLP, which involve frequent changes in activation maps
and resource calls, limiting the acceleration benefits of sparse activation. In
this paper, we introduce CoreInfer, an MLP-free adaptive sparse activation
inference method based on sentence-level prediction. Specifically, we propose
the concept of sentence-wise core neurons, which refers to the subset of
neurons most critical for a given sentence, and empirically demonstrate its
effectiveness. To determine the core neurons, we explore the correlation
between core neurons and the sentence's semantics. Remarkably, we discovered
that core neurons exhibit both stability and similarity in relation to the
sentence's semantics -- an insight overlooked by previous studies. Building on
this finding, we further design two semantic-based methods for predicting core
neurons to fit different input scenarios. In CoreInfer, the core neurons are
determined during the pre-filling stage and fixed during the encoding stage,
enabling zero-cost sparse inference. We evaluated the model generalization and
task generalization of CoreInfer across various models and tasks. Notably, on
an NVIDIA TITAN XP GPU, CoreInfer achieved a 10.33 times and 2.72 times speedup
compared to the Huggingface implementation and PowerInfer, respectively.",2024-10-23,"Qinsi Wang, Saeed Vahidian, Hancheng Ye, Jianyang Gu, Jianyi Zhang, Yiran Chen",http://arxiv.org/pdf/2410.18311v1,cs.LG
Robust and Explainable Depression Identification from Speech Using Vowel-Based Ensemble Learning Approaches,"This study investigates explainable machine learning algorithms for
identifying depression from speech. Grounded in evidence from speech production
that depression affects motor control and vowel generation, pre-trained
vowel-based embeddings, that integrate semantically meaningful linguistic
units, are used. Following that, an ensemble learning approach decomposes the
problem into constituent parts characterized by specific depression symptoms
and severity levels. Two methods are explored: a ""bottom-up"" approach with 8
models predicting individual Patient Health Questionnaire-8 (PHQ-8) item
scores, and a ""top-down"" approach using a Mixture of Experts (MoE) with a
router module for assessing depression severity. Both methods depict
performance comparable to state-of-the-art baselines, demonstrating robustness
and reduced susceptibility to dataset mean/median values. System explainability
benefits are discussed highlighting their potential to assist clinicians in
depression diagnosis and screening.",2024-10-23,"Kexin Feng, Theodora Chaspari",http://arxiv.org/pdf/2410.18298v1,cs.LG
NexusIndex: Integrating Advanced Vector Indexing and Multi-Model Embeddings for Robust Fake News Detection,"The proliferation of fake news on digital platforms has underscored the need
for robust and scalable detection mechanisms. Traditional methods often fall
short in handling large and diverse datasets due to limitations in scalability
and accuracy. In this paper, we propose NexusIndex, a novel framework and model
that enhances fake news detection by integrating advanced language models, an
innovative FAISSNexusIndex layer, and attention mechanisms. Our approach
leverages multi-model embeddings to capture rich contextual and semantic
nuances, significantly improving text interpretation and classification
accuracy. By transforming articles into high-dimensional embeddings and
indexing them efficiently, NexusIndex facilitates rapid similarity searches
across extensive collections of news articles. The FAISSNexusIndex layer
further optimizes this process, enabling real-time detection and enhancing the
system's scalability and performance. Our experimental results demonstrate that
NexusIndex outperforms state-of-the-art methods in efficiency and accuracy
across diverse datasets.",2024-10-23,"Solmaz Seyed Monir, Dongfang Zhao",http://arxiv.org/pdf/2410.18294v1,cs.LG
Reservoir computing for system identification and predictive control with limited data,"Model predictive control (MPC) is an industry standard control technique that
iteratively solves an open-loop optimization problem to guide a system towards
a desired state or trajectory. Consequently, an accurate forward model of
system dynamics is critical for the efficacy of MPC and much recent work has
been aimed at the use of neural networks to act as data-driven surrogate models
to enable MPC. Perhaps the most common network architecture applied to this
task is the recurrent neural network (RNN) due to its natural interpretation as
a dynamical system. In this work, we assess the ability of RNN variants to both
learn the dynamics of benchmark control systems and serve as surrogate models
for MPC. We find that echo state networks (ESNs) have a variety of benefits
over competing architectures, namely reductions in computational complexity,
longer valid prediction times, and reductions in cost of the MPC objective
function.",2024-10-23,"Jan P. Williams, J. Nathan Kutz, Krithika Manohar",http://arxiv.org/pdf/2411.05016v1,cs.LG
1-2-3-Go! Policy Synthesis for Parameterized Markov Decision Processes via Decision-Tree Learning and Generalization,"Despite the advances in probabilistic model checking, the scalability of the
verification methods remains limited. In particular, the state space often
becomes extremely large when instantiating parameterized Markov decision
processes (MDPs) even with moderate values. Synthesizing policies for such
\emph{huge} MDPs is beyond the reach of available tools. We propose a
learning-based approach to obtain a reasonable policy for such huge MDPs.
  The idea is to generalize optimal policies obtained by model-checking small
instances to larger ones using decision-tree learning. Consequently, our method
bypasses the need for explicit state-space exploration of large models,
providing a practical solution to the state-space explosion problem. We
demonstrate the efficacy of our approach by performing extensive
experimentation on the relevant models from the quantitative verification
benchmark set. The experimental results indicate that our policies perform
well, even when the size of the model is orders of magnitude beyond the reach
of state-of-the-art analysis tools.",2024-10-23,"Muqsit Azeem, Debraj Chakraborty, Sudeep Kanav, Jan Kretinsky, Mohammadsadegh Mohagheghi, Stefanie Mohr, Maximilian Weininger",http://arxiv.org/pdf/2410.18293v2,cs.LG
LEGO: Language Model Building Blocks,"Large language models (LLMs) are essential in natural language processing
(NLP) but are costly in data collection, pre-training, fine-tuning, and
inference. Task-specific small language models (SLMs) offer a cheaper
alternative but lack robustness and generalization. This paper proposes LEGO, a
novel technique to extract SLMs from an LLM and recombine them. Using
state-of-the-art LLM pruning strategies, we can create task- and user-specific
SLM building blocks that are efficient for fine-tuning and inference while also
preserving user data privacy. LEGO utilizes Federated Learning and a novel
aggregation scheme for the LLM reconstruction, maintaining robustness without
high costs and preserving user data privacy. We experimentally demonstrate the
versatility of LEGO, showing its ability to enable model heterogeneity and
mitigate the effects of data heterogeneity while maintaining LLM robustness.",2024-10-23,"Shrenik Bhansali, Alwin Jin, Tyler Lizzo, Larry Heck",http://arxiv.org/pdf/2410.18287v1,cs.LG
Simultaneous Dimensionality Reduction for Extracting Useful Representations of Large Empirical Multimodal Datasets,"The quest for simplification in physics drives the exploration of concise
mathematical representations for complex systems. This Dissertation focuses on
the concept of dimensionality reduction as a means to obtain low-dimensional
descriptions from high-dimensional data, facilitating comprehension and
analysis. We address the challenges posed by real-world data that defy
conventional assumptions, such as complex interactions within neural systems or
high-dimensional dynamical systems. Leveraging insights from both theoretical
physics and machine learning, this work unifies diverse reduction methods under
a comprehensive framework, the Deep Variational Multivariate Information
Bottleneck. This framework enables the design of tailored reduction algorithms
based on specific research questions. We explore and assert the efficacy of
simultaneous reduction approaches over their independent reduction
counterparts, demonstrating their superiority in capturing covariation between
multiple modalities, while requiring less data. We also introduced novel
techniques, such as the Deep Variational Symmetric Information Bottleneck, for
general nonlinear simultaneous reduction. We show that the same principle of
simultaneous reduction is the key to efficient estimation of mutual
information. We show that our new method is able to discover the coordinates of
high-dimensional observations of dynamical systems. Through analytical
investigations and empirical validations, we shed light on the intricacies of
dimensionality reduction methods, paving the way for enhanced data analysis
across various domains. We underscore the potential of these methodologies to
extract meaningful insights from complex datasets, driving advancements in
fundamental research and applied sciences. As these methods evolve, they
promise to deepen our understanding of complex systems and inform more
effective data analysis strategies.",2024-10-23,Eslam Abdelaleem,http://arxiv.org/pdf/2410.19867v1,cs.LG
Augmenting Training Data with Vector-Quantized Variational Autoencoder for Classifying RF Signals,"Radio frequency (RF) communication has been an important part of civil and
military communication for decades. With the increasing complexity of wireless
environments and the growing number of devices sharing the spectrum, it has
become critical to efficiently manage and classify the signals that populate
these frequencies. In such scenarios, the accurate classification of wireless
signals is essential for effective spectrum management, signal interception,
and interference mitigation. However, the classification of wireless RF signals
often faces challenges due to the limited availability of labeled training
data, especially under low signal-to-noise ratio (SNR) conditions. To address
these challenges, this paper proposes the use of a Vector-Quantized Variational
Autoencoder (VQ-VAE) to augment training data, thereby enhancing the
performance of a baseline wireless classifier. The VQ-VAE model generates
high-fidelity synthetic RF signals, increasing the diversity and fidelity of
the training dataset by capturing the complex variations inherent in RF
communication signals. Our experimental results show that incorporating
VQ-VAE-generated data significantly improves the classification accuracy of the
baseline model, particularly in low SNR conditions. This augmentation leads to
better generalization and robustness of the classifier, overcoming the
constraints imposed by limited real-world data. By improving RF signal
classification, the proposed approach enhances the efficacy of wireless
communication in both civil and tactical settings, ensuring reliable and secure
operations. This advancement supports critical decision-making and operational
readiness in environments where communication fidelity is essential.",2024-10-23,"Srihari Kamesh Kompella, Kemal Davaslioglu, Yalin E. Sagduyu, Sastry Kompella",http://arxiv.org/pdf/2410.18283v1,cs.LG
Stabilizing black-box model selection with the inflated argmax,"Model selection is the process of choosing from a class of candidate models
given data. For instance, methods such as the LASSO and sparse identification
of nonlinear dynamics (SINDy) formulate model selection as finding a sparse
solution to a linear system of equations determined by training data. However,
absent strong assumptions, such methods are highly unstable: if a single data
point is removed from the training set, a different model may be selected. In
this paper, we present a new approach to stabilizing model selection with
theoretical stability guarantees that leverages a combination of bagging and an
''inflated'' argmax operation. Our method selects a small collection of models
that all fit the data, and it is stable in that, with high probability, the
removal of any training point will result in a collection of selected models
that overlaps with the original collection. We illustrate this method in (a) a
simulation in which strongly correlated covariates make standard LASSO model
selection highly unstable, (b) a Lotka-Volterra model selection problem focused
on identifying how competition in an ecosystem influences species' abundances,
and (c) a graph subset selection problem using cell-signaling data from
proteomics. In these settings, the proposed method yields stable, compact, and
accurate collections of selected models, outperforming a variety of benchmarks.",2024-10-23,"Melissa Adrian, Jake A. Soloff, Rebecca Willett",http://arxiv.org/pdf/2410.18268v2,cs.LG
Hamiltonian Matching for Symplectic Neural Integrators,"Hamilton's equations of motion form a fundamental framework in various
branches of physics, including astronomy, quantum mechanics, particle physics,
and climate science. Classical numerical solvers are typically employed to
compute the time evolution of these systems. However, when the system spans
multiple spatial and temporal scales numerical errors can accumulate, leading
to reduced accuracy. To address the challenges of evolving such systems over
long timescales, we propose SympFlow, a novel neural network-based symplectic
integrator, which is the composition of a sequence of exact flow maps of
parametrised time-dependent Hamiltonian functions. This architecture allows for
a backward error analysis: we can identify an underlying Hamiltonian function
of the architecture and use it to define a Hamiltonian matching objective
function, which we use for training. In numerical experiments, we show that
SympFlow exhibits promising results, with qualitative energy conservation
behaviour similar to that of time-stepping symplectic integrators.",2024-10-23,"Priscilla Canizares, Davide Murari, Carola-Bibiane Schönlieb, Ferdia Sherry, Zakhar Shumaylov",http://arxiv.org/pdf/2410.18262v1,cs.LG
Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models,"The dominant paradigm for RLHF is online and on-policy RL: synchronously
generating from the large language model (LLM) policy, labelling with a reward
model, and learning using feedback on the LLM's own outputs. While performant,
this paradigm is computationally inefficient. Inspired by classical deep RL
literature, we propose separating generation and learning in RLHF. This enables
asynchronous generation of new samples while simultaneously training on old
samples, leading to faster training and more compute-optimal scaling. However,
asynchronous training relies on an underexplored regime, online but off-policy
RLHF: learning on samples from previous iterations of our model which give a
worse training signal. We tackle the fundamental challenge in this regime: how
much off-policyness can we tolerate for asynchronous training to speed up
learning but maintain performance? Among several RLHF algorithms we test,
online DPO is found to be most robust to off-policy data, and robustness
increases with the scale of the policy model. We study further compute
optimizations for asynchronous RLHF but find that they come at a performance
cost, giving rise to a trade-off. We verify the scalability of asynchronous
RLHF by training a general-purpose chatbot from LLaMA 3.1 8B on an
instruction-following task ~40% faster than a synchronous run while matching
final performance. Finally, we extend our results to math and reasoning to
demonstrate asynchronous RL can finetune Rho 1B on GSM8k ~70% faster while
matching synchronous accuracy.",2024-10-23,"Michael Noukhovitch, Shengyi Huang, Sophie Xhonneux, Arian Hosseini, Rishabh Agarwal, Aaron Courville",http://arxiv.org/pdf/2410.18252v3,cs.LG
Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification,"Modeling strong gravitational lenses is computationally expensive for the
complex data from modern and next-generation cosmic surveys. Deep learning has
emerged as a promising approach for finding lenses and predicting lensing
parameters, such as the Einstein radius. Mean-variance Estimators (MVEs) are a
common approach for obtaining aleatoric (data) uncertainties from a neural
network prediction. However, neural networks have not been demonstrated to
perform well on out-of-domain target data successfully - e.g., when trained on
simulated data and applied to real, observational data. In this work, we
perform the first study of the efficacy of MVEs in combination with
unsupervised domain adaptation (UDA) on strong lensing data. The source domain
data is noiseless, and the target domain data has noise mimicking modern
cosmology surveys. We find that adding UDA to MVE increases the accuracy on the
target data by a factor of about two over an MVE model without UDA. Including
UDA also permits much more well-calibrated aleatoric uncertainty predictions.
Advancements in this approach may enable future applications of MVE models to
real observational data.",2024-10-23,"Shrihan Agarwal, Aleksandra Ćiprijanović, Brian D. Nord",http://arxiv.org/pdf/2411.03334v3,cs.LG
Fast Inference for Augmented Large Language Models,"Augmented Large Language Models (LLMs) enhance the capabilities of standalone
LLMs by integrating external data sources through API calls. In interactive LLM
applications, efficient scheduling is crucial for maintaining low request
completion times, directly impacting user engagement. However, these
augmentations introduce scheduling challenges due to the need to manage limited
memory for cached information (KV caches). As a result, traditional size-based
scheduling algorithms, such as Shortest Job First (SJF), become less effective
at minimizing completion times. Existing work focuses only on handling requests
during API calls by preserving, discarding, or swapping memory without
considering how to schedule requests with API calls. In this paper, we propose
LAMPS, a novel LLM inference framework for augmented LLMs. LAMPS minimizes
request completion time through a unified scheduling approach that considers
the total length of requests and their handling strategies during API calls.
Recognizing that LLM inference is memory-bound, our approach ranks requests
based on their consumption of memory over time, which depends on both the
output sizes and how a request is managed during its API calls. To implement
our scheduling, LAMPS predicts the strategy that minimizes memory waste of a
request during its API calls, aligning with but improving upon existing
approaches. We also propose starvation prevention techniques and optimizations
to mitigate the overhead of our scheduling. We implement LAMPS on top of vLLM
and evaluate its performance against baseline LLM inference systems,
demonstrating improvements in end-to-end latency by 27%-85% and reductions in
TTFT by 4%-96% compared to the existing augmented-LLM system, with even greater
gains over vLLM.",2024-10-23,"Rana Shahout, Cong Liang, Shiji Xin, Qianru Lao, Yong Cui, Minlan Yu, Michael Mitzenmacher",http://arxiv.org/pdf/2410.18248v2,cs.LG
Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits,"We consider multi-draft speculative sampling, where the proposal sequences
are sampled independently from different draft models. At each step, a
token-level draft selection scheme takes a list of valid tokens as input and
produces an output token whose distribution matches that of the target model.
Previous works have demonstrated that the optimal scheme (which maximizes the
probability of accepting one of the input tokens) can be cast as a solution to
a linear program. In this work we show that the optimal scheme can be
decomposed into a two-step solution: in the first step an importance sampling
(IS) type scheme is used to select one intermediate token; in the second step
(single-draft) speculative sampling is applied to generate the output token.
For the case of two identical draft models we further 1) establish a necessary
and sufficient condition on the distributions of the target and draft models
for the acceptance probability to equal one and 2) provide an explicit
expression for the optimal acceptance probability. Our theoretical analysis
also motives a new class of token-level selection schemes based on weighted
importance sampling. Our experimental results demonstrate consistent
improvements in the achievable block efficiency and token rates over baseline
schemes in a number of scenarios.",2024-10-23,"Ashish Khisti, M. Reza Ebrahimi, Hassan Dbouk, Arash Behboodi, Roland Memisevic, Christos Louizos",http://arxiv.org/pdf/2410.18234v2,cs.LG
Assessment of Developmental Dysgraphia Utilising a Display Tablet,"Even though the computerised assessment of developmental dysgraphia (DD)
based on online handwriting processing has increasing popularity, most of the
solutions are based on a setup, where a child writes on a paper fixed to a
digitizing tablet that is connected to a computer. Although this approach
enables the standard way of writing using an inking pen, it is difficult to be
administered by children themselves. The main goal of this study is thus to
explore, whether the quantitative analysis of online handwriting recorded via a
display screen tablet could sufficiently support the assessment of DD as well.
For the purpose of this study, we enrolled 144 children (attending the 3rd and
4th class of a primary school), whose handwriting proficiency was assessed by a
special education counsellor, and who assessed themselves by the Handwriting
Proficiency Screening Questionnaires for Children (HPSQ C). Using machine
learning models based on a gradient-boosting algorithm, we were able to support
the DD diagnosis with up to 83.6% accuracy. The HPSQ C total score was
estimated with a minimum error equal to 10.34 %. Children with DD spent
significantly higher time in-air, they had a higher number of pen elevations, a
bigger height of on-surface strokes, a lower in-air tempo, and a higher
variation in the angular velocity. Although this study shows a promising impact
of DD assessment via display tablets, it also accents the fact that modelling
of subjective scores is challenging and a complex and data-driven
quantification of DD manifestations is needed.",2024-10-23,"Jiri Mekyska, Zoltan Galaz, Katarina Safarova, Vojtech Zvoncak, Lukas Cunek, Tomas Urbanek, Jana Marie Havigerova, Jirina Bednarova, Jan Mucha, Michal Gavenciak, Zdenek Smekal, Marcos Faundez-Zanuy",http://arxiv.org/pdf/2410.18230v1,cs.LG
Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks,"Recent advancements in Large Language Models (LLMs) have sparked widespread
concerns about their safety. Recent work demonstrates that safety alignment of
LLMs can be easily removed by fine-tuning with a few adversarially chosen
instruction-following examples, i.e., fine-tuning attacks. We take a further
step to understand fine-tuning attacks in multilingual LLMs. We first discover
cross-lingual generalization of fine-tuning attacks: using a few adversarially
chosen instruction-following examples in one language, multilingual LLMs can
also be easily compromised (e.g., multilingual LLMs fail to refuse harmful
prompts in other languages). Motivated by this finding, we hypothesize that
safety-related information is language-agnostic and propose a new method termed
Safety Information Localization (SIL) to identify the safety-related
information in the model parameter space. Through SIL, we validate this
hypothesis and find that only changing 20% of weight parameters in fine-tuning
attacks can break safety alignment across all languages. Furthermore, we
provide evidence to the alternative pathways hypothesis for why freezing
safety-related parameters does not prevent fine-tuning attacks, and we
demonstrate that our attack vector can still jailbreak LLMs adapted to new
languages.",2024-10-23,"Samuele Poppi, Zheng-Xin Yong, Yifei He, Bobbie Chern, Han Zhao, Aobo Yang, Jianfeng Chi",http://arxiv.org/pdf/2410.18210v2,cs.LG
Automated Defect Detection and Grading of Piarom Dates Using Deep Learning,"Grading and quality control of Piarom dates, a premium and high-value variety
cultivated predominantly in Iran, present significant challenges due to the
complexity and variability of defects, as well as the absence of specialized
automated systems tailored to this fruit. Traditional manual inspection methods
are labor intensive, time consuming, and prone to human error, while existing
AI-based sorting solutions are insufficient for addressing the nuanced
characteristics of Piarom dates. In this study, we propose an innovative deep
learning framework designed specifically for the real-time detection,
classification, and grading of Piarom dates. Leveraging a custom dataset
comprising over 9,900 high-resolution images annotated across 11 distinct
defect categories, our framework integrates state-of-the-art object detection
algorithms and Convolutional Neural Networks (CNNs) to achieve high precision
in defect identification. Furthermore, we employ advanced segmentation
techniques to estimate the area and weight of each date, thereby optimizing the
grading process according to industry standards. Experimental results
demonstrate that our system significantly outperforms existing methods in terms
of accuracy and computational efficiency, making it highly suitable for
industrial applications requiring real-time processing. This work not only
provides a robust and scalable solution for automating quality control in the
Piarom date industry but also contributes to the broader field of AI-driven
food inspection technologies, with potential applications across various
agricultural products.",2024-10-23,"Nasrin Azimi, Danial Mohammad Rezaei",http://arxiv.org/pdf/2410.18208v1,cs.LG
Vocal Melody Construction for Persian Lyrics Using LSTM Recurrent Neural Networks,"The present paper investigated automatic melody construction for Persian
lyrics as an input. It was assumed that there is a phonological correlation
between the lyric syllables and the melody in a song. A seq2seq neural network
was developed to investigate this assumption, trained on parallel syllable and
note sequences in Persian songs to suggest a pleasant melody for a new sequence
of syllables. More than 100 pieces of Persian music were collected and
converted from the printed version to the digital format due to the lack of a
dataset on Persian digital music. Finally, 14 new lyrics were given to the
model as input, and the suggested melodies were performed and recorded by music
experts to evaluate the trained model. The evaluation was conducted using an
audio questionnaire, which more than 170 persons answered. According to the
answers about the pleasantness of melody, the system outputs scored an average
of 3.005 from 5, while the human-made melodies for the same lyrics obtained an
average score of 4.078.",2024-10-23,"Farshad Jafari, Farzad Didehvar, Amin Gheibi",http://arxiv.org/pdf/2410.18203v1,cs.LG
Rethinking Positive Pairs in Contrastive Learning,"Contrastive learning, a prominent approach to representation learning,
traditionally assumes positive pairs are closely related samples (the same
image or class) and negative pairs are distinct samples. We challenge this
assumption by proposing to learn from arbitrary pairs, allowing any pair of
samples to be positive within our framework.The primary challenge of the
proposed approach lies in applying contrastive learning to disparate pairs
which are semantically distant. Motivated by the discovery that SimCLR can
separate given arbitrary pairs (e.g., garter snake and table lamp) in a
subspace, we propose a feature filter in the condition of class pairs that
creates the requisite subspaces by gate vectors selectively activating or
deactivating dimensions. This filter can be optimized through gradient descent
within a conventional contrastive learning mechanism.
  We present Hydra, a universal contrastive learning framework for visual
representations that extends conventional contrastive learning to accommodate
arbitrary pairs. Our approach is validated using IN1K, where 1K diverse classes
compose 500,500 pairs, most of them being distinct. Surprisingly, Hydra
achieves superior performance in this challenging setting. Additional benefits
include the prevention of dimensional collapse and the discovery of class
relationships. Our work highlights the value of learning common features of
arbitrary pairs and potentially broadens the applicability of contrastive
learning techniques on the sample pairs with weak relationships.",2024-10-23,"Jiantao Wu, Shentong Mo, Zhenhua Feng, Sara Atito, Josef Kitler, Muhammad Awais",http://arxiv.org/pdf/2410.18200v1,cs.LG
ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment,"Data selection is crucial for optimizing language model (LM) performance on
specific tasks, yet most existing methods fail to effectively consider the
target task distribution.
  Current approaches either ignore task-specific requirements entirely or rely
on approximations that fail to capture the nuanced patterns needed for tasks
like Autoformalization or code generation.
  Methods that do consider the target distribution often rely on simplistic,
sometimes noisy, representations, like hashed n-gram features, which can lead
to collisions and introduce noise.
  We introduce ZIP-FIT, a data selection framework that uses gzip compression
to directly measure alignment between potential training data and the target
task distribution.
  In extensive evaluations on Autoformalization and Python code generation,
ZIP-FIT significantly outperforms leading baselines like DSIR and D4.
  Models trained on ZIP-FIT-selected data achieve their lowest cross-entropy
loss up to 85.1\% faster than baselines, demonstrating that better task
alignment leads to more efficient learning.
  In addition, ZIP-FIT performs selection up to 65.8\% faster than DSIR and two
orders of magnitude faster than D4.
  Notably, ZIP-FIT shows that smaller, well-aligned datasets often outperform
larger but less targeted ones, demonstrating that a small amount of higher
quality data is superior to a large amount of lower quality data.
  Our results imply that task-aware data selection is crucial for efficient
domain adaptation, and that compression offers a principled way to measure task
alignment.
  By showing that targeted data selection can dramatically improve
task-specific performance, our work provides new insights into the relationship
between data quality, task alignment, and model learning efficiency.",2024-10-23,"Elyas Obbad, Iddah Mlauzi, Brando Miranda, Rylan Schaeffer, Kamal Obbad, Suhana Bedi, Sanmi Koyejo",http://arxiv.org/pdf/2410.18194v2,cs.LG
TabDPT: Scaling Tabular Foundation Models,"The challenges faced by neural networks on tabular data are well-documented
and have hampered the progress of tabular foundation models. Techniques
leveraging in-context learning (ICL) have shown promise here, allowing for
dynamic adaptation to unseen data. ICL can provide predictions for entirely new
datasets without further training or hyperparameter tuning, therefore providing
very fast inference when encountering a novel task. However, scaling ICL for
tabular data remains an issue: approaches based on large language models cannot
efficiently process numeric tables, and tabular-specific techniques have not
been able to effectively harness the power of real data to improve performance
and generalization. We are able to overcome these challenges by training
tabular-specific ICL-based architectures on real data with self-supervised
learning and retrieval, combining the best of both worlds. Our resulting model
-- the Tabular Discriminative Pre-trained Transformer (TabDPT) -- achieves
state-of-the-art performance on the CC18 (classification) and CTR23
(regression) benchmarks with no task-specific fine-tuning, demonstrating the
adapatability and speed of ICL once the model is pre-trained. TabDPT also
demonstrates strong scaling as both model size and amount of available data
increase, pointing towards future improvements simply through the curation of
larger tabular pre-training datasets and training larger models.",2024-10-23,"Junwei Ma, Valentin Thomas, Rasa Hosseinzadeh, Hamidreza Kamkari, Alex Labach, Jesse C. Cresswell, Keyvan Golestan, Guangwei Yu, Maksims Volkovs, Anthony L. Caterini",http://arxiv.org/pdf/2410.18164v1,cs.LG
Prioritized Generative Replay,"Sample-efficient online reinforcement learning often uses replay buffers to
store experience for reuse when updating the value function. However, uniform
replay is inefficient, since certain classes of transitions can be more
relevant to learning. While prioritization of more useful samples is helpful,
this strategy can also lead to overfitting, as useful samples are likely to be
more rare. In this work, we instead propose a prioritized, parametric version
of an agent's memory, using generative models to capture online experience.
This paradigm enables (1) densification of past experience, with new
generations that benefit from the generative model's generalization capacity
and (2) guidance via a family of ""relevance functions"" that push these
generations towards more useful parts of an agent's acquired history. We show
this recipe can be instantiated using conditional diffusion models and simple
relevance functions such as curiosity- or value-based metrics. Our approach
consistently improves performance and sample efficiency in both state- and
pixel-based domains. We expose the mechanisms underlying these gains, showing
how guidance promotes diversity in our generated transitions and reduces
overfitting. We also showcase how our approach can train policies with even
higher update-to-data ratios than before, opening up avenues to better scale
online RL agents.",2024-10-23,"Renhao Wang, Kevin Frans, Pieter Abbeel, Sergey Levine, Alexei A. Efros",http://arxiv.org/pdf/2410.18082v2,cs.LG
ALTA: Compiler-Based Analysis of Transformers,"We propose a new programming language called ALTA and a compiler that can map
ALTA programs to Transformer weights. ALTA is inspired by RASP, a language
proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler
from RASP programs to Transformer weights. ALTA complements and extends this
prior work, offering the ability to express loops and to compile programs to
Universal Transformers, among other advantages. ALTA allows us to
constructively show how Transformers can represent length-invariant algorithms
for computing parity and addition, as well as a solution to the SCAN benchmark
of compositional generalization tasks, without requiring intermediate
scratchpad decoding steps. We also propose tools to analyze cases where the
expressibility of an algorithm is established, but end-to-end training on a
given training set fails to induce behavior consistent with the desired
algorithm. To this end, we explore training from ALTA execution traces as a
more fine-grained supervision signal. This enables additional experiments and
theoretical analyses relating the learnability of various algorithms to data
availability and modeling decisions, such as positional encodings. We make the
ALTA framework -- language specification, symbolic interpreter, and weight
compiler -- available to the community to enable further applications and
insights.",2024-10-23,"Peter Shaw, James Cohan, Jacob Eisenstein, Kenton Lee, Jonathan Berant, Kristina Toutanova",http://arxiv.org/pdf/2410.18077v1,cs.LG
Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration,"Unsupervised pretraining has been transformative in many supervised domains.
However, applying such ideas to reinforcement learning (RL) presents a unique
challenge in that fine-tuning does not involve mimicking task-specific data,
but rather exploring and locating the solution through iterative
self-improvement. In this work, we study how unlabeled offline trajectory data
can be leveraged to learn efficient exploration strategies. While prior data
can be used to pretrain a set of low-level skills, or as additional off-policy
data for online RL, it has been unclear how to combine these ideas effectively
for online exploration. Our method SUPE (Skills from Unlabeled Prior data for
Exploration) demonstrates that a careful combination of these ideas compounds
their benefits. Our method first extracts low-level skills using a variational
autoencoder (VAE), and then pseudo-labels unlabeled trajectories with
optimistic rewards and high-level action labels, transforming prior data into
high-level, task-relevant examples that encourage novelty-seeking behavior.
Finally, SUPE uses these transformed examples as additional off-policy data for
online RL to learn a high-level policy that composes pretrained low-level
skills to explore efficiently. In our experiments, SUPE consistently
outperforms prior strategies across a suite of 42 long-horizon, sparse-reward
tasks. Code: https://github.com/rail-berkeley/supe.",2024-10-23,"Max Wilcoxson, Qiyang Li, Kevin Frans, Sergey Levine",http://arxiv.org/pdf/2410.18076v3,cs.LG
ProFL: Performative Robust Optimal Federated Learning,"Performative prediction (PP) is a framework that captures distribution shifts
that occur during the training of machine learning models due to their
deployment. As the trained model is used, its generated data could cause the
model to evolve, leading to deviations from the original data distribution. The
impact of such model-induced distribution shifts in the federated learning (FL)
setup remains unexplored despite being increasingly likely to transpire in
real-life use cases. Although Jin et al. (2024) recently extended PP to FL in a
straightforward manner, the resulting model only converges to a performative
stable point, which may be far from optimal. The methods in Izzo et al. (2021);
Miller et al. (2021) can find a performative optimal point in centralized
settings, but they require the performative risk to be convex and the training
data to be noiseless, assumptions often violated in realistic FL systems. This
paper overcomes all of these shortcomings and proposes Performative robust
optimal Federated Learning (ProFL), an algorithm that finds performative
optimal points in FL from noisy and contaminated data. We present the
convergence analysis under the Polyak-Lojasiewicz condition, which applies to
non-convex objectives. Extensive experiments on multiple datasets validate our
proposed algorithms' efficiency.",2024-10-23,"Xue Zheng, Tian Xie, Xuwei Tan, Aylin Yener, Xueru Zhang, Ali Payani, Myungjin Lee",http://arxiv.org/pdf/2410.18075v1,cs.LG
UnCLe: Benchmarking Continual Learning for Unsupervised Depth Completion,"We propose UnCLe, a standardized benchmark for Unsupervised Continual
Learning of a multimodal depth estimation task: Depth completion aims to infer
a dense depth map from a pair of synchronized RGB image and sparse depth map.
We benchmark depth completion models under the practical scenario of
unsupervised learning over continuous streams of data. Existing methods are
typically trained on a static, or stationary, dataset. However, when adapting
to novel non-stationary distributions, they ""catastrophically forget""
previously learned information. UnCLe simulates these non-stationary
distributions by adapting depth completion models to sequences of datasets
containing diverse scenes captured from distinct domains using different visual
and range sensors. We adopt representative methods from continual learning
paradigms and translate them to enable unsupervised continual learning of depth
completion. We benchmark these models for indoor and outdoor and investigate
the degree of catastrophic forgetting through standard quantitative metrics.
Furthermore, we introduce model inversion quality as an additional measure of
forgetting. We find that unsupervised continual learning of depth completion is
an open problem, and we invite researchers to leverage UnCLe as a development
platform.",2024-10-23,"Suchisrit Gangopadhyay, Xien Chen, Michael Chu, Patrick Rim, Hyoungseob Park, Alex Wong",http://arxiv.org/pdf/2410.18074v3,cs.LG
Training Free Guided Flow Matching with Optimal Control,"Controlled generation with pre-trained Diffusion and Flow Matching models has
vast applications. One strategy for guiding ODE-based generative models is
through optimizing a target loss $R(x_1)$ while staying close to the prior
distribution. Along this line, some recent work showed the effectiveness of
guiding flow model by differentiating through its ODE sampling process. Despite
the superior performance, the theoretical understanding of this line of methods
is still preliminary, leaving space for algorithm improvement. Moreover,
existing methods predominately focus on Euclidean data manifold, and there is a
compelling need for guided flow methods on complex geometries such as SO(3),
which prevails in high-stake scientific applications like protein design. We
present OC-Flow, a general and theoretically grounded training-free framework
for guided flow matching using optimal control. Building upon advances in
optimal control theory, we develop effective and practical algorithms for
solving optimal control in guided ODE-based generation and provide a systematic
theoretical analysis of the convergence guarantee in both Euclidean and SO(3).
We show that existing backprop-through-ODE methods can be interpreted as
special cases of Euclidean OC-Flow. OC-Flow achieved superior performance in
extensive experiments on text-guided image manipulation, conditional molecule
generation, and all-atom peptide design.",2024-10-23,"Luran Wang, Chaoran Cheng, Yizhen Liao, Yanru Qu, Ge Liu",http://arxiv.org/pdf/2410.18070v3,cs.LG
Beyond Position: the emergence of wavelet-like properties in Transformers,"This paper studies how transformer models develop robust wavelet-like
properties that effectively compensate for the theoretical limitations of
Rotary Position Embeddings (RoPE), providing insights into how these networks
process sequential information across different scales. Through theoretical
analysis and empirical validation across models ranging from 1B to 12B
parameters, we show that attention heads naturally evolve to implement
multi-resolution processing analogous to wavelet transforms. Our analysis
establishes that attention heads consistently organize into complementary
frequency bands with systematic power distribution patterns, and these
wavelet-like characteristics become more pronounced in larger models. We
provide mathematical analysis showing how these properties align with optimal
solutions to the fundamental uncertainty principle between positional precision
and frequency resolution. Our findings suggest that the effectiveness of modern
transformer architectures stems significantly from their development of optimal
multi-resolution decompositions that naturally address the theoretical
constraints of position encoding.",2024-10-23,"Valeria Ruscio, Fabrizio Silvestri",http://arxiv.org/pdf/2410.18067v3,cs.LG
The Double-Edged Sword of Behavioral Responses in Strategic Classification: Theory and User Studies,"When humans are subject to an algorithmic decision system, they can
strategically adjust their behavior accordingly (``game'' the system). While a
growing line of literature on strategic classification has used game-theoretic
modeling to understand and mitigate such gaming, these existing works consider
standard models of fully rational agents. In this paper, we propose a strategic
classification model that considers behavioral biases in human responses to
algorithms. We show how misperceptions of a classifier (specifically, of its
feature weights) can lead to different types of discrepancies between biased
and rational agents' responses, and identify when behavioral agents over- or
under-invest in different features. We also show that strategic agents with
behavioral biases can benefit or (perhaps, unexpectedly) harm the firm compared
to fully rational strategic agents. We complement our analytical results with
user studies, which support our hypothesis of behavioral biases in human
responses to the algorithm. Together, our findings highlight the need to
account for human (cognitive) biases when designing AI systems, and providing
explanations of them, to strategic human in the loop.",2024-10-23,"Raman Ebrahimi, Kristen Vaccaro, Parinaz Naghizadeh",http://arxiv.org/pdf/2410.18066v2,cs.LG
"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation","Robot learning has proven to be a general and effective technique for
programming manipulators. Imitation learning is able to teach robots solely
from human demonstrations but is bottlenecked by the capabilities of the
demonstrations. Reinforcement learning uses exploration to discover better
behaviors; however, the space of possible improvements can be too large to
start from scratch. And for both techniques, the learning difficulty increases
proportional to the length of the manipulation task. Accounting for this, we
propose SPIRE, a system that first uses Task and Motion Planning (TAMP) to
decompose tasks into smaller learning subproblems and second combines imitation
and reinforcement learning to maximize their strengths. We develop novel
strategies to train learning agents when deployed in the context of a planning
system. We evaluate SPIRE on a suite of long-horizon and contact-rich robot
manipulation problems. We find that SPIRE outperforms prior approaches that
integrate imitation learning, reinforcement learning, and planning by 35% to
50% in average task performance, is 6 times more data efficient in the number
of human demonstrations needed to train proficient agents, and learns to
complete tasks nearly twice as efficiently. View
https://sites.google.com/view/spire-corl-2024 for more details.",2024-10-23,"Zihan Zhou, Animesh Garg, Dieter Fox, Caelan Garrett, Ajay Mandlekar",http://arxiv.org/pdf/2410.18065v1,cs.LG
Stochastic gradient descent in high dimensions for multi-spiked tensor PCA,"We study the dynamics in high dimensions of online stochastic gradient
descent for the multi-spiked tensor model. This multi-index model arises from
the tensor principal component analysis (PCA) problem with multiple spikes,
where the goal is to estimate $r$ unknown signal vectors within the
$N$-dimensional unit sphere through maximum likelihood estimation from noisy
observations of a $p$-tensor. We determine the number of samples and the
conditions on the signal-to-noise ratios (SNRs) required to efficiently recover
the unknown spikes from natural random initializations. We show that full
recovery of all spikes is possible provided a number of sample scaling as
$N^{p-2}$, matching the algorithmic threshold identified in the rank-one case
[Ben Arous, Gheissari, Jagannath 2020, 2021]. Our results are obtained through
a detailed analysis of a low-dimensional system that describes the evolution of
the correlations between the estimators and the spikes, while controlling the
noise in the dynamics. We find that the spikes are recovered sequentially in a
process we term ""sequential elimination"": once a correlation exceeds a critical
threshold, all correlations sharing a row or column index become sufficiently
small, allowing the next correlation to grow and become macroscopic. The order
in which correlations become macroscopic depends on their initial values and
the corresponding SNRs, leading to either exact recovery or recovery of a
permutation of the spikes. In the matrix case, when $p=2$, if the SNRs are
sufficiently separated, we achieve exact recovery of the spikes, whereas equal
SNRs lead to recovery of the subspace spanned by the spikes.",2024-10-23,"Gérard Ben Arous, Cédric Gerbelot, Vanessa Piccolo",http://arxiv.org/pdf/2410.18162v1,cs.LG
POD-Attention: Unlocking Full Prefill-Decode Overlap for Faster LLM Inference,"Each request in LLM inference goes through two phases: compute-bound prefill
and memory-bandwidth-bound decode. To improve GPU utilization, recent systems
use hybrid batching that combines the prefill and decode phases of different
requests into the same batch. This approach optimizes linear operations but
remains inefficient for attention computation because existing attention
kernels specialize execution independently for the prefill and decode phases.
  In this paper, we present POD-Attention - the first GPU kernel that
efficiently computes attention for hybrid batches. POD-Attention aims to
maximize the utilization of both compute and memory bandwidth by carefully
allocating the GPU's resources such that prefill and decode operations happen
concurrently on the same multiprocessor. POD-Attention speeds up attention
computation by up to $59\%$ (mean $28\%$), enabling higher throughput and lower
latency LLM inference compared to the use of independently optimized prefill
and decode attention kernels.",2024-10-23,"Aditya K Kamath, Ramya Prabhu, Jayashree Mohan, Simon Peter, Ramachandran Ramjee, Ashish Panwar",http://arxiv.org/pdf/2410.18038v2,cs.LG
Inferring stability properties of chaotic systems on autoencoders' latent spaces,"The data-driven learning of solutions of partial differential equations can
be based on a divide-and-conquer strategy. First, the high dimensional data is
compressed to a latent space with an autoencoder; and, second, the temporal
dynamics are inferred on the latent space with a form of recurrent neural
network. In chaotic systems and turbulence, convolutional autoencoders and echo
state networks (CAE-ESN) successfully forecast the dynamics, but little is
known about whether the stability properties can also be inferred. We show that
the CAE-ESN model infers the invariant stability properties and the geometry of
the tangent space in the low-dimensional manifold (i.e. the latent space)
through Lyapunov exponents and covariant Lyapunov vectors. This work opens up
new opportunities for inferring the stability of high-dimensional chaotic
systems in latent spaces.",2024-10-23,"Elise Özalp, Luca Magri",http://arxiv.org/pdf/2410.18003v1,cs.LG
Adaptive Segment-level Reward: Bridging the Gap Between Action and Reward Space in Alignment,"Reinforcement Learning (RL) has proven highly effective in aligning Large
Language Models (LLMs) with human preferences. Typical RL methods optimize
under an overall sequence reward, which can lead to a suboptimal learning
process. This reflects a key credit assignment problem: identifying which
tokens to reinforce or suppress. To rectify these shortcomings, step-wise and
token-wise methods have been proposed. However, step-wise methods rely on
punctuation segmentation and still cannot accurately identify the key tokens.
The token-level approach is too fine-grained, attending to many unimportant
tokens and thus introducing a large amount of noise. To assign more accurate
rewards to different tokens, improving credit assignment, we propose the
""Adaptive Segment-wise Reward"" method. We employ semantic meaning, rather than
punctuation, to adaptively delineate segments. Experiments demonstrate that our
method can be integrated into various training methods. Compared to training
methods \textit{without} our approach, our method improves the success rate on
adversarial samples by 10\%, and achieves a 1.3\% improvement on evaluation
benchmarks such as MMLU, GSM8K, HumanEval, etc.",2024-10-23,"Yanshi Li, Shaopan Xiong, Gengru Chen, Xiaoyang Li, Yijia Luo, Xingyuan Bu, Yingshui Tan, Wenbo Su, Bo Zheng",http://arxiv.org/pdf/2411.00809v3,cs.LG
Estimating the Spectral Moments of the Kernel Integral Operator from Finite Sample Matrices,"Analyzing the structure of sampled features from an input data distribution
is challenging when constrained by limited measurements in both the number of
inputs and features. Traditional approaches often rely on the eigenvalue
spectrum of the sample covariance matrix derived from finite measurement
matrices; however, these spectra are sensitive to the size of the measurement
matrix, leading to biased insights. In this paper, we introduce a novel
algorithm that provides unbiased estimates of the spectral moments of the
kernel integral operator in the limit of infinite inputs and features from
finitely sampled measurement matrices. Our method, based on dynamic
programming, is efficient and capable of estimating the moments of the operator
spectrum. We demonstrate the accuracy of our estimator on radial basis function
(RBF) kernels, highlighting its consistency with the theoretical spectra.
Furthermore, we showcase the practical utility and robustness of our method in
understanding the geometry of learned representations in neural networks.",2024-10-23,"Chanwoo Chun, SueYeon Chung, Daniel D. Lee",http://arxiv.org/pdf/2410.17998v3,cs.LG
Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data,"Federated Learning (FL) is an evolving paradigm that enables multiple parties
to collaboratively train models without sharing raw data. Among its variants,
Vertical Federated Learning (VFL) is particularly relevant in real-world,
cross-organizational collaborations, where distinct features of a shared
instance group are contributed by different parties. In these scenarios,
parties are often linked using fuzzy identifiers, leading to a common practice
termed as multi-party fuzzy VFL. Existing models generally address either
multi-party VFL or fuzzy VFL between two parties. Extending these models to
practical multi-party fuzzy VFL typically results in significant performance
degradation and increased costs for maintaining privacy. To overcome these
limitations, we introduce the Federated Transformer (FeT), a novel framework
that supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes
these identifiers into data representations and employs a transformer
architecture distributed across different parties, incorporating three new
techniques to enhance performance. Furthermore, we have developed a multi-party
privacy framework for VFL that integrates differential privacy with secure
multi-party computation, effectively protecting local representations while
minimizing associated utility costs. Our experiments demonstrate that the FeT
surpasses the baseline models by up to 46\% in terms of accuracy when scaled to
50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows
improved performance and privacy over cutting-edge VFL models.",2024-10-23,"Zhaomin Wu, Junyi Hou, Yiqun Diao, Bingsheng He",http://arxiv.org/pdf/2410.17986v1,cs.LG
Scaling Stick-Breaking Attention: An Efficient Implementation and In-depth Study,"The self-attention mechanism traditionally relies on the softmax operator,
necessitating positional embeddings like RoPE, or position biases to account
for token order. But current methods using still face length generalisation
challenges. We investigate an alternative attention mechanism based on the
stick-breaking process in larger scale settings. The method works as follows:
For each token before the current, we determine a break point, which represents
the proportion of the stick, the weight of the attention, to allocate to the
current token. We repeat this on the remaining stick, until all tokens are
allocated a weight, resulting in a sequence of attention weights. This process
naturally incorporates recency bias, which has linguistic motivations for
grammar parsing. We study the implications of replacing the conventional
softmax-based attention mechanism with stick-breaking attention. We then
discuss implementation of numerically stable stick-breaking attention and adapt
Flash Attention to accommodate this mechanism. When used as a drop-in
replacement for current softmax+RoPE attention systems, we find that
stick-breaking attention performs competitively with current methods on length
generalisation and downstream tasks. Stick-breaking also performs well at
length generalisation, allowing a model trained with $2^{11}$ context window to
perform well at $2^{14}$ with perplexity improvements.",2024-10-23,"Shawn Tan, Songlin Yang, Aaron Courville, Rameswar Panda, Yikang Shen",http://arxiv.org/pdf/2410.17980v2,cs.LG
metasnf: Meta Clustering with Similarity Network Fusion in R,"metasnf is an R package that enables users to apply meta clustering, a method
for efficiently searching a broad space of cluster solutions by clustering the
solutions themselves, to clustering workflows based on similarity network
fusion (SNF). SNF is a multi-modal data integration algorithm commonly used for
biomedical subtype discovery. The package also contains functions to assist
with cluster visualization, characterization, and validation. This package can
help researchers identify SNF-derived cluster solutions that are guided by
context-specific utility over context-agnostic measures of quality.",2024-10-23,"Prashanth S Velayudhan, Xiaoqiao Xu, Prajkta Kallurkar, Ana Patricia Balbon, Maria T Secara, Adam Taback, Denise Sabac, Nicholas Chan, Shihao Ma, Bo Wang, Daniel Felsky, Stephanie H Ameis, Brian Cox, Colin Hawco, Lauren Erdman, Anne L Wheeler",http://arxiv.org/pdf/2410.17976v1,cs.LG
Evaluating Deep Learning Approaches for Predictions in Unmonitored Basins with Continental-scale Stream Temperature Models,"The prediction of streamflows and other environmental variables in
unmonitored basins is a grand challenge in hydrology. Recent machine learning
(ML) models can harness vast datasets for accurate predictions at large spatial
scales. However, there are open questions regarding model design and data
needed for inputs and training to improve performance. This study explores
these questions while demonstrating the ability of deep learning models to make
accurate stream temperature predictions in unmonitored basins across the
conterminous United States. First, we compare top-down models that utilize data
from a large number of basins with bottom-up methods that transfer ML models
built on local sites, reflecting traditional regionalization techniques. We
also evaluate an intermediary grouped modeling approach that categorizes sites
based on regional co-location or similarity of catchment characteristics.
Second, we evaluate trade-offs between model complexity, prediction accuracy,
and applicability for more target locations by systematically removing inputs.
We then examine model performance when additional training data becomes
available due to reductions in input requirements. Our results suggest that
top-down models significantly outperform bottom-up and grouped models.
Moreover, it is possible to get acceptable accuracy by reducing both dynamic
and static inputs enabling predictions for more sites with lower model
complexity and computational needs. From detailed error analysis, we determined
that the models are more accurate for sites primarily controlled by air
temperatures compared to locations impacted by groundwater and dams. By
addressing these questions, this research offers a comprehensive perspective on
optimizing ML model design for accurate predictions in unmonitored regions.",2024-10-23,"Jared D. Willard, Fabio Ciulla, Helen Weierbach, Vipin Kumar, Charuleka Varadharajan",http://arxiv.org/pdf/2410.19865v1,cs.LG
Optical Generative Models,"Generative models cover various application areas, including image, video and
music synthesis, natural language processing, and molecular design, among many
others. As digital generative models become larger, scalable inference in a
fast and energy-efficient manner becomes a challenge. Here, we present optical
generative models inspired by diffusion models, where a shallow and fast
digital encoder first maps random noise into phase patterns that serve as
optical generative seeds for a desired data distribution; a jointly-trained
free-space-based reconfigurable decoder all-optically processes these
generative seeds to create novel images (never seen before) following the
target data distribution. Except for the illumination power and the random seed
generation through a shallow encoder, these optical generative models do not
consume computing power during the synthesis of novel images. We report the
optical generation of monochrome and multi-color novel images of handwritten
digits, fashion products, butterflies, and human faces, following the data
distributions of MNIST, Fashion MNIST, Butterflies-100, and Celeb-A datasets,
respectively, achieving an overall performance comparable to digital neural
network-based generative models. To experimentally demonstrate optical
generative models, we used visible light to generate, in a snapshot, novel
images of handwritten digits and fashion products. These optical generative
models might pave the way for energy-efficient, scalable and rapid inference
tasks, further exploiting the potentials of optics and photonics for artificial
intelligence-generated content.",2024-10-23,"Shiqi Chen, Yuhang Li, Hanlong Chen, Aydogan Ozcan",http://arxiv.org/pdf/2410.17970v1,cs.LG
POMDP-Driven Cognitive Massive MIMO Radar: Joint Target Detection-Tracking In Unknown Disturbances,"The joint detection and tracking of a moving target embedded in an unknown
disturbance represents a key feature that motivates the development of the
cognitive radar paradigm. Building upon recent advancements in robust target
detection with multiple-input multiple-output (MIMO) radars, this work explores
the application of a Partially Observable Markov Decision Process (POMDP)
framework to enhance the tracking and detection tasks in a statistically
unknown environment. In the POMDP setup, the radar system is considered as an
intelligent agent that continuously senses the surrounding environment,
optimizing its actions to maximize the probability of detection $(P_D)$ and
improve the target position and velocity estimation, all this while keeping a
constant probability of false alarm $(P_{FA})$. The proposed approach employs
an online algorithm that does not require any apriori knowledge of the noise
statistics, and it relies on a much more general observation model than the
traditional range-azimuth-elevation model employed by conventional tracking
algorithms. Simulation results clearly show substantial performance improvement
of the POMDP-based algorithm compared to the State-Action-Reward-State-Action
(SARSA)-based one that has been recently investigated in the context of massive
MIMO (MMIMO) radar systems.",2024-10-23,"Imad Bouhou, Stefano Fortunati, Leila Gharsalli, Alexandre Renaux",http://arxiv.org/pdf/2410.17967v2,cs.LG
A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024,"The eRisk laboratory aims to address issues related to early risk detection
on the Web. In this year's edition, three tasks were proposed, where Task 2 was
about early detection of signs of anorexia. Early risk detection is a problem
where precision and speed are two crucial objectives. Our research group solved
Task 2 by defining a CPI+DMC approach, addressing both objectives
independently, and a time-aware approach, where precision and speed are
considered a combined single-objective. We implemented the last approach by
explicitly integrating time during the learning process, considering the
ERDE{\theta} metric as the training objective. It also allowed us to
incorporate temporal metrics to validate and select the optimal models. We
achieved outstanding results for the ERDE50 metric and ranking-based metrics,
demonstrating consistency in solving ERD problems.",2024-10-23,"Horacio Thompson, Marcelo Errecalde",http://arxiv.org/pdf/2410.17963v1,cs.LG
Closed-form merging of parameter-efficient modules for Federated Continual Learning,"Model merging has emerged as a crucial technique in Deep Learning, enabling
the integration of multiple models into a unified system while preserving
perfor-mance and scalability. In this respect, the compositional properties of
low-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple
averaging LoRA modules yields a single model that mostly integrates the
capabilities of all individual modules. Building on LoRA, we take a step
further by imposing that the merged model matches the responses of all learned
modules. Solving this objective in closed form yields an indeterminate system
with A and B as unknown variables, indicating the existence of infinitely many
closed-form solutions. To address this challenge, we introduce LoRM, an
alternating optimization strategy that trains one LoRA matrix at a time. This
allows solving for each unknown variable individually, thus finding a unique
solution. We apply our proposed methodology to Federated Class-Incremental
Learning (FCIL), ensuring alignment of model responses both between clients and
across tasks. Our method demonstrates state-of-the-art performance across a
range of FCIL scenarios. The code to reproduce our experiments is available at
github.com/aimagelab/fed-mammoth.",2024-10-23,"Riccardo Salami, Pietro Buzzega, Matteo Mosconi, Jacopo Bonato, Luigi Sabetta, Simone Calderara",http://arxiv.org/pdf/2410.17961v2,cs.LG
Medical Imaging Complexity and its Effects on GAN Performance,"The proliferation of machine learning models in diverse clinical applications
has led to a growing need for high-fidelity, medical image training data. Such
data is often scarce due to cost constraints and privacy concerns. Alleviating
this burden, medical image synthesis via generative adversarial networks (GANs)
emerged as a powerful method for synthetically generating photo-realistic
images based on existing sets of real medical images. However, the exact image
set size required to efficiently train such a GAN is unclear. In this work, we
experimentally establish benchmarks that measure the relationship between a
sample dataset size and the fidelity of the generated images, given the
dataset's distribution of image complexities. We analyze statistical metrics
based on delentropy, an image complexity measure rooted in Shannon's entropy in
information theory. For our pipeline, we conduct experiments with two
state-of-the-art GANs, StyleGAN 3 and SPADE-GAN, trained on multiple medical
imaging datasets with variable sample sizes. Across both GANs, general
performance improved with increasing training set size but suffered with
increasing complexity.",2024-10-23,"William Cagas, Chan Ko, Blake Hsiao, Shryuk Grandhi, Rishi Bhattacharya, Kevin Zhu, Michael Lam",http://arxiv.org/pdf/2410.17959v1,cs.LG
MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers,"In this paper, we propose MCUBERT to enable language models like BERT on tiny
microcontroller units (MCUs) through network and scheduling co-optimization. We
observe the embedding table contributes to the major storage bottleneck for
tiny BERT models. Hence, at the network level, we propose an MCU-aware
two-stage neural architecture search algorithm based on clustered low-rank
approximation for embedding compression. To reduce the inference memory
requirements, we further propose a novel fine-grained MCU-friendly scheduling
strategy. Through careful computation tiling and re-ordering as well as kernel
design, we drastically increase the input sequence lengths supported on MCUs
without any latency or accuracy penalty. MCUBERT reduces the parameter size of
BERT-tiny and BERT-mini by 5.7$\times$ and 3.0$\times$ and the execution memory
by 3.5$\times$ and 4.3$\times$, respectively. MCUBERT also achieves 1.5$\times$
latency reduction. For the first time, MCUBERT enables lightweight BERT models
on commodity MCUs and processing more than 512 tokens with less than 256KB of
memory.",2024-10-23,"Zebin Yang, Renze Chen, Taiqiang Wu, Ngai Wong, Yun Liang, Runsheng Wang, Ru Huang, Meng Li",http://arxiv.org/pdf/2410.17957v1,cs.LG
SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains,"Retrieval-augmented generation (RAG) enhances the question-answering (QA)
abilities of large language models (LLMs) by integrating external knowledge.
However, adapting general-purpose RAG systems to specialized fields such as
science and medicine poses unique challenges due to distribution shifts and
limited access to domain-specific data. To tackle this, we propose SimRAG, a
self-training approach that equips the LLM with joint capabilities of question
answering and question generation for domain adaptation. Our method first
fine-tunes the LLM on instruction-following, question-answering, and
search-related data. Then, it prompts the same LLM to generate diverse
domain-relevant questions from unlabeled corpora, with an additional filtering
strategy to retain high-quality synthetic examples. By leveraging these
self-generated synthetic examples, the LLM can improve their performance on
domain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone
sizes and three domains, demonstrate that SimRAG outperforms baselines by
1.2\%--8.6\%.",2024-10-23,"Ran Xu, Hui Liu, Sreyashi Nag, Zhenwei Dai, Yaochen Xie, Xianfeng Tang, Chen Luo, Yang Li, Joyce C. Ho, Carl Yang, Qi He",http://arxiv.org/pdf/2410.17952v2,cs.LG
Generalized Resubstitution for Regression Error Estimation,"We propose generalized resubstitution error estimators for regression, a
broad family of estimators, each corresponding to a choice of empirical
probability measures and loss function. The usual sum of squares criterion is a
special case corresponding to the standard empirical probability measure and
the quadratic loss. Other choices of empirical probability measure lead to more
general estimators with superior bias and variance properties. We prove that
these error estimators are consistent under broad assumptions. In addition,
procedures for choosing the empirical measure based on the method of moments
and maximum pseudo-likelihood are proposed and investigated. Detailed
experimental results using polynomial regression demonstrate empirically the
superior finite-sample bias and variance properties of the proposed estimators.
The R code for the experiments is provided.",2024-10-23,"Diego Marcondes, Ulisses Braga-Neto",http://arxiv.org/pdf/2410.17948v1,cs.LG
"Theoretically Grounded Pruning of Large Ground Sets for Constrained, Discrete Optimization","Modern instances of combinatorial optimization problems often exhibit
billion-scale ground sets, which have many uninformative or redundant elements.
In this work, we develop light-weight pruning algorithms to quickly discard
elements that are unlikely to be part of an optimal solution. Under mild
assumptions on the instance, we prove theoretical guarantees on the fraction of
the optimal value retained and the size of the resulting pruned ground set.
Through extensive experiments on real-world datasets for various applications,
we demonstrate that our algorithm, QuickPrune, efficiently prunes over 90% of
the ground set and outperforms state-of-the-art classical and machine learning
heuristics for pruning.",2024-10-23,"Ankur Nath, Alan Kuhnle",http://arxiv.org/pdf/2410.17945v1,cs.LG
"Optimizing Travel Itineraries with AI Algorithms in a Microservices Architecture: Balancing Cost, Time, Preferences, and Sustainability","The objective of this research is how an implementation of AI algorithms in
the microservices architecture enhances travel itineraries by cost, time, user
preferences, and environmental sustainability. It uses machine learning models
for both cost forecasting and personalization, genetic algorithm for
optimization of the itinerary, and heuristics for sustainability checking.
Primary evaluated parameters consist of latency, ability to satisfy user
preferences, cost and environmental concern. The experimental results
demonstrate an average of 4.5 seconds of response time on 1000 concurrent users
and 92% of user preferences accuracy. The cost efficiency is proved, with 95%
of provided trips being within the limits of the budget declared by the user.
The system also implements some measures to alleviate negative externalities
related to travel and 60% of offered travel plans had green options
incorporated, resulting in the average 15% lower carbon emissions than the
traditional travel plans offered. The genetic algorithm with time complexity
O(g.p.f) provides the optimal solution in 100 generations. Every iteration
improves the quality of the solution by 5%, thus enabling its effective use in
optimization problems where time is measured in seconds. Finally, the system is
designed to be fault-tolerant with functional 99.9% availability which allows
the provision of services even when requirements are exceeded. Travel
optimization platform is turned dynamic and efficient by this microservices
based architecture which provides enhanced scaling, allows asynchronous
communication and real time changes. Because of the incorporation of Ai, cost
control and eco-friendliness approaches, the system addresses the different
user needs in the present days travel business.",2024-10-23,"Biman Barua, M. Shamim Kaiser",http://arxiv.org/pdf/2410.17943v1,cs.LG
Spiking Graph Neural Network on Riemannian Manifolds,"Graph neural networks (GNNs) have become the dominant solution for learning
on graphs, the typical non-Euclidean structures. Conventional GNNs, constructed
with the Artificial Neuron Network (ANN), have achieved impressive performance
at the cost of high computation and energy consumption. In parallel, spiking
GNNs with brain-like spiking neurons are drawing increasing research attention
owing to the energy efficiency. So far, existing spiking GNNs consider graphs
in Euclidean space, ignoring the structural geometry, and suffer from the high
latency issue due to Back-Propagation-Through-Time (BPTT) with the surrogate
gradient. In light of the aforementioned issues, we are devoted to exploring
spiking GNN on Riemannian manifolds, and present a Manifold-valued Spiking GNN
(MSG). In particular, we design a new spiking neuron on geodesically complete
manifolds with the diffeomorphism, so that BPTT regarding the spikes is
replaced by the proposed differentiation via manifold. Theoretically, we show
that MSG approximates a solver of the manifold ordinary differential equation.
Extensive experiments on common graphs show the proposed MSG achieves superior
performance to previous spiking GNNs and energy efficiency to conventional
GNNs.",2024-10-23,"Li Sun, Zhenhao Huang, Qiqi Wan, Hao Peng, Philip S. Yu",http://arxiv.org/pdf/2410.17941v1,cs.LG
Semi-Implicit Functional Gradient Flow for Efficient Sampling,"Particle-based variational inference methods (ParVIs) use nonparametric
variational families represented by particles to approximate the target
distribution according to the kernelized Wasserstein gradient flow for the
Kullback-Leibler (KL) divergence. Although functional gradient flows have been
introduced to expand the kernel space for better flexibility, the deterministic
updating mechanism may limit exploration and require expensive repetitive runs
for new samples. In this paper, we propose Semi-Implicit Functional Gradient
flow (SIFG), a functional gradient ParVI method that uses perturbed particles
with Gaussian noise as the approximation family. We show that the corresponding
functional gradient flow, which can be estimated via denoising score matching
with neural networks, exhibits strong theoretical convergence guarantees due to
a higher-order smoothness brought to the approximation family via Gaussian
perturbation. In addition, we present an adaptive version of our method that
automatically selects the appropriate noise magnitude during sampling, striking
a good balance between exploration efficiency and approximation accuracy.
Extensive experiments on both simulated and real-world datasets demonstrate the
effectiveness and efficiency of the proposed framework.",2024-10-23,"Shiyue Zhang, Ziheng Cheng, Cheng Zhang",http://arxiv.org/pdf/2410.17935v2,cs.LG
Retrieving snow depth distribution by downscaling ERA5 Reanalysis with ICESat-2 laser altimetry,"Estimating the variability of seasonal snow cover, in particular snow depth
in remote areas, poses significant challenges due to limited spatial and
temporal data availability. This study uses snow depth measurements from the
ICESat-2 satellite laser altimeter, which are sparse in both space and time,
and incorporates them with climate reanalysis data into a
downscaling-calibration scheme to produce monthly gridded snow depth maps at
microscale (10 m). Snow surface elevation measurements from ICESat-2 along
profiles are compared to a digital elevation model to determine snow depth at
each point. To efficiently turn sparse measurements into snow depth maps, a
regression model is fitted to establish a relationship between the retrieved
snow depth and the corresponding ERA5 Land snow depth. This relationship,
referred to as subgrid variability, is then applied to downscale the monthly
ERA5 Land snow depth data. The method can provide timeseries of monthly snow
depth maps for the entire ERA5 time range (since 1950). The validation of
downscaled snow depth data was performed at an intermediate scale (100 m x 500
m) using datasets from airborne laser scanning (ALS) in the Hardangervidda
region of southern Norway. Results show that snow depth prediction achieved R2
values ranging from 0.74 to 0.88 (post-calibration). The method relies on
globally available data and is applicable to other snow regions above the
treeline. Though requiring area-specific calibration, our approach has the
potential to provide snow depth maps in areas where no such data exist and can
be used to extrapolate existing snow surveys in time and over larger areas.
With this, it can offer valuable input data for hydrological, ecological or
permafrost modeling tasks.",2024-10-23,"Zhihao Liu, Simon Filhol, Désirée Treichler",http://arxiv.org/pdf/2410.17934v1,cs.LG
Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning,"One of the biggest challenges of building artificial intelligence (AI) model
in healthcare area is the data sharing. Since healthcare data is private,
sensitive, and heterogeneous, collecting sufficient data for modelling is
exhausted, costly, and sometimes impossible. In this paper, we propose a
framework for global healthcare modelling using datasets from multi-continents
(Europe, North America and Asia) while without sharing the local datasets, and
choose glucose management as a study model to verify its effectiveness.
Technically, blockchain-enabled federated learning is implemented with adaption
to make it meet with the privacy and safety requirements of healthcare data,
meanwhile rewards honest participation and penalize malicious activities using
its on-chain incentive mechanism. Experimental results show that the proposed
framework is effective, efficient, and privacy preserved. Its prediction
accuracy is much better than the models trained from limited personal data and
is similar to, and even slightly better than, the results from a centralized
dataset. This work paves the way for international collaborations on healthcare
projects, where additional data is crucial for reducing bias and providing
benefits to humanity.",2024-10-23,"Rui Sun, Zhipeng Wang, Hengrui Zhang, Ming Jiang, Yizhe Wen, Jiqun Zhang, Jiahao Sun, Shuoying Zhang, Erwu Liu, Kezhi Li",http://arxiv.org/pdf/2410.17933v1,cs.LG
Future Token Prediction -- Causal Language Modelling with Per-Token Semantic State Vector for Multi-Token Prediction,"Causal decoder-only transformer models used for generative language
modelling, such as Generative Pre-trained Transformers (GPT), are trained to
predict the next token in a sequence based only on its previous tokens. Despite
this simple training objective, they have proved to be powerful AI tools.
However, only predicting the next token results in top layer embedding vectors
that are highly token-focused. There may be benefits in generating embedding
vectors at each token position that better capture the overall meaning of
longer sequences of future text. Recent studies matching brain scans with deep
language models suggest that humans also predict upcoming words when listening
or reading but consider multiple future tokens rather than just one.
  This research investigates a new pretraining method called Future Token
Prediction (FTP). In FTP, a large transformer encoder generates top layer
embedding vectors for each token position, which, instead of being passed to a
language head, are linearly and expansively projected to a pseudo-sequence,
which is cross attended to by a small transformer decoder to predict the next N
tokens forward from that position in the sequence.
  The top layer embedding vectors from FTP models exhibit distinct properties
compared to those from standard GPT models, varying smoothly along a text
sequence as measured by cosine similarity between adjacent tokens. Text
generated by FTP models show improved topic coherence compared to standard
GPT-like models trained with the same prediction perplexity for the next single
token. The vectors are shown to better represent the topic of text based on the
results of text classification examples. On a toy, but complex, coding problem,
FTP networks produce significantly better results than GPT networks.",2024-10-23,Nicholas Walker,http://arxiv.org/pdf/2410.18160v1,cs.LG
Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation,"Integrating multi-modal clinical data, such as electronic health records
(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical
prediction tasks. However, in a temporal setting, multi-modal data are often
inherently asynchronous. EHR can be continuously collected but CXR is generally
taken with a much longer interval due to its high cost and radiation dose. When
clinical prediction is needed, the last available CXR image might have been
outdated, leading to suboptimal predictions. To address this challenge, we
propose DDL-CXR, a method that dynamically generates an up-to-date latent
representation of the individualized CXR images. Our approach leverages latent
diffusion models for patient-specific generation strategically conditioned on a
previous CXR image and EHR time series, providing information regarding
anatomical structures and disease progressions, respectively. In this way, the
interaction across modalities could be better captured by the latent CXR
generation process, ultimately improving the prediction performance.
Experiments using MIMIC datasets show that the proposed model could effectively
address asynchronicity in multimodal fusion and consistently outperform
existing methods.",2024-10-23,"Wenfang Yao, Chen Liu, Kejing Yin, William K. Cheung, Jing Qin",http://arxiv.org/pdf/2410.17918v1,cs.LG
regAL: Python Package for Active Learning of Regression Problems,"Increasingly more research areas rely on machine learning methods to
accelerate discovery while saving resources. Machine learning models, however,
usually require large datasets of experimental or computational results, which
in certain fields, such as (bio)chemistry, materials science, or medicine, are
rarely given and often prohibitively expensive to obtain. To bypass that
obstacle, active learning methods are employed to develop machine learning
models with a desired performance while requiring the least possible number of
computational or experimental results from the domain of application. For this
purpose, the model's knowledge about certain regions of the application domain
is estimated to guide the choice of the model's training set. Although active
learning is widely studied for classification problems (discrete outcomes),
comparatively few works handle this method for regression problems (continuous
outcomes). In this work, we present our Python package regAL, which allows
users to evaluate different active learning strategies for regression problems.
With a minimal input of just the dataset in question, but many additional
customization and insight options, this package is intended for anyone who aims
to perform and understand active learning in their problem-specific scope.",2024-10-23,"Elizaveta Surzhikova, Jonny Proppe",http://arxiv.org/pdf/2410.17917v1,cs.LG
Deep learning for model correction of dynamical systems with data scarcity,"We present a deep learning framework for correcting existing dynamical system
models utilizing only a scarce high-fidelity data set. In many practical
situations, one has a low-fidelity model that can capture the dynamics
reasonably well but lacks high resolution, due to the inherent limitation of
the model and the complexity of the underlying physics. When high resolution
data become available, it is natural to seek model correction to improve the
resolution of the model predictions. We focus on the case when the amount of
high-fidelity data is so small that most of the existing data driven modeling
methods cannot be applied. In this paper, we address these challenges with a
model-correction method which only requires a scarce high-fidelity data set.
Our method first seeks a deep neural network (DNN) model to approximate the
existing low-fidelity model. By using the scarce high-fidelity data, the method
then corrects the DNN model via transfer learning (TL). After TL, an improved
DNN model with high prediction accuracy to the underlying dynamics is obtained.
One distinct feature of the propose method is that it does not assume a
specific form of the model correction terms. Instead, it offers an inherent
correction to the low-fidelity model via TL. A set of numerical examples are
presented to demonstrate the effectiveness of the proposed method.",2024-10-23,"Caroline Tatsuoka, Dongbin Xiu",http://arxiv.org/pdf/2410.17913v1,cs.LG
Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity,"Real-world applications of reinforcement learning often involve environments
where agents operate on complex, high-dimensional observations, but the
underlying (''latent'') dynamics are comparatively simple. However, outside of
restrictive settings such as small latent spaces, the fundamental statistical
requirements and algorithmic principles for reinforcement learning under latent
dynamics are poorly understood.
  This paper addresses the question of reinforcement learning under
$\textit{general}$ latent dynamics from a statistical and algorithmic
perspective. On the statistical side, our main negative result shows that most
well-studied settings for reinforcement learning with function approximation
become intractable when composed with rich observations; we complement this
with a positive result, identifying latent pushforward coverability as a
general condition that enables statistical tractability. Algorithmically, we
develop provably efficient observable-to-latent reductions -- that is,
reductions that transform an arbitrary algorithm for the latent MDP into an
algorithm that can operate on rich observations -- in two settings: one where
the agent has access to hindsight observations of the latent dynamics [LADZ23],
and one where the agent can estimate self-predictive latent models [SAGHCB20].
Together, our results serve as a first step toward a unified statistical and
algorithmic theory for reinforcement learning under latent dynamics.",2024-10-23,"Philip Amortila, Dylan J. Foster, Nan Jiang, Akshay Krishnamurthy, Zakaria Mhammedi",http://arxiv.org/pdf/2410.17904v1,cs.LG
Scalable Offline Reinforcement Learning for Mean Field Games,"Reinforcement learning algorithms for mean-field games offer a scalable
framework for optimizing policies in large populations of interacting agents.
Existing methods often depend on online interactions or access to system
dynamics, limiting their practicality in real-world scenarios where such
interactions are infeasible or difficult to model. In this paper, we present
Offline Munchausen Mirror Descent (Off-MMD), a novel mean-field RL algorithm
that approximates equilibrium policies in mean-field games using purely offline
data. By leveraging iterative mirror descent and importance sampling
techniques, Off-MMD estimates the mean-field distribution from static datasets
without relying on simulation or environment dynamics. Additionally, we
incorporate techniques from offline reinforcement learning to address common
issues like Q-value overestimation, ensuring robust policy learning even with
limited data coverage. Our algorithm scales to complex environments and
demonstrates strong performance on benchmark tasks like crowd exploration or
navigation, highlighting its applicability to real-world multi-agent systems
where online experimentation is infeasible. We empirically demonstrate the
robustness of Off-MMD to low-quality datasets and conduct experiments to
investigate its sensitivity to hyperparameter choices.",2024-10-23,"Axel Brunnbauer, Julian Lemmel, Zahra Babaiee, Sophie Neubauer, Radu Grosu",http://arxiv.org/pdf/2410.17898v1,cs.LG
Identifiable Representation and Model Learning for Latent Dynamic Systems,"Learning identifiable representations and models from low-level observations
is helpful for an intelligent spacecraft to complete downstream tasks reliably.
For temporal observations, to ensure that the data generating process is
provably inverted, most existing works either assume the noise variables in the
dynamic mechanisms are (conditionally) independent or require that the
interventions can directly affect each latent variable. However, in practice,
the relationship between the exogenous inputs/interventions and the latent
variables may follow some complex deterministic mechanisms. In this work, we
study the problem of identifiable representation and model learning for latent
dynamic systems. The key idea is to use an inductive bias inspired by
controllable canonical forms, which are sparse and input-dependent by
definition. We prove that, for linear and affine nonlinear latent dynamic
systems with sparse input matrices, it is possible to identify the latent
variables up to scaling and determine the dynamic models up to some simple
transformations. The results have the potential to provide some theoretical
guarantees for developing more trustworthy decision-making and control methods
for intelligent spacecrafts.",2024-10-23,"Congxi Zhang, Yongchun Xie",http://arxiv.org/pdf/2410.17882v2,cs.LG
AdaRankGrad: Adaptive Gradient-Rank and Moments for Memory-Efficient LLMs Training and Fine-Tuning,"Training and fine-tuning large language models (LLMs) come with challenges
related to memory and computational requirements due to the increasing size of
the model weights and the optimizer states. Various techniques have been
developed to tackle these challenges, such as low-rank adaptation (LoRA), which
involves introducing a parallel trainable low-rank matrix to the fixed
pre-trained weights at each layer. However, these methods often fall short
compared to the full-rank weight training approach, as they restrict the
parameter search to a low-rank subspace. This limitation can disrupt training
dynamics and require a full-rank warm start to mitigate the impact. In this
paper, we introduce a new method inspired by a phenomenon we formally prove: as
training progresses, the rank of the estimated layer gradients gradually
decreases, and asymptotically approaches rank one. Leveraging this, our
approach involves adaptively reducing the rank of the gradients during Adam
optimization steps, using an efficient online-updating low-rank projections
rule. We further present a randomized SVD scheme for efficiently finding the
projection matrix. Our technique enables full-parameter fine-tuning with
adaptive low-rank gradient updates, significantly reducing overall memory
requirements during training compared to state-of-the-art methods while
improving model performance in both pretraining and fine-tuning. Finally, we
provide a convergence analysis of our method and demonstrate its merits for
training and fine-tuning language and biological foundation models.",2024-10-23,"Yehonathan Refael, Jonathan Svirsky, Boris Shustin, Wasim Huleihel, Ofir Lindenbaum",http://arxiv.org/pdf/2410.17881v2,cs.LG
Relaxed Equivariance via Multitask Learning,"Incorporating equivariance as an inductive bias into deep learning
architectures to take advantage of the data symmetry has been successful in
multiple applications, such as chemistry and dynamical systems. In particular,
roto-translations are crucial for effectively modeling geometric graphs and
molecules, where understanding the 3D structures enhances generalization.
However, equivariant models often pose challenges due to their high
computational complexity. In this paper, we introduce REMUL, a training
procedure for approximating equivariance with multitask learning. We show that
unconstrained models (which do not build equivariance into the architecture)
can learn approximate symmetries by minimizing an additional simple
equivariance loss. By formulating equivariance as a new learning objective, we
can control the level of approximate equivariance in the model. Our method
achieves competitive performance compared to equivariant baselines while being
$10 \times$ faster at inference and $2.5 \times$ at training.",2024-10-23,"Ahmed A. Elhag, T. Konstantin Rusch, Francesco Di Giovanni, Michael Bronstein",http://arxiv.org/pdf/2410.17878v2,cs.LG
Fast and interpretable electricity consumption scenario generation for individual consumers,"To enable the transition from fossil fuels towards renewable energy, the
low-voltage grid needs to be reinforced at a faster pace and on a larger scale
than was historically the case. To efficiently plan reinforcements, one needs
to estimate the currents and voltages throughout the grid, which are unknown
but can be calculated from the grid layout and the electricity consumption time
series of each consumer. However, for many consumers, these time series are
unknown and have to be estimated from the available consumer information. We
refer to this task as scenario generation. The state-of-the-art approach that
generates electricity consumption scenarios is complex, resulting in a
computationally expensive procedure with only limited interpretability. To
alleviate these drawbacks, we propose a fast and interpretable scenario
generation technique based on predictive clustering trees (PCTs) that does not
compromise accuracy. In our experiments on three datasets from different
locations, we found that our proposed approach generates time series that are
at least as accurate as the state-of-the-art while being at least 7 times
faster in training and prediction. Moreover, the interpretability of the PCT
allows domain experts to gain insight into their data while simultaneously
building trust in the predictions of the model.",2024-10-23,"J. Soenen, A. Yurtman, T. Becker, K. Vanthournout, H. Blockeel",http://arxiv.org/pdf/2411.05014v1,cs.LG
Enhancing literature review with LLM and NLP methods. Algorithmic trading case,"This study utilizes machine learning algorithms to analyze and organize
knowledge in the field of algorithmic trading. By filtering a dataset of 136
million research papers, we identified 14,342 relevant articles published
between 1956 and Q1 2020. We compare traditional practices-such as
keyword-based algorithms and embedding techniques-with state-of-the-art topic
modeling methods that employ dimensionality reduction and clustering. This
comparison allows us to assess the popularity and evolution of different
approaches and themes within algorithmic trading. We demonstrate the usefulness
of Natural Language Processing (NLP) in the automatic extraction of knowledge,
highlighting the new possibilities created by the latest iterations of Large
Language Models (LLMs) like ChatGPT. The rationale for focusing on this topic
stems from our analysis, which reveals that research articles on algorithmic
trading are increasing at a faster rate than the overall number of
publications. While stocks and main indices comprise more than half of all
assets considered, certain asset classes, such as cryptocurrencies, exhibit a
much stronger growth trend. Machine learning models have become the most
popular methods in recent years. The study demonstrates the efficacy of LLMs in
refining datasets and addressing intricate questions about the analyzed
articles, such as comparing the efficiency of different models. Our research
shows that by decomposing tasks into smaller components and incorporating
reasoning steps, we can effectively tackle complex questions supported by case
analyses. This approach contributes to a deeper understanding of algorithmic
trading methodologies and underscores the potential of advanced NLP techniques
in literature reviews.",2024-10-23,"Stanisław Łaniewski, Robert Ślepaczuk",http://arxiv.org/pdf/2411.05013v1,cs.LG
Population stratification for prediction of mortality in post-AKI patients,"Acute kidney injury (AKI) is a serious clinical condition that affects up to
20% of hospitalised patients. AKI is associated with short term unplanned
hospital readmission and post-discharge mortality risk. Patient risk and
healthcare expenditures can be minimised by followup planning grounded on
predictive models and machine learning. Since AKI is multi-factorial,
predictive models specialised in different categories of patients can increase
accuracy of predictions. In the present article we present some results
following this approach.",2024-10-23,"Flavio S. Correa da Silva, Simon Sawhney",http://arxiv.org/pdf/2410.17865v1,cs.LG
CASCRNet: An Atrous Spatial Pyramid Pooling and Shared Channel Residual based Network for Capsule Endoscopy,"This manuscript summarizes work on the Capsule Vision Challenge 2024 by
MISAHUB. To address the multi-class disease classification task, which is
challenging due to the complexity and imbalance in the Capsule Vision challenge
dataset, this paper proposes CASCRNet (Capsule endoscopy-Aspp-SCR-Network), a
parameter-efficient and novel model that uses Shared Channel Residual (SCR)
blocks and Atrous Spatial Pyramid Pooling (ASPP) blocks. Further, the
performance of the proposed model is compared with other well-known approaches.
The experimental results yield that proposed model provides better disease
classification results. The proposed model was successful in classifying
diseases with an F1 Score of 78.5% and a Mean AUC of 98.3%, which is promising
given its compact architecture.",2024-10-23,"K V Srinanda, M Manvith Prabhu, Shyam Lal",http://arxiv.org/pdf/2410.17863v2,cs.LG
The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification,"Tsetlin Machines (TMs) have emerged as a compelling alternative to
conventional deep learning methods, offering notable advantages such as smaller
memory footprint, faster inference, fault-tolerant properties, and
interpretability. Although various adaptations of TMs have expanded their
applicability across diverse domains, a fundamental gap remains in
understanding how TMs quantify uncertainty in their predictions. In response,
this paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed
at providing a robust, reliable, and interpretable approach for uncertainty
quantification. Unlike the original TM, the PTM learns the probability of
staying on each state of each Tsetlin Automaton (TA) across all clauses. These
probabilities are updated using the feedback tables that are part of the TM
framework: Type I and Type II feedback. During inference, TAs decide their
actions by sampling states based on learned probability distributions, akin to
Bayesian neural networks when generating weight values. In our experimental
analysis, we first illustrate the spread of the probabilities across TA states
for the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models
using both simulated and real-world datasets. The experiments on the simulated
dataset reveal the PTM's effectiveness in uncertainty quantification,
particularly in delineating decision boundaries and identifying regions of high
uncertainty. Moreover, when applied to multiclass classification tasks using
the Iris dataset, the PTM demonstrates competitive performance in terms of
predictive entropy and expected calibration error, showcasing its potential as
a reliable tool for uncertainty estimation. Our findings underscore the
importance of selecting appropriate models for accurate uncertainty
quantification in predictive tasks, with the PTM offering a particularly
interpretable and effective solution.",2024-10-23,"K. Darshana Abeyrathna, Sara El Mekkaoui, Andreas Hafver, Christian Agrell",http://arxiv.org/pdf/2410.17851v2,cs.LG
Is the GPU Half-Empty or Half-Full? Practical Scheduling Techniques for LLMs,"Serving systems for Large Language Models (LLMs) improve throughput by
processing several requests concurrently. However, multiplexing hardware
resources between concurrent requests involves non-trivial scheduling
decisions. Practical serving systems typically implement these decisions at two
levels: First, a load balancer routes requests to different servers which each
hold a replica of the LLM. Then, on each server, an engine-level scheduler
decides when to run a request, or when to queue or preempt it. Improved
scheduling policies may benefit a wide range of LLM deployments and can often
be implemented as ""drop-in replacements"" to a system's current policy. In this
work, we survey scheduling techniques from the literature and from practical
serving systems. We find that schedulers from the literature often achieve good
performance but introduce significant complexity. In contrast, schedulers in
practical deployments often leave easy performance gains on the table but are
easy to implement, deploy and configure. This finding motivates us to introduce
two new scheduling techniques, which are both easy to implement, and outperform
current techniques on production workload traces.",2024-10-23,"Ferdi Kossmann, Bruce Fontaine, Daya Khudia, Michael Cafarella, Samuel Madden",http://arxiv.org/pdf/2410.17840v2,cs.LG
Optimal Streaming Algorithms for Multi-Armed Bandits,"This paper studies two variants of the best arm identification (BAI) problem
under the streaming model, where we have a stream of $n$ arms with reward
distributions supported on $[0,1]$ with unknown means. The arms in the stream
are arriving one by one, and the algorithm cannot access an arm unless it is
stored in a limited size memory.
  We first study the streaming \eps-$top$-$k$ arms identification problem,
which asks for $k$ arms whose reward means are lower than that of the $k$-th
best arm by at most $\eps$ with probability at least $1-\delta$. For general
$\eps \in (0,1)$, the existing solution for this problem assumes $k = 1$ and
achieves the optimal sample complexity $O(\frac{n}{\eps^2} \log
\frac{1}{\delta})$ using $O(\log^*(n))$ ($\log^*(n)$ equals the number of times
that we need to apply the logarithm function on $n$ before the results is no
more than 1.) memory and a single pass of the stream. We propose an algorithm
that works for any $k$ and achieves the optimal sample complexity
$O(\frac{n}{\eps^2} \log\frac{k}{\delta})$ using a single-arm memory and a
single pass of the stream.
  Second, we study the streaming BAI problem, where the objective is to
identify the arm with the maximum reward mean with at least $1-\delta$
probability, using a single-arm memory and as few passes of the input stream as
possible. We present a single-arm-memory algorithm that achieves a near
instance-dependent optimal sample complexity within $O(\log \Delta_2^{-1})$
passes, where $\Delta_2$ is the gap between the mean of the best arm and that
of the second best arm.",2024-10-23,"Tianyuan Jin, Keke Huang, Jing Tang, Xiaokui Xiao",http://arxiv.org/pdf/2410.17835v1,cs.LG
Non-intrusive Speech Quality Assessment with Diffusion Models Trained on Clean Speech,"Diffusion models have found great success in generating high quality, natural
samples of speech, but their potential for density estimation for speech has so
far remained largely unexplored. In this work, we leverage an unconditional
diffusion model trained only on clean speech for the assessment of speech
quality. We show that the quality of a speech utterance can be assessed by
estimating the likelihood of a corresponding sample in the terminating Gaussian
distribution, obtained via a deterministic noising process. The resulting
method is purely unsupervised, trained only on clean speech, and therefore does
not rely on annotations. Our diffusion-based approach leverages clean speech
priors to assess quality based on how the input relates to the learned
distribution of clean data. Our proposed log-likelihoods show promising
results, correlating well with intrusive speech quality metrics such as POLQA
and SI-SDR.",2024-10-23,"Danilo de Oliveira, Julius Richter, Jean-Marie Lemercier, Simon Welker, Timo Gerkmann",http://arxiv.org/pdf/2410.17834v1,cs.LG
Att2CPC: Attention-Guided Lossy Attribute Compression of Point Clouds,"With the great progress of 3D sensing and acquisition technology, the volume
of point cloud data has grown dramatically, which urges the development of
efficient point cloud compression methods. In this paper, we focus on the task
of learned lossy point cloud attribute compression (PCAC). We propose an
efficient attention-based method for lossy compression of point cloud
attributes leveraging on an autoencoder architecture. Specifically, at the
encoding side, we conduct multiple downsampling to best exploit the local
attribute patterns, in which effective External Cross Attention (ECA) is
devised to hierarchically aggregate features by intergrating attributes and
geometry contexts. At the decoding side, the attributes of the point cloud are
progressively reconstructed based on the multi-scale representation and the
zero-padding upsampling tactic. To the best of our knowledge, this is the first
approach to introduce attention mechanism to point-based lossy PCAC task. We
verify the compression efficiency of our model on various sequences, including
human body frames, sparse objects, and large-scale point cloud scenes.
Experiments show that our method achieves an average improvement of 1.15 dB and
2.13 dB in BD-PSNR of Y channel and YUV channel, respectively, when comparing
with the state-of-the-art point-based method Deep-PCAC. Codes of this paper are
available at https://github.com/I2-Multimedia-Lab/Att2CPC.",2024-10-23,"Kai Liu, Kang You, Pan Gao, Manoranjan Paul",http://arxiv.org/pdf/2410.17823v1,cs.LG
Learning Lossless Compression for High Bit-Depth Volumetric Medical Image,"Recent advances in learning-based methods have markedly enhanced the
capabilities of image compression. However, these methods struggle with high
bit-depth volumetric medical images, facing issues such as degraded
performance, increased memory demand, and reduced processing speed. To address
these challenges, this paper presents the Bit-Division based Lossless
Volumetric Image Compression (BD-LVIC) framework, which is tailored for high
bit-depth medical volume compression. The BD-LVIC framework skillfully divides
the high bit-depth volume into two lower bit-depth segments: the Most
Significant Bit-Volume (MSBV) and the Least Significant Bit-Volume (LSBV). The
MSBV concentrates on the most significant bits of the volumetric medical image,
capturing vital structural details in a compact manner. This reduction in
complexity greatly improves compression efficiency using traditional codecs.
Conversely, the LSBV deals with the least significant bits, which encapsulate
intricate texture details. To compress this detailed information effectively,
we introduce an effective learning-based compression model equipped with a
Transformer-Based Feature Alignment Module, which exploits both intra-slice and
inter-slice redundancies to accurately align features. Subsequently, a Parallel
Autoregressive Coding Module merges these features to precisely estimate the
probability distribution of the least significant bit-planes. Our extensive
testing demonstrates that the BD-LVIC framework not only sets new performance
benchmarks across various datasets but also maintains a competitive coding
speed, highlighting its significant potential and practical utility in the
realm of volumetric medical image compression.",2024-10-23,"Kai Wang, Yuanchao Bai, Daxin Li, Deming Zhai, Junjun Jiang, Xianming Liu",http://arxiv.org/pdf/2410.17814v1,cs.LG
A Comprehensive Analysis on the Learning Curve in Kernel Ridge Regression,"This paper conducts a comprehensive study of the learning curves of kernel
ridge regression (KRR) under minimal assumptions. Our contributions are
three-fold: 1) we analyze the role of key properties of the kernel, such as its
spectral eigen-decay, the characteristics of the eigenfunctions, and the
smoothness of the kernel; 2) we demonstrate the validity of the Gaussian
Equivalent Property (GEP), which states that the generalization performance of
KRR remains the same when the whitened features are replaced by standard
Gaussian vectors, thereby shedding light on the success of previous analyzes
under the Gaussian Design Assumption; 3) we derive novel bounds that improve
over existing bounds across a broad range of setting such as (in)dependent
feature vectors and various combinations of eigen-decay rates in the
over/underparameterized regimes.",2024-10-23,"Tin Sum Cheng, Aurelien Lucchi, Anastasis Kratsios, David Belius",http://arxiv.org/pdf/2410.17796v1,cs.LG
Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection,"Federated Learning (FL) is a decentralized approach for collaborative model
training on edge devices. This distributed method of model training offers
advantages in privacy, security, regulatory compliance, and cost-efficiency.
Our emphasis in this research lies in addressing statistical complexity in FL,
especially when the data stored locally across devices is not identically and
independently distributed (non-IID). We have observed an accuracy reduction of
up to approximately 10\% to 30\%, particularly in skewed scenarios where each
edge device trains with only 1 class of data. This reduction is attributed to
weight divergence, quantified using the Euclidean distance between device-level
class distributions and the population distribution, resulting in a bias term
(\(\delta_k\)). As a solution, we present a method to improve convergence in FL
by creating a global subset of data on the server and dynamically distributing
it across devices using a Dynamic Data queue-driven Federated Learning (DDFL).
Next, we leverage Data Entropy metrics to observe the process during each
training round and enable reasonable device selection for aggregation.
Furthermore, we provide a convergence analysis of our proposed DDFL to justify
their viability in practical FL scenarios, aiming for better device selection,
a non-sub-optimal global model, and faster convergence. We observe that our
approach results in a substantial accuracy boost of approximately 5\% for the
MNIST dataset, around 18\% for CIFAR-10, and 20\% for CIFAR-100 with a 10\%
global subset of data, outperforming the state-of-the-art (SOTA) aggregation
algorithms.",2024-10-23,"Charuka Herath, Xiaolan Liu, Sangarapillai Lambotharan, Yogachandran Rahulamathavan",http://arxiv.org/pdf/2410.17792v1,cs.LG
Large Language Models Engineer Too Many Simple Features For Tabular Data,"Tabular machine learning problems often require time-consuming and
labor-intensive feature engineering. Recent efforts have focused on using large
language models (LLMs) to capitalize on their potential domain knowledge. At
the same time, researchers have observed ethically concerning negative biases
in other LLM-related use cases, such as text generation. These developments
motivated us to investigate whether LLMs exhibit a bias that negatively impacts
the performance of feature engineering. While not ethically concerning, such a
bias could hinder practitioners from fully utilizing LLMs for automated data
science. Therefore, we propose a method to detect potential biases by detecting
anomalies in the frequency of operators (e.g., adding two features) suggested
by LLMs when engineering new features. Our experiments evaluate the bias of
four LLMs, two big frontier and two small open-source models, across 27 tabular
datasets. Our results indicate that LLMs are biased toward simple operators,
such as addition, and can fail to utilize more complex operators, such as
grouping followed by aggregations. Furthermore, the bias can negatively impact
the predictive performance when using LLM-generated features. Our results call
for mitigating bias when using LLMs for feature engineering.",2024-10-23,"Jaris Küken, Lennart Purucker, Frank Hutter",http://arxiv.org/pdf/2410.17787v1,cs.LG
Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models,"A central challenge towards developing robots that can relate human language
to their perception and actions is the scarcity of natural language annotations
in diverse robot datasets. Moreover, robot policies that follow natural
language instructions are typically trained on either templated language or
expensive human-labeled instructions, hindering their scalability. To this end,
we introduce NILS: Natural language Instruction Labeling for Scalability. NILS
automatically labels uncurated, long-horizon robot data at scale in a zero-shot
manner without any human intervention. NILS combines pretrained vision-language
foundation models in order to detect objects in a scene, detect object-centric
changes, segment tasks from large datasets of unlabelled interaction data and
ultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a
kitchen play dataset show that NILS can autonomously annotate diverse robot
demonstrations of unlabeled and unstructured datasets while alleviating several
shortcomings of crowdsourced human annotations, such as low data quality and
diversity. We use NILS to label over 115k trajectories obtained from over 430
hours of robot data. We open-source our auto-labeling code and generated
annotations on our website: http://robottasklabeling.github.io.",2024-10-23,"Nils Blank, Moritz Reuss, Marcel Rühle, Ömer Erdinç Yağmurlu, Fabian Wenzel, Oier Mees, Rudolf Lioutikov",http://arxiv.org/pdf/2410.17772v2,cs.LG
Small Singular Values Matter: A Random Matrix Analysis of Transformer Models,"As large language models (LLMs) become increasingly central to AI
applications, understanding their inner workings is essential. In this work, we
analyze the spectra of weight matrices in pretrained transformer models through
the lens of random matrix theory (RMT) to uncover learned structures. We find
that certain regions of the weight matrix spectra deviate markedly from RMT
predictions, indicating richer feature encoding. By comparing the corresponding
singular vectors to eigenvectors of activation covariance matrices, we observe
substantial overlap precisely where the spectra deviate from RMT expectations.
Our analysis further reveals the important role of small singular values in
LLMs, showing that these values contain significant information, a claim
supported by increased perplexity when they are removed from the model.
Although these small values may appear unimportant prior to task-specific
fine-tuning, removing them afterward significantly degrades performance,
revealing that fine-tuning refines the model primarily in these spectral
regions. These results emphasize the critical role of small singular values,
suggesting that removing them in an already aligned transformer can be
detrimental, as it may compromise model alignment.",2024-10-23,"Max Staats, Matthias Thamm, Bernd Rosenow",http://arxiv.org/pdf/2410.17770v2,cs.LG
Breaking the Illusion: Real-world Challenges for Adversarial Patches in Object Detection,"Adversarial attacks pose a significant threat to the robustness and
reliability of machine learning systems, particularly in computer vision
applications. This study investigates the performance of adversarial patches
for the YOLO object detection network in the physical world. Two attacks were
tested: a patch designed to be placed anywhere within the scene - global patch,
and another patch intended to partially overlap with specific object targeted
for removal from detection - local patch. Various factors such as patch size,
position, rotation, brightness, and hue were analyzed to understand their
impact on the effectiveness of the adversarial patches. The results reveal a
notable dependency on these parameters, highlighting the challenges in
maintaining attack efficacy in real-world conditions. Learning to align
digitally applied transformation parameters with those measured in the real
world still results in up to a 64\% discrepancy in patch performance. These
findings underscore the importance of understanding environmental influences on
adversarial attacks, which can inform the development of more robust defenses
for practical machine learning applications.",2024-10-23,"Jakob Shack, Katarina Petrovic, Olga Saukh",http://arxiv.org/pdf/2410.19863v2,cs.LG
Faster Language Models with Better Multi-Token Prediction Using Tensor Decomposition,"We propose a new model for multi-token prediction in transformers, aiming to
enhance sampling efficiency without compromising accuracy. Motivated by recent
work that predicts the probabilities of subsequent tokens using multiple heads,
we connect this approach to rank-$1$ canonical tensor decomposition. By
generalizing it to a rank-$r$ canonical probability decomposition, we develop
an improved model that predicts multiple tokens simultaneously. This model can
also be interpreted as a mixture of experts, allowing us to leverage successful
techniques from that domain for efficient and robust training. Importantly, the
overall overhead for training and sampling remains low. Our method demonstrates
significant improvements in inference speed for both text and code generation
tasks, proving particularly beneficial within the self-speculative decoding
paradigm. It maintains its effectiveness across various model sizes and
training epochs, highlighting its robustness and scalability.",2024-10-23,"Artem Basharin, Andrei Chertkov, Ivan Oseledets",http://arxiv.org/pdf/2410.17765v2,cs.LG
Beyond Backpropagation: Optimization with Multi-Tangent Forward Gradients,"The gradients used to train neural networks are typically computed using
backpropagation. While an efficient way to obtain exact gradients,
backpropagation is computationally expensive, hinders parallelization, and is
biologically implausible. Forward gradients are an approach to approximate the
gradients from directional derivatives along random tangents computed by
forward-mode automatic differentiation. So far, research has focused on using a
single tangent per step. This paper provides an in-depth analysis of
multi-tangent forward gradients and introduces an improved approach to
combining the forward gradients from multiple tangents based on orthogonal
projections. We demonstrate that increasing the number of tangents improves
both approximation quality and optimization performance across various tasks.",2024-10-23,"Katharina Flügel, Daniel Coquelin, Marie Weiel, Achim Streit, Markus Götz",http://arxiv.org/pdf/2410.17764v1,cs.LG
Anomaly Resilient Temporal QoS Prediction using Hypergraph Convoluted Transformer Network,"Quality-of-Service (QoS) prediction is a critical task in the service
lifecycle, enabling precise and adaptive service recommendations by
anticipating performance variations over time in response to evolving network
uncertainties and user preferences. However, contemporary QoS prediction
methods frequently encounter data sparsity and cold-start issues, which hinder
accurate QoS predictions and limit the ability to capture diverse user
preferences. Additionally, these methods often assume QoS data reliability,
neglecting potential credibility issues such as outliers and the presence of
greysheep users and services with atypical invocation patterns. Furthermore,
traditional approaches fail to leverage diverse features, including
domain-specific knowledge and complex higher-order patterns, essential for
accurate QoS predictions. In this paper, we introduce a real-time, trust-aware
framework for temporal QoS prediction to address the aforementioned challenges,
featuring an end-to-end deep architecture called the Hypergraph Convoluted
Transformer Network (HCTN). HCTN combines a hypergraph structure with graph
convolution over hyper-edges to effectively address high-sparsity issues by
capturing complex, high-order correlations. Complementing this, the transformer
network utilizes multi-head attention along with parallel 1D convolutional
layers and fully connected dense blocks to capture both fine-grained and
coarse-grained dynamic patterns. Additionally, our approach includes a
sparsity-resilient solution for detecting greysheep users and services,
incorporating their unique characteristics to improve prediction accuracy.
Trained with a robust loss function resistant to outliers, HCTN demonstrated
state-of-the-art performance on the large-scale WSDREAM-2 datasets for response
time and throughput.",2024-10-23,"Suraj Kumar, Soumi Chattopadhyay, Chandranath Adak",http://arxiv.org/pdf/2410.17762v1,cs.LG
Topology meets Machine Learning: An Introduction using the Euler Characteristic Transform,"This overview article makes the case for how topological concepts can enrich
research in machine learning. Using the Euler Characteristic Transform (ECT), a
geometrical-topological invariant, as a running example, I present different
use cases that result in more efficient models for analyzing point clouds,
graphs, and meshes. Moreover, I outline a vision for how topological concepts
could be used in the future, comprising (1) the learning of functions on
topological spaces, (2) the building of hybrid models that imbue neural
networks with knowledge about the topological information in data, and (3) the
analysis of qualitative properties of neural networks. With current research
already addressing some of these aspects, this article thus serves as an
introduction and invitation to this nascent area of research.",2024-10-23,Bastian Rieck,http://arxiv.org/pdf/2410.17760v2,cs.LG
A Neural Network Alternative to Tree-based Models,"Tabular datasets are widely used in scientific disciplines such as biology.
While these disciplines have already adopted AI methods to enhance their
findings and analysis, they mainly use tree-based methods due to their
interpretability. At the same time, artificial neural networks have been shown
to offer superior flexibility and depth for rich and complex non-tabular
problems, but they are falling behind tree-based models for tabular data in
terms of performance and interpretability. Although sparsity has been shown to
improve the interpretability and performance of ANN models for complex
non-tabular datasets, enforcing sparsity structurally and formatively for
tabular data before training the model, remains an open question. To address
this question, we establish a method that infuses sparsity in neural networks
by utilising attention mechanisms to capture the features' importance in
tabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with
attention mechanisms, are more effective than tree-based models, reaching the
state-of-the-art on biological datasets. They further permit the extraction of
insights from these datasets and achieve better performance than post-hoc
methods like SHAP.",2024-10-23,"Salvatore Raieli, Nathalie Jeanray, Stéphane Gerart, Sebastien Vachenc, Abdulrahman Altahhan",http://arxiv.org/pdf/2410.17758v2,cs.LG
VISAGE: Video Synthesis using Action Graphs for Surgery,"Surgical data science (SDS) is a field that analyzes patient data before,
during, and after surgery to improve surgical outcomes and skills. However,
surgical data is scarce, heterogeneous, and complex, which limits the
applicability of existing machine learning methods. In this work, we introduce
the novel task of future video generation in laparoscopic surgery. This task
can augment and enrich the existing surgical data and enable various
applications, such as simulation, analysis, and robot-aided surgery.
Ultimately, it involves not only understanding the current state of the
operation but also accurately predicting the dynamic and often unpredictable
nature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis
using Action Graphs for Surgery), leverages the power of action scene graphs to
capture the sequential nature of laparoscopic procedures and utilizes diffusion
models to synthesize temporally coherent video sequences. VISAGE predicts the
future frames given only a single initial frame, and the action graph triplets.
By incorporating domain-specific knowledge through the action graph, VISAGE
ensures the generated videos adhere to the expected visual and motion patterns
observed in real laparoscopic procedures. The results of our experiments
demonstrate high-fidelity video generation for laparoscopy procedures, which
enables various applications in SDS.",2024-10-23,"Yousef Yeganeh, Rachmadio Lazuardi, Amir Shamseddin, Emine Dari, Yash Thirani, Nassir Navab, Azade Farshad",http://arxiv.org/pdf/2410.17751v2,cs.LG
Can Uncertainty Quantification Enable Better Learning-based Index Tuning?,"Index tuning is crucial for optimizing database performance by selecting
optimal indexes based on workload. The key to this process lies in an accurate
and efficient benefit estimator. Traditional methods relying on what-if tools
often suffer from inefficiency and inaccuracy. In contrast, learning-based
models provide a promising alternative but face challenges such as instability,
lack of interpretability, and complex management. To overcome these
limitations, we adopt a novel approach: quantifying the uncertainty in
learning-based models' results, thereby combining the strengths of both
traditional and learning-based methods for reliable index tuning. We propose
Beauty, the first uncertainty-aware framework that enhances learning-based
models with uncertainty quantification and uses what-if tools as a
complementary mechanism to improve reliability and reduce management
complexity. Specifically, we introduce a novel method that combines AutoEncoder
and Monte Carlo Dropout to jointly quantify uncertainty, tailored to the
characteristics of benefit estimation tasks. In experiments involving sixteen
models, our approach outperformed existing uncertainty quantification methods
in the majority of cases. We also conducted index tuning tests on six datasets.
By applying the Beauty framework, we eliminated worst-case scenarios and more
than tripled the occurrence of best-case scenarios.",2024-10-23,"Tao Yu, Zhaonian Zou, Hao Xiong",http://arxiv.org/pdf/2410.17748v1,cs.LG
Learning Versatile Skills with Curriculum Masking,"Masked prediction has emerged as a promising pretraining paradigm in offline
reinforcement learning (RL) due to its versatile masking schemes, enabling
flexible inference across various downstream tasks with a unified model.
Despite the versatility of masked prediction, it remains unclear how to balance
the learning of skills at different levels of complexity. To address this, we
propose CurrMask, a curriculum masking pretraining paradigm for sequential
decision making. Motivated by how humans learn by organizing knowledge in a
curriculum, CurrMask adjusts its masking scheme during pretraining for learning
versatile skills. Through extensive experiments, we show that CurrMask exhibits
superior zero-shot performance on skill prompting tasks, goal-conditioned
planning tasks, and competitive finetuning performance on offline RL tasks.
Additionally, our analysis of training dynamics reveals that CurrMask gradually
acquires skills of varying complexity by dynamically adjusting its masking
scheme.",2024-10-23,"Yao Tang, Zhihui Xie, Zichuan Lin, Deheng Ye, Shuai Li",http://arxiv.org/pdf/2410.17744v2,cs.LG
Continual Learning on a Data Diet,"Continual Learning (CL) methods usually learn from all available data.
However, this is not the case in human cognition which efficiently focuses on
key experiences while disregarding the redundant information. Similarly, not
all data points in a dataset have equal potential; some can be more informative
than others. This disparity may significantly impact the performance, as both
the quality and quantity of samples directly influence the model's
generalizability and efficiency. Drawing inspiration from this, we explore the
potential of learning from important samples and present an empirical study for
evaluating coreset selection techniques in the context of CL to stimulate
research in this unexplored area. We train different continual learners on
increasing amounts of selected samples and investigate the learning-forgetting
dynamics by shedding light on the underlying mechanisms driving their improved
stability-plasticity balance. We present several significant observations:
learning from selectively chosen samples (i) enhances incremental accuracy,
(ii) improves knowledge retention of previous tasks, and (iii) refines learned
representations. This analysis contributes to a deeper understanding of
selective learning strategies in CL scenarios.",2024-10-23,"Elif Ceren Gok Yildirim, Murat Onur Yildirim, Joaquin Vanschoren",http://arxiv.org/pdf/2410.17715v1,cs.LG
Beware of Calibration Data for Pruning Large Language Models,"As large language models (LLMs) are widely applied across various fields,
model compression has become increasingly crucial for reducing costs and
improving inference efficiency. Post-training pruning is a promising method
that does not require resource-intensive iterative training and only needs a
small amount of calibration data to assess the importance of parameters.
Previous research has primarily focused on designing advanced pruning methods,
while different calibration data's impact on pruning performance still lacks
systematical exploration. We fill this blank and surprisingly observe that the
effects of calibration data even value more than designing advanced pruning
strategies, especially for high sparsity. Our preliminary exploration also
discloses that using calibration data similar to the training data can yield
better performance. As pre-training data is usually inaccessible for advanced
LLMs, we further provide a self-generating calibration data synthesis strategy
to construct feasible calibration data. We conduct experiments on the recent
strong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that
the proposed method outperforms commonly used calibration data and can
effectively enhance strong pruning methods (e.g., Wanda, OWL).",2024-10-23,"Yixin Ji, Yang Xiang, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang",http://arxiv.org/pdf/2410.17711v1,cs.LG
Scalable Random Feature Latent Variable Models,"Random feature latent variable models (RFLVMs) represent the state-of-the-art
in latent variable models, capable of handling non-Gaussian likelihoods and
effectively uncovering patterns in high-dimensional data. However, their heavy
reliance on Monte Carlo sampling results in scalability issues which makes it
difficult to use these models for datasets with a massive number of
observations. To scale up RFLVMs, we turn to the optimization-based variational
Bayesian inference (VBI) algorithm which is known for its scalability compared
to sampling-based methods. However, implementing VBI for RFLVMs poses
challenges, such as the lack of explicit probability distribution functions
(PDFs) for the Dirichlet process (DP) in the kernel learning component, and the
incompatibility of existing VBI algorithms with RFLVMs. To address these
issues, we introduce a stick-breaking construction for DP to obtain an explicit
PDF and a novel VBI algorithm called ``block coordinate descent variational
inference"" (BCD-VI). This enables the development of a scalable version of
RFLVMs, or in short, SRFLVM. Our proposed method shows scalability,
computational efficiency, superior performance in generating informative latent
representations and the ability of imputing missing data across various
real-world datasets, outperforming state-of-the-art competitors.",2024-10-23,"Ying Li, Zhidi Lin, Yuhao Liu, Michael Minyi Zhang, Pablo M. Olmos, Petar M. Djurić",http://arxiv.org/pdf/2410.17700v1,cs.LG
Dreaming Learning,"Incorporating novelties into deep learning systems remains a challenging
problem. Introducing new information to a machine learning system can interfere
with previously stored data and potentially alter the global model paradigm,
especially when dealing with non-stationary sources. In such cases, traditional
approaches based on validation error minimization offer limited advantages. To
address this, we propose a training algorithm inspired by Stuart Kauffman's
notion of the Adjacent Possible. This novel training methodology explores new
data spaces during the learning phase. It predisposes the neural network to
smoothly accept and integrate data sequences with different statistical
characteristics than expected. The maximum distance compatible with such
inclusion depends on a specific parameter: the sampling temperature used in the
explorative phase of the present method. This algorithm, called Dreaming
Learning, anticipates potential regime shifts over time, enhancing the neural
network's responsiveness to non-stationary events that alter statistical
properties. To assess the advantages of this approach, we apply this
methodology to unexpected statistical changes in Markov chains and
non-stationary dynamics in textual sequences. We demonstrated its ability to
improve the auto-correlation of generated textual sequences by $\sim 29\%$ and
enhance the velocity of loss convergence by $\sim 100\%$ in the case of a
paradigm shift in Markov chains.",2024-10-23,"Alessandro Londei, Matteo Benati, Denise Lanzieri, Vittorio Loreto",http://arxiv.org/pdf/2410.18156v2,cs.LG
Optimizing Load Scheduling in Power Grids Using Reinforcement Learning and Markov Decision Processes,"Power grid load scheduling is a critical task that ensures the balance
between electricity generation and consumption while minimizing operational
costs and maintaining grid stability. Traditional optimization methods often
struggle with the dynamic and stochastic nature of power systems, especially
when faced with renewable energy sources and fluctuating demand. This paper
proposes a reinforcement learning (RL) approach using a Markov Decision Process
(MDP) framework to address the challenges of dynamic load scheduling. The MDP
is defined by a state space representing grid conditions, an action space
covering control operations like generator adjustments and storage management,
and a reward function balancing economic efficiency and system reliability. We
investigate the application of various RL algorithms, from basic Q-Learning to
more advanced Deep Q-Networks (DQN) and Actor-Critic methods, to determine
optimal scheduling policies. The proposed approach is evaluated through a
simulated power grid environment, demonstrating its potential to improve
scheduling efficiency and adapt to variable demand patterns. Our results show
that the RL-based method provides a robust and scalable solution for real-time
load scheduling, contributing to the efficient management of modern power
grids.",2024-10-23,Dongwen Luo,http://arxiv.org/pdf/2410.17696v1,cs.LG
PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a resource-limited Context,"Following their success in natural language processing (NLP), there has been
a shift towards transformer models in computer vision. While transformers
perform well and offer promising multi-tasking performance, due to their high
compute requirements, many resource-constrained applications still rely on
convolutional or hybrid models that combine the benefits of convolution and
attention layers and achieve the best results in the sub 100M parameter range.
Simultaneously, task adaptation techniques that allow for the use of one shared
transformer backbone for multiple downstream tasks, resulting in great storage
savings at negligible cost in performance, have not yet been adopted for hybrid
transformers. In this work, we investigate how to achieve the best
task-adaptation performance and introduce PETAH: Parameter Efficient Task
Adaptation for Hybrid Transformers. We further combine PETAH adaptation with
pruning to achieve highly performant and storage friendly models for
multi-tasking. In our extensive evaluation on classification and other vision
tasks, we demonstrate that our PETAH-adapted hybrid models outperform
established task-adaptation techniques for ViTs while requiring fewer
parameters and being more efficient on mobile hardware.",2024-10-23,"Maximilian Augustin, Syed Shakib Sarwar, Mostafa Elhoushi, Sai Qian Zhang, Yuecheng Li, Barbara De Salvo",http://arxiv.org/pdf/2410.17661v1,cs.LG
Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions,"Bias assessment of news sources is paramount for professionals,
organizations, and researchers who rely on truthful evidence for information
gathering and reporting. While certain bias indicators are discernible from
content analysis, descriptors like political bias and fake news pose greater
challenges. In this paper, we propose an extension to a recently presented news
media reliability estimation method that focuses on modeling outlets and their
longitudinal web interactions. Concretely, we assess the classification
performance of four reinforcement learning strategies on a large news media
hyperlink graph. Our experiments, targeting two challenging bias descriptors,
factual reporting and political bias, showed a significant performance
improvement at the source media level. Additionally, we validate our methods on
the CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in
both, F1-score and the official MAE metric. Furthermore, we contribute by
releasing the largest annotated dataset of news source media, categorized with
factual reporting and political bias labels. Our findings suggest that
profiling news media sources based on their hyperlink interactions over time is
feasible, offering a bird's-eye view of evolving media landscapes.",2024-10-23,"Dairazalia Sánchez-Cortés, Sergio Burdisso, Esaú Villatoro-Tello, Petr Motlicek",http://arxiv.org/pdf/2410.17655v1,cs.LG
Towards Active Participant Centric Vertical Federated Learning: Some Representations May Be All You Need,"Existing Vertical FL (VFL) methods often struggle with realistic and
unaligned data partitions, and incur into high communication costs and
significant operational complexity. This work introduces a novel approach to
VFL, Active Participant Centric VFL (APC-VFL), that excels in scenarios when
data samples among participants are partially aligned at training. Among its
strengths, APC-VFL only requires a single communication step with the active
participant. This is made possible through a local and unsupervised
representation learning stage at each participant followed by a knowledge
distillation step in the active participant. Compared to other VFL methods such
as SplitNN or VFedTrans, APC-VFL consistently outperforms them across three
popular VFL datasets in terms of F1, accuracy and communication costs as the
ratio of aligned data is reduced.",2024-10-23,"Jon Irureta, Jon Imaz, Aizea Lojo, Javier Fernandez-Marques, Marco González, Iñigo Perona",http://arxiv.org/pdf/2410.17648v2,cs.LG
Entity-based Reinforcement Learning for Autonomous Cyber Defence,"A significant challenge for autonomous cyber defence is ensuring a defensive
agent's ability to generalise across diverse network topologies and
configurations. This capability is necessary for agents to remain effective
when deployed in dynamically changing environments, such as an enterprise
network where devices may frequently join and leave. Standard approaches to
deep reinforcement learning, where policies are parameterised using a
fixed-input multi-layer perceptron (MLP) expect fixed-size observation and
action spaces. In autonomous cyber defence, this makes it hard to develop
agents that generalise to environments with network topologies different from
those trained on, as the number of nodes affects the natural size of the
observation and action spaces. To overcome this limitation, we reframe the
problem of autonomous network defence using entity-based reinforcement
learning, where the observation and action space of an agent are decomposed
into a collection of discrete entities. This framework enables the use of
policy parameterisations specialised in compositional generalisation. We train
a Transformer-based policy on the Yawning Titan cyber-security simulation
environment and test its generalisation capabilities across various network
topologies. We demonstrate that this approach significantly outperforms an
MLP-based policy when training across fixed-size networks of varying
topologies, and matches performance when training on a single network. We also
demonstrate the potential for zero-shot generalisation to networks of a
different size to those seen in training. These findings highlight the
potential for entity-based reinforcement learning to advance the field of
autonomous cyber defence by providing more generalisable policies capable of
handling variations in real-world network environments.",2024-10-23,"Isaac Symes Thompson, Alberto Caron, Chris Hicks, Vasilios Mavroudis",http://arxiv.org/pdf/2410.17647v3,cs.LG
Exploring structure diversity in atomic resolution microscopy with graph neural networks,"The emergence of deep learning (DL) has provided great opportunities for the
high-throughput analysis of atomic-resolution micrographs. However, the DL
models trained by image patches in fixed size generally lack efficiency and
flexibility when processing micrographs containing diversified atomic
configurations. Herein, inspired by the similarity between the atomic
structures and graphs, we describe a few-shot learning framework based on an
equivariant graph neural network (EGNN) to analyze a library of atomic
structures (e.g., vacancies, phases, grain boundaries, doping, etc.), showing
significantly promoted robustness and three orders of magnitude reduced
computing parameters compared to the image-driven DL models, which is
especially evident for those aggregated vacancy lines with flexible lattice
distortion. Besides, the intuitiveness of graphs enables quantitative and
straightforward extraction of the atomic-scale structural features in batches,
thus statistically unveiling the self-assembly dynamics of vacancy lines under
electron beam irradiation. A versatile model toolkit is established by
integrating EGNN sub-models for single structure recognition to process images
involving varied configurations in the form of a task chain, leading to the
discovery of novel doping configurations with superior electrocatalytic
properties for hydrogen evolution reactions. This work provides a powerful tool
to explore structure diversity in a fast, accurate, and intelligent manner.",2024-10-23,"Zheng Luo, Ming Feng, Zijian Gao, Jinyang Yu, Liang Hu, Tao Wang, Shenao Xue, Shen Zhou, Fangping Ouyang, Dawei Feng, Kele Xu, Shanshan Wang",http://arxiv.org/pdf/2410.17631v1,cs.LG
Is Smoothness the Key to Robustness? A Comparison of Attention and Convolution Models Using a Novel Metric,"Robustness is a critical aspect of machine learning models. Existing
robustness evaluation approaches often lack theoretical generality or rely
heavily on empirical assessments, limiting insights into the structural factors
contributing to robustness. Moreover, theoretical robustness analysis is not
applicable for direct comparisons between models. To address these challenges,
we propose $\textit{TopoLip}$, a metric based on layer-wise analysis that
bridges topological data analysis and Lipschitz continuity for robustness
evaluation. TopoLip provides a unified framework for both theoretical and
empirical robustness comparisons across different architectures or
configurations, and it reveals how model parameters influence the robustness of
models. Using TopoLip, we demonstrate that attention-based models typically
exhibit smoother transformations and greater robustness compared to
convolution-based models, as validated through theoretical analysis and
adversarial tasks. Our findings establish a connection between architectural
design, robustness, and topological properties.",2024-10-23,Baiyuan Chen,http://arxiv.org/pdf/2410.17628v2,cs.LG
Incremental Learning of Affordances using Markov Logic Networks,"Affordances enable robots to have a semantic understanding of their
surroundings. This allows them to have more acting flexibility when completing
a given task. Capturing object affordances in a machine learning model is a
difficult task, because of their dependence on contextual information. Markov
Logic Networks (MLN) combine probabilistic reasoning with logic that is able to
capture such context. Mobile robots operate in partially known environments
wherein unseen object affordances can be observed. This new information must be
incorporated into the existing knowledge, without having to retrain the MLN
from scratch. We introduce the MLN Cumulative Learning Algorithm (MLN-CLA).
MLN-CLA learns new relations in various knowledge domains by retaining
knowledge and only updating the changed knowledge, for which the MLN is
retrained. We show that MLN-CLA is effective for accumulative learning and
zero-shot affordance inference, outperforming strong baselines.",2024-10-23,"George Potter, Gertjan Burghouts, Joris Sijs",http://arxiv.org/pdf/2410.17624v1,cs.LG
Self-Supervised Graph Neural Networks for Enhanced Feature Extraction in Heterogeneous Information Networks,"This paper explores the applications and challenges of graph neural networks
(GNNs) in processing complex graph data brought about by the rapid development
of the Internet. Given the heterogeneity and redundancy problems that graph
data often have, traditional GNN methods may be overly dependent on the initial
structure and attribute information of the graph, which limits their ability to
accurately simulate more complex relationships and patterns in the graph.
Therefore, this study proposes a graph neural network model under a
self-supervised learning framework, which can flexibly combine different types
of additional information of the attribute graph and its nodes, so as to better
mine the deep features in the graph data. By introducing a self-supervisory
mechanism, it is expected to improve the adaptability of existing models to the
diversity and complexity of graph data and improve the overall performance of
the model.",2024-10-23,"Jianjun Wei, Yue Liu, Xin Huang, Xin Zhang, Wenyi Liu, Xu Yan",http://arxiv.org/pdf/2410.17617v1,cs.LG
A Kernel Perspective on Distillation-based Collaborative Learning,"Over the past decade, there is a growing interest in collaborative learning
that can enhance AI models of multiple parties. However, it is still
challenging to enhance performance them without sharing private data and models
from individual parties. One recent promising approach is to develop
distillation-based algorithms that exploit unlabeled public data but the
results are still unsatisfactory in both theory and practice. To tackle this
problem, we rigorously analyze a representative distillation-based algorithm in
the view of kernel regression. This work provides the first theoretical results
to prove the (nearly) minimax optimality of the nonparametric collaborative
learning algorithm that does not directly share local data or models in
massively distributed statistically heterogeneous environments. Inspired by our
theoretical results, we also propose a practical distillation-based
collaborative learning algorithm based on neural network architecture. Our
algorithm successfully bridges the gap between our theoretical assumptions and
practical settings with neural networks through feature kernel matching. We
simulate various regression tasks to verify our theory and demonstrate the
practical feasibility of our proposed algorithm.",2024-10-23,"Sejun Park, Kihun Hong, Ganguk Hwang",http://arxiv.org/pdf/2410.17592v2,cs.LG
Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation,"Despite significant advancements in neural text-to-audio generation,
challenges persist in controllability and evaluation. This paper addresses
these issues through the Sound Scene Synthesis challenge held as part of the
Detection and Classification of Acoustic Scenes and Events 2024. We present an
evaluation protocol combining objective metric, namely Fr\'echet Audio
Distance, with perceptual assessments, utilizing a structured prompt format to
enable diverse captions and effective evaluation. Our analysis reveals varying
performance across sound categories and model architectures, with larger models
generally excelling but innovative lightweight approaches also showing promise.
The strong correlation between objective metrics and human ratings validates
our evaluation approach. We discuss outcomes in terms of audio quality,
controllability, and architectural considerations for text-to-audio
synthesizers, providing direction for future research.",2024-10-23,"Junwon Lee, Modan Tailleur, Laurie M. Heller, Keunwoo Choi, Mathieu Lagrange, Brian McFee, Keisuke Imoto, Yuki Okamoto",http://arxiv.org/pdf/2410.17589v1,cs.LG
Predicting Company Growth by Econophysics informed Machine Learning,"Predicting company growth is crucial for strategic adjustment, operational
decision-making, risk assessment, and loan eligibility reviews. Traditional
models for company growth often focus too much on theory, overlooking practical
forecasting, or they rely solely on time series forecasting techniques,
ignoring interpretability and the inherent mechanisms of company growth. In
this paper, we propose a machine learning-based prediction framework that
incorporates an econophysics model for company growth. Our model captures both
the intrinsic growth mechanisms of companies led by scaling laws and the
fluctuations influenced by random factors and individual decisions,
demonstrating superior predictive performance compared with methods that use
time series techniques alone. Its advantages are more pronounced in long-range
prediction tasks. By explicitly modeling the baseline growth and volatility
components, our model is more interpretable.",2024-10-23,"Ruyi Tao, Kaiwei Liu, Xu Jing, Jiang Zhang",http://arxiv.org/pdf/2410.17587v1,cs.LG
Bonsai: Gradient-free Graph Condensation for Node Classification,"Graph condensation has emerged as a promising avenue to enable scalable
training of GNNs by compressing the training dataset while preserving essential
graph characteristics. Our study uncovers significant shortcomings in current
graph condensation techniques. First, the majority of the algorithms
paradoxically require training on the full dataset to perform condensation.
Second, due to their gradient-emulating approach, these methods require fresh
condensation for any change in hyperparameters or GNN architecture, limiting
their flexibility and reusability. Finally, they fail to achieve substantial
size reduction due to synthesizing fully-connected, edge-weighted graphs. To
address these challenges, we present Bonsai, a novel graph condensation method
empowered by the observation that \textit{computation trees} form the
fundamental processing units of message-passing GNNs. Bonsai condenses datasets
by encoding a careful selection of \textit{exemplar} trees that maximize the
representation of all computation trees in the training set. This unique
approach imparts Bonsai as the first linear-time, model-agnostic graph
condensation algorithm for node classification that outperforms existing
baselines across $7$ real-world datasets on accuracy, while being $22$ times
faster on average. Bonsai is grounded in rigorous mathematical guarantees on
the adopted approximation strategies making it robust to GNN architectures,
datasets, and parameters.",2024-10-23,"Mridul Gupta, Samyak Jain, Vansh Ramani, Hariprasad Kodamana, Sayan Ranu",http://arxiv.org/pdf/2410.17579v5,cs.LG
Adversarial Domain Adaptation for Metal Cutting Sound Detection: Leveraging Abundant Lab Data for Scarce Industry Data,"Cutting state monitoring in the milling process is crucial for improving
manufacturing efficiency and tool life. Cutting sound detection using machine
learning (ML) models, inspired by experienced machinists, can be employed as a
cost-effective and non-intrusive monitoring method in a complex manufacturing
environment. However, labeling industry data for training is costly and
time-consuming. Moreover, industry data is often scarce. In this study, we
propose a novel adversarial domain adaptation (DA) approach to leverage
abundant lab data to learn from scarce industry data, both labeled, for
training a cutting-sound detection model. Rather than adapting the features
from separate domains directly, we project them first into two separate latent
spaces that jointly work as the feature space for learning domain-independent
representations. We also analyze two different mechanisms for adversarial
learning where the discriminator works as an adversary and a critic in separate
settings, enabling our model to learn expressive domain-invariant and
domain-ingrained features, respectively. We collected cutting sound data from
multiple sensors in different locations, prepared datasets from lab and
industry domain, and evaluated our learning models on them. Experiments showed
that our models outperformed the multi-layer perceptron based vanilla domain
adaptation models in labeling tasks on the curated datasets, achieving near
92%, 82% and 85% accuracy respectively for three different sensors installed in
industry settings.",2024-10-23,"Mir Imtiaz Mostafiz, Eunseob Kim, Adrian Shuai Li, Elisa Bertino, Martin Byung-Guk Jun, Ali Shakouri",http://arxiv.org/pdf/2410.17574v1,cs.LG
Securing Federated Learning against Backdoor Threats with Foundation Model Integration,"Federated Learning (FL) enables decentralized model training while preserving
privacy. Recently, the integration of Foundation Models (FMs) into FL has
enhanced performance but introduced a novel backdoor attack mechanism.
Attackers can exploit FM vulnerabilities to embed backdoors into synthetic data
generated by FMs. During global model fusion, these backdoors are transferred
to the global model through compromised synthetic data, subsequently infecting
all client models. Existing FL backdoor defenses are ineffective against this
novel attack due to its fundamentally different mechanism compared to classic
ones. In this work, we propose a novel data-free defense strategy that
addresses both classic and novel backdoor attacks in FL. The shared attack
pattern lies in the abnormal activations within the hidden feature space during
model aggregation. Hence, we propose to constrain internal activations to
remain within reasonable ranges, effectively mitigating attacks while
preserving model functionality. The activation constraints are optimized using
synthetic data alongside FL training. Extensive experiments demonstrate its
effectiveness against both novel and classic backdoor attacks, outperforming
existing defenses.",2024-10-23,"Xiaohuan Bi, Xi Li",http://arxiv.org/pdf/2410.17573v2,cs.LG
Differentially Private Learning Needs Better Model Initialization and Self-Distillation,"Differentially private SGD (DPSGD) enables privacy-preserving training of
language models, but often reduces utility, diversity, and linguistic quality.
We introduce DPRefine, a three-phase method that initializes a model using data
synthesis from a small pre-trained LM with rigorous filtering, applies DP
finetuning on private data, and performs self-distillation to refine outputs.
This approach significantly outperforms vanilla DPSGD, with AlpacaEval
preferring DPRefine's generations in 78.4% of cases across all datasets. Our
analysis reveals that DPRefine reduces linguistic errors in generated text by
84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.
It also reduces inconsistencies of non-private models, such as hallucinated
details and misattributed quotes. We find that small models like GPT-2 can be
effective for initialization and distillation, highlighting their potential in
enabling scalable and efficient deployment of privacy-preserving language.",2024-10-23,"Ivoline C. Ngong, Joseph P. Near, Niloofar Mireshghallah",http://arxiv.org/pdf/2410.17566v1,cs.LG
"Hypergraphs as Weighted Directed Self-Looped Graphs: Spectral Properties, Clustering, Cheeger Inequality","Hypergraphs naturally arise when studying group relations and have been
widely used in the field of machine learning. There has not been a unified
formulation of hypergraphs, yet the recently proposed edge-dependent vertex
weights (EDVW) modeling is one of the most generalized modeling methods of
hypergraphs, i.e., most existing hypergraphs can be formulated as EDVW
hypergraphs without any information loss to the best of our knowledge. However,
the relevant algorithmic developments on EDVW hypergraphs remain nascent:
compared to spectral graph theories, the formulations are incomplete, the
spectral clustering algorithms are not well-developed, and one result regarding
hypergraph Cheeger Inequality is even incorrect. To this end, deriving a
unified random walk-based formulation, we propose our definitions of hypergraph
Rayleigh Quotient, NCut, boundary/cut, volume, and conductance, which are
consistent with the corresponding definitions on graphs. Then, we prove that
the normalized hypergraph Laplacian is associated with the NCut value, which
inspires our HyperClus-G algorithm for spectral clustering on EDVW hypergraphs.
Finally, we prove that HyperClus-G can always find an approximately linearly
optimal partitioning in terms of Both NCut and conductance. Additionally, we
provide extensive experiments to validate our theoretical findings from an
empirical perspective.",2024-10-23,"Zihao Li, Dongqi Fu, Hengyu Liu, Jingrui He",http://arxiv.org/pdf/2411.03331v1,cs.LG
DisenGCD: A Meta Multigraph-assisted Disentangled Graph Learning Framework for Cognitive Diagnosis,"Existing graph learning-based cognitive diagnosis (CD) methods have made
relatively good results, but their student, exercise, and concept
representations are learned and exchanged in an implicit unified graph, which
makes the interaction-agnostic exercise and concept representations be learned
poorly, failing to provide high robustness against noise in students'
interactions. Besides, lower-order exercise latent representations obtained in
shallow layers are not well explored when learning the student representation.
To tackle the issues, this paper suggests a meta multigraph-assisted
disentangled graph learning framework for CD (DisenGCD), which learns three
types of representations on three disentangled graphs: student-exercise-concept
interaction, exercise-concept relation, and concept dependency graphs,
respectively. Specifically, the latter two graphs are first disentangled from
the interaction graph. Then, the student representation is learned from the
interaction graph by a devised meta multigraph learning module; multiple
learnable propagation paths in this module enable current student latent
representation to access lower-order exercise latent representations, which can
lead to more effective nad robust student representations learned; the exercise
and concept representations are learned on the relation and dependency graphs
by graph attention modules. Finally, a novel diagnostic function is devised to
handle three disentangled representations for prediction. Experiments show
better performance and robustness of DisenGCD than state-of-the-art CD methods
and demonstrate the effectiveness of the disentangled learning framework and
meta multigraph module. The source code is available at
\textcolor{red}{\url{https://github.com/BIMK/Intelligent-Education/tree/main/DisenGCD}}.",2024-10-23,"Shangshang Yang, Mingyang Chen, Ziwen Wang, Xiaoshan Yu, Panpan Zhang, Haiping Ma, Xingyi Zhang",http://arxiv.org/pdf/2410.17564v1,cs.LG
BlurryScope: a cost-effective and compact scanning microscope for automated HER2 scoring using deep learning on blurry image data,"We developed a rapid scanning optical microscope, termed ""BlurryScope"", that
leverages continuous image acquisition and deep learning to provide a
cost-effective and compact solution for automated inspection and analysis of
tissue sections. BlurryScope integrates specialized hardware with a neural
network-based model to quickly process motion-blurred histological images and
perform automated pathology classification. This device offers comparable speed
to commercial digital pathology scanners, but at a significantly lower price
point and smaller size/weight, making it ideal for fast triaging in small
clinics, as well as for resource-limited settings. To demonstrate the
proof-of-concept of BlurryScope, we implemented automated classification of
human epidermal growth factor receptor 2 (HER2) scores on immunohistochemically
(IHC) stained breast tissue sections, achieving concordant results with those
obtained from a high-end digital scanning microscope. We evaluated this
approach by scanning HER2-stained tissue microarrays (TMAs) at a continuous
speed of 5 mm/s, which introduces bidirectional motion blur artifacts. These
compromised images were then used to train our network models. Using a test set
of 284 unique patient cores, we achieved blind testing accuracies of 79.3% and
89.7% for 4-class (0, 1+, 2+, 3+) and 2-class (0/1+ , 2+/3+) HER2 score
classification, respectively. BlurryScope automates the entire workflow, from
image scanning to stitching and cropping of regions of interest, as well as
HER2 score classification. We believe BlurryScope has the potential to enhance
the current pathology infrastructure in resource-scarce environments, save
diagnostician time and bolster cancer identification and classification across
various clinical environments.",2024-10-23,"Michael John Fanous, Christopher Michael Seybold, Hanlong Chen, Nir Pillar, Aydogan Ozcan",http://arxiv.org/pdf/2410.17557v1,cs.LG
LEADS: Lightweight Embedded Assisted Driving System,"With the rapid development of electric vehicles, formula races that face high
school and university students have become more popular than ever as the
threshold for design and manufacturing has been lowered. In many cases, we see
teams inspired by or directly using toolkits and technologies inherited from
standardized commercial vehicles. These architectures are usually overly
complicated for amateur applications like the races. In order to improve the
efficiency and simplify the development of instrumentation, control, and
analysis systems, we propose LEADS (Lightweight Embedded Assisted Driving
System), a dedicated solution for such scenarios.",2024-10-23,"Tianhao Fu, Querobin Mascarenhas, Andrew Forti",http://arxiv.org/pdf/2410.17554v1,cs.LG
Multimodal Information Bottleneck for Deep Reinforcement Learning with Multiple Sensors,"Reinforcement learning has achieved promising results on robotic control
tasks but struggles to leverage information effectively from multiple sensory
modalities that differ in many characteristics. Recent works construct
auxiliary losses based on reconstruction or mutual information to extract joint
representations from multiple sensory inputs to improve the sample efficiency
and performance of reinforcement learning algorithms. However, the
representations learned by these methods could capture information irrelevant
to learning a policy and may degrade the performance. We argue that compressing
information in the learned joint representations about raw multimodal
observations is helpful, and propose a multimodal information bottleneck model
to learn task-relevant joint representations from egocentric images and
proprioception. Our model compresses and retains the predictive information in
multimodal observations for learning a compressed joint representation, which
fuses complementary information from visual and proprioceptive feedback and
meanwhile filters out task-irrelevant information in raw multimodal
observations. We propose to minimize the upper bound of our multimodal
information bottleneck objective for computationally tractable optimization.
Experimental evaluations on several challenging locomotion tasks with
egocentric images and proprioception show that our method achieves better
sample efficiency and zero-shot robustness to unseen white noise than leading
baselines. We also empirically demonstrate that leveraging information from
egocentric images and proprioception is more helpful for learning policies on
locomotion tasks than solely using one single modality.",2024-10-23,"Bang You, Huaping Liu",http://arxiv.org/pdf/2410.17551v1,cs.LG
Predicting 30-Day Hospital Readmission in Medicare Patients: Insights from an LSTM Deep Learning Model,"Readmissions among Medicare beneficiaries are a major problem for the US
healthcare system from a perspective of both healthcare operations and patient
caregiving outcomes. Our study analyzes Medicare hospital readmissions using
LSTM networks with feature engineering to assess feature contributions. We
selected variables from admission-level data, inpatient medical history and
patient demography. The LSTM model is designed to capture temporal dynamics
from admission-level and patient-level data. On a case study on the MIMIC
dataset, the LSTM model outperformed the logistic regression baseline,
accurately leveraging temporal features to predict readmission. The major
features were the Charlson Comorbidity Index, hospital length of stay, the
hospital admissions over the past 6 months, while demographic variables were
less impactful. This work suggests that LSTM networks offers a more promising
approach to improve Medicare patient readmission prediction. It captures
temporal interactions in patient databases, enhancing current prediction models
for healthcare providers. Adoption of predictive models into clinical practice
may be more effective in identifying Medicare patients to provide early and
targeted interventions to improve patient outcomes.",2024-10-23,"Xintao Li, Sibei Liu, Dezhi Yu, Yang Zhang, Xiaoyu Liu",http://arxiv.org/pdf/2410.17545v1,cs.LG
Primal-Dual Spectral Representation for Off-policy Evaluation,"Off-policy evaluation (OPE) is one of the most fundamental problems in
reinforcement learning (RL) to estimate the expected long-term payoff of a
given target policy with only experiences from another behavior policy that is
potentially unknown. The distribution correction estimation (DICE) family of
estimators have advanced the state of the art in OPE by breaking the curse of
horizon. However, the major bottleneck of applying DICE estimators lies in the
difficulty of solving the saddle-point optimization involved, especially with
neural network implementations. In this paper, we tackle this challenge by
establishing a linear representation of value function and stationary
distribution correction ratio, i.e., primal and dual variables in the DICE
framework, using the spectral decomposition of the transition operator. Such
primal-dual representation not only bypasses the non-convex non-concave
optimization in vanilla DICE, therefore enabling an computational efficient
algorithm, but also paves the way for more efficient utilization of historical
data. We highlight that our algorithm, SpectralDICE, is the first to leverage
the linear representation of primal-dual variables that is both computation and
sample efficient, the performance of which is supported by a rigorous
theoretical sample complexity guarantee and a thorough empirical evaluation on
various benchmarks.",2024-10-23,"Yang Hu, Tianyi Chen, Na Li, Kai Wang, Bo Dai",http://arxiv.org/pdf/2410.17538v1,cs.LG
Music102: An $D_{12}$-equivariant transformer for chord progression accompaniment,"We present Music102, an advanced model built upon the Music101 prototype,
aimed at enhancing chord progression accompaniment through a D12-equivariant
transformer. Inspired by group theory and symbolic music structures, Music102
leverages musical symmetry--such as transposition and reflection
operations--integrating these properties into the transformer architecture. By
encoding prior music knowledge, the model maintains equivariance across both
melody and chord sequences. The POP909 dataset was employed to train and
evaluate Music102, revealing significant improvements over Music101 in both
weighted loss and exact accuracy metrics, despite using fewer parameters. This
work showcases the adaptability of self-attention mechanisms and layer
normalization to the discrete musical domain, addressing challenges in
computational music analysis. With its stable and flexible neural framework,
Music102 sets the stage for further exploration in equivariant music generation
and computational composition tools, bridging mathematical theory with
practical music performance.",2024-10-23,Weiliang Luo,http://arxiv.org/pdf/2410.18151v1,cs.LG
GDDA: Semantic OOD Detection on Graphs under Covariate Shift via Score-Based Diffusion Models,"Out-of-distribution (OOD) detection poses a significant challenge for Graph
Neural Networks (GNNs), particularly in open-world scenarios with varying
distribution shifts. Most existing OOD detection methods on graphs primarily
focus on identifying instances in test data domains caused by either semantic
shifts (changes in data classes) or covariate shifts (changes in data
features), while leaving the simultaneous occurrence of both distribution
shifts under-explored. In this work, we address both types of shifts
simultaneously and introduce a novel challenge for OOD detection on graphs:
graph-level semantic OOD detection under covariate shift. In this scenario,
variations between the training and test domains result from the concurrent
presence of both covariate and semantic shifts, where only graphs associated
with unknown classes are identified as OOD samples (OODs). To tackle this
challenge, we propose a novel two-phase framework called Graph Disentangled
Diffusion Augmentation (GDDA). The first phase focuses on disentangling graph
representations into domain-invariant semantic factors and domain-specific
style factors. In the second phase, we introduce a novel
distribution-shift-controlled score-based generative diffusion model that
generates latent factors outside the training semantic and style spaces.
Additionally, auxiliary pseudo-in-distribution (InD) and pseudo-OOD graph
representations are employed to enhance the effectiveness of the energy-based
semantic OOD detector. Extensive empirical studies on three benchmark datasets
demonstrate that our approach outperforms state-of-the-art baselines.",2024-10-23,"Zhixia He, Chen Zhao, Minglai Shao, Yujie Lin, Dong Li, Qin Tian",http://arxiv.org/pdf/2410.17526v1,cs.LG
MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control,"Autonomous agents powered by large language models (LLMs) show promising
potential in assistive tasks across various domains, including mobile device
control. As these agents interact directly with personal information and device
settings, ensuring their safe and reliable behavior is crucial to prevent
undesirable outcomes. However, no benchmark exists for standardized evaluation
of the safety of mobile device-control agents. In this work, we introduce
MobileSafetyBench, a benchmark designed to evaluate the safety of
device-control agents within a realistic mobile environment based on Android
emulators. We develop a diverse set of tasks involving interactions with
various mobile applications, including messaging and banking applications,
challenging agents with managing risks encompassing misuse and negative side
effects. These tasks include tests to evaluate the safety of agents in daily
scenarios as well as their robustness against indirect prompt injection
attacks. Our experiments demonstrate that baseline agents, based on
state-of-the-art LLMs, often fail to effectively prevent harm while performing
the tasks. To mitigate these safety concerns, we propose a prompting method
that encourages agents to prioritize safety considerations. While this method
shows promise in promoting safer behaviors, there is still considerable room
for improvement to fully earn user trust. This highlights the urgent need for
continued research to develop more robust safety mechanisms in mobile
environments. We open-source our benchmark at:
https://mobilesafetybench.github.io/.",2024-10-23,"Juyong Lee, Dongyoon Hahm, June Suk Choi, W. Bradley Knox, Kimin Lee",http://arxiv.org/pdf/2410.17520v2,cs.LG
Univariate Conditional Variational Autoencoder for Morphogenic Patterns Design in Frontal Polymerization-Based Manufacturing,"Under some initial and boundary conditions, the rapid reaction-thermal
diffusion process taking place during frontal polymerization (FP) destabilizes
the planar mode of front propagation, leading to spatially varying, complex
hierarchical patterns in thermoset polymeric materials. Although modern
reaction-diffusion models can predict the patterns resulting from unstable FP,
the inverse design of patterns, which aims to retrieve process conditions that
produce a desired pattern, remains an open challenge due to the non-unique and
non-intuitive mapping between process conditions and manufactured patterns. In
this work, we propose a probabilistic generative model named univariate
conditional variational autoencoder (UcVAE) for the inverse design of
hierarchical patterns in FP-based manufacturing. Unlike the cVAE, which encodes
both the design space and the design target, the UcVAE encodes only the design
space. In the encoder of the UcVAE, the number of training parameters is
significantly reduced compared to the cVAE, resulting in a shorter training
time while maintaining comparable performance. Given desired pattern images,
the trained UcVAE can generate multiple process condition solutions that
produce high-fidelity hierarchical patterns.",2024-10-23,"Qibang Liu, Pengfei Cai, Diab Abueidda, Sagar Vyas, Seid Koric, Rafael Gomez-Bombarelli, Philippe Geubelle",http://arxiv.org/pdf/2410.17518v2,cs.LG
Time and Frequency Synergy for Source-Free Time-Series Domain Adaptations,"The issue of source-free time-series domain adaptations still gains scarce
research attentions. On the other hand, existing approaches rely solely on
time-domain features ignoring frequency components providing complementary
information. This paper proposes Time Frequency Domain Adaptation (TFDA), a
method to cope with the source-free time-series domain adaptation problems.
TFDA is developed with a dual branch network structure fully utilizing both
time and frequency features in delivering final predictions. It induces
pseudo-labels based on a neighborhood concept where predictions of a sample
group are aggregated to generate reliable pseudo labels. The concept of
contrastive learning is carried out in both time and frequency domains with
pseudo label information and a negative pair exclusion strategy to make valid
neighborhood assumptions. In addition, the time-frequency consistency technique
is proposed using the self-distillation strategy while the uncertainty
reduction strategy is implemented to alleviate uncertainties due to the domain
shift problem. Last but not least, the curriculum learning strategy is
integrated to combat noisy pseudo labels. Our experiments demonstrate the
advantage of our approach over prior arts with noticeable margins in benchmark
problems.",2024-10-23,"Muhammad Tanzil Furqon, Mahardhika Pratama, Ary Mazharuddin Shiddiqi, Lin Liu, Habibullah Habibullah, Kutluyil Dogancay",http://arxiv.org/pdf/2410.17511v1,cs.LG
Congestion Forecast for Trains with Railroad-Graph-based Semi-Supervised Learning using Sparse Passenger Reports,"Forecasting rail congestion is crucial for efficient mobility in transport
systems. We present rail congestion forecasting using reports from passengers
collected through a transit application. Although reports from passengers have
received attention from researchers, ensuring a sufficient volume of reports is
challenging due to passenger's reluctance. The limited number of reports
results in the sparsity of the congestion label, which can be an issue in
building a stable prediction model. To address this issue, we propose a
semi-supervised method for congestion forecasting for trains, or SURCONFORT.
Our key idea is twofold: firstly, we adopt semi-supervised learning to leverage
sparsely labeled data and many unlabeled data. Secondly, in order to complement
the unlabeled data from nearby stations, we design a railway network-oriented
graph and apply the graph to semi-supervised graph regularization. Empirical
experiments with actual reporting data show that SURCONFORT improved the
forecasting performance by 14.9% over state-of-the-art methods under the label
sparsity.",2024-10-23,"Soto Anno, Kota Tsubouchi, Masamichi Shimosaka",http://arxiv.org/pdf/2410.17510v1,cs.LG
WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models,"The need for effective unlearning mechanisms in large language models (LLMs)
is increasingly urgent, driven by the necessity to adhere to data regulations
and foster ethical generative AI practices. Despite growing interest of LLM
unlearning, much of the existing research has focused on varied unlearning
method designs to boost effectiveness and efficiency. However, the inherent
relationship between model weights and LLM unlearning has not been extensively
examined. In this paper, we systematically explore how model weights interact
with unlearning processes in LLMs and we design the weight attribution-guided
LLM unlearning method, WAGLE, which unveils the interconnections between
'influence' of weights and 'influence' of data to forget and retain in LLM
generation. By strategically guiding the LLM unlearning across different types
of unlearning methods and tasks, WAGLE can erase the undesired content, while
maintaining the performance of the original tasks. We refer to the weight
attribution-guided LLM unlearning method as WAGLE, which unveils the
interconnections between 'influence' of weights and 'influence' of data to
forget and retain in LLM generation. Our extensive experiments show that WAGLE
boosts unlearning performance across a range of LLM unlearning methods such as
gradient difference and (negative) preference optimization, applications such
as fictitious unlearning, malicious use prevention, and copyrighted information
removal, and models including Zephyr-7b-beta and Llama2-7b. To the best of our
knowledge, our work offers the first principled method for attributing and
pinpointing the influential weights in enhancing LLM unlearning. It stands in
contrast to previous methods that lack weight attribution and simpler weight
attribution techniques.",2024-10-23,"Jinghan Jia, Jiancheng Liu, Yihua Zhang, Parikshit Ram, Nathalie Baracaldo, Sijia Liu",http://arxiv.org/pdf/2410.17509v2,cs.LG
Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation,"Distribution shifts between training and testing datasets significantly
impair the model performance on graph learning. A commonly-taken causal view in
graph invariant learning suggests that stable predictive features of graphs are
causally associated with labels, whereas varying environmental features lead to
distribution shifts. In particular, covariate shifts caused by unseen
environments in test graphs underscore the critical need for
out-of-distribution (OOD) generalization. Existing graph augmentation methods
designed to address the covariate shift often disentangle the stable and
environmental features in the input space, and selectively perturb or mixup the
environmental features. However, such perturbation-based methods heavily rely
on an accurate separation of stable and environmental features, and their
exploration ability is confined to existing environmental features in the
training distribution. To overcome these limitations, we introduce a novel
approach using score-based graph generation strategies that synthesize unseen
environmental features while preserving the validity and stable features of
overall graph patterns. Our comprehensive empirical evaluations demonstrate the
enhanced effectiveness of our method in improving graph OOD generalization.",2024-10-23,"Bohan Wang, Yurui Chang, Lu Lin",http://arxiv.org/pdf/2410.17506v1,cs.LG
BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers,"Attacking fairness is crucial because compromised models can introduce biased
outcomes, undermining trust and amplifying inequalities in sensitive
applications like hiring, healthcare, and law enforcement. This highlights the
urgent need to understand how fairness mechanisms can be exploited and to
develop defenses that ensure both fairness and robustness. We introduce
BadFair, a novel backdoored fairness attack methodology. BadFair stealthily
crafts a model that operates with accuracy and fairness under regular
conditions but, when activated by certain triggers, discriminates and produces
incorrect results for specific groups. This type of attack is particularly
stealthy and dangerous, as it circumvents existing fairness detection methods,
maintaining an appearance of fairness in normal use. Our findings reveal that
BadFair achieves a more than 85% attack success rate in attacks aimed at target
groups on average while only incurring a minimal accuracy loss. Moreover, it
consistently exhibits a significant discrimination score, distinguishing
between pre-defined target and non-target attacked groups across various
datasets and models.",2024-10-23,"Jiaqi Xue, Qian Lou, Mengxin Zheng",http://arxiv.org/pdf/2410.17492v1,cs.LG
GenDP: 3D Semantic Fields for Category-Level Generalizable Diffusion Policy,"Diffusion-based policies have shown remarkable capability in executing
complex robotic manipulation tasks but lack explicit characterization of
geometry and semantics, which often limits their ability to generalize to
unseen objects and layouts. To enhance the generalization capabilities of
Diffusion Policy, we introduce a novel framework that incorporates explicit
spatial and semantic information via 3D semantic fields. We generate 3D
descriptor fields from multi-view RGBD observations with large foundational
vision models, then compare these descriptor fields against reference
descriptors to obtain semantic fields. The proposed method explicitly considers
geometry and semantics, enabling strong generalization capabilities in tasks
requiring category-level generalization, resolving geometric ambiguities, and
attention to subtle geometric details. We evaluate our method across eight
tasks involving articulated objects and instances with varying shapes and
textures from multiple object categories. Our method demonstrates its
effectiveness by increasing Diffusion Policy's average success rate on unseen
instances from 20% to 93%. Additionally, we provide a detailed analysis and
visualization to interpret the sources of performance gain and explain how our
method can generalize to novel instances.",2024-10-23,"Yixuan Wang, Guang Yin, Binghao Huang, Tarik Kelestemur, Jiuguang Wang, Yunzhu Li",http://arxiv.org/pdf/2410.17488v1,cs.LG
Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering,"Conventional medical artificial intelligence (AI) models face barriers in
clinical application and ethical issues owing to their inability to handle the
privacy-sensitive characteristics of medical data. We present a novel
personalized federated learning (pFL) method for medical visual question
answering (VQA) models, addressing privacy reliability challenges in the
medical domain. Our method introduces learnable prompts into a Transformer
architecture to efficiently train it on diverse medical datasets without
massive computational costs. Then we introduce a reliable client VQA model that
incorporates Dempster-Shafer evidence theory to quantify uncertainty in
predictions, enhancing the model's reliability. Furthermore, we propose a novel
inter-client communication mechanism that uses maximum likelihood estimation to
balance accuracy and uncertainty, fostering efficient integration of insights
across clients.",2024-10-23,"He Zhu, Ren Togo, Takahiro Ogawa, Miki Haseyama",http://arxiv.org/pdf/2410.17484v1,cs.LG
Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction,"Representation learning for high-dimensional, complex physical systems aims
to identify a low-dimensional intrinsic latent space, which is crucial for
reduced-order modeling and modal analysis. To overcome the well-known
Kolmogorov barrier, deep autoencoders (AEs) have been introduced in recent
years, but they often suffer from poor convergence behavior as the rank of the
latent space increases. To address this issue, we propose the learnable
weighted hybrid autoencoder, a hybrid approach that combines the strengths of
singular value decomposition (SVD) with deep autoencoders through a learnable
weighted framework. We find that the introduction of learnable weighting
parameters is essential -- without them, the resulting model would either
collapse into a standard POD or fail to exhibit the desired convergence
behavior. Interestingly, we empirically find that our trained model has a
sharpness thousands of times smaller compared to other models. Our experiments
on classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and
forced isotropic turbulence datasets, demonstrate that our approach
significantly improves generalization performance compared to several competing
methods. Additionally, when combining with time series modeling techniques
(e.g., Koopman operator, LSTM), the proposed technique offers significant
improvements for surrogate modeling of high-dimensional multi-scale PDE
systems.",2024-10-23,"Nithin Somasekharan, Shaowu Pan",http://arxiv.org/pdf/2410.18148v3,cs.LG
Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination,"The growth in prominence of large language models (LLMs) in everyday life can
be largely attributed to their generative abilities, yet some of this is also
owed to the risks and costs associated with their use. On one front is their
tendency to hallucinate false or misleading information, limiting their
reliability. On another is the increasing focus on the computational
limitations associated with traditional self-attention based LLMs, which has
brought about new alternatives, in particular recurrent models, meant to
overcome them. Yet it remains uncommon to consider these two concerns
simultaneously. Do changes in architecture exacerbate/alleviate existing
concerns about hallucinations? Do they affect how and where they occur? Through
an extensive evaluation, we study how these architecture-based inductive biases
affect the propensity to hallucinate. While hallucination remains a general
phenomenon not limited to specific architectures, the situations in which they
occur and the ease with which specific types of hallucinations can be induced
can significantly differ based on the model architecture. These findings
highlight the need for better understanding both these problems in conjunction
with each other, as well as consider how to design more universal techniques
for handling hallucinations.",2024-10-22,"Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar",http://arxiv.org/pdf/2410.17477v5,cs.LG
DROP: Distributional and Regular Optimism and Pessimism for Reinforcement Learning,"In reinforcement learning (RL), temporal difference (TD) error is known to be
related to the firing rate of dopamine neurons. It has been observed that each
dopamine neuron does not behave uniformly, but each responds to the TD error in
an optimistic or pessimistic manner, interpreted as a kind of distributional
RL. To explain such a biological data, a heuristic model has also been designed
with learning rates asymmetric for the positive and negative TD errors.
However, this heuristic model is not theoretically-grounded and unknown whether
it can work as a RL algorithm. This paper therefore introduces a novel
theoretically-grounded model with optimism and pessimism, which is derived from
control as inference. In combination with ensemble learning, a distributional
value function as a critic is estimated from regularly introduced optimism and
pessimism. Based on its central value, a policy in an actor is improved. This
proposed algorithm, so-called DROP (distributional and regular optimism and
pessimism), is compared on dynamic tasks. Although the heuristic model showed
poor learning performance, DROP showed excellent one in all tasks with high
generality. In other words, it was suggested that DROP is a new model that can
elicit the potential contributions of optimism and pessimism.",2024-10-22,Taisuke Kobayashi,http://arxiv.org/pdf/2410.17473v1,cs.LG
"ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design","Engineering molecules to exhibit precise 3D intermolecular interactions with
their environment forms the basis of chemical design. In ligand-based drug
design, bioisosteric analogues of known bioactive hits are often identified by
virtually screening chemical libraries with shape, electrostatic, and
pharmacophore similarity scoring functions. We instead hypothesize that a
generative model which learns the joint distribution over 3D molecular
structures and their interaction profiles may facilitate 3D interaction-aware
chemical design. We specifically design ShEPhERD, an SE(3)-equivariant
diffusion model which jointly diffuses/denoises 3D molecular graphs and
representations of their shapes, electrostatic potential surfaces, and
(directional) pharmacophores to/from Gaussian noise. Inspired by traditional
ligand discovery, we compose 3D similarity scoring functions to assess
ShEPhERD's ability to conditionally generate novel molecules with desired
interaction profiles. We demonstrate ShEPhERD's potential for impact via
exemplary drug design tasks including natural product ligand hopping,
protein-blind bioactive hit diversification, and bioisosteric fragment merging.",2024-10-22,"Keir Adams, Kento Abeywardane, Jenna Fromer, Connor W. Coley",http://arxiv.org/pdf/2411.04130v2,cs.LG
MEC-IP: Efficient Discovery of Markov Equivalent Classes via Integer Programming,"This paper presents a novel Integer Programming (IP) approach for discovering
the Markov Equivalent Class (MEC) of Bayesian Networks (BNs) through
observational data. The MEC-IP algorithm utilizes a unique clique-focusing
strategy and Extended Maximal Spanning Graphs (EMSG) to streamline the search
for MEC, thus overcoming the computational limitations inherent in other
existing algorithms. Our numerical results show that not only a remarkable
reduction in computational time is achieved by our algorithm but also an
improvement in causal discovery accuracy is seen across diverse datasets. These
findings underscore this new algorithm's potential as a powerful tool for
researchers and practitioners in causal discovery and BNSL, offering a
significant leap forward toward the efficient and accurate analysis of complex
data structures.",2024-10-22,"Abdelmonem Elrefaey, Rong Pan",http://arxiv.org/pdf/2410.18147v1,cs.LG
Interpretable Multimodal Machine Learning Analysis of X-ray Absorption Near-Edge Spectra and Pair Distribution Functions,"We used interpretable machine learning to combine information from multiple
heterogeneous spectra: X-ray absorption near-edge spectra (XANES) and atomic
pair distribution functions (PDFs) to extract local structural and chemical
environments of transition metal cations in oxides. Random forest models were
trained on simulated XANES, PDF, and both combined to extract oxidation state,
coordination number, and mean nearest-neighbor bond length. XANES-only models
generally outperformed PDF-only models, even for structural tasks, although
using the metal's differential PDFs (dPDFs) instead of total PDFs narrowed this
gap. When combined with PDFs, information from XANES often dominates the
prediction. Our results demonstrate that XANES contain rich structural
information and highlight the utility of species-specificity. This
interpretable, multimodal approach is quick to implement with suitable
databases and offers valuable insights into the relative strengths of different
modalities, guiding researchers in experiment design and identifying when
combining complementary techniques adds meaningful information to a scientific
investigation.",2024-10-22,"Tanaporn Na Narong, Zoe N. Zachko, Steven B. Torrisi, Simon J. L. Billinge",http://arxiv.org/pdf/2410.17467v2,cs.LG
Evolution of Societies via Reinforcement Learning,"The universe involves many independent co-learning agents as an ever-evolving
part of our observed environment. Yet, in practice, Multi-Agent Reinforcement
Learning (MARL) applications are typically constrained to small, homogeneous
populations and remain computationally intensive. We propose a methodology that
enables simulating populations of Reinforcement Learning agents at evolutionary
scale. More specifically, we derive a fast, parallelizable implementation of
Policy Gradient (PG) and Opponent-Learning Awareness (LOLA), tailored for
evolutionary simulations where agents undergo random pairwise interactions in
stateless normal-form games. We demonstrate our approach by simulating the
evolution of very large populations made of heterogeneous co-learning agents,
under both naive and advanced learning strategies. In our experiments, 200,000
PG or LOLA agents evolve in the classic games of Hawk-Dove, Stag-Hunt, and
Rock-Paper-Scissors. Each game provides distinct insights into how populations
evolve under both naive and advanced MARL rules, including compelling ways in
which Opponent-Learning Awareness affects social evolution.",2024-10-22,"Yann Bouteiller, Karthik Soma, Giovanni Beltrame",http://arxiv.org/pdf/2410.17466v4,cs.LG
"Bauplan: zero-copy, scale-up FaaS for data pipelines","Chaining functions for longer workloads is a key use case for FaaS platforms
in data applications. However, modern data pipelines differ significantly from
typical serverless use cases (e.g., webhooks and microservices); this makes it
difficult to retrofit existing pipeline frameworks due to structural
constraints. In this paper, we describe these limitations in detail and
introduce bauplan, a novel FaaS programming model and serverless runtime
designed for data practitioners. bauplan enables users to declaratively define
functional Directed Acyclic Graphs (DAGs) along with their runtime
environments, which are then efficiently executed on cloud-based workers. We
show that bauplan achieves both better performance and a superior developer
experience for data workloads by making the trade-off of reducing generality in
favor of data-awareness",2024-10-22,"Jacopo Tagliabue, Tyler Caraza-Harter, Ciro Greco",http://arxiv.org/pdf/2410.17465v1,cs.LG
Scalable Implicit Graphon Learning,"Graphons are continuous models that represent the structure of graphs and
allow the generation of graphs of varying sizes. We propose Scalable Implicit
Graphon Learning (SIGL), a scalable method that combines implicit neural
representations (INRs) and graph neural networks (GNNs) to estimate a graphon
from observed graphs. Unlike existing methods, which face important limitations
like fixed resolution and scalability issues, SIGL learns a continuous graphon
at arbitrary resolutions. GNNs are used to determine the correct node ordering,
improving graph alignment. Furthermore, we characterize the asymptotic
consistency of our estimator, showing that more expressive INRs and GNNs lead
to consistent estimators. We evaluate SIGL in synthetic and real-world graphs,
showing that it outperforms existing methods and scales effectively to larger
graphs, making it ideal for tasks like graph data augmentation.",2024-10-22,"Ali Azizpour, Nicolas Zilberstein, Santiago Segarra",http://arxiv.org/pdf/2410.17464v2,cs.LG
Graph Neural Network-Accelerated Network-Reconfigured Optimal Power Flow,"Optimal power flow (OPF) has been used for real-time grid operations. Prior
efforts demonstrated that utilizing flexibility from dynamic topologies will
improve grid efficiency. However, this will convert the linear OPF into a
mixed-integer linear programming network-reconfigured OPF (NR-OPF) problem,
substantially increasing the computing time. Thus, a machine learning
(ML)-based approach, particularly utilizing graph neural network (GNN), is
proposed to accelerate the solution process. The GNN model is trained offline
to predict the best topology before entering the optimization stage. In
addition, this paper proposes an offline pre-ML filter layer to reduce GNN
model size and training time while improving its accuracy. A fast online
post-ML selection layer is also proposed to analyze GNN predictions and then
select a subset of predicted NR solutions with high confidence. Case studies
have demonstrated superior performance of the proposed GNN-accelerated NR-OPF
method augmented with the proposed pre-ML and post-ML layers.",2024-10-22,"Thuan Pham, Xingpeng Li",http://arxiv.org/pdf/2410.17460v1,cs.LG
Data Obfuscation through Latent Space Projection (LSP) for Privacy-Preserving AI Governance: Case Studies in Medical Diagnosis and Finance Fraud Detection,"As AI systems increasingly integrate into critical societal sectors, the
demand for robust privacy-preserving methods has escalated. This paper
introduces Data Obfuscation through Latent Space Projection (LSP), a novel
technique aimed at enhancing AI governance and ensuring Responsible AI
compliance. LSP uses machine learning to project sensitive data into a latent
space, effectively obfuscating it while preserving essential features for model
training and inference. Unlike traditional privacy methods like differential
privacy or homomorphic encryption, LSP transforms data into an abstract,
lower-dimensional form, achieving a delicate balance between data utility and
privacy. Leveraging autoencoders and adversarial training, LSP separates
sensitive from non-sensitive information, allowing for precise control over
privacy-utility trade-offs. We validate LSP's effectiveness through experiments
on benchmark datasets and two real-world case studies: healthcare cancer
diagnosis and financial fraud analysis. Our results show LSP achieves high
performance (98.7% accuracy in image classification) while providing strong
privacy (97.3% protection against sensitive attribute inference), outperforming
traditional anonymization and privacy-preserving methods. The paper also
examines LSP's alignment with global AI governance frameworks, such as GDPR,
CCPA, and HIPAA, highlighting its contribution to fairness, transparency, and
accountability. By embedding privacy within the machine learning pipeline, LSP
offers a promising approach to developing AI systems that respect privacy while
delivering valuable insights. We conclude by discussing future research
directions, including theoretical privacy guarantees, integration with
federated learning, and enhancing latent space interpretability, positioning
LSP as a critical tool for ethical AI advancement.",2024-10-22,Mahesh Vaijainthymala Krishnamoorthy,http://arxiv.org/pdf/2410.17459v1,cs.LG
Guaranteeing Conservation Laws with Projection in Physics-Informed Neural Networks,"Physics-informed neural networks (PINNs) incorporate physical laws into their
training to efficiently solve partial differential equations (PDEs) with
minimal data. However, PINNs fail to guarantee adherence to conservation laws,
which are also important to consider in modeling physical systems. To address
this, we proposed PINN-Proj, a PINN-based model that uses a novel projection
method to enforce conservation laws. We found that PINN-Proj substantially
outperformed PINN in conserving momentum and lowered prediction error by three
to four orders of magnitude from the best benchmark tested. PINN-Proj also
performed marginally better in the separate task of state prediction on three
PDE datasets.",2024-10-22,"Anthony Baez, Wang Zhang, Ziwen Ma, Subhro Das, Lam M. Nguyen, Luca Daniel",http://arxiv.org/pdf/2410.17445v1,cs.LG
Detecting Adversarial Examples,"Deep Neural Networks (DNNs) have been shown to be vulnerable to adversarial
examples. While numerous successful adversarial attacks have been proposed,
defenses against these attacks remain relatively understudied. Existing defense
approaches either focus on negating the effects of perturbations caused by the
attacks to restore the DNNs' original predictions or use a secondary model to
detect adversarial examples. However, these methods often become ineffective
due to the continuous advancements in attack techniques. We propose a novel
universal and lightweight method to detect adversarial examples by analyzing
the layer outputs of DNNs. Through theoretical justification and extensive
experiments, we demonstrate that our detection method is highly effective,
compatible with any DNN architecture, and applicable across different domains,
such as image, video, and audio.",2024-10-22,"Furkan Mumcu, Yasin Yilmaz",http://arxiv.org/pdf/2410.17442v1,cs.LG
Interpreting Affine Recurrence Learning in GPT-style Transformers,"Understanding the internal mechanisms of GPT-style transformers, particularly
their capacity to perform in-context learning (ICL), is critical for advancing
AI alignment and interpretability. In-context learning allows transformers to
generalize during inference without modifying their weights, yet the precise
operations driving this capability remain largely opaque. This paper presents
an investigation into the mechanistic interpretability of these transformers,
focusing specifically on their ability to learn and predict affine recurrences
as an ICL task. To address this, we trained a custom three-layer transformer to
predict affine recurrences and analyzed the model's internal operations using
both empirical and theoretical approaches. Our findings reveal that the model
forms an initial estimate of the target sequence using a copying mechanism in
the zeroth layer, which is subsequently refined through negative similarity
heads in the second layer. These insights contribute to a deeper understanding
of transformer behaviors in recursive tasks and offer potential avenues for
improving AI alignment through mechanistic interpretability. Finally, we
discuss the implications of our results for future work, including extensions
to higher-dimensional recurrences and the exploration of polynomial sequences.",2024-10-22,"Samarth Bhargav, Alexander Gu",http://arxiv.org/pdf/2410.17438v1,cs.LG
"AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset","Query Autocomplete (QAC) is a critical feature in modern search engines,
facilitating user interaction by predicting search queries based on input
prefixes. Despite its widespread adoption, the absence of large-scale,
realistic datasets has hindered advancements in QAC system development. This
paper addresses this gap by introducing AmazonQAC, a new QAC dataset sourced
from Amazon Search logs, comprising 395M samples. The dataset includes actual
sequences of user-typed prefixes leading to final search terms, as well as
session IDs and timestamps that support modeling the context-dependent aspects
of QAC. We assess Prefix Trees, semantic retrieval, and Large Language Models
(LLMs) with and without finetuning. We find that finetuned LLMs perform best,
particularly when incorporating contextual information. However, even our best
system achieves only half of what we calculate is theoretically possible on our
test data, which implies QAC is a challenging problem that is far from solved
with existing systems. This contribution aims to stimulate further research on
QAC systems to better serve user needs in diverse environments. We open-source
this data on Hugging Face at https://huggingface.co/datasets/amazon/AmazonQAC.",2024-10-22,"Dante Everaert, Rohit Patki, Tianqi Zheng, Christopher Potts",http://arxiv.org/pdf/2411.04129v1,cs.LG
Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks,"Federated learning (FL) is susceptible to a range of security threats.
Although various defense mechanisms have been proposed, they are typically
non-adaptive and tailored to specific types of attacks, leaving them
insufficient in the face of multiple uncertain, unknown, and adaptive attacks
employing diverse strategies. This work formulates adversarial federated
learning under a mixture of various attacks as a Bayesian Stackelberg Markov
game, based on which we propose the meta-Stackelberg defense composed of
pre-training and online adaptation. {The gist is to simulate strong attack
behavior using reinforcement learning (RL-based attacks) in pre-training and
then design meta-RL-based defense to combat diverse and adaptive attacks.} We
develop an efficient meta-learning approach to solve the game, leading to a
robust and adaptive FL defense. Theoretically, our meta-learning algorithm,
meta-Stackelberg learning, provably converges to the first-order
$\varepsilon$-meta-equilibrium point in $O(\varepsilon^{-2})$ gradient
iterations with $O(\varepsilon^{-4})$ samples per iteration. Experiments show
that our meta-Stackelberg framework performs superbly against strong model
poisoning and backdoor attacks of uncertain and unknown types.",2024-10-22,"Tao Li, Henger Li, Yunian Pan, Tianyi Xu, Zizhan Zheng, Quanyan Zhu",http://arxiv.org/pdf/2410.17431v1,cs.LG
Real-time experiment-theory closed-loop interaction for autonomous materials science,"Iterative cycles of theoretical prediction and experimental validation are
the cornerstone of the modern scientific method. However, the proverbial
""closing of the loop"" in experiment-theory cycles in practice are usually ad
hoc, often inherently difficult, or impractical to repeat on a systematic
basis, beset by the scale or the time constraint of computation or the
phenomena under study. Here, we demonstrate Autonomous MAterials Search Engine
(AMASE), where we enlist robot science to perform self-driving continuous
cyclical interaction of experiments and computational predictions for materials
exploration. In particular, we have applied the AMASE formalism to the rapid
mapping of a temperature-composition phase diagram, a fundamental task for the
search and discovery of new materials. Thermal processing and experimental
determination of compositional phase boundaries in thin films are autonomously
interspersed with real-time updating of the phase diagram prediction through
the minimization of Gibbs free energies. AMASE was able to accurately determine
the eutectic phase diagram of the Sn-Bi binary thin-film system on the fly from
a self-guided campaign covering just a small fraction of the entire composition
- temperature phase space, translating to a 6-fold reduction in the number of
necessary experiments. This study demonstrates for the first time the
possibility of real-time, autonomous, and iterative interactions of experiments
and theory carried out without any human intervention.",2024-10-22,"Haotong Liang, Chuangye Wang, Heshan Yu, Dylan Kirsch, Rohit Pant, Austin McDannald, A. Gilad Kusne, Ji-Cheng Zhao, Ichiro Takeuchi",http://arxiv.org/pdf/2410.17430v1,cs.LG
Uncovering RL Integration in SSL Loss: Objective-Specific Implications for Data-Efficient RL,"In this study, we investigate the effect of SSL objective modifications
within the SPR framework, focusing on specific adjustments such as terminal
state masking and prioritized replay weighting, which were not explicitly
addressed in the original design. While these modifications are specific to RL,
they are not universally applicable across all RL algorithms. Therefore, we aim
to assess their impact on performance and explore other SSL objectives that do
not accommodate these adjustments like Barlow Twins and VICReg. We evaluate six
SPR variants on the Atari 100k benchmark, including versions both with and
without these modifications. Additionally, we test the performance of these
objectives on the DeepMind Control Suite, where such modifications are absent.
Our findings reveal that incorporating specific SSL modifications within SPR
significantly enhances performance, and this influence extends to subsequent
frameworks like SR-SPR and BBF, highlighting the critical importance of SSL
objective selection and related adaptations in achieving data efficiency in
self-predictive reinforcement learning.",2024-10-22,"Ömer Veysel Çağatan, Barış Akgün",http://arxiv.org/pdf/2410.17428v2,cs.LG
SigCLR: Sigmoid Contrastive Learning of Visual Representations,"We propose SigCLR: Sigmoid Contrastive Learning of Visual Representations.
SigCLR utilizes the logistic loss that only operates on pairs and does not
require a global view as in the cross-entropy loss used in SimCLR. We show that
logistic loss shows competitive performance on CIFAR-10, CIFAR-100, and Tiny-IN
compared to other established SSL objectives. Our findings verify the
importance of learnable bias as in the case of SigLUP, however, it requires a
fixed temperature as in the SimCLR to excel. Overall, SigCLR is a promising
replacement for the SimCLR which is ubiquitous and has shown tremendous success
in various domains.",2024-10-22,Ömer Veysel Çağatan,http://arxiv.org/pdf/2410.17427v1,cs.LG
End-to-End Optimization and Learning of Fair Court Schedules,"Criminal courts across the United States handle millions of cases every year,
and the scheduling of those cases must accommodate a diverse set of
constraints, including the preferences and availability of courts, prosecutors,
and defense teams. When criminal court schedules are formed, defendants'
scheduling preferences often take the least priority, although defendants may
face significant consequences (including arrest or detention) for missed court
dates. Additionally, studies indicate that defendants' nonappearances impose
costs on the courts and other system stakeholders. To address these issues,
courts and commentators have begun to recognize that pretrial outcomes for
defendants and for the system would be improved with greater attention to court
processes, including \emph{court scheduling practices}. There is thus a need
for fair criminal court pretrial scheduling systems that account for
defendants' preferences and availability, but the collection of such data poses
logistical challenges. Furthermore, optimizing schedules fairly across various
parties' preferences is a complex optimization problem, even when such data is
available. In an effort to construct such a fair scheduling system under data
uncertainty, this paper proposes a joint optimization and learning framework
that combines machine learning models trained end-to-end with efficient
matching algorithms. This framework aims to produce court scheduling schedules
that optimize a principled measure of fairness, balancing the availability and
preferences of all parties.",2024-10-22,"My H Dinh, James Kotary, Lauryn P. Gouldin, William Yeoh, Ferdinando Fioretto",http://arxiv.org/pdf/2410.17415v1,cs.LG
Learning Graph Filters for Structure-Function Coupling based Hub Node Identification,"Over the past two decades, tools from network science have been leveraged to
characterize the organization of both structural and functional networks of the
brain. One such measure of network organization is hub node identification.
Hubs are specialized nodes within a network that link distinct brain units
corresponding to specialized functional processes. Conventional methods for
identifying hub nodes utilize different types of centrality measures and
participation coefficient to profile various aspects of nodal importance. These
methods solely rely on the functional connectivity networks constructed from
functional magnetic resonance imaging (fMRI), ignoring the structure-function
coupling in the brain. In this paper, we introduce a graph signal processing
(GSP) based hub detection framework that utilizes both the structural
connectivity and the functional activation to identify hub nodes. The proposed
framework models functional activity as graph signals on the structural
connectivity. Hub nodes are then detected based on the premise that hub nodes
are sparse, have higher level of activity compared to their neighbors, and the
non-hub nodes' activity can be modeled as the output of a graph-based filter.
Based on these assumptions, an optimization framework, GraFHub, is formulated
to learn the coefficients of the optimal polynomial graph filter and detect the
hub nodes. The proposed framework is evaluated on both simulated data and
resting state fMRI (rs-fMRI) data from Human Connectome Project (HCP).",2024-10-22,"Meiby Ortiz-Bouza, Duc Vu, Abdullah Karaaslanli, Selin Aviyente",http://arxiv.org/pdf/2410.17410v1,cs.LG
Geometric Graph Neural Network Modeling of Human Interactions in Crowded Environments,"Modeling human trajectories in crowded environments is challenging due to the
complex nature of pedestrian behavior and interactions. This paper proposes a
geometric graph neural network (GNN) architecture that integrates domain
knowledge from psychological studies to model pedestrian interactions and
predict future trajectories. Unlike prior studies using complete graphs, we
define interaction neighborhoods using pedestrians' field of view, motion
direction, and distance-based kernel functions to construct graph
representations of crowds. Evaluations across multiple datasets demonstrate
improved prediction accuracy through reduced average and final displacement
error metrics. Our findings underscore the importance of integrating domain
knowledge with data-driven approaches for effective modeling of human
interactions in crowds.",2024-10-22,"Sara Honarvar, Yancy Diaz-Mercado",http://arxiv.org/pdf/2410.17409v1,cs.LG
Quantum Large Language Models via Tensor Network Disentanglers,"We propose a method to enhance the performance of Large Language Models
(LLMs) by integrating quantum computing and quantum-inspired techniques.
Specifically, our approach involves replacing the weight matrices in the
Self-Attention and Multi-layer Perceptron layers with a combination of two
variational quantum circuits and a quantum-inspired tensor network, such as a
Matrix Product Operator (MPO). This substitution enables the reproduction of
classical LLM functionality by decomposing weight matrices through the
application of tensor network disentanglers and MPOs, leveraging
well-established tensor network techniques. By incorporating more complex and
deeper quantum circuits, along with increasing the bond dimensions of the MPOs,
our method captures additional correlations within the quantum-enhanced LLM,
leading to improved accuracy beyond classical models while maintaining low
memory overhead.",2024-10-22,"Borja Aizpurua, Saeed S. Jahromi, Sukhbinder Singh, Roman Orus",http://arxiv.org/pdf/2410.17397v1,cs.LG
packetLSTM: Dynamic LSTM Framework for Streaming Data with Varying Feature Space,"We study the online learning problem characterized by the varying input
feature space of streaming data. Although LSTMs have been employed to
effectively capture the temporal nature of streaming data, they cannot handle
the dimension-varying streams in an online learning setting. Therefore, we
propose a dynamic LSTM-based novel method, called packetLSTM, to model the
dimension-varying streams. The packetLSTM's dynamic framework consists of an
evolving packet of LSTMs, each dedicated to processing one input feature. Each
LSTM retains the local information of its corresponding feature, while a shared
common memory consolidates global information. This configuration facilitates
continuous learning and mitigates the issue of forgetting, even when certain
features are absent for extended time periods. The idea of utilizing one LSTM
per feature coupled with a dimension-invariant operator for information
aggregation enhances the dynamic nature of packetLSTM. This dynamic nature is
evidenced by the model's ability to activate, deactivate, and add new LSTMs as
required, thus seamlessly accommodating varying input dimensions. The
packetLSTM achieves state-of-the-art results on five datasets, and its
underlying principle is extended to other RNN types, like GRU and vanilla RNN.",2024-10-22,"Rohit Agarwal, Karaka Prasanth Naidu, Alexander Horsch, Krishna Agarwal, Dilip K. Prasad",http://arxiv.org/pdf/2410.17394v1,cs.LG
Enhancing Deep Learning based RMT Data Inversion using Gaussian Random Field,"Deep learning (DL) methods have emerged as a powerful tool for the inversion
of geophysical data. When applied to field data, these models often struggle
without additional fine-tuning of the network. This is because they are built
on the assumption that the statistical patterns in the training and test
datasets are the same. To address this, we propose a DL-based inversion scheme
for Radio Magnetotelluric data where the subsurface resistivity models are
generated using Gaussian Random Fields (GRF). The network's generalization
ability was tested with an out-of-distribution (OOD) dataset comprising a
homogeneous background and various rectangular-shaped anomalous bodies. After
end-to-end training with the GRF dataset, the pre-trained network successfully
identified anomalies in the OOD dataset. Synthetic experiments confirmed that
the GRF dataset enhances generalization compared to a homogeneous background
OOD dataset. The network accurately recovered structures in a checkerboard
resistivity model, and demonstrated robustness to noise, outperforming
traditional gradient-based methods. Finally, the developed scheme is tested
using exemplary field data from a waste site near Roorkee, India. The proposed
scheme enhances generalization in a data-driven supervised learning framework,
suggesting a promising direction for OOD generalization in DL methods.",2024-10-22,"Koustav Ghosal, Arun Singh, Samir Malakar, Shalivahan Srivastava, Deepak Gupta",http://arxiv.org/pdf/2410.19858v1,cs.LG
Cooperative Multi-Agent Constrained Stochastic Linear Bandits,"In this study, we explore a collaborative multi-agent stochastic linear
bandit setting involving a network of $N$ agents that communicate locally to
minimize their collective regret while keeping their expected cost under a
specified threshold $\tau$. Each agent encounters a distinct linear bandit
problem characterized by its own reward and cost parameters, i.e., local
parameters. The goal of the agents is to determine the best overall action
corresponding to the average of these parameters, or so-called global
parameters. In each round, an agent is randomly chosen to select an action
based on its current knowledge of the system. This chosen action is then
executed by all agents, then they observe their individual rewards and costs.
We propose a safe distributed upper confidence bound algorithm, so called
\textit{MA-OPLB}, and establish a high probability bound on its $T$-round
regret. MA-OPLB utilizes an accelerated consensus method, where agents can
compute an estimate of the average rewards and costs across the network by
communicating the proper information with their neighbors. We show that our
regret bound is of order $
\mathcal{O}\left(\frac{d}{\tau-c_0}\frac{\log(NT)^2}{\sqrt{N}}\sqrt{\frac{T}{\log(1/|\lambda_2|)}}\right)$,
where $\lambda_2$ is the second largest (in absolute value) eigenvalue of the
communication matrix, and $\tau-c_0$ is the known cost gap of a feasible
action. We also experimentally show the performance of our proposed algorithm
in different network structures.",2024-10-22,"Amirhossein Afsharrad, Parisa Oftadeh, Ahmadreza Moradipari, Sanjay Lall",http://arxiv.org/pdf/2410.17382v1,cs.LG
AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration,"Large language models typically generate tokens autoregressively, using each
token as input for the next. Recent work on Speculative Decoding has sought to
accelerate this process by employing a smaller, faster draft model to more
quickly generate candidate tokens. These candidates are then verified in
parallel by the larger (original) verify model, resulting in overall speedup
compared to using the larger model by itself in an autoregressive fashion. In
this work, we introduce AMUSD (Asynchronous Multi-device Speculative Decoding),
a system that further accelerates generation by decoupling the draft and verify
phases into a continuous, asynchronous approach. Unlike conventional
speculative decoding, where only one model (draft or verify) performs token
generation at a time, AMUSD enables both models to perform predictions
independently on separate devices (e.g., GPUs). We evaluate our approach over
multiple datasets and show that AMUSD achieves an average 29% improvement over
speculative decoding and up to 1.96$\times$ speedup over conventional
autoregressive decoding, while achieving identical output quality. Our system
is open-source and available at https://github.com/BradMcDanel/AMUSD/.",2024-10-22,Bradley McDanel,http://arxiv.org/pdf/2410.17375v1,cs.LG
Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning,"Understanding cognitive processes in multi-agent interactions is a primary
goal in cognitive science. It can guide the direction of artificial
intelligence (AI) research toward social decision-making in multi-agent
systems, which includes uncertainty from character heterogeneity. In this
paper, we introduce an episodic future thinking (EFT) mechanism for a
reinforcement learning (RL) agent, inspired by cognitive processes observed in
animals. To enable future thinking functionality, we first develop a
multi-character policy that captures diverse characters with an ensemble of
heterogeneous policies. Here, the character of an agent is defined as a
different weight combination on reward components, representing distinct
behavioral preferences. The future thinking agent collects observation-action
trajectories of the target agents and uses the pre-trained multi-character
policy to infer their characters. Once the character is inferred, the agent
predicts the upcoming actions of target agents and simulates the potential
future scenario. This capability allows the agent to adaptively select the
optimal action, considering the predicted future scenario in multi-agent
interactions. To evaluate the proposed mechanism, we consider the multi-agent
autonomous driving scenario with diverse driving traits and multiple particle
environments. Simulation results demonstrate that the EFT mechanism with
accurate character inference leads to a higher reward than existing multi-agent
solutions. We also confirm that the effect of reward improvement remains valid
across societies with different levels of character diversity.",2024-10-22,"Dongsu Lee, Minhae Kwon",http://arxiv.org/pdf/2410.17373v1,cs.LG
Characterizing Robocalls with Multiple Vantage Points,"Telephone spam has been among the highest network security concerns for users
for many years. In response, industry and government have deployed new
technologies and regulations to curb the problem, and academic and industry
researchers have provided methods and measurements to characterize robocalls.
Have these efforts borne fruit? Are the research characterizations reliable,
and have the prevention and deterrence mechanisms succeeded?
  In this paper, we address these questions through analysis of data from
several independently-operated vantage points, ranging from industry and
academic voice honeypots to public enforcement and consumer complaints, some
with over 5 years of historic data. We first describe how we address the
non-trivial methodological challenges of comparing disparate data sources,
including comparing audio and transcripts from about 3 million voice calls. We
also detail the substantial coherency of these diverse perspectives, which
dramatically strengthens the evidence for the conclusions we draw about
robocall characterization and mitigation while highlighting advantages of each
approach. Among our many findings, we find that unsolicited calls are in slow
decline, though complaints and call volumes remain high. We also find that
robocallers have managed to adapt to STIR/SHAKEN, a mandatory call
authentication scheme. In total, our findings highlight the most promising
directions for future efforts to characterize and stop telephone spam.",2024-10-22,"Sathvik Prasad, Aleksandr Nahapetyan, Bradley Reaves",http://arxiv.org/pdf/2410.17361v1,cs.LG
VideoSAM: A Large Vision Foundation Model for High-Speed Video Segmentation,"High-speed video (HSV) segmentation is essential for analyzing dynamic
physical processes in scientific and industrial applications, such as boiling
heat transfer. Existing models like U-Net struggle with generalization and
accurately segmenting complex bubble formations. We present VideoSAM, a
specialized adaptation of the Segment Anything Model (SAM), fine-tuned on a
diverse HSV dataset for phase detection. Through diverse experiments, VideoSAM
demonstrates superior performance across four fluid environments -- Water,
FC-72, Nitrogen, and Argon -- significantly outperforming U-Net in complex
segmentation tasks. In addition to introducing VideoSAM, we contribute an
open-source HSV segmentation dataset designed for phase detection, enabling
future research in this domain. Our findings underscore VideoSAM's potential to
set new standards in robust and accurate HSV segmentation. The code and dataset
used in this study are available online at
https://github.com/chikap421/videosam.",2024-10-22,"Chika Maduabuchi, Ericmoore Jossou, Matteo Bucci",http://arxiv.org/pdf/2410.21304v3,cs.LG
Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense,"Recent advances in multi-agent reinforcement learning (MARL) have created
opportunities to solve complex real-world tasks. Cybersecurity is a notable
application area, where defending networks against sophisticated adversaries
remains a challenging task typically performed by teams of security operators.
In this work, we explore novel MARL strategies for building autonomous cyber
network defenses that address challenges such as large policy spaces, partial
observability, and stealthy, deceptive adversarial strategies. To facilitate
efficient and generalized learning, we propose a hierarchical Proximal Policy
Optimization (PPO) architecture that decomposes the cyber defense task into
specific sub-tasks like network investigation and host recovery. Our approach
involves training sub-policies for each sub-task using PPO enhanced with domain
expertise. These sub-policies are then leveraged by a master defense policy
that coordinates their selection to solve complex network defense tasks.
Furthermore, the sub-policies can be fine-tuned and transferred with minimal
cost to defend against shifts in adversarial behavior or changes in network
settings. We conduct extensive experiments using CybORG Cage 4, the
state-of-the-art MARL environment for cyber defense. Comparisons with multiple
baselines across different adversaries show that our hierarchical learning
approach achieves top performance in terms of convergence speed, episodic
return, and several interpretable metrics relevant to cybersecurity, including
the fraction of clean machines on the network, precision, and false positives
on recoveries.",2024-10-22,"Aditya Vikram Singh, Ethan Rathbun, Emma Graham, Lisa Oakley, Simona Boboila, Alina Oprea, Peter Chin",http://arxiv.org/pdf/2410.17351v2,cs.LG
Privacy-Computation trade-offs in Private Repetition and Metaselection,"A Private Repetition algorithm takes as input a differentially private
algorithm with constant success probability and boosts it to one that succeeds
with high probability. These algorithms are closely related to private
metaselection algorithms that compete with the best of many private algorithms,
and private hyperparameter tuning algorithms that compete with the best
hyperparameter settings for a private learning algorithm. Existing algorithms
for these tasks pay either a large overhead in privacy cost, or a large
overhead in computational cost. In this work, we show strong lower bounds for
problems of this kind, showing in particular that for any algorithm that
preserves the privacy cost up to a constant factor, the failure probability can
only fall polynomially in the computational overhead. This is in stark contrast
with the non-private setting, where the failure probability falls exponentially
in the computational overhead. By carefully combining existing algorithms for
metaselection, we prove computation-privacy tradeoffs that nearly match our
lower bounds.",2024-10-22,Kunal Talwar,http://arxiv.org/pdf/2410.19012v1,cs.LG
EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting,"Multi-channel EEG signals are commonly used for the diagnosis and assessment
of diseases such as epilepsy. Currently, various EEG diagnostic algorithms
based on deep learning have been developed. However, most research efforts
focus solely on diagnosing and classifying current signal data but do not
consider the prediction of future trends for early warning. Additionally, since
multi-channel EEG can be essentially regarded as the spatio-temporal signal
data received by detectors at different locations in the brain, how to
construct spatio-temporal information representations of EEG signals to
facilitate future trend prediction for multi-channel EEG becomes an important
problem. This study proposes a multi-signal prediction algorithm based on
generative diffusion models (EEG-DIF), which transforms the multi-signal
forecasting task into an image completion task, allowing for comprehensive
representation and learning of the spatio-temporal correlations and future
developmental patterns of multi-channel EEG signals. Here, we employ a publicly
available epilepsy EEG dataset to construct and validate the EEG-DIF. The
results demonstrate that our method can accurately predict future trends for
multi-channel EEG signals simultaneously. Furthermore, the early warning
accuracy for epilepsy seizures based on the generated EEG data reaches 0.89. In
general, EEG-DIF provides a novel approach for characterizing multi-channel EEG
signals and an innovative early warning algorithm for epilepsy seizures, aiding
in optimizing and enhancing the clinical diagnosis process. The code is
available at https://github.com/JZK00/EEG-DIF.",2024-10-22,"Zekun Jiang, Wei Dai, Qu Wei, Ziyuan Qin, Kang Li, Le Zhang",http://arxiv.org/pdf/2410.17343v1,cs.LG
Enhancing Robustness and Efficiency of Least Square Twin SVM via Granular Computing,"In the domain of machine learning, least square twin support vector machine
(LSTSVM) stands out as one of the state-of-the-art models. However, LSTSVM
suffers from sensitivity to noise and outliers, overlooking the SRM principle
and instability in resampling. Moreover, its computational complexity and
reliance on matrix inversions hinder the efficient processing of large
datasets. As a remedy to the aforementioned challenges, we propose the robust
granular ball LSTSVM (GBLSTSVM). GBLSTSVM is trained using granular balls
instead of original data points. The core of a granular ball is found at its
center, where it encapsulates all the pertinent information of the data points
within the ball of specified radius. To improve scalability and efficiency, we
further introduce the large-scale GBLSTSVM (LS-GBLSTSVM), which incorporates
the SRM principle through regularization terms. Experiments are performed on
UCI, KEEL, and NDC benchmark datasets; both the proposed GBLSTSVM and
LS-GBLSTSVM models consistently outperform the baseline models.",2024-10-22,"M. Tanveer, R. K. Sharma, A. Quadir, M. Sajid",http://arxiv.org/pdf/2410.17338v2,cs.LG
Computing Optimal Regularizers for Online Linear Optimization,"Follow-the-Regularized-Leader (FTRL) algorithms are a popular class of
learning algorithms for online linear optimization (OLO) that guarantee
sub-linear regret, but the choice of regularizer can significantly impact
dimension-dependent factors in the regret bound. We present an algorithm that
takes as input convex and symmetric action sets and loss sets for a specific
OLO instance, and outputs a regularizer such that running FTRL with this
regularizer guarantees regret within a universal constant factor of the best
possible regret bound. In particular, for any choice of (convex, symmetric)
action set and loss set we prove that there exists an instantiation of FTRL
which achieves regret within a constant factor of the best possible learning
algorithm, strengthening the universality result of Srebro et al., 2011.
  Our algorithm requires preprocessing time and space exponential in the
dimension $d$ of the OLO instance, but can be run efficiently online assuming a
membership and linear optimization oracle for the action and loss sets,
respectively (and is fully polynomial time for the case of constant dimension
$d$). We complement this with a lower bound showing that even deciding whether
a given regularizer is $\alpha$-strongly-convex with respect to a given norm is
NP-hard.",2024-10-22,"Khashayar Gatmiry, Jon Schneider, Stefanie Jegelka",http://arxiv.org/pdf/2410.17336v1,cs.LG
Literature Meets Data: A Synergistic Approach to Hypothesis Generation,"AI holds promise for transforming scientific processes, including hypothesis
generation. Prior work on hypothesis generation can be broadly categorized into
theory-driven and data-driven approaches. While both have proven effective in
generating novel and plausible hypotheses, it remains an open question whether
they can complement each other. To address this, we develop the first method
that combines literature-based insights with data to perform LLM-powered
hypothesis generation. We apply our method on five different datasets and
demonstrate that integrating literature and data outperforms other baselines
(8.97\% over few-shot, 15.75\% over literature-based alone, and 3.37\% over
data-driven alone). Additionally, we conduct the first human evaluation to
assess the utility of LLM-generated hypotheses in assisting human
decision-making on two challenging tasks: deception detection and AI generated
content detection. Our results show that human accuracy improves significantly
by 7.44\% and 14.19\% on these tasks, respectively. These findings suggest that
integrating literature-based and data-driven approaches provides a
comprehensive and nuanced framework for hypothesis generation and could open
new avenues for scientific inquiry.",2024-10-22,"Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, Chenhao Tan",http://arxiv.org/pdf/2410.17309v3,cs.LG
LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias,"We propose the Large View Synthesis Model (LVSM), a novel transformer-based
approach for scalable and generalizable novel view synthesis from sparse-view
inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which
encodes input image tokens into a fixed number of 1D latent tokens, functioning
as a fully learned scene representation, and decodes novel-view images from
them; and (2) a decoder-only LVSM, which directly maps input images to
novel-view outputs, completely eliminating intermediate scene representations.
Both models bypass the 3D inductive biases used in previous methods -- from 3D
representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar
projections, plane sweeps) -- addressing novel view synthesis with a fully
data-driven approach. While the encoder-decoder model offers faster inference
due to its independent latent representation, the decoder-only LVSM achieves
superior quality, scalability, and zero-shot generalization, outperforming
previous state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive
evaluations across multiple datasets demonstrate that both LVSM variants
achieve state-of-the-art novel view synthesis quality. Notably, our models
surpass all previous methods even with reduced computational resources (1-2
GPUs). Please see our website for more details:
https://haian-jin.github.io/projects/LVSM/ .",2024-10-22,"Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi, Tianyuan Zhang, Fujun Luan, Noah Snavely, Zexiang Xu",http://arxiv.org/pdf/2410.17242v2,cs.LG
SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning,"Automated Machine Learning (AutoML) approaches encompass traditional methods
that optimize fixed pipelines for model selection and ensembling, as well as
newer LLM-based frameworks that autonomously build pipelines. While LLM-based
agents have shown promise in automating machine learning tasks, they often
generate low-diversity and suboptimal code, even after multiple iterations. To
overcome these limitations, we introduce Tree-Search Enhanced LLM Agents
(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search
(MCTS) to optimize the AutoML process. By representing pipeline configurations
as trees, our framework enables agents to conduct experiments intelligently and
iteratively refine their strategies, facilitating a more effective exploration
of the machine learning solution space. This novel approach allows SELA to
discover optimal pathways based on experimental feedback, improving the overall
quality of the solutions. In an extensive evaluation across 20 machine learning
datasets, we compare the performance of traditional and agent-based AutoML
methods, demonstrating that SELA achieves a win rate of 65% to 80% against each
baseline across all datasets. These results underscore the significant
potential of agent-based strategies in AutoML, offering a fresh perspective on
tackling complex machine learning challenges.",2024-10-22,"Yizhou Chi, Yizhang Lin, Sirui Hong, Duyi Pan, Yaying Fei, Guanghao Mei, Bangbang Liu, Tianqi Pang, Jacky Kwok, Ceyao Zhang, Bang Liu, Chenglin Wu",http://arxiv.org/pdf/2410.17238v1,cs.LG
Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy,"Large Language Models (LLMs) are known to hallucinate, whereby they generate
plausible but inaccurate text. This phenomenon poses significant risks in
critical applications, such as medicine or law, necessitating robust
hallucination mitigation strategies. While recent works have proposed
fine-tuning methods to teach LLMs to abstain from answering questions beyond
their knowledge or capabilities, these methods rely on the existence of
ground-truth labels or are limited to short-form responses. To address these
limitations, we propose fine-tuning using semantic entropy, an uncertainty
measure derived from introspection into the model which does not require
external labels. We demonstrate that our approach matches or outperforms models
fine-tuned using prior work and achieves strong performance for both short and
long-form generations on a range of datasets.",2024-10-22,"Benedict Aaron Tjandra, Muhammed Razzak, Jannik Kossen, Kunal Handa, Yarin Gal",http://arxiv.org/pdf/2410.17234v1,cs.LG
ICPL: Few-shot In-context Preference Learning via LLMs,"Preference-based reinforcement learning is an effective way to handle tasks
where rewards are hard to specify but can be exceedingly inefficient as
preference learning is often tabula rasa. We demonstrate that Large Language
Models (LLMs) have native preference-learning capabilities that allow them to
achieve sample-efficient preference learning, addressing this challenge. We
propose In-Context Preference Learning (ICPL), which uses in-context learning
capabilities of LLMs to reduce human query inefficiency. ICPL uses the task
description and basic environment code to create sets of reward functions which
are iteratively refined by placing human feedback over videos of the resultant
policies into the context of an LLM and then requesting better rewards. We
first demonstrate ICPL's effectiveness through a synthetic preference study,
providing quantitative evidence that it significantly outperforms baseline
preference-based methods with much higher performance and orders of magnitude
greater efficiency. We observe that these improvements are not solely coming
from LLM grounding in the task but that the quality of the rewards improves
over time, indicating preference learning capabilities. Additionally, we
perform a series of real human preference-learning trials and observe that ICPL
extends beyond synthetic settings and can work effectively with
humans-in-the-loop.",2024-10-22,"Chao Yu, Qixin Tan, Hong Lu, Jiaxuan Gao, Xinting Yang, Yu Wang, Yi Wu, Eugene Vinitsky",http://arxiv.org/pdf/2410.17233v3,cs.LG
Optimal Robust Estimation under Local and Global Corruptions: Stronger Adversary and Smaller Error,"Algorithmic robust statistics has traditionally focused on the contamination
model where a small fraction of the samples are arbitrarily corrupted. We
consider a recent contamination model that combines two kinds of corruptions:
(i) small fraction of arbitrary outliers, as in classical robust statistics,
and (ii) local perturbations, where samples may undergo bounded shifts on
average. While each noise model is well understood individually, the combined
contamination model poses new algorithmic challenges, with only partial results
known. Existing efficient algorithms are limited in two ways: (i) they work
only for a weak notion of local perturbations, and (ii) they obtain suboptimal
error for isotropic subgaussian distributions (among others). The latter
limitation led [NGS24, COLT'24] to hypothesize that improving the error might,
in fact, be computationally hard. Perhaps surprisingly, we show that
information theoretically optimal error can indeed be achieved in polynomial
time, under an even \emph{stronger} local perturbation model (the
sliced-Wasserstein metric as opposed to the Wasserstein metric). Notably, our
analysis reveals that the entire family of stability-based robust mean
estimators continues to work optimally in a black-box manner for the combined
contamination model. This generalization is particularly useful in real-world
scenarios where the specific form of data corruption is not known in advance.
We also present efficient algorithms for distribution learning and principal
component analysis in the combined contamination model.",2024-10-22,"Thanasis Pittas, Ankit Pensia",http://arxiv.org/pdf/2410.17230v1,cs.LG
Dhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing,"Climate change poses critical challenges globally, disproportionately
affecting low-income countries that often lack resources and linguistic
representation on the international stage. Despite Bangladesh's status as one
of the most vulnerable nations to climate impacts, research gaps persist in
Bengali-language studies related to climate change and NLP. To address this
disparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and
environmental news dataset, comprising a 2300 annotated Bangla news articles,
offering multiple perspectives such as political influence,
scientific/statistical data, authenticity, stance detection, and stakeholder
involvement. Furthermore, we present an in-depth exploratory analysis of
Dhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family
for climate and environmental opinion detection in Bangla, fine-tuned on our
dataset. This research contributes significantly to enhancing accessibility and
analysis of climate discourse in Bengali (Bangla), addressing crucial
communication and research gaps in climate-impacted regions like Bangladesh
with 180 million people.",2024-10-22,"Azmine Toushik Wasi, Wahid Faisal, Taj Ahmad, Abdur Rahman, Mst Rafia Islam",http://arxiv.org/pdf/2410.17225v2,cs.LG
Scalable spectral representations for multi-agent reinforcement learning in network MDPs,"Network Markov Decision Processes (MDPs), a popular model for multi-agent
control, pose a significant challenge to efficient learning due to the
exponential growth of the global state-action space with the number of agents.
In this work, utilizing the exponential decay property of network dynamics, we
first derive scalable spectral local representations for network MDPs, which
induces a network linear subspace for the local $Q$-function of each agent.
Building on these local spectral representations, we design a scalable
algorithmic framework for continuous state-action network MDPs, and provide
end-to-end guarantees for the convergence of our algorithm. Empirically, we
validate the effectiveness of our scalable representation-based approach on two
benchmark problems, and demonstrate the advantages of our approach over generic
function approximation approaches to representing the local $Q$-functions.",2024-10-22,"Zhaolin Ren, Runyu Zhang, Bo Dai, Na Li",http://arxiv.org/pdf/2410.17221v2,cs.LG
Hierarchical Upper Confidence Bounds for Constrained Online Learning,"The multi-armed bandit (MAB) problem is a foundational framework in
sequential decision-making under uncertainty, extensively studied for its
applications in areas such as clinical trials, online advertising, and resource
allocation. Traditional MAB formulations, however, do not adequately capture
scenarios where decisions are structured hierarchically, involve multi-level
constraints, or feature context-dependent action spaces. In this paper, we
introduce the hierarchical constrained bandits (HCB) framework, which extends
the contextual bandit problem to incorporate hierarchical decision structures
and multi-level constraints. We propose the hierarchical constrained upper
confidence bound (HC-UCB) algorithm, designed to address the complexities of
the HCB problem by leveraging confidence bounds within a hierarchical setting.
Our theoretical analysis establishes sublinear regret bounds for HC-UCB and
provides high-probability guarantees for constraint satisfaction at all
hierarchical levels. Furthermore, we derive a minimax lower bound on the regret
for the HCB problem, demonstrating the near-optimality of our algorithm. The
results are significant for real-world applications where decision-making
processes are inherently hierarchical and constrained, offering a robust and
efficient solution that balances exploration and exploitation across multiple
levels of decision-making.",2024-10-22,Ali Baheri,http://arxiv.org/pdf/2410.17216v2,cs.LG
Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio Trading,"Stock return forecasting is a major component of numerous finance
applications. Predicted stock returns can be incorporated into portfolio
trading algorithms to make informed buy or sell decisions which can optimize
returns. In such portfolio trading applications, the predictive performance of
a time series forecasting model is crucial. In this work, we propose the use of
the Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to
progressively evolve recurrent neural networks (RNNs) for stock return
predictions. RNNs are evolved independently for each stocks and portfolio
trading decisions are made based on the predicted stock returns. The portfolio
used for testing consists of the 30 companies in the Dow-Jones Index (DJI) with
each stock have the same weight. Results show that using these evolved RNNs and
a simple daily long-short strategy can generate higher returns than both the
DJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull
market).",2024-10-22,"Zimeng Lyu, Amulya Saxena, Rohaan Nadeem, Hao Zhang, Travis Desell",http://arxiv.org/pdf/2410.17212v1,cs.LG
Audio-to-Score Conversion Model Based on Whisper methodology,"This thesis develops a Transformer model based on Whisper, which extracts
melodies and chords from music audio and records them into ABC notation. A
comprehensive data processing workflow is customized for ABC notation,
including data cleansing, formatting, and conversion, and a mutation mechanism
is implemented to increase the diversity and quality of training data. This
thesis innovatively introduces the ""Orpheus' Score"", a custom notation system
that converts music information into tokens, designs a custom vocabulary
library, and trains a corresponding custom tokenizer. Experiments show that
compared to traditional algorithms, the model has significantly improved
accuracy and performance. While providing a convenient audio-to-score tool for
music enthusiasts, this work also provides new ideas and tools for research in
music information processing.",2024-10-22,"Hongyao Zhang, Bohang Sun",http://arxiv.org/pdf/2410.17209v1,cs.LG
Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing,"Knowledge Editing (KE) algorithms alter models' weights to perform targeted
updates to incorrect, outdated, or otherwise unwanted factual associations. To
better identify the possibilities and limitations of these approaches, recent
work has shown that applying KE can adversely affect models' factual recall
accuracy and diminish their general reasoning abilities. While these studies
give broad insights into the potential harms of KE algorithms, e.g., via
performance evaluations on benchmarks, we argue little is understood as to why
such destructive failures occur. Is it possible KE methods distort
representations of concepts beyond the targeted fact, hence hampering abilities
at broad? If so, what is the extent of this distortion? Motivated by such
questions, we define a novel synthetic task wherein a Transformer is trained
from scratch to internalize a ""structured"" knowledge graph. The structure
enforces relationships between entities of the graph, such that editing a
factual association has ""trickling effects"" on other entities in the graph
(e.g., altering X's parent is Y to Z affects who X's siblings' parent is).
Through evaluations of edited models and analysis of extracted representations,
we show that KE inadvertently affects representations of entities beyond the
targeted one, distorting relevant structures that allow a model to infer unseen
knowledge about an entity. We call this phenomenon representation shattering
and demonstrate that it results in degradation of factual recall and reasoning
performance more broadly. To corroborate our findings in a more naturalistic
setup, we perform preliminary experiments with pre-trained Llama and Mamba
models, reproducing the representation shattering effect therein as well.
Overall, our work yields a precise mechanistic hypothesis to explain why KE has
adverse effects on model abilities.",2024-10-22,"Kento Nishi, Maya Okawa, Rahul Ramesh, Mikail Khona, Hidenori Tanaka, Ekdeep Singh Lubana",http://arxiv.org/pdf/2410.17194v3,cs.LG
On Functional Dimension and Persistent Pseudodimension,"For any fixed feedforward ReLU neural network architecture, it is well-known
that many different parameter settings can determine the same function. It is
less well-known that the degree of this redundancy is inhomogeneous across
parameter space. In this work, we discuss two locally applicable complexity
measures for ReLU network classes and what we know about the relationship
between them: (1) the local functional dimension [14, 18], and (2) a local
version of VC dimension that we call persistent pseudodimension. The former is
easy to compute on finite batches of points; the latter should give local
bounds on the generalization gap, which would inform an understanding of the
mechanics of the double descent phenomenon [7].",2024-10-22,"J. Elisenda Grigsby, Kathryn Lindsey",http://arxiv.org/pdf/2410.17191v2,cs.LG
Remote Timing Attacks on Efficient Language Model Inference,"Scaling up language models has significantly increased their capabilities.
But larger models are slower models, and so there is now an extensive body of
work (e.g., speculative sampling or parallel decoding) that improves the
(average case) efficiency of language model generation. But these techniques
introduce data-dependent timing characteristics. We show it is possible to
exploit these timing differences to mount a timing attack. By monitoring the
(encrypted) network traffic between a victim user and a remote language model,
we can learn information about the content of messages by noting when responses
are faster or slower. With complete black-box access, on open source systems we
show how it is possible to learn the topic of a user's conversation (e.g.,
medical advice vs. coding assistance) with 90%+ precision, and on production
systems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish between
specific messages or infer the user's language. We further show that an active
adversary can leverage a boosting attack to recover PII placed in messages
(e.g., phone numbers or credit card numbers) for open source systems. We
conclude with potential defenses and directions for future work.",2024-10-22,"Nicholas Carlini, Milad Nasr",http://arxiv.org/pdf/2410.17175v1,cs.LG
Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence,"We propose a novel approach for learning interchangeable tokens in language
models to obtain an extendable vocabulary that can generalize to new tokens.
Our method addresses alpha-equivalence, the principle that renaming bound
variables preserves semantics. This property arises in many formal languages
such as temporal logics, where all proposition symbols represent the same
concept but remain distinct. To handle such tokens, we develop a dual-part
embedding approach. The first part is shared across all interchangeable tokens,
enforcing that they represent the same core concept. The second part is
randomly generated for each token, enabling distinguishability. As a baseline,
we consider a simpler approach that uses alpha-renaming for data augmentation.
We also present alpha-covariance, a metric for measuring robustness against
alpha-conversions. When evaluated in a Transformer encoder-decoder model for
solving linear temporal logic formulae and copying with extendable vocabulary,
our method demonstrates promising generalization capabilities as well as a
favorable inductive bias for alpha-equivalence.",2024-10-22,"İlker Işık, Ramazan Gokberk Cinbis, Ebru Aydin Gol",http://arxiv.org/pdf/2410.17161v2,cs.LG
LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting,"Forecasting models are pivotal in a data-driven world with vast volumes of
time series data that appear as a compound of vast Linear and Nonlinear
patterns. Recent deep time series forecasting models struggle to utilize
seasonal and trend decomposition to separate the entangled components. Such a
strategy only explicitly extracts simple linear patterns like trends, leaving
the other linear modes and vast unexplored nonlinear patterns to the residual.
Their flawed linear and nonlinear feature extraction models and shallow-level
decomposition limit their adaptation to the diverse patterns present in
real-world scenarios. Given this, we innovate Recursive Residual Decomposition
by introducing explicit extraction of both linear and nonlinear patterns. This
deeper-level decomposition framework, which is named LiNo, captures linear
patterns using a Li block which can be a moving average kernel, and models
nonlinear patterns using a No block which can be a Transformer encoder. The
extraction of these two patterns is performed alternatively and recursively. To
achieve the full potential of LiNo, we develop the current simple linear
pattern extractor to a general learnable autoregressive model, and design a
novel No block that can handle all essential nonlinear patterns. Remarkably,
the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks
under univariate and multivariate forecasting scenarios. Experiments show that
current forecasting models can deliver more robust and precise results through
this advanced Recursive Residual Decomposition. We hope this work could offer
insight into designing more effective forecasting models. Code is available at
this Repository: https://github.com/Levi-Ackman/LiNo.",2024-10-22,"Guoqi Yu, Yaoming Li, Xiaoyu Guo, Dayu Wang, Zirui Liu, Shujun Wang, Tong Yang",http://arxiv.org/pdf/2410.17159v4,cs.LG
Using Platt's scaling for calibration after undersampling -- limitations and how to address them,"When modelling data where the response is dichotomous and highly imbalanced,
response-based sampling where a subset of the majority class is retained (i.e.,
undersampling) is often used to create more balanced training datasets prior to
modelling. However, the models fit to this undersampled data, which we refer to
as base models, generate predictions that are severely biased. There are
several calibration methods that can be used to combat this bias, one of which
is Platt's scaling. Here, a logistic regression model is used to model the
relationship between the base model's original predictions and the response.
Despite its popularity for calibrating models after undersampling, Platt's
scaling was not designed for this purpose. Our work presents what we believe is
the first detailed study focused on the validity of using Platt's scaling to
calibrate models after undersampling. We show analytically, as well as via a
simulation study and a case study, that Platt's scaling should not be used for
calibration after undersampling without critical thought. If Platt's scaling
would have been able to successfully calibrate the base model had it been
trained on the entire dataset (i.e., without undersampling), then Platt's
scaling might be appropriate for calibration after undersampling. If this is
not the case, we recommend a modified version of Platt's scaling that fits a
logistic generalized additive model to the logit of the base model's
predictions, as it is both theoretically motivated and performed well across
the settings considered in our study.",2024-10-22,"Nathan Phelps, Daniel J. Lizotte, Douglas G. Woolford",http://arxiv.org/pdf/2410.18144v3,cs.LG
Covariance estimation using Markov chain Monte Carlo,"We investigate the complexity of covariance matrix estimation for Gibbs
distributions based on dependent samples from a Markov chain. We show that when
$\pi$ satisfies a Poincar\'e inequality and the chain possesses a spectral gap,
we can achieve similar sample complexity using MCMC as compared to an estimator
constructed using i.i.d. samples, with potentially much better query
complexity. As an application of our methods, we show improvements for the
query complexity in both constrained and unconstrained settings for concrete
instances of MCMC. In particular, we provide guarantees regarding isotropic
rounding procedures for sampling uniformly on convex bodies.",2024-10-22,"Yunbum Kook, Matthew S. Zhang",http://arxiv.org/pdf/2410.17147v1,cs.LG
LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging,"Fine-tuning pre-trained models has become the standard approach to endow them
with specialized knowledge, but it poses fundamental challenges. In particular,
\textit{(i)} fine-tuning often leads to catastrophic forgetting, where
improvements on a target domain degrade generalization on other tasks, and
\textit{(ii)} merging fine-tuned checkpoints from disparate tasks can lead to
significant performance loss. To address these challenges, we introduce LiNeS,
Layer-increasing Network Scaling, a post-training editing technique designed to
preserve pre-trained generalization while enhancing fine-tuned task
performance. LiNeS scales parameter updates linearly based on their layer depth
within the network, maintaining shallow layers close to their pre-trained
values to preserve general features while allowing deeper layers to retain
task-specific representations. In multi-task model merging scenarios,
layer-wise scaling of merged parameters reduces negative task interference.
LiNeS demonstrates significant improvements in both single-task and multi-task
settings across various benchmarks in vision and natural language processing.
It mitigates forgetting, enhances out-of-distribution generalization,
integrates seamlessly with existing multi-task model merging baselines
improving their performance across benchmarks and model sizes, and can boost
generalization when merging LLM policies aligned with different rewards via
RLHF. Our method is simple to implement, computationally efficient and
complementary to many existing techniques. Our source code is available at
https://github.com/wang-kee/LiNeS",2024-10-22,"Ke Wang, Nikolaos Dimitriadis, Alessandro Favero, Guillermo Ortiz-Jimenez, Francois Fleuret, Pascal Frossard",http://arxiv.org/pdf/2410.17146v2,cs.LG
Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?,"Large language models (LLMs) perform well on common tasks but struggle with
generalization in low-resource and low-computation settings. We examine this
limitation by testing various LLMs and specialized translation models on
English-Thai machine translation and code-switching datasets. Our findings
reveal that under more strict computational constraints, such as 4-bit
quantization, LLMs fail to translate effectively. In contrast, specialized
models, with comparable or lower computational requirements, consistently
outperform LLMs. This underscores the importance of specialized models for
maintaining performance under resource constraints.",2024-10-22,"Jirat Chiaranaipanich, Naiyarat Hanmatheekuna, Jitkapat Sawatphol, Krittamate Tiankanon, Jiramet Kinchagawat, Amrest Chinkamol, Parinthapat Pengpun, Piyalitt Ittichaiwong, Peerat Limkonchotiwat",http://arxiv.org/pdf/2410.17145v1,cs.LG
Coniferest: a complete active anomaly detection framework,"We present coniferest, an open source generic purpose active anomaly
detection framework written in Python. The package design and implemented
algorithms are described. Currently, static outlier detection analysis is
supported via the Isolation forest algorithm. Moreover, Active Anomaly
Discovery (AAD) and Pineforest algorithms are available to tackle active
anomaly detection problems. The algorithms and package performance are
evaluated on a series of synthetic datasets. We also describe a few success
cases which resulted from applying the package to real astronomical data in
active anomaly detection tasks within the SNAD project.",2024-10-22,"M. V. Kornilov, V. S. Korolev, K. L. Malanchev, A. D. Lavrukhina, E. Russeil, T. A. Semenikhin, E. Gangler, E. E. O. Ishida, M. V. Pruzhinskaya, A. A. Volnova, S. Sreejith",http://arxiv.org/pdf/2410.17142v2,cs.LG
Reinforcement Learning for Data-Driven Workflows in Radio Interferometry. I. Principal Demonstration in Calibration,"Radio interferometry is an observational technique used to study
astrophysical phenomena. Data gathered by an interferometer requires
substantial processing before astronomers can extract the scientific
information from it. Data processing consists of a sequence of calibration and
analysis procedures where choices must be made about the sequence of procedures
as well as the specific configuration of the procedure itself. These choices
are typically based on a combination of measurable data characteristics, an
understanding of the instrument itself, an appreciation of the trade-offs
between compute cost and accuracy, and a learned understanding of what is
considered ""best practice"". A metric of absolute correctness is not always
available and validity is often subject to human judgment. The underlying
principles and software configurations to discern a reasonable workflow for a
given dataset is the subject of training workshops for students and scientists.
Our goal is to use objective metrics that quantify best practice, and
numerically map out the decision space with respect to our metrics. With these
objective metrics we demonstrate an automated, data-driven, decision system
that is capable of sequencing the optimal action(s) for processing
interferometric data. This paper introduces a simplified description of the
principles behind interferometry and the procedures required for data
processing. We highlight the issues with current automation approaches and
propose our ideas for solving these bottlenecks. A prototype is demonstrated
and the results are discussed.",2024-10-22,"Brian M. Kirk, Urvashi Rau, Ramyaa Ramyaa",http://arxiv.org/pdf/2410.17135v1,cs.LG
Understanding Transfer Learning via Mean-field Analysis,"We propose a novel framework for exploring generalization errors of transfer
learning through the lens of differential calculus on the space of probability
measures. In particular, we consider two main transfer learning scenarios,
$\alpha$-ERM and fine-tuning with the KL-regularized empirical risk
minimization and establish generic conditions under which the generalization
error and the population risk convergence rates for these scenarios are
studied. Based on our theoretical results, we show the benefits of transfer
learning with a one-hidden-layer neural network in the mean-field regime under
some suitable integrability and regularity assumptions on the loss and
activation functions.",2024-10-22,"Gholamali Aminian, Łukasz Szpruch, Samuel N. Cohen",http://arxiv.org/pdf/2410.17128v2,cs.LG
Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards,"Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning
from Human Feedback to align large language models (LLMs) with downstream
tasks. This paper investigates the feasibility of using PPO for direct
reinforcement learning (RL) from explicitly programmed reward signals, as
opposed to indirect learning from human feedback via an intermediary reward
model. We focus on tasks expressed through formal languages, such as
mathematics and programming, where explicit reward functions can be programmed
to automatically assess the quality of generated outputs. We apply this
approach to a sentiment alignment task, a simple arithmetic task, and a more
complex game synthesis task. The sentiment alignment task replicates prior
research and serves to validate our experimental setup. Our results show that
pure RL-based training for the two formal language tasks is challenging, with
success being limited even for the simple arithmetic task. We propose a novel
batch-entropy regularization term to aid exploration, although training is not
yet entirely stable. Our findings suggest that direct RL training of LLMs may
be more suitable for relatively minor changes, such as alignment, than for
learning new tasks altogether, even if an informative reward signal can be
expressed programmatically.",2024-10-22,"Alexander G. Padula, Dennis J. N. J. Soemers",http://arxiv.org/pdf/2410.17126v1,cs.LG
On the analysis of saturated pressure to detect fatigue,"This paper examines the saturation of pressure signals during various
handwriting tasks, including drawings, cursive text, capital words text, and
signature, under different levels of fatigue. Experimental results demonstrate
a significant rise in the proportion of saturated samples following strenuous
exercise in tasks performed without resting wrist. The analysis of saturation
highlights significant differences when comparing the results to the baseline
situation and strenuous fatigue.",2024-10-22,"Marcos Faundez-Zanuy, Josep Lopez-Xarbau, Moises Diaz, Manuel Garnacho-Castaño",http://arxiv.org/pdf/2411.04128v1,cs.LG
Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks,"Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a
promising paradigm of heterogeneous network (HetNet), attributed to the
complementary physical properties of optical spectra and radio frequency.
However, the current development of such HetNets is mostly bottlenecked by the
existing transmission control protocol (TCP), which restricts the user
equipment (UE) to connecting one access point (AP) at a time. While the ongoing
investigation on multipath TCP (MPTCP) can bring significant benefits, it
complicates the network topology of HetNets, making the existing load balancing
(LB) learning models less effective. Driven by this, we propose a graph neural
network (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets,
which results in a partial mesh topology. Such a topology can be modeled as a
graph, with the channel state information and data rate requirement embedded as
node features, while the LB solutions are deemed as edge labels. Compared to
the conventional deep neural network (DNN), the proposed GNN-based model
exhibits two key strengths: i) it can better interpret a complex network
topology; and ii) it can handle various numbers of APs and UEs with a single
trained model. Simulation results show that against the traditional
optimisation method, the proposed learning model can achieve near-optimal
throughput within a gap of 11.5%, while reducing the inference time by 4 orders
of magnitude. In contrast to the DNN model, the new method can improve the
network throughput by up to 21.7%, at a similar inference time level.",2024-10-22,"Han Ji, Xiping Wu, Zhihong Zeng, Chen Chen",http://arxiv.org/pdf/2410.17118v1,cs.LG
Permutation Picture of Graph Combinatorial Optimization Problems,"This paper proposes a framework that formulates a wide range of graph
combinatorial optimization problems using permutation-based representations.
These problems include the travelling salesman problem, maximum independent
set, maximum cut, and various other related problems. This work potentially
opens up new avenues for algorithm design in neural combinatorial optimization,
bridging the gap between discrete and continuous optimization techniques.",2024-10-22,Yimeng Min,http://arxiv.org/pdf/2410.17111v1,cs.LG
Foundation Models for Rapid Autonomy Validation,"We are motivated by the problem of autonomous vehicle performance validation.
A key challenge is that an autonomous vehicle requires testing in every kind of
driving scenario it could encounter, including rare events, to provide a strong
case for safety and show there is no edge-case pathological behavior.
Autonomous vehicle companies rely on potentially millions of miles driven in
realistic simulation to expose the driving stack to enough miles to estimate
rates and severity of collisions. To address scalability and coverage, we
propose the use of a behavior foundation model, specifically a masked
autoencoder (MAE), trained to reconstruct driving scenarios. We leverage the
foundation model in two complementary ways: we (i) use the learned embedding
space to group qualitatively similar scenarios together and (ii) fine-tune the
model to label scenario difficulty based on the likelihood of a collision upon
re-simulation. We use the difficulty scoring as importance weighting for the
groups of scenarios. The result is an approach which can more rapidly estimate
the rates and severity of collisions by prioritizing hard scenarios while
ensuring exposure to every kind of driving scenario.",2024-10-22,"Alec Farid, Peter Schleede, Aaron Huang, Christoffer Heckman",http://arxiv.org/pdf/2411.03328v1,cs.LG
Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations,"The quality is a crucial issue for crowd annotations. Answer aggregation is
an important type of solution. The aggregated answers estimated from multiple
crowd answers to the same instance are the eventually collected annotations,
rather than the individual crowd answers themselves. Recently, the capability
of Large Language Models (LLMs) on data annotation tasks has attracted interest
from researchers. Most of the existing studies mainly focus on the average
performance of individual crowd workers; several recent works studied the
scenarios of aggregation on categorical labels and LLMs used as label creators.
However, the scenario of aggregation on text answers and the role of LLMs as
aggregators are not yet well-studied. In this paper, we investigate the
capability of LLMs as aggregators in the scenario of close-ended crowd text
answer aggregation. We propose a human-LLM hybrid text answer aggregation
method with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We
make the experiments based on public crowdsourcing datasets. The results show
the effectiveness of our approach based on the collaboration of crowd workers
and LLMs.",2024-10-22,Jiyi Li,http://arxiv.org/pdf/2410.17099v1,cs.LG
Exploration and Persuasion,"How to incentivize self-interested agents to explore when they prefer to
exploit? Consider a population of self-interested agents that make decisions
under uncertainty. They ""explore"" to acquire new information and ""exploit"" this
information to make good decisions. Collectively they need to balance these two
objectives, but their incentives are skewed toward exploitation. This is
because exploration is costly, but its benefits are spread over many agents in
the future.
  ""Incentivized Exploration"" addresses this issue via strategic communication.
Consider a benign ``principal"" which can communicate with the agents and make
recommendations, but cannot force the agents to comply. Moreover, suppose the
principal can observe the agents' decisions and the outcomes of these
decisions. The goal is to design a communication and recommendation policy
which (i) achieves a desirable balance between exploration and exploitation,
and (ii) incentivizes the agents to follow recommendations. What makes it
feasible is ""information asymmetry"": the principal knows more than any one
agent, as it collects information from many. It is essential that the principal
does not fully reveal all its knowledge to the agents.
  Incentivized exploration combines two important problems in, resp., machine
learning and theoretical economics. First, if agents always follow
recommendations, the principal faces a multi-armed bandit problem: essentially,
design an algorithm that balances exploration and exploitation. Second,
interaction with a single agent corresponds to ""Bayesian persuasion"", where a
principal leverages information asymmetry to convince an agent to take a
particular action. We provide a brief but self-contained introduction to each
problem through the lens of incentivized exploration, solving a key special
case of the former as a sub-problem of the latter.",2024-10-22,Aleksandrs Slivkins,http://arxiv.org/pdf/2410.17086v1,cs.LG
Combinatorial Logistic Bandits,"We introduce a novel framework called combinatorial logistic bandits (CLogB),
where in each round, a subset of base arms (called the super arm) is selected,
with the outcome of each base arm being binary and its expectation following a
logistic parametric model. The feedback is governed by a general arm triggering
process. Our study covers CLogB with reward functions satisfying two smoothness
conditions, capturing application scenarios such as online content delivery,
online learning to rank, and dynamic channel allocation. We first propose a
simple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic
exploration bonus. Under the 1-norm triggering probability modulated (TPM)
smoothness condition, CLogUCB achieves a regret bound of
$\tilde{O}(d\sqrt{\kappa KT})$, where $\tilde{O}$ ignores logarithmic factors,
$d$ is the dimension of the feature vector, $\kappa$ represents the
nonlinearity of the logistic model, and $K$ is the maximum number of base arms
a super arm can trigger. This result improves on prior work by a factor of
$\tilde{O}(\sqrt{\kappa})$. We then enhance CLogUCB with a variance-adaptive
version, VA-CLogUCB, which attains a regret bound of $\tilde{O}(d\sqrt{KT})$
under the same 1-norm TPM condition, improving another
$\tilde{O}(\sqrt{\kappa})$ factor. VA-CLogUCB shows even greater promise under
the stronger triggering probability and variance modulated (TPVM) condition,
achieving a leading $\tilde{O}(d\sqrt{T})$ regret, thus removing the additional
dependency on the action-size $K$. Furthermore, we enhance the computational
efficiency of VA-CLogUCB by eliminating the nonconvex optimization process when
the context feature map is time-invariant while maintaining the tight
$\tilde{O}(d\sqrt{T})$ regret. Finally, experiments on synthetic and real-world
datasets demonstrate the superior performance of our algorithms compared to
benchmark algorithms.",2024-10-22,"Xutong Liu, Xiangxiang Dai, Xuchuang Wang, Mohammad Hajiesmaili, John C. S. Lui",http://arxiv.org/pdf/2410.17075v3,cs.LG
Neuronal Competition Groups with Supervised STDP for Spike-Based Classification,"Spike Timing-Dependent Plasticity (STDP) is a promising substitute to
backpropagation for local training of Spiking Neural Networks (SNNs) on
neuromorphic hardware. STDP allows SNNs to address classification tasks by
combining unsupervised STDP for feature extraction and supervised STDP for
classification. Unsupervised STDP is usually employed with Winner-Takes-All
(WTA) competition to learn distinct patterns. However, WTA for supervised STDP
classification faces unbalanced competition challenges. In this paper, we
propose a method to effectively implement WTA competition in a spiking
classification layer employing first-spike coding and supervised STDP training.
We introduce the Neuronal Competition Group (NCG), an architecture that
improves classification capabilities by promoting the learning of various
patterns per class. An NCG is a group of neurons mapped to a specific class,
implementing intra-class WTA and a novel competition regulation mechanism based
on two-compartment thresholds. We incorporate our proposed architecture into
spiking classification layers trained with state-of-the-art supervised STDP
rules. On top of two different unsupervised feature extractors, we obtain
significant accuracy improvements on image recognition datasets such as
CIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is
crucial for ensuring balanced competition and improved class separation.",2024-10-22,"Gaspard Goupy, Pierre Tirilly, Ioan Marius Bilasco",http://arxiv.org/pdf/2410.17066v1,cs.LG
Optimal Design for Reward Modeling in RLHF,"Reinforcement Learning from Human Feedback (RLHF) has become a popular
approach to align language models (LMs) with human preferences. This method
involves collecting a large dataset of human pairwise preferences across
various text generations and using it to infer (implicitly or explicitly) a
reward model. Numerous methods have been proposed to learn the reward model and
align a LM with it. However, the costly process of collecting human preferences
has received little attention and could benefit from theoretical insights. This
paper addresses this issue and aims to formalize the reward training model in
RLHF. We frame the selection of an effective dataset as a simple regret
minimization task, using a linear contextual dueling bandit method. Given the
potentially large number of arms, this approach is more coherent than the
best-arm identification setting. We then propose an offline framework for
solving this problem. Under appropriate assumptions - linearity of the reward
model in the embedding space, and boundedness of the reward parameter - we
derive bounds on the simple regret. Finally, we provide a lower bound that
matches our upper bound up to constant and logarithmic terms. To our knowledge,
this is the first theoretical contribution in this area to provide an offline
approach as well as worst-case guarantees.",2024-10-22,"Antoine Scheid, Etienne Boursier, Alain Durmus, Michael I. Jordan, Pierre Ménard, Eric Moulines, Michal Valko",http://arxiv.org/pdf/2410.17055v2,cs.LG
UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs,"The key components of machine learning are data samples for training, model
for learning patterns, and loss function for optimizing accuracy. Analogously,
unlearning can potentially be achieved through anti-data samples (or
anti-samples), unlearning method, and reversed loss function. While prior
research has explored unlearning methods and reversed loss functions, the
potential of anti-samples remains largely untapped. In this paper, we introduce
UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language
models (LLMs). Our contributions are threefold; first, we propose a novel
concept of anti-sample-induced unlearning; second, we generate anti-samples by
leveraging misleading rationales, which help reverse learned associations and
accelerate the unlearning process; and third, we enable fine-grained targeted
unlearning, allowing for the selective removal of specific associations without
impacting related knowledge - something not achievable by previous works.
Results demonstrate that anti-samples offer an efficient, targeted unlearning
strategy for LLMs, opening new avenues for privacy-preserving machine learning
and model modification.",2024-10-22,"Yash Sinha, Murari Mandal, Mohan Kankanhalli",http://arxiv.org/pdf/2410.17050v1,cs.LG
A Comparison of Baseline Models and a Transformer Network for SOC Prediction in Lithium-Ion Batteries,"Accurately predicting the state of charge of Lithium-ion batteries is
essential to the performance of battery management systems of electric
vehicles. One of the main reasons for the slow global adoption of electric cars
is driving range anxiety. The ability of a battery management system to
accurately estimate the state of charge can help alleviate this problem. In
this paper, a comparison between data-driven state-of-charge estimation methods
is conducted. The paper compares different neural network-based models and
common regression models for SOC estimation. These models include several
ablated transformer networks, a neural network, a lasso regression model, a
linear regression model and a decision tree. Results of various experiments
conducted on data obtained from natural driving cycles of the BMW i3 battery
show that the decision tree outperformed all other models including the more
complex transformer network with self-attention and positional encoding.",2024-10-22,"Hadeel Aboueidah, Abdulrahman Altahhan",http://arxiv.org/pdf/2410.17049v1,cs.LG
Optimizing Mixture-of-Experts Inference Time Combining Model Deployment and Communication Scheduling,"As machine learning models scale in size and complexity, their computational
requirements become a significant barrier. Mixture-of-Experts (MoE) models
alleviate this issue by selectively activating relevant experts. Despite this,
MoE models are hindered by high communication overhead from all-to-all
operations, low GPU utilization due to the synchronous communication
constraint, and complications from heterogeneous GPU environments.
  This paper presents Aurora, which optimizes both model deployment and
all-to-all communication scheduling to address these challenges in MoE
inference. Aurora achieves minimal communication times by strategically
ordering token transmissions in all-to-all communications. It improves GPU
utilization by colocating experts from different models on the same device,
avoiding the limitations of synchronous all-to-all communication. We analyze
Aurora's optimization strategies theoretically across four common GPU cluster
settings: exclusive vs. colocated models on GPUs, and homogeneous vs.
heterogeneous GPUs. Aurora provides optimal solutions for three cases, and for
the remaining NP-hard scenario, it offers a polynomial-time sub-optimal
solution with only a 1.07x degradation from the optimal.
  Aurora is the first approach to minimize MoE inference time via optimal model
deployment and communication scheduling across various scenarios. Evaluations
demonstrate that Aurora significantly accelerates inference, achieving speedups
of up to 2.38x in homogeneous clusters and 3.54x in heterogeneous environments.
Moreover, Aurora enhances GPU utilization by up to 1.5x compared to existing
methods.",2024-10-22,"Jialong Li, Shreyansh Tripathi, Lakshay Rastogi, Yiming Lei, Rui Pan, Yiting Xia",http://arxiv.org/pdf/2410.17043v1,cs.LG
Prototype-Based Methods in Explainable AI and Emerging Opportunities in the Geosciences,"Prototype-based methods are intrinsically interpretable XAI methods that
produce predictions and explanations by comparing input data with a set of
learned prototypical examples that are representative of the training data. In
this work, we discuss a series of developments in the field of prototype-based
XAI that show potential for scientific learning tasks, with a focus on the
geosciences. We organize the prototype-based XAI literature into three themes:
the development and visualization of prototypes, types of prototypes, and the
use of prototypes in various learning tasks. We discuss how the authors use
prototype-based methods, their novel contributions, and any limitations or
challenges that may arise when adapting these methods for geoscientific
learning tasks. We highlight differences between geoscientific data sets and
the standard benchmarks used to develop XAI methods, and discuss how specific
geoscientific applications may benefit from using or modifying existing
prototype-based XAI techniques.",2024-10-22,"Anushka Narayanan, Karianne J. Bergen",http://arxiv.org/pdf/2410.19856v1,cs.LG
Deep Memory Search: A Metaheuristic Approach for Optimizing Heuristic Search,"Metaheuristic search methods have proven to be essential tools for tackling
complex optimization challenges, but their full potential is often constrained
by conventional algorithmic frameworks. In this paper, we introduce a novel
approach called Deep Heuristic Search (DHS), which models metaheuristic search
as a memory-driven process. DHS employs multiple search layers and memory-based
exploration-exploitation mechanisms to navigate large, dynamic search spaces.
By utilizing model-free memory representations, DHS enhances the ability to
traverse temporal trajectories without relying on probabilistic transition
models. The proposed method demonstrates significant improvements in search
efficiency and performance across a range of heuristic optimization problems.",2024-10-22,"Abdel-Rahman Hedar, Alaa E. Abdel-Hakim, Wael Deabes, Youseef Alotaibi, Kheir Eddine Bouazza",http://arxiv.org/pdf/2410.17042v1,cs.LG
"Personalized Recommendation Systems using Multimodal, Autonomous, Multi Agent Systems","This paper describes a highly developed personalised recommendation system
using multimodal, autonomous, multi-agent systems. The system focuses on the
incorporation of futuristic AI tech and LLMs like Gemini-1.5- pro and LLaMA-70B
to improve customer service experiences especially within e-commerce. Our
approach uses multi agent, multimodal systems to provide best possible
recommendations to its users. The system is made up of three agents as a whole.
The first agent recommends products appropriate for answering the given
question, while the second asks follow-up questions based on images that belong
to these recommended products and is followed up with an autonomous search by
the third agent. It also features a real-time data fetch, user
preferences-based recommendations and is adaptive learning. During complicated
queries the application processes with Symphony, and uses the Groq API to
answer quickly with low response times. It uses a multimodal way to utilize
text and images comprehensively, so as to optimize product recommendation and
customer interaction.",2024-10-22,"Param Thakkar, Anushka Yadav",http://arxiv.org/pdf/2410.19855v1,cs.LG
Dynamic User Grouping based on Location and Heading in 5G NR Systems,"User grouping based on geographic location in fifth generation (5G) New Radio
(NR) systems has several applications that can significantly improve network
performance, user experience, and service delivery. We demonstrate how Sounding
Reference Signals channel fingerprints can be used for dynamic user grouping in
a 5G NR commercial deployment based on outdoor positions and heading direction
employing machine learning methods such as neural networks combined with
clustering methods.",2024-10-22,"Dino Pjanić, Korkut Emre Arslantürk, Xuesong Cai, Fredrik Tufvesson",http://arxiv.org/pdf/2410.19854v1,cs.LG
Can a Machine Distinguish High and Low Amount of Social Creak in Speech?,"Objectives: ncreased prevalence of social creak particularly among female
speakers has been reported in several studies. The study of social creak has
been previously conducted by combining perceptual evaluation of speech with
conventional acoustical parameters such as the harmonic-to-noise ratio and
cepstral peak prominence. In the current study, machine learning (ML) was used
to automatically distinguish speech of low amount of social creak from speech
of high amount of social creak.
  Methods: The amount of creak in continuous speech samples produced in Finnish
by 90 female speakers was first perceptually assessed by two voice specialists.
Based on their assessments, the speech samples were divided into two categories
(low $vs$. high amount of creak). Using the speech signals and their creak
labels, seven different ML models were trained. Three spectral representations
were used as feature for each model.
  Results: The results show that the best performance (accuracy of 71.1\%) was
obtained by the following two systems: an Adaboost classifier using the
mel-spectrogram feature and a decision tree classifier using the mel-frequency
cepstral coefficient feature.
  Conclusions: The study of social creak is becoming increasingly popular in
sociolinguistic and vocological research. The conventional human perceptual
assessment of the amount of creak is laborious and therefore ML technology
could be used to assist researchers studying social creak. The classification
systems reported in this study could be considered as baselines in future
ML-based studies on social creak.",2024-10-22,"Anne-Maria Laukkanen, Sudarsana Reddy Kadiri, Shrikanth Narayanan, Paavo Alku",http://arxiv.org/pdf/2410.17028v1,cs.LG
LFME: A Simple Framework for Learning from Multiple Experts in Domain Generalization,"Domain generalization (DG) methods aim to maintain good performance in an
unseen target domain by using training data from multiple source domains. While
success on certain occasions are observed, enhancing the baseline across most
scenarios remains challenging. This work introduces a simple yet effective
framework, dubbed learning from multiple experts (LFME), that aims to make the
target model an expert in all source domains to improve DG. Specifically,
besides learning the target model used in inference, LFME will also train
multiple experts specialized in different domains, whose output probabilities
provide professional guidance by simply regularizing the logit of the target
model. Delving deep into the framework, we reveal that the introduced logit
regularization term implicitly provides effects of enabling the target model to
harness more information, and mining hard samples from the experts during
training. Extensive experiments on benchmarks from different DG tasks
demonstrate that LFME is consistently beneficial to the baseline and can
achieve comparable performance to existing arts. Code is available
at~\url{https://github.com/liangchen527/LFME}.",2024-10-22,"Liang Chen, Yong Zhang, Yibing Song, Zhiqiang Shen, Lingqiao Liu",http://arxiv.org/pdf/2410.17020v2,cs.LG
Sample-Efficient Geometry Reconstruction from Euclidean Distances using Non-Convex Optimization,"The problem of finding suitable point embedding or geometric configurations
given only Euclidean distance information of point pairs arises both as a core
task and as a sub-problem in a variety of machine learning applications. In
this paper, we aim to solve this problem given a minimal number of distance
samples. To this end, we leverage continuous and non-convex rank minimization
formulations of the problem and establish a local convergence guarantee for a
variant of iteratively reweighted least squares (IRLS), which applies if a
minimal random set of observed distances is provided. As a technical tool, we
establish a restricted isometry property (RIP) restricted to a tangent space of
the manifold of symmetric rank-$r$ matrices given random Euclidean distance
measurements, which might be of independent interest for the analysis of other
non-convex approaches. Furthermore, we assess data efficiency, scalability and
generalizability of different reconstruction algorithms through numerical
experiments with simulated data as well as real-world data, demonstrating the
proposed algorithm's ability to identify the underlying geometry from fewer
distance samples compared to the state-of-the-art.",2024-10-22,"Ipsita Ghosh, Abiy Tasissa, Christian Kümmerle",http://arxiv.org/pdf/2410.16982v1,cs.LG
Publishing Neural Networks in Drug Discovery Might Compromise Training Data Privacy,"This study investigates the risks of exposing confidential chemical
structures when machine learning models trained on these structures are made
publicly available. We use membership inference attacks, a common method to
assess privacy that is largely unexplored in the context of drug discovery, to
examine neural networks for molecular property prediction in a black-box
setting. Our results reveal significant privacy risks across all evaluated
datasets and neural network architectures. Combining multiple attacks increases
these risks. Molecules from minority classes, often the most valuable in drug
discovery, are particularly vulnerable. We also found that representing
molecules as graphs and using message-passing neural networks may mitigate
these risks. We provide a framework to assess privacy risks of classification
models and molecular representations. Our findings highlight the need for
careful consideration when sharing neural networks trained on proprietary
chemical structures, informing organisations and researchers about the
trade-offs between data confidentiality and model openness.",2024-10-22,"Fabian P. Krüger, Johan Östman, Lewis Mervin, Igor V. Tetko, Ola Engkvist",http://arxiv.org/pdf/2410.16975v1,cs.LG
Learning Mathematical Rules with Large Language Models,"In this paper, we study the ability of large language models to learn
specific mathematical rules such as distributivity or simplifying equations. We
present an empirical analysis of their ability to generalize these rules, as
well as to reuse them in the context of word problems. For this purpose, we
provide a rigorous methodology to build synthetic data incorporating such
rules, and perform fine-tuning of large language models on such data. Our
experiments show that our model can learn and generalize these rules to some
extent, as well as suitably reuse them in the context of word problems.",2024-10-22,"Antoine Gorceix, Bastien Le Chenadec, Ahmad Rammal, Nelson Vadori, Manuela Veloso",http://arxiv.org/pdf/2410.16973v3,cs.LG
Sample-efficient Bayesian Optimisation Using Known Invariances,"Bayesian optimisation (BO) is a powerful framework for global optimisation of
costly functions, using predictions from Gaussian process models (GPs). In this
work, we apply BO to functions that exhibit invariance to a known group of
transformations. We show that vanilla and constrained BO algorithms are
inefficient when optimising such invariant objectives, and provide a method for
incorporating group invariances into the kernel of the GP to produce
invariance-aware algorithms that achieve significant improvements in sample
efficiency. We derive a bound on the maximum information gain of these
invariant kernels, and provide novel upper and lower bounds on the number of
observations required for invariance-aware BO algorithms to achieve
$\epsilon$-optimality. We demonstrate our method's improved performance on a
range of synthetic invariant and quasi-invariant functions. We also apply our
method in the case where only some of the invariance is incorporated into the
kernel, and find that these kernels achieve similar gains in sample efficiency
at significantly reduced computational cost. Finally, we use invariant BO to
design a current drive system for a nuclear fusion reactor, finding a
high-performance solution where non-invariant methods failed.",2024-10-22,"Theodore Brown, Alexandru Cioba, Ilija Bogunovic",http://arxiv.org/pdf/2410.16972v1,cs.LG
ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial Information in Medical Images,"This paper demonstrates that spatial information can be used to learn
interpretable representations in medical images using Self-Supervised Learning
(SSL). Our proposed method, ISImed, is based on the observation that medical
images exhibit a much lower variability among different images compared to
classic data vision benchmarks. By leveraging this resemblance of human body
structures across multiple images, we establish a self-supervised objective
that creates a latent representation capable of capturing its location in the
physical realm. More specifically, our method involves sampling image crops and
creating a distance matrix that compares the learned representation vectors of
all possible combinations of these crops to the true distance between them. The
intuition is, that the learned latent space is a positional encoding for a
given image crop. We hypothesize, that by learning these positional encodings,
comprehensive image representations have to be generated. To test this
hypothesis and evaluate our method, we compare our learned representation with
two state-of-the-art SSL benchmarking methods on two publicly available medical
imaging datasets. We show that our method can efficiently learn representations
that capture the underlying structure of the data and can be used to transfer
to a downstream classification task.",2024-10-22,"Nabil Jabareen, Dongsheng Yuan, Sören Lukassen",http://arxiv.org/pdf/2410.16947v1,cs.LG
Business Process Simulation: Probabilistic Modeling of Intermittent Resource Availability and Multitasking Behavior,"In business process simulation, resource availability is typically modeled by
assigning a calendar to each resource, e.g., Monday-Friday, 9:00-18:00.
Resources are assumed to be always available during each time slot in their
availability calendar. This assumption often becomes invalid due to
interruptions, breaks, or time-sharing across processes. In other words,
existing approaches fail to capture intermittent availability. Another
limitation of existing approaches is that they either do not consider
multitasking behavior, or if they do, they assume that resources always
multitask (up to a maximum capacity) whenever available. However, studies have
shown that the multitasking patterns vary across days. This paper introduces a
probabilistic approach to model resource availability and multitasking behavior
for business process simulation. In this approach, each time slot in a resource
calendar has an associated availability probability and a multitasking
probability per multitasking level. For example, a resource may be available on
Fridays between 14:00-15:00 with 90\% probability, and given that they are
performing one task during this slot, they may take on a second concurrent task
with 60\% probability. We propose algorithms to discover probabilistic
calendars and probabilistic multitasking capacities from event logs. An
evaluation shows that, with these enhancements, simulation models discovered
from event logs better replicate the distribution of activities and cycle
times, relative to approaches with crisp calendars and monotasking assumptions.",2024-10-22,"Orlenys López-Pintado, Marlon Dumas",http://arxiv.org/pdf/2410.16941v1,cs.LG
Graph Neural Networks for Edge Signals: Orientation Equivariance and Invariance,"Many applications in traffic, civil engineering, or electrical engineering
revolve around edge-level signals. Such signals can be categorized as
inherently directed, for example, the water flow in a pipe network, and
undirected, like the diameter of a pipe. Topological methods model edge signals
with inherent direction by representing them relative to a so-called
orientation assigned to each edge. These approaches can neither model
undirected edge signals nor distinguish if an edge itself is directed or
undirected. We address these shortcomings by (i) revising the notion of
orientation equivariance to enable edge direction-aware topological models,
(ii) proposing orientation invariance as an additional requirement to describe
signals without inherent direction, and (iii) developing EIGN, an architecture
composed of novel direction-aware edge-level graph shift operators, that
provably fulfills the aforementioned desiderata. It is the first
general-purpose topological GNN for edge-level signals that can model directed
and undirected signals while distinguishing between directed and undirected
edges. A comprehensive evaluation shows that EIGN outperforms prior work in
edge-level tasks, for example, improving in RMSE on flow simulation tasks by up
to 23.5%.",2024-10-22,"Dominik Fuchsgruber, Tim Poštuvan, Stephan Günnemann, Simon Geisler",http://arxiv.org/pdf/2410.16935v2,cs.LG
xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar Memories,"Time series data is prevalent across numerous fields, necessitating the
development of robust and accurate forecasting models. Capturing patterns both
within and between temporal and multivariate components is crucial for reliable
predictions. We introduce xLSTM-Mixer, a model designed to effectively
integrate temporal sequences, joint time-variate information, and multiple
perspectives for robust forecasting. Our approach begins with a linear forecast
shared across variates, which is then refined by xLSTM blocks. These blocks
serve as key elements for modeling the complex dynamics of challenging time
series data. xLSTM-Mixer ultimately reconciles two distinct views to produce
the final forecast. Our extensive evaluations demonstrate xLSTM-Mixer's
superior long-term forecasting performance compared to recent state-of-the-art
methods. A thorough model analysis provides further insights into its key
components and confirms its robustness and effectiveness. This work contributes
to the resurgence of recurrent models in time series forecasting.",2024-10-22,"Maurice Kraus, Felix Divo, Devendra Singh Dhami, Kristian Kersting",http://arxiv.org/pdf/2410.16928v2,cs.LG
Pyramid Vector Quantization for LLMs,"Recent works on compression of large language models (LLM) using quantization
considered reparameterizing the architecture such that weights are distributed
on the sphere. This demonstratively improves the ability to quantize by
increasing the mathematical notion of coherence, resulting in fewer weight
outliers without affecting the network output. In this work, we aim to further
exploit this spherical geometry of the weights when performing quantization by
considering Pyramid Vector Quantization (PVQ) for large language models.
Arranging points evenly on the sphere is notoriously difficult, especially in
high dimensions, and in case approximate solutions exists, representing points
explicitly in a codebook is typically not feasible due to its additional memory
cost. Instead, PVQ uses a fixed integer lattice on the sphere by projecting
points onto the 1-sphere, which allows for efficient encoding and decoding
without requiring an explicit codebook in memory. To obtain a practical
algorithm, we propose to combine PVQ with scale quantization for which we
derive theoretically optimal quantizations, under empirically verified
assumptions. Further, we extend pyramid vector quantization to use Hessian
information to minimize quantization error under expected feature activations,
instead of only relying on weight magnitudes. Experimentally, we achieves
state-of-the-art quantization performance with pareto-optimal trade-off between
performance and bits per weight and bits per activation, compared to compared
methods. On weight-only, we find that we can quantize a Llama-3 70B model to
3.25 bits per weight and retain 98\% accuracy on downstream tasks.",2024-10-22,"Tycho F. A. van der Ouderaa, Maximilian L. Croci, Agrin Hilmkil, James Hensman",http://arxiv.org/pdf/2410.16926v2,cs.LG
EnvBridge: Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI,"In recent years, Large Language Models (LLMs) have demonstrated high
reasoning capabilities, drawing attention for their applications as agents in
various decision-making processes. One notably promising application of LLM
agents is robotic manipulation. Recent research has shown that LLMs can
generate text planning or control code for robots, providing substantial
flexibility and interaction capabilities. However, these methods still face
challenges in terms of flexibility and applicability across different
environments, limiting their ability to adapt autonomously. Current approaches
typically fall into two categories: those relying on environment-specific
policy training, which restricts their transferability, and those generating
code actions based on fixed prompts, which leads to diminished performance when
confronted with new environments. These limitations significantly constrain the
generalizability of agents in robotic manipulation. To address these
limitations, we propose a novel method called EnvBridge. This approach involves
the retention and transfer of successful robot control codes from source
environments to target environments. EnvBridge enhances the agent's
adaptability and performance across diverse settings by leveraging insights
from multiple environments. Notably, our approach alleviates environmental
constraints, offering a more flexible and generalizable solution for robotic
manipulation tasks. We validated the effectiveness of our method using robotic
manipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments
demonstrate that LLM agents can successfully leverage diverse knowledge sources
to solve complex tasks. Consequently, our approach significantly enhances the
adaptability and robustness of robotic manipulation agents in planning across
diverse environments.",2024-10-22,"Tomoyuki Kagaya, Yuxuan Lou, Thong Jing Yuan, Subramanian Lakshmi, Jayashree Karlekar, Sugiri Pranata, Natsuki Murakami, Akira Kinose, Koki Oguri, Felix Wick, Yang You",http://arxiv.org/pdf/2410.16919v1,cs.LG
DNAHLM -- DNA sequence and Human Language mixed large language Model,"There are already many DNA large language models, but most of them still
follow traditional uses, such as extracting sequence features for
classification tasks. More innovative applications of large language models,
such as prompt engineering, RAG, and zero-shot or few-shot prediction, remain
challenging for DNA-based models. The key issue lies in the fact that DNA
models and human natural language models are entirely separate; however,
techniques like prompt engineering require the use of natural language, thereby
significantly limiting the application of DNA large language models. This paper
introduces a pre-trained model trained on the GPT-2 network, combining DNA
sequences and English text, and uses a unified BPE tokenization method. We then
convert classification and other downstream tasks into Alpaca format
instruction data, and perform instruction fine-tuning on this pre-trained model
to create a fine-tuned model capable of handling multiple tasks. The model has
demonstrated its effectiveness in DNA related zero-shot prediction and
multitask application. This research provides a highly promising direction for
building a unified DNA sequence task framework.",2024-10-22,Wang Liang,http://arxiv.org/pdf/2410.16917v2,cs.LG
Tethering Broken Themes: Aligning Neural Topic Models with Labels and Authors,"Topic models are a popular approach for extracting semantic information from
large document collections. However, recent studies suggest that the topics
generated by these models often do not align well with human intentions.
Although metadata such as labels and authorship information are available, it
has not yet been effectively incorporated into neural topic models. To address
this gap, we introduce FANToM, a novel method to align neural topic models with
both labels and authorship information. FANToM allows for the inclusion of this
metadata when available, producing interpretable topics and author
distributions for each topic. Our approach demonstrates greater expressiveness
than conventional topic models by learning the alignment between labels,
topics, and authors. Experimental results show that FANToM improves existing
models in terms of both topic quality and alignment. Additionally, it
identifies author interests and similarities.",2024-10-22,"Mayank Nagda, Phil Ostheimer, Sophie Fellenz",http://arxiv.org/pdf/2410.18140v2,cs.LG
Bayes without Underfitting: Fully Correlated Deep Learning Posteriors via Alternating Projections,"Bayesian deep learning all too often underfits so that the Bayesian
prediction is less accurate than a simple point estimate. Uncertainty
quantification then comes at the cost of accuracy. For linearized models, the
null space of the generalized Gauss-Newton matrix corresponds to parameters
that preserve the training predictions of the point estimate. We propose to
build Bayesian approximations in this null space, thereby guaranteeing that the
Bayesian predictive does not underfit. We suggest a matrix-free algorithm for
projecting onto this null space, which scales linearly with the number of
parameters and quadratically with the number of output dimensions. We further
propose an approximation that only scales linearly with parameters to make the
method applicable to generative models. An extensive empirical evaluation shows
that the approach scales to large models, including vision transformers with 28
million parameters.",2024-10-22,"Marco Miani, Hrittik Roy, Søren Hauberg",http://arxiv.org/pdf/2410.16901v1,cs.LG
MBD: Multi b-value Denoising of Diffusion Magnetic Resonance Images,"We propose a novel approach to denoising diffusion magnetic resonance images
(dMRI) using convolutional neural networks, that exploits the benefits of data
acquired at multiple b-values to offset the need for many redundant
observations. Denoising is especially relevant in dMRI since noise can have a
deleterious impact on both quantification accuracy and image preprocessing. The
most successful methods proposed to date, like Marchenko-Pastur Principal
Component Analysis (MPPCA) denoising, are tailored to diffusion-weighting
repeated for many encoding directions. They exploit high redundancy of the
dataset that oversamples the diffusion-encoding direction space, since many
directions have collinear components.
  However, there are many dMRI techniques that do not entail a large number of
encoding directions or repetitions, and are therefore less suited to this
approach. For example, clinical dMRI exams may include as few as three encoding
directions, with low or negligible data redundancy across directions. Moreover,
promising new dMRI approaches, like spherical b-tensor encoding (STE), benefit
from high b-values while sensitizing the signal to diffusion along all
directions in just a single shot.
  We introduce a convolutional neural network approach that we call
multi-b-value-based denoising (MBD). MBD exploits the similarity in
diffusion-weighted images (DWI) across different b-values but along the same
diffusion encoding direction. It allows denoising of diffusion images with high
noise variance while avoiding blurring, and using just a small number input
images.",2024-10-22,"Jakub Jurek, Andrzej Materka, Kamil Ludwisiak, Agata Majos, Filip Szczepankiewicz",http://arxiv.org/pdf/2410.16898v1,cs.LG
Global Optimization of Gaussian Process Acquisition Functions Using a Piecewise-Linear Kernel Approximation,"Bayesian optimization relies on iteratively constructing and optimizing an
acquisition function. The latter turns out to be a challenging, non-convex
optimization problem itself. Despite the relative importance of this step, most
algorithms employ sampling- or gradient-based methods, which do not provably
converge to global optima. This work investigates mixed-integer programming
(MIP) as a paradigm for \textit{global} acquisition function optimization.
Specifically, our Piecewise-linear Kernel Mixed Integer Quadratic Programming
(PK-MIQP) formulation introduces a piecewise-linear approximation for Gaussian
process kernels and admits a corresponding MIQP representation for acquisition
functions. We analyze the theoretical regret bounds of the proposed
approximation, and empirically demonstrate the framework on synthetic
functions, constrained benchmarks, and a hyperparameter tuning task.",2024-10-22,"Yilin Xie, Shiqiang Zhang, Joel Paulson, Calvin Tsay",http://arxiv.org/pdf/2410.16893v1,cs.LG
Unsupervised Time Series Anomaly Prediction with Importance-based Generative Contrastive Learning,"Time series anomaly prediction plays an essential role in many real-world
scenarios, such as environmental prevention and prompt maintenance of
cyber-physical systems. However, existing time series anomaly prediction
methods mainly require supervised training with plenty of manually labeled
data, which are difficult to obtain in practice. Besides, unseen anomalies can
occur during inference, which could differ from the labeled training data and
make these models fail to predict such new anomalies. In this paper, we study a
novel problem of unsupervised time series anomaly prediction. We provide a
theoretical analysis and propose Importance-based Generative Contrastive
Learning (IGCL) to address the aforementioned problems. IGCL distinguishes
between normal and anomaly precursors, which are generated by our anomaly
precursor pattern generation module. To address the efficiency issues caused by
the potential complex anomaly precursor combinations, we propose a memory bank
with importance-based scores to adaptively store representative anomaly
precursors and generate more complicated anomaly precursors. Extensive
experiments on seven benchmark datasets show our method outperforms
state-of-the-art baselines on unsupervised time series anomaly prediction
problems.",2024-10-22,"Kai Zhao, Zhihao Zhuang, Chenjuan Guo, Hao Miao, Yunyao Cheng, Bin Yang",http://arxiv.org/pdf/2410.16888v2,cs.LG
SaVe-TAG: Semantic-aware Vicinal Risk Minimization for Long-Tailed Text-Attributed Graphs,"Real-world graph data often follows long-tailed distributions, making it
difficult for Graph Neural Networks (GNNs) to generalize well across both head
and tail classes. Recent advances in Vicinal Risk Minimization (VRM) have shown
promise in mitigating class imbalance with numeric interpolation; however,
existing approaches largely rely on embedding-space arithmetic, which fails to
capture the rich semantics inherent in text-attributed graphs. In this work, we
propose our method, SaVe-TAG (Semantic-aware Vicinal Risk Minimization for
Long-Tailed Text-Attributed Graphs), a novel VRM framework that leverages Large
Language Models (LLMs) to perform text-level interpolation, generating
on-manifold, boundary-enriching synthetic samples for minority classes. To
mitigate the risk of noisy generation, we introduce a confidence-based edge
assignment mechanism that uses graph topology as a natural filter to ensure
structural consistency. We provide theoretical justification for our method and
conduct extensive experiments on benchmark datasets, showing that our approach
consistently outperforms both numeric interpolation and prior long-tailed node
classification baselines. Our results highlight the importance of integrating
semantic and structural signals for balanced and effective learning on
text-attributed graphs.",2024-10-22,"Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Hanyu Wang, Yao Ma, Tyler Derr",http://arxiv.org/pdf/2410.16882v3,cs.LG
Just In Time Transformers,"Precise energy load forecasting in residential households is crucial for
mitigating carbon emissions and enhancing energy efficiency; indeed, accurate
forecasting enables utility companies and policymakers, who advocate
sustainable energy practices, to optimize resource utilization. Moreover, smart
meters provide valuable information by allowing for granular insights into
consumption patterns. Building upon available smart meter data, our study aims
to cluster consumers into distinct groups according to their energy usage
behaviours, effectively capturing a diverse spectrum of consumption patterns.
Next, we design JITtrans (Just In Time transformer), a novel transformer deep
learning model that significantly improves energy consumption forecasting
accuracy, with respect to traditional forecasting methods. Extensive
experimental results validate our claims using proprietary smart meter data.
Our findings highlight the potential of advanced predictive technologies to
revolutionize energy management and advance sustainable power systems: the
development of efficient and eco-friendly energy solutions critically depends
on such technologies.",2024-10-22,"Ahmed Ala Eddine Benali, Massimo Cafaro, Italo Epicoco, Marco Pulimeno, Enrico Junior Schioppa",http://arxiv.org/pdf/2410.16881v2,cs.LG
Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study,"Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.",2024-10-22,"Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay",http://arxiv.org/pdf/2410.16879v1,cs.LG
CK4Gen: A Knowledge Distillation Framework for Generating High-Utility Synthetic Survival Datasets in Healthcare,"Access to real clinical data is heavily restricted by privacy regulations,
hindering both healthcare research and education. These constraints slow
progress in developing new treatments and data-driven healthcare solutions,
while also limiting students' access to real-world datasets, leaving them
without essential practical skills. High-utility synthetic datasets are
therefore critical for advancing research and providing meaningful training
material. However, current generative models -- such as Variational
Autoencoders (VAEs) and Generative Adversarial Networks (GANs) -- produce
surface-level realism at the expense of healthcare utility, blending distinct
patient profiles and producing synthetic data of limited practical relevance.
To overcome these limitations, we introduce CK4Gen (Cox Knowledge for
Generation), a novel framework that leverages knowledge distillation from Cox
Proportional Hazards (CoxPH) models to create synthetic survival datasets that
preserve key clinical characteristics, including hazard ratios and survival
curves. CK4Gen avoids the interpolation issues seen in VAEs and GANs by
maintaining distinct patient risk profiles, ensuring realistic and reliable
outputs for research and educational use. Validated across four benchmark
datasets -- GBSG2, ACTG320, WHAS500, and FLChain -- CK4Gen outperforms
competing techniques by better aligning real and synthetic data, enhancing
survival model performance in both discrimination and calibration via data
augmentation. As CK4Gen is scalable across clinical conditions, and with code
to be made publicly available, future researchers can apply it to their own
datasets to generate synthetic versions suitable for open sharing.",2024-10-22,"Nicholas I-Hsien Kuo, Blanca Gallego, Louisa Jorm",http://arxiv.org/pdf/2410.16872v1,cs.LG
"Error Feedback under $(L_0,L_1)$-Smoothness: Normalization and Momentum","We provide the first proof of convergence for normalized error feedback
algorithms across a wide range of machine learning problems. Despite their
popularity and efficiency in training deep neural networks, traditional
analyses of error feedback algorithms rely on the smoothness assumption that
does not capture the properties of objective functions in these problems.
Rather, these problems have recently been shown to satisfy generalized
smoothness assumptions, and the theoretical understanding of error feedback
algorithms under these assumptions remains largely unexplored. Moreover, to the
best of our knowledge, all existing analyses under generalized smoothness
either i) focus on single-node settings or ii) make unrealistically strong
assumptions for distributed settings, such as requiring data heterogeneity, and
almost surely bounded stochastic gradient noise variance. In this paper, we
propose distributed error feedback algorithms that utilize normalization to
achieve the $O(1/\sqrt{K})$ convergence rate for nonconvex problems under
generalized smoothness. Our analyses apply for distributed settings without
data heterogeneity conditions, and enable stepsize tuning that is independent
of problem parameters. Additionally, we provide strong convergence guarantees
of normalized error feedback algorithms for stochastic settings. Finally, we
show that due to their larger allowable stepsizes, our new normalized error
feedback algorithms outperform their non-normalized counterparts on various
tasks, including the minimization of polynomial functions, logistic regression,
and ResNet-20 training.",2024-10-22,"Sarit Khirirat, Abdurakhmon Sadiev, Artem Riabinin, Eduard Gorbunov, Peter Richtárik",http://arxiv.org/pdf/2410.16871v1,cs.LG
Federated Causal Inference: Multi-Study ATE Estimation beyond Meta-Analysis,"We study Federated Causal Inference, an approach to estimate treatment
effects from decentralized data across centers. We compare three classes of
Average Treatment Effect (ATE) estimators derived from the Plug-in G-Formula,
ranging from simple meta-analysis to one-shot and multi-shot federated
learning, the latter leveraging the full data to learn the outcome model
(albeit requiring more communication). Focusing on Randomized Controlled Trials
(RCTs), we derive the asymptotic variance of these estimators for linear
models. Our results provide practical guidance on selecting the appropriate
estimator for various scenarios, including heterogeneity in sample sizes,
covariate distributions, treatment assignment schemes, and center effects. We
validate these findings with a simulation study.",2024-10-22,"Rémi Khellaf, Aurélien Bellet, Julie Josse",http://arxiv.org/pdf/2410.16870v2,cs.LG
Rethinking generalization of classifiers in separable classes scenarios and over-parameterized regimes,"We investigate the learning dynamics of classifiers in scenarios where
classes are separable or classifiers are over-parameterized. In both cases,
Empirical Risk Minimization (ERM) results in zero training error. However,
there are many global minima with a training error of zero, some of which
generalize well and some of which do not. We show that in separable classes
scenarios the proportion of ""bad"" global minima diminishes exponentially with
the number of training data n. Our analysis provides bounds and learning curves
dependent solely on the density distribution of the true error for the given
classifier function set, irrespective of the set's size or complexity (e.g.,
number of parameters). This observation may shed light on the unexpectedly good
generalization of over-parameterized Neural Networks. For the
over-parameterized scenario, we propose a model for the density distribution of
the true error, yielding learning curves that align with experiments on MNIST
and CIFAR-10.",2024-10-22,"Julius Martinetz, Christoph Linse, Thomas Martinetz",http://arxiv.org/pdf/2410.16868v1,cs.LG
VEMOCLAP: A video emotion classification web application,"We introduce VEMOCLAP: Video EMOtion Classifier using Pretrained features,
the first readily available and open-source web application that analyzes the
emotional content of any user-provided video. We improve our previous work,
which exploits open-source pretrained models that work on video frames and
audio, and then efficiently fuse the resulting pretrained features using
multi-head cross-attention. Our approach increases the state-of-the-art
classification accuracy on the Ekman-6 video emotion dataset by 4.3% and offers
an online application for users to run our model on their own videos or YouTube
videos. We invite the readers to try our application at serkansulun.com/app.",2024-10-22,"Serkan Sulun, Paula Viana, Matthew E. P. Davies",http://arxiv.org/pdf/2410.21303v1,cs.LG
Dynamic graph neural networks for enhanced volatility prediction in financial markets,"Volatility forecasting is essential for risk management and decision-making
in financial markets. Traditional models like Generalized Autoregressive
Conditional Heteroskedasticity (GARCH) effectively capture volatility
clustering but often fail to model complex, non-linear interdependencies
between multiple indices. This paper proposes a novel approach using Graph
Neural Networks (GNNs) to represent global financial markets as dynamic graphs.
The Temporal Graph Attention Network (Temporal GAT) combines Graph
Convolutional Networks (GCNs) and Graph Attention Networks (GATs) to capture
the temporal and structural dynamics of volatility spillovers. By utilizing
correlation-based and volatility spillover indices, the Temporal GAT constructs
directed graphs that enhance the accuracy of volatility predictions. Empirical
results from a 15-year study of eight major global indices show that the
Temporal GAT outperforms traditional GARCH models and other machine learning
methods, particularly in short- to mid-term forecasts. The sensitivity and
scenario-based analysis over a range of parameters and hyperparameters further
demonstrate the significance of the proposed technique. Hence, this work
highlights the potential of GNNs in modeling complex market behaviors,
providing valuable insights for financial analysts and investors.",2024-10-22,"Pulikandala Nithish Kumar, Nneka Umeorah, Alex Alochukwu",http://arxiv.org/pdf/2410.16858v1,cs.LG
Polyak's Heavy Ball Method Achieves Accelerated Local Rate of Convergence under Polyak-Lojasiewicz Inequality,"In this work, we consider the convergence of Polyak's heavy ball method, both
in continuous and discrete time, on a non-convex objective function. We recover
the convergence rates derived in [Polyak, U.S.S.R. Comput. Math. and Math.
Phys., 1964] for strongly convex objective functions, assuming only validity of
the Polyak-Lojasiewicz inequality. In continuous time our result holds for all
initializations, whereas in the discrete time setting we conduct a local
analysis around the global minima. Our results demonstrate that the heavy ball
method does, in fact, accelerate on the class of objective functions satisfying
the Polyak-Lojasiewicz inequality. This holds even in the discrete time
setting, provided the method reaches a neighborhood of the global minima.
Instead of the usually employed Lyapunov-type arguments, our approach leverages
a new differential geometric perspective of the Polyak-Lojasiewicz inequality
proposed in [Rebjock and Boumal, Math. Program., 2024].",2024-10-22,"Sebastian Kassing, Simon Weissmann",http://arxiv.org/pdf/2410.16849v1,cs.LG
Safe Load Balancing in Software-Defined-Networking,"High performance, reliability and safety are crucial properties of any
Software-Defined-Networking (SDN) system. Although the use of Deep
Reinforcement Learning (DRL) algorithms has been widely studied to improve
performance, their practical applications are still limited as they fail to
ensure safe operations in exploration and decision-making. To fill this gap, we
explore the design of a Control Barrier Function (CBF) on top of Deep
Reinforcement Learning (DRL) algorithms for load-balancing. We show that our
DRL-CBF approach is capable of meeting safety requirements during training and
testing while achieving near-optimal performance in testing. We provide results
using two simulators: a flow-based simulator, which is used for
proof-of-concept and benchmarking, and a packet-based simulator that implements
real protocols and scheduling. Thanks to the flow-based simulator, we compared
the performance against the optimal policy, solving a Non Linear Programming
(NLP) problem with the SCIP solver. Furthermore, we showed that pre-trained
models in the flow-based simulator, which is faster, can be transferred to the
packet simulator, which is slower but more accurate, with some fine-tuning.
Overall, the results suggest that near-optimal Quality-of-Service (QoS)
performance in terms of end-to-end delay can be achieved while safety
requirements related to link capacity constraints are guaranteed. In the
packet-based simulator, we also show that our DRL-CBF algorithms outperform
non-RL baseline algorithms. When the models are fine-tuned over a few episodes,
we achieved smoother QoS and safety in training, and similar performance in
testing compared to the case where models have been trained from scratch.",2024-10-22,"Lam Dinh, Pham Tran Anh Quang, Jérémie Leguay",http://arxiv.org/pdf/2410.16846v1,cs.LG
Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating Few-Shot Node Classification,"Graph Neural Networks (GNNs) have shown superior performance in node
classification. However, GNNs perform poorly in the Few-Shot Node
Classification (FSNC) task that requires robust generalization to make accurate
predictions for unseen classes with limited labels. To tackle the challenge, we
propose the integration of Sharpness-Aware Minimization (SAM)--a technique
designed to enhance model generalization by finding a flat minimum of the loss
landscape--into GNN training. The standard SAM approach, however, consists of
two forward-backward steps in each training iteration, doubling the
computational cost compared to the base optimizer (e.g., Adam). To mitigate
this drawback, we introduce a novel algorithm, Fast Graph Sharpness-Aware
Minimization (FGSAM), that integrates the rapid training of Multi-Layer
Perceptrons (MLPs) with the superior performance of GNNs. Specifically, we
utilize GNNs for parameter perturbation while employing MLPs to minimize the
perturbed loss so that we can find a flat minimum with good generalization more
efficiently. Moreover, our method reutilizes the gradient from the perturbation
phase to incorporate graph topology into the minimization process at almost
zero additional cost. To further enhance training efficiency, we develop FGSAM+
that executes exact perturbations periodically. Extensive experiments
demonstrate that our proposed algorithm outperforms the standard SAM with lower
computational costs in FSNC tasks. In particular, our FGSAM+ as a SAM variant
offers a faster optimization than the base optimizer in most cases. In addition
to FSNC, our proposed methods also demonstrate competitive performance in the
standard node classification task for heterophilic graphs, highlighting the
broad applicability. The code is available at
https://github.com/draym28/FGSAM_NeurIPS24.",2024-10-22,"Yihong Luo, Yuhan Chen, Siya Qiu, Yiwei Wang, Chen Zhang, Yan Zhou, Xiaochun Cao, Jing Tang",http://arxiv.org/pdf/2410.16845v1,cs.LG
Survival of the Fittest: Evolutionary Adaptation of Policies for Environmental Shifts,"Reinforcement learning (RL) has been successfully applied to solve the
problem of finding obstacle-free paths for autonomous agents operating in
stochastic and uncertain environments. However, when the underlying stochastic
dynamics of the environment experiences drastic distribution shifts, the
optimal policy obtained in the trained environment may be sub-optimal or may
entirely fail in helping find goal-reaching paths for the agent. Approaches
like domain randomization and robust RL can provide robust policies, but
typically assume minor (bounded) distribution shifts. For substantial
distribution shifts, retraining (either with a warm-start policy or from
scratch) is an alternative approach. In this paper, we develop a novel approach
called {\em Evolutionary Robust Policy Optimization} (ERPO), an adaptive
re-training algorithm inspired by evolutionary game theory (EGT). ERPO learns
an optimal policy for the shifted environment iteratively using a temperature
parameter that controls the trade off between exploration and adherence to the
old optimal policy. The policy update itself is an instantiation of the
replicator dynamics used in EGT. We show that under fairly common sparsity
assumptions on rewards in such environments, ERPO converges to the optimal
policy in the shifted environment. We empirically demonstrate that for path
finding tasks in a number of environments, ERPO outperforms several popular RL
and deep RL algorithms (PPO, A3C, DQN) in many scenarios and popular
environments. This includes scenarios where the RL algorithms are allowed to
train from scratch in the new environment, when they are retrained on the new
environment, or when they are used in conjunction with domain randomization.
ERPO shows faster policy adaptation, higher average rewards, and reduced
computational costs in policy adaptation.",2024-10-22,"Sheryl Paul, Jyotirmoy V. Deshmukh",http://arxiv.org/pdf/2410.19852v1,cs.LG
Guarantees of a Preconditioned Subgradient Algorithm for Overparameterized Asymmetric Low-rank Matrix Recovery,"In this paper, we focus on a matrix factorization-based approach for robust
low-rank and asymmetric matrix recovery from corrupted measurements. We address
the challenging scenario where the rank of the sought matrix is unknown and
employ an overparameterized approach using the variational form of the nuclear
norm as a regularizer. We propose a subgradient algorithm that inherits the
merits of preconditioned algorithms, whose rate of convergence does not depend
on the condition number of the sought matrix, and addresses their current
limitation, i.e., the lack of convergence guarantees in the case of asymmetric
matrices with unknown rank. In this setting, we provide, for the first time in
the literature, linear convergence guarantees for the derived overparameterized
preconditioned subgradient algorithm in the presence of gross corruptions.
Additionally, by applying our approach to matrix sensing, we highlight its
merits when the measurement operator satisfies the mixed-norm restricted
isometry properties. Lastly, we present numerical experiments that validate our
theoretical results and demonstrate the effectiveness of our approach.",2024-10-22,"Paris Giampouras, HanQin Cai, Rene Vidal",http://arxiv.org/pdf/2410.16826v1,cs.LG
Klein Model for Hyperbolic Neural Networks,"Hyperbolic neural networks (HNNs) have been proved effective in modeling
complex data structures. However, previous works mainly focused on the
Poincar\'e ball model and the hyperboloid model as coordinate representations
of the hyperbolic space, often neglecting the Klein model. Despite this, the
Klein model offers its distinct advantages thanks to its straight-line
geodesics, which facilitates the well-known Einstein midpoint construction,
previously leveraged to accompany HNNs in other models. In this work, we
introduce a framework for hyperbolic neural networks based on the Klein model.
We provide detailed formulation for representing useful operations using the
Klein model. We further study the Klein linear layer and prove that the
""tangent space construction"" of the scalar multiplication and parallel
transport are exactly the Einstein scalar multiplication and the Einstein
addition, analogous to the M\""obius operations used in the Poincar\'e ball
model. We show numerically that the Klein HNN performs on par with the
Poincar\'e ball model, providing a third option for HNN that works as a
building block for more complicated architectures.",2024-10-22,"Yidan Mao, Jing Gu, Marcus C. Werner, Dongmian Zou",http://arxiv.org/pdf/2410.16813v1,cs.LG
Masked Clinical Modelling: A Framework for Synthetic and Augmented Survival Data Generation,"Access to real clinical data is often restricted due to privacy obligations,
creating significant barriers for healthcare research. Synthetic datasets
provide a promising solution, enabling secure data sharing and model
development. However, most existing approaches focus on data realism rather
than utility -- ensuring that models trained on synthetic data yield clinically
meaningful insights comparable to those trained on real data. In this paper, we
present Masked Clinical Modelling (MCM), a framework inspired by masked
language modelling, designed for both data synthesis and conditional data
augmentation. We evaluate this prototype on the WHAS500 dataset using Cox
Proportional Hazards models, focusing on the preservation of hazard ratios as
key clinical metrics. Our results show that data generated using the MCM
framework improves both discrimination and calibration in survival analysis,
outperforming existing methods. MCM demonstrates strong potential to support
survival data analysis and broader healthcare applications.",2024-10-22,"Nicholas I-Hsien Kuo, Blanca Gallego, Louisa Jorm",http://arxiv.org/pdf/2410.16811v2,cs.LG
Test-time Adversarial Defense with Opposite Adversarial Path and High Attack Time Cost,"Deep learning models are known to be vulnerable to adversarial attacks by
injecting sophisticated designed perturbations to input data. Training-time
defenses still exhibit a significant performance gap between natural accuracy
and robust accuracy. In this paper, we investigate a new test-time adversarial
defense method via diffusion-based recovery along opposite adversarial paths
(OAPs). We present a purifier that can be plugged into a pre-trained model to
resist adversarial attacks. Different from prior arts, the key idea is
excessive denoising or purification by integrating the opposite adversarial
direction with reverse diffusion to push the input image further toward the
opposite adversarial direction. For the first time, we also exemplify the
pitfall of conducting AutoAttack (Rand) for diffusion-based defense methods.
Through the lens of time complexity, we examine the trade-off between the
effectiveness of adaptive attack and its computation complexity against our
defense. Experimental evaluation along with time cost analysis verifies the
effectiveness of the proposed method.",2024-10-22,"Cheng-Han Yeh, Kuanchun Yu, Chun-Shien Lu",http://arxiv.org/pdf/2410.16805v2,cs.LG
Evaluating the Effectiveness of Attack-Agnostic Features for Morphing Attack Detection,"Morphing attacks have diversified significantly over the past years, with new
methods based on generative adversarial networks (GANs) and diffusion models
posing substantial threats to face recognition systems. Recent research has
demonstrated the effectiveness of features extracted from large vision models
pretrained on bonafide data only (attack-agnostic features) for detecting deep
generative images. Building on this, we investigate the potential of these
image representations for morphing attack detection (MAD). We develop
supervised detectors by training a simple binary linear SVM on the extracted
features and one-class detectors by modeling the distribution of bonafide
features with a Gaussian Mixture Model (GMM). Our method is evaluated across a
comprehensive set of attacks and various scenarios, including generalization to
unseen attacks, different source datasets, and print-scan data. Our results
indicate that attack-agnostic features can effectively detect morphing attacks,
outperforming traditional supervised and one-class detectors from the
literature in most scenarios. Additionally, we provide insights into the
strengths and limitations of each considered representation and discuss
potential future research directions to further enhance the robustness and
generalizability of our approach.",2024-10-22,"Laurent Colbois, Sébastien Marcel",http://arxiv.org/pdf/2410.16802v1,cs.LG
One-Step Diffusion Distillation through Score Implicit Matching,"Despite their strong performances on many generative tasks, diffusion models
require a large number of sampling steps in order to generate realistic
samples. This has motivated the community to develop effective methods to
distill pre-trained diffusion models into more efficient models, but these
methods still typically require few-step inference or perform substantially
worse than the underlying model. In this paper, we present Score Implicit
Matching (SIM) a new approach to distilling pre-trained diffusion models into
single-step generator models, while maintaining almost the same sample
generation ability as the original model as well as being data-free with no
need of training samples for distillation. The method rests upon the fact that,
although the traditional score-based loss is intractable to minimize for
generator models, under certain conditions we can efficiently compute the
gradients for a wide class of score-based divergences between a diffusion model
and a generator. SIM shows strong empirical performances for one-step
generators: on the CIFAR10 dataset, it achieves an FID of 2.06 for
unconditional generation and 1.96 for class-conditional generation. Moreover,
by applying SIM to a leading transformer-based diffusion model, we distill a
single-step generator for text-to-image (T2I) generation that attains an
aesthetic score of 6.42 with no performance decline over the original
multi-step counterpart, clearly outperforming the other one-step generators
including SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We
will release this industry-ready one-step transformer-based T2I generator along
with this paper.",2024-10-22,"Weijian Luo, Zemin Huang, Zhengyang Geng, J. Zico Kolter, Guo-jun Qi",http://arxiv.org/pdf/2410.16794v1,cs.LG
Curriculum Reinforcement Learning for Complex Reward Functions,"Reinforcement learning (RL) has emerged as a powerful tool for tackling
control problems, but its practical application is often hindered by the
complexity arising from intricate reward functions with multiple terms. The
reward hypothesis posits that any objective can be encapsulated in a scalar
reward function, yet balancing individual, potentially adversarial, reward
terms without exploitation remains challenging. To overcome the limitations of
traditional RL methods, which often require precise balancing of competing
reward terms, we propose a two-stage reward curriculum that first maximizes a
simple reward function and then transitions to the full, complex reward. We
provide a method based on how well an actor fits a critic to automatically
determine the transition point between the two stages. Additionally, we
introduce a flexible replay buffer that enables efficient phase transfer by
reusing samples from one stage in the next. We evaluate our method on the
DeepMind control suite, modified to include an additional constraint term in
the reward definitions. We further evaluate our method in a mobile robot
scenario with even more competing reward terms. In both settings, our two-stage
reward curriculum achieves a substantial improvement in performance compared to
a baseline trained without curriculum. Instead of exploiting the constraint
term in the reward, it is able to learn policies that balance task completion
and constraint satisfaction. Our results demonstrate the potential of two-stage
reward curricula for efficient and stable RL in environments with complex
rewards, paving the way for more robust and adaptable robotic systems in
real-world applications.",2024-10-22,"Kilian Freitag, Kristian Ceder, Rita Laezza, Knut Åkesson, Morteza Haghir Chehreghani",http://arxiv.org/pdf/2410.16790v2,cs.LG
Annotation-Free MIDI-to-Audio Synthesis via Concatenative Synthesis and Generative Refinement,"Recent MIDI-to-audio synthesis methods have employed deep neural networks to
successfully generate high-quality and expressive instrumental tracks. However,
these methods require MIDI annotations for supervised training, limiting the
diversity of the output audio in terms of instrument timbres, and expression
styles. We propose CoSaRef, a MIDI-to-audio synthesis method that can be
developed without MIDI-audio paired datasets. CoSaRef first performs
concatenative synthesis based on MIDI inputs and then refines the resulting
audio into realistic tracks using a diffusion-based deep generative model
trained on audio-only datasets. This approach enhances the diversity of audio
timbres and expression styles. It also allows for control over the output
timbre based on audio sample selection, similar to traditional functions in
digital audio workstations. Experiments show that while inherently capable of
generating general tracks with high control over timbre, CoSaRef can also
perform comparably to conventional methods in generating realistic audio.",2024-10-22,"Osamu Take, Taketo Akama",http://arxiv.org/pdf/2410.16785v1,cs.LG
Beyond Retrieval: Generating Narratives in Conversational Recommender Systems,"The recent advances in Large Language Model's generation and reasoning
capabilities present an opportunity to develop truly conversational
recommendation systems. However, effectively integrating recommender system
knowledge into LLMs for natural language generation which is tailored towards
recommendation tasks remains a challenge. This paper addresses this challenge
by making two key contributions.
  First, we introduce a new dataset (REGEN) for natural language generation
tasks in conversational recommendations. REGEN (Reviews Enhanced with
GEnerative Narratives) extends the Amazon Product Reviews dataset with rich
user narratives, including personalized explanations of product preferences,
product endorsements for recommended items, and summaries of user purchase
history. REGEN is made publicly available to facilitate further research.
Furthermore, we establish benchmarks using well-known generative metrics, and
perform an automated evaluation of the new dataset using a rater LLM. Second,
the paper introduces a fusion architecture (CF model with an LLM) which serves
as a baseline for REGEN. And to the best of our knowledge, represents the first
attempt to analyze the capabilities of LLMs in understanding recommender
signals and generating rich narratives. We demonstrate that LLMs can
effectively learn from simple fusion architectures utilizing interaction-based
CF embeddings, and this can be further enhanced using the metadata and
personalization data associated with items. Our experiments show that combining
CF and content embeddings leads to improvements of 4-12% in key language
metrics compared to using either type of embedding individually. We also
provide an analysis to interpret how CF and content embeddings contribute to
this new generative task.",2024-10-22,"Krishna Sayana, Raghavendra Vasudeva, Yuri Vasilevski, Kun Su, Liam Hebert, James Pine, Hubert Pham, Ambarish Jash, Sukhdeep Sodhi",http://arxiv.org/pdf/2410.16780v2,cs.LG
Error estimates between SGD with momentum and underdamped Langevin diffusion,"Stochastic gradient descent with momentum is a popular variant of stochastic
gradient descent, which has recently been reported to have a close relationship
with the underdamped Langevin diffusion. In this paper, we establish a
quantitative error estimate between them in the 1-Wasserstein and total
variation distances.",2024-10-22,"Arnaud Guillin, Yu Wang, Lihu Xu, Haoran Yang",http://arxiv.org/pdf/2410.17297v1,cs.LG
Survival Models: Proper Scoring Rule and Stochastic Optimization with Competing Risks,"When dealing with right-censored data, where some outcomes are missing due to
a limited observation period, survival analysis -- known as time-to-event
analysis -- focuses on predicting the time until an event of interest occurs.
Multiple classes of outcomes lead to a classification variant: predicting the
most likely event, a less explored area known as competing risks. Classic
competing risks models couple architecture and loss, limiting scalability.To
address these issues, we design a strictly proper censoring-adjusted separable
scoring rule, allowing optimization on a subset of the data as each observation
is evaluated independently. The loss estimates outcome probabilities and
enables stochastic optimization for competing risks, which we use for efficient
gradient boosting trees. SurvivalBoost not only outperforms 12 state-of-the-art
models across several metrics on 4 real-life datasets, both in competing risks
and survival settings, but also provides great calibration, the ability to
predict across any time horizon, and computation times faster than existing
methods.",2024-10-22,"Julie Alberge, Vincent Maladière, Olivier Grisel, Judith Abécassis, Gaël Varoquaux",http://arxiv.org/pdf/2410.16765v1,cs.LG
Efficient Frequency Selective Surface Analysis via End-to-End Model-Based Learning,"This paper introduces an innovative end-to-end model-based deep learning
approach for efficient electromagnetic analysis of high-dimensional frequency
selective surfaces (FSS). Unlike traditional data-driven methods that require
large datasets, this approach combines physical insights from equivalent
circuit models with deep learning techniques to significantly reduce model
complexity and enhance prediction accuracy. Compared to previously introduced
model-based learning approaches, the proposed method is trained end-to-end from
the physical structure of the FSS (geometric parameters) to its electromagnetic
response (S-parameters). Additionally, an improvement in phase prediction
accuracy through a modified loss function is presented. Comparisons with direct
models, including deep neural networks (DNN) and radial basis function networks
(RBFN), demonstrate the superiority of the model-based approach in terms of
computational efficiency, model size, and generalization capability.",2024-10-22,"Cheima Hammami, Lucas Polo-López, Luc Le Magoarou",http://arxiv.org/pdf/2410.16760v1,cs.LG
Theoretical Convergence Guarantees for Variational Autoencoders,"Variational Autoencoders (VAE) are popular generative models used to sample
from complex data distributions. Despite their empirical success in various
machine learning tasks, significant gaps remain in understanding their
theoretical properties, particularly regarding convergence guarantees. This
paper aims to bridge that gap by providing non-asymptotic convergence
guarantees for VAE trained using both Stochastic Gradient Descent and Adam
algorithms.We derive a convergence rate of $\mathcal{O}(\log n / \sqrt{n})$,
where $n$ is the number of iterations of the optimization algorithm, with
explicit dependencies on the batch size, the number of variational samples, and
other key hyperparameters. Our theoretical analysis applies to both Linear VAE
and Deep Gaussian VAE, as well as several VAE variants, including $\beta$-VAE
and IWAE. Additionally, we empirically illustrate the impact of hyperparameters
on convergence, offering new insights into the theoretical understanding of VAE
training.",2024-10-22,"Sobihan Surendran, Antoine Godichon-Baggioni, Sylvain Le Corff",http://arxiv.org/pdf/2410.16750v2,cs.LG
Deep Learning and Machine Learning -- Python Data Structures and Mathematics Fundamental: From Theory to Practice,"This book provides a comprehensive introduction to the foundational concepts
of machine learning (ML) and deep learning (DL). It bridges the gap between
theoretical mathematics and practical application, focusing on Python as the
primary programming language for implementing key algorithms and data
structures. The book covers a wide range of topics, including basic and
advanced Python programming, fundamental mathematical operations, matrix
operations, linear algebra, and optimization techniques crucial for training ML
and DL models. Advanced subjects like neural networks, optimization algorithms,
and frequency domain methods are also explored, along with real-world
applications of large language models (LLMs) and artificial intelligence (AI)
in big data management. Designed for both beginners and advanced learners, the
book emphasizes the critical role of mathematical principles in developing
scalable AI solutions. Practical examples and Python code are provided
throughout, ensuring readers gain hands-on experience in applying theoretical
knowledge to solve complex problems in ML, DL, and big data analytics.",2024-10-22,"Silin Chen, Ziqian Bi, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Keyu Chen, Caitlyn Heqi Yin, Pohsun Feng, Yizhu Wen, Tianyang Wang, Ming Li, Jintao Ren, Qian Niu, Ming Liu",http://arxiv.org/pdf/2410.19849v1,cs.LG
Rethinking Soft Actor-Critic in High-Dimensional Action Spaces: The Cost of Ignoring Distribution Shift,"Soft Actor-Critic algorithm is widely recognized for its robust performance
across a range of deep reinforcement learning tasks, where it leverages the
tanh transformation to constrain actions within bounded limits. However, this
transformation induces a distribution shift, distorting the original Gaussian
action distribution and potentially leading the policy to select suboptimal
actions, particularly in high-dimensional action spaces. In this paper, we
conduct a comprehensive theoretical and empirical analysis of this distribution
shift, deriving the precise probability density function (PDF) for actions
following the tanh transformation to clarify the misalignment introduced
between the transformed distribution's mode and the intended action output. We
substantiate these theoretical insights through extensive experiments on
high-dimensional tasks within the HumanoidBench benchmark. Our findings
indicate that accounting for this distribution shift substantially enhances
SAC's performance, resulting in notable improvements in cumulative rewards,
sample efficiency, and reliability across tasks. These results underscore a
critical consideration for SAC and similar algorithms: addressing
transformation-induced distribution shifts is essential to optimizing policy
effectiveness in high-dimensional deep reinforcement learning environments,
thereby expanding the robustness and applicability of SAC in complex control
tasks.",2024-10-22,"Yanjun Chen, Xinming Zhang, Xianghui Wang, Zhiqiang Xu, Xiaoyu Shen, Wei Zhang",http://arxiv.org/pdf/2410.16739v2,cs.LG
"LLM-Assisted Red Teaming of Diffusion Models through ""Failures Are Fated, But Can Be Faded""","In large deep neural networks that seem to perform surprisingly well on many
tasks, we also observe a few failures related to accuracy, social biases, and
alignment with human values, among others. Therefore, before deploying these
models, it is crucial to characterize this failure landscape for engineers to
debug or audit models. Nevertheless, it is infeasible to exhaustively test for
all possible combinations of factors that could lead to a model's failure. In
this paper, we improve the ""Failures are fated, but can be faded"" framework
(arXiv:2406.07145)--a post-hoc method to explore and construct the failure
landscape in pre-trained generative models--with a variety of deep
reinforcement learning algorithms, screening tests, and LLM-based rewards and
state generation. With the aid of limited human feedback, we then demonstrate
how to restructure the failure landscape to be more desirable by moving away
from the discovered failure modes. We empirically demonstrate the effectiveness
of the proposed method on diffusion models. We also highlight the strengths and
weaknesses of each algorithm in identifying failure modes.",2024-10-22,"Som Sagar, Aditya Taparia, Ransalu Senanayake",http://arxiv.org/pdf/2410.16738v1,cs.LG
Co-training partial domain adaptation networks for industrial Fault Diagnosis,"The partial domain adaptation (PDA) challenge is a prevalent issue in
industrial fault diagnosis. Drawing inspiration from traditional classification
settings where such partial challenge is not a concern, we propose a novel PDA
framework called Interactive Residual Domain Adaptation Networks (IRDAN), which
introduces domain-wise models for each domain to provide a new perspective for
the PDA challenge. Each domain-wise model is equipped with a residual domain
adaptation (RDA) block to mitigate the ADP problem. Additionally, we introduce
a confident information flow via an interactive learning strategy, training the
modules of IRDAN sequentially to avoid cross-interference. We also establish a
reliable stopping criterion for selecting the best-performing model, ensuring
practical usability in real-world applications. Experiments have demonstrated
the superior performance of the proposed IRDAN.",2024-10-22,Gecheng Chen,http://arxiv.org/pdf/2410.16737v2,cs.LG
Progressive Compositionality in Text-to-Image Generative Models,"Despite the impressive text-to-image (T2I) synthesis capabilities of
diffusion models, they often struggle to understand compositional relationships
between objects and attributes, especially in complex settings. Existing
solutions have tackled these challenges by optimizing the cross-attention
mechanism or learning from the caption pairs with minimal semantic changes.
However, can we generate high-quality complex contrastive images that diffusion
models can directly discriminate based on visual representations? In this work,
we leverage large-language models (LLMs) to compose realistic, complex
scenarios and harness Visual-Question Answering (VQA) systems alongside
diffusion models to automatically curate a contrastive dataset, ConPair,
consisting of 15k pairs of high-quality contrastive images. These pairs feature
minimal visual discrepancies and cover a wide range of attribute categories,
especially complex and natural scenarios. To learn effectively from these error
cases, i.e., hard negative images, we propose EvoGen, a new multi-stage
curriculum for contrastive learning of diffusion models. Through extensive
experiments across a wide range of compositional scenarios, we showcase the
effectiveness of our proposed framework on compositional T2I benchmarks.",2024-10-22,"Evans Xu Han, Linghao Jin, Xiaofeng Liu, Paul Pu Liang",http://arxiv.org/pdf/2410.16719v2,cs.LG
Learning Partial Graph Matching via Optimal Partial Transport,"Partial graph matching extends traditional graph matching by allowing some
nodes to remain unmatched, enabling applications in more complex scenarios.
However, this flexibility introduces additional complexity, as both the subset
of nodes to match and the optimal mapping must be determined. While recent
studies have explored deep learning techniques for partial graph matching, a
significant limitation remains: the absence of an optimization objective that
fully captures the problem's intrinsic nature while enabling efficient
solutions. In this paper, we propose a novel optimization framework for partial
graph matching, inspired by optimal partial transport. Our approach formulates
an objective that enables partial assignments while incorporating matching
biases, using weighted total variation as the divergence function to guarantee
optimal partial assignments. Our method can achieve efficient, exact solutions
within cubic worst case time complexity. Our contributions are threefold: (i)
we introduce a novel optimization objective that balances matched and unmatched
nodes; (ii) we establish a connection between partial graph matching and linear
sum assignment problem, enabling efficient solutions; (iii) we propose a deep
graph matching architecture with a novel partial matching loss, providing an
end-to-end solution. The empirical evaluations on standard graph matching
benchmarks demonstrate the efficacy of the proposed approach.",2024-10-22,"Gathika Ratnayaka, James Nichols, Qing Wang",http://arxiv.org/pdf/2410.16718v7,cs.LG
Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World,"What happens when generative machine learning models are pretrained on
web-scale datasets containing data generated by earlier models? Some prior work
warns of ""model collapse"" as the web is overwhelmed by synthetic data; other
work suggests the problem can be contained (i.e. collapse can be avoided) by
managing how available data are used in pretraining. In this paper, we report
experiments on three ways of using data (training-workflows), across three
generative model task-settings (multivariate Gaussian estimation, kernel
density estimation, and language-model fine-tuning) to further confirm the
possibility of containment: (a) we confirm that the training-workflow of {\it
replacing} all real data by successive generations of purely synthetic data
indeed suffers model collapse in all task-settings studied; (b) we consider the
training-workflow of {\it accumulating} synthetic data alongside real data and
training on all data combined and confirming that, although the proportion of
real data eventually becomes zero, models remain stable and their test losses
do not diverge under this training-workflow; (c) we consider a
training-workflow where real and synthetic data accumulate together but
successive generations of pretraining are constrained to use fixed-size data
subsets each generation. In this workflow, we observe slow and gradual rather
than explosive degradation of test loss performance across generations. Our
insights are particularly important when forecasting whether future frontier
generative models will collapse or thrive, and our results open avenues for
empirically and mathematically studying the context-dependent value of
synthetic data.",2024-10-22,"Joshua Kazdan, Rylan Schaeffer, Apratim Dey, Matthias Gerstgrasser, Rafael Rafailov, David L. Donoho, Sanmi Koyejo",http://arxiv.org/pdf/2410.16713v4,cs.LG
Influential Language Data Selection via Gradient Trajectory Pursuit,"Curating a desirable dataset for training has been the core of building
highly capable large language models (Touvron et al., 2023; Achiam et al.,
2023; Team et al.,2024). Gradient influence scores (Pruthi et al., 2020; Xia et
al., 2024) are shown to be correlated with model performance and are commonly
used as the criterion for data selection. However, existing methods are built
upon either individual sample rankings or inefficient matching process, leading
to suboptimal performance or scaling up issues.In this paper, we propose
Gradient Trajectory Pursuit (GTP), an algorithm that performs pursuit of
gradient trajectories via jointly selecting data points under an L0-norm
regularized objective. The proposed algorithm highlights: (1) joint selection
instead of independent top-k selection, which automatically de-duplicates
samples; (2) higher efficiency with compressive sampling processes, which can
be further sped up using a distributed framework. In the experiments, we
demonstrate the algorithm in both in-domain and target-domain selection
benchmarks and show that it outperforms top-k selection and competitive
algorithms consistently, for example, our algorithm chooses as low as 0.5% data
to achieve full performance on the targeted instruction tuning tasks",2024-10-22,"Zhiwei Deng, Tao Li, Yang Li",http://arxiv.org/pdf/2410.16710v1,cs.LG
Universal approximation property of ODENet and ResNet with a single activation function,"We study a universal approximation property of ODENet and ResNet. The ODENet
is a map from an initial value to the final value of an ODE system in a finite
interval. It is considered a mathematical model of a ResNet-type deep learning
system. We consider dynamical systems with vector fields given by a single
composition of the activation function and an affine mapping, which is the most
common choice of the ODENet or ResNet vector field in actual machine learning
systems. We show that such an ODENet and ResNet with a restricted vector field
can uniformly approximate ODENet with a general vector field.",2024-10-22,"Masato Kimura, Kazunori Matsui, Yosuke Mizuno",http://arxiv.org/pdf/2410.16709v1,cs.LG
A Surrogate Model for Quay Crane Scheduling Problem,"In ports, a variety of tasks are carried out, and scheduling these tasks is
crucial due to its significant impact on productivity, making the generation of
precise plans essential. This study proposes a method to solve the Quay Crane
Scheduling Problem (QCSP), a representative task scheduling problem in ports
known to be NP-Hard, more quickly and accurately. First, the study suggests a
method to create more accurate work plans for Quay Cranes (QCs) by learning
from actual port data to accurately predict the working speed of QCs. Next, a
Surrogate Model is proposed by combining a Machine Learning (ML) model with a
Genetic Algorithm (GA), which is widely used to solve complex optimization
problems, enabling faster and more precise exploration of solutions. Unlike
methods that use fixed-dimensional chromosome encoding, the proposed
methodology can provide solutions for encodings of various dimensions. To
validate the performance of the newly proposed methodology, comparative
experiments were conducted, demonstrating faster search speeds and improved
fitness scores. The method proposed in this study can be applied not only to
QCSP but also to various NP-Hard problems, and it opens up possibilities for
the further development of advanced search algorithms by combining heuristic
algorithms with ML models.",2024-10-22,"Kikun Park, Hyerim Bae",http://arxiv.org/pdf/2411.03324v1,cs.LG
Privacy-hardened and hallucination-resistant synthetic data generation with logic-solvers,"Machine-generated data is a valuable resource for training Artificial
Intelligence algorithms, evaluating rare workflows, and sharing data under
stricter data legislations. The challenge is to generate data that is accurate
and private. Current statistical and deep learning methods struggle with large
data volumes, are prone to hallucinating scenarios incompatible with reality,
and seldom quantify privacy meaningfully. Here we introduce Genomator, a logic
solving approach (SAT solving), which efficiently produces private and
realistic representations of the original data. We demonstrate the method on
genomic data, which arguably is the most complex and private information.
Synthetic genomes hold great potential for balancing underrepresented
populations in medical research and advancing global data exchange. We
benchmark Genomator against state-of-the-art methodologies (Markov generation,
Restricted Boltzmann Machine, Generative Adversarial Network and Conditional
Restricted Boltzmann Machines), demonstrating an 84-93% accuracy improvement
and 95-98% higher privacy. Genomator is also 1000-1600 times more efficient,
making it the only tested method that scales to whole genomes. We show the
universal trade-off between privacy and accuracy, and use Genomator's tuning
capability to cater to all applications along the spectrum, from provable
private representations of sensitive cohorts, to datasets with
indistinguishable pharmacogenomic profiles. Demonstrating the production-scale
generation of tuneable synthetic data can increase trust and pave the way into
the clinic.",2024-10-22,"Mark A. Burgess, Brendan Hosking, Roc Reguant, Anubhav Kaphle, Mitchell J. O'Brien, Letitia M. F. Sng, Yatish Jain, Denis C. Bauer",http://arxiv.org/pdf/2410.16705v1,cs.LG
ClimaQA: An Automated Evaluation Framework for Climate Question Answering Models,"The use of Large Language Models (LLMs) in climate science has recently
gained significant attention. However, a critical issue remains: the lack of a
comprehensive evaluation framework capable of assessing the quality and
scientific validity of model outputs. To address this issue, we develop
ClimaGen (Climate QA Generator), an adaptive learning framework that generates
question-answer pairs from graduate textbooks with climate scientists in the
loop. As a result, we present ClimaQA-Gold, an expert-annotated benchmark
dataset alongside ClimaQA-Silver, a large-scale, comprehensive synthetic QA
dataset for climate science. Finally, we develop evaluation strategies and
compare different LLMs on our benchmarks. Our results offer novel insights into
various approaches used to enhance knowledge of climate LLMs. The source code
is publicly available at https://github.com/Rose-STL-Lab/genie-climaqa",2024-10-22,"Veeramakali Vignesh Manivannan, Yasaman Jafari, Srikar Eranky, Spencer Ho, Rose Yu, Duncan Watson-Parris, Yian Ma, Leon Bergen, Taylor Berg-Kirkpatrick",http://arxiv.org/pdf/2410.16701v2,cs.LG
Graph Transformers Dream of Electric Flow,"We show theoretically and empirically that the linear Transformer, when
applied to graph data, can implement algorithms that solve canonical problems
such as electric flow and eigenvector decomposition. The Transformer has access
to information on the input graph only via the graph's incidence matrix. We
present explicit weight configurations for implementing each algorithm, and we
bound the constructed Transformers' errors by the errors of the underlying
algorithms. Our theoretical findings are corroborated by experiments on
synthetic data. Additionally, on a real-world molecular regression task, we
observe that the linear Transformer is capable of learning a more effective
positional encoding than the default one based on Laplacian eigenvectors. Our
work is an initial step towards elucidating the inner-workings of the
Transformer for graph data. Code is available at
https://github.com/chengxiang/LinearGraphTransformer",2024-10-22,"Xiang Cheng, Lawrence Carin, Suvrit Sra",http://arxiv.org/pdf/2410.16699v2,cs.LG
Hyperboloid GPLVM for Discovering Continuous Hierarchies via Nonparametric Estimation,"Dimensionality reduction (DR) offers a useful representation of complex
high-dimensional data. Recent DR methods focus on hyperbolic geometry to derive
a faithful low-dimensional representation of hierarchical data. However,
existing methods are based on neighbor embedding, frequently ruining the
continual relation of the hierarchies. This paper presents hyperboloid Gaussian
process (GP) latent variable models (hGP-LVMs) to embed high-dimensional
hierarchical data with implicit continuity via nonparametric estimation. We
adopt generative modeling using the GP, which brings effective hierarchical
embedding and executes ill-posed hyperparameter tuning. This paper presents
three variants that employ original point, sparse point, and Bayesian
estimations. We establish their learning algorithms by incorporating the
Riemannian optimization and active approximation scheme of GP-LVM. For Bayesian
inference, we further introduce the reparameterization trick to realize
Bayesian latent variable learning. In the last part of this paper, we apply
hGP-LVMs to several datasets and show their ability to represent
high-dimensional hierarchies in low-dimensional spaces.",2024-10-22,"Koshi Watanabe, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama",http://arxiv.org/pdf/2410.16698v1,cs.LG
Governing equation discovery of a complex system from snapshots,"Complex systems in physics, chemistry, and biology that evolve over time with
inherent randomness are typically described by stochastic differential
equations (SDEs). A fundamental challenge in science and engineering is to
determine the governing equations of a complex system from snapshot data.
Traditional equation discovery methods often rely on stringent assumptions,
such as the availability of the trajectory information or time-series data, and
the presumption that the underlying system is deterministic. In this work, we
introduce a data-driven, simulation-free framework, called Sparse
Identification of Differential Equations from Snapshots (SpIDES), that
discovers the governing equations of a complex system from snapshots by
utilizing the advanced machine learning techniques to perform three essential
steps: probability flow reconstruction, probability density estimation, and
Bayesian sparse identification. We validate the effectiveness and robustness of
SpIDES by successfully identifying the governing equation of an over-damped
Langevin system confined within two potential wells. By extracting
interpretable drift and diffusion terms from the SDEs, our framework provides
deeper insights into system dynamics, enhances predictive accuracy, and
facilitates more effective strategies for managing and simulating stochastic
systems.",2024-10-22,"Qunxi Zhu, Bolin Zhao, Jingdong Zhang, Peiyang Li, Wei Lin",http://arxiv.org/pdf/2410.16694v1,cs.LG
Lower Bounds for Time-Varying Kernelized Bandits,"The optimization of black-box functions with noisy observations is a
fundamental problem with widespread applications, and has been widely studied
under the assumption that the function lies in a reproducing kernel Hilbert
space (RKHS). This problem has been studied extensively in the stationary
setting, and near-optimal regret bounds are known via developments in both
upper and lower bounds. In this paper, we consider non-stationary scenarios,
which are crucial for certain applications but are currently less
well-understood. Specifically, we provide the first algorithm-independent lower
bounds, where the time variations are subject satisfying a total variation
budget according to some function norm. Under $\ell_{\infty}$-norm variations,
our bounds are found to be close to an existing upper bound (Hong et al.,
2023). Under RKHS norm variations, the upper and lower bounds are still
reasonably close but with more of a gap, raising the interesting open question
of whether non-minor improvements in the upper bound are possible.",2024-10-22,"Xu Cai, Jonathan Scarlett",http://arxiv.org/pdf/2410.16692v2,cs.LG
Methods of improving LLM training stability,"Training stability of large language models(LLMs) is an important research
topic. Reproducing training instabilities can be costly, so we use a small
language model with 830M parameters and experiment with higher learning rates
to force models to diverge. One of the sources of training instability is the
growth of logits in attention layers. We extend the focus of the previous work
and look not only at the magnitude of the logits but at all outputs of linear
layers in the Transformer block. We observe that with a high learning rate the
L2 norm of all linear layer outputs can grow with each training step and the
model diverges. Specifically we observe that QKV, Proj and FC2 layers have the
largest growth of the output magnitude. This prompts us to explore several
options: 1) apply layer normalization not only after QK layers but also after
Proj and FC2 layers too; 2) apply layer normalization after the QKV layer (and
remove pre normalization). 3) apply QK layer normalization together with
softmax capping. We show that with the last two methods we can increase
learning rate by 1.5x (without model divergence) in comparison to an approach
based on QK layer normalization only. Also we observe significant perplexity
improvements for all three methods in comparison to the baseline model.",2024-10-22,"Oleg Rybakov, Mike Chrzanowski, Peter Dykas, Jinze Xue, Ben Lanir",http://arxiv.org/pdf/2410.16682v1,cs.LG
Efficient Antibody Structure Refinement Using Energy-Guided SE(3) Flow Matching,"Antibodies are proteins produced by the immune system that recognize and bind
to specific antigens, and their 3D structures are crucial for understanding
their binding mechanism and designing therapeutic interventions. The
specificity of antibody-antigen binding predominantly depends on the
complementarity-determining regions (CDR) within antibodies. Despite recent
advancements in antibody structure prediction, the quality of predicted CDRs
remains suboptimal. In this paper, we develop a novel antibody structure
refinement method termed FlowAB based on energy-guided flow matching. FlowAB
adopts the powerful deep generative method SE(3) flow matching and
simultaneously incorporates important physical prior knowledge into the flow
model to guide the generation process. The extensive experiments demonstrate
that FlowAB can significantly improve the antibody CDR structures. It achieves
new state-of-the-art performance on the antibody structure prediction task when
used in conjunction with an appropriate prior model while incurring only
marginal computational overhead. This advantage makes FlowAB a practical tool
in antibody engineering.",2024-10-22,"Jiying Zhang, Zijing Liu, Shengyuan Bai, He Cao, Yu Li, Lei Zhang",http://arxiv.org/pdf/2410.16673v1,cs.LG
CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing,"Sequential reasoning in agent systems has been significantly advanced by
large language models (LLMs), yet existing approaches face limitations.
Reflection-driven reasoning relies solely on knowledge in pretrained models,
limiting performance in novel scenarios, while experience-assisted reasoning
often depends on external experiences and lacks clear principles for selecting
representative experiences. We address these limitations by proposing CoPS
(Cross-Task Experience Sharing), a generalizable algorithm that enhances
sequential reasoning by cross-task experience sharing and selection. In detail,
CoPS leverages agents' experiences on previous tasks, selecting
distribution-matched experiences via a provable pessimism-based strategy to
maximize utility while minimizing risks from distribution shifts. Extensive
experimental results on benchmarks like Alfworld, Webshop, and HotPotQA
demonstrate that CoPS consistently outperforms state-of-the-art baselines, with
superior sample efficiency suitable for resource-constrained scenarios.
Theoretically, we show that the performance of our algorithm depends on both
the quality of the pretrained LLM and the matching between the agent's
task-dependent trial distribution and that generated by the LLM. Our work
bridges the gap between existing sequential reasoning paradigms and validates
the effectiveness of leveraging cross-task experiences, shedding light on the
potential to improve agents' generalization and adaptability across diverse
tasks. Our codes are available at
$\href{https://github.com/uclaml/COPS}{\text{https://github.com/uclaml/COPS}}$.",2024-10-22,"Chen Yang, Chenyang Zhao, Quanquan Gu, Dongruo Zhou",http://arxiv.org/pdf/2410.16670v1,cs.LG
Linear Partial Gromov-Wasserstein Embedding,"The Gromov-Wasserstein (GW) problem, a variant of the classical optimal
transport (OT) problem, has attracted growing interest in the machine learning
and data science communities due to its ability to quantify similarity between
measures in different metric spaces. However, like the classical OT problem, GW
imposes an equal mass constraint between measures, which restricts its
application in many machine learning tasks. To address this limitation, the
partial Gromov-Wasserstein (PGW) problem has been introduced. It relaxes the
equal mass constraint, allowing the comparison of general positive Radon
measures. Despite this, both GW and PGW face significant computational
challenges due to their non-convex nature. To overcome these challenges, we
propose the linear partial Gromov-Wasserstein (LPGW) embedding, a linearized
embedding technique for the PGW problem. For $K$ different metric measure
spaces, the pairwise computation of the PGW distance requires solving the PGW
problem ${O}(K^2)$ times. In contrast, the proposed linearization technique
reduces this to ${O}(K)$ times. Similar to the linearization technique for the
classical OT problem, we prove that LPGW defines a valid metric for metric
measure spaces. Finally, we demonstrate the effectiveness of LPGW in practical
applications such as shape retrieval and learning with transport-based
embeddings, showing that LPGW preserves the advantages of PGW in partial
matching while significantly enhancing computational efficiency. The code is
available at https://github.com/mint-vu/Linearized_Partial_Gromov_Wasserstein.",2024-10-22,"Yikun Bai, Abihith Kothapalli, Hengrong Du, Rocio Diaz Martin, Soheil Kolouri",http://arxiv.org/pdf/2410.16669v3,cs.LG
Dual Space Training for GANs: A Pathway to Efficient and Creative Generative Models,"Generative Adversarial Networks (GANs) have demonstrated remarkable
advancements in generative modeling; however, their training is often
resource-intensive, requiring extensive computational time and hundreds of
thousands of epochs. This paper proposes a novel optimization approach that
transforms the training process by operating within a dual space of the initial
data using invertible mappings, specifically autoencoders. By training GANs on
the encoded representations in the dual space, which encapsulate the most
salient features of the data, the generative process becomes significantly more
efficient and potentially reveals underlying patterns beyond human recognition.
This approach not only enhances training speed and resource usage but also
explores the philosophical question of whether models can generate insights
that transcend the human intelligence while being limited by the
human-generated data.",2024-10-22,Beka Modrekiladze,http://arxiv.org/pdf/2410.19009v1,cs.LG
QuasiNav: Asymmetric Cost-Aware Navigation Planning with Constrained Quasimetric Reinforcement Learning,"Autonomous navigation in unstructured outdoor environments is inherently
challenging due to the presence of asymmetric traversal costs, such as varying
energy expenditures for uphill versus downhill movement. Traditional
reinforcement learning methods often assume symmetric costs, which can lead to
suboptimal navigation paths and increased safety risks in real-world scenarios.
In this paper, we introduce QuasiNav, a novel reinforcement learning framework
that integrates quasimetric embeddings to explicitly model asymmetric costs and
guide efficient, safe navigation. QuasiNav formulates the navigation problem as
a constrained Markov decision process (CMDP) and employs quasimetric embeddings
to capture directionally dependent costs, allowing for a more accurate
representation of the terrain. This approach is combined with adaptive
constraint tightening within a constrained policy optimization framework to
dynamically enforce safety constraints during learning. We validate QuasiNav
across three challenging navigation scenarios-undulating terrains, asymmetric
hill traversal, and directionally dependent terrain traversal-demonstrating its
effectiveness in both simulated and real-world environments. Experimental
results show that QuasiNav significantly outperforms conventional methods,
achieving higher success rates, improved energy efficiency, and better
adherence to safety constraints.",2024-10-22,"Jumman Hossain, Abu-Zaher Faridee, Derrik Asher, Jade Freeman, Theron Trout, Timothy Gregory, Nirmalya Roy",http://arxiv.org/pdf/2410.16666v1,cs.LG
FastAttention: Extend FlashAttention2 to NPUs and Low-resource GPUs,"FlashAttention series has been widely applied in the inference of large
language models (LLMs). However, FlashAttention series only supports the
high-level GPU architectures, e.g., Ampere and Hopper. At present,
FlashAttention series is not easily transferrable to NPUs and low-resource
GPUs. Moreover, FlashAttention series is inefficient for multi- NPUs or GPUs
inference scenarios. In this work, we propose FastAttention which pioneers the
adaptation of FlashAttention series for NPUs and low-resource GPUs to boost LLM
inference efficiency. Specifically, we take Ascend NPUs and Volta-based GPUs as
representatives for designing our FastAttention. We migrate FlashAttention
series to Ascend NPUs by proposing a novel two-level tiling strategy for
runtime speedup, tiling-mask strategy for memory saving and the
tiling-AllReduce strategy for reducing communication overhead, respectively.
Besides, we adapt FlashAttention for Volta-based GPUs by redesigning the
operands layout in shared memory and introducing a simple yet effective CPU-GPU
cooperative strategy for efficient memory utilization. On Ascend NPUs, our
FastAttention can achieve a 10.7$\times$ speedup compared to the standard
attention implementation. Llama-7B within FastAttention reaches up to
5.16$\times$ higher throughput than within the standard attention. On Volta
architecture GPUs, FastAttention yields 1.43$\times$ speedup compared to its
equivalents in \texttt{xformers}. Pangu-38B within FastAttention brings
1.46$\times$ end-to-end speedup using FasterTransformer. Coupled with the
propose CPU-GPU cooperative strategy, FastAttention supports a maximal input
length of 256K on 8 V100 GPUs. All the codes will be made available soon.",2024-10-22,"Haoran Lin, Xianzhi Yu, Kang Zhao, Lu Hou, Zongyuan Zhan, Stanislav Kamenev, Han Bao, Ting Hu, Mingkai Wang, Qixin Chang, Siyue Sui, Weihao Sun, Jiaxin Hu, Jun Yao, Zekun Yin, Cheng Qian, Ying Zhang, Yinfei Pan, Yu Yang, Weiguo Liu",http://arxiv.org/pdf/2410.16663v1,cs.LG
RKadiyala at SemEval-2024 Task 8: Black-Box Word-Level Text Boundary Detection in Partially Machine Generated Texts,"With increasing usage of generative models for text generation and widespread
use of machine generated texts in various domains, being able to distinguish
between human written and machine generated texts is a significant challenge.
While existing models and proprietary systems focus on identifying whether
given text is entirely human written or entirely machine generated, only a few
systems provide insights at sentence or paragraph level at likelihood of being
machine generated at a non reliable accuracy level, working well only for a set
of domains and generators. This paper introduces few reliable approaches for
the novel task of identifying which part of a given text is machine generated
at a word level while comparing results from different approaches and methods.
We present a comparison with proprietary systems , performance of our model on
unseen domains' and generators' texts. The findings reveal significant
improvements in detection accuracy along with comparison on other aspects of
detection capabilities. Finally we discuss potential avenues for improvement
and implications of our work. The proposed model is also well suited for
detecting which parts of a text are machine generated in outputs of Instruct
variants of many LLMs.",2024-10-22,Ram Mohan Rao Kadiyala,http://arxiv.org/pdf/2410.16659v1,cs.LG
Dual-Model Defense: Safeguarding Diffusion Models from Membership Inference Attacks through Disjoint Data Splitting,"Diffusion models have demonstrated remarkable capabilities in image
synthesis, but their recently proven vulnerability to Membership Inference
Attacks (MIAs) poses a critical privacy concern. This paper introduces two
novel and efficient approaches (DualMD and DistillMD) to protect diffusion
models against MIAs while maintaining high utility. Both methods are based on
training two separate diffusion models on disjoint subsets of the original
dataset. DualMD then employs a private inference pipeline that utilizes both
models. This strategy significantly reduces the risk of black-box MIAs by
limiting the information any single model contains about individual training
samples. The dual models can also generate ""soft targets"" to train a private
student model in DistillMD, enhancing privacy guarantees against all types of
MIAs. Extensive evaluations of DualMD and DistillMD against state-of-the-art
MIAs across various datasets in white-box and black-box settings demonstrate
their effectiveness in substantially reducing MIA success rates while
preserving competitive image generation performance. Notably, our experiments
reveal that DistillMD not only defends against MIAs but also mitigates model
memorization, indicating that both vulnerabilities stem from overfitting and
can be addressed simultaneously with our unified approach.",2024-10-22,"Bao Q. Tran, Viet Nguyen, Anh Tran, Toan Tran",http://arxiv.org/pdf/2410.16657v1,cs.LG
Parsimonious Dynamic Mode Decomposition: A Robust and Automated Approach for Optimally Sparse Mode Selection in Complex Systems,"This paper introduces the Parsimonious Dynamic Mode Decomposition (parsDMD),
a novel algorithm designed to automatically select an optimally sparse subset
of dynamic modes for both spatiotemporal and purely temporal data. By
incorporating time-delay embedding and leveraging Orthogonal Matching Pursuit
(OMP), parsDMD ensures robustness against noise and effectively handles
complex, nonlinear dynamics. The algorithm is validated on a diverse range of
datasets, including standing wave signals, identifying hidden dynamics, fluid
dynamics simulations (flow past a cylinder and transonic buffet), and
atmospheric sea-surface temperature (SST) data. ParsDMD addresses a significant
limitation of the traditional sparsity-promoting DMD (spDMD), which requires
manual tuning of sparsity parameters through a rigorous trial-and-error process
to balance between single-mode and all-mode solutions. In contrast, parsDMD
autonomously determines the optimally sparse subset of modes without user
intervention, while maintaining minimal computational complexity. Comparative
analyses demonstrate that parsDMD consistently outperforms spDMD by providing
more accurate mode identification and effective reconstruction in noisy
environments. These advantages render parsDMD an effective tool for real-time
diagnostics, forecasting, and reduced-order model construction across various
disciplines.",2024-10-22,"Arpan Das, Pier Marzocca, Oleg Levinski",http://arxiv.org/pdf/2410.16656v2,cs.LG
Enhancing Two-Player Performance Through Single-Player Knowledge Transfer: An Empirical Study on Atari 2600 Games,"Playing two-player games using reinforcement learning and self-play can be
challenging due to the complexity of two-player environments and the possible
instability in the training process. We propose that a reinforcement learning
algorithm can train more efficiently and achieve improved performance in a
two-player game if it leverages the knowledge from the single-player version of
the same game. This study examines the proposed idea in ten different Atari
2600 environments using the Atari 2600 RAM as the input state. We discuss the
advantages of using transfer learning from a single-player training process
over training in a two-player setting from scratch, and demonstrate our results
in a few measures such as training time and average total reward. We also
discuss a method of calculating RAM complexity and its relationship to
performance.",2024-10-22,"Kimiya Saadat, Richard Zhao",http://arxiv.org/pdf/2410.16653v1,cs.LG
Improving Insurance Catastrophic Data with Resampling and GAN Methods,"The precise and large dataset concerning catastrophic events is very
important for insurers. To improve the quality of such data three methods based
on the bootstrap, bootknife, and GAN algorithms are proposed. Using numerical
experiments and real-life data, simulated outputs for these approaches are
compared based on the mean squared (MSE) and mean absolute errors (MAE). Then,
a direct algorithm to construct a fuzzy expert's opinion concerning such
outputs is also considered.",2024-10-22,"Norbert Dzadz, Maciej Romaniuk",http://arxiv.org/pdf/2410.17294v1,cs.LG
GE2E-KWS: Generalized End-to-End Training and Evaluation for Zero-shot Keyword Spotting,"We propose GE2E-KWS -- a generalized end-to-end training and evaluation
framework for customized keyword spotting. Specifically, enrollment utterances
are separated and grouped by keywords from the training batch and their
embedding centroids are compared to all other test utterance embeddings to
compute the loss. This simulates runtime enrollment and verification stages,
and improves convergence stability and training speed by optimizing matrix
operations compared to SOTA triplet loss approaches. To benchmark different
models reliably, we propose an evaluation process that mimics the production
environment and compute metrics that directly measure keyword matching
accuracy. Trained with GE2E loss, our 419KB quantized conformer model beats a
7.5GB ASR encoder by 23.6% relative AUC, and beats a same size triplet loss
model by 60.7% AUC. Our KWS models are natively streamable with low memory
footprints, and designed to continuously run on-device with no retraining
needed for new keywords (zero-shot).",2024-10-22,"Pai Zhu, Jacob W. Bartel, Dhruuv Agarwal, Kurt Partridge, Hyun Jin Park, Quan Wang",http://arxiv.org/pdf/2410.16647v1,cs.LG
LLMScan: Causal Scan for LLM Misbehavior Detection,"Despite the success of Large Language Models (LLMs) across various fields,
their potential to generate untruthful, biased and harmful responses poses
significant risks, particularly in critical applications. This highlights the
urgent need for systematic methods to detect and prevent such misbehavior.
While existing approaches target specific issues such as harmful responses,
this work introduces LLMScan, an innovative LLM monitoring technique based on
causality analysis, offering a comprehensive solution. LLMScan systematically
monitors the inner workings of an LLM through the lens of causal inference,
operating on the premise that the LLM's `brain' behaves differently when
misbehaving. By analyzing the causal contributions of the LLM's input tokens
and transformer layers, LLMScan effectively detects misbehavior. Extensive
experiments across various tasks and models reveal clear distinctions in the
causal distributions between normal behavior and misbehavior, enabling the
development of accurate, lightweight detectors for a variety of misbehavior
detection tasks.",2024-10-22,"Mengdi Zhang, Kai Kiat Goh, Peixin Zhang, Jun Sun, Rose Lin Xin, Hongyu Zhang",http://arxiv.org/pdf/2410.16638v4,cs.LG
General Frameworks for Conditional Two-Sample Testing,"We study the problem of conditional two-sample testing, which aims to
determine whether two populations have the same distribution after accounting
for confounding factors. This problem commonly arises in various applications,
such as domain adaptation and algorithmic fairness, where comparing two groups
is essential while controlling for confounding variables. We begin by
establishing a hardness result for conditional two-sample testing,
demonstrating that no valid test can have significant power against any single
alternative without proper assumptions. We then introduce two general
frameworks that implicitly or explicitly target specific classes of
distributions for their validity and power. Our first framework allows us to
convert any conditional independence test into a conditional two-sample test in
a black-box manner, while preserving the asymptotic properties of the original
conditional independence test. The second framework transforms the problem into
comparing marginal distributions with estimated density ratios, which allows us
to leverage existing methods for marginal two-sample testing. We demonstrate
this idea in a concrete manner with classification and kernel-based methods.
Finally, simulation studies are conducted to illustrate the proposed frameworks
in finite-sample scenarios.",2024-10-22,"Seongchan Lee, Suman Cha, Ilmun Kim",http://arxiv.org/pdf/2410.16636v1,cs.LG
Benchmarking Smoothness and Reducing High-Frequency Oscillations in Continuous Control Policies,"Reinforcement learning (RL) policies are prone to high-frequency
oscillations, especially undesirable when deploying to hardware in the
real-world. In this paper, we identify, categorize, and compare methods from
the literature that aim to mitigate high-frequency oscillations in deep RL. We
define two broad classes: loss regularization and architectural methods. At
their core, these methods incentivize learning a smooth mapping, such that
nearby states in the input space produce nearby actions in the output space. We
present benchmarks in terms of policy performance and control smoothness on
traditional RL environments from the Gymnasium and a complex manipulation task,
as well as three robotics locomotion tasks that include deployment and
evaluation with real-world hardware. Finally, we also propose hybrid methods
that combine elements from both loss regularization and architectural methods.
We find that the best-performing hybrid outperforms other methods, and improves
control smoothness by 26.8% over the baseline, with a worst-case performance
degradation of just 2.8%.",2024-10-22,"Guilherme Christmann, Ying-Sheng Luo, Hanjaya Mandala, Wei-Chao Chen",http://arxiv.org/pdf/2410.16632v1,cs.LG
SoK: Dataset Copyright Auditing in Machine Learning Systems,"As the implementation of machine learning (ML) systems becomes more
widespread, especially with the introduction of larger ML models, we perceive a
spring demand for massive data. However, it inevitably causes infringement and
misuse problems with the data, such as using unauthorized online artworks or
face images to train ML models. To address this problem, many efforts have been
made to audit the copyright of the model training dataset. However, existing
solutions vary in auditing assumptions and capabilities, making it difficult to
compare their strengths and weaknesses. In addition, robustness evaluations
usually consider only part of the ML pipeline and hardly reflect the
performance of algorithms in real-world ML applications. Thus, it is essential
to take a practical deployment perspective on the current dataset copyright
auditing tools, examining their effectiveness and limitations. Concretely, we
categorize dataset copyright auditing research into two prominent strands:
intrusive methods and non-intrusive methods, depending on whether they require
modifications to the original dataset. Then, we break down the intrusive
methods into different watermark injection options and examine the
non-intrusive methods using various fingerprints. To summarize our results, we
offer detailed reference tables, highlight key points, and pinpoint unresolved
issues in the current literature. By combining the pipeline in ML systems and
analyzing previous studies, we highlight several future directions to make
auditing tools more suitable for real-world copyright protection requirements.",2024-10-22,"Linkang Du, Xuanru Zhou, Min Chen, Chusong Zhang, Zhou Su, Peng Cheng, Jiming Chen, Zhikun Zhang",http://arxiv.org/pdf/2410.16618v2,cs.LG
Scattered Forest Search: Smarter Code Space Exploration with LLMs,"We frame code generation as a black-box optimization problem within the code
space and demonstrate how optimization-inspired techniques can enhance
inference scaling. Based on this perspective, we propose SCATTERED FOREST
SEARCH (SFS), a novel approach that improves solution diversity and better
exploits feedback during evolutionary search. Our theoretical analysis
illustrates how these methods help avoid local optima during optimization,
leading to more efficient exploration. Extensive experiments on HumanEval,
MBPP, APPS, CodeContests, and Leetcode reveal significant performance gains.
For instance, our method achieves a pass@1 rate of 67.1% on HumanEval+ and
87.2% on HumanEval with GPT-3.5, marking improvements of 8.6% and 4.3% over the
state-of-the-art, while also halving the iterations needed to find the correct
solution. Furthermore, our approach scales more efficiently than existing
search techniques, including tree search, line search, and repeated sampling.",2024-10-22,"Jonathan Light, Yue Wu, Yiyou Sun, Wenchao Yu, Yanchi liu, Xujiang Zhao, Ziniu Hu, Haifeng Chen, Wei Cheng",http://arxiv.org/pdf/2411.05010v2,cs.LG
Real-time Sub-milliwatt Epilepsy Detection Implemented on a Spiking Neural Network Edge Inference Processor,"Analyzing electroencephalogram (EEG) signals to detect the epileptic seizure
status of a subject presents a challenge to existing technologies aimed at
providing timely and efficient diagnosis. In this study, we aimed to detect
interictal and ictal periods of epileptic seizures using a spiking neural
network (SNN). Our proposed approach provides an online and real-time
preliminary diagnosis of epileptic seizures and helps to detect possible
pathological conditions.To validate our approach, we conducted experiments
using multiple datasets. We utilized a trained SNN to identify the presence of
epileptic seizures and compared our results with those of related studies. The
SNN model was deployed on Xylo, a digital SNN neuromorphic processor designed
to process temporal signals. Xylo efficiently simulates spiking leaky
integrate-and-fire neurons with exponential input synapses. Xylo has much lower
energy requirments than traditional approaches to signal processing, making it
an ideal platform for developing low-power seizure detection systems.Our
proposed method has a high test accuracy of 93.3% and 92.9% when classifying
ictal and interictal periods. At the same time, the application has an average
power consumption of 87.4 uW(IO power) + 287.9 uW(computational power) when
deployed to Xylo. Our method demonstrates excellent low-latency performance
when tested on multiple datasets. Our work provides a new solution for seizure
detection, and it is expected to be widely used in portable and wearable
devices in the future.",2024-10-22,"Ruixin Lia, Guoxu Zhaoa, Dylan Richard Muir, Yuya Ling, Karla Burelo, Mina Khoei, Dong Wang, Yannan Xing, Ning Qiao",http://arxiv.org/pdf/2410.16613v1,cs.LG
Assessing and improving reliability of neighbor embedding methods: a map-continuity perspective,"Visualizing high-dimensional data is essential for understanding biomedical
data and deep learning models. Neighbor embedding methods, such as t-SNE and
UMAP, are widely used but can introduce misleading visual artifacts. We find
that the manifold learning interpretations from many prior works are inaccurate
and that the misuse stems from a lack of data-independent notions of embedding
maps, which project high-dimensional data into a lower-dimensional space.
Leveraging the leave-one-out principle, we introduce LOO-map, a framework that
extends embedding maps beyond discrete points to the entire input space. We
identify two forms of map discontinuity that distort visualizations: one
exaggerates cluster separation and the other creates spurious local structures.
As a remedy, we develop two types of point-wise diagnostic scores to detect
unreliable embedding points and improve hyperparameter selection, which are
validated on datasets from computer vision and single-cell omics.",2024-10-22,"Zhexuan Liu, Rong Ma, Yiqiao Zhong",http://arxiv.org/pdf/2410.16608v2,cs.LG
GALA: Graph Diffusion-based Alignment with Jigsaw for Source-free Domain Adaptation,"Source-free domain adaptation is a crucial machine learning topic, as it
contains numerous applications in the real world, particularly with respect to
data privacy. Existing approaches predominantly focus on Euclidean data, such
as images and videos, while the exploration of non-Euclidean graph data remains
scarce. Recent graph neural network (GNN) approaches can suffer from serious
performance decline due to domain shift and label scarcity in source-free
adaptation scenarios. In this study, we propose a novel method named Graph
Diffusion-based Alignment with Jigsaw (GALA), tailored for source-free graph
domain adaptation. To achieve domain alignment, GALA employs a graph diffusion
model to reconstruct source-style graphs from target data. Specifically, a
score-based graph diffusion model is trained using source graphs to learn the
generative source styles. Then, we introduce perturbations to target graphs via
a stochastic differential equation instead of sampling from a prior, followed
by the reverse process to reconstruct source-style graphs. We feed the
source-style graphs into an off-the-shelf GNN and introduce class-specific
thresholds with curriculum learning, which can generate accurate and unbiased
pseudo-labels for target graphs. Moreover, we develop a simple yet effective
graph-mixing strategy named graph jigsaw to combine confident graphs and
unconfident graphs, which can enhance generalization capabilities and
robustness via consistency learning. Extensive experiments on benchmark
datasets validate the effectiveness of GALA.",2024-10-22,"Junyu Luo, Yiyang Gu, Xiao Luo, Wei Ju, Zhiping Xiao, Yusheng Zhao, Jingyang Yuan, Ming Zhang",http://arxiv.org/pdf/2410.16606v1,cs.LG
Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs,"Graph Neural Networks (GNNs) excel in many graph machine learning tasks but
face challenges when scaling to large networks. GNN transferability allows
training on smaller graphs and applying the model to larger ones, but existing
methods often rely on random subsampling, leading to disconnected subgraphs and
reduced model expressivity. We propose a novel graph sampling algorithm that
leverages feature homophily to preserve graph structure. By minimizing the
trace of the data correlation matrix, our method better preserves the graph
Laplacian trace -- a proxy for the graph connectivity -- than random sampling,
while achieving lower complexity than spectral methods. Experiments on citation
networks show improved performance in preserving Laplacian trace and GNN
transferability compared to random sampling.",2024-10-22,"Haolin Li, Haoyu Wang, Luana Ruiz",http://arxiv.org/pdf/2410.16593v3,cs.LG
ViMGuard: A Novel Multi-Modal System for Video Misinformation Guarding,"The rise of social media and short-form video (SFV) has facilitated a
breeding ground for misinformation. With the emergence of large language
models, significant research has gone into curbing this misinformation problem
with automatic false claim detection for text. Unfortunately, the automatic
detection of misinformation in SFV is a more complex problem that remains
largely unstudied. While text samples are monomodal (only containing words),
SFVs comprise three different modalities: words, visuals, and non-linguistic
audio. In this work, we introduce Video Masked Autoencoders for Misinformation
Guarding (ViMGuard), the first deep-learning architecture capable of
fact-checking an SFV through analysis of all three of its constituent
modalities. ViMGuard leverages a dual-component system. First, Video and Audio
Masked Autoencoders analyze the visual and non-linguistic audio elements of a
video to discern its intention; specifically whether it intends to make an
informative claim. If it is deemed that the SFV has informative intent, it is
passed through our second component: a Retrieval Augmented Generation system
that validates the factual accuracy of spoken words. In evaluation, ViMGuard
outperformed three cutting-edge fact-checkers, thus setting a new standard for
SFV fact-checking and marking a significant stride toward trustworthy news on
social platforms. To promote further testing and iteration, VimGuard was
deployed into a Chrome extension and all code was open-sourced on GitHub.",2024-10-22,"Andrew Kan, Christopher Kan, Zaid Nabulsi",http://arxiv.org/pdf/2410.16592v1,cs.LG
Advancing Super-Resolution in Neural Radiance Fields via Variational Diffusion Strategies,"We present a novel method for diffusion-guided frameworks for view-consistent
super-resolution (SR) in neural rendering. Our approach leverages existing 2D
SR models in conjunction with advanced techniques such as Variational Score
Distilling (VSD) and a LoRA fine-tuning helper, with spatial training to
significantly boost the quality and consistency of upscaled 2D images compared
to the previous methods in the literature, such as Renoised Score Distillation
(RSD) proposed in DiSR-NeRF (1), or SDS proposed in DreamFusion. The VSD score
facilitates precise fine-tuning of SR models, resulting in high-quality,
view-consistent images. To address the common challenge of inconsistencies
among independent SR 2D images, we integrate Iterative 3D Synchronization
(I3DS) from the DiSR-NeRF framework. Our quantitative benchmarks and
qualitative results on the LLFF dataset demonstrate the superior performance of
our system compared to existing methods such as DiSR-NeRF.",2024-10-22,"Shrey Vishen, Jatin Sarabu, Saurav Kumar, Chinmay Bharathulwar, Rithwick Lakshmanan, Vishnu Srinivas",http://arxiv.org/pdf/2410.18137v2,cs.LG
Conflict-Aware Adversarial Training,"Adversarial training is the most effective method to obtain adversarial
robustness for deep neural networks by directly involving adversarial samples
in the training procedure. To obtain an accurate and robust model, the
weighted-average method is applied to optimize standard loss and adversarial
loss simultaneously. In this paper, we argue that the weighted-average method
does not provide the best tradeoff for the standard performance and adversarial
robustness. We argue that the failure of the weighted-average method is due to
the conflict between the gradients derived from standard and adversarial loss,
and further demonstrate such a conflict increases with attack budget
theoretically and practically. To alleviate this problem, we propose a new
trade-off paradigm for adversarial training with a conflict-aware factor for
the convex combination of standard and adversarial loss, named
\textbf{Conflict-Aware Adversarial Training~(CA-AT)}. Comprehensive
experimental results show that CA-AT consistently offers a superior trade-off
between standard performance and adversarial robustness under the settings of
adversarial training from scratch and parameter-efficient finetuning.",2024-10-21,"Zhiyu Xue, Haohan Wang, Yao Qin, Ramtin Pedarsani",http://arxiv.org/pdf/2410.16579v1,cs.LG
Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge of Large Language Models,"Designing functional transition metal complexes (TMCs) faces challenges due
to the vast search space of metals and ligands, requiring efficient
optimization strategies. Traditional genetic algorithms (GAs) are commonly
used, employing random mutations and crossovers driven by explicit mathematical
objectives to explore this space. Transferring knowledge between different GA
tasks, however, is difficult. We integrate large language models (LLMs) into
the evolutionary optimization framework (LLM-EO) and apply it in both single-
and multi-objective optimization for TMCs. We find that LLM-EO surpasses
traditional GAs by leveraging the chemical knowledge of LLMs gained during
their extensive pretraining. Remarkably, without supervised fine-tuning, LLMs
utilize the full historical data from optimization processes, outperforming
those focusing only on top-performing TMCs. LLM-EO successfully identifies
eight of the top-20 TMCs with the largest HOMO-LUMO gaps by proposing only 200
candidates out of a 1.37 million TMCs space. Through prompt engineering using
natural language, LLM-EO introduces unparalleled flexibility into
multi-objective optimizations, thereby circumventing the necessity for
intricate mathematical formulations. As generative models, LLMs can suggest new
ligands and TMCs with unique properties by merging both internal knowledge and
external chemistry data, thus combining the benefits of efficient optimization
and molecular generation. With increasing potential of LLMs as pretrained
foundational models and new post-training inference strategies, we foresee
broad applications of LLM-based evolutionary optimization in chemistry and
materials design.",2024-10-21,"Jieyu Lu, Zhangde Song, Qiyuan Zhao, Yuanqi Du, Yirui Cao, Haojun Jia, Chenru Duan",http://arxiv.org/pdf/2410.18136v1,cs.LG
How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?,"Recent advancements in Large Language Models (LLMs) have positioned them as
powerful tools for clinical decision-making, with rapidly expanding
applications in healthcare. However, concerns about bias remain a significant
challenge in the clinical implementation of LLMs, particularly regarding gender
and ethnicity. This research investigates the evaluation and mitigation of bias
in LLMs applied to complex clinical cases, focusing on gender and ethnicity
biases. We introduce a novel Counterfactual Patient Variations (CPV) dataset
derived from the JAMA Clinical Challenge. Using this dataset, we built a
framework for bias evaluation, employing both Multiple Choice Questions (MCQs)
and corresponding explanations. We explore prompting with eight LLMs and
fine-tuning as debiasing methods. Our findings reveal that addressing social
biases in LLMs requires a multidimensional approach as mitigating gender bias
can occur while introducing ethnicity biases, and that gender bias in LLM
embeddings varies significantly across medical specialities. We demonstrate
that evaluating both MCQ response and explanation processes is crucial, as
correct responses can be based on biased \textit{reasoning}. We provide a
framework for evaluating LLM bias in real-world clinical cases, offer insights
into the complex nature of bias in these models, and present strategies for
bias mitigation.",2024-10-21,"Kenza Benkirane, Jackie Kay, Maria Perez-Ortiz",http://arxiv.org/pdf/2410.16574v1,cs.LG
Enhancing PAC Learning of Half spaces Through Robust Optimization Techniques,"This paper explores the challenges of PAC learning in semi-enclosed
environments that face persistent disruptive noise and demonstrates the
weaknesses of traditional learning models based on noise-free data. We present
a novel algorithm that enhances noise robustness in semiconservative learning
by using robust optimization techniques and advanced error correction methods
and improves learning accuracy without adding additional computational cost. We
also prove that this algorithm is very resistant to hostile noises.
Experimental results on various datasets demonstrate its effectiveness. They
provide a scalable solution for increasing the reliability of machine learning
in noisy environments which contributes to noise-resilient learning and
increased confidence in ML applications.",2024-10-21,"Shirmohammad Tavangari, Zahra Shakarami, Aref Yelghi, Asef Yelghi",http://arxiv.org/pdf/2410.16573v2,cs.LG
Implicit Contact Diffuser: Sequential Contact Reasoning with Latent Point Cloud Diffusion,"Long-horizon contact-rich manipulation has long been a challenging problem,
as it requires reasoning over both discrete contact modes and continuous object
motion. We introduce Implicit Contact Diffuser (ICD), a diffusion-based model
that generates a sequence of neural descriptors that specify a series of
contact relationships between the object and the environment. This sequence is
then used as guidance for an MPC method to accomplish a given task. The key
advantage of this approach is that the latent descriptors provide more
task-relevant guidance to MPC, helping to avoid local minima for contact-rich
manipulation tasks. Our experiments demonstrate that ICD outperforms baselines
on complex, long-horizon, contact-rich manipulation tasks, such as cable
routing and notebook folding. Additionally, our experiments also indicate that
\methodshort can generalize a target contact relationship to a different
environment. More visualizations can be found on our website
$\href{https://implicit-contact-diffuser.github.io/}{https://implicit-contact-diffuser.github.io}$",2024-10-21,"Zixuan Huang, Yinong He, Yating Lin, Dmitry Berenson",http://arxiv.org/pdf/2410.16571v1,cs.LG
Domain-Adaptive Pre-training of Self-Supervised Foundation Models for Medical Image Classification in Gastrointestinal Endoscopy,"Video capsule endoscopy has transformed gastrointestinal endoscopy (GIE)
diagnostics by offering a non-invasive method for capturing detailed images of
the gastrointestinal tract, enabling early disease detection. However, its
potential is limited by the sheer volume of images generated during the imaging
procedure, which can take anywhere from 6-8 hours and often produce up to 1
million images, necessitating automated analysis. Additionally, the variability
of these images, combined with the need for expert annotations and the scarcity
of large, high-quality labeled datasets, constrains the effectiveness of
current medical image analysis models. To address this, we introduce a novel
large GIE dataset, called EndoExtend24, created by merging ten existing public
and private datasets, ensuring patient integrity across splits. EndoExtend24
includes over 226,000 labeled images, as well as dynamic class mappings, which
allow unified training across datasets with differing labeling granularity,
supporting up to 123 distinct pathological findings. Further, we propose to
leverage domain adaptive pre-training of foundation models trained with
self-supervision on generic image data, to adapt them to the task of GIE
medical image diagnosis. Specifically, the EVA-02 model, which is based on the
ViT architecture and trained on ImageNet-22k with masked image modeling (using
EVA-CLIP as a MIM teacher), is pre-trained on the EndoExtend24 dataset to
achieve domain adaptation, and finally trained on the Capsule Endoscopy 2024
Challenge dataset. Our model demonstrates robust performance, securing third
place in the Capsule Endoscopy 2024 Challenge. We achieved a macro AUC of 0.762
and a balanced accuracy of 37.1% on the test set. These results emphasize the
effectiveness of our domain-adaptive pre-training approach and the enriched
EndoExtend24 dataset in advancing gastrointestinal endoscopy diagnostics.",2024-10-21,"Marcel Roth, Micha V. Nowak, Adrian Krenzer, Frank Puppe",http://arxiv.org/pdf/2410.21302v4,cs.LG
Gradient Normalization Provably Benefits Nonconvex SGD under Heavy-Tailed Noise,"This paper investigates the roles of gradient normalization and clipping in
ensuring the convergence of Stochastic Gradient Descent (SGD) under
heavy-tailed noise. While existing approaches consider gradient clipping
indispensable for SGD convergence, we theoretically demonstrate that gradient
normalization alone without clipping is sufficient to ensure convergence.
Furthermore, we establish that combining gradient normalization with clipping
offers significantly improved convergence rates compared to using either
technique in isolation, notably as gradient noise diminishes. With these
results, our work provides the first theoretical evidence demonstrating the
benefits of gradient normalization in SGD under heavy-tailed noise. Finally, we
introduce an accelerated SGD variant incorporating gradient normalization and
clipping, further enhancing convergence rates under heavy-tailed noise.",2024-10-21,"Tao Sun, Xinwang Liu, Kun Yuan",http://arxiv.org/pdf/2410.16561v3,cs.LG
Can Transformers In-Context Learn Behavior of a Linear Dynamical System?,"We investigate whether transformers can learn to track a random process when
given observations of a related process and parameters of the dynamical system
that relates them as context. More specifically, we consider a
finite-dimensional state-space model described by the state transition matrix
$F$, measurement matrices $h_1, \dots, h_N$, and the process and measurement
noise covariance matrices $Q$ and $R$, respectively; these parameters, randomly
sampled, are provided to the transformer along with the observations
$y_1,\dots,y_N$ generated by the corresponding linear dynamical system. We
argue that in such settings transformers learn to approximate the celebrated
Kalman filter, and empirically verify this both for the task of estimating
hidden states $\hat{x}_{N|1,2,3,...,N}$ as well as for one-step prediction of
the $(N+1)^{st}$ observation, $\hat{y}_{N+1|1,2,3,...,N}$. A further study of
the transformer's robustness reveals that its performance is retained even if
the model's parameters are partially withheld. In particular, we demonstrate
that the transformer remains accurate at the considered task even in the
absence of state transition and noise covariance matrices, effectively
emulating operations of the Dual-Kalman filter.",2024-10-21,"Usman Akram, Haris Vikalo",http://arxiv.org/pdf/2410.16546v1,cs.LG
Spatio-temporal Multivariate Cluster Evolution Analysis for Detecting and Tracking Climate Impacts,"Recent years have seen a growing concern about climate change and its
impacts. While Earth System Models (ESMs) can be invaluable tools for studying
the impacts of climate change, the complex coupling processes encoded in ESMs
and the large amounts of data produced by these models, together with the high
internal variability of the Earth system, can obscure important
source-to-impact relationships. This paper presents a novel and efficient
unsupervised data-driven approach for detecting statistically-significant
impacts and tracing spatio-temporal source-impact pathways in the climate
through a unique combination of ideas from anomaly detection, clustering and
Natural Language Processing (NLP). Using as an exemplar the 1991 eruption of
Mount Pinatubo in the Philippines, we demonstrate that the proposed approach is
capable of detecting known post-eruption impacts/events. We additionally
describe a methodology for extracting meaningful sequences of post-eruption
impacts/events by using NLP to efficiently mine frequent multivariate cluster
evolutions, which can be used to confirm or discover the chain of physical
processes between a climate source and its impact(s).",2024-10-21,"Warren L. Davis IV, Max Carlson, Irina Tezaur, Diana Bull, Kara Peterson, Laura Swiler",http://arxiv.org/pdf/2410.16544v1,cs.LG
A Theoretical Study of Neural Network Expressive Power via Manifold Topology,"A prevalent assumption regarding real-world data is that it lies on or close
to a low-dimensional manifold. When deploying a neural network on data
manifolds, the required size, i.e., the number of neurons of the network,
heavily depends on the intricacy of the underlying latent manifold. While
significant advancements have been made in understanding the geometric
attributes of manifolds, it's essential to recognize that topology, too, is a
fundamental characteristic of manifolds. In this study, we investigate network
expressive power in terms of the latent data manifold. Integrating both
topological and geometric facets of the data manifold, we present a size upper
bound of ReLU neural networks.",2024-10-21,"Jiachen Yao, Mayank Goswami, Chao Chen",http://arxiv.org/pdf/2410.16542v2,cs.LG
A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration,"Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance
in improving the reasoning capabilities of large language models (LLMs). While
theoretical investigations have been conducted to understand CoT, the
underlying transformer used in these studies isolates the CoT reasoning process
into separated in-context learning steps (Stepwise ICL). In this work, we
theoretically show that, compared to Stepwise ICL, the transformer gains better
error correction ability and more accurate predictions if the reasoning from
earlier steps (Coherent CoT) is integrated. Given that this coherent reasoning
changes the behavior of the transformer, we further investigate the sensitivity
of the transformer with Coherent CoT when the demonstration examples are
corrupted at the inference stage. Our theoretical results indicate that the
transformer is more sensitive to errors in intermediate reasoning steps than
the final outcome. Building upon this observation, we propose an improvement on
CoT by incorporating both correct and incorrect reasoning paths in the
demonstration. Our experiments validate the effectiveness of the proposed
approach.",2024-10-21,"Yingqian Cui, Pengfei He, Xianfeng Tang, Qi He, Chen Luo, Jiliang Tang, Yue Xing",http://arxiv.org/pdf/2410.16540v1,cs.LG
Satellite monitoring uncovers progress but large disparities in doubling crop yields,"High-resolution satellite-based crop yield mapping offers enormous promise
for monitoring progress towards the SDGs. Across 15,000 villages in Rwanda we
uncover areas that are on and off track to double productivity by 2030. This
machine learning enabled analysis is used to design spatially explicit
productivity targets that, if met, would simultaneously ensure national goals
without leaving anyone behind.",2024-10-21,"Katie Fankhauser, Evan Thomas, Zia Mehrabi",http://arxiv.org/pdf/2411.03322v1,cs.LG
QIXAI: A Quantum-Inspired Framework for Enhancing Classical and Quantum Model Transparency and Understanding,"The impressive performance of deep learning models, particularly
Convolutional Neural Networks (CNNs), is often hindered by their lack of
interpretability, rendering them ""black boxes."" This opacity raises concerns in
critical areas like healthcare, finance, and autonomous systems, where trust
and accountability are crucial. This paper introduces the QIXAI Framework
(Quantum-Inspired Explainable AI), a novel approach for enhancing neural
network interpretability through quantum-inspired techniques. By utilizing
principles from quantum mechanics, such as Hilbert spaces, superposition,
entanglement, and eigenvalue decomposition, the QIXAI framework reveals how
different layers of neural networks process and combine features to make
decisions.
  We critically assess model-agnostic methods like SHAP and LIME, as well as
techniques like Layer-wise Relevance Propagation (LRP), highlighting their
limitations in providing a comprehensive view of neural network operations. The
QIXAI framework overcomes these limitations by offering deeper insights into
feature importance, inter-layer dependencies, and information propagation. A
CNN for malaria parasite detection is used as a case study to demonstrate how
quantum-inspired methods like Singular Value Decomposition (SVD), Principal
Component Analysis (PCA), and Mutual Information (MI) provide interpretable
explanations of model behavior. Additionally, we explore the extension of QIXAI
to other architectures, including Recurrent Neural Networks (RNNs), Long
Short-Term Memory (LSTM) networks, Transformers, and Natural Language
Processing (NLP) models, and its application to generative models and
time-series analysis. The framework applies to both quantum and classical
systems, demonstrating its potential to improve interpretability and
transparency across a range of models, advancing the broader goal of developing
trustworthy AI systems.",2024-10-21,John M. Willis,http://arxiv.org/pdf/2410.16537v1,cs.LG
SoftSRV: Learn to Generate Targeted Synthetic Data,"We present a novel framework, SoftSRV, that is used to generate targeted
synthetic fine-tuning data for improving task-specific model performance. Given
a sample from a target distribution, our proposed framework uses a data-driven
loss minimization approach to steer a frozen large language model (LLM) to
generate synthetic sequences that are similar to those from the target
distribution. SoftSRV provides a practical improvement over common prompt
engineering approaches that rely on human-engineered prompt-templates, which
can be idiosyncratic, labor-intensive to craft, and may need to be specialized
per domain. We empirically evaluate our method against standard baselines
guiding a large LLM to generate synthetic data to fine-tune a smaller language
model on three different domains (coding, math, reasoning). We perform these
evaluations without any particular specialization of the framework to each
domain, emphasizing the generality of our approach. We find that SoftSRV
improves upon typical prompt engineering approaches, generating targeted data
that leads to fine-tuned models with significantly better task-specific
performance. In addition, SoftSRV-generated data better matches the target
distribution according to the MAUVE similarity metric.",2024-10-21,"Giulia DeSalvo, Jean-Fracois Kagy, Lazaros Karydas, Afshin Rostamizadeh, Sanjiv Kumar",http://arxiv.org/pdf/2410.16534v3,cs.LG
Large Body Language Models,"As virtual agents become increasingly prevalent in human-computer
interaction, generating realistic and contextually appropriate gestures in
real-time remains a significant challenge. While neural rendering techniques
have made substantial progress with static scripts, their applicability to
human-computer interactions remains limited. To address this, we introduce
Large Body Language Models (LBLMs) and present LBLM-AVA, a novel LBLM
architecture that combines a Transformer-XL large language model with a
parallelized diffusion model to generate human-like gestures from multimodal
inputs (text, audio, and video). LBLM-AVA incorporates several key components
enhancing its gesture generation capabilities, such as multimodal-to-pose
embeddings, enhanced sequence-to-sequence mapping with redefined attention
mechanisms, a temporal smoothing module for gesture sequence coherence, and an
attention-based refinement module for enhanced realism. The model is trained on
our large-scale proprietary open-source dataset Allo-AVA. LBLM-AVA achieves
state-of-the-art performance in generating lifelike and contextually
appropriate gestures with a 30% reduction in Fr\'echet Gesture Distance (FGD),
and a 25% improvement in Fr\'echet Inception Distance compared to existing
approaches.",2024-10-21,"Saif Punjwani, Larry Heck",http://arxiv.org/pdf/2410.16533v1,cs.LG
Bayesian scaling laws for in-context learning,"In-context learning (ICL) is a powerful technique for getting language models
to perform complex tasks with no training updates. Prior work has established
strong correlations between the number of in-context examples provided and the
accuracy of the model's predictions. In this paper, we seek to explain this
correlation by showing that ICL approximates a Bayesian learner. This
perspective gives rise to a family of novel Bayesian scaling laws for ICL. In
experiments with \mbox{GPT-2} models of different sizes, our scaling laws
exceed or match existing scaling laws in accuracy while also offering
interpretable terms for task priors, learning efficiency, and per-example
probabilities. To illustrate the analytic power that such interpretable scaling
laws provide, we report on controlled synthetic dataset experiments designed to
inform real-world studies of safety alignment. In our experimental protocol, we
use SFT to suppress an unwanted existing model capability and then use ICL to
try to bring that capability back (many-shot jailbreaking). We then experiment
on real-world instruction-tuned LLMs using capabilities benchmarks as well as a
new many-shot jailbreaking dataset. In all cases, Bayesian scaling laws
accurately predict the conditions under which ICL will cause the suppressed
behavior to reemerge, which sheds light on the ineffectiveness of post-training
at increasing LLM safety.",2024-10-21,"Aryaman Arora, Dan Jurafsky, Christopher Potts, Noah D. Goodman",http://arxiv.org/pdf/2410.16531v3,cs.LG
ADAM-SINDy: An Efficient Optimization Framework for Parameterized Nonlinear Dynamical System Identification,"Identifying dynamical systems characterized by nonlinear parameters presents
significant challenges in deriving mathematical models that enhance
understanding of physics. Traditional methods, such as Sparse Identification of
Nonlinear Dynamics (SINDy) and symbolic regression, can extract governing
equations from observational data; however, they also come with distinct
advantages and disadvantages. This paper introduces a novel method within the
SINDy framework, termed ADAM-SINDy, which synthesizes the strengths of
established approaches by employing the ADAM optimization algorithm. This
facilitates the simultaneous optimization of nonlinear parameters and
coefficients associated with nonlinear candidate functions, enabling precise
parameter estimation without requiring prior knowledge of nonlinear
characteristics such as trigonometric frequencies, exponential bandwidths, or
polynomial exponents, thereby addressing a key limitation of SINDy. Through an
integrated global optimization, ADAM-SINDy dynamically adjusts all unknown
variables in response to data, resulting in an adaptive identification
procedure that reduces the sensitivity to the library of candidate functions.
The performance of the ADAM-SINDy methodology is demonstrated across a spectrum
of dynamical systems, including benchmark coupled nonlinear ordinary
differential equations such as oscillators, chaotic fluid flows, reaction
kinetics, pharmacokinetics, as well as nonlinear partial differential equations
(wildfire transport). The results demonstrate significant improvements in
identifying parameterized dynamical systems and underscore the importance of
concurrently optimizing all parameters, particularly those characterized by
nonlinear parameters. These findings highlight the potential of ADAM-SINDy to
extend the applicability of the SINDy framework in addressing more complex
challenges in dynamical system identification.",2024-10-21,"Siva Viknesh, Younes Tatari, Amirhossein Arzani",http://arxiv.org/pdf/2410.16528v2,cs.LG
Insights and Current Gaps in Open-Source LLM Vulnerability Scanners: A Comparative Analysis,"This report presents a comparative analysis of open-source vulnerability
scanners for conversational large language models (LLMs). As LLMs become
integral to various applications, they also present potential attack surfaces,
exposed to security risks such as information leakage and jailbreak attacks.
Our study evaluates prominent scanners - Garak, Giskard, PyRIT, and
CyberSecEval - that adapt red-teaming practices to expose these
vulnerabilities. We detail the distinctive features and practical use of these
scanners, outline unifying principles of their design and perform quantitative
evaluations to compare them. These evaluations uncover significant reliability
issues in detecting successful attacks, highlighting a fundamental gap for
future development. Additionally, we contribute a preliminary labelled dataset,
which serves as an initial step to bridge this gap. Based on the above, we
provide strategic recommendations to assist organizations choose the most
suitable scanner for their red-teaming needs, accounting for customizability,
test suite comprehensiveness, and industry-specific use cases.",2024-10-21,"Jonathan Brokman, Omer Hofman, Oren Rachmil, Inderjeet Singh, Vikas Pahuja, Rathina Sabapathy Aishvariya Priya, Amit Giloni, Roman Vainshtein, Hisashi Kojima",http://arxiv.org/pdf/2410.16527v3,cs.LG
Efficient Neural Network Training via Subset Pretraining,"In training neural networks, it is common practice to use partial gradients
computed over batches, mostly very small subsets of the training set. This
approach is motivated by the argument that such a partial gradient is close to
the true one, with precision growing only with the square root of the batch
size. A theoretical justification is with the help of stochastic approximation
theory. However, the conditions for the validity of this theory are not
satisfied in the usual learning rate schedules. Batch processing is also
difficult to combine with efficient second-order optimization methods. This
proposal is based on another hypothesis: the loss minimum of the training set
can be expected to be well-approximated by the minima of its subsets. Such
subset minima can be computed in a fraction of the time necessary for
optimizing over the whole training set. This hypothesis has been tested with
the help of the MNIST, CIFAR-10, and CIFAR-100 image classification benchmarks,
optionally extended by training data augmentation. The experiments have
confirmed that results equivalent to conventional training can be reached. In
summary, even small subsets are representative if the overdetermination ratio
for the given model parameter set sufficiently exceeds unity. The computing
expense can be reduced to a tenth or less.",2024-10-21,"Jan Spörer, Bernhard Bermeitinger, Tomas Hrycej, Niklas Limacher, Siegfried Handschuh",http://arxiv.org/pdf/2410.16523v2,cs.LG
Cancer Cell Classification using Deep Learning,"In the current technological era, the medical profession has emerged as one
of the researchers' favorite subject areas, and cancer is one of them. Because
there is now no effective treatment for this illness, it is a matter of
concern. Only if this disease is discovered early may patients be rescued
(stage I and stage II). The likelihood of survival is quite low if it is
discovered in later stages (stages III and IV). The application of machine
learning, deep learning, and data mining techniques in the medical industry has
the potential to address current issues and bring benefits. Numerous symptoms
of cancer exist, including tumors, unusual bleeding, increased weight loss,
etc. It is not necessary for all tumor types to be cancerous. There are two
sorts of tumors: benign and malignant. To give patients, the right care,
symptoms must be carefully examined, and an automated system is to distinguish
between benign and malignant tumors. Most data produced in today's online
environment comes from websites related to healthcare or social media. Using
data mining techniques, it is possible to extract symptoms from this vast
amount of data, which will be helpful for identifying or classifying cancer.
This research classifies bacteria cells as benign or cancerous using various
deep-learning Algorithms. To get the best and most reliable results for the
classification, a variety of methodologies and models are trained and improved.",2024-10-21,"Praneeth Kumar T, Nidhi Srivastava, Rakshith Mahishi, Chayadevi M L",http://arxiv.org/pdf/2410.16519v1,cs.LG
RGMDT: Return-Gap-Minimizing Decision Tree Extraction in Non-Euclidean Metric Space,"Deep Reinforcement Learning (DRL) algorithms have achieved great success in
solving many challenging tasks while their black-box nature hinders
interpretability and real-world applicability, making it difficult for human
experts to interpret and understand DRL policies. Existing works on
interpretable reinforcement learning have shown promise in extracting decision
tree (DT) based policies from DRL policies with most focus on the single-agent
settings while prior attempts to introduce DT policies in multi-agent scenarios
mainly focus on heuristic designs which do not provide any quantitative
guarantees on the expected return. In this paper, we establish an upper bound
on the return gap between the oracle expert policy and an optimal decision tree
policy. This enables us to recast the DT extraction problem into a novel
non-euclidean clustering problem over the local observation and action values
space of each agent, with action values as cluster labels and the upper bound
on the return gap as clustering loss. Both the algorithm and the upper bound
are extended to multi-agent decentralized DT extractions by an
iteratively-grow-DT procedure guided by an action-value function conditioned on
the current DTs of other agents. Further, we propose the
Return-Gap-Minimization Decision Tree (RGMDT) algorithm, which is a
surprisingly simple design and is integrated with reinforcement learning
through the utilization of a novel Regularized Information Maximization loss.
Evaluations on tasks like D4RL show that RGMDT significantly outperforms
heuristic DT-based baselines and can achieve nearly optimal returns under given
DT complexity constraints (e.g., maximum number of DT nodes).",2024-10-21,"Jingdi Chen, Hanhan Zhou, Yongsheng Mei, Carlee Joe-Wong, Gina Adam, Nathaniel D. Bastian, Tian Lan",http://arxiv.org/pdf/2410.16517v1,cs.LG
Scalability of memorization-based machine unlearning,"Machine unlearning (MUL) focuses on removing the influence of specific
subsets of data (such as noisy, poisoned, or privacy-sensitive data) from
pretrained models. MUL methods typically rely on specialized forms of
fine-tuning. Recent research has shown that data memorization is a key
characteristic defining the difficulty of MUL. As a result, novel
memorization-based unlearning methods have been developed, demonstrating
exceptional performance with respect to unlearning quality, while maintaining
high performance for model utility. Alas, these methods depend on knowing the
memorization scores of data points and computing said scores is a notoriously
time-consuming process. This in turn severely limits the scalability of these
solutions and their practical impact for real-world applications. In this work,
we tackle these scalability challenges of state-of-the-art memorization-based
MUL algorithms using a series of memorization-score proxies. We first analyze
the profiles of various proxies and then evaluate the performance of
state-of-the-art (memorization-based) MUL algorithms in terms of both accuracy
and privacy preservation. Our empirical results show that these proxies can
introduce accuracy on par with full memorization-based unlearning while
dramatically improving scalability. We view this work as an important step
toward scalable and efficient machine unlearning.",2024-10-21,"Kairan Zhao, Peter Triantafillou",http://arxiv.org/pdf/2410.16516v2,cs.LG
Learning from others' mistakes: Finetuning machine translation models with span-level error annotations,"Despite growing interest in incorporating feedback to improve language
models, most efforts focus only on sequence-level annotations. In this work, we
explore the potential of utilizing fine-grained span-level annotations from
offline datasets to improve model quality. We develop a simple finetuning
algorithm, called Training with Annotations (TWA), to directly train machine
translation models on such annotated data. TWA utilizes targeted span-level
error information while also flexibly learning what to penalize within a span.
Moreover, TWA considers the overall trajectory of a sequence when deciding
which non-error spans to utilize as positive signals. Experiments on
English-German and Chinese-English machine translation show that TWA
outperforms baselines such as Supervised FineTuning on sequences filtered for
quality and Direct Preference Optimization on pairs constructed from the same
data.",2024-10-21,"Lily H. Zhang, Hamid Dadkhahi, Mara Finkelstein, Firas Trabelsi, Jiaming Luo, Markus Freitag",http://arxiv.org/pdf/2410.16509v1,cs.LG
ReLU neural network approximation to piecewise constant functions,"This paper studies the approximation property of ReLU neural networks (NNs)
to piecewise constant functions with unknown interfaces in bounded regions in
$\mathbb{R}^d$. Under the assumption that the discontinuity interface $\Gamma$
may be approximated by a connected series of hyperplanes with a prescribed
accuracy $\varepsilon >0$, we show that a three-layer ReLU NN is sufficient to
accurately approximate any piecewise constant function and establish its error
bound. Moreover, if the discontinuity interface is convex, an analytical
formula of the ReLU NN approximation with exact weights and biases is provided.",2024-10-21,"Zhiqiang Cai, Junpyo Choi, Min Liu",http://arxiv.org/pdf/2410.16506v1,cs.LG
Do Audio-Language Models Understand Linguistic Variations?,"Open-vocabulary audio language models (ALMs), like Contrastive Language Audio
Pretraining (CLAP), represent a promising new paradigm for audio-text retrieval
using natural language queries. In this paper, for the first time, we perform
controlled experiments on various benchmarks to show that existing ALMs
struggle to generalize to linguistic variations in textual queries. To address
this issue, we propose RobustCLAP, a novel and compute-efficient technique to
learn audio-language representations agnostic to linguistic variations.
Specifically, we reformulate the contrastive loss used in CLAP architectures by
introducing a multi-view contrastive learning objective, where paraphrases are
treated as different views of the same audio scene and use this for training.
Our proposed approach improves the text-to-audio retrieval performance of CLAP
by 0.8%-13% across benchmarks and enhances robustness to linguistic variation.",2024-10-21,"Ramaneswaran Selvakumar, Sonal Kumar, Hemant Kumar Giri, Nishit Anand, Ashish Seth, Sreyan Ghosh, Dinesh Manocha",http://arxiv.org/pdf/2410.16505v2,cs.LG
Forecasting Opioid Incidents for Rapid Actionable Data for Opioid Response in Kentucky,"We present efforts in the fields of machine learning and time series
forecasting to accurately predict counts of future opioid overdose incidents
recorded by Emergency Medical Services (EMS) in the state of Kentucky.
Forecasts are useful to state government agencies to properly prepare and
distribute resources related to opioid overdoses effectively. Our approach uses
county and district level aggregations of EMS opioid overdose encounters and
forecasts future counts for each month. A variety of additional covariates were
tested to determine their impact on the model's performance. Models with
different levels of complexity were evaluated to optimize training time and
accuracy. Our results show that when special precautions are taken to address
data sparsity, useful predictions can be generated with limited error by
utilizing yearly trends and covariance with additional data sources.",2024-10-21,"Aaron D. Mullen, Daniel Harris, Peter Rock, Svetla Slavova, Jeffery Talbert, V. K. Cody Bumgardner",http://arxiv.org/pdf/2410.16500v1,cs.LG
Building Conformal Prediction Intervals with Approximate Message Passing,"Conformal prediction has emerged as a powerful tool for building prediction
intervals that are valid in a distribution-free way. However, its evaluation
may be computationally costly, especially in the high-dimensional setting where
the dimensionality and sample sizes are both large and of comparable
magnitudes. To address this challenge in the context of generalized linear
regression, we propose a novel algorithm based on Approximate Message Passing
(AMP) to accelerate the computation of prediction intervals using full
conformal prediction, by approximating the computation of conformity scores.
Our work bridges a gap between modern uncertainty quantification techniques and
tools for high-dimensional problems involving the AMP algorithm. We evaluate
our method on both synthetic and real data, and show that it produces
prediction intervals that are close to the baseline methods, while being orders
of magnitude faster. Additionally, in the high-dimensional limit and under
assumptions on the data distribution, the conformity scores computed by AMP
converge to the one computed exactly, which allows theoretical study and
benchmarking of conformal methods in high dimensions.",2024-10-21,"Lucas Clarté, Lenka Zdeborová",http://arxiv.org/pdf/2410.16493v1,cs.LG
A Fusion-Driven Approach of Attention-Based CNN-BiLSTM for Protein Family Classification -- ProFamNet,"Advanced automated AI techniques allow us to classify protein sequences and
discern their biological families and functions. Conventional approaches for
classifying these protein families often focus on extracting N-Gram features
from the sequences while overlooking crucial motif information and the
interplay between motifs and neighboring amino acids. Recently, convolutional
neural networks have been applied to amino acid and motif data, even with a
limited dataset of well-characterized proteins, resulting in improved
performance. This study presents a model for classifying protein families using
the fusion of 1D-CNN, BiLSTM, and an attention mechanism, which combines
spatial feature extraction, long-term dependencies, and context-aware
representations. The proposed model (ProFamNet) achieved superior model
efficiency with 450,953 parameters and a compact size of 1.72 MB, outperforming
the state-of-the-art model with 4,578,911 parameters and a size of 17.47 MB.
Further, we achieved a higher F1 score (98.30% vs. 97.67%) with more instances
(271,160 vs. 55,077) in fewer training epochs (25 vs. 30).",2024-10-21,"Bahar Ali, Anwar Shah, Malik Niaz, Musadaq Mansoord, Sami Ullah, Muhammad Adnan",http://arxiv.org/pdf/2410.17293v1,cs.LG
LLM-TS Integrator: Integrating LLM for Enhanced Time Series Modeling,"Time series~(TS) modeling is essential in dynamic systems like weather
prediction and anomaly detection. Recent studies utilize Large Language Models
(LLMs) for TS modeling, leveraging their powerful pattern recognition
capabilities. These methods primarily position LLMs as the predictive backbone,
often omitting the mathematical modeling within traditional TS models, such as
periodicity. However, disregarding the potential of LLMs also overlooks their
pattern recognition capabilities. To address this gap, we introduce
\textit{LLM-TS Integrator}, a novel framework that effectively integrates the
capabilities of LLMs into traditional TS modeling. Central to this integration
is our \textit{mutual information} module. The core of this \textit{mutual
information} module is a traditional TS model enhanced with LLM-derived
insights for improved predictive abilities. This enhancement is achieved by
maximizing the mutual information between traditional model's TS
representations and LLM's textual representation counterparts, bridging the two
modalities. Moreover, we recognize that samples vary in importance for two
losses: traditional prediction and mutual information maximization. To address
this variability, we introduce the \textit{sample reweighting} module to
improve information utilization. This module assigns dual weights to each
sample: one for prediction loss and another for mutual information loss,
dynamically optimizing these weights via bi-level optimization. Our method
achieves state-of-the-art or comparable performance across five mainstream TS
tasks, including short-term and long-term forecasting, imputation,
classification, and anomaly detection.",2024-10-21,"Can Chen, Gabriel Oliveira, Hossein Sharifi Noghabi, Tristan Sylvain",http://arxiv.org/pdf/2410.16489v1,cs.LG
AEPL: Automated and Editable Prompt Learning for Brain Tumor Segmentation,"Brain tumor segmentation is crucial for accurate diagnosisand treatment
planning, but the small size and irregular shapeof tumors pose significant
challenges. Existing methods of-ten fail to effectively incorporate medical
domain knowledgesuch as tumor grade, which correlates with tumor
aggres-siveness and morphology, providing critical insights for moreaccurate
detection of tumor subregions during segmentation.We propose an Automated and
Editable Prompt Learning(AEPL) framework that integrates tumor grade into the
seg-mentation process by combining multi-task learning andprompt learning with
automatic and editable prompt gen-eration. Specifically, AEPL employs an
encoder to extractimage features for both tumor-grade prediction and
segmen-tation mask generation. The predicted tumor grades serveas
auto-generated prompts, guiding the decoder to produceprecise segmentation
masks. This eliminates the need formanual prompts while allowing clinicians to
manually editthe auto-generated prompts to fine-tune the segmentation,enhancing
both flexibility and precision. The proposed AEPLachieves state-of-the-art
performance on the BraTS 2018dataset, demonstrating its effectiveness and
clinical potential.The source code can be accessed online.",2024-10-21,"Yongheng Sun, Mingxia Liu, Chunfeng Lian",http://arxiv.org/pdf/2410.19847v1,cs.LG
Survival Multiarmed Bandits with Bootstrapping Methods,"The Multiarmed Bandits (MAB) problem has been extensively studied and has
seen many practical applications in a variety of fields. The Survival
Multiarmed Bandits (S-MAB) open problem is an extension which constrains an
agent to a budget that is directly related to observed rewards. As budget
depletion leads to ruin, an agent's objective is to both maximize expected
cumulative rewards and minimize the probability of ruin. This paper presents a
framework that addresses such a dual goal using an objective function balanced
by a ruin aversion component. Action values are estimated through a novel
approach which consists of bootstrapping samples from previously observed
rewards. In numerical experiments, the policies we present outperform
benchmarks from the literature.",2024-10-21,"Peter Veroutis, Frédéric Godin",http://arxiv.org/pdf/2410.16486v3,cs.LG
Identifying Sub-networks in Neural Networks via Functionally Similar Representations,"Providing human-understandable insights into the inner workings of neural
networks is an important step toward achieving more explainable and trustworthy
AI. Existing approaches to such mechanistic interpretability typically require
substantial prior knowledge and manual effort, with strategies tailored to
specific tasks. In this work, we take a step toward automating the
understanding of the network by investigating the existence of distinct
sub-networks. Specifically, we explore a novel automated and task-agnostic
approach based on the notion of functionally similar representations within
neural networks to identify similar and dissimilar layers, revealing potential
sub-networks. We achieve this by proposing, for the first time to our
knowledge, the use of Gromov-Wasserstein distance, which overcomes challenges
posed by varying distributions and dimensionalities across intermediate
representations, issues that complicate direct layer to layer comparisons. On
algebraic, language, and vision tasks, we observe the emergence of sub-groups
within neural network layers corresponding to functional abstractions. Through
downstream applications of model compression and fine-tuning, we show the
proposed approach offers meaningful insights into the behavior of neural
networks with minimal human and computational cost.",2024-10-21,"Tian Gao, Amit Dhurandhar, Karthikeyan Natesan Ramamurthy, Dennis Wei",http://arxiv.org/pdf/2410.16484v2,cs.LG
In Search of the Successful Interpolation: On the Role of Sharpness in CLIP Generalization,"\textit{Zero-shot} models like CLIP are often fine-tuned on a target dataset
to improve its accuracy further, but this can compromise out-of-distribution
(OOD) robustness. Robust Fine-Tuning (\texttt{RFT}
)~\citep{wortsman2021robust}, which interpolates between the \textit{zero-shot}
and \textit{fine-tuned} models, has been proposed to address this issue.
However, understanding when \texttt{RFT} actually improves OOD error remains
limited. In this work, we empirically investigate the robustness of
\texttt{RFT} in CLIP models, with a focus on the \textit{sharpness} of the CLIP
model during interpolation. First, we demonstrate that while sharpness may not
serve as a reliable indicator for predicting the generalization of modern
architectures like CLIP on OOD data, this challenges the conventional belief in
the generalization benefits of flat minima in foundation models. However, by
examining the role of the \textit{straggler layer} phenomenon, we show that,
unlike overall sharpness, the \textit{layer-wise} sharpness of
\textit{straggler} layers can reliably capture the generalization performance
of interpolated CLIP models on OOD data. Our extensive experiments reveal that
\textit{layer-wise} sharpness correlates with generalization in OOD accuracy
for \texttt{RFT}. Furthermore, we demonstrate that by inducing sparsity in the
\textit{straggler} layers, we can mitigate the \textit{failure mode} phenomenon
in \texttt{RFT}. To the best of our knowledge, this is the first work to study
the role of sharpness in the \textit{success} of interpolation in the weight
space of CLIP foundation models. Our code is available at
\url{https://github.com/alirezaabdollahpour/CLIP_Mode_Connectivity}.",2024-10-21,Alireza Abdollahpoorrostam,http://arxiv.org/pdf/2410.16476v1,cs.LG
QuickBind: A Light-Weight And Interpretable Molecular Docking Model,"Predicting a ligand's bound pose to a target protein is a key component of
early-stage computational drug discovery. Recent developments in machine
learning methods have focused on improving pose quality at the cost of model
runtime. For high-throughput virtual screening applications, this exposes a
capability gap that can be filled by moderately accurate but fast pose
prediction. To this end, we developed QuickBind, a light-weight pose prediction
algorithm. We assess QuickBind on widely used benchmarks and find that it
provides an attractive trade-off between model accuracy and runtime. To
facilitate virtual screening applications, we augment QuickBind with a binding
affinity module and demonstrate its capabilities for multiple
clinically-relevant drug targets. Finally, we investigate the mechanistic basis
by which QuickBind makes predictions and find that it has learned key
physicochemical properties of molecular docking, providing new insights into
how machine learning models generate protein-ligand poses. By virtue of its
simplicity, QuickBind can serve as both an effective virtual screening tool and
a minimal test bed for exploring new model architectures and innovations. Model
code and weights are available at https://github.com/aqlaboratory/QuickBind .",2024-10-21,"Wojtek Treyde, Seohyun Chris Kim, Nazim Bouatta, Mohammed AlQuraishi",http://arxiv.org/pdf/2410.16474v1,cs.LG
Evaluating the Performance of a D-Wave Quantum Annealing System for Feature Subset Selection in Software Defect Prediction,"Predicting software defects early in the development process not only
enhances the quality and reliability of the software but also decreases the
cost of development. A wide range of machine learning techniques can be
employed to create software defect prediction models, but the effectiveness and
accuracy of these models are often influenced by the choice of appropriate
feature subset. Since finding the optimal feature subset is computationally
intensive, heuristic and metaheuristic approaches are commonly employed to
identify near-optimal solutions within a reasonable time frame. Recently, the
quantum computing paradigm quantum annealing (QA) has been deployed to find
solutions to complex optimization problems. This opens up the possibility of
addressing the feature subset selection problem with a QA machine. Although
several strategies have been proposed for feature subset selection using a QA
machine, little exploration has been done regarding the viability of a QA
machine for feature subset selection in software defect prediction. This study
investigates the potential of D-Wave QA system for this task, where we
formulate a mutual information (MI)-based filter approach as an optimization
problem and utilize a D-Wave Quantum Processing Unit (QPU) solver as a QA
solver for feature subset selection. We evaluate the performance of this
approach using multiple software defect datasets from the AEEM, JIRA, and NASA
projects. We also utilize a D-Wave classical solver for comparative analysis.
Our experimental results demonstrate that QA-based feature subset selection can
enhance software defect prediction. Although the D-Wave QPU solver exhibits
competitive prediction performance with the classical solver in software defect
prediction, it significantly reduces the time required to identify the best
feature subset compared to its classical counterpart.",2024-10-21,"Ashis Kumar Mandal, Md Nadim, Chanchal K. Roy, Banani Roy, Kevin A. Schneider",http://arxiv.org/pdf/2410.16469v1,cs.LG
R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation,"Radiology report generation is crucial in medical imaging,but the manual
annotation process by physicians is time-consuming and labor-intensive,
necessitating the develop-ment of automatic report generation methods.
Existingresearch predominantly utilizes Transformers to generateradiology
reports, which can be computationally intensive,limiting their use in real
applications. In this work, we presentR2Gen-Mamba, a novel automatic radiology
report genera-tion method that leverages the efficient sequence processingof
the Mamba with the contextual benefits of Transformerarchitectures. Due to
lower computational complexity ofMamba, R2Gen-Mamba not only enhances training
and in-ference efficiency but also produces high-quality reports.Experimental
results on two benchmark datasets with morethan 210,000 X-ray image-report
pairs demonstrate the ef-fectiveness of R2Gen-Mamba regarding report quality
andcomputational efficiency compared with several state-of-the-art methods. The
source code can be accessed online.",2024-10-21,"Yongheng Sun, Yueh Z. Lee, Genevieve A. Woodard, Hongtu Zhu, Chunfeng Lian, Mingxia Liu",http://arxiv.org/pdf/2410.18135v1,cs.LG
STAR: A Simple Training-free Approach for Recommendations using Large Language Models,"Recent progress in large language models (LLMs) offers promising new
approaches for recommendation system tasks. While the current state-of-the-art
methods rely on fine-tuning LLMs to achieve optimal results, this process is
costly and introduces significant engineering complexities. Conversely, methods
that directly use LLMs without additional fine-tuning result in a large drop in
recommendation quality, often due to the inability to capture collaborative
information. In this paper, we propose a Simple Training-free Approach for
Recommendation (STAR), a framework that utilizes LLMs and can be applied to
various recommendation tasks without the need for fine-tuning, while
maintaining high quality recommendation performance. Our approach involves a
retrieval stage that uses semantic embeddings from LLMs combined with
collaborative user information to retrieve candidate items. We then apply an
LLM for pairwise ranking to enhance next-item prediction. Experimental results
on the Amazon Review dataset show competitive performance for next item
prediction, even with our retrieval stage alone. Our full method achieves
Hits@10 performance of +23.8% on Beauty, +37.5% on Toys & Games, and -1.8% on
Sports & Outdoors relative to the best supervised models. This framework offers
an effective alternative to traditional supervised models, highlighting the
potential of LLMs in recommendation systems without extensive training or
custom architectures.",2024-10-21,"Dong-Ho Lee, Adam Kraft, Long Jin, Nikhil Mehta, Taibai Xu, Lichan Hong, Ed H. Chi, Xinyang Yi",http://arxiv.org/pdf/2410.16458v2,cs.LG
Robust Feature Learning for Multi-Index Models in High Dimensions,"Recently, there have been numerous studies on feature learning with neural
networks, specifically on learning single- and multi-index models where the
target is a function of a low-dimensional projection of the input. Prior works
have shown that in high dimensions, the majority of the compute and data
resources are spent on recovering the low-dimensional projection; once this
subspace is recovered, the remainder of the target can be learned independently
of the ambient dimension. However, implications of feature learning in
adversarial settings remain unexplored. In this work, we take the first steps
towards understanding adversarially robust feature learning with neural
networks. Specifically, we prove that the hidden directions of a multi-index
model offer a Bayes optimal low-dimensional projection for robustness against
$\ell_2$-bounded adversarial perturbations under the squared loss, assuming
that the multi-index coordinates are statistically independent from the rest of
the coordinates. Therefore, robust learning can be achieved by first performing
standard feature learning, then robustly tuning a linear readout layer on top
of the standard representations. In particular, we show that adversarially
robust learning is just as easy as standard learning. Specifically, the
additional number of samples needed to robustly learn multi-index models when
compared to standard learning does not depend on dimensionality.",2024-10-21,"Alireza Mousavi-Hosseini, Adel Javanmard, Murat A. Erdogdu",http://arxiv.org/pdf/2410.16449v2,cs.LG
Improving Neuron-level Interpretability with White-box Language Models,"Neurons in auto-regressive language models like GPT-2 can be interpreted by
analyzing their activation patterns. Recent studies have shown that techniques
such as dictionary learning, a form of post-hoc sparse coding, enhance this
neuron-level interpretability. In our research, we are driven by the goal to
fundamentally improve neural network interpretability by embedding sparse
coding directly within the model architecture, rather than applying it as an
afterthought. In our study, we introduce a white-box transformer-like
architecture named Coding RAte TransformEr (CRATE), explicitly engineered to
capture sparse, low-dimensional structures within data distributions. Our
comprehensive experiments showcase significant improvements (up to 103%
relative improvement) in neuron-level interpretability across a variety of
evaluation metrics. Detailed investigations confirm that this enhanced
interpretability is steady across different layers irrespective of the model
size, underlining CRATE's robust performance in enhancing neural network
interpretability. Further analysis shows that CRATE's increased
interpretability comes from its enhanced ability to consistently and
distinctively activate on relevant tokens. These findings point towards a
promising direction for creating white-box foundation models that excel in
neuron-level interpretation.",2024-10-21,"Hao Bai, Yi Ma",http://arxiv.org/pdf/2410.16443v4,cs.LG
Fair Bilevel Neural Network (FairBiNN): On Balancing fairness and accuracy via Stackelberg Equilibrium,"The persistent challenge of bias in machine learning models necessitates
robust solutions to ensure parity and equal treatment across diverse groups,
particularly in classification tasks. Current methods for mitigating bias often
result in information loss and an inadequate balance between accuracy and
fairness. To address this, we propose a novel methodology grounded in bilevel
optimization principles. Our deep learning-based approach concurrently
optimizes for both accuracy and fairness objectives, and under certain
assumptions, achieving proven Pareto optimal solutions while mitigating bias in
the trained model. Theoretical analysis indicates that the upper bound on the
loss incurred by this method is less than or equal to the loss of the
Lagrangian approach, which involves adding a regularization term to the loss
function. We demonstrate the efficacy of our model primarily on tabular
datasets such as UCI Adult and Heritage Health. When benchmarked against
state-of-the-art fairness methods, our model exhibits superior performance,
advancing fairness-aware machine learning solutions and bridging the
accuracy-fairness gap. The implementation of FairBiNN is available on
https://github.com/yazdanimehdi/FairBiNN.",2024-10-21,"Mehdi Yazdani-Jahromi, Ali Khodabandeh Yalabadi, AmirArsalan Rajabi, Aida Tayebi, Ivan Garibay, Ozlem Ozmen Garibay",http://arxiv.org/pdf/2410.16432v2,cs.LG
"Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4","Machine-assisted theorem proving refers to the process of conducting
structured reasoning to automatically generate proofs for mathematical
theorems. Recently, there has been a surge of interest in using machine
learning models in conjunction with proof assistants to perform this task. In
this paper, we introduce Pantograph, a tool that provides a versatile interface
to the Lean 4 proof assistant and enables efficient proof search via powerful
search algorithms such as Monte Carlo Tree Search. In addition, Pantograph
enables high-level reasoning by enabling a more robust handling of Lean 4's
inference steps. We provide an overview of Pantograph's architecture and
features. We also report on an illustrative use case: using machine learning
models and proof sketches to prove Lean 4 theorems. Pantograph's innovative
features pave the way for more advanced machine learning models to perform
complex proof searches and high-level reasoning, equipping future researchers
to design more versatile and powerful theorem provers.",2024-10-21,"Leni Aniva, Chuyue Sun, Brando Miranda, Clark Barrett, Sanmi Koyejo",http://arxiv.org/pdf/2410.16429v2,cs.LG
Promoting cross-modal representations to improve multimodal foundation models for physiological signals,"Many healthcare applications are inherently multimodal, involving several
physiological signals. As sensors for these signals become more common,
improving machine learning methods for multimodal healthcare data is crucial.
Pretraining foundation models is a promising avenue for success. However,
methods for developing foundation models in healthcare are still in early
exploration and it is unclear which pretraining strategies are most effective
given the diversity of physiological signals. This is partly due to challenges
in multimodal health data: obtaining data across many patients is difficult and
costly, there is a lot of inter-subject variability, and modalities are often
heterogeneously informative across downstream tasks. Here, we explore these
challenges in the PhysioNet 2018 dataset. We use a masked autoencoding
objective to pretrain a multimodal model. We show that the model learns
representations that can be linearly probed for a diverse set of downstream
tasks. We hypothesize that cross-modal reconstruction objectives are important
for successful multimodal training, as they encourage the model to integrate
information across modalities. We demonstrate that modality dropout in the
input space improves performance across downstream tasks. We also find that
late-fusion models pretrained with contrastive learning objectives are less
effective across multiple tasks. Finally, we analyze the model's
representations, showing that attention weights become more cross-modal and
temporally aligned with our pretraining strategy. The learned embeddings also
become more distributed in terms of the modalities encoded by each unit.
Overall, our work demonstrates the utility of multimodal foundation models with
health data, even across diverse physiological data sources. We further argue
that explicit methods for inducing cross-modality may enhance multimodal
pretraining strategies.",2024-10-21,"Ching Fang, Christopher Sandino, Behrooz Mahasseni, Juri Minxha, Hadi Pouransari, Erdrin Azemi, Ali Moin, Ellen Zippi",http://arxiv.org/pdf/2410.16424v1,cs.LG
Position: Challenges and Opportunities for Differential Privacy in the U.S. Federal Government,"In this article, we seek to elucidate challenges and opportunities for
differential privacy within the federal government setting, as seen by a team
of differential privacy researchers, privacy lawyers, and data scientists
working closely with the U.S. government. After introducing differential
privacy, we highlight three significant challenges which currently restrict the
use of differential privacy in the U.S. government. We then provide two
examples where differential privacy can enhance the capabilities of government
agencies. The first example highlights how the quantitative nature of
differential privacy allows policy security officers to release multiple
versions of analyses with different levels of privacy. The second example,
which we believe is a novel realization, indicates that differential privacy
can be used to improve staffing efficiency in classified applications. We hope
that this article can serve as a nontechnical resource which can help frame
future action from the differential privacy community, privacy regulators,
security officers, and lawmakers.",2024-10-21,"Amol Khanna, Adam McCormick, Andre Nguyen, Chris Aguirre, Edward Raff",http://arxiv.org/pdf/2410.16423v1,cs.LG
BI-EqNO: Generalized Approximate Bayesian Inference with an Equivariant Neural Operator Framework,"Bayesian inference offers a robust framework for updating prior beliefs based
on new data using Bayes' theorem, but exact inference is often computationally
infeasible, necessitating approximate methods. Though widely used, these
methods struggle to estimate marginal likelihoods accurately, particularly due
to the rigid functional structures of deterministic models like Gaussian
processes and the limitations of small sample sizes in stochastic models like
the ensemble Kalman method. In this work, we introduce BI-EqNO, an equivariant
neural operator framework for generalized approximate Bayesian inference,
designed to enhance both deterministic and stochastic approaches. BI-EqNO
transforms priors into posteriors conditioned on observation data through
data-driven training. The framework is flexible, supporting diverse prior and
posterior representations with arbitrary discretizations and varying numbers of
observations. Crucially, BI-EqNO's architecture ensures (1) permutation
equivariance between prior and posterior representations, and (2) permutation
invariance with respect to observational data. We demonstrate BI-EqNO's utility
through two examples: (1) as a generalized Gaussian process (gGP) for
regression, and (2) as an ensemble neural filter (EnNF) for sequential data
assimilation. Results show that gGP outperforms traditional Gaussian processes
by offering a more flexible representation of covariance functions.
Additionally, EnNF not only outperforms the ensemble Kalman filter in
small-ensemble settings but also has the potential to function as a ""super""
ensemble filter, capable of representing and integrating multiple ensemble
filters for enhanced assimilation performance. This study highlights BI-EqNO's
versatility and effectiveness, improving Bayesian inference through data-driven
training while reducing computational costs across various applications.",2024-10-21,"Xu-Hui Zhou, Zhuo-Ran Liu, Heng Xiao",http://arxiv.org/pdf/2410.16420v1,cs.LG
Data Augmentation of Multivariate Sensor Time Series using Autoregressive Models and Application to Failure Prognostics,"This work presents a novel data augmentation solution for non-stationary
multivariate time series and its application to failure prognostics. The method
extends previous work from the authors which is based on time-varying
autoregressive processes. It can be employed to extract key information from a
limited number of samples and generate new synthetic samples in a way that
potentially improves the performance of PHM solutions. This is especially
valuable in situations of data scarcity which are very usual in PHM, especially
for failure prognostics. The proposed approach is tested based on the CMAPSS
dataset, commonly employed for prognostics experiments and benchmarks. An
AutoML approach from PHM literature is employed for automating the design of
the prognostics solution. The empirical evaluation provides evidence that the
proposed method can substantially improve the performance of PHM solutions.",2024-10-21,"Douglas Baptista de Souza, Bruno Paes Leao",http://arxiv.org/pdf/2410.16419v2,cs.LG
On conditional diffusion models for PDE simulations,"Modelling partial differential equations (PDEs) is of crucial importance in
science and engineering, and it includes tasks ranging from forecasting to
inverse problems, such as data assimilation. However, most previous numerical
and machine learning approaches that target forecasting cannot be applied
out-of-the-box for data assimilation. Recently, diffusion models have emerged
as a powerful tool for conditional generation, being able to flexibly
incorporate observations without retraining. In this work, we perform a
comparative study of score-based diffusion models for forecasting and
assimilation of sparse observations. In particular, we focus on diffusion
models that are either trained in a conditional manner, or conditioned after
unconditional training. We address the shortcomings of existing models by
proposing 1) an autoregressive sampling approach that significantly improves
performance in forecasting, 2) a new training strategy for conditional
score-based models that achieves stable performance over a range of history
lengths, and 3) a hybrid model which employs flexible pre-training conditioning
on initial conditions and flexible post-training conditioning to handle data
assimilation. We empirically show that these modifications are crucial for
successfully tackling the combination of forecasting and data assimilation, a
task commonly encountered in real-world scenarios.",2024-10-21,"Aliaksandra Shysheya, Cristiana Diaconu, Federico Bergamin, Paris Perdikaris, José Miguel Hernández-Lobato, Richard E. Turner, Emile Mathieu",http://arxiv.org/pdf/2410.16415v1,cs.LG
Integrating Reinforcement Learning with Foundation Models for Autonomous Robotics: Methods and Perspectives,"Foundation models (FMs), large deep learning models pre-trained on vast,
unlabeled datasets, exhibit powerful capabilities in understanding complex
patterns and generating sophisticated outputs. However, they often struggle to
adapt to specific tasks. Reinforcement learning (RL), which allows agents to
learn through interaction and feedback, offers a compelling solution.
Integrating RL with FMs enables these models to achieve desired outcomes and
excel at particular tasks. Additionally, RL can be enhanced by leveraging the
reasoning and generalization capabilities of FMs. This synergy is
revolutionizing various fields, including robotics. FMs, rich in knowledge and
generalization, provide robots with valuable information, while RL facilitates
learning and adaptation through real-world interactions.
  This survey paper comprehensively explores this exciting intersection,
examining how these paradigms can be integrated to advance robotic
intelligence. We analyze the use of foundation models as action planners, the
development of robotics-specific foundation models, and the mutual benefits of
combining FMs with RL. Furthermore, we present a taxonomy of integration
approaches, including large language models, vision-language models, diffusion
models, and transformer-based RL models. We also explore how RL can utilize
world representations learned from FMs to enhance robotic task execution.
  Our survey aims to synthesize current research and highlight key challenges
in robotic reasoning and control, particularly in the context of integrating
FMs and RL--two rapidly evolving technologies. By doing so, we seek to spark
future research and emphasize critical areas that require further investigation
to enhance robotics. We provide an updated collection of papers based on our
taxonomy, accessible on our open-source project website at:
https://github.com/clmoro/Robotics-RL-FMs-Integration.",2024-10-21,"Angelo Moroncelli, Vishal Soni, Asad Ali Shahid, Marco Maccarini, Marco Forgione, Dario Piga, Blerina Spahiu, Loris Roveda",http://arxiv.org/pdf/2410.16411v1,cs.LG
Hotel Booking Cancellation Prediction Using Applied Bayesian Models,"This study applies Bayesian models to predict hotel booking cancellations, a
key challenge affecting resource allocation, revenue, and customer satisfaction
in the hospitality industry. Using a Kaggle dataset with 36,285 observations
and 17 features, Bayesian Logistic Regression and Beta-Binomial models were
implemented. The logistic model, applied to 12 features and 5,000 randomly
selected observations, outperformed the Beta-Binomial model in predictive
accuracy. Key predictors included the number of adults, children, stay
duration, lead time, car parking space, room type, and special requests. Model
evaluation using Leave-One-Out Cross-Validation (LOO-CV) confirmed strong
alignment between observed and predicted outcomes, demonstrating the model's
robustness. Special requests and parking availability were found to be the
strongest predictors of cancellation. This Bayesian approach provides a
valuable tool for improving booking management and operational efficiency in
the hotel industry.",2024-10-21,"Md Asifuzzaman Jishan, Vikas Singh, Ayan Kumar Ghosh, Md Shahabub Alam, Khan Raqib Mahmud, Bijan Paul",http://arxiv.org/pdf/2410.16406v2,cs.LG
Simplicity Bias via Global Convergence of Sharpness Minimization,"The remarkable generalization ability of neural networks is usually
attributed to the implicit bias of SGD, which often yields models with lower
complexity using simpler (e.g. linear) and low-rank features. Recent works have
provided empirical and theoretical evidence for the bias of particular variants
of SGD (such as label noise SGD) toward flatter regions of the loss landscape.
Despite the folklore intuition that flat solutions are 'simple', the connection
with the simplicity of the final trained model (e.g. low-rank) is not well
understood. In this work, we take a step toward bridging this gap by studying
the simplicity structure that arises from minimizers of the sharpness for a
class of two-layer neural networks. We show that, for any high dimensional
training data and certain activations, with small enough step size, label noise
SGD always converges to a network that replicates a single linear feature
across all neurons; thereby, implying a simple rank one feature matrix. To
obtain this result, our main technical contribution is to show that label noise
SGD always minimizes the sharpness on the manifold of models with zero loss for
two-layer networks. Along the way, we discover a novel property -- a local
geodesic convexity -- of the trace of Hessian of the loss at approximate
stationary points on the manifold of zero loss, which links sharpness to the
geometry of the manifold. This tool may be of independent interest.",2024-10-21,"Khashayar Gatmiry, Zhiyuan Li, Sashank J. Reddi, Stefanie Jegelka",http://arxiv.org/pdf/2410.16401v1,cs.LG
Federated Communication-Efficient Multi-Objective Optimization,"We study a federated version of multi-objective optimization (MOO), where a
single model is trained to optimize multiple objective functions. MOO has been
extensively studied in the centralized setting but is less explored in
federated or distributed settings. We propose FedCMOO, a novel
communication-efficient federated multi-objective optimization (FMOO) algorithm
that improves the error convergence performance of the model compared to
existing approaches. Unlike prior works, the communication cost of FedCMOO does
not scale with the number of objectives, as each client sends a single
aggregated gradient to the central server. We provide a convergence analysis of
the proposed method for smooth and non-convex objective functions under milder
assumptions than in prior work. In addition, we introduce a variant of FedCMOO
that allows users to specify a preference over the objectives in terms of a
desired ratio of the final objective values. Through extensive experiments, we
demonstrate the superiority of our proposed method over baseline approaches.",2024-10-21,"Baris Askin, Pranay Sharma, Gauri Joshi, Carlee Joe-Wong",http://arxiv.org/pdf/2410.16398v2,cs.LG
Training of Scaffolded Language Models with Language Supervision: A Survey,"This survey organizes the intricate literature on the design and optimization
of emerging structures around post-trained LMs. We refer to this overarching
structure as scaffolded LMs and focus on LMs that are integrated into
multi-step processes with tools. We view scaffolded LMs as semi-parametric
models wherein we train non-parametric variables, including the prompt, tools,
and scaffold's code. In particular, they interpret instructions, use tools, and
receive feedback all in language. Recent works use an LM as an optimizer to
interpret language supervision and update non-parametric variables according to
intricate objectives. In this survey, we refer to this paradigm as training of
scaffolded LMs with language supervision. A key feature of non-parametric
training is the ability to learn from language. Parametric training excels in
learning from demonstration (supervised learning), exploration (reinforcement
learning), or observations (unsupervised learning), using well-defined loss
functions. Language-based optimization enables rich, interpretable, and
expressive objectives, while mitigating issues like catastrophic forgetting and
supporting compatibility with closed-source models. Furthermore, agents are
increasingly deployed as co-workers in real-world applications such as Copilot
in Office tools or software development. In these mixed-autonomy settings,
where control and decision-making are shared between human and AI, users point
out errors or suggest corrections. Accordingly, we discuss agents that
continuously improve by learning from this real-time, language-based feedback
and refer to this setting as streaming learning from language supervision.",2024-10-21,"Matthieu Lin, Jenny Sheng, Andrew Zhao, Shenzhi Wang, Yang Yue, Victor Shea Jay Huang, Huan Liu, Jun Liu, Gao Huang, Yong-Jin Liu",http://arxiv.org/pdf/2410.16392v2,cs.LG
LEGO-Learn: Label-Efficient Graph Open-Set Learning,"How can we train graph-based models to recognize unseen classes while keeping
labeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD)
detection aim to address this challenge by training models that can accurately
classify known, in-distribution (ID) classes while identifying and handling
previously unseen classes during inference. It is critical for high-stakes,
real-world applications where models frequently encounter unexpected data,
including finance, security, and healthcare. However, current GOL methods
assume access to many labeled ID samples, which is unrealistic for large-scale
graphs due to high annotation costs. In this paper, we propose LEGO-Learn
(Label-Efficient Graph Open-set Learning), a novel framework that tackles
open-set node classification on graphs within a given label budget by selecting
the most informative ID nodes. LEGO-Learn employs a GNN-based filter to
identify and exclude potential OOD nodes and then select highly informative ID
nodes for labeling using the K-Medoids algorithm. To prevent the filter from
discarding valuable ID examples, we introduce a classifier that differentiates
between the C known ID classes and an additional class representing OOD nodes
(hence, a C+1 classifier). This classifier uses a weighted cross-entropy loss
to balance the removal of OOD nodes while retaining informative ID nodes.
Experimental results on four real-world datasets demonstrate that LEGO-Learn
significantly outperforms leading methods, with up to a 6.62% improvement in ID
classification accuracy and a 7.49% increase in AUROC for OOD detection.",2024-10-21,"Haoyan Xu, Kay Liu, Zhengtao Yao, Philip S. Yu, Mengyuan Li, Kaize Ding, Yue Zhao",http://arxiv.org/pdf/2410.16386v2,cs.LG
Designing Robust Cyber-Defense Agents with Evolving Behavior Trees,"Modern network defense can benefit from the use of autonomous systems,
offloading tedious and time-consuming work to agents with standard and
learning-enabled components. These agents, operating on critical network
infrastructure, need to be robust and trustworthy to ensure defense against
adaptive cyber-attackers and, simultaneously, provide explanations for their
actions and network activity. However, learning-enabled components typically
use models, such as deep neural networks, that are not transparent in their
high-level decision-making leading to assurance challenges. Additionally,
cyber-defense agents must execute complex long-term defense tasks in a reactive
manner that involve coordination of multiple interdependent subtasks. Behavior
trees are known to be successful in modelling interpretable, reactive, and
modular agent policies with learning-enabled components. In this paper, we
develop an approach to design autonomous cyber defense agents using behavior
trees with learning-enabled components, which we refer to as Evolving Behavior
Trees (EBTs). We learn the structure of an EBT with a novel abstract cyber
environment and optimize learning-enabled components for deployment. The
learning-enabled components are optimized for adapting to various cyber-attacks
and deploying security mechanisms. The learned EBT structure is evaluated in a
simulated cyber environment, where it effectively mitigates threats and
enhances network visibility. For deployment, we develop a software architecture
for evaluating EBT-based agents in computer network defense scenarios. Our
results demonstrate that the EBT-based agent is robust to adaptive
cyber-attacks and provides high-level explanations for interpreting its
decisions and actions.",2024-10-21,"Nicholas Potteiger, Ankita Samaddar, Hunter Bergstrom, Xenofon Koutsoukos",http://arxiv.org/pdf/2410.16383v1,cs.LG
A Simple Model of Inference Scaling Laws,"Neural scaling laws have garnered significant interest due to their ability
to predict model performance as a function of increasing parameters, data, and
compute. In this work, we propose a simple statistical ansatz based on
memorization to study scaling laws in the context of inference, specifically
how performance improves with multiple inference attempts. We explore the
coverage, or pass@k metric, which measures the chance of success over repeated
attempts and provide a motivation for the observed functional form of the
inference scaling behavior of the coverage in large language models (LLMs) on
reasoning tasks. We then define an ""inference loss"", which exhibits a power law
decay as the number of trials increases, and connect this result with prompting
costs. We further test our construction by conducting experiments on a simple
generative model, and find that our predictions are in agreement with the
empirical coverage curves in a controlled setting. Our simple framework sets
the ground for incorporating inference scaling with other known scaling laws.",2024-10-21,Noam Levi,http://arxiv.org/pdf/2410.16377v2,cs.LG
xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs,"We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for
videos, particularly designed to efficiently capture temporal information over
multiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in
addition to the conventional visual tokenizer, which maps a sequence of tokens
over multiple frames into a compact set of visual tokens. This enables
BLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32
vs. 4608 tokens). We explore different types of temporal encoders, including
learnable spatio-temporal pooling as well as sequential models like Token
Turing Machines. We experimentally confirm that BLIP-3-Video obtains video
question-answering accuracies comparable to much larger state-of-the-art models
(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using
fewer visual tokens. The project website is at
https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html",2024-10-21,"Michael S. Ryoo, Honglu Zhou, Shrikant Kendre, Can Qin, Le Xue, Manli Shu, Silvio Savarese, Ran Xu, Caiming Xiong, Juan Carlos Niebles",http://arxiv.org/pdf/2410.16267v1,cs.LG
Revisiting Deep Feature Reconstruction for Logical and Structural Industrial Anomaly Detection,"Industrial anomaly detection is crucial for quality control and predictive
maintenance, but it presents challenges due to limited training data, diverse
anomaly types, and external factors that alter object appearances. Existing
methods commonly detect structural anomalies, such as dents and scratches, by
leveraging multi-scale features from image patches extracted through deep
pre-trained networks. However, significant memory and computational demands
often limit their practical application. Additionally, detecting logical
anomalies-such as images with missing or excess elements-requires an
understanding of spatial relationships that traditional patch-based methods
fail to capture. In this work, we address these limitations by focusing on Deep
Feature Reconstruction (DFR), a memory- and compute-efficient approach for
detecting structural anomalies. We further enhance DFR into a unified
framework, called ULSAD, which is capable of detecting both structural and
logical anomalies. Specifically, we refine the DFR training objective to
improve performance in structural anomaly detection, while introducing an
attention-based loss mechanism using a global autoencoder-like network to
handle logical anomaly detection. Our empirical evaluation across five
benchmark datasets demonstrates the performance of ULSAD in detecting and
localizing both structural and logical anomalies, outperforming eight
state-of-the-art methods. An extensive ablation study further highlights the
contribution of each component to the overall performance improvement. Our code
is available at https://github.com/sukanyapatra1997/ULSAD-2024.git",2024-10-21,"Sukanya Patra, Souhaib Ben Taieb",http://arxiv.org/pdf/2410.16255v1,cs.LG
Distribution Learning with Valid Outputs Beyond the Worst-Case,"Generative models at times produce ""invalid"" outputs, such as images with
generation artifacts and unnatural sounds. Validity-constrained distribution
learning attempts to address this problem by requiring that the learned
distribution have a provably small fraction of its mass in invalid parts of
space -- something which standard loss minimization does not always ensure. To
this end, a learner in this model can guide the learning via ""validity
queries"", which allow it to ascertain the validity of individual examples.
Prior work on this problem takes a worst-case stance, showing that proper
learning requires an exponential number of validity queries, and demonstrating
an improper algorithm which -- while generating guarantees in a wide-range of
settings -- makes an atypical polynomial number of validity queries. In this
work, we take a first step towards characterizing regimes where guaranteeing
validity is easier than in the worst-case. We show that when the data
distribution lies in the model class and the log-loss is minimized, the number
of samples required to ensure validity has a weak dependence on the validity
requirement. Additionally, we show that when the validity region belongs to a
VC-class, a limited number of validity queries are often sufficient.",2024-10-21,"Nick Rittler, Kamalika Chaudhuri",http://arxiv.org/pdf/2410.16253v1,cs.LG
Implicit Regularization for Tubal Tensor Factorizations via Gradient Descent,"We provide a rigorous analysis of implicit regularization in an
overparametrized tensor factorization problem beyond the lazy training regime.
For matrix factorization problems, this phenomenon has been studied in a number
of works. A particular challenge has been to design universal initialization
strategies which provably lead to implicit regularization in gradient-descent
methods. At the same time, it has been argued by Cohen et. al. 2016 that more
general classes of neural networks can be captured by considering tensor
factorizations. However, in the tensor case, implicit regularization has only
been rigorously established for gradient flow or in the lazy training regime.
In this paper, we prove the first tensor result of its kind for gradient
descent rather than gradient flow. We focus on the tubal tensor product and the
associated notion of low tubal rank, encouraged by the relevance of this model
for image data. We establish that gradient descent in an overparametrized
tensor factorization model with a small random initialization exhibits an
implicit bias towards solutions of low tubal rank. Our theoretical findings are
illustrated in an extensive set of numerical simulations show-casing the
dynamics predicted by our theory as well as the crucial role of using a small
random initialization.",2024-10-21,"Santhosh Karnik, Anna Veselovska, Mark Iwen, Felix Krahmer",http://arxiv.org/pdf/2410.16247v1,cs.LG
Large Language Models in Computer Science Education: A Systematic Literature Review,"Large language models (LLMs) are becoming increasingly better at a wide range
of Natural Language Processing tasks (NLP), such as text generation and
understanding. Recently, these models have extended their capabilities to
coding tasks, bridging the gap between natural languages (NL) and programming
languages (PL). Foundational models such as the Generative Pre-trained
Transformer (GPT) and LLaMA series have set strong baseline performances in
various NL and PL tasks. Additionally, several models have been fine-tuned
specifically for code generation, showing significant improvements in
code-related applications. Both foundational and fine-tuned models are
increasingly used in education, helping students write, debug, and understand
code. We present a comprehensive systematic literature review to examine the
impact of LLMs in computer science and computer engineering education. We
analyze their effectiveness in enhancing the learning experience, supporting
personalized education, and aiding educators in curriculum development. We
address five research questions to uncover insights into how LLMs contribute to
educational outcomes, identify challenges, and suggest directions for future
research.",2024-10-21,"Nishat Raihan, Mohammed Latif Siddiq, Joanna C. S. Santos, Marcos Zampieri",http://arxiv.org/pdf/2410.16349v1,cs.LG
"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report","In this paper, we introduce a novel Multi-Modal Contrastive Pre-training
Framework that synergistically combines X-rays, electrocardiograms (ECGs), and
radiology/cardiology reports. Our approach leverages transformers to encode
these diverse modalities into a unified representation space, aiming to enhance
diagnostic accuracy and facilitate comprehensive patient assessments. We
utilize LoRA-Peft to significantly reduce trainable parameters in the LLM and
incorporate recent linear attention dropping strategy in the Vision
Transformer(ViT) for smoother attention. Furthermore, we provide novel
multimodal attention explanations and retrieval for our model. To the best of
our knowledge, we are the first to propose an integrated model that combines
X-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing
contrastive loss, MoRE effectively aligns modality-specific features into a
coherent embedding, which supports various downstream tasks such as zero-shot
classification and multimodal retrieval. Employing our proposed methodology, we
achieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and
PtbXl downstream datasets, surpassing existing multimodal approaches. Our
proposed framework shows significant improvements in capturing intricate
inter-modal relationships and its robustness in medical diagnosis that
establishes a framework for future research in multimodal learning in the
healthcare sector.",2024-10-21,"Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le",http://arxiv.org/pdf/2410.16239v2,cs.LG
A Realistic Threat Model for Large Language Model Jailbreaks,"A plethora of jailbreaking attacks have been proposed to obtain harmful
responses from safety-tuned LLMs. In their original settings, these methods all
largely succeed in coercing the target output, but their attacks vary
substantially in fluency and computational effort. In this work, we propose a
unified threat model for the principled comparison of these methods. Our threat
model combines constraints in perplexity, measuring how far a jailbreak
deviates from natural text, and computational budget, in total FLOPs. For the
former, we build an N-gram model on 1T tokens, which, in contrast to
model-based perplexity, allows for an LLM-agnostic and inherently interpretable
evaluation. We adapt popular attacks to this new, realistic threat model, with
which we, for the first time, benchmark these attacks on equal footing. After a
rigorous comparison, we not only find attack success rates against safety-tuned
modern models to be lower than previously presented but also find that attacks
based on discrete optimization significantly outperform recent LLM-based
attacks. Being inherently interpretable, our threat model allows for a
comprehensive analysis and comparison of jailbreak attacks. We find that
effective attacks exploit and abuse infrequent N-grams, either selecting
N-grams absent from real-world text or rare ones, e.g. specific to code
datasets.",2024-10-21,"Valentyn Boreiko, Alexander Panfilov, Vaclav Voracek, Matthias Hein, Jonas Geiping",http://arxiv.org/pdf/2410.16222v1,cs.LG
On Creating an English-Thai Code-switched Machine Translation in Medical Domain,"Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",2024-10-21,"Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Sae-jia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat",http://arxiv.org/pdf/2410.16221v1,cs.LG
Comprehensive benchmarking of large language models for RNA secondary structure prediction,"Inspired by the success of large language models (LLM) for DNA and proteins,
several LLM for RNA have been developed recently. RNA-LLM uses large datasets
of RNA sequences to learn, in a self-supervised way, how to represent each RNA
base with a semantically rich numerical vector. This is done under the
hypothesis that obtaining high-quality RNA representations can enhance
data-costly downstream tasks. Among them, predicting the secondary structure is
a fundamental task for uncovering RNA functional mechanisms. In this work we
present a comprehensive experimental analysis of several pre-trained RNA-LLM,
comparing them for the RNA secondary structure prediction task in an unified
deep learning framework. The RNA-LLM were assessed with increasing
generalization difficulty on benchmark datasets. Results showed that two LLM
clearly outperform the other models, and revealed significant challenges for
generalization in low-homology scenarios.",2024-10-21,"L. I. Zablocki, L. A. Bugnon, M. Gerard, L. Di Persia, G. Stegmayer, D. H. Milone",http://arxiv.org/pdf/2410.16212v2,cs.LG
Compute-Constrained Data Selection,"Data selection can reduce the amount of training data needed to finetune
LLMs; however, the efficacy of data selection scales directly with its compute.
Motivated by the practical challenge of compute-constrained finetuning, we
consider the setting in which both the cost of selecting data and training are
budgeted for. We first formalize the problem of data selection with a
cost-aware utility function, and model the data selection problem as trading
off initial-selection cost for training gain. We run a comprehensive sweep of
experiments across multiple tasks, varying compute budget by scaling finetuning
tokens, model sizes, and data selection compute. Interestingly we find that
many powerful data selection methods are almost never compute-optimal, and that
cheaper data selection alternatives dominate both from a theoretical and
empirical perspective. For compute-optimal training, we find that perplexity
and gradient data selection require training-to-selection model size ratios of
5x and 10x, respectively.",2024-10-21,"Junjie Oscar Yin, Alexander M. Rush",http://arxiv.org/pdf/2410.16208v4,cs.LG
CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning,"Autonomous agents often face the challenge of interpreting uncertain natural
language instructions for planning tasks. Representing these instructions as
Linear Temporal Logic (LTL) enables planners to synthesize actionable plans. We
introduce CoT-TL, a data-efficient in-context learning framework for
translating natural language specifications into LTL representations. CoT-TL
addresses the limitations of large language models, which typically rely on
extensive fine-tuning data, by extending chain-of-thought reasoning and
semantic roles to align with the requirements of formal logic creation. This
approach enhances the transparency and rationale behind LTL generation,
fostering user trust. CoT-TL achieves state-of-the-art accuracy across three
diverse datasets in low-data scenarios, outperforming existing methods without
fine-tuning or intermediate translations. To improve reliability and minimize
hallucinations, we incorporate model checking to validate the syntax of the
generated LTL output. We further demonstrate CoT-TL's effectiveness through
ablation studies and evaluations on unseen LTL structures and formulas in a new
dataset. Finally, we validate CoT-TL's practicality by integrating it into a
QuadCopter for multi-step drone planning based on natural language
instructions.",2024-10-21,"Kumar Manas, Stefan Zwicklbauer, Adrian Paschke",http://arxiv.org/pdf/2410.16207v1,cs.LG
Machine Learning Approaches for Mental Illness Detection on Social Media: A Systematic Review of Biases and Methodological Challenges,"The global increase in mental illness requires innovative detection methods
for early intervention. Social media provides a valuable platform to identify
mental illness through user-generated content. This systematic review examines
machine learning (ML) models for detecting mental illness, with a particular
focus on depression, using social media data. It highlights biases and
methodological challenges encountered throughout the ML lifecycle. A search of
PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies
published after 2010. The Prediction model Risk Of Bias ASsessment Tool
(PROBAST) was utilized to assess methodological quality and risk of bias.
  The review reveals significant biases affecting model reliability and
generalizability. A predominant reliance on Twitter (63.8%) and
English-language content (over 90%) limits diversity, with most studies focused
on users from the United States and Europe. Non-probability sampling (80%)
limits representativeness. Only 23% explicitly addressed linguistic nuances
like negations, crucial for accurate sentiment analysis. Inconsistent
hyperparameter tuning (27.7%) and inadequate data partitioning (17%) risk
overfitting. While 74.5% used appropriate evaluation metrics for imbalanced
data, others relied on accuracy without addressing class imbalance, potentially
skewing results. Reporting transparency varied, often lacking critical
methodological details.
  These findings highlight the need to diversify data sources, standardize
preprocessing, ensure consistent model development, address class imbalance,
and enhance reporting transparency. By overcoming these challenges, future
research can develop more robust and generalizable ML models for depression
detection on social media, contributing to improved mental health outcomes
globally.",2024-10-21,"Yuchen Cao, Jianglai Dai, Zhongyan Wang, Yeyubei Zhang, Xiaorui Shen, Yunchong Liu, Yexin Tian",http://arxiv.org/pdf/2410.16204v3,cs.LG
Theoretical Limitations of Ensembles in the Age of Overparameterization,"Classic tree-based ensembles generalize better than any single decision tree.
In contrast, recent empirical studies find that modern ensembles of
(overparameterized) neural networks may not provide any inherent generalization
advantage over single but larger neural networks. This paper clarifies how
modern overparameterized ensembles differ from their classic underparameterized
counterparts, using ensembles of random feature (RF) regressors as a basis for
developing theory. In contrast to the underparameterized regime, where
ensembling typically induces regularization and increases generalization, we
prove that infinite ensembles of overparameterized RF regressors become
pointwise equivalent to (single) infinite-width RF regressors. This
equivalence, which is exact for ridgeless models and approximate for small
ridge penalties, implies that overparameterized ensembles and single large
models exhibit nearly identical generalization. As a consequence, we can
characterize the predictive variance amongst ensemble members, and demonstrate
that it quantifies the expected effects of increasing capacity rather than
capturing any conventional notion of uncertainty. Our results challenge common
assumptions about the advantages of ensembles in overparameterized settings,
prompting a reconsideration of how well intuitions from underparameterized
ensembles transfer to deep ensembles and the overparameterized regime.",2024-10-21,"Niclas Dern, John P. Cunningham, Geoff Pleiss",http://arxiv.org/pdf/2410.16201v1,cs.LG
A Trust-Region Method for Graphical Stein Variational Inference,"Stein variational inference (SVI) is a sample-based approximate Bayesian
inference technique that generates a sample set by jointly optimizing the
samples' locations to minimize an information-theoretic measure of discrepancy
with the target probability distribution. SVI thus provides a fast and
significantly more sample-efficient approach to Bayesian inference than
traditional (random-sampling-based) alternatives. However, the optimization
techniques employed in existing SVI methods struggle to address problems in
which the target distribution is high-dimensional, poorly-conditioned, or
non-convex, which severely limits the range of their practical applicability.
In this paper, we propose a novel trust-region optimization approach for SVI
that successfully addresses each of these challenges. Our method builds upon
prior work in SVI by leveraging conditional independences in the target
distribution (to achieve high-dimensional scaling) and second-order information
(to address poor conditioning), while additionally providing an effective
adaptive step control procedure, which is essential for ensuring convergence on
challenging non-convex optimization problems. Experimental results show our
method achieves superior numerical performance, both in convergence rate and
sample accuracy, and scales better in high-dimensional distributions, than
previous SVI techniques.",2024-10-21,"Liam Pavlovic, David M. Rosen",http://arxiv.org/pdf/2410.16195v1,cs.LG
MagicPIG: LSH Sampling for Efficient LLM Generation,"Large language models (LLMs) with long context windows have gained
significant attention. However, the KV cache, stored to avoid re-computation,
becomes a bottleneck. Various dynamic sparse or TopK-based attention
approximation methods have been proposed to leverage the common insight that
attention is sparse. In this paper, we first show that TopK attention itself
suffers from quality degradation in certain downstream tasks because attention
is not always as sparse as expected. Rather than selecting the keys and values
with the highest attention scores, sampling with theoretical guarantees can
provide a better estimation for attention output. To make the sampling-based
approximation practical in LLM generation, we propose MagicPIG, a heterogeneous
system based on Locality Sensitive Hashing (LSH). MagicPIG significantly
reduces the workload of attention computation while preserving high accuracy
for diverse tasks. MagicPIG stores the LSH hash tables and runs the attention
computation on the CPU, which allows it to serve longer contexts and larger
batch sizes with high approximation accuracy. MagicPIG can improve decoding
throughput by up to $5\times$ across various GPU hardware and achieve 54ms
decoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a
context of 96k tokens. The code is available at
https://github.com/Infini-AI-Lab/MagicPIG.",2024-10-21,"Zhuoming Chen, Ranajoy Sadhukhan, Zihao Ye, Yang Zhou, Jianyu Zhang, Niklas Nolte, Yuandong Tian, Matthijs Douze, Leon Bottou, Zhihao Jia, Beidi Chen",http://arxiv.org/pdf/2410.16179v4,cs.LG
DMM: Distributed Matrix Mechanism for Differentially-Private Federated Learning using Packed Secret Sharing,"Federated Learning (FL) has gained lots of traction recently, both in
industry and academia. In FL, a machine learning model is trained using data
from various end-users arranged in committees across several rounds. Since such
data can often be sensitive, a primary challenge in FL is providing privacy
while still retaining utility of the model. Differential Privacy (DP) has
become the main measure of privacy in the FL setting. DP comes in two flavors:
central and local. In the former, a centralized server is trusted to receive
the users' raw gradients from a training step, and then perturb their
aggregation with some noise before releasing the next version of the model. In
the latter (more private) setting, noise is applied on users' local devices,
and only the aggregation of users' noisy gradients is revealed even to the
server. Great strides have been made in increasing the privacy-utility
trade-off in the central DP setting, by utilizing the so-called matrix
mechanism. However, progress has been mostly stalled in the local DP setting.
In this work, we introduce the distributed matrix mechanism to achieve the
best-of-both-worlds; local DP and also better privacy-utility trade-off from
the matrix mechanism. We accomplish this by proposing a cryptographic protocol
that securely transfers sensitive values across rounds, which makes use of
packed secret sharing. This protocol accommodates the dynamic participation of
users per training round required by FL, including those that may drop out from
the computation. We provide experiments which show that our mechanism indeed
significantly improves the privacy-utility trade-off of FL models compared to
previous local DP mechanisms, with little added overhead.",2024-10-21,"Alexander Bienstock, Ujjwal Kumar, Antigoni Polychroniadou",http://arxiv.org/pdf/2410.16161v1,cs.LG
Metric as Transform: Exploring beyond Affine Transform for Interpretable Neural Network,"Artificial Neural Networks of varying architectures are generally paired with
affine transformation at the core. However, we find dot product neurons with
global influence less interpretable as compared to local influence of euclidean
distance (as used in Radial Basis Function Network). In this work, we explore
the generalization of dot product neurons to $l^p$-norm, metrics, and beyond.
We find that metrics as transform performs similarly to affine transform when
used in MultiLayer Perceptron or Convolutional Neural Network. Moreover, we
explore various properties of Metrics, compare it with Affine, and present
multiple cases where metrics seem to provide better interpretability. We
develop an interpretable local dictionary based Neural Networks and use it to
understand and reject adversarial examples.",2024-10-21,Suman Sapkota,http://arxiv.org/pdf/2410.16159v1,cs.LG
Unsupervised Replay Strategies for Continual Learning with Limited Data,"Artificial neural networks (ANNs) show limited performance with scarce or
imbalanced training data and face challenges with continuous learning, such as
forgetting previously learned data after new tasks training. In contrast, the
human brain can learn continuously and from just a few examples. This research
explores the impact of 'sleep', an unsupervised phase incorporating stochastic
activation with local Hebbian learning rules, on ANNs trained incrementally
with limited and imbalanced datasets, specifically MNIST and Fashion MNIST. We
discovered that introducing a sleep phase significantly enhanced accuracy in
models trained with limited data. When a few tasks were trained sequentially,
sleep replay not only rescued previously learned information that had been
catastrophically forgetting following new task training but often enhanced
performance in prior tasks, especially those trained with limited data. This
study highlights the multifaceted role of sleep replay in augmenting learning
efficiency and facilitating continual learning in ANNs.",2024-10-21,"Anthony Bazhenov, Pahan Dewasurendra, Giri P. Krishnan, Jean Erik Delanois",http://arxiv.org/pdf/2410.16154v1,cs.LG
Disease Outbreak Detection and Forecasting: A Review of Methods and Data Sources,"Infectious diseases occur when pathogens from other individuals or animals
infect a person, resulting in harm to both individuals and society as a whole.
The outbreak of such diseases can pose a significant threat to human health.
However, early detection and tracking of these outbreaks have the potential to
reduce the mortality impact. To address these threats, public health
authorities have endeavored to establish comprehensive mechanisms for
collecting disease data. Many countries have implemented infectious disease
surveillance systems, with the detection of epidemics being a primary
objective. The clinical healthcare system, local/state health agencies, federal
agencies, academic/professional groups, and collaborating governmental entities
all play pivotal roles within this system. Moreover, nowadays, search engines
and social media platforms can serve as valuable tools for monitoring disease
trends. The Internet and social media have become significant platforms where
users share information about their preferences and relationships. This
real-time information can be harnessed to gauge the influence of ideas and
societal opinions, making it highly useful across various domains and research
areas, such as marketing campaigns, financial predictions, and public health,
among others. This article provides a review of the existing standard methods
developed by researchers for detecting outbreaks using time series data. These
methods leverage various data sources, including conventional data sources and
social media data or Internet data sources. The review particularly
concentrates on works published within the timeframe of 2015 to 2022.",2024-10-21,"Ghazaleh Babanejaddehaki, Aijun An, Manos Papagelis",http://arxiv.org/pdf/2410.17290v1,cs.LG
Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models,"Using image models naively for solving inverse video problems often suffers
from flickering, texture-sticking, and temporal inconsistency in generated
videos. To tackle these problems, in this paper, we view frames as continuous
functions in the 2D space, and videos as a sequence of continuous warping
transformations between different frames. This perspective allows us to train
function space diffusion models only on images and utilize them to solve
temporally correlated inverse problems. The function space diffusion models
need to be equivariant with respect to the underlying spatial transformations.
To ensure temporal consistency, we introduce a simple post-hoc test-time
guidance towards (self)-equivariant solutions. Our method allows us to deploy
state-of-the-art latent diffusion models such as Stable Diffusion XL to solve
video inverse problems. We demonstrate the effectiveness of our method for
video inpainting and $8\times$ video super-resolution, outperforming existing
techniques based on noise transformations. We provide generated video results:
https://giannisdaras.github.io/warped_diffusion.github.io/.",2024-10-21,"Giannis Daras, Weili Nie, Karsten Kreis, Alex Dimakis, Morteza Mardani, Nikola Borislavov Kovachki, Arash Vahdat",http://arxiv.org/pdf/2410.16152v2,cs.LG
"Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance","Recent advancements have scaled neural networks to unprecedented sizes,
achieving remarkable performance across a wide range of tasks. However,
deploying these large-scale models on resource-constrained devices poses
significant challenges due to substantial storage and computational
requirements. Neural network pruning has emerged as an effective technique to
mitigate these limitations by reducing model size and complexity. In this
paper, we introduce an intuitive and interpretable pruning method based on
activation statistics, rooted in information theory and statistical analysis.
Our approach leverages the statistical properties of neuron activations to
identify and remove weights with minimal contributions to neuron outputs.
Specifically, we build a distribution of weight contributions across the
dataset and utilize its parameters to guide the pruning process. Furthermore,
we propose a Pruning-aware Training strategy that incorporates an additional
regularization term to enhance the effectiveness of our pruning method.
Extensive experiments on multiple datasets and network architectures
demonstrate that our method consistently outperforms several baseline and
state-of-the-art pruning techniques.",2024-10-21,"Mostafa Hussien, Mahmoud Afifi, Kim Khoa Nguyen, Mohamed Cheriet",http://arxiv.org/pdf/2410.16151v1,cs.LG
Modeling Structured Data Learning with Restricted Boltzmann Machines in the Teacher-Student Setting,"Restricted Boltzmann machines (RBM) are generative models capable to learn
data with a rich underlying structure. We study the teacher-student setting
where a student RBM learns structured data generated by a teacher RBM. The
amount of structure in the data is controlled by adjusting the number of hidden
units of the teacher and the correlations in the rows of the weights, a.k.a.
patterns. In the absence of correlations, we validate the conjecture that the
performance is independent of the number of teacher patters and hidden units of
the student RBMs, and we argue that the teacher-student setting can be used as
a toy model for studying the lottery ticket hypothesis. Beyond this regime, we
find that the critical amount of data required to learn the teacher patterns
decreases with both their number and correlations. In both regimes, we find
that, even with a relatively large dataset, it becomes impossible to learn the
teacher patterns if the inference temperature used for regularization is kept
too low. In our framework, the student can learn teacher patterns one-to-one or
many-to-one, generalizing previous findings about the teacher-student setting
with two hidden units to any arbitrary finite number of hidden units.",2024-10-21,"Robin Thériault, Francesco Tosello, Daniele Tantari",http://arxiv.org/pdf/2410.16150v2,cs.LG
Towards Combating Frequency Simplicity-biased Learning for Domain Generalization,"Domain generalization methods aim to learn transferable knowledge from source
domains that can generalize well to unseen target domains. Recent studies show
that neural networks frequently suffer from a simplicity-biased learning
behavior which leads to over-reliance on specific frequency sets, namely as
frequency shortcuts, instead of semantic information, resulting in poor
generalization performance. Despite previous data augmentation techniques
successfully enhancing generalization performances, they intend to apply more
frequency shortcuts, thereby causing hallucinations of generalization
improvement. In this paper, we aim to prevent such learning behavior of
applying frequency shortcuts from a data-driven perspective. Given the
theoretical justification of models' biased learning behavior on different
spatial frequency components, which is based on the dataset frequency
properties, we argue that the learning behavior on various frequency components
could be manipulated by changing the dataset statistical structure in the
Fourier domain. Intuitively, as frequency shortcuts are hidden in the dominant
and highly dependent frequencies of dataset structure, dynamically perturbating
the over-reliance frequency components could prevent the application of
frequency shortcuts. To this end, we propose two effective data augmentation
modules designed to collaboratively and adaptively adjust the frequency
characteristic of the dataset, aiming to dynamically influence the learning
behavior of the model and ultimately serving as a strategy to mitigate shortcut
learning. Code is available at AdvFrequency
(https://github.com/C0notSilly/AdvFrequency).",2024-10-21,"Xilin He, Jingyu Hu, Qinliang Lin, Cheng Luo, Weicheng Xie, Siyang Song, Muhammad Haris Khan, Linlin Shen",http://arxiv.org/pdf/2410.16146v1,cs.LG
Theoretical Insights into Line Graph Transformation on Graph Learning,"Line graph transformation has been widely studied in graph theory, where each
node in a line graph corresponds to an edge in the original graph. This has
inspired a series of graph neural networks (GNNs) applied to transformed line
graphs, which have proven effective in various graph representation learning
tasks. However, there is limited theoretical study on how line graph
transformation affects the expressivity of GNN models. In this study, we focus
on two types of graphs known to be challenging to the Weisfeiler-Leman (WL)
tests: Cai-F\""urer-Immerman (CFI) graphs and strongly regular graphs, and show
that applying line graph transformation helps exclude these challenging graph
properties, thus potentially assist WL tests in distinguishing these graphs. We
empirically validate our findings by conducting a series of experiments that
compare the accuracy and efficiency of graph isomorphism tests and GNNs on both
line-transformed and original graphs across these graph structure types.",2024-10-21,"Fan Yang, Xingyue Huang",http://arxiv.org/pdf/2410.16138v2,cs.LG
Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs,"To date, 2:4 sparsity has stood as the only sparse pattern that can be
accelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often
possesses low actual speedups ($\leq 1.3$) and requires fixed sparse ratios,
meaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,
do not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity
is promising in addressing these limitations of 2:4 sparsity. However,
regarding accuracy, the effects of V:N:M sparsity on broader Transformer
models, such as vision Transformers and large language models (LLMs), are
largely unexamined. Moreover, Some specific issues related to V:N:M sparsity,
such as how to select appropriate V and M values, remain unresolved. In this
study, we thoroughly investigate the application of V:N:M sparsity in vision
models and LLMs across multiple tasks, from pertaining to downstream tasks. We
propose three key approaches to enhance the applicability and accuracy of
V:N:M-sparse Transformers, including heuristic V and M selection,
V:N:M-specific channel permutation, and three-staged LoRA training techniques.
Experimental results show that, with our methods, the DeiT-small achieves
lossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy
even at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5
sparsity performs comparably or better than training-free 2:4 sparse
alternatives on downstream tasks. More importantly, V:N:M-sparse Transformers
offer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.
Overall, our exploration largely facilitates the V:N:M sparsity to act as a
truly effective acceleration solution for Transformers in cost-sensitive
inference scenarios.",2024-10-21,"Kang Zhao, Tao Yuan, Han Bao, Zhenfeng Su, Chang Gao, Zhaofeng Sun, Zichen Liang, Liping Jing, Jianfei Chen",http://arxiv.org/pdf/2410.16135v2,cs.LG
SMART: Self-learning Meta-strategy Agent for Reasoning Tasks,"Tasks requiring deductive reasoning, especially those involving multiple
steps, often demand adaptive strategies such as intermediate generation of
rationales or programs, as no single approach is universally optimal. While
Language Models (LMs) can enhance their outputs through iterative
self-refinement and strategy adjustments, they frequently fail to apply the
most effective strategy in their first attempt. This inefficiency raises the
question: Can LMs learn to select the optimal strategy in the first attempt,
without a need for refinement? To address this challenge, we introduce SMART
(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that
enables LMs to autonomously learn and select the most effective strategies for
various reasoning tasks. We model the strategy selection process as a Markov
Decision Process and leverage reinforcement learning-driven continuous
self-improvement to allow the model to find the suitable strategy to solve a
given task. Unlike traditional self-refinement methods that rely on multiple
inference passes or external feedback, SMART allows an LM to internalize the
outcomes of its own reasoning processes and adjust its strategy accordingly,
aiming for correct solutions on the first attempt. Our experiments across
various reasoning datasets and with different model architectures demonstrate
that SMART significantly enhances the ability of models to choose optimal
strategies without external guidance (+15 points on the GSM8K dataset). By
achieving higher accuracy with a single inference pass, SMART not only improves
performance but also reduces computational costs for refinement-based
strategies, paving the way for more efficient and intelligent reasoning in LMs.",2024-10-21,"Rongxing Liu, Kumar Shridhar, Manish Prajapat, Patrick Xia, Mrinmaya Sachan",http://arxiv.org/pdf/2410.16128v1,cs.LG
MNIST-Nd: a set of naturalistic datasets to benchmark clustering across dimensions,"Driven by advances in recording technology, large-scale high-dimensional
datasets have emerged across many scientific disciplines. Especially in
biology, clustering is often used to gain insights into the structure of such
datasets, for instance to understand the organization of different cell types.
However, clustering is known to scale poorly to high dimensions, even though
the exact impact of dimensionality is unclear as current benchmark datasets are
mostly two-dimensional. Here we propose MNIST-Nd, a set of synthetic datasets
that share a key property of real-world datasets, namely that individual
samples are noisy and clusters do not perfectly separate. MNIST-Nd is obtained
by training mixture variational autoencoders with 2 to 64 latent dimensions on
MNIST, resulting in six datasets with comparable structure but varying
dimensionality. It thus offers the chance to disentangle the impact of
dimensionality on clustering. Preliminary common clustering algorithm
benchmarks on MNIST-Nd suggest that Leiden is the most robust for growing
dimensions.",2024-10-21,"Polina Turishcheva, Laura Hansel, Martin Ritzert, Marissa A. Weis, Alexander S. Ecker",http://arxiv.org/pdf/2410.16124v1,cs.LG
Integer linear programming for unsupervised training set selection in molecular machine learning,"Integer linear programming (ILP) is an elegant approach to solve linear
optimization problems, naturally described using integer decision variables.
Within the context of physics-inspired machine learning applied to chemistry,
we demonstrate the relevance of an ILP formulation to select molecular training
sets for predictions of size-extensive properties. We show that our algorithm
outperforms existing unsupervised training set selection approaches, especially
when predicting properties of molecules larger than those present in the
training set. We argue that the reason for the improved performance is due to
the selection that is based on the notion of local similarity (i.e., per-atom)
and a unique ILP approach that finds optimal solutions efficiently. Altogether,
this work provides a practical algorithm to improve the performance of
physics-inspired machine learning models and offers insights into the
conceptual differences with existing training set selection approaches.",2024-10-21,"Matthieu Haeberle, Puck van Gerwen, Ruben Laplaza, Ksenia R. Briling, Jan Weinreich, Friedrich Eisenbrand, Clemence Corminboeuf",http://arxiv.org/pdf/2410.16122v2,cs.LG
Extracting Spatiotemporal Data from Gradients with Large Language Models,"Recent works show that sensitive user data can be reconstructed from gradient
updates, breaking the key privacy promise of federated learning. While success
was demonstrated primarily on image data, these methods do not directly
transfer to other domains, such as spatiotemporal data. To understand privacy
risks in spatiotemporal federated learning, we first propose Spatiotemporal
Gradient Inversion Attack (ST-GIA), a gradient attack algorithm tailored to
spatiotemporal data that successfully reconstructs the original location from
gradients. Furthermore, the absence of priors in attacks on spatiotemporal data
has hindered the accurate reconstruction of real client data. To address this
limitation, we propose ST-GIA+, which utilizes an auxiliary language model to
guide the search for potential locations, thereby successfully reconstructing
the original data from gradients. In addition, we design an adaptive defense
strategy to mitigate gradient inversion attacks in spatiotemporal federated
learning. By dynamically adjusting the perturbation levels, we can offer
tailored protection for varying rounds of training data, thereby achieving a
better trade-off between privacy and utility than current state-of-the-art
methods. Through intensive experimental analysis on three real-world datasets,
we reveal that the proposed defense strategy can well preserve the utility of
spatiotemporal federated learning with effective security protection.",2024-10-21,"Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, Masatoshi Yoshikawa",http://arxiv.org/pdf/2410.16121v1,cs.LG
SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation,"We introduce SeaDAG, a semi-autoregressive diffusion model for conditional
generation of Directed Acyclic Graphs (DAGs). Considering their inherent
layer-wise structure, we simulate layer-wise autoregressive generation by
designing different denoising speed for different layers. Unlike conventional
autoregressive generation that lacks a global graph structure view, our method
maintains a complete graph structure at each diffusion step, enabling
operations such as property control that require the full graph structure.
Leveraging this capability, we evaluate the DAG properties during training by
employing a graph property decoder. We explicitly train the model to learn
graph conditioning with a condition loss, which enhances the diffusion model's
capacity to generate graphs that are both realistic and aligned with specified
properties. We evaluate our method on two representative conditional DAG
generation tasks: (1) circuit generation from truth tables, where precise DAG
structures are crucial for realizing circuit functionality, and (2) molecule
generation based on quantum properties. Our approach demonstrates promising
results, generating high-quality and realistic DAGs that closely align with
given conditions.",2024-10-21,"Xinyi Zhou, Xing Li, Yingzhao Lian, Yiwen Wang, Lei Chen, Mingxuan Yuan, Jianye Hao, Guangyong Chen, Pheng Ann Heng",http://arxiv.org/pdf/2410.16119v1,cs.LG
Statistical Inference for Temporal Difference Learning with Linear Function Approximation,"Statistical inference with finite-sample validity for the value function of a
given policy in Markov decision processes (MDPs) is crucial for ensuring the
reliability of reinforcement learning. Temporal Difference (TD) learning,
arguably the most widely used algorithm for policy evaluation, serves as a
natural framework for this purpose. In this paper, we study the consistency
properties of TD learning with Polyak-Ruppert averaging and linear function
approximation, and obtain three significant improvements over existing results.
First, we derive a novel sharp high-dimensional probability convergence
guarantee that depends explicitly on the asymptotic variance and holds under
weak conditions. We further establish refined high-dimensional Berry-Esseen
bounds over the class of convex sets that guarantee faster rates than those in
the literature. Finally, we propose a plug-in estimator for the asymptotic
covariance matrix, designed for efficient online computation. These results
enable the construction of confidence regions and simultaneous confidence
intervals for the linear parameters of the value function, with guaranteed
finite-sample coverage. We demonstrate the applicability of our theoretical
findings through numerical experiments.",2024-10-21,"Weichen Wu, Gen Li, Yuting Wei, Alessandro Rinaldo",http://arxiv.org/pdf/2410.16106v2,cs.LG
Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning,"Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs
typically exhibit a tendency to prioritize the learning of lower-frequency
components of a function, struggling to capture its high-frequency features.
This paper is to address this issue. Notice that a function having only low
frequency components may be well-represented by a shallow neural network (SNN),
a network having only a few layers. By observing that composition of low
frequency functions can effectively approximate a high-frequency function, we
propose to learn a function containing high-frequency components by composing
several SNNs, each of which learns certain low-frequency information from the
given data. We implement the proposed idea by exploiting the multi-grade deep
learning (MGDL) model, a recently introduced model that trains a DNN
incrementally, grade by grade, a current grade learning from the residue of the
previous grade only an SNN composed with the SNNs trained in the preceding
grades as features. We apply MGDL to synthetic, manifold, colored images, and
MNIST datasets, all characterized by presence of high-frequency features. Our
study reveals that MGDL excels at representing functions containing
high-frequency information. Specifically, the neural networks learned in each
grade adeptly capture some low-frequency information, allowing their
compositions with SNNs learned in the previous grades effectively representing
the high-frequency features. Our experimental results underscore the efficacy
of MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,
we offer insights into overcoming spectral bias limitation of DNNs, thereby
enhancing the performance and applicability of deep learning models in tasks
requiring the representation of high-frequency information. This study confirms
that the proposed method offers a promising solution to address the spectral
bias of DNNs.",2024-10-21,"Ronglong Fang, Yuesheng Xu",http://arxiv.org/pdf/2410.16105v1,cs.LG
LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics,"We introduce LDAdam, a memory-efficient optimizer for training large models,
that performs adaptive optimization steps within lower dimensional subspaces,
while consistently exploring the full parameter space during training. This
strategy keeps the optimizer's memory footprint to a fraction of the model
size. LDAdam relies on a new projection-aware update rule for the optimizer
states that allows for transitioning between subspaces, i.e., estimation of the
statistics of the projected gradients. To mitigate the errors due to low-rank
projection, LDAdam integrates a new generalized error feedback mechanism, which
explicitly accounts for both gradient and optimizer state compression. We prove
the convergence of LDAdam under standard assumptions, and show that LDAdam
allows for accurate and efficient fine-tuning and pre-training of language
models. Code is available at https://github.com/IST-DASLab/LDAdam",2024-10-21,"Thomas Robert, Mher Safaryan, Ionut-Vlad Modoranu, Dan Alistarh",http://arxiv.org/pdf/2410.16103v4,cs.LG
ExDBN: Exact learning of Dynamic Bayesian Networks,"Causal learning from data has received much attention in recent years. One
way of capturing causal relationships is by utilizing Bayesian networks. There,
one recovers a weighted directed acyclic graph, in which random variables are
represented by vertices, and the weights associated with each edge represent
the strengths of the causal relationships between them. This concept is
extended to capture dynamic effects by introducing a dependency on past data,
which may be captured by the structural equation model, which is utilized in
the present contribution to formulate a score-based learning approach. A
mixed-integer quadratic program is formulated and an algorithmic solution
proposed, in which the pre-generation of exponentially many acyclicity
constraints is avoided by utilizing the so-called branch-and-cut (""lazy
constraint"") method. Comparing the novel approach to the state of the art, we
show that the proposed approach turns out to produce excellent results when
applied to small and medium-sized synthetic instances of up to 25 time-series.
Lastly, two interesting applications in bio-science and finance, to which the
method is directly applied, further stress the opportunities in developing
highly accurate, globally convergent solvers that can handle modest instances.",2024-10-21,"Pavel Rytir, Ales Wodecki, Georgios Korpas, Jakub Marecek",http://arxiv.org/pdf/2410.16100v2,cs.LG
Enhancing Trust and Safety in Digital Payments: An LLM-Powered Approach,"Digital payment systems have revolutionized financial transactions, offering
unparalleled convenience and accessibility to users worldwide. However, the
increasing popularity of these platforms has also attracted malicious actors
seeking to exploit their vulnerabilities for financial gain. To address this
challenge, robust and adaptable scam detection mechanisms are crucial for
maintaining the trust and safety of digital payment ecosystems. This paper
presents a comprehensive approach to scam detection, focusing on the Unified
Payments Interface (UPI) in India, Google Pay (GPay) as a specific use case.
The approach leverages Large Language Models (LLMs) to enhance scam
classification accuracy and designs a digital assistant to aid human reviewers
in identifying and mitigating fraudulent activities. The results demonstrate
the potential of LLMs in augmenting existing machine learning models and
improving the efficiency, accuracy, quality, and consistency of scam reviews,
ultimately contributing to a safer and more secure digital payment landscape.
Our evaluation of the Gemini Ultra model on curated transaction data showed a
93.33% accuracy in scam classification. Furthermore, the model demonstrated 89%
accuracy in generating reasoning for these classifications. A promising fact,
the model identified 32% new accurate reasons for suspected scams that human
reviewers had not included in the review notes.",2024-10-21,"Devendra Dahiphale, Naveen Madiraju, Justin Lin, Rutvik Karve, Monu Agrawal, Anant Modwal, Ramanan Balakrishnan, Shanay Shah, Govind Kaushal, Priya Mandawat, Prakash Hariramani, Arif Merchant",http://arxiv.org/pdf/2410.19845v1,cs.LG
CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts,"Large language models (LLM) have been attracting much attention from the
community recently, due to their remarkable performance in all kinds of
downstream tasks. According to the well-known scaling law, scaling up a dense
LLM enhances its capabilities, but also significantly increases the
computational complexity. Mixture-of-Experts (MoE) models address that by
allowing the model size to grow without substantially raising training or
inference costs. Yet MoE models face challenges regarding knowledge sharing
among experts, making their performance somehow sensitive to routing accuracy.
To tackle that, previous works introduced shared experts and combined their
outputs with those of the top $K$ routed experts in an ``addition'' manner. In
this paper, inspired by collective matrix factorization to learn shared
knowledge among data, we propose CartesianMoE, which implements more effective
knowledge sharing among experts in more like a ``multiplication'' manner.
Extensive experimental results indicate that CartesianMoE outperforms previous
MoE models for building LLMs, in terms of both perplexity and downstream task
performance. And we also find that CartesianMoE achieves better expert routing
robustness.",2024-10-21,"Zhenpeng Su, Xing Wu, Zijia Lin, Yizhe Xiong, Minxuan Lv, Guangyuan Ma, Hui Chen, Songlin Hu, Guiguang Ding",http://arxiv.org/pdf/2410.16077v3,cs.LG
On the Geometry of Regularization in Adversarial Training: High-Dimensional Asymptotics and Generalization Bounds,"Regularization, whether explicit in terms of a penalty in the loss or
implicit in the choice of algorithm, is a cornerstone of modern machine
learning. Indeed, controlling the complexity of the model class is particularly
important when data is scarce, noisy or contaminated, as it translates a
statistical belief on the underlying structure of the data. This work
investigates the question of how to choose the regularization norm $\lVert
\cdot \rVert$ in the context of high-dimensional adversarial training for
binary classification. To this end, we first derive an exact asymptotic
description of the robust, regularized empirical risk minimizer for various
types of adversarial attacks and regularization norms (including non-$\ell_p$
norms). We complement this analysis with a uniform convergence analysis,
deriving bounds on the Rademacher Complexity for this class of problems.
Leveraging our theoretical results, we quantitatively characterize the
relationship between perturbation size and the optimal choice of $\lVert \cdot
\rVert$, confirming the intuition that, in the data scarce regime, the type of
regularization becomes increasingly important for adversarial training as
perturbations grow in size.",2024-10-21,"Matteo Vilucchio, Nikolaos Tsilivis, Bruno Loureiro, Julia Kempe",http://arxiv.org/pdf/2410.16073v1,cs.LG
Near-Optimal Algorithm for Non-Stationary Kernelized Bandits,"This paper studies a non-stationary kernelized bandit (KB) problem, also
called time-varying Bayesian optimization, where one seeks to minimize the
regret under an unknown reward function that varies over time. In particular,
we focus on a near-optimal algorithm whose regret upper bound matches the
regret lower bound. For this goal, we show the first algorithm-independent
regret lower bound for non-stationary KB with squared exponential and Mat\'ern
kernels, which reveals that an existing optimization-based KB algorithm with
slight modification is near-optimal. However, this existing algorithm suffers
from feasibility issues due to its huge computational cost. Therefore, we
propose a novel near-optimal algorithm called restarting phased elimination
with random permutation (R-PERP), which bypasses the huge computational cost. A
technical key point is the simple permutation procedures of query candidates,
which enable us to derive a novel tighter confidence bound tailored to the
non-stationary problems.",2024-10-21,"Shogo Iwazaki, Shion Takeno",http://arxiv.org/pdf/2410.16052v1,cs.LG
Forecasting Company Fundamentals,"Company fundamentals are key to assessing companies' financial and overall
success and stability. Forecasting them is important in multiple fields,
including investing and econometrics. While statistical and contemporary
machine learning methods have been applied to many time series tasks, there is
a lack of comparison of these approaches on this particularly challenging data
regime. To this end, we try to bridge this gap and thoroughly evaluate the
theoretical properties and practical performance of 22 deterministic and
probabilistic company fundamentals forecasting models on real company data. We
observe that deep learning models provide superior forcasting performance to
classical models, in particular when considering uncertainty estimation. To
validate the findings, we compare them to human analyst expectations and find
that their accuracy is comparable to the automatic forecasts. We further show
how these high-quality forecasts can benefit automated stock allocation. We
close by presenting possible ways of integrating domain experts to further
improve performance and increase reliability.",2024-10-21,"Felix Divo, Eric Endress, Kevin Endler, Kristian Kersting, Devendra Singh Dhami",http://arxiv.org/pdf/2411.05791v1,cs.LG
GFlowNets for Hamiltonian decomposition in groups of compatible operators,"Quantum computing presents a promising alternative for the direct simulation
of quantum systems with the potential to explore chemical problems beyond the
capabilities of classical methods. However, current quantum algorithms are
constrained by hardware limitations and the increased number of measurements
required to achieve chemical accuracy. To address the measurement challenge,
techniques for grouping commuting and anti-commuting terms, driven by
heuristics, have been developed to reduce the number of measurements needed in
quantum algorithms on near-term quantum devices. In this work, we propose a
probabilistic framework using GFlowNets to group fully (FC) or qubit-wise
commuting (QWC) terms within a given Hamiltonian. The significance of this
approach is demonstrated by the reduced number of measurements for the found
groupings; 51% and 67% reduction factors respectively for FC and QWC
partitionings with respect to greedy coloring algorithms, highlighting the
potential of GFlowNets for future applications in the measurement problem.
Furthermore, the flexibility of our algorithm extends its applicability to
other resource optimization problems in Hamiltonian simulation, such as circuit
design.",2024-10-21,"Isaac L. Huidobro-Meezs, Jun Dai, Guillaume Rabusseau, Rodrigo A. Vargas-Hernández",http://arxiv.org/pdf/2410.16041v1,cs.LG
Domain-Adaptive Neural Posterior Estimation for Strong Gravitational Lens Analysis,"Modeling strong gravitational lenses is prohibitively expensive for modern
and next-generation cosmic survey data. Neural posterior estimation (NPE), a
simulation-based inference (SBI) approach, has been studied as an avenue for
efficient analysis of strong lensing data. However, NPE has not been
demonstrated to perform well on out-of-domain target data -- e.g., when trained
on simulated data and then applied to real, observational data. In this work,
we perform the first study of the efficacy of NPE in combination with
unsupervised domain adaptation (UDA). The source domain is noiseless, and the
target domain has noise mimicking modern cosmology surveys. We find that
combining UDA and NPE improves the accuracy of the inference by 1-2 orders of
magnitude and significantly improves the posterior coverage over an NPE model
without UDA. We anticipate that this combination of approaches will help enable
future applications of NPE models to real observational data.",2024-10-21,"Paxson Swierc, Marcos Tamargo-Arizmendi, Aleksandra Ćiprijanović, Brian D. Nord",http://arxiv.org/pdf/2410.16347v1,cs.LG
TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis,"Time series analysis plays a critical role in numerous applications,
supporting tasks such as forecasting, classification, anomaly detection, and
imputation. In this work, we present the time series pattern machine (TSPM), a
model designed to excel in a broad range of time series tasks through powerful
representation and pattern extraction capabilities. Traditional time series
models often struggle to capture universal patterns, limiting their
effectiveness across diverse tasks. To address this, we define multiple scales
in the time domain and various resolutions in the frequency domain, employing
various mixing strategies to extract intricate, task-adaptive time series
patterns. Specifically, we introduce a general-purpose TSPM that processes
multi-scale time series using (1) multi-resolution time imaging (MRTI), (2)
time image decomposition (TID), (3) multi-scale mixing (MCM), and (4)
multi-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI
transforms multi-scale time series into multi-resolution time images, capturing
patterns across both temporal and frequency domains. TID leverages dual-axis
attention to extract seasonal and trend patterns, while MCM hierarchically
aggregates these patterns across scales. MRM adaptively integrates all
representations across resolutions. This method achieves state-of-the-art
performance across 8 time series analytical tasks, consistently surpassing both
general-purpose and task-specific models. Our work marks a promising step
toward the next generation of TSPMs, paving the way for further advancements in
time series analysis.",2024-10-21,"Shiyu Wang, Jiawei Li, Xiaoming Shi, Zhou Ye, Baichuan Mo, Wenze Lin, Shengtong Ju, Zhixuan Chu, Ming Jin",http://arxiv.org/pdf/2410.16032v5,cs.LG
Natural GaLore: Accelerating GaLore for memory-efficient LLM Training and Fine-tuning,"Training LLMs presents significant memory challenges due to growing size of
data, weights, and optimizer states. Techniques such as data and model
parallelism, gradient checkpointing, and offloading strategies address this
issue but are often infeasible due to hardware constraints. To mitigate memory
usage, alternative methods like Parameter-Efficient-Fine-Tuning (PEFT) and
GaLore approximate weights or optimizer states. PEFT methods, such as LoRA,
have gained popularity for fine-tuning LLMs, though they require a full-rank
warm start. In contrast, GaLore allows full-parameter learning while being more
memory-efficient. This work introduces Natural GaLore, a simple drop in
replacement for AdamW, which efficiently applies the inverse Empirical Fisher
Information Matrix to low-rank gradients using Woodbury's Identity. We
demonstrate that incorporating second-order information speeds up optimization
significantly, especially when the iteration budget is limited. Empirical
pretraining on 60M, 130M, 350M, and 1.1B parameter Llama models on C4 data
demonstrate significantly lower perplexity over GaLore without additional
memory overhead. By fine-tuning RoBERTa on the GLUE benchmark using Natural
GaLore, we demonstrate significant reduction in gap 86.05% vs 86.28% for
full-finetuning. Furthermore, fine-tuning the TinyLlama 1.1B model for function
calling using the TinyAgent framework shows that Natural GaLore achieving
83.09% accuracy on the TinyAgent dataset, significantly outperforms 16-bit LoRA
at 80.06% and even surpasses GPT4-Turbo by 4%, all while using 30% less memory.
  All code to reproduce the results are available at:
https://github.com/selfsupervised-ai/Natural-GaLore.git",2024-10-21,Arijit Das,http://arxiv.org/pdf/2410.16029v1,cs.LG
Information-Theoretic Minimax Regret Bounds for Reinforcement Learning based on Duality,"We study agents acting in an unknown environment where the agent's goal is to
find a robust policy. We consider robust policies as policies that achieve high
cumulative rewards for all possible environments. To this end, we consider
agents minimizing the maximum regret over different environment parameters,
leading to the study of minimax regret. This research focuses on deriving
information-theoretic bounds for minimax regret in Markov Decision Processes
(MDPs) with a finite time horizon. Building on concepts from supervised
learning, such as minimum excess risk (MER) and minimax excess risk, we use
recent bounds on the Bayesian regret to derive minimax regret bounds.
Specifically, we establish minimax theorems and use bounds on the Bayesian
regret to perform minimax regret analysis using these minimax theorems. Our
contributions include defining a suitable minimax regret in the context of
MDPs, finding information-theoretic bounds for it, and applying these bounds in
various scenarios.",2024-10-21,"Raghav Bongole, Amaury Gouverneur, Borja Rodríguez-Gálvez, Tobias J. Oechtering, Mikael Skoglund",http://arxiv.org/pdf/2410.16013v1,cs.LG
Massimo: Public Queue Monitoring and Management using Mass-Spring Model,"An efficient system of a queue control and regulation in public spaces is
very important in order to avoid the traffic jams and to improve the customer
satisfaction. This article offers a detailed road map based on a merger of
intelligent systems and creating an efficient systems of queues in public
places. Through the utilization of different technologies i.e. computer vision,
machine learning algorithms, deep learning our system provide accurate
information about the place is crowded or not and the necessary efforts to be
taken.",2024-10-21,"Abhijeet Kumar, Unnati Singh, Rajdeep Chatterjee, Tathagata Bandyopadhyay",http://arxiv.org/pdf/2410.16012v1,cs.LG
Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies,"State Estimation is a crucial task in power systems. Graph Neural Networks
have demonstrated significant potential in state estimation for power systems
by effectively analyzing measurement data and capturing the complex
interactions and interrelations among the measurements through the system's
graph structure. However, the information about the system's graph structure
may be inaccurate due to noise, attack or lack of accurate information about
the topology of the system. This paper studies these scenarios under topology
uncertainties and evaluates the impact of the topology uncertainties on the
performance of a Temporal Graph Convolutional Network (TGCN) for state
estimation in power systems. In order to make the model resilient to topology
uncertainties, modifications in the TGCN model are proposed to incorporate a
knowledge graph, generated based on the measurement data. This knowledge graph
supports the assumed uncertain system graph. Two variations of the TGCN
architecture are introduced to integrate the knowledge graph, and their
performances are evaluated and compared to demonstrate improved resilience
against topology uncertainties. The evaluation results indicate that while the
two proposed architecture show different performance, they both improve the
performance of the TGCN state estimation under topology uncertainties.",2024-10-21,"Seyed Hamed Haghshenas, Mia Naeini",http://arxiv.org/pdf/2410.16008v1,cs.LG
"1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification","Social media is a great source of data for users reporting information and
regarding their health and how various things have had an effect on them. This
paper presents various approaches using Transformers and Large Language Models
and their ensembles, their performance along with advantages and drawbacks for
various tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor
spaces on the author's mental health (Task 3), Binary classification of tweets
reporting their children's health disorders like Asthma, Autism, ADHD and
Speech disorder (task 5), Binary classification of users self-reporting their
age (task 6).",2024-10-21,"Ram Mohan Rao Kadiyala, M. V. P. Chandra Sekhara Rao",http://arxiv.org/pdf/2410.15998v1,cs.LG
MultiRC: Joint Learning for Time Series Anomaly Prediction and Detection with Multi-scale Reconstructive Contrast,"Many methods have been proposed for unsupervised time series anomaly
detection. Despite some progress, research on predicting future anomalies is
still relatively scarce. Predicting anomalies is particularly challenging due
to the diverse reaction time and the lack of labeled data. To address these
challenges, we propose MultiRC to integrate reconstructive and contrastive
learning for joint learning of anomaly prediction and detection, with
multi-scale structure and adaptive dominant period mask to deal with the
diverse reaction time. MultiRC also generates negative samples to provide
essential training momentum for the anomaly prediction tasks and prevent model
degradation. We evaluate seven benchmark datasets from different fields. For
both anomaly prediction and detection tasks, MultiRC outperforms existing
state-of-the-art methods.",2024-10-21,"Shiyan Hu, Kai Zhao, Xiangfei Qiu, Yang Shu, Jilin Hu, Bin Yang, Chenjuan Guo",http://arxiv.org/pdf/2410.15997v1,cs.LG
Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence,"This paper presents our system description and error analysis of our entry
for NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)
\citep{hagag2024legallenssharedtask2024}. The task required classifying these
relationships as entailed, contradicted, or neutral, indicating any association
between the review and the complaint. Our system emerged as the winning
submission, significantly outperforming other entries with a substantial margin
and demonstrating the effectiveness of our approach in legal text analysis. We
provide a detailed analysis of the strengths and limitations of each model and
approach tested, along with a thorough error analysis and suggestions for
future improvements. This paper aims to contribute to the growing field of
legal NLP by offering insights into advanced techniques for natural language
inference in legal contexts, making it accessible to both experts and newcomers
in the field.",2024-10-21,"Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Subhasya Tippareddy, Ashay Srivastava",http://arxiv.org/pdf/2410.15990v1,cs.LG
Exploring how deep learning decodes anomalous diffusion via Grad-CAM,"While deep learning has been successfully applied to the data-driven
classification of anomalous diffusion mechanisms, how the algorithm achieves
the feat still remains a mystery. In this study, we use a well-known technique
aimed at achieving explainable AI, namely the Gradient-weighted Class
Activation Map (Grad-CAM), to investigate how deep learning (implemented by
ResNets) recognizes the distinctive features of a particular anomalous
diffusion model from the raw trajectory data. Our results show that Grad-CAM
reveals the portions of the trajectory that hold crucial information about the
underlying mechanism of anomalous diffusion, which can be utilized to enhance
the robustness of the trained classifier against the measurement noise.
Moreover, we observe that deep learning distills unique statistical
characteristics of different diffusion mechanisms at various spatiotemporal
scales, with larger-scale (smaller-scale) features identified at higher (lower)
layers.",2024-10-21,"Jaeyong Bae, Yongjoo Baek, Hawoong Jeong",http://arxiv.org/pdf/2410.16345v1,cs.LG
Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations,"Simulation plays a crucial role in the rapid development and safe deployment
of autonomous vehicles. Realistic traffic agent models are indispensable for
bridging the gap between simulation and the real world. Many existing
approaches for imitating human behavior are based on learning from
demonstration. However, these approaches are often constrained by focusing on
individual training strategies. Therefore, to foster a broader understanding of
realistic traffic agent modeling, in this paper, we provide an extensive
comparative analysis of different training principles, with a focus on
closed-loop methods for highway driving simulation. We experimentally compare
(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.
deterministic supervised training, (iii) the impact of reinforcement losses,
and (iv) the impact of training alongside log-replayed agents to identify
suitable training techniques for realistic agent modeling. Furthermore, we
identify promising combinations of different closed-loop training methods.",2024-10-21,"Matthias Bitzer, Reinis Cimurs, Benjamin Coors, Johannes Goth, Sebastian Ziesche, Philipp Geiger, Maximilian Naumann",http://arxiv.org/pdf/2410.15987v1,cs.LG
A quantitative Robbins-Siegmund theorem,"The Robbins-Siegmund theorem is one of the most important results in
stochastic optimization, where it is widely used to prove the convergence of
stochastic algorithms. We provide a quantitative version of the theorem,
establishing a bound on how far one needs to look in order to locate a region
of metastability in the sense of Tao. Our proof involves a metastable analogue
of Doob's theorem for $L_1$-supermartingales along with a series of technical
lemmas that make precise how quantitative information propagates through sums
and products of stochastic processes. In this way, our paper establishes a
general methodology for finding metastable bounds for stochastic processes that
can be reduced to supermartingales, and therefore for obtaining quantitative
convergence information across a broad class of stochastic algorithms whose
convergence proof relies on some variation of the Robbins-Siegmund theorem. We
conclude by discussing how our general quantitative result might be used in
practice.",2024-10-21,"Morenikeji Neri, Thomas Powell",http://arxiv.org/pdf/2410.15986v1,cs.LG
State Estimation Using Sparse DEIM and Recurrent Neural Networks,"Discrete Empirical Interpolation Method (DEIM) estimates a function from its
pointwise incomplete observations. In particular, this method can be used to
estimate the state of a dynamical system from observational data gathered by
sensors. However, when the number of observations are limited, DEIM returns
large estimation errors. Sparse DEIM (S-DEIM) was recently developed to address
this problem by introducing a kernel vector which previous DEIM-based methods
had ignored. Unfortunately, estimating the optimal kernel vector in S-DEIM is a
difficult task. Here, we introduce a data-driven method to estimate this kernel
vector from sparse observational time series using recurrent neural networks.
Using numerical examples, we demonstrate that this machine learning approach
together with S-DEIM leads to nearly optimal state estimations.",2024-10-21,Mohammad Farazmand,http://arxiv.org/pdf/2410.15982v1,cs.LG
Robust Visual Representation Learning with Multi-modal Prior Knowledge for Image Classification Under Distribution Shift,"Despite the remarkable success of deep neural networks (DNNs) in computer
vision, they fail to remain high-performing when facing distribution shifts
between training and testing data. In this paper, we propose Knowledge-Guided
Visual representation learning (KGV) - a distribution-based learning approach
leveraging multi-modal prior knowledge - to improve generalization under
distribution shift. It integrates knowledge from two distinct modalities: 1) a
knowledge graph (KG) with hierarchical and association relationships; and 2)
generated synthetic images of visual elements semantically represented in the
KG. The respective embeddings are generated from the given modalities in a
common latent space, i.e., visual embeddings from original and synthetic images
as well as knowledge graph embeddings (KGEs). These embeddings are aligned via
a novel variant of translation-based KGE methods, where the node and relation
embeddings of the KG are modeled as Gaussian distributions and translations,
respectively. We claim that incorporating multi-model prior knowledge enables
more regularized learning of image representations. Thus, the models are able
to better generalize across different data distributions. We evaluate KGV on
different image classification tasks with major or minor distribution shifts,
namely road sign classification across datasets from Germany, China, and
Russia, image classification with the mini-ImageNet dataset and its variants,
as well as the DVM-CAR dataset. The results demonstrate that KGV consistently
exhibits higher accuracy and data efficiency across all experiments.",2024-10-21,"Hongkuan Zhou, Lavdim Halilaj, Sebastian Monka, Stefan Schmid, Yuqicheng Zhu, Bo Xiong, Steffen Staab",http://arxiv.org/pdf/2410.15981v2,cs.LG
Large Language Models for Cross-lingual Emotion Detection,"This paper presents a detailed system description of our entry for the WASSA
2024 Task 2, focused on cross-lingual emotion detection. We utilized a
combination of large language models (LLMs) and their ensembles to effectively
understand and categorize emotions across different languages. Our approach not
only outperformed other submissions with a large margin, but also demonstrated
the strength of integrating multiple models to enhance performance.
Additionally, We conducted a thorough comparison of the benefits and
limitations of each model used. An error analysis is included along with
suggested areas for future improvement. This paper aims to offer a clear and
comprehensive understanding of advanced techniques in emotion detection, making
it accessible even to those new to the field.",2024-10-21,Ram Mohan Rao Kadiyala,http://arxiv.org/pdf/2410.15974v1,cs.LG
Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets),"This paper presents a novel approach to solving convex optimization problems
by leveraging the fact that, under certain regularity conditions, any set of
primal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is
necessary and sufficient for optimality. Similar to Theory-Trained Neural
Networks (TTNNs), the parameters of the convex optimization problem are input
to the neural network, and the expected outputs are the optimal primal and dual
variables. A choice for the loss function in this case is a loss, which we
refer to as the KKT Loss, that measures how well the network's outputs satisfy
the KKT conditions. We demonstrate the effectiveness of this approach using a
linear program as an example. For this problem, we observe that minimizing the
KKT Loss alone outperforms training the network with a weighted sum of the KKT
Loss and a Data Loss (the mean-squared error between the ground truth optimal
solutions and the network's output). Moreover, minimizing only the Data Loss
yields inferior results compared to those obtained by minimizing the KKT Loss.
While the approach is promising, the obtained primal and dual solutions are not
sufficiently close to the ground truth optimal solutions. In the future, we aim
to develop improved models to obtain solutions closer to the ground truth and
extend the approach to other problem classes.",2024-10-21,"Shreya Arvind, Rishabh Pomaje, Rajshekhar V Bhat",http://arxiv.org/pdf/2410.15973v1,cs.LG
"A practical, fast method for solving sum-of-squares problems for very large polynomials","Sum of squares (SOS) optimization is a powerful technique for solving
problems where the positivity of a polynomials must be enforced. The common
approach to solve an SOS problem is by relaxation to a Semidefinite Program
(SDP). The main advantage of this transormation is that SDP is a convex problem
for which efficient solvers are readily available. However, while considerable
progress has been made in recent years, the standard approaches for solving
SDPs are still known to scale poorly. Our goal is to devise an approach that
can handle larger, more complex problems than is currently possible. The
challenge indeed lies in how SDPs are commonly solved. State-Of-The-Art
approaches rely on the interior point method, which requires the factorization
of large matrices. We instead propose an approach inspired by polynomial neural
networks, which exhibit excellent performance when optimized using techniques
from the deep learning toolbox. In a somewhat counter-intuitive manner, we
replace the convex SDP formulation with a non-convex, unconstrained, and
\emph{over parameterized} formulation, and solve it using a first order
optimization method. It turns out that this approach can handle very large
problems, with polynomials having over four million coefficients, well beyond
the range of current SDP-based approaches. Furthermore, we highlight
theoretical and practical results supporting the experimental success of our
approach in avoiding spurious local minima, which makes it amenable to simple
and fast solutions based on gradient descent. In all the experiments, our
approach had always converged to a correct global minimum, on general
(non-sparse) polynomials, with running time only slightly higher than linear in
the number of polynomial coefficients, compared to higher than quadratic in the
number of coefficients for SDP-based methods.",2024-10-21,"Daniel Keren, Margarita Osadchy, Roi Poranne",http://arxiv.org/pdf/2410.19844v1,cs.LG
TS-ACL: Closed-Form Solution for Time Series-oriented Continual Learning,"Time series classification underpins critical applications such as healthcare
diagnostics and gesture-driven interactive systems in multimedia scenarios.
However, time series class-incremental learning (TSCIL) faces two major
challenges: catastrophic forgetting and intra-class variations. Catastrophic
forgetting occurs because gradient-based parameter update strategies inevitably
erase past knowledge. And unlike images, time series data exhibits
subject-specific patterns, also known as intra-class variations, which refer to
differences in patterns observed within the same class. While exemplar-based
methods fail to cover diverse variation with limited samples, existing
exemplar-free methods lack explicit mechanisms to handle intra-class
variations. To address these two challenges, we propose TS-ACL, which leverages
a gradient-free closed-form solution to avoid the catastrophic forgetting
problem inherent in gradient-based optimization methods while simultaneously
learning global distributions to resolve intra-class variations. Additionally,
it provides privacy protection and efficiency. Extensive experiments on five
benchmark datasets covering various sensor modalities and tasks demonstrate
that TS-ACL achieves performance close to joint training on four datasets,
outperforming existing methods and establishing a new state-of-the-art (SOTA)
for TSCIL.",2024-10-21,"Jiaxu Li, Kejia Fan, Songning Lai, Linpu Lv, Jinfeng Xu, Jianheng Tang, Anfeng Liu, Houbing Herbert Song, Yutao Yue, Yunhuai Liu, Huiping Zhuang",http://arxiv.org/pdf/2410.15954v3,cs.LG
User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study,"This study is located in the Human-Centered Artificial Intelligence (HCAI)
and focuses on the results of a user-centered assessment of commonly used
eXplainable Artificial Intelligence (XAI) algorithms, specifically
investigating how humans understand and interact with the explanations provided
by these algorithms. To achieve this, we employed a multi-disciplinary approach
that included state-of-the-art research methods from social sciences to measure
the comprehensibility of explanations generated by a state-of-the-art lachine
learning model, specifically the Gradient Boosting Classifier (XGBClassifier).
We conducted an extensive empirical user study involving interviews with 39
participants from three different groups, each with varying expertise in data
science, data visualization, and domain-specific knowledge related to the
dataset used for training the machine learning model. Participants were asked a
series of questions to assess their understanding of the model's explanations.
To ensure replicability, we built the model using a publicly available dataset
from the UC Irvine Machine Learning Repository, focusing on edible and
non-edible mushrooms. Our findings reveal limitations in existing XAI methods
and confirm the need for new design principles and evaluation techniques that
address the specific information needs and user perspectives of different
classes of AI stakeholders. We believe that the results of our research and the
cross-disciplinary methodology we developed can be successfully adapted to
various data types and user profiles, thus promoting dialogue and address
opportunities in HCAI research. To support this, we are making the data
resulting from our study publicly available.",2024-10-21,"Szymon Bobek, Paloma Korycińska, Monika Krakowska, Maciej Mozolewski, Dorota Rak, Magdalena Zych, Magdalena Wójcik, Grzegorz J. Nalepa",http://arxiv.org/pdf/2410.15952v1,cs.LG
GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution,"Reliable facial expression learning (FEL) involves the effective learning of
distinctive facial expression characteristics for more reliable, unbiased and
accurate predictions in real-life settings. However, current systems struggle
with FEL tasks because of the variance in people's facial expressions due to
their unique facial structures, movements, tones, and demographics. Biased and
imbalanced datasets compound this challenge, leading to wrong and biased
prediction labels. To tackle these, we introduce GReFEL, leveraging Vision
Transformers and a facial geometry-aware anchor-based reliability balancing
module to combat imbalanced data distributions, bias, and uncertainty in facial
expression learning. Integrating local and global data with anchors that learn
different facial data points and structural features, our approach adjusts
biased and mislabeled emotions caused by intra-class disparity, inter-class
similarity, and scale sensitivity, resulting in comprehensive, accurate, and
reliable facial expression predictions. Our model outperforms current
state-of-the-art methodologies, as demonstrated by extensive experiments on
various datasets.",2024-10-21,"Azmine Toushik Wasi, Taki Hasan Rafi, Raima Islam, Karlo Serbetar, Dong Kyu Chae",http://arxiv.org/pdf/2410.15927v1,cs.LG
Automatic Differentiation of Optimization Algorithms with Time-Varying Updates,"Numerous Optimization Algorithms have a time-varying update rule thanks to,
for instance, a changing step size, momentum parameter or, Hessian
approximation. In this paper, we apply unrolled or automatic differentiation to
a time-varying iterative process and provide convergence (rate) guarantees for
the resulting derivative iterates. We adapt these convergence results and apply
them to proximal gradient descent with variable step size and FISTA when
solving partly smooth problems. We confirm our findings numerically by solving
$\ell_1$ and $\ell_2$-regularized linear and logisitc regression respectively.
Our theoretical and numerical results show that the convergence rate of the
algorithm is reflected in its derivative iterates.",2024-10-21,"Sheheryar Mehmood, Peter Ochs",http://arxiv.org/pdf/2410.15923v2,cs.LG
Evaluating the Posterior Sampling Ability of Plug&Play Diffusion Methods in Sparse-View CT,"Plug&Play (PnP) diffusion models are state-of-the-art methods in computed
tomography (CT) reconstruction. Such methods usually consider applications
where the sinogram contains a sufficient amount of information for the
posterior distribution to be concentrated around a single mode, and
consequently are evaluated using image-to-image metrics such as PSNR/SSIM.
Instead, we are interested in reconstructing compressible flow images from
sinograms having a small number of projections, which results in a posterior
distribution no longer concentrated or even multimodal. Thus, in this paper, we
aim at evaluating the approximate posterior of PnP diffusion models and
introduce two posterior evaluation properties. We quantitatively evaluate three
PnP diffusion methods on three different datasets for several numbers of
projections. We surprisingly find that, for each method, the approximate
posterior deviates from the true posterior when the number of projections
decreases.",2024-10-21,"Liam Moroy, Guillaume Bourmaud, Frédéric Champagnat, Jean-François Giovannelli",http://arxiv.org/pdf/2410.21301v2,cs.LG
XAI-FUNGI: Dataset resulting from the user study on comprehensibility of explainable AI algorithms,"This paper introduces a dataset that is the result of a user study on the
comprehensibility of explainable artificial intelligence (XAI) algorithms. The
study participants were recruited from 149 candidates to form three groups
representing experts in the domain of mycology (DE), students with a data
science and visualization background (IT) and students from social sciences and
humanities (SSH). The main part of the dataset contains 39 transcripts of
interviews during which participants were asked to complete a series of tasks
and questions related to the interpretation of explanations of decisions of a
machine learning model trained to distinguish between edible and inedible
mushrooms. The transcripts were complemented with additional data that includes
visualizations of explanations presented to the user, results from thematic
analysis, recommendations of improvements of explanations provided by the
participants, and the initial survey results that allow to determine the domain
knowledge of the participant and data analysis literacy. The transcripts were
manually tagged to allow for automatic matching between the text and other data
related to particular fragments. In the advent of the area of rapid development
of XAI techniques, the need for a multidisciplinary qualitative evaluation of
explainability is one of the emerging topics in the community. Our dataset
allows not only to reproduce the study we conducted, but also to open a wide
range of possibilities for the analysis of the material we gathered.",2024-10-21,"Szymon Bobek, Paloma Korycińska, Monika Krakowska, Maciej Mozolewski, Dorota Rak, Magdalena Zych, Magdalena Wójcik, Grzegorz J. Nalepa",http://arxiv.org/pdf/2411.02419v1,cs.LG
Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning,"Recovering a spectrum of diverse policies from a set of expert trajectories
is an important research topic in imitation learning. After determining a
latent style for a trajectory, previous diverse policies recovering methods
usually employ a vanilla behavioral cloning learning objective conditioned on
the latent style, treating each state-action pair in the trajectory with equal
importance. Based on an observation that in many scenarios, behavioral styles
are often highly relevant with only a subset of state-action pairs, this paper
presents a new principled method in diverse polices recovery. In particular,
after inferring or assigning a latent style for a trajectory, we enhance the
vanilla behavioral cloning by incorporating a weighting mechanism based on
pointwise mutual information. This additional weighting reflects the
significance of each state-action pair's contribution to learning the style,
thus allowing our method to focus on state-action pairs most representative of
that style. We provide theoretical justifications for our new objective, and
extensive empirical evaluations confirm the effectiveness of our method in
recovering diverse policies from expert data.",2024-10-21,"Hanlin Yang, Jian Yao, Weiming Liu, Qing Wang, Hanmin Qin, Hansheng Kong, Kirk Tang, Jiechao Xiong, Chao Yu, Kai Li, Junliang Xing, Hongwu Chen, Juchao Zhuo, Qiang Fu, Yang Wei, Haobo Fu",http://arxiv.org/pdf/2410.15910v2,cs.LG
Hydra-LSTM: A semi-shared Machine Learning architecture for prediction across Watersheds,"Long Short Term Memory networks (LSTMs) are used to build single models that
predict river discharge across many catchments. These models offer greater
accuracy than models trained on each catchment independently if using the same
data. However, the same data is rarely available for all catchments. This
prevents the use of variables available only in some catchments, such as
historic river discharge or upstream discharge. The only existing method that
allows for optional variables requires all variables to be considered in the
initial training of the model, limiting its transferability to new catchments.
To address this limitation, we develop the Hydra-LSTM. The Hydra-LSTM processes
variables used across all catchments and variables used in only some catchments
separately to allow general training and use of catchment-specific data in
individual catchments. The bulk of the model can be shared across catchments,
maintaining the benefits of multi-catchment models to generalise, while also
benefitting from the advantages of using bespoke data. We apply this
methodology to 1 day-ahead river discharge prediction in the Western US, as
next-day river discharge prediction is the first step towards prediction across
longer time scales. We obtain state-of-the-art performance, generating more
accurate median and quantile predictions than Multi-Catchment and
Single-Catchment LSTMs while allowing local forecasters to easily introduce and
remove variables from their prediction set. We test the ability of the
Hydra-LSTM to incorporate catchment-specific data by introducing historical
river discharge as a catchment-specific input, outperforming state-of-the-art
models without needing to train an entirely new model.",2024-10-21,"Karan Ruparell, Robert J. Marks, Andy Wood, Kieran M. R. Hunt, Hannah L. Cloke, Christel Prudhomme, Florian Pappenberger, Matthew Chantry",http://arxiv.org/pdf/2410.16343v1,cs.LG
Data Matters: The Case of Predicting Mobile Cellular Traffic,"Accurate predictions of base stations' traffic load are essential to mobile
cellular operators and their users as they support the efficient use of network
resources and sustain smart cities and roads. Traditionally, cellular network
time-series have been considered for this prediction task. More recently,
exogenous factors such as points of presence and other environmental knowledge
have been introduced to facilitate cellular traffic forecasting. In this study,
we focus on smart roads and explore road traffic measures to model the
processes underlying cellular traffic generation with the goal to improve
prediction performance. Comprehensive experiments demonstrate that by employing
road flow and speed, in addition to cellular network metrics, cellular load
prediction errors can be reduced by as much as 56.5 %. The code and more
detailed results are available on https://github.com/nvassileva/DataMatters.",2024-10-21,"Natalia Vesselinova, Matti Harjula, Pauliina Ilmonen",http://arxiv.org/pdf/2411.02418v1,cs.LG
On the Design and Performance of Machine Learning Based Error Correcting Decoders,"This paper analyzes the design and competitiveness of four neural network
(NN) architectures recently proposed as decoders for forward error correction
(FEC) codes. We first consider the so-called single-label neural network (SLNN)
and the multi-label neural network (MLNN) decoders which have been reported to
achieve near maximum likelihood (ML) performance. Here, we show analytically
that SLNN and MLNN decoders can always achieve ML performance, regardless of
the code dimensions -- although at the cost of computational complexity -- and
no training is in fact required. We then turn our attention to two
transformer-based decoders: the error correction code transformer (ECCT) and
the cross-attention message passing transformer (CrossMPT). We compare their
performance against traditional decoders, and show that ordered statistics
decoding outperforms these transformer-based decoders. The results in this
paper cast serious doubts on the application of NN-based FEC decoders in the
short and medium block length regime.",2024-10-21,"Yuncheng Yuan, Péter Scheepers, Lydia Tasiou, Yunus Can Gültekin, Federico Corradi, Alex Alvarado",http://arxiv.org/pdf/2410.15899v2,cs.LG
Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples,"The vulnerability of artificial neural networks to adversarial perturbations
in the black-box setting is widely studied in the literature. The majority of
attack methods to construct these perturbations suffer from an impractically
large number of queries required to find an adversarial example. In this work,
we focus on knowledge distillation as an approach to conduct transfer-based
black-box adversarial attacks and propose an iterative training of the
surrogate model on an expanding dataset. This work is the first, to our
knowledge, to provide provable guarantees on the success of knowledge
distillation-based attack on classification neural networks: we prove that if
the student model has enough learning capabilities, the attack on the teacher
model is guaranteed to be found within the finite number of distillation
iterations.",2024-10-21,"Kirill Lukyanov, Andrew Perminov, Denis Turdakov, Mikhail Pautov",http://arxiv.org/pdf/2410.15889v1,cs.LG
Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process,"The paper considers an approach of using Google Search API and GPT-4o model
for qualitative and quantitative analyses of news through retrieval-augmented
generation (RAG). This approach was applied to analyze news about the 2024 US
presidential election process. Different news sources for different time
periods have been analyzed. Quantitative scores generated by GPT model have
been analyzed using Bayesian regression to derive trend lines. The
distributions found for the regression parameters allow for the analysis of
uncertainty in the election process. The obtained results demonstrate that
using the GPT models for news analysis, one can get informative analytics and
provide key insights that can be applied in further analyses of election
processes.",2024-10-21,Bohdan M. Pavlyshenko,http://arxiv.org/pdf/2410.15884v1,cs.LG
Distributed Learning for UAV Swarms,"Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic,
data-rich environments for applications such as environmental monitoring and
surveillance. These scenarios demand efficient data processing while
maintaining privacy and security, making Federated Learning (FL) a promising
solution. FL allows UAVs to collaboratively train global models without sharing
raw data, but challenges arise due to the non-Independent and Identically
Distributed (non-IID) nature of the data collected by UAVs. In this study, we
show an integration of the state-of-the-art FL methods to UAV Swarm application
and invetigate the performance of multiple aggregation methods (namely FedAvg,
FedProx, FedOpt, and MOON) with a particular focus on tackling non-IID on a
variety of datasets, specifically MNIST for baseline performance, CIFAR10 for
natural object classification, EuroSAT for environment monitoring, and CelebA
for surveillance. These algorithms were selected to cover improved techniques
on both client-side updates and global aggregation. Results show that while all
algorithms perform comparably on IID data, their performance deteriorates
significantly under non-IID conditions. FedProx demonstrated the most stable
overall performance, emphasising the importance of regularising local updates
in non-IID environments to mitigate drastic deviations in local models.",2024-10-21,"Chen Hu, Hanchi Ren, Jingjing Deng, Xianghua Xie",http://arxiv.org/pdf/2410.15882v1,cs.LG
FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL,"Multi-agent reinforcement learning has demonstrated significant potential in
addressing complex cooperative tasks across various real-world applications.
However, existing MARL approaches often rely on the restrictive assumption that
the number of entities (e.g., agents, obstacles) remains constant between
training and inference. This overlooks scenarios where entities are dynamically
removed or added during the inference trajectory -- a common occurrence in
real-world environments like search and rescue missions and dynamic combat
situations. In this paper, we tackle the challenge of intra-trajectory dynamic
entity composition under zero-shot out-of-domain (OOD) generalization, where
such dynamic changes cannot be anticipated beforehand. Our empirical studies
reveal that existing MARL methods suffer significant performance degradation
and increased uncertainty in these scenarios. In response, we propose
FlickerFusion, a novel OOD generalization method that acts as a universally
applicable augmentation technique for MARL backbone methods. FlickerFusion
stochastically drops out parts of the observation space, emulating being
in-domain when inferenced OOD. The results show that FlickerFusion not only
achieves superior inference rewards but also uniquely reduces uncertainty
vis-\`a-vis the backbone, compared to existing methods. Benchmarks,
implementations, and model weights are organized and open-sourced at
flickerfusion305.github.io, accompanied by ample demo video renderings.",2024-10-21,"Woosung Koh, Wonbeen Oh, Siyeol Kim, Suhin Shin, Hyeongjin Kim, Jaein Jang, Junghyun Lee, Se-Young Yun",http://arxiv.org/pdf/2410.15876v3,cs.LG
Enabling Asymmetric Knowledge Transfer in Multi-Task Learning with Self-Auxiliaries,"Knowledge transfer in multi-task learning is typically viewed as a dichotomy;
positive transfer, which improves the performance of all tasks, or negative
transfer, which hinders the performance of all tasks. In this paper, we
investigate the understudied problem of asymmetric task relationships, where
knowledge transfer aids the learning of certain tasks while hindering the
learning of others. We propose an optimisation strategy that includes
additional cloned tasks named self-auxiliaries into the learning process to
flexibly transfer knowledge between tasks asymmetrically. Our method can
exploit asymmetric task relationships, benefiting from the positive transfer
component while avoiding the negative transfer component. We demonstrate that
asymmetric knowledge transfer provides substantial improvements in performance
compared to existing multi-task optimisation strategies on benchmark computer
vision problems.",2024-10-21,"Olivier Graffeuille, Yun Sing Koh, Joerg Wicker, Moritz Lehmann",http://arxiv.org/pdf/2410.15875v1,cs.LG
Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs,"Large language models (LLMs), although having revolutionized many fields,
still suffer from the challenging extrapolation problem, where the inference
ability of LLMs sharply declines beyond their max training lengths. In this
work, we conduct a theoretical analysis to better understand why No Position
Encoding (NoPE) fails outside its effective range, as well as examining the
power of Position Encoding (PE) in this context. Our findings reveal that with
meticulous weave position, PE can indeed be extended beyond effective range.
Our theorems establish that LLMs equipped with weave PE can achieve improved
extrapolation performance without additional cost. Furthermore, we introduce a
novel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based
triangular attention matrix and applies Stair PE to manage the final chunk.
This method not only retains competitive performance but also offers
substantial benefits such as significantly reduced memory demand and faster
inference speed. Extensive experiments validate the effectiveness of
Mesa-Extrapolation, demonstrating its potential as a scalable solution to
enhancing LLMs applicative reach. Our code is available at
\url{https://github.com/soacker/Mesa-Extrapolation}.",2024-10-21,"Xin Ma, Yang Liu, Jingjing Liu, Xiaoxu Ma",http://arxiv.org/pdf/2410.15859v3,cs.LG
Towards Optimal Adapter Placement for Efficient Transfer Learning,"Parameter-efficient transfer learning (PETL) aims to adapt pre-trained models
to new downstream tasks while minimizing the number of fine-tuned parameters.
Adapters, a popular approach in PETL, inject additional capacity into existing
networks by incorporating low-rank projections, achieving performance
comparable to full fine-tuning with significantly fewer parameters. This paper
investigates the relationship between the placement of an adapter and its
performance. We observe that adapter location within a network significantly
impacts its effectiveness, and that the optimal placement is task-dependent. To
exploit this observation, we introduce an extended search space of adapter
connections, including long-range and recurrent adapters. We demonstrate that
even randomly selected adapter placements from this expanded space yield
improved results, and that high-performing placements often correlate with high
gradient rank. Our findings reveal that a small number of strategically placed
adapters can match or exceed the performance of the common baseline of adding
adapters in every block, opening a new avenue for research into optimal adapter
placement strategies.",2024-10-21,"Aleksandra I. Nowak, Otniel-Bogdan Mercea, Anurag Arnab, Jonas Pfeiffer, Yann Dauphin, Utku Evci",http://arxiv.org/pdf/2410.15858v1,cs.LG
TEXEL: A neuromorphic processor with on-chip learning for beyond-CMOS device integration,"Recent advances in memory technologies, devices and materials have shown
great potential for integration into neuromorphic electronic systems. However,
a significant gap remains between the development of these materials and the
realization of large-scale, fully functional systems. One key challenge is
determining which devices and materials are best suited for specific functions
and how they can be paired with CMOS circuitry. To address this, we introduce
TEXEL, a mixed-signal neuromorphic architecture designed to explore the
integration of on-chip learning circuits and novel two- and three-terminal
devices. TEXEL serves as an accessible platform to bridge the gap between
CMOS-based neuromorphic computation and the latest advancements in emerging
devices. In this paper, we demonstrate the readiness of TEXEL for device
integration through comprehensive chip measurements and simulations. TEXEL
provides a practical system for testing bio-inspired learning algorithms
alongside emerging devices, establishing a tangible link between brain-inspired
computation and cutting-edge device research.",2024-10-21,"Hugh Greatorex, Ole Richter, Michele Mastella, Madison Cotteret, Philipp Klein, Maxime Fabre, Arianna Rubino, Willian Soares Girão, Junren Chen, Martin Ziegler, Laura Bégon-Lours, Giacomo Indiveri, Elisabetta Chicca",http://arxiv.org/pdf/2410.15854v1,cs.LG
R2I-rPPG: A Robust Region of Interest Selection Method for Remote Photoplethysmography to Extract Heart Rate,"The COVID-19 pandemic has underscored the need for low-cost, scalable
approaches to measuring contactless vital signs, either during initial triage
at a healthcare facility or virtual telemedicine visits. Remote
photoplethysmography (rPPG) can accurately estimate heart rate (HR) when
applied to close-up videos of healthy volunteers in well-lit laboratory
settings. However, results from such highly optimized laboratory studies may
not be readily translated to healthcare settings. One significant barrier to
the practical application of rPPG in health care is the accurate localization
of the region of interest (ROI). Clinical or telemedicine visits may involve
sub-optimal lighting, movement artifacts, variable camera angle, and subject
distance. This paper presents an rPPG ROI selection method based on 3D facial
landmarks and patient head yaw angle. We then demonstrate the robustness of
this ROI selection method when coupled to the Plane-Orthogonal-to-Skin (POS)
rPPG method when applied to videos of patients presenting to an Emergency
Department for respiratory complaints. Our results demonstrate the
effectiveness of our proposed approach in improving the accuracy and robustness
of rPPG in a challenging clinical environment.",2024-10-21,"Sandeep Nagar, Mark Hasegawa-Johnson, David G. Beiser, Narendra Ahuja",http://arxiv.org/pdf/2410.15851v2,cs.LG
Focus Where It Matters: Graph Selective State Focused Attention Networks,"Traditional graph neural networks (GNNs) lack scalability and lose individual
node characteristics due to over-smoothing, especially in the case of deeper
networks. This results in sub-optimal feature representation, affecting the
model's performance on tasks involving dynamically changing graphs. To address
this issue, we present Graph Selective States Focused Attention Networks
(GSANs) based neural network architecture for graph-structured data. The GSAN
is enabled by multi-head masked self-attention (MHMSA) and selective state
space modeling (S3M) layers to overcome the limitations of GNNs. In GSAN, the
MHMSA allows GSAN to dynamically emphasize crucial node connections,
particularly in evolving graph environments. The S3M layer enables the network
to adjust dynamically in changing node states and improving predictions of node
behavior in varying contexts without needing primary knowledge of the graph
structure. Furthermore, the S3M layer enhances the generalization of unseen
structures and interprets how node states influence link importance. With this,
GSAN effectively outperforms inductive and transductive tasks and overcomes the
issues that traditional GNNs experience. To analyze the performance behavior of
GSAN, a set of state-of-the-art comparative experiments are conducted on graphs
benchmark datasets, including $Cora$, $Citeseer$, $Pubmed$ network citation,
and $protein-protein-interaction$ datasets, as an outcome, GSAN improved the
classification accuracy by $1.56\%$, $8.94\%$, $0.37\%$, and $1.54\%$ on
$F1-score$ respectively.",2024-10-21,"Shikhar Vashistha, Neetesh Kumar",http://arxiv.org/pdf/2410.15849v1,cs.LG
Random Token Fusion for Multi-View Medical Diagnosis,"In multi-view medical diagnosis, deep learning-based models often fuse
information from different imaging perspectives to improve diagnostic
performance. However, existing approaches are prone to overfitting and rely
heavily on view-specific features, which can lead to trivial solutions. In this
work, we introduce Random Token Fusion (RTF), a novel technique designed to
enhance multi-view medical image analysis using vision transformers. By
integrating randomness into the feature fusion process during training, RTF
addresses the issue of overfitting and enhances the robustness and accuracy of
diagnostic models without incurring any additional cost at inference. We
validate our approach on standard mammography and chest X-ray benchmark
datasets. Through extensive experiments, we demonstrate that RTF consistently
improves the performance of existing fusion methods, paving the way for a new
generation of multi-view medical foundation models.",2024-10-21,"Jingyu Guo, Christos Matsoukas, Fredrik Strand, Kevin Smith",http://arxiv.org/pdf/2410.15847v1,cs.LG
Modelling Concurrent RTP Flows for End-to-end Predictions of QoS in Real Time Communications,"The Real-time Transport Protocol (RTP)-based real-time communications (RTC)
applications, exemplified by video conferencing, have experienced an
unparalleled surge in popularity and development in recent years. In pursuit of
optimizing their performance, the prediction of Quality of Service (QoS)
metrics emerges as a pivotal endeavor, bolstering network monitoring and
proactive solutions. However, contemporary approaches are confined to
individual RTP flows and metrics, falling short in relationship capture and
computational efficiency. To this end, we propose Packet-to-Prediction (P2P), a
novel deep learning (DL) framework that hinges on raw packets to simultaneously
process concurrent RTP flows and perform end-to-end prediction of multiple QoS
metrics. Specifically, we implement a streamlined architecture, namely
length-free Transformer with cross and neighbourhood attention, capable of
handling an unlimited number of RTP flows, and employ a multi-task learning
paradigm to forecast four key metrics in a single shot. Our work is based on
extensive traffic collected during real video calls, and conclusively, P2P
excels comparative models in both prediction performance and temporal
efficiency.",2024-10-21,"Tailai Song, Paolo Garza, Michela Meo, Maurizio Matteo Munafò",http://arxiv.org/pdf/2410.15846v1,cs.LG
Vulnerabilities in Machine Learning-Based Voice Disorder Detection Systems,"The impact of voice disorders is becoming more widely acknowledged as a
public health issue. Several machine learning-based classifiers with the
potential to identify disorders have been used in recent studies to
differentiate between normal and pathological voices and sounds. In this paper,
we focus on analyzing the vulnerabilities of these systems by exploring the
possibility of attacks that can reverse classification and compromise their
reliability. Given the critical nature of personal health information,
understanding which types of attacks are effective is a necessary first step
toward improving the security of such systems. Starting from the original
audios, we implement various attack methods, including adversarial, evasion,
and pitching techniques, and evaluate how state-of-the-art disorder detection
models respond to them. Our findings identify the most effective attack
strategies, underscoring the need to address these vulnerabilities in
machine-learning systems used in the healthcare domain.",2024-10-21,"Gianpaolo Perelli, Andrea Panzino, Roberto Casula, Marco Micheletto, Giulia Orrù, Gian Luca Marcialis",http://arxiv.org/pdf/2410.16341v1,cs.LG
Artificial intelligence for partial differential equations in computational mechanics: A review,"In recent years, Artificial intelligence (AI) has become ubiquitous,
empowering various fields, especially integrating artificial intelligence and
traditional science (AI for Science: Artificial intelligence for science),
which has attracted widespread attention. In AI for Science, using artificial
intelligence algorithms to solve partial differential equations (AI for PDEs:
Artificial intelligence for partial differential equations) has become a focal
point in computational mechanics. The core of AI for PDEs is the fusion of data
and partial differential equations (PDEs), which can solve almost any PDEs.
Therefore, this article provides a comprehensive review of the research on AI
for PDEs, summarizing the existing algorithms and theories. The article
discusses the applications of AI for PDEs in computational mechanics, including
solid mechanics, fluid mechanics, and biomechanics. The existing AI for PDEs
algorithms include those based on Physics-Informed Neural Networks (PINNs),
Deep Energy Methods (DEM), Operator Learning, and Physics-Informed Neural
Operator (PINO). AI for PDEs represents a new method of scientific simulation
that provides approximate solutions to specific problems using large amounts of
data, then fine-tuning according to specific physical laws, avoiding the need
to compute from scratch like traditional algorithms. Thus, AI for PDEs is the
prototype for future foundation models in computational mechanics, capable of
significantly accelerating traditional numerical algorithms.",2024-10-21,"Yizheng Wang, Jinshuai Bai, Zhongya Lin, Qimin Wang, Cosmin Anitescu, Jia Sun, Mohammad Sadegh Eshaghi, Yuantong Gu, Xi-Qiao Feng, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu",http://arxiv.org/pdf/2410.19843v2,cs.LG
"Private, Efficient and Scalable Kernel Learning for Medical Image Analysis","Medical imaging is key in modern medicine. From magnetic resonance imaging
(MRI) to microscopic imaging for blood cell detection, diagnostic medical
imaging reveals vital insights into patient health. To predict diseases or
provide individualized therapies, machine learning techniques like kernel
methods have been widely used. Nevertheless, there are multiple challenges for
implementing kernel methods. Medical image data often originates from various
hospitals and cannot be combined due to privacy concerns, and the high
dimensionality of image data presents another significant obstacle. While
randomised encoding offers a promising direction, existing methods often
struggle with a trade-off between accuracy and efficiency. Addressing the need
for efficient privacy-preserving methods on distributed image data, we
introduce OKRA (Orthonormal K-fRAmes), a novel randomized encoding-based
approach for kernel-based machine learning. This technique, tailored for widely
used kernel functions, significantly enhances scalability and speed compared to
current state-of-the-art solutions. Through experiments conducted on various
clinical image datasets, we evaluated model quality, computational performance,
and resource overhead. Additionally, our method outperforms comparable
approaches",2024-10-21,"Anika Hannemann, Arjhun Swaminathan, Ali Burak Ünal, Mete Akgün",http://arxiv.org/pdf/2410.15840v1,cs.LG
Explainability of Highly Associated Fuzzy Churn Patterns in Binary Classification,"Customer churn, particularly in the telecommunications sector, influences
both costs and profits. As the explainability of models becomes increasingly
important, this study emphasizes not only the explainability of customer churn
through machine learning models, but also the importance of identifying
multivariate patterns and setting soft bounds for intuitive interpretation. The
main objective is to use a machine learning model and fuzzy-set theory with
top-\textit{k} HUIM to identify highly associated patterns of customer churn
with intuitive identification, referred to as Highly Associated Fuzzy Churn
Patterns (HAFCP). Moreover, this method aids in uncovering association rules
among multiple features across low, medium, and high distributions. Such
discoveries are instrumental in enhancing the explainability of findings.
Experiments show that when the top-5 HAFCPs are included in five datasets, a
mixture of performance results is observed, with some showing notable
improvements. It becomes clear that high importance features enhance
explanatory power through their distribution and patterns associated with other
features. As a result, the study introduces an innovative approach that
improves the explainability and effectiveness of customer churn prediction
models.",2024-10-21,"D. Y. C. Wang, Lars Arne Jordanger, Jerry Chun-Wei Lin",http://arxiv.org/pdf/2410.15827v1,cs.LG
Limit Theorems for Stochastic Gradient Descent with Infinite Variance,"Stochastic gradient descent is a classic algorithm that has gained great
popularity especially in the last decades as the most common approach for
training models in machine learning. While the algorithm has been well-studied
when stochastic gradients are assumed to have a finite variance, there is
significantly less research addressing its theoretical properties in the case
of infinite variance gradients. In this paper, we establish the asymptotic
behavior of stochastic gradient descent in the context of infinite variance
stochastic gradients, assuming that the stochastic gradient is regular varying
with index $\alpha\in(1,2)$. The closest result in this context was established
in 1969 , in the one-dimensional case and assuming that stochastic gradients
belong to a more restrictive class of distributions. We extend it to the
multidimensional case, covering a broader class of infinite variance
distributions. As we show, the asymptotic distribution of the stochastic
gradient descent algorithm can be characterized as the stationary distribution
of a suitably defined Ornstein-Uhlenbeck process driven by an appropriate
stable L\'evy process. Additionally, we explore the applications of these
results in linear regression and logistic regression models.",2024-10-21,"Jose Blanchet, Aleksandar Mijatović, Wenhao Yang",http://arxiv.org/pdf/2410.16340v3,cs.LG
LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration,"Predicting the behavior of road users accurately is crucial to enable the
safe operation of autonomous vehicles in urban or densely populated areas.
Therefore, there has been a growing interest in time series motion prediction
research, leading to significant advancements in state-of-the-art techniques in
recent years. However, the potential of using LiDAR data to capture more
detailed local features, such as a person's gaze or posture, remains largely
unexplored. To address this, we develop a novel multimodal approach for motion
prediction based on the PointNet foundation model architecture, incorporating
local LiDAR features. Evaluation on the Waymo Open Dataset shows a performance
improvement of 6.20% and 1.58% in minADE and mAP respectively, when integrated
and compared with the previous state-of-the-art MTR. We open-source the code of
our LiMTR model.",2024-10-21,"Camiel Oerlemans, Bram Grooten, Michiel Braat, Alaa Alassi, Emilia Silvas, Decebal Constantin Mocanu",http://arxiv.org/pdf/2410.15819v1,cs.LG
Contrastive random lead coding for channel-agnostic self-supervision of biosignals,"Contrastive learning yields impressive results for self-supervision in
computer vision. The approach relies on the creation of positive pairs,
something which is often achieved through augmentations. However, for
multivariate time series effective augmentations can be difficult to design.
Additionally, the number of input channels for biosignal datasets often varies
from application to application, limiting the usefulness of large
self-supervised models trained with specific channel configurations. Motivated
by these challenges, we set out to investigate strategies for creation of
positive pairs for channel-agnostic self-supervision of biosignals. We
introduce contrastive random lead coding (CRLC), where random subsets of the
input channels are used to create positive pairs and compare with using
augmentations and neighboring segments in time as positive pairs. We validate
our approach by pre-training models on EEG and ECG data, and then fine-tuning
them for downstream tasks. CRLC outperforms competing strategies in both
scenarios in the channel-agnostic setting. For EEG, the approach additionally
outperforms the state-of-the-art reference model. Notably, for EEG tasks CRLC
surpasses the current state-of-the-art reference model. While, the
state-of-the-art reference model is superior in the ECG task, incorporating
CRLC allows us to obtain comparable results. In conclusion, CRLC helps
generalization across variable channel setups when training our
channel-agnostic model.",2024-10-21,"Thea Brüsch, Mikkel N. Schmidt, Tommy S. Alstrøm",http://arxiv.org/pdf/2410.19842v1,cs.LG
Solvation Free Energies from Neural Thermodynamic Integration,"We present a method for computing free-energy differences using thermodynamic
integration with a neural network potential that interpolates between two
target Hamiltonians. The interpolation is defined at the sample distribution
level, and the neural network potential is optimized to match the corresponding
equilibrium potential at every intermediate time-step. Once the interpolating
potentials and samples are well-aligned, the free-energy difference can be
estimated using (neural) thermodynamic integration. To target molecular
systems, we simultaneously couple Lennard-Jones and electrostatic interactions
and model the rigid-body rotation of molecules. We report accurate results for
several benchmark systems: a Lennard-Jones particle in a Lennard-Jones fluid,
as well as the insertion of both water and methane solutes in a water solvent
at atomistic resolution using a simple three-body neural-network potential.",2024-10-21,"Bálint Máté, François Fleuret, Tristan Bereau",http://arxiv.org/pdf/2410.15815v3,cs.LG
Mean-Field Simulation-Based Inference for Cosmological Initial Conditions,"Reconstructing cosmological initial conditions (ICs) from late-time
observations is a difficult task, which relies on the use of computationally
expensive simulators alongside sophisticated statistical methods to navigate
multi-million dimensional parameter spaces. We present a simple method for
Bayesian field reconstruction based on modeling the posterior distribution of
the initial matter density field to be diagonal Gaussian in Fourier space, with
its covariance and the mean estimator being the trainable parts of the
algorithm. Training and sampling are extremely fast (training: $\sim 1 \,
\mathrm{h}$ on a GPU, sampling: $\lesssim 3 \, \mathrm{s}$ for 1000 samples at
resolution $128^3$), and our method supports industry-standard
(non-differentiable) $N$-body simulators. We verify the fidelity of the
obtained IC samples in terms of summary statistics.",2024-10-21,"Oleg Savchenko, Florian List, Guillermo Franco Abellán, Noemi Anau Montel, Christoph Weniger",http://arxiv.org/pdf/2410.15808v1,cs.LG
Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt,"Self-Admitted Technical Debt (SATD) refers to circumstances where developers
use textual artifacts to explain why the existing implementation is not
optimal. Past research in detecting SATD has focused on either identifying SATD
(classifying SATD items as SATD or not) or categorizing SATD (labeling
instances as SATD that pertain to requirement, design, code, test debt, etc.).
However, the performance of these approaches remains suboptimal, particularly
for specific types of SATD, such as test and requirement debt, primarily due to
extremely imbalanced datasets. To address these challenges, we build on earlier
research by utilizing BiLSTM architecture for the binary identification of SATD
and BERT architecture for categorizing different types of SATD. Despite their
effectiveness, both architectures struggle with imbalanced data. Therefore, we
employ a large language model data augmentation strategy to mitigate this
issue. Furthermore, we introduce a two-step approach to identify and categorize
SATD across various datasets derived from different artifacts. Our
contributions include providing a balanced dataset for future SATD researchers
and demonstrating that our approach significantly improves SATD identification
and categorization performance compared to baseline methods.",2024-10-21,"Edi Sutoyo, Paris Avgeriou, Andrea Capiluppi",http://arxiv.org/pdf/2410.15804v1,cs.LG
On the VC dimension of deep group convolutional neural networks,"We study the generalization capabilities of Group Convolutional Neural
Networks (GCNNs) with ReLU activation function by deriving upper and lower
bounds for their Vapnik-Chervonenkis (VC) dimension. Specifically, we analyze
how factors such as the number of layers, weights, and input dimension affect
the VC dimension. We further compare the derived bounds to those known for
other types of neural networks. Our findings extend previous results on the VC
dimension of continuous GCNNs with two layers, thereby providing new insights
into the generalization properties of GCNNs, particularly regarding the
dependence on the input resolution of the data.",2024-10-21,"Anna Sepliarskaia, Sophie Langer, Johannes Schmidt-Hieber",http://arxiv.org/pdf/2410.15800v1,cs.LG
Contrastive Learning with Auxiliary User Detection for Identifying Activities,"Human Activity Recognition (HAR) is essential in ubiquitous computing, with
far-reaching real-world applications. While recent SOTA HAR research has
demonstrated impressive performance, some key aspects remain under-explored.
Firstly, HAR can be both highly contextualized and personalized. However, prior
work has predominantly focused on being Context-Aware (CA) while largely
ignoring the necessity of being User-Aware (UA). We argue that addressing the
impact of innate user action-performing differences is equally crucial as
considering external contextual environment settings in HAR tasks. Secondly,
being user-aware makes the model acknowledge user discrepancies but does not
necessarily guarantee mitigation of these discrepancies, i.e., unified
predictions under the same activities. There is a need for a methodology that
explicitly enforces closer (different user, same activity) representations. To
bridge this gap, we introduce CLAUDIA, a novel framework designed to address
these issues. Specifically, we expand the contextual scope of the CA-HAR task
by integrating User Identification (UI) within the CA-HAR framework, jointly
predicting both CA-HAR and UI in a new task called User and Context-Aware HAR
(UCA-HAR). This approach enriches personalized and contextual understanding by
jointly learning user-invariant and user-specific patterns. Inspired by SOTA
designs in the visual domain, we introduce a supervised contrastive loss
objective on instance-instance pairs to enhance model efficacy and improve
learned feature quality. Evaluation across three real-world CA-HAR datasets
reveals substantial performance enhancements, with average improvements ranging
from 5.8% to 14.1% in Matthew's Correlation Coefficient and 3.0% to 7.2% in
Macro F1 score.",2024-10-21,"Wen Ge, Guanyi Mou, Emmanuel O. Agu, Kyumin Lee",http://arxiv.org/pdf/2410.21300v1,cs.LG
Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count,"Transformers often struggle with length generalization, meaning they fail to
generalize to sequences longer than those encountered during training. While
arithmetic tasks are commonly used to study length generalization, certain
tasks are considered notoriously difficult, e.g., multi-operand addition
(requiring generalization over both the number of operands and their lengths)
and multiplication (requiring generalization over both operand lengths). In
this work, we achieve approximately 2-3x length generalization on both tasks,
which is the first such achievement in arithmetic Transformers. We design
task-specific scratchpads enabling the model to focus on a fixed number of
tokens per each next-token prediction step, and apply multi-level versions of
\Position Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers
know the right position to attend to. On the theory side, we prove that a
1-layer Transformer using our method can solve multi-operand addition, up to
operand length and operand count that are exponential in embedding dimension.",2024-10-21,"Hanseul Cho, Jaeyoung Cha, Srinadh Bhojanapalli, Chulhee Yun",http://arxiv.org/pdf/2410.15787v2,cs.LG
Reducing Hallucinations in Vision-Language Models via Latent Space Steering,"Hallucination poses a challenge to the deployment of large vision-language
models (LVLMs) in applications. Unlike in large language models (LLMs),
hallucination in LVLMs often arises from misalignments between visual inputs
and textual outputs. This paper investigates the underlying mechanisms of
hallucination, focusing on the unique structure of LVLMs that distinguishes
them from large language models (LLMs). We identify that hallucinations often
arise from the sensitivity of text decoders to vision inputs, a natural
phenomenon when image encoders and text decoders are pre-trained separately.
Inspired by this, we introduce Visual and Textual Intervention (VTI), a novel
technique designed to reduce hallucinations by steering latent space
representations during inference to enhance the stability of vision features.
As a task-agnostic test-time intervention, VTI can be easily applied to any
problem without additional cost. Extensive experiments demonstrate that it can
effectively reduce hallucinations and outperform baseline methods across
multiple metrics, highlighting the critical role of vision feature stability in
LVLMs.",2024-10-21,"Sheng Liu, Haotian Ye, Lei Xing, James Zou",http://arxiv.org/pdf/2410.15778v2,cs.LG
Revisiting the Equivalence of Bayesian Neural Networks and Gaussian Processes: On the Importance of Learning Activations,"Gaussian Processes (GPs) provide a convenient framework for specifying
function-space priors, making them a natural choice for modeling uncertainty.
In contrast, Bayesian Neural Networks (BNNs) offer greater scalability and
extendability but lack the advantageous properties of GPs. This motivates the
development of BNNs capable of replicating GP-like behavior. However, existing
solutions are either limited to specific GP kernels or rely on heuristics.
  We demonstrate that trainable activations are crucial for effective mapping
of GP priors to wide BNNs. Specifically, we leverage the closed-form
2-Wasserstein distance for efficient gradient-based optimization of
reparameterized priors and activations. Beyond learned activations, we also
introduce trainable periodic activations that ensure global stationarity by
design, and functional priors conditioned on GP hyperparameters to allow
efficient model selection.
  Empirically, our method consistently outperforms existing approaches or
matches performance of the heuristic methods, while offering stronger
theoretical foundations.",2024-10-21,"Marcin Sendera, Amin Sorkhei, Tomasz Kuśmierczyk",http://arxiv.org/pdf/2410.15777v2,cs.LG
"Mislabeled examples detection viewed as probing machine learning models: concepts, survey and extensive benchmark","Mislabeled examples are ubiquitous in real-world machine learning datasets,
advocating the development of techniques for automatic detection. We show that
most mislabeled detection methods can be viewed as probing trained machine
learning models using a few core principles. We formalize a modular framework
that encompasses these methods, parameterized by only 4 building blocks, as
well as a Python library that demonstrates that these principles can actually
be implemented. The focus is on classifier-agnostic concepts, with an emphasis
on adapting methods developed for deep learning models to non-deep classifiers
for tabular data. We benchmark existing methods on (artificial) Completely At
Random (NCAR) as well as (realistic) Not At Random (NNAR) labeling noise from a
variety of tasks with imperfect labeling rules. This benchmark provides new
insights as well as limitations of existing methods in this setup.",2024-10-21,"Thomas George, Pierre Nodet, Alexis Bondu, Vincent Lemaire",http://arxiv.org/pdf/2410.15772v1,cs.LG
SeisLM: a Foundation Model for Seismic Waveforms,"We introduce the Seismic Language Model (SeisLM), a foundational model
designed to analyze seismic waveforms -- signals generated by Earth's
vibrations such as the ones originating from earthquakes. SeisLM is pretrained
on a large collection of open-source seismic datasets using a self-supervised
contrastive loss, akin to BERT in language modeling. This approach allows the
model to learn general seismic waveform patterns from unlabeled data without
being tied to specific downstream tasks. When fine-tuned, SeisLM excels in
seismological tasks like event detection, phase-picking, onset time regression,
and foreshock-aftershock classification. The code has been made publicly
available on https://github.com/liutianlin0121/seisLM.",2024-10-21,"Tianlin Liu, Jannes Münchmeyer, Laura Laurenti, Chris Marone, Maarten V. de Hoop, Ivan Dokmanić",http://arxiv.org/pdf/2410.15765v1,cs.LG
Solving Sparse \& High-Dimensional-Output Regression via Compression,"Multi-Output Regression (MOR) has been widely used in scientific data
analysis for decision-making. Unlike traditional regression models, MOR aims to
simultaneously predict multiple real-valued outputs given an input. However,
the increasing dimensionality of the outputs poses significant challenges
regarding interpretability and computational scalability for modern MOR
applications. As a first step to address these challenges, this paper proposes
a Sparse \& High-dimensional-Output REgression (SHORE) model by incorporating
additional sparsity requirements to resolve the output interpretability, and
then designs a computationally efficient two-stage optimization framework
capable of solving SHORE with provable accuracy via compression on outputs.
Theoretically, we show that the proposed framework is computationally scalable
while maintaining the same order of training loss and prediction loss
before-and-after compression under arbitrary or relatively weak sample set
conditions. Empirically, numerical results further validate the theoretical
findings, showcasing the efficiency and accuracy of the proposed framework.",2024-10-21,"Renyuan Li, Zhehui Chen, Guanyi Wang",http://arxiv.org/pdf/2410.15762v1,cs.LG
Optimal Query Allocation in Extractive QA with LLMs: A Learning-to-Defer Framework with Theoretical Guarantees,"Large Language Models excel in generative tasks but exhibit inefficiencies in
structured text selection, particularly in extractive question answering. This
challenge is magnified in resource-constrained environments, where deploying
multiple specialized models for different tasks is impractical. We propose a
Learning-to-Defer framework that allocates queries to specialized experts,
ensuring high-confidence predictions while optimizing computational efficiency.
Our approach integrates a principled allocation strategy with theoretical
guarantees on optimal deferral that balances performance and cost. Empirical
evaluations on SQuADv1, SQuADv2, and TriviaQA demonstrate that our method
enhances answer reliability while significantly reducing computational
overhead, making it well-suited for scalable and efficient EQA deployment.",2024-10-21,"Yannis Montreuil, Shu Heng Yeo, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi",http://arxiv.org/pdf/2410.15761v3,cs.LG
DeepVigor+: Scalable and Accurate Semi-Analytical Fault Resilience Analysis for Deep Neural Network,"Growing exploitation of Machine Learning (ML) in safety-critical applications
necessitates rigorous safety analysis. Hardware reliability assessment is a
major concern with respect to measuring the level of safety. Quantifying the
reliability of emerging ML models, including Deep Neural Networks (DNNs), is
highly complex due to their enormous size in terms of the number of parameters
and computations. Conventionally, Fault Injection (FI) is applied to perform a
reliability measurement. However, performing FI on modern-day DNNs is
prohibitively time-consuming if an acceptable confidence level is to be
achieved. In order to speed up FI for large DNNs, statistical FI has been
proposed. However, the run-time for the large DNN models is still considerably
long.
  In this work, we introduce DeepVigor+, a scalable, fast and accurate
semi-analytical method as an efficient alternative for reliability measurement
in DNNs. DeepVigor+ implements a fault propagation analysis model and attempts
to acquire Vulnerability Factors (VFs) as reliability metrics in an optimal
way. The results indicate that DeepVigor+ obtains VFs for DNN models with an
error less than 1\% and 14.9 up to 26.9 times fewer simulations than the
best-known state-of-the-art statistical FI enabling an accurate reliability
analysis for emerging DNNs within a few minutes.",2024-10-21,"Mohammad Hasan Ahmadilivani, Jaan Raik, Masoud Daneshtalab, Maksim Jenihhin",http://arxiv.org/pdf/2410.15742v1,cs.LG
A Two-Stage Learning-to-Defer Approach for Multi-Task Learning,"The Two-Stage Learning-to-Defer (L2D) framework has been extensively studied
for classification and, more recently, regression tasks. However, many
real-world applications require solving both tasks jointly in a multi-task
setting. We introduce a novel Two-Stage L2D framework for multi-task learning
that integrates classification and regression through a unified deferral
mechanism. Our method leverages a two-stage surrogate loss family, which we
prove to be both Bayes-consistent and $(\mathcal{G}, \mathcal{R})$-consistent,
ensuring convergence to the Bayes-optimal rejector. We derive explicit
consistency bounds tied to the cross-entropy surrogate and the $L_1$-norm of
agent-specific costs, and extend minimizability gap analysis to the
multi-expert two-stage regime. We also make explicit how shared representation
learning--commonly used in multi-task models--affects these consistency
guarantees. Experiments on object detection and electronic health record
analysis demonstrate the effectiveness of our approach and highlight the
limitations of existing L2D methods in multi-task scenarios.",2024-10-21,"Yannis Montreuil, Shu Heng Yeo, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi",http://arxiv.org/pdf/2410.15729v4,cs.LG
Object-Centric Temporal Consistency via Conditional Autoregressive Inductive Biases,"Unsupervised object-centric learning from videos is a promising approach
towards learning compositional representations that can be applied to various
downstream tasks, such as prediction and reasoning. Recently, it was shown that
pretrained Vision Transformers (ViTs) can be useful to learn object-centric
representations on real-world video datasets. However, while these approaches
succeed at extracting objects from the scenes, the slot-based representations
fail to maintain temporal consistency across consecutive frames in a video,
i.e. the mapping of objects to slots changes across the video. To address this,
we introduce Conditional Autoregressive Slot Attention (CA-SA), a framework
that enhances the temporal consistency of extracted object-centric
representations in video-centric vision tasks. Leveraging an autoregressive
prior network to condition representations on previous timesteps and a novel
consistency loss function, CA-SA predicts future slot representations and
imposes consistency across frames. We present qualitative and quantitative
results showing that our proposed method outperforms the considered baselines
on downstream tasks, such as video prediction and visual question-answering
tasks.",2024-10-21,"Cristian Meo, Akihiro Nakano, Mircea Lică, Aniket Didolkar, Masahiro Suzuki, Anirudh Goyal, Mengmi Zhang, Justin Dauwels, Yutaka Matsuo, Yoshua Bengio",http://arxiv.org/pdf/2410.15728v1,cs.LG
S-CFE: Simple Counterfactual Explanations,"We study the problem of finding optimal sparse, manifold-aligned
counterfactual explanations for classifiers. Canonically, this can be
formulated as an optimization problem with multiple non-convex components,
including classifier loss functions and manifold alignment (or
\emph{plausibility}) metrics. The added complexity of enforcing
\emph{sparsity}, or shorter explanations, complicates the problem further.
Existing methods often focus on specific models and plausibility measures,
relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, we
tackle the canonical formulation using the accelerated proximal gradient (APG)
method, a simple yet efficient first-order procedure capable of handling smooth
non-convex objectives and non-smooth $\ell_p$ (where $0 \leq p < 1$)
regularizers. This enables our approach to seamlessly incorporate various
classifiers and plausibility measures while producing sparser solutions. Our
algorithm only requires differentiable data-manifold regularizers and supports
box constraints for bounded feature ranges, ensuring the generated
counterfactuals remain \emph{actionable}. Finally, experiments on real-world
datasets demonstrate that our approach effectively produces sparse,
manifold-aligned counterfactual explanations while maintaining proximity to the
factual data and computational efficiency.",2024-10-21,"Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta",http://arxiv.org/pdf/2410.15723v5,cs.LG
Learning signals defined on graphs with optimal transport and Gaussian process regression,"In computational physics, machine learning has now emerged as a powerful
complementary tool to explore efficiently candidate designs in engineering
studies. Outputs in such supervised problems are signals defined on meshes, and
a natural question is the extension of general scalar output regression models
to such complex outputs. Changes between input geometries in terms of both size
and adjacency structure in particular make this transition non-trivial. In this
work, we propose an innovative strategy for Gaussian process regression where
inputs are large and sparse graphs with continuous node attributes and outputs
are signals defined on the nodes of the associated inputs. The methodology
relies on the combination of regularized optimal transport, dimension reduction
techniques, and the use of Gaussian processes indexed by graphs. In addition to
enabling signal prediction, the main point of our proposal is to come with
confidence intervals on node values, which is crucial for uncertainty
quantification and active learning. Numerical experiments highlight the
efficiency of the method to solve real problems in fluid dynamics and solid
mechanics.",2024-10-21,"Raphaël Carpintero Perez, Sébastien da Veiga, Josselin Garnier, Brian Staber",http://arxiv.org/pdf/2410.15721v2,cs.LG
Traffic Matrix Estimation based on Denoising Diffusion Probabilistic Model,"The traffic matrix estimation (TME) problem has been widely researched for
decades of years. Recent progresses in deep generative models offer new
opportunities to tackle TME problems in a more advanced way. In this paper, we
leverage the powerful ability of denoising diffusion probabilistic models
(DDPMs) on distribution learning, and for the first time adopt DDPM to address
the TME problem. To ensure a good performance of DDPM on learning the
distributions of TMs, we design a preprocessing module to reduce the dimensions
of TMs while keeping the data variety of each OD flow. To improve the
estimation accuracy, we parameterize the noise factors in DDPM and transform
the TME problem into a gradient-descent optimization problem. Finally, we
compared our method with the state-of-the-art TME methods using two real-world
TM datasets, the experimental results strongly demonstrate the superiority of
our method on both TM synthesis and TM estimation.",2024-10-21,"Xinyu Yuan, Yan Qiao, Pei Zhao, Rongyao Hu, Benchu Zhang",http://arxiv.org/pdf/2410.15716v1,cs.LG
Offline reinforcement learning for job-shop scheduling problems,"Recent advances in deep learning have shown significant potential for solving
combinatorial optimization problems in real-time. Unlike traditional methods,
deep learning can generate high-quality solutions efficiently, which is crucial
for applications like routing and scheduling. However, existing approaches like
deep reinforcement learning (RL) and behavioral cloning have notable
limitations, with deep RL suffering from slow learning and behavioral cloning
relying solely on expert actions, which can lead to generalization issues and
neglect of the optimization objective. This paper introduces a novel offline RL
method designed for combinatorial optimization problems with complex
constraints, where the state is represented as a heterogeneous graph and the
action space is variable. Our approach encodes actions in edge attributes and
balances expected rewards with the imitation of expert solutions. We
demonstrate the effectiveness of this method on job-shop scheduling and
flexible job-shop scheduling benchmarks, achieving superior performance
compared to state-of-the-art techniques.",2024-10-21,"Imanol Echeverria, Maialen Murua, Roberto Santana",http://arxiv.org/pdf/2410.15714v3,cs.LG
Estimating Individual Dose-Response Curves under Unobserved Confounders from Observational Data,"Estimating an individual's potential response to continuously varied
treatments is crucial for addressing causal questions across diverse domains,
from healthcare to social sciences. However, existing methods are limited
either to estimating causal effects of binary treatments, or scenarios where
all confounding variables are measurable. In this work, we present ContiVAE, a
novel framework for estimating causal effects of continuous treatments,
measured by individual dose-response curves, considering the presence of
unobserved confounders using observational data. Leveraging a variational
auto-encoder with a Tilted Gaussian prior distribution, ContiVAE models the
hidden confounders as latent variables, and is able to predict the potential
outcome of any treatment level for each individual while effectively capture
the heterogeneity among individuals. Experiments on semi-synthetic datasets
show that ContiVAE outperforms existing methods by up to 62%, demonstrating its
robustness and flexibility. Application on a real-world dataset illustrates its
practical utility.",2024-10-21,"Shutong Chen, Yang Li",http://arxiv.org/pdf/2410.15706v1,cs.LG
Residual vector quantization for KV cache compression in large language model,"KV cache compression methods have mainly relied on scalar quantization
techniques to reduce the memory requirements during decoding. In this work, we
apply residual vector quantization, which has been widely used for high
fidelity audio compression, to compress KV cache in large language models
(LLM). We adapt the standard recipe with minimal changes to compress the output
of any key or value projection matrix in a pretrained LLM: we scale the vector
by its standard deviation, divide channels into groups and then quantize each
group with the same residual vector quantizer. We learn the codebook using
exponential moving average and there are no other learnable parameters
including the input and output projections normally used in a vector
quantization set up. We find that a residual depth of 8 recovers most of the
performance of the unquantized model. We also find that grouping non-contiguous
channels together works better than grouping contiguous channels for
compressing key matrix and the method further benefits from a light weight
finetuning of LLM together with the quantization. Overall, the proposed
technique is competitive with existing quantization methods while being much
simpler and results in 5.5x compression compared to half precision.",2024-10-21,Ankur Kumar,http://arxiv.org/pdf/2410.15704v1,cs.LG
Solving Continual Offline RL through Selective Weights Activation on Aligned Spaces,"Continual offline reinforcement learning (CORL) has shown impressive ability
in diffusion-based lifelong learning systems by modeling the joint
distributions of trajectories. However, most research only focuses on limited
continual task settings where the tasks have the same observation and action
space, which deviates from the realistic demands of training agents in various
environments. In view of this, we propose Vector-Quantized Continual Diffuser,
named VQ-CD, to break the barrier of different spaces between various tasks.
Specifically, our method contains two complementary sections, where the
quantization spaces alignment provides a unified basis for the selective
weights activation. In the quantized spaces alignment, we leverage vector
quantization to align the different state and action spaces of various tasks,
facilitating continual training in the same space. Then, we propose to leverage
a unified diffusion model attached by the inverse dynamic model to master all
tasks by selectively activating different weights according to the task-related
sparse masks. Finally, we conduct extensive experiments on 15 continual
learning (CL) tasks, including conventional CL task settings (identical state
and action spaces) and general CL task settings (various state and action
spaces). Compared with 16 baselines, our method reaches the SOTA performance.",2024-10-21,"Jifeng Hu, Sili Huang, Li Shen, Zhejian Yang, Shengchao Hu, Shisong Tang, Hechang Chen, Yi Chang, Dacheng Tao, Lichao Sun",http://arxiv.org/pdf/2410.15698v1,cs.LG
Enhancing SNN-based Spatio-Temporal Learning: A Benchmark Dataset and Cross-Modality Attention Model,"Spiking Neural Networks (SNNs), renowned for their low power consumption,
brain-inspired architecture, and spatio-temporal representation capabilities,
have garnered considerable attention in recent years. Similar to Artificial
Neural Networks (ANNs), high-quality benchmark datasets are of great importance
to the advances of SNNs. However, our analysis indicates that many prevalent
neuromorphic datasets lack strong temporal correlation, preventing SNNs from
fully exploiting their spatio-temporal representation capabilities. Meanwhile,
the integration of event and frame modalities offers more comprehensive visual
spatio-temporal information. Yet, the SNN-based cross-modality fusion remains
underexplored.
  In this work, we present a neuromorphic dataset called DVS-SLR that can
better exploit the inherent spatio-temporal properties of SNNs. Compared to
existing datasets, it offers advantages in terms of higher temporal
correlation, larger scale, and more varied scenarios. In addition, our
neuromorphic dataset contains corresponding frame data, which can be used for
developing SNN-based fusion methods. By virtue of the dual-modal feature of the
dataset, we propose a Cross-Modality Attention (CMA) based fusion method. The
CMA model efficiently utilizes the unique advantages of each modality, allowing
for SNNs to learn both temporal and spatial attention scores from the
spatio-temporal features of event and frame modalities, subsequently allocating
these scores across modalities to enhance their synergy. Experimental results
demonstrate that our method not only improves recognition accuracy but also
ensures robustness across diverse scenarios.",2024-10-21,"Shibo Zhou, Bo Yang, Mengwen Yuan, Runhao Jiang, Rui Yan, Gang Pan, Huajin Tang",http://arxiv.org/pdf/2410.15689v1,cs.LG
"MIK: Modified Isolation Kernel for Biological Sequence Visualization, Classification, and Clustering","The t-Distributed Stochastic Neighbor Embedding (t-SNE) has emerged as a
popular dimensionality reduction technique for visualizing high-dimensional
data. It computes pairwise similarities between data points by default using an
RBF kernel and random initialization (in low-dimensional space), which
successfully captures the overall structure but may struggle to preserve the
local structure efficiently. This research proposes a novel approach called the
Modified Isolation Kernel (MIK) as an alternative to the Gaussian kernel, which
is built upon the concept of the Isolation Kernel. MIK uses adaptive density
estimation to capture local structures more accurately and integrates
robustness measures. It also assigns higher similarity values to nearby points
and lower values to distant points. Comparative research using the normal
Gaussian kernel, the isolation kernel, and several initialization techniques,
including random, PCA, and random walk initializations, are used to assess the
proposed approach (MIK). Additionally, we compare the computational efficiency
of all $3$ kernels with $3$ different initialization methods. Our experimental
results demonstrate several advantages of the proposed kernel (MIK) and
initialization method selection. It exhibits improved preservation of the local
and global structure and enables better visualization of clusters and
subclusters in the embedded space. These findings contribute to advancing
dimensionality reduction techniques and provide researchers and practitioners
with an effective tool for data exploration, visualization, and analysis in
various domains.",2024-10-21,"Sarwan Ali, Prakash Chourasia, Haris Mansoor, Bipin koirala, Murray Patterson",http://arxiv.org/pdf/2410.15688v1,cs.LG
Federated Learning with MMD-based Early Stopping for Adaptive GNSS Interference Classification,"Federated learning (FL) enables multiple devices to collaboratively train a
global model while maintaining data on local servers. Each device trains the
model on its local server and shares only the model updates (i.e., gradient
weights) during the aggregation step. A significant challenge in FL is managing
the feature distribution of novel and unbalanced data across devices. In this
paper, we propose an FL approach using few-shot learning and aggregation of the
model weights on a global server. We introduce a dynamic early stopping method
to balance out-of-distribution classes based on representation learning,
specifically utilizing the maximum mean discrepancy of feature embeddings
between local and global models. An exemplary application of FL is to
orchestrate machine learning models along highways for interference
classification based on snapshots from global navigation satellite system
(GNSS) receivers. Extensive experiments on four GNSS datasets from two
real-world highways and controlled environments demonstrate that our FL method
surpasses state-of-the-art techniques in adapting to both novel interference
classes and multipath scenarios.",2024-10-21,"Nishant S. Gaikwad, Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Christopher Mutschler, Felix Ott",http://arxiv.org/pdf/2410.15681v2,cs.LG
Towards More Accurate US Presidential Election via Multi-step Reasoning with Large Language Models,"Can Large Language Models (LLMs) accurately predict election outcomes? While
LLMs have demonstrated impressive performance in various domains, including
healthcare, legal analysis, and creative tasks, their ability to forecast
elections remains unknown. Election prediction poses unique challenges, such as
limited voter-level data, rapidly changing political landscapes, and the need
to model complex human behavior. To address these challenges, we introduce a
multi-step reasoning framework designed for political analysis. Our approach is
validated on real-world data from the American National Election Studies (ANES)
2016 and 2020, as well as synthetic personas generated by the leading machine
learning framework, offering scalable datasets for voter behavior modeling. To
capture temporal dynamics, we incorporate candidates' policy positions and
biographical details, ensuring that the model adapts to evolving political
contexts. Drawing on Chain of Thought prompting, our multi-step reasoning
pipeline systematically integrates demographic, ideological, and time-dependent
factors, enhancing the model's predictive power.",2024-10-21,"Chenxiao Yu, Zhaotian Weng, Yuangang Li, Zheng Li, Xiyang Hu, Yue Zhao",http://arxiv.org/pdf/2411.03321v3,cs.LG
RAC: Efficient LLM Factuality Correction with Retrieval Augmentation,"Large Language Models (LLMs) exhibit impressive results across a wide range
of natural language processing (NLP) tasks, yet they can often produce
factually incorrect outputs. This paper introduces a simple but effective
low-latency post-correction method, \textbf{Retrieval Augmented Correction
(RAC)}, aimed at enhancing the factual performance of LLMs without requiring
additional fine-tuning. Our method is general and can be used with any
instruction-tuned LLM, and has greatly reduced latency compared to prior
approaches. RAC decomposes the LLM's output into atomic facts and applies a
fine-grained verification and correction process with retrieved content to
verify and correct the LLM-generated output. Our extensive experiments show
that RAC yields up to 30\% improvements over state-of-the-art baselines across
two popular factuality evaluation datasets, validating its efficacy and
robustness in both with and without the integration of Retrieval-Augmented
Generation (RAG) across different LLMs.\footnote{Our code is at
\url{https://github.com/jlab-nlp/Retrieval-Augmented-Correction}}",2024-10-21,"Changmao Li, Jeffrey Flanigan",http://arxiv.org/pdf/2410.15667v1,cs.LG
Long Term Memory: The Foundation of AI Self-Evolution,"Large language models (LLMs) like GPTs, trained on vast datasets, have
demonstrated impressive capabilities in language understanding, reasoning, and
planning, achieving human-level performance in various tasks. Most studies
focus on enhancing these models by training on ever-larger datasets to build
more powerful foundation models. While training stronger models is important,
enabling models to evolve during inference is equally crucial, a process we
refer to as AI self-evolution. Unlike large-scale training, self-evolution may
rely on limited data or interactions. Inspired by the columnar organization of
the human cerebral cortex, we hypothesize that AI models could develop
cognitive abilities and build internal representations through iterative
interactions with their environment. To achieve this, models need long-term
memory (LTM) to store and manage processed interaction data. LTM supports
self-evolution by representing diverse experiences across environments and
agents. In this report, we explore AI self-evolution and its potential to
enhance models during inference. We examine LTM's role in lifelong learning,
allowing models to evolve based on accumulated interactions. We outline the
structure of LTM and the systems needed for effective data retention and
representation. We also classify approaches for building personalized models
with LTM data and show how these models achieve self-evolution through
interaction. Using LTM, our multi-agent framework OMNE achieved first place on
the GAIA benchmark, demonstrating LTM's potential for AI self-evolution.
Finally, we present a roadmap for future research, emphasizing the importance
of LTM for advancing AI technology and its practical applications.",2024-10-21,"Xun Jiang, Feng Li, Han Zhao, Jiahao Qiu, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, Mengyue Wu, Weizhi Ma, Mengdi Wang, Tianqiao Chen",http://arxiv.org/pdf/2410.15665v4,cs.LG
Scalable Data Ablation Approximations for Language Models through Modular Training and Merging,"Training data compositions for Large Language Models (LLMs) can significantly
affect their downstream performance. However, a thorough data ablation study
exploring large sets of candidate data mixtures is typically prohibitively
expensive since the full effect is seen only after training the models; this
can lead practitioners to settle for sub-optimal data mixtures. We propose an
efficient method for approximating data ablations which trains individual
models on subsets of a training corpus and reuses them across evaluations of
combinations of subsets. In continued pre-training experiments, we find that,
given an arbitrary evaluation set, the perplexity score of a single model
trained on a candidate set of data is strongly correlated with perplexity
scores of parameter averages of models trained on distinct partitions of that
data. From this finding, we posit that researchers and practitioners can
conduct inexpensive simulations of data ablations by maintaining a pool of
models that were each trained on partitions of a large training corpus, and
assessing candidate data mixtures by evaluating parameter averages of
combinations of these models. This approach allows for substantial improvements
in amortized training efficiency -- scaling only linearly with respect to new
data -- by enabling reuse of previous training computation, opening new avenues
for improving model performance through rigorous, incremental data assessment
and mixing.",2024-10-21,"Clara Na, Ian Magnusson, Ananya Harsh Jha, Tom Sherborne, Emma Strubell, Jesse Dodge, Pradeep Dasigi",http://arxiv.org/pdf/2410.15661v1,cs.LG
Calibration of Ordinal Regression Networks,"Recent studies have shown that deep neural networks are not well-calibrated
and often produce over-confident predictions. The miscalibration issue
primarily stems from using cross-entropy in classifications, which aims to
align predicted softmax probabilities with one-hot labels. In ordinal
regression tasks, this problem is compounded by an additional challenge: the
expectation that softmax probabilities should exhibit unimodal distribution is
not met with cross-entropy. The ordinal regression literature has focused on
learning orders and overlooked calibration. To address both issues, we propose
a novel loss function that introduces ordinal-aware calibration, ensuring that
prediction confidence adheres to ordinal relationships between classes. It
incorporates soft ordinal encoding and ordinal-aware regularization to enforce
both calibration and unimodality. Extensive experiments across four popular
ordinal regression benchmarks demonstrate that our approach achieves
state-of-the-art calibration without compromising classification accuracy.",2024-10-21,"Daehwan Kim, Haejun Chung, Ikbeom Jang",http://arxiv.org/pdf/2410.15658v3,cs.LG
Accounting for Missing Covariates in Heterogeneous Treatment Estimation,"Many applications of causal inference require using treatment effects
estimated on a study population to make decisions in a separate target
population. We consider the challenging setting where there are covariates that
are observed in the target population that were not seen in the original study.
Our goal is to estimate the tightest possible bounds on heterogeneous treatment
effects conditioned on such newly observed covariates. We introduce a novel
partial identification strategy based on ideas from ecological inference; the
main idea is that estimates of conditional treatment effects for the full
covariate set must marginalize correctly when restricted to only the covariates
observed in both populations. Furthermore, we introduce a bias-corrected
estimator for these bounds and prove that it enjoys fast convergence rates and
statistical guarantees (e.g., asymptotic normality). Experimental results on
both real and synthetic data demonstrate that our framework can produce bounds
that are much tighter than would otherwise be possible.",2024-10-21,"Khurram Yamin, Vibhhu Sharma, Ed Kennedy, Bryan Wilder",http://arxiv.org/pdf/2410.15655v1,cs.LG
Understanding and Alleviating Memory Consumption in RLHF for LLMs,"Fine-tuning with Reinforcement Learning with Human Feedback (RLHF) is
essential for aligning large language models (LLMs). However, RLHF often
encounters significant memory challenges. This study is the first to examine
memory usage in the RLHF context, exploring various memory management
strategies and unveiling the reasons behind excessive memory consumption.
Additionally, we introduce a simple yet effective approach that substantially
reduces the memory required for RLHF fine-tuning.",2024-10-21,"Jin Zhou, Hanmei Yang, Steven, Tang, Mingcan Xiang, Hui Guan, Tongping Liu",http://arxiv.org/pdf/2410.15651v1,cs.LG
Linking Model Intervention to Causal Interpretation in Model Explanation,"Intervention intuition is often used in model explanation where the
intervention effect of a feature on the outcome is quantified by the difference
of a model prediction when the feature value is changed from the current value
to the baseline value. Such a model intervention effect of a feature is
inherently association. In this paper, we will study the conditions when an
intuitive model intervention effect has a causal interpretation, i.e., when it
indicates whether a feature is a direct cause of the outcome. This work links
the model intervention effect to the causal interpretation of a model. Such an
interpretation capability is important since it indicates whether a machine
learning model is trustworthy to domain experts. The conditions also reveal the
limitations of using a model intervention effect for causal interpretation in
an environment with unobserved features. Experiments on semi-synthetic datasets
have been conducted to validate theorems and show the potential for using the
model intervention effect for model interpretation.",2024-10-21,"Debo Cheng, Ziqi Xu, Jiuyong Li, Lin Liu, Kui Yu, Thuc Duy Le, Jixue Liu",http://arxiv.org/pdf/2410.15648v1,cs.LG
Deep Graph Attention Networks,"Graphs are useful for representing various realworld objects. However, graph
neural networks (GNNs) tend to suffer from over-smoothing, where the
representations of nodes of different classes become similar as the number of
layers increases, leading to performance degradation. A method that does not
require protracted tuning of the number of layers is needed to effectively
construct a graph attention network (GAT), a type of GNN. Therefore, we
introduce a method called ""DeepGAT"" for predicting the class to which nodes
belong in a deep GAT. It avoids over-smoothing in a GAT by ensuring that nodes
in different classes are not similar at each layer. Using DeepGAT to predict
class labels, a 15-layer network is constructed without the need to tune the
number of layers. DeepGAT prevented over-smoothing and achieved a 15-layer GAT
with similar performance to a 2-layer GAT, as indicated by the similar
attention coefficients. DeepGAT enables the training of a large network to
acquire similar attention coefficients to a network with few layers. It avoids
the over-smoothing problem and obviates the need to tune the number of layers,
thus saving time and enhancing GNN performance.",2024-10-21,"Jun Kato, Airi Mita, Keita Gobara, Akihiro Inokuchi",http://arxiv.org/pdf/2410.15640v1,cs.LG
Large Deviation Upper Bounds and Improved MSE Rates of Nonlinear SGD: Heavy-tailed Noise and Power of Symmetry,"We study large deviation upper bounds and mean-squared error (MSE) guarantees
of a general framework of nonlinear stochastic gradient methods in the online
setting, in the presence of heavy-tailed noise. Unlike existing works that rely
on the closed form of a nonlinearity (typically clipping), our framework treats
the nonlinearity in a black-box manner, allowing us to provide unified
guarantees for a broad class of bounded nonlinearities, including many popular
ones, like sign, quantization, normalization, as well as component-wise and
joint clipping. We provide several strong results for a broad range of
step-sizes in the presence of heavy-tailed noise with symmetric probability
density function, positive in a neighbourhood of zero and potentially unbounded
moments. In particular, for non-convex costs we provide a large deviation upper
bound for the minimum norm-squared of gradients, showing an asymptotic tail
decay on an exponential scale, at a rate $\sqrt{t} / \log(t)$. We establish the
accompanying rate function, showing an explicit dependence on the choice of
step-size, nonlinearity, noise and problem parameters. Next, for non-convex
costs and the minimum norm-squared of gradients, we derive the optimal MSE rate
$\widetilde{\mathcal{O}}(t^{-1/2})$. Moreover, for strongly convex costs and
the last iterate, we provide an MSE rate that can be made arbitrarily close to
the optimal rate $\mathcal{O}(t^{-1})$, improving on the state-of-the-art
results in the presence of heavy-tailed noise. Finally, we establish almost
sure convergence of the minimum norm-squared of gradients, providing an
explicit rate, which can be made arbitrarily close to $o(t^{-1/4})$.",2024-10-21,"Aleksandar Armacki, Shuhua Yu, Dragana Bajovic, Dusan Jakovetic, Soummya Kar",http://arxiv.org/pdf/2410.15637v2,cs.LG
Towards Kriging-informed Conditional Diffusion for Regional Sea-Level Data Downscaling,"Given coarser-resolution projections from global climate models or satellite
data, the downscaling problem aims to estimate finer-resolution regional
climate data, capturing fine-scale spatial patterns and variability.
Downscaling is any method to derive high-resolution data from low-resolution
variables, often to provide more detailed and local predictions and analyses.
This problem is societally crucial for effective adaptation, mitigation, and
resilience against significant risks from climate change. The challenge arises
from spatial heterogeneity and the need to recover finer-scale features while
ensuring model generalization. Most downscaling methods \cite{Li2020} fail to
capture the spatial dependencies at finer scales and underperform on real-world
climate datasets, such as sea-level rise. We propose a novel Kriging-informed
Conditional Diffusion Probabilistic Model (Ki-CDPM) to capture spatial
variability while preserving fine-scale features. Experimental results on
climate data show that our proposed method is more accurate than
state-of-the-art downscaling techniques.",2024-10-21,"Subhankar Ghosh, Arun Sharma, Jayant Gupta, Aneesh Subramanian, Shashi Shekhar",http://arxiv.org/pdf/2410.15628v3,cs.LG
Improving Parallel Program Performance with LLM Optimizers via Agent-System Interface,"Modern scientific discovery increasingly relies on high-performance computing
for complex modeling and simulation. A key challenge in improving parallel
program performance is efficiently mapping tasks to processors and data to
memory, a process dictated by intricate, low-level system code known as
mappers. Developing high-performance mappers demands days of manual tuning,
posing a significant barrier for domain scientists without systems expertise.
We introduce a framework that automates mapper development with generative
optimization, leveraging richer feedback beyond scalar performance metrics. Our
approach features the Agent-System Interface, which includes a Domain-Specific
Language (DSL) to abstract away low-level complexity of system code and define
a structured search space, as well as AutoGuide, a mechanism that interprets
raw execution output into actionable feedback. Unlike traditional reinforcement
learning methods such as OpenTuner, which rely solely on scalar feedback, our
method finds superior mappers in far fewer iterations. With just 10 iterations,
it outperforms OpenTuner even after 1000 iterations, achieving 3.8X faster
performance. Our approach finds mappers that surpass expert-written mappers by
up to 1.34X speedup across nine benchmarks while reducing tuning time from days
to minutes.",2024-10-21,"Anjiang Wei, Allen Nie, Thiago S. F. X. Teixeira, Rohan Yadav, Wonchan Lee, Ke Wang, Alex Aiken",http://arxiv.org/pdf/2410.15625v2,cs.LG
Test-time Adaptation for Cross-modal Retrieval with Query Shift,"The success of most existing cross-modal retrieval methods heavily relies on
the assumption that the given queries follow the same distribution of the
source domain. However, such an assumption is easily violated in real-world
scenarios due to the complexity and diversity of queries, thus leading to the
query shift problem. Specifically, query shift refers to the online query
stream originating from the domain that follows a different distribution with
the source one. In this paper, we observe that query shift would not only
diminish the uniformity (namely, within-modality scatter) of the query modality
but also amplify the gap between query and gallery modalities. Based on the
observations, we propose a novel method dubbed Test-time adaptation for
Cross-modal Retrieval (TCR). In brief, TCR employs a novel module to refine the
query predictions (namely, retrieval results of the query) and a joint
objective to prevent query shift from disturbing the common space, thus
achieving online adaptation for the cross-modal retrieval models with query
shift. Expensive experiments demonstrate the effectiveness of the proposed TCR
against query shift. The code will be released upon acceptance.",2024-10-21,"Haobin Li, Peng Hu, Qianjun Zhang, Xi Peng, Xiting Liu, Mouxing Yang",http://arxiv.org/pdf/2410.15624v1,cs.LG
Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation,"Diffusion models excel at generating visually striking content from text but
can inadvertently produce undesirable or harmful content when trained on
unfiltered internet data. A practical solution is to selectively removing
target concepts from the model, but this may impact the remaining concepts.
Prior approaches have tried to balance this by introducing a loss term to
preserve neutral content or a regularization term to minimize changes in the
model parameters, yet resolving this trade-off remains challenging. In this
work, we propose to identify and preserving concepts most affected by parameter
changes, termed as \textit{adversarial concepts}. This approach ensures stable
erasure with minimal impact on the other concepts. We demonstrate the
effectiveness of our method using the Stable Diffusion model, showing that it
outperforms state-of-the-art erasure methods in eliminating unwanted content
while maintaining the integrity of other unrelated elements. Our code is
available at https://github.com/tuananhbui89/Erasing-Adversarial-Preservation.",2024-10-21,"Anh Bui, Long Vuong, Khanh Doan, Trung Le, Paul Montague, Tamas Abraham, Dinh Phung",http://arxiv.org/pdf/2410.15618v4,cs.LG
Long-time Integration of Nonlinear Wave Equations with Neural Operators,"Neural operators have shown promise in solving many types of Partial
Differential Equations (PDEs). They are significantly faster compared to
traditional numerical solvers once they have been trained with a certain amount
of observed data. However, their numerical performance in solving
time-dependent PDEs, particularly in long-time prediction of dynamic systems,
still needs improvement. In this paper, we focus on solving the long-time
integration of nonlinear wave equations via neural operators by replacing the
initial condition with the prediction in a recurrent manner. Given limited
observed temporal trajectory data, we utilize some intrinsic features of these
nonlinear wave equations, such as conservation laws and well-posedness, to
improve the algorithm design and reduce accumulated error. Our numerical
experiments examine these improvements in the Korteweg-de Vries (KdV) equation,
the sine-Gordon equation, and the Klein-Gordon wave equation on the irregular
domain.",2024-10-21,"Guanhang Lei, Zhen Lei, Lei Shi",http://arxiv.org/pdf/2410.15617v3,cs.LG
In-Trajectory Inverse Reinforcement Learning: Learn Incrementally Before An Ongoing Trajectory Terminates,"Inverse reinforcement learning (IRL) aims to learn a reward function and a
corresponding policy that best fit the demonstrated trajectories of an expert.
However, current IRL works cannot learn incrementally from an ongoing
trajectory because they have to wait to collect at least one complete
trajectory to learn. To bridge the gap, this paper considers the problem of
learning a reward function and a corresponding policy while observing the
initial state-action pair of an ongoing trajectory and keeping updating the
learned reward and policy when new state-action pairs of the ongoing trajectory
are observed. We formulate this problem as an online bi-level optimization
problem where the upper level dynamically adjusts the learned reward according
to the newly observed state-action pairs with the help of a meta-regularization
term, and the lower level learns the corresponding policy. We propose a novel
algorithm to solve this problem and guarantee that the algorithm achieves
sub-linear local regret $O(\sqrt{T}+\log T+\sqrt{T}\log T)$. If the reward
function is linear, we prove that the proposed algorithm achieves sub-linear
regret $O(\log T)$. Experiments are used to validate the proposed algorithm.",2024-10-21,"Shicheng Liu, Minghui Zhu",http://arxiv.org/pdf/2410.15612v6,cs.LG
On The Global Convergence Of Online RLHF With Neural Parametrization,"The importance of Reinforcement Learning from Human Feedback (RLHF) in
aligning large language models (LLMs) with human values cannot be overstated.
RLHF is a three-stage process that includes supervised fine-tuning (SFT),
reward learning, and policy learning. Although there are several offline and
online approaches to aligning LLMs, they often suffer from distribution shift
issues. These issues arise from the inability to accurately capture the
distributional interdependence between the reward learning and policy learning
stages. Consequently, this has led to various approximated approaches, but the
theoretical insights and motivations remain largely limited to tabular
settings, which do not hold in practice. This gap between theoretical insights
and practical implementations is critical. It is challenging to address this
gap as it requires analyzing the performance of AI alignment algorithms in
neural network-parameterized settings. Although bi-level formulations have
shown promise in addressing distribution shift issues, they suffer from the
hyper-gradient problem, and current approaches lack efficient algorithms to
solve this. In this work, we tackle these challenges employing the bi-level
formulation laid out in Kwon et al. (2024) along with the assumption \emph{Weak
Gradient Domination} to demonstrate convergence in an RLHF setup, obtaining a
sample complexity of $\epsilon^{-\frac{7}{2}}$ . Our key contributions are
twofold: (i) We propose a bi-level formulation for AI alignment in
parameterized settings and introduce a first-order approach to solve this
problem. (ii) We analyze the theoretical convergence rates of the proposed
algorithm and derive state-of-the-art bounds. To the best of our knowledge,
this is the first work to establish convergence rate bounds and global
optimality for the RLHF framework in neural network-parameterized settings.",2024-10-21,"Mudit Gaur, Amrit Singh Bedi, Raghu Pasupathy, Vaneet Aggarwal",http://arxiv.org/pdf/2410.15610v2,cs.LG
Moonshine: Speech Recognition for Live Transcription and Voice Commands,"This paper introduces Moonshine, a family of speech recognition models
optimized for live transcription and voice command processing. Moonshine is
based on an encoder-decoder transformer architecture and employs Rotary
Position Embedding (RoPE) instead of traditional absolute position embeddings.
The model is trained on speech segments of various lengths, but without using
zero-padding, leading to greater efficiency for the encoder during inference
time. When benchmarked against OpenAI's Whisper tiny-en, Moonshine Tiny
demonstrates a 5x reduction in compute requirements for transcribing a
10-second speech segment while incurring no increase in word error rates across
standard evaluation datasets. These results highlight Moonshine's potential for
real-time and resource-constrained applications.",2024-10-21,"Nat Jeffries, Evan King, Manjunath Kudlur, Guy Nicholson, James Wang, Pete Warden",http://arxiv.org/pdf/2410.15608v2,cs.LG
All You Need is an Improving Column: Enhancing Column Generation for Parallel Machine Scheduling via Transformers,"We present a neural network-enhanced column generation (CG) approach for a
parallel machine scheduling problem. The proposed approach utilizes an
encoder-decoder attention model, namely the transformer and pointer
architectures, to develop job sequences with negative reduced cost and thus
generate columns to add to the master problem. By training the neural network
offline and using it in inference mode to predict negative reduced costs
columns, we achieve significant computational time savings compared to dynamic
programming (DP). Since the exact DP procedure is used to verify that no
further columns with negative reduced cost can be identified at termination,
the optimality guarantee of the original CG procedure is preserved. For small
to medium-sized instances, our approach achieves an average 45% reduction in
computation time compared to solving the subproblems with DP. Furthermore, the
model generalizes not only to unseen, larger problem instances from the same
probability distribution but also to instances from different probability
distributions than those presented at training time. For large-sized instances,
the proposed approach achieves an 80% improvement in the objective value in
under 500 seconds, demonstrating both its scalability and efficiency.",2024-10-21,"Amira Hijazi, Osman Ozaltin, Reha Uzsoy",http://arxiv.org/pdf/2410.15601v1,cs.LG
A Comprehensive Comparative Study of Individual ML Models and Ensemble Strategies for Network Intrusion Detection Systems,"The escalating frequency of intrusions in networked systems has spurred the
exploration of new research avenues in devising artificial intelligence (AI)
techniques for intrusion detection systems (IDS). Various AI techniques have
been used to automate network intrusion detection tasks, yet each model
possesses distinct strengths and weaknesses. Selecting the optimal model for a
given dataset can pose a challenge, necessitating the exploration of ensemble
methods to enhance generalization and applicability in network intrusion
detection. This paper addresses this gap by conducting a comprehensive
evaluation of diverse individual models and both simple and advanced ensemble
methods for network IDS. We introduce an ensemble learning framework tailored
for assessing individual models and ensemble methods in network intrusion
detection tasks. Our framework encompasses the loading of input datasets,
training of individual models and ensemble methods, and the generation of
evaluation metrics. Furthermore, we incorporate all features across individual
models and ensemble techniques. The study presents results for our framework,
encompassing 14 methods, including various bagging, stacking, blending, and
boosting techniques applied to multiple base learners such as decision trees,
neural networks, and among others. We evaluate the framework using two distinct
network intrusion datasets, RoEduNet-SIMARGL2021 and CICIDS-2017, each
possessing unique characteristics. Additionally, we categorize AI models based
on their performances on our evaluation metrics and via their confusion
matrices. Our assessment demonstrates the efficacy of learning across most
setups explored in this study. Furthermore, we contribute to the community by
releasing our source codes, providing a foundational ensemble learning
framework for network intrusion detection.",2024-10-21,"Ismail Bibers, Osvaldo Arreche, Mustafa Abdallah",http://arxiv.org/pdf/2410.15597v1,cs.LG
"Whither Bias Goes, I Will Go: An Integrative, Systematic Review of Algorithmic Bias Mitigation","Machine learning (ML) models are increasingly used for personnel assessment
and selection (e.g., resume screeners, automatically scored interviews).
However, concerns have been raised throughout society that ML assessments may
be biased and perpetuate or exacerbate inequality. Although organizational
researchers have begun investigating ML assessments from traditional
psychometric and legal perspectives, there is a need to understand, clarify,
and integrate fairness operationalizations and algorithmic bias mitigation
methods from the computer science, data science, and organizational research
literatures. We present a four-stage model of developing ML assessments and
applying bias mitigation methods, including 1) generating the training data, 2)
training the model, 3) testing the model, and 4) deploying the model. When
introducing the four-stage model, we describe potential sources of bias and
unfairness at each stage. Then, we systematically review definitions and
operationalizations of algorithmic bias, legal requirements governing personnel
selection from the United States and Europe, and research on algorithmic bias
mitigation across multiple domains and integrate these findings into our
framework. Our review provides insights for both research and practice by
elucidating possible mechanisms of algorithmic bias while identifying which
bias mitigation methods are legal and effective. This integrative framework
also reveals gaps in the knowledge of algorithmic bias mitigation that should
be addressed by future collaborative research between organizational
researchers, computer scientists, and data scientists. We provide
recommendations for developing and deploying ML assessments, as well as
recommendations for future research into algorithmic bias and fairness.",2024-10-21,"Louis Hickman, Christopher Huynh, Jessica Gass, Brandon Booth, Jason Kuruzovich, Louis Tay",http://arxiv.org/pdf/2410.19003v2,cs.LG
"A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications","With the rapid advancement of large language models (LLMs), aligning policy
models with human preferences has become increasingly critical. Direct
Preference Optimization (DPO) has emerged as a promising approach for
alignment, acting as an RL-free alternative to Reinforcement Learning from
Human Feedback (RLHF). Despite DPO's various advancements and inherent
limitations, an in-depth review of these aspects is currently lacking in the
literature. In this work, we present a comprehensive review of the challenges
and opportunities in DPO, covering theoretical analyses, variants, relevant
preference datasets, and applications. Specifically, we categorize recent
studies on DPO based on key research questions to provide a thorough
understanding of DPO's current landscape. Additionally, we propose several
future research directions to offer insights on model alignment for the
research community.",2024-10-21,"Wenyi Xiao, Zechuan Wang, Leilei Gan, Shuai Zhao, Wanggui He, Luu Anh Tuan, Long Chen, Hao Jiang, Zhou Zhao, Fei Wu",http://arxiv.org/pdf/2410.15595v2,cs.LG
CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein Representation and Origin Evaluation,"Protein structures are important for understanding their functions and
interactions. Currently, many protein structure prediction methods are
enriching the structure database. Discriminating the origin of structures is
crucial for distinguishing between experimentally resolved and computationally
predicted structures, evaluating the reliability of prediction methods, and
guiding downstream biological studies. Building on works in structure
prediction, We developed a structure-sensitive supervised deep learning model,
Crystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent
and discriminate the origin of protein structures. CPE-Pro learns the
structural information of proteins and captures inter-structural differences to
achieve accurate traceability on four data classes, and is expected to be
extended to more. Simultaneously, we utilized Foldseek to encode protein
structures into ""structure-sequences"" and trained a protein Structural Sequence
Language Model, SSLM. Preliminary experiments demonstrated that, compared to
large-scale protein language models pre-trained on vast amounts of amino acid
sequences, the ""structure-sequence"" enables the language model to learn more
informative protein features, enhancing and optimizing structural
representations. We have provided the code, model weights, and all related
materials on https://github.com/GouWenrui/CPE-Pro-main.git.",2024-10-21,"Wenrui Gou, Wenhui Ge, Yang Tan, Mingchen Li, Guisheng Fan, Huiqun Yu",http://arxiv.org/pdf/2410.15592v2,cs.LG
SSMT: Few-Shot Traffic Forecasting with Single Source Meta-Transfer,"Traffic forecasting in Intelligent Transportation Systems (ITS) is vital for
intelligent traffic prediction. Yet, ITS often relies on data from traffic
sensors or vehicle devices, where certain cities might not have all those smart
devices or enabling infrastructures. Also, recent studies have employed
meta-learning to generalize spatial-temporal traffic networks, utilizing data
from multiple cities for effective traffic forecasting for data-scarce target
cities. However, collecting data from multiple cities can be costly and
time-consuming. To tackle this challenge, we introduce Single Source
Meta-Transfer Learning (SSMT) which relies only on a single source city for
traffic prediction. Our method harnesses this transferred knowledge to enable
few-shot traffic forecasting, particularly when the target city possesses
limited data. Specifically, we use memory-augmented attention to store the
heterogeneous spatial knowledge from the source city and selectively recall
them for the data-scarce target city. We extend the idea of sinusoidal
positional encoding to establish meta-learning tasks by leveraging diverse
temporal traffic patterns from the source city. Moreover, to capture a more
generalized representation of the positions we introduced a meta-positional
encoding that learns the most optimal representation of the temporal pattern
across all the tasks. We experiment on five real-world benchmark datasets to
demonstrate that our method outperforms several existing methods in time series
traffic prediction.",2024-10-21,"Kishor Kumar Bhaumik, Minha Kim, Fahim Faisal Niloy, Amin Ahsan Ali, Simon S. Woo",http://arxiv.org/pdf/2410.15589v1,cs.LG
Multimodal Learning for Embryo Viability Prediction in Clinical IVF,"In clinical In-Vitro Fertilization (IVF), identifying the most viable embryo
for transfer is important to increasing the likelihood of a successful
pregnancy. Traditionally, this process involves embryologists manually
assessing embryos' static morphological features at specific intervals using
light microscopy. This manual evaluation is not only time-intensive and costly,
due to the need for expert analysis, but also inherently subjective, leading to
variability in the selection process. To address these challenges, we develop a
multimodal model that leverages both time-lapse video data and Electronic
Health Records (EHRs) to predict embryo viability. One of the primary
challenges of our research is to effectively combine time-lapse video and EHR
data, owing to their inherent differences in modality. We comprehensively
analyze our multimodal model with various modality inputs and integration
approaches. Our approach will enable fast and automated embryo viability
predictions in scale for clinical IVF.",2024-10-21,"Junsik Kim, Zhiyi Shi, Davin Jeong, Johannes Knittel, Helen Y. Yang, Yonghyun Song, Wanhua Li, Yicong Li, Dalit Ben-Yosef, Daniel Needleman, Hanspeter Pfister",http://arxiv.org/pdf/2410.15581v1,cs.LG
Language Models are Symbolic Learners in Arithmetic,"Large Language Models (LLMs) are thought to struggle with arithmetic learning
due to the inherent differences between language modeling and numerical
computation, but concrete evidence has been lacking. This work responds to this
claim through a two-side experiment. We first investigate whether LLMs leverage
partial products during arithmetic learning. We find that although LLMs can
identify some partial products after learning, they fail to leverage them for
arithmetic tasks, conversely. We then explore how LLMs approach arithmetic
symbolically by breaking tasks into subgroups, hypothesizing that difficulties
arise from subgroup complexity and selection. Our results show that when
subgroup complexity is fixed, LLMs treat a collection of different arithmetic
operations similarly. By analyzing position-level accuracy across different
training sizes, we further observe that it follows a U-shaped pattern: LLMs
quickly learn the easiest patterns at the first and last positions, while
progressively learning the more difficult patterns in the middle positions.
This suggests that LLMs select subgroup following an easy-to-hard paradigm
during learning. Our work confirms that LLMs are pure symbolic learners in
arithmetic tasks and underscores the importance of understanding them deeply
through subgroup-level quantification.",2024-10-21,"Chunyuan Deng, Zhiqi Li, Roy Xie, Ruidi Chang, Hanjie Chen",http://arxiv.org/pdf/2410.15580v1,cs.LG
Generalized Probabilistic Attention Mechanism in Transformers,"The Transformer architecture has become widely adopted due to its
demonstrated success, attributed to the attention mechanism at its core.
Despite these successes, the attention mechanism of Transformers is associated
with two well-known issues: rank-collapse and gradient vanishing. In this
paper, we present a theoretical analysis that it is inherently difficult to
address both issues simultaneously in the conventional attention mechanism. To
handle these issues, we introduce a novel class of attention mechanism,
referred to as generalized probabilistic attention mechanism (GPAM), and its
dual-attention implementation within the Transformer architecture. Unlike
conventional attention mechanisms, GPAM allows for negative attention scores
while preserving a fixed total sum. We provide theoretical evidence that the
proposed dual-attention GPAM (daGPAM) effectively mitigates both the
rank-collapse and gradient vanishing issues which are difficult to resolve
simultaneously with the conventional attention mechanisms. Furthermore, we
empirically validate this theoretical evidence, demonstrating the superiority
of daGPAM compared to other alternative attention mechanisms that were proposed
to address the same issues. Additionally, we demonstrate the practical benefits
of GPAM in natural language processing tasks, such as language modeling and
neural machine translation.",2024-10-21,"DongNyeong Heo, Heeyoul Choi",http://arxiv.org/pdf/2410.15578v1,cs.LG
Stacking Small Language Models for Generalizability,"Recent advances show that large language models (LLMs) generalize strong
performance across different natural language benchmarks. However, the large
size of LLMs makes training and inference expensive and impractical to run in
resource-limited settings. This paper introduces a new approach called
fine-tuning stacks of language models (FSLM), which involves stacking small
language models (SLM) as an alternative to LLMs. By fine-tuning each SLM to
perform a specific task, this approach breaks down high level reasoning into
multiple lower-level steps that specific SLMs are responsible for. As a result,
FSLM allows for lower training and inference costs, and also improves model
interpretability as each SLM communicates with the subsequent one through
natural language. By evaluating FSLM on common natural language benchmarks,
this paper highlights promising early results toward generalizable performance
using FSLM as a cost-effective alternative to LLMs.",2024-10-21,Laurence Liang,http://arxiv.org/pdf/2410.15570v1,cs.LG
Pruning Foundation Models for High Accuracy without Retraining,"Despite the superior performance, it is challenging to deploy foundation
models or large language models (LLMs) due to their massive parameters and
computations. While pruning is a promising technique to reduce model size and
accelerate the inference, the traditional pruning techniques can hardly be
applied for LLMs as they need to finetune the model on the full dataset with
multiple epochs consuming massive data and hardware resources. To deal with
this problem, post-training pruning methods are proposed to prune LLMs in
one-shot without retraining. However, their accuracy after pruning may suffer
from certain performance degradation due to the lack of retraining with massive
data. To address this issue, in this paper, we first formulate the
post-training problem for layer-wise LLM compression to simultaneously prune
multiple weights in LLMs. Next, we provide an optimal solution for this problem
and design our post-training pruning algorithm for both unstructured and
semi-structured sparsity. Our extensive experiments demonstrate the superior
performance of the proposed methods in comparison to SOTA baselines across
various LLM families including transformer-based LLMs and Mamba-based LLMs.
Code link: https://github.com/piuzha/APT",2024-10-21,"Pu Zhao, Fei Sun, Xuan Shen, Pinrui Yu, Zhenglun Kong, Yanzhi Wang, Xue Lin",http://arxiv.org/pdf/2410.15567v1,cs.LG
Reward Maximization for Pure Exploration: Minimax Optimal Good Arm Identification for Nonparametric Multi-Armed Bandits,"In multi-armed bandits, the tasks of reward maximization and pure exploration
are often at odds with each other. The former focuses on exploiting arms with
the highest means, while the latter may require constant exploration across all
arms. In this work, we focus on good arm identification (GAI), a practical
bandit inference objective that aims to label arms with means above a threshold
as quickly as possible. We show that GAI can be efficiently solved by combining
a reward-maximizing sampling algorithm with a novel nonparametric anytime-valid
sequential test for labeling arm means. We first establish that our sequential
test maintains error control under highly nonparametric assumptions and
asymptotically achieves the minimax optimal e-power, a notion of power for
anytime-valid tests. Next, by pairing regret-minimizing sampling schemes with
our sequential test, we provide an approach that achieves minimax optimal
stopping times for labeling arms with means above a threshold, under an error
probability constraint. Our empirical results validate our approach beyond the
minimax setting, reducing the expected number of samples for all stopping times
by at least 50% across both synthetic and real-world settings.",2024-10-21,"Brian Cho, Dominik Meier, Kyra Gan, Nathan Kallus",http://arxiv.org/pdf/2410.15564v1,cs.LG
How to Find the Exact Pareto Front for Multi-Objective MDPs?,"Multi-Objective Markov Decision Processes (MO-MDPs) are receiving increasing
attention, as real-world decision-making problems often involve conflicting
objectives that cannot be addressed by a single-objective MDP. The Pareto front
identifies the set of policies that cannot be dominated, providing a foundation
for finding Pareto optimal solutions that can efficiently adapt to various
preferences. However, finding the Pareto front is a highly challenging problem.
Most existing methods either (i) rely on traversing the continuous preference
space, which is impractical and results in approximations that are difficult to
evaluate against the true Pareto front, or (ii) focus solely on deterministic
Pareto optimal policies, from which there are no known techniques to
characterize the full Pareto front. Moreover, finding the structure of the
Pareto front itself remains unclear even in the context of dynamic programming,
where the MDP is fully known in advance. In this work, we address the challenge
of efficiently discovering the Pareto front. By investigating the geometric
structure of the Pareto front in MO-MDPs, we uncover a key property: the Pareto
front is on the boundary of a convex polytope whose vertices all correspond to
deterministic policies, and neighboring vertices of the Pareto front differ by
only one state-action pair of the deterministic policy, almost surely. This
insight transforms the global comparison across all policies into a localized
search among deterministic policies that differ by only one state-action pair,
drastically reducing the complexity of searching for the exact Pareto front. We
develop an efficient algorithm that identifies the vertices of the Pareto front
by solving a single-objective MDP only once and then traversing the edges of
the Pareto front, making it more efficient than existing methods.",2024-10-21,"Yining Li, Peizhong Ju, Ness B. Shroff",http://arxiv.org/pdf/2410.15557v2,cs.LG
Gradient Rewiring for Editable Graph Neural Network Training,"Deep neural networks are ubiquitously adopted in many applications, such as
computer vision, natural language processing, and graph analytics. However,
well-trained neural networks can make prediction errors after deployment as the
world changes. \textit{Model editing} involves updating the base model to
correct prediction errors with less accessible training data and computational
resources. Despite recent advances in model editors in computer vision and
natural language processing, editable training in graph neural networks (GNNs)
is rarely explored. The challenge with editable GNN training lies in the
inherent information aggregation across neighbors, which can lead model editors
to affect the predictions of other nodes unintentionally. In this paper, we
first observe the gradient of cross-entropy loss for the target node and
training nodes with significant inconsistency, which indicates that directly
fine-tuning the base model using the loss on the target node deteriorates the
performance on training nodes. Motivated by the gradient inconsistency
observation, we propose a simple yet effective \underline{G}radient
\underline{R}ewiring method for \underline{E}ditable graph neural network
training, named \textbf{GRE}. Specifically, we first store the anchor gradient
of the loss on training nodes to preserve the locality. Subsequently, we rewire
the gradient of the loss on the target node to preserve performance on the
training node using anchor gradient. Experiments demonstrate the effectiveness
of GRE on various model architectures and graph datasets in terms of multiple
editing situations. The source code is available at
\url{https://github.com/zhimengj0326/Gradient_rewiring_editing}",2024-10-21,"Zhimeng Jiang, Zirui Liu, Xiaotian Han, Qizhang Feng, Hongye Jin, Qiaoyu Tan, Kaixiong Zhou, Na Zou, Xia Hu",http://arxiv.org/pdf/2410.15556v2,cs.LG
Bayesian Concept Bottleneck Models with LLM Priors,"Concept Bottleneck Models (CBMs) have been proposed as a compromise between
white-box and black-box models, aiming to achieve interpretability without
sacrificing accuracy. The standard training procedure for CBMs is to predefine
a candidate set of human-interpretable concepts, extract their values from the
training data, and identify a sparse subset as inputs to a transparent
prediction model. However, such approaches are often hampered by the tradeoff
between enumerating a sufficiently large set of concepts to include those that
are truly relevant versus controlling the cost of obtaining concept
extractions. This work investigates a novel approach that sidesteps these
challenges: BC-LLM iteratively searches over a potentially infinite set of
concepts within a Bayesian framework, in which Large Language Models (LLMs)
serve as both a concept extraction mechanism and prior. BC-LLM is broadly
applicable and multi-modal. Despite imperfections in LLMs, we prove that BC-LLM
can provide rigorous statistical inference and uncertainty quantification. In
experiments, it outperforms comparator methods including black-box models,
converges more rapidly towards relevant concepts and away from spuriously
correlated ones, and is more robust to out-of-distribution samples.",2024-10-21,"Jean Feng, Avni Kothari, Luke Zier, Chandan Singh, Yan Shuo Tan",http://arxiv.org/pdf/2410.15555v1,cs.LG
A Plug-and-Play Fully On-the-Job Real-Time Reinforcement Learning Algorithm for a Direct-Drive Tandem-Wing Experiment Platforms Under Multiple Random Operating Conditions,"The nonlinear and unstable aerodynamic interference generated by the tandem
wings of such biomimetic systems poses substantial challenges for motion
control, especially under multiple random operating conditions. To address
these challenges, the Concerto Reinforcement Learning Extension (CRL2E)
algorithm has been developed. This plug-and-play, fully on-the-job, real-time
reinforcement learning algorithm incorporates a novel Physics-Inspired
Rule-Based Policy Composer Strategy with a Perturbation Module alongside a
lightweight network optimized for real-time control. To validate the
performance and the rationality of the module design, experiments were
conducted under six challenging operating conditions, comparing seven different
algorithms. The results demonstrate that the CRL2E algorithm achieves safe and
stable training within the first 500 steps, improving tracking accuracy by 14
to 66 times compared to the Soft Actor-Critic, Proximal Policy Optimization,
and Twin Delayed Deep Deterministic Policy Gradient algorithms. Additionally,
CRL2E significantly enhances performance under various random operating
conditions, with improvements in tracking accuracy ranging from 8.3% to 60.4%
compared to the Concerto Reinforcement Learning (CRL) algorithm. The
convergence speed of CRL2E is 36.11% to 57.64% faster than the CRL algorithm
with only the Composer Perturbation and 43.52% to 65.85% faster than the CRL
algorithm when both the Composer Perturbation and Time-Interleaved Capability
Perturbation are introduced, especially in conditions where the standard CRL
struggles to converge. Hardware tests indicate that the optimized lightweight
network structure excels in weight loading and average inference time, meeting
real-time control requirements.",2024-10-21,"Zhang Minghao, Song Bifeng, Yang Xiaojun, Wang Liang",http://arxiv.org/pdf/2410.15554v2,cs.LG
Hiding in Plain Sight: Reframing Hardware Trojan Benchmarking as a Hide&Seek Modification,"This work focuses on advancing security research in the hardware design space
by formally defining the realistic problem of Hardware Trojan (HT) detection.
The goal is to model HT detection more closely to the real world, i.e.,
describing the problem as The Seeker's Dilemma where a detecting agent is
unaware of whether circuits are infected by HTs or not. Using this theoretical
problem formulation, we create a benchmark that consists of a mixture of
HT-free and HT-infected restructured circuits while preserving their original
functionalities. The restructured circuits are randomly infected by HTs,
causing a situation where the defender is uncertain if a circuit is infected or
not. We believe that our innovative benchmark and methodology of creating
benchmarks will help the community judge the detection quality of different
methods by comparing their success rates in circuit classification. We use our
developed benchmark to evaluate three state-of-the-art HT detection tools to
show baseline results for this approach. We use Principal Component Analysis to
assess the strength of our benchmark, where we observe that some restructured
HT-infected circuits are mapped closely to HT-free circuits, leading to
significant label misclassification by detectors.",2024-10-21,"Amin Sarihi, Ahmad Patooghy, Peter Jamieson, Abdel-Hameed A. Badawy",http://arxiv.org/pdf/2410.15550v1,cs.LG
Distributed Thompson sampling under constrained communication,"In Bayesian optimization, a black-box function is maximized via the use of a
surrogate model. We apply distributed Thompson sampling, using a Gaussian
process as a surrogate model, to approach the multi-agent Bayesian optimization
problem. In our distributed Thompson sampling implementation, each agent
receives sampled points from neighbors, where the communication network is
encoded in a graph; each agent utilizes their own Gaussian process to model the
objective function. We demonstrate theoretical bounds on Bayesian average
regret and Bayesian simple regret, where the bound depends on the structure of
the communication graph. Unlike in batch Bayesian optimization, this bound is
applicable in cases where the communication graph amongst agents is
constrained. When compared to sequential single-agent Thompson sampling, our
bound guarantees faster convergence with respect to time as long as the
communication graph is connected. We confirm the efficacy of our algorithm with
numerical simulations on traditional optimization test functions, demonstrating
the significance of graph connectivity on improving regret convergence.",2024-10-21,"Saba Zerefa, Zhaolin Ren, Haitong Ma, Na Li",http://arxiv.org/pdf/2410.15543v3,cs.LG
Grammatical Error Correction for Low-Resource Languages: The Case of Zarma,"Grammatical error correction (GEC) aims to improve quality and readability of
texts through accurate correction of linguistic mistakes. Previous work has
focused on high-resource languages, while low-resource languages lack robust
tools. However, low-resource languages often face problems such as:
non-standard orthography, limited annotated corpora, and diverse dialects,
which slows down the development of GEC tools. We present a study on GEC for
Zarma, spoken by over five million in West Africa. We compare three approaches:
rule-based methods, machine translation (MT) models, and large language models
(LLMs). We evaluated them using a dataset of more than 250,000 examples,
including synthetic and human-annotated data. Our results showed that the
MT-based approach using M2M100 outperforms others, with a detection rate of 95.
82% and a suggestion accuracy of 78. 90% in automatic evaluations (AE) and an
average score of 3.0 out of 5.0 in manual evaluation (ME) from native speakers
for grammar and logical corrections. The rule-based method was effective for
spelling errors but failed on complex context-level errors. LLMs -- MT5-small
-- showed moderate performance. Our work supports use of MT models to enhance
GEC in low-resource settings, and we validated these results with Bambara,
another West African language.",2024-10-20,"Mamadou K. Keita, Christopher Homan, Marcos Zampieri, Adwoa Bremang, Habibatou Abdoulaye Alfari, Elysabhete Amadou Ibrahim, Dennis Owusu",http://arxiv.org/pdf/2410.15539v2,cs.LG
SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training,"Recent years have witnessed a clear trend towards language models with an
ever-increasing number of parameters, as well as the growing training overhead
and memory usage. Distributed training, particularly through Sharded Data
Parallelism (ShardedDP) which partitions optimizer states among workers, has
emerged as a crucial technique to mitigate training time and memory usage. Yet,
a major challenge in the scalability of ShardedDP is the intensive
communication of weights and gradients. While compression techniques can
alleviate this issue, they often result in worse accuracy. Driven by this
limitation, we propose SDP4Bit (Toward 4Bit Communication Quantization in
Sharded Data Parallelism for LLM Training), which effectively reduces the
communication of weights and gradients to nearly 4 bits via two novel
techniques: quantization on weight differences, and two-level gradient smooth
quantization. Furthermore, SDP4Bit presents an algorithm-system co-design with
runtime optimization to minimize the computation overhead of compression. In
addition to the theoretical guarantees of convergence, we empirically evaluate
the accuracy of SDP4Bit on the pre-training of GPT models with up to 6.7
billion parameters, and the results demonstrate a negligible impact on training
loss. Furthermore, speed experiments show that SDP4Bit achieves up to
4.08$\times$ speedup in end-to-end throughput on a scale of 128 GPUs.",2024-10-20,"Jinda Jia, Cong Xie, Hanlin Lu, Daoce Wang, Hao Feng, Chengming Zhang, Baixi Sun, Haibin Lin, Zhi Zhang, Xin Liu, Dingwen Tao",http://arxiv.org/pdf/2410.15526v2,cs.LG
"Advancing Gasoline Consumption Forecasting: A Novel Hybrid Model Integrating Transformers, LSTM, and CNN","Iran, endowed with abundant hydrocarbon resources, plays a crucial role in
the global energy landscape. Gasoline, as a critical fuel, significantly
supports the nation's transportation sector. Accurate forecasting of gasoline
consumption is essential for strategic resource management and environmental
planning. This research introduces a novel approach to predicting monthly
gasoline consumption using a hybrid Transformer-LSTM-CNN model, which
integrates the strengths of Transformer networks, Long Short-Term Memory (LSTM)
networks, and Convolutional Neural Networks (CNN). This advanced architecture
offers a superior alternative to conventional methods such as artificial neural
networks and regression models by capturing both short- and long-term
dependencies in time series data. By leveraging the self-attention mechanism of
Transformers, the temporal memory of LSTMs, and the local pattern detection of
CNNs, our hybrid model delivers improved prediction accuracy. Implemented using
Python, the model provides precise future gasoline consumption forecasts and
evaluates the environmental impact through the analysis of greenhouse gas
emissions. This study examines gasoline consumption trends from 2007 to 2021,
which rose from 64.5 million liters per day in 2007 to 99.80 million liters per
day in 2021. Our proposed model forecasts consumption levels up to 2031,
offering a valuable tool for policymakers and energy analysts. The results
highlight the superiority of this hybrid model in improving the accuracy of
gasoline consumption forecasts, reinforcing the need for advanced machine
learning techniques to optimize resource management and mitigate environmental
risks in the energy sector.",2024-10-20,"Mahmoud Ranjbar, Mohammad Rahimzadeh",http://arxiv.org/pdf/2410.16336v2,cs.LG
Fairness Evaluation with Item Response Theory,"Item Response Theory (IRT) has been widely used in educational psychometrics
to assess student ability, as well as the difficulty and discrimination of test
questions. In this context, discrimination specifically refers to how
effectively a question distinguishes between students of different ability
levels, and it does not carry any connotation related to fairness. In recent
years, IRT has been successfully used to evaluate the predictive performance of
Machine Learning (ML) models, but this paper marks its first application in
fairness evaluation. In this paper, we propose a novel Fair-IRT framework to
evaluate a set of predictive models on a set of individuals, while
simultaneously eliciting specific parameters, namely, the ability to make fair
predictions (a feature of predictive models), as well as the discrimination and
difficulty of individuals that affect the prediction results. Furthermore, we
conduct a series of experiments to comprehensively understand the implications
of these parameters for fairness evaluation. Detailed explanations for item
characteristic curves (ICCs) are provided for particular individuals. We
propose the flatness of ICCs to disentangle the unfairness between individuals
and predictive models. The experiments demonstrate the effectiveness of this
framework as a fairness evaluation tool. Two real-world case studies illustrate
its potential application in evaluating fairness in both classification and
regression tasks. Our paper aligns well with the Responsible Web track by
proposing a Fair-IRT framework to evaluate fairness in ML models, which
directly contributes to the development of a more inclusive, equitable, and
trustworthy AI.",2024-10-20,"Ziqi Xu, Sevvandi Kandanaarachchi, Cheng Soon Ong, Eirini Ntoutsi",http://arxiv.org/pdf/2411.02414v1,cs.LG
MIRA: A Method of Federated MultI-Task Learning for LaRge LAnguage Models,"In this paper, we introduce a method for fine-tuning Large Language Models
(LLMs), inspired by Multi-Task learning in a federated manner. Our approach
leverages the structure of each client's model and enables a learning scheme
that considers other clients' tasks and data distribution. To mitigate the
extensive computational and communication overhead often associated with LLMs,
we utilize a parameter-efficient fine-tuning method, specifically Low-Rank
Adaptation (LoRA), reducing the number of trainable parameters. Experimental
results, with different datasets and models, demonstrate the proposed method's
effectiveness compared to existing frameworks for federated fine-tuning of LLMs
in terms of average and local performances. The proposed scheme outperforms
existing baselines by achieving lower local loss for each client while
maintaining comparable global performance.",2024-10-20,"Ahmed Elbakary, Chaouki Ben Issaid, Tamer ElBatt, Karim Seddik, Mehdi Bennis",http://arxiv.org/pdf/2410.15524v1,cs.LG
M-RewardBench: Evaluating Reward Models in Multilingual Settings,"Reward models (RMs) have driven the state-of-the-art performance of LLMs
today by enabling the integration of human feedback into the language modeling
process. However, RMs are primarily trained and evaluated in English, and their
capabilities in multilingual settings remain largely understudied. In this
work, we conduct a systematic evaluation of several reward models in
multilingual settings. We first construct the first-of-its-kind multilingual RM
evaluation benchmark, M-RewardBench, consisting of 2.87k preference instances
for 23 typologically diverse languages, that tests the chat, safety, reasoning,
and translation capabilities of RMs. We then rigorously evaluate a wide range
of reward models on M-RewardBench, offering fresh insights into their
performance across diverse languages. We identify a significant gap in RMs'
performances between English and non-English languages and show that RM
preferences can change substantially from one language to another. We also
present several findings on how different multilingual aspects impact RM
performance. Specifically, we show that the performance of RMs is improved with
improved translation quality. Similarly, we demonstrate that the models exhibit
better performance for high-resource languages. We release M-RewardBench
dataset and the codebase in this study to facilitate a better understanding of
RM evaluation in multilingual settings.",2024-10-20,"Srishti Gureja, Lester James V. Miranda, Shayekh Bin Islam, Rishabh Maheshwary, Drishti Sharma, Gusti Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, Marzieh Fadaee",http://arxiv.org/pdf/2410.15522v3,cs.LG
Generating Tabular Data Using Heterogeneous Sequential Feature Forest Flow Matching,"Privacy and regulatory constraints make data generation vital to advancing
machine learning without relying on real-world datasets. A leading approach for
tabular data generation is the Forest Flow (FF) method, which combines Flow
Matching with XGBoost. Despite its good performance, FF is slow and makes
errors when treating categorical variables as one-hot continuous features. It
is also highly sensitive to small changes in the initial conditions of the
ordinary differential equation (ODE). To overcome these limitations, we develop
Heterogeneous Sequential Feature Forest Flow (HS3F). Our method generates data
sequentially (feature-by-feature), reducing the dependency on noisy initial
conditions through the additional information from previously generated
features. Furthermore, it generates categorical variables using multinomial
sampling (from an XGBoost classifier) instead of flow matching, improving
generation speed. We also use a Runge-Kutta 4th order (Rg4) ODE solver for
improved performance over the Euler solver used in FF. Our experiments with 25
datasets reveal that HS3F produces higher quality and more diverse synthetic
data than FF, especially for categorical variables. It also generates data
21-27 times faster for datasets with $\geq20%$ categorical variables. HS3F
further demonstrates enhanced robustness to affine transformation in flow ODE
initial conditions compared to FF. This study not only validates the HS3F but
also unveils promising new strategies to advance generative models.",2024-10-20,"Ange-Clément Akazan, Alexia Jolicoeur-Martineau, Ioannis Mitliagkas",http://arxiv.org/pdf/2410.15516v1,cs.LG
Exploring Curriculum Learning for Vision-Language Tasks: A Study on Small-Scale Multimodal Training,"For specialized domains, there is often not a wealth of data with which to
train large machine learning models. In such limited data / compute settings,
various methods exist aiming to $\textit{do more with less}$, such as
finetuning from a pretrained model, modulating difficulty levels as data are
presented to a model (curriculum learning), and considering the role of model
type / size. Approaches to efficient $\textit{machine}$ learning also take
inspiration from $\textit{human}$ learning by considering use cases where
machine learning systems have access to approximately the same number of words
experienced by a 13 year old child (100M words). We investigate the role of 3
primary variables in a limited data regime as part of the multimodal track of
the BabyLM challenge. We contrast: (i) curriculum learning, (ii), pretraining
(with text-only data), (iii) model type. We modulate these variables and assess
them on two types of tasks: (a) multimodal (text+image), and (b) unimodal
(text-only) tasks. We find that curriculum learning benefits multimodal
evaluations over non-curriclum learning models, particularly when combining
text-only pretraining. On text-only tasks, curriculum learning appears to help
models with smaller trainable parameter counts. We suggest possible reasons
based on architectural differences and training designs as to why one might
observe such results.",2024-10-20,"Rohan Saha, Abrar Fahim, Alona Fyshe, Alex Murphy",http://arxiv.org/pdf/2410.15509v1,cs.LG
Predicting adaptively chosen observables in quantum systems,"Recent advances have demonstrated that $\mathcal{O}(\log M)$ measurements
suffice to predict $M$ properties of arbitrarily large quantum many-body
systems. However, these remarkable findings assume that the properties to be
predicted are chosen independently of the data. This assumption can be violated
in practice, where scientists adaptively select properties after looking at
previous predictions. This work investigates the adaptive setting for three
classes of observables: local, Pauli, and bounded-Frobenius-norm observables.
We prove that $\Omega(\sqrt{M})$ samples of an arbitrarily large unknown
quantum state are necessary to predict expectation values of $M$ adaptively
chosen local and Pauli observables. We also present computationally-efficient
algorithms that achieve this information-theoretic lower bound. In contrast,
for bounded-Frobenius-norm observables, we devise an algorithm requiring only
$\mathcal{O}(\log M)$ samples, independent of system size. Our results
highlight the potential pitfalls of adaptivity in analyzing data from quantum
experiments and provide new algorithmic tools to safeguard against erroneous
predictions in quantum experiments.",2024-10-20,"Jerry Huang, Laura Lewis, Hsin-Yuan Huang, John Preskill",http://arxiv.org/pdf/2410.15501v1,cs.LG
SEA: State-Exchange Attention for High-Fidelity Physics Based Transformers,"Current approaches using sequential networks have shown promise in estimating
field variables for dynamical systems, but they are often limited by high
rollout errors. The unresolved issue of rollout error accumulation results in
unreliable estimations as the network predicts further into the future, with
each step's error compounding and leading to an increase in inaccuracy. Here,
we introduce the State-Exchange Attention (SEA) module, a novel
transformer-based module enabling information exchange between encoded fields
through multi-head cross-attention. The cross-field multidirectional
information exchange design enables all state variables in the system to
exchange information with one another, capturing physical relationships and
symmetries between fields. Additionally, we introduce an efficient ViT-like
mesh autoencoder to generate spatially coherent mesh embeddings for a large
number of meshing cells. The SEA integrated transformer demonstrates the
state-of-the-art rollout error compared to other competitive baselines.
Specifically, we outperform PbGMR-GMUS Transformer-RealNVP and GMR-GMUS
Transformer, with a reduction in error of 88% and 91%, respectively.
Furthermore, we demonstrate that the SEA module alone can reduce errors by 97%
for state variables that are highly dependent on other states of the system.
The repository for this work is available at:
https://github.com/ParsaEsmati/SEA",2024-10-20,"Parsa Esmati, Amirhossein Dadashzadeh, Vahid Goodarzi, Nicolas Larrosa, Nicolò Grilli",http://arxiv.org/pdf/2410.15495v2,cs.LG
Reinforcement Learning for Dynamic Memory Allocation,"In recent years, reinforcement learning (RL) has gained popularity and has
been applied to a wide range of tasks. One such popular domain where RL has
been effective is resource management problems in systems. We look to extend
work on RL for resource management problems by considering the novel domain of
dynamic memory allocation management. We consider dynamic memory allocation to
be a suitable domain for RL since current algorithms like first-fit, best-fit,
and worst-fit can fail to adapt to changing conditions and can lead to
fragmentation and suboptimal efficiency. In this paper, we present a framework
in which an RL agent continuously learns from interactions with the system to
improve memory management tactics. We evaluate our approach through various
experiments using high-level and low-level action spaces and examine different
memory allocation patterns. Our results show that RL can successfully train
agents that can match and surpass traditional allocation strategies,
particularly in environments characterized by adversarial request patterns. We
also explore the potential of history-aware policies that leverage previous
allocation requests to enhance the allocator's ability to handle complex
request patterns. Overall, we find that RL offers a promising avenue for
developing more adaptive and efficient memory allocation strategies,
potentially overcoming limitations of hardcoded allocation algorithms.",2024-10-20,"Arisrei Lim, Abhiram Maddukuri",http://arxiv.org/pdf/2410.15492v1,cs.LG
Structural Causality-based Generalizable Concept Discovery Models,"The rising need for explainable deep neural network architectures has
utilized semantic concepts as explainable units. Several approaches utilizing
disentangled representation learning estimate the generative factors and
utilize them as concepts for explaining DNNs. However, even though the
generative factors for a dataset remain fixed, concepts are not fixed entities
and vary based on downstream tasks. In this paper, we propose a disentanglement
mechanism utilizing a variational autoencoder (VAE) for learning mutually
independent generative factors for a given dataset and subsequently learning
task-specific concepts using a structural causal model (SCM). Our method
assumes generative factors and concepts to form a bipartite graph, with
directed causal edges from generative factors to concepts. Experiments are
conducted on datasets with known generative factors: D-sprites and Shapes3D. On
specific downstream tasks, our proposed method successfully learns
task-specific concepts which are explained well by the causal edges from the
generative factors. Lastly, separate from current causal concept discovery
methods, our methodology is generalizable to an arbitrary number of concepts
and flexible to any downstream tasks.",2024-10-20,"Sanchit Sinha, Guangzhi Xiong, Aidong Zhang",http://arxiv.org/pdf/2410.15491v1,cs.LG
Generative AI Agents in Autonomous Machines: A Safety Perspective,"The integration of Generative Artificial Intelligence (AI) into autonomous
machines represents a major paradigm shift in how these systems operate and
unlocks new solutions to problems once deemed intractable. Although generative
AI agents provide unparalleled capabilities, they also have unique safety
concerns. These challenges require robust safeguards, especially for autonomous
machines that operate in high-stakes environments. This work investigates the
evolving safety requirements when generative models are integrated as agents
into physical autonomous machines, comparing these to safety considerations in
less critical AI applications. We explore the challenges and opportunities to
ensure the safe deployment of generative AI-driven autonomous machines.
Furthermore, we provide a forward-looking perspective on the future of
AI-driven autonomous systems and emphasize the importance of evaluating and
communicating safety risks. As an important step towards addressing these
concerns, we recommend the development and implementation of comprehensive
safety scorecards for the use of generative AI technologies in autonomous
machines.",2024-10-20,"Jason Jabbour, Vijay Janapa Reddi",http://arxiv.org/pdf/2410.15489v1,cs.LG
Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning,"Post-training of pre-trained LLMs, which typically consists of the supervised
fine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is
crucial to effective and safe LLM applications. The widely adopted approach in
post-training popular open-source LLMs is to sequentially perform SFT and
RLHF/DPO. However, sequential training is sub-optimal in terms of SFT and
RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training
when undergoing the second stage's training. We theoretically prove the
sub-optimality of sequential post-training. Furthermore, we propose a practical
joint post-training framework with theoretical convergence guarantees and
empirically outperforms sequential post-training framework, while having
similar computational cost. Our code is available at
https://github.com/heshandevaka/XRIGHT.",2024-10-20,"Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen",http://arxiv.org/pdf/2410.15483v3,cs.LG
Optimizing Backward Policies in GFlowNets via Trajectory Likelihood Maximization,"Generative Flow Networks (GFlowNets) are a family of generative models that
learn to sample objects with probabilities proportional to a given reward
function. The key concept behind GFlowNets is the use of two stochastic
policies: a forward policy, which incrementally constructs compositional
objects, and a backward policy, which sequentially deconstructs them. Recent
results show a close relationship between GFlowNet training and
entropy-regularized reinforcement learning (RL) problems with a particular
reward design. However, this connection applies only in the setting of a fixed
backward policy, which might be a significant limitation. As a remedy to this
problem, we introduce a simple backward policy optimization algorithm that
involves direct maximization of the value function in an entropy-regularized
Markov Decision Process (MDP) over intermediate rewards. We provide an
extensive experimental evaluation of the proposed approach across various
benchmarks in combination with both RL and GFlowNet algorithms and demonstrate
its faster convergence and mode discovery in complex environments.",2024-10-20,"Timofei Gritsaev, Nikita Morozov, Sergey Samsonov, Daniil Tiapkin",http://arxiv.org/pdf/2410.15474v2,cs.LG
A Bayesian Framework for Clustered Federated Learning,"One of the main challenges of federated learning (FL) is handling
non-independent and identically distributed (non-IID) client data, which may
occur in practice due to unbalanced datasets and use of different data sources
across clients. Knowledge sharing and model personalization are key strategies
for addressing this issue. Clustered federated learning is a class of FL
methods that groups clients that observe similarly distributed data into
clusters, such that every client is typically associated with one data
distribution and participates in training a model for that distribution along
their cluster peers. In this paper, we present a unified Bayesian framework for
clustered FL which associates clients to clusters. Then we propose several
practical algorithms to handle the, otherwise growing, data associations in a
way that trades off performance and computational complexity. This work
provides insights on client-cluster associations and enables client knowledge
sharing in new ways. The proposed framework circumvents the need for unique
client-cluster associations, which is seen to increase the performance of the
resulting models in a variety of experiments.",2024-10-20,"Peng Wu, Tales Imbiriba, Pau Closas",http://arxiv.org/pdf/2410.15473v2,cs.LG
Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for Kidney Tumor Segmentation,"Renal tumors, especially renal cell carcinoma (RCC), show significant
heterogeneity, posing challenges for diagnosis using radiology images such as
MRI, echocardiograms, and CT scans. U-Net based deep learning techniques are
emerging as a promising approach for automated medical image segmentation for
minimally invasive diagnosis of renal tumors. However, current techniques need
further improvements in accuracy to become clinically useful to radiologists.
In this study, we present an improved U-Net based model for end-to-end
automated semantic segmentation of CT scan images to identify renal tumors. The
model uses residual connections across convolution layers, integrates a
multi-layer feature fusion (MFF) and cross-channel attention (CCA) within
encoder blocks, and incorporates skip connections augmented with additional
information derived using MFF and CCA. We evaluated our model on the KiTS19
dataset, which contains data from 210 patients. For kidney segmentation, our
model achieves a Dice Similarity Coefficient (DSC) of 0.97 and a Jaccard index
(JI) of 0.95. For renal tumor segmentation, our model achieves a DSC of 0.96
and a JI of 0.91. Based on a comparison of available DSC scores, our model
outperforms the current leading models.",2024-10-20,"Fnu Neha, Arvind K. Bansal",http://arxiv.org/pdf/2410.15472v2,cs.LG
"Generative Models, Humans, Predictive Models: Who Is Worse at High-Stakes Decision Making?","Despite strong advisory against it, large generative models (LMs) are already
being used for decision making tasks that were previously done by predictive
models or humans. We put popular LMs to the test in a high-stakes decision
making task: recidivism prediction. Studying three closed-access and
open-source LMs, we analyze the LMs not exclusively in terms of accuracy, but
also in terms of agreement with (imperfect, noisy, and sometimes biased) human
predictions or existing predictive models. We conduct experiments that assess
how providing different types of information, including distractor information
such as photos, can influence LM decisions. We also stress test techniques
designed to either increase accuracy or mitigate bias in LMs, and find that
some to have unintended consequences on LM decisions. Our results provide
additional quantitative evidence to the wisdom that current LMs are not the
right tools for these types of tasks.",2024-10-20,"Keri Mallari, Julius Adebayo, Kori Inkpen, Martin T. Wells, Albert Gordo, Sarah Tan",http://arxiv.org/pdf/2410.15471v2,cs.LG
Data Augmentation via Diffusion Model to Enhance AI Fairness,"AI fairness seeks to improve the transparency and explainability of AI
systems by ensuring that their outcomes genuinely reflect the best interests of
users. Data augmentation, which involves generating synthetic data from
existing datasets, has gained significant attention as a solution to data
scarcity. In particular, diffusion models have become a powerful technique for
generating synthetic data, especially in fields like computer vision. This
paper explores the potential of diffusion models to generate synthetic tabular
data to improve AI fairness. The Tabular Denoising Diffusion Probabilistic
Model (Tab-DDPM), a diffusion model adaptable to any tabular dataset and
capable of handling various feature types, was utilized with different amounts
of generated data for data augmentation. Additionally, reweighting samples from
AIF360 was employed to further enhance AI fairness. Five traditional machine
learning models-Decision Tree (DT), Gaussian Naive Bayes (GNB), K-Nearest
Neighbors (KNN), Logistic Regression (LR), and Random Forest (RF)-were used to
validate the proposed approach. Experimental results demonstrate that the
synthetic data generated by Tab-DDPM improves fairness in binary
classification.",2024-10-20,"Christina Hastings Blow, Lijun Qian, Camille Gibson, Pamela Obiomon, Xishuang Dong",http://arxiv.org/pdf/2410.15470v1,cs.LG
log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling,"Accurate prediction of chemical reaction yields is crucial for optimizing
organic synthesis, potentially reducing time and resources spent on
experimentation. With the rise of artificial intelligence (AI), there is
growing interest in leveraging AI-based methods to accelerate yield predictions
without conducting in vitro experiments. We present log-RRIM, an innovative
graph transformer-based framework designed for predicting chemical reaction
yields. A key feature of log-RRIM is its integration of a cross-attention
mechanism that focuses on the interplay between reagents and reaction centers.
This design reflects a fundamental principle in chemical reactions: the crucial
role of reagents in influencing bond-breaking and formation processes, which
ultimately affect reaction yields. log-RRIM also implements a local-to-global
reaction representation learning strategy. This approach initially captures
detailed molecule-level information and then models and aggregates
intermolecular interactions. Through this hierarchical process, log-RRIM
effectively captures how different molecular fragments contribute to and
influence the overall reaction yield, regardless of their size variations.
log-RRIM shows superior performance in our experiments, especially for medium
to high-yielding reactions, proving its reliability as a predictor. The
framework's sophisticated modeling of reactant-reagent interactions and precise
capture of molecular fragment contributions make it a valuable tool for
reaction planning and optimization in chemical synthesis. The data and codes of
log-RRIM are accessible through https://github.com/ninglab/Yield_log_RRIM.",2024-10-20,"Xiao Hu, Ziqi Chen, Bo Peng, Daniel Adu-Ampratwum, Xia Ning",http://arxiv.org/pdf/2411.03320v4,cs.LG
Non-invasive Neural Decoding in Source Reconstructed Brain Space,"Non-invasive brainwave decoding is usually done using
Magneto/Electroencephalography (MEG/EEG) sensor measurements as inputs. This
makes combining datasets and building models with inductive biases difficult as
most datasets use different scanners and the sensor arrays have a nonintuitive
spatial structure. In contrast, fMRI scans are acquired directly in brain
space, a voxel grid with a typical structured input representation. By using
established techniques to reconstruct the sensors' sources' neural activity it
is possible to decode from voxels for MEG data as well. We show that this
enables spatial inductive biases, spatial data augmentations, better
interpretability, zero-shot generalisation between datasets, and data
harmonisation.",2024-10-20,"Yonatan Gideoni, Ryan Charles Timms, Oiwi Parker Jones",http://arxiv.org/pdf/2410.19838v1,cs.LG
An Improved Chicken Swarm Optimization Algorithm for Handwritten Document Image Enhancement,"Chicken swarm optimization is a new meta-heuristic algorithm which mimics the
foraging hierarchical behavior of chicken. In this paper, we describe the
preprocessing of handwritten document by contrast enhancement while preserving
detail with an improved chicken swarm optimization algorithm.The results of the
algorithm are compared with other existing meta heuristic algorithms like
Cuckoo Search, Firefly Algorithm and the Artificial bee colony. The proposed
algorithm considerably outperforms all the above by giving good results.",2024-10-20,"Stanley Mugisha, Lynn tar Gutu, P Nagabhushan",http://arxiv.org/pdf/2411.00802v1,cs.LG
Discriminating image representations with principal distortions,"Image representations (artificial or biological) are often compared in terms
of their global geometric structure; however, representations with similar
global structure can have strikingly different local geometries. Here, we
propose a framework for comparing a set of image representations in terms of
their local geometries. We quantify the local geometry of a representation
using the Fisher information matrix, a standard statistical tool for
characterizing the sensitivity to local stimulus distortions, and use this as a
substrate for a metric on the local geometry in the vicinity of a base image.
This metric may then be used to optimally differentiate a set of models, by
finding a pair of ""principal distortions"" that maximize the variance of the
models under this metric. As an example, we use this framework to compare a set
of simple models of the early visual system, identifying a novel set of image
distortions that allow immediate comparison of the models by visual inspection.
In a second example, we apply our method to a set of deep neural network models
and reveal differences in the local geometry that arise due to architecture and
training types. These examples demonstrate how our framework can be used to
probe for informative differences in local sensitivities between complex
models, and suggest how it could be used to compare model representations with
human perception.",2024-10-20,"Jenelle Feather, David Lipshutz, Sarah E. Harvey, Alex H. Williams, Eero P. Simoncelli",http://arxiv.org/pdf/2410.15433v2,cs.LG
Efficient Model Extraction via Boundary Sampling,"This paper introduces a novel data-free model extraction attack that
significantly advances the current state-of-the-art in terms of efficiency,
accuracy, and effectiveness. Traditional black-box methods rely on using the
victim's model as an oracle to label a vast number of samples within
high-confidence areas. This approach not only requires an extensive number of
queries but also results in a less accurate and less transferable model. In
contrast, our method innovates by focusing on sampling low-confidence areas
(along the decision boundaries) and employing an evolutionary algorithm to
optimize the sampling process. These novel contributions allow for a dramatic
reduction in the number of queries needed by the attacker by a factor of 10x to
600x while simultaneously improving the accuracy of the stolen model. Moreover,
our approach improves boundary alignment, resulting in better transferability
of adversarial examples from the stolen model to the victim's model (increasing
the attack success rate from 60\% to 82\% on average). Finally, we accomplish
all of this with a strict black-box assumption on the victim, with no knowledge
of the target's architecture or dataset.
  We demonstrate our attack on three datasets with increasingly larger
resolutions and compare our performance to four state-of-the-art model
extraction attacks.",2024-10-20,"Maor Biton Dor, Yisroel Mirsky",http://arxiv.org/pdf/2410.15429v1,cs.LG
Accelerated Sub-Image Search For Variable-Size Patches Identification Based On Virtual Time Series Transformation And Segmentation,"This paper addresses two tasks: (i) fixed-size objects such as hay bales are
to be identified in an aerial image for a given reference image of the object,
and (ii) variable-size patches such as areas on fields requiring spot spraying
or other handling are to be identified in an image for a given small-scale
reference image. Both tasks are related. The second differs in that identified
sub-images similar to the reference image are further clustered before patches
contours are determined by solving a traveling salesman problem. Both tasks are
complex in that the exact number of similar sub-images is not known a priori.
The main discussion of this paper is presentation of an acceleration mechanism
for sub-image search that is based on a transformation of an image to
multivariate time series along the RGB-channels and subsequent segmentation to
reduce the 2D search space in the image. Two variations of the acceleration
mechanism are compared to exhaustive search on diverse synthetic and real-world
images. Quantitatively, proposed method results in solve time reductions of up
to 2 orders of magnitude, while qualitatively delivering comparative visual
results. Proposed method is neural network-free and does not use any image
pre-processing.",2024-10-20,Mogens Plessen,http://arxiv.org/pdf/2410.15425v1,cs.LG
Power Plays: Unleashing Machine Learning Magic in Smart Grids,"The integration of machine learning into smart grid systems represents a
transformative step in enhancing the efficiency, reliability, and
sustainability of modern energy networks. By adding advanced data analytics,
these systems can better manage the complexities of renewable energy
integration, demand response, and predictive maintenance. Machine learning
algorithms analyze vast amounts of data from smart meters, sensors, and other
grid components to optimize energy distribution, forecast demand, and detect
irregularities that could indicate potential failures. This enables more
precise load balancing, reduces operational costs, and enhances the resilience
of the grid against disturbances. Furthermore, the use of predictive models
helps in anticipating equipment failures, thereby improving the reliability of
the energy supply. As smart grids continue to evolve, the role of machine
learning in managing decentralized energy sources and enabling real-time
decision-making will become increasingly critical. However, the deployment of
these technologies also raises challenges related to data privacy, security,
and the need for robust infrastructure. Addressing these issues in this
research authors will focus on realizing the full potential of smart grids,
ensuring they meet the growing energy demands while maintaining a focus on
sustainability and efficiency using Machine Learning techniques. Furthermore,
this research will help determine the smart grid's essentiality with the aid of
Machine Learning. Multiple ML algorithms have been integrated along with their
pros and cons. The future scope of these algorithms are also integrated.",2024-10-20,"Abdur Rashid, Parag Biswas, abdullah al masum, MD Abdullah Al Nasim, Kishor Datta Gupta",http://arxiv.org/pdf/2410.15423v1,cs.LG
Where to Build Food Banks and Pantries: A Two-Level Machine Learning Approach,"Over 44 million Americans currently suffer from food insecurity, of whom 13
million are children. Across the United States, thousands of food banks and
pantries serve as vital sources of food and other forms of aid for food
insecure families. By optimizing food bank and pantry locations, food would
become more accessible to families who desperately require it. In this work, we
introduce a novel two-level optimization framework, which utilizes the
K-Medoids clustering algorithm in conjunction with the Open-Source Routing
Machine engine, to optimize food bank and pantry locations based on real road
distances to houses and house blocks. Our proposed framework also has the
adaptability to factor in considerations such as median household income using
a pseudo-weighted K-Medoids algorithm. Testing conducted with California and
Indiana household data, as well as comparisons with real food bank and pantry
locations showed that interestingly, our proposed framework yields food pantry
locations superior to those of real existing ones and saves significant
distance for households, while there is a marginal penalty on the first level
food bank to food pantry distance. Overall, we believe that the second-level
benefits of this framework far outweigh any drawbacks and yield a net benefit
result.",2024-10-20,"Gavin Ruan, Ziqi Guo, Guang Lin",http://arxiv.org/pdf/2410.15420v1,cs.LG
Dynamic Contrastive Learning for Time Series Representation,"Understanding events in time series is an important task in a variety of
contexts. However, human analysis and labeling are expensive and
time-consuming. Therefore, it is advantageous to learn embeddings for moments
in time series in an unsupervised way, which allows for good performance in
classification or detection tasks after later minimal human labeling. In this
paper, we propose dynamic contrastive learning (DynaCL), an unsupervised
contrastive representation learning framework for time series that uses
temporal adjacent steps to define positive pairs. DynaCL adopts N-pair loss to
dynamically treat all samples in a batch as positive or negative pairs,
enabling efficient training and addressing the challenges of complicated
sampling of positives. We demonstrate that DynaCL embeds instances from time
series into semantically meaningful clusters, which allows superior performance
on downstream tasks on a variety of public time series datasets. Our findings
also reveal that high scores on unsupervised clustering metrics do not
guarantee that the representations are useful in downstream tasks.",2024-10-20,"Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor",http://arxiv.org/pdf/2410.15416v1,cs.LG
A Heterogeneous Network-based Contrastive Learning Approach for Predicting Drug-Target Interaction,"Drug-target interaction (DTI) prediction is crucial for drug development and
repositioning. Methods using heterogeneous graph neural networks (HGNNs) for
DTI prediction have become a promising approach, with attention-based models
often achieving excellent performance. However, these methods typically
overlook edge features when dealing with heterogeneous biomedical networks. We
propose a heterogeneous network-based contrastive learning method called
HNCL-DTI, which designs a heterogeneous graph attention network to predict
potential/novel DTIs. Specifically, our HNCL-DTI utilizes contrastive learning
to collaboratively learn node representations from the perspective of both
node-based and edge-based attention within the heterogeneous structure of
biomedical networks. Experimental results show that HNCL-DTI outperforms
existing advanced baseline methods on benchmark datasets, demonstrating strong
predictive ability and practical effectiveness. The data and source code are
available at https://github.com/Zaiwen/HNCL-DTI.",2024-10-20,"Junwei Hu, Michael Bewong, Selasi Kwashie, Wen Zhang, Vincent M. Nofong, Guangsheng Wu, Zaiwen Feng",http://arxiv.org/pdf/2411.00801v1,cs.LG
PEAS: A Strategy for Crafting Transferable Adversarial Examples,"Black box attacks, where adversaries have limited knowledge of the target
model, pose a significant threat to machine learning systems. Adversarial
examples generated with a substitute model often suffer from limited
transferability to the target model. While recent work explores ranking
perturbations for improved success rates, these methods see only modest gains.
We propose a novel strategy called PEAS that can boost the transferability of
existing black box attacks. PEAS leverages the insight that samples which are
perceptually equivalent exhibit significant variability in their adversarial
transferability. Our approach first generates a set of images from an initial
sample via subtle augmentations. We then evaluate the transferability of
adversarial perturbations on these images using a set of substitute models.
Finally, the most transferable adversarial example is selected and used for the
attack. Our experiments show that PEAS can double the performance of existing
attacks, achieving a 2.5x improvement in attack success rates on average over
current ranking methods. We thoroughly evaluate PEAS on ImageNet and CIFAR-10,
analyze hyperparameter impacts, and provide an ablation study to isolate each
component's importance.",2024-10-20,"Bar Avraham, Yisroel Mirsky",http://arxiv.org/pdf/2410.15409v1,cs.LG
Slicing for AI: An Online Learning Framework for Network Slicing Supporting AI Services,"The forthcoming 6G networks will embrace a new realm of AI-driven services
that requires innovative network slicing strategies, namely slicing for AI,
which involves the creation of customized network slices to meet Quality of
service (QoS) requirements of diverse AI services. This poses challenges due to
time-varying dynamics of users' behavior and mobile networks. Thus, this paper
proposes an online learning framework to optimize the allocation of
computational and communication resources to AI services, while considering
their unique key performance indicators (KPIs), such as accuracy, latency, and
cost. We define a problem of optimizing the total accuracy while balancing
conflicting KPIs, prove its NP-hardness, and propose an online learning
framework for solving it in dynamic environments. We present a basic online
solution and two variations employing a pre-learning elimination method for
reducing the decision space to expedite the learning. Furthermore, we propose a
biased decision space subset selection by incorporating prior knowledge to
enhance the learning speed without compromising performance and present two
alternatives of handling the selected subset. Our results depict the efficiency
of the proposed solutions in converging to the optimal decisions, while
reducing decision space and improving time complexity.",2024-10-20,"Menna Helmy, Alaa Awad Abdellatif, Naram Mhaisen, Amr Mohamed, Aiman Erbad",http://arxiv.org/pdf/2411.02412v1,cs.LG
IPO: Interpretable Prompt Optimization for Vision-Language Models,"Pre-trained vision-language models like CLIP have remarkably adapted to
various downstream tasks. Nonetheless, their performance heavily depends on the
specificity of the input text prompts, which requires skillful prompt template
engineering. Instead, current approaches to prompt optimization learn the
prompts through gradient descent, where the prompts are treated as adjustable
parameters. However, these methods tend to lead to overfitting of the base
classes seen during training and produce prompts that are no longer
understandable by humans. This paper introduces a simple but interpretable
prompt optimizer (IPO), that utilizes large language models (LLMs) to generate
textual prompts dynamically. We introduce a Prompt Optimization Prompt that not
only guides LLMs in creating effective prompts but also stores past prompts
with their performance metrics, providing rich in-context information.
Additionally, we incorporate a large multimodal model (LMM) to condition on
visual content by generating image descriptions, which enhance the interaction
between textual and visual modalities. This allows for thae creation of
dataset-specific prompts that improve generalization performance, while
maintaining human comprehension. Extensive testing across 11 datasets reveals
that IPO not only improves the accuracy of existing gradient-descent-based
prompt learning methods but also considerably enhances the interpretability of
the generated prompts. By leveraging the strengths of LLMs, our approach
ensures that the prompts remain human-understandable, thereby facilitating
better transparency and oversight for vision-language models.",2024-10-20,"Yingjun Du, Wenfang Sun, Cees G. M. Snoek",http://arxiv.org/pdf/2410.15397v1,cs.LG
"Comparative Analysis of LSTM, GRU, and Transformer Models for Stock Price Prediction","In recent fast-paced financial markets, investors constantly seek ways to
gain an edge and make informed decisions. Although achieving perfect accuracy
in stock price predictions remains elusive, artificial intelligence (AI)
advancements have significantly enhanced our ability to analyze historical data
and identify potential trends. This paper takes AI driven stock price trend
prediction as the core research, makes a model training data set of famous
Tesla cars from 2015 to 2024, and compares LSTM, GRU, and Transformer Models.
The analysis is more consistent with the model of stock trend prediction, and
the experimental results show that the accuracy of the LSTM model is 94%. These
methods ultimately allow investors to make more informed decisions and gain a
clearer insight into market behaviors.",2024-10-20,"Jue Xiao, Tingting Deng, Shuochen Bi",http://arxiv.org/pdf/2411.05790v1,cs.LG
Synthetic Data Generation for Residential Load Patterns via Recurrent GAN and Ensemble Method,"Generating synthetic residential load data that can accurately represent
actual electricity consumption patterns is crucial for effective power system
planning and operation. The necessity for synthetic data is underscored by the
inherent challenges associated with using real-world load data, such as privacy
considerations and logistical complexities in large-scale data collection. In
this work, we tackle the above-mentioned challenges by developing the Ensemble
Recurrent Generative Adversarial Network (ERGAN) framework to generate
high-fidelity synthetic residential load data. ERGAN leverages an ensemble of
recurrent Generative Adversarial Networks, augmented by a loss function that
concurrently takes into account adversarial loss and differences between
statistical properties. Our developed ERGAN can capture diverse load patterns
across various households, thereby enhancing the realism and diversity of the
synthetic data generated. Comprehensive evaluations demonstrate that our method
consistently outperforms established benchmarks in the synthetic generation of
residential load data across various performance metrics including diversity,
similarity, and statistical measures. The findings confirm the potential of
ERGAN as an effective tool for energy applications requiring synthetic yet
realistic load data. We also make the generated synthetic residential load
patterns publicly available.",2024-10-20,"Xinyu Liang, Ziheng Wang, Hao Wang",http://arxiv.org/pdf/2410.15379v1,cs.LG
Explainability of Point Cloud Neural Networks Using SMILE: Statistical Model-Agnostic Interpretability with Local Explanations,"In today's world, the significance of explainable AI (XAI) is growing in
robotics and point cloud applications, as the lack of transparency in
decision-making can pose considerable safety risks, particularly in autonomous
systems. As these technologies are integrated into real-world environments,
ensuring that model decisions are interpretable and trustworthy is vital for
operational reliability and safety assurance. This study explores the
implementation of SMILE, a novel explainability method originally designed for
deep neural networks, on point cloud-based models. SMILE builds on LIME by
incorporating Empirical Cumulative Distribution Function (ECDF) statistical
distances, offering enhanced robustness and interpretability, particularly when
the Anderson-Darling distance is used. The approach demonstrates superior
performance in terms of fidelity loss, R2 scores, and robustness across various
kernel widths, perturbation numbers, and clustering configurations. Moreover,
this study introduces a stability analysis for point cloud data using the
Jaccard index, establishing a new benchmark and baseline for model stability in
this field. The study further identifies dataset biases in the classification
of the 'person' category, emphasizing the necessity for more comprehensive
datasets in safety-critical applications like autonomous driving and robotics.
The results underscore the potential of advanced explainability models and
highlight areas for future research, including the application of alternative
surrogate models and explainability techniques in point cloud data.",2024-10-20,"Seyed Mohammad Ahmadi, Koorosh Aslansefat, Ruben Valcarce-Dineiro, Joshua Barnfather",http://arxiv.org/pdf/2410.15374v1,cs.LG
Hybrid Memory Replay: Blending Real and Distilled Data for Class Incremental Learning,"Incremental learning (IL) aims to acquire new knowledge from current tasks
while retaining knowledge learned from previous tasks. Replay-based IL methods
store a set of exemplars from previous tasks in a buffer and replay them when
learning new tasks. However, there is usually a size-limited buffer that cannot
store adequate real exemplars to retain the knowledge of previous tasks. In
contrast, data distillation (DD) can reduce the exemplar buffer's size, by
condensing a large real dataset into a much smaller set of more
information-compact synthetic exemplars. Nevertheless, DD's performance gain on
IL quickly vanishes as the number of synthetic exemplars grows. To overcome the
weaknesses of real-data and synthetic-data buffers, we instead optimize a
hybrid memory including both types of data. Specifically, we propose an
innovative modification to DD that distills synthetic data from a sliding
window of checkpoints in history (rather than checkpoints on multiple training
trajectories). Conditioned on the synthetic data, we then optimize the
selection of real exemplars to provide complementary improvement to the DD
objective. The optimized hybrid memory combines the strengths of synthetic and
real exemplars, effectively mitigating catastrophic forgetting in Class IL
(CIL) when the buffer size for exemplars is limited. Notably, our method can be
seamlessly integrated into most existing replay-based CIL models. Extensive
experiments across multiple benchmarks demonstrate that our method
significantly outperforms existing replay-based baselines.",2024-10-20,"Jiangtao Kong, Jiacheng Shi, Ashley Gao, Shaohan Hu, Tianyi Zhou, Huajie Shao",http://arxiv.org/pdf/2410.15372v1,cs.LG
FrameBridge: Improving Image-to-Video Generation with Bridge Models,"Image-to-video (I2V) generation is gaining increasing attention with its wide
application in video synthesis. Recently, diffusion-based I2V models have
achieved remarkable progress given their novel design on network architecture,
cascaded framework, and motion representation. However, restricted by their
noise-to-data generation process, diffusion-based methods inevitably suffer the
difficulty to generate video samples with both appearance consistency and
temporal coherence from an uninformative Gaussian noise, which may limit their
synthesis quality. In this work, we present FrameBridge, taking the given
static image as the prior of video target and establishing a tractable bridge
model between them. By formulating I2V synthesis as a frames-to-frames
generation task and modelling it with a data-to-data process, we fully exploit
the information in input image and facilitate the generative model to learn the
image animation process. In two popular settings of training I2V models, namely
fine-tuning a pre-trained text-to-video (T2V) model or training from scratch,
we further propose two techniques, SNR-Aligned Fine-tuning (SAF) and neural
prior, which improve the fine-tuning efficiency of diffusion-based T2V models
to FrameBridge and the synthesis quality of bridge-based I2V models
respectively. Experiments conducted on WebVid-2M and UCF-101 demonstrate that:
(1) our FrameBridge achieves superior I2V quality in comparison with the
diffusion counterpart (zero-shot FVD 83 vs. 176 on MSR-VTT and non-zero-shot
FVD 122 vs. 171 on UCF-101); (2) our proposed SAF and neural prior effectively
enhance the ability of bridge-based I2V models in the scenarios of fine-tuning
and training from scratch. Demo samples can be visited at:
https://framebridge-demo.github.io/.",2024-10-20,"Yuji Wang, Zehua Chen, Xiaoyu Chen, Jun Zhu, Jianfei Chen",http://arxiv.org/pdf/2410.15371v1,cs.LG
Tighter Performance Theory of FedExProx,"We revisit FedExProx - a recently proposed distributed optimization method
designed to enhance convergence properties of parallel proximal algorithms via
extrapolation. In the process, we uncover a surprising flaw: its known
theoretical guarantees on quadratic optimization tasks are no better than those
offered by the vanilla Gradient Descent (GD) method. Motivated by this
observation, we develop a novel analysis framework, establishing a tighter
linear convergence rate for non-strongly convex quadratic problems. By
incorporating both computation and communication costs, we demonstrate that
FedExProx can indeed provably outperform GD, in stark contrast to the original
analysis. Furthermore, we consider partial participation scenarios and analyze
two adaptive extrapolation strategies - based on gradient diversity and Polyak
stepsizes - again significantly outperforming previous results. Moving beyond
quadratics, we extend the applicability of our analysis to general functions
satisfying the Polyak-Lojasiewicz condition, outperforming the previous
strongly convex analysis while operating under weaker assumptions. Backed by
empirical results, our findings point to a new and stronger potential of
FedExProx, paving the way for further exploration of the benefits of
extrapolation in federated learning.",2024-10-20,"Wojciech Anyszka, Kaja Gruntkowska, Alexander Tyurin, Peter Richtárik",http://arxiv.org/pdf/2410.15368v1,cs.LG
Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models,"Aligned Large Language Models (LLMs) have demonstrated remarkable performance
across various tasks. However, LLMs remain susceptible to jailbreak adversarial
attacks, where adversaries manipulate prompts to elicit malicious responses
that aligned LLMs should have avoided. Identifying these vulnerabilities is
crucial for understanding the inherent weaknesses of LLMs and preventing their
potential misuse. One pioneering work in jailbreaking is the GCG attack, a
discrete token optimization algorithm that seeks to find a suffix capable of
jailbreaking aligned LLMs. Despite the success of GCG, we find it suboptimal,
requiring significantly large computational costs, and the achieved
jailbreaking performance is limited. In this work, we propose Faster-GCG, an
efficient adversarial jailbreak method by delving deep into the design of GCG.
Experiments demonstrate that Faster-GCG can surpass the original GCG with only
1/10 of the computational cost, achieving significantly higher attack success
rates on various open-source aligned LLMs. In addition, We demonstrate that
Faster-GCG exhibits improved attack transferability when testing on
closed-sourced LLMs such as ChatGPT.",2024-10-20,"Xiao Li, Zhuhong Li, Qiongxiu Li, Bingze Lee, Jinghao Cui, Xiaolin Hu",http://arxiv.org/pdf/2410.15362v1,cs.LG
A Novel Characterization of the Population Area Under the Risk Coverage Curve (AURC) and Rates of Finite Sample Estimators,"The selective classifier (SC) has been proposed for rank based uncertainty
thresholding, which could have applications in safety critical areas such as
medical diagnostics, autonomous driving, and the justice system. The Area Under
the Risk-Coverage Curve (AURC) has emerged as the foremost evaluation metric
for assessing the performance of SC systems. In this work, we present a formal
statistical formulation of population AURC, presenting an equivalent expression
that can be interpreted as a reweighted risk function. Through Monte Carlo
methods, we derive empirical AURC plug-in estimators for finite sample
scenarios. The weight estimators associated with these plug-in estimators are
shown to be consistent, with low bias and tightly bounded mean squared error
(MSE). The plug-in estimators are proven to converge at a rate of
$\mathcal{O}(\sqrt{\ln(n)/n})$ demonstrating statistical consistency. We
empirically validate the effectiveness of our estimators through experiments
across multiple datasets, model architectures, and confidence score functions
(CSFs), demonstrating consistency and effectiveness in fine-tuning AURC
performance.",2024-10-20,"Han Zhou, Jordy Van Landeghem, Teodora Popordanoska, Matthew B. Blaschko",http://arxiv.org/pdf/2410.15361v2,cs.LG
Wireless Link Quality Estimation Using LSTM Model,"In recent years, various services have been provided through high-speed and
high-capacity wireless networks on mobile communication devices, necessitating
stable communication regardless of indoor or outdoor environments. To achieve
stable communication, it is essential to implement proactive measures, such as
switching to an alternative path and ensuring data buffering before the
communication quality becomes unstable. The technology of Wireless Link Quality
Estimation (WLQE), which predicts the communication quality of wireless
networks in advance, plays a crucial role in this context. In this paper, we
propose a novel WLQE model for estimating the communication quality of wireless
networks by leveraging sequential information. Our proposed method is based on
Long Short-Term Memory (LSTM), enabling highly accurate estimation by
considering the sequential information of link quality. We conducted a
comparative evaluation with the conventional model, stacked autoencoder-based
link quality estimator (LQE-SAE), using a dataset recorded in real-world
environmental conditions. Our LSTM-based LQE model demonstrates its
superiority, achieving a 4.0% higher accuracy and a 4.6% higher macro-F1 score
than the LQE-SAE model in the evaluation.",2024-10-20,"Yuki Kanto, Kohei Watabe",http://arxiv.org/pdf/2410.15357v2,cs.LG
LAC: Graph Contrastive Learning with Learnable Augmentation in Continuous Space,"Graph Contrastive Learning frameworks have demonstrated success in generating
high-quality node representations.
  The existing research on efficient data augmentation methods and ideal
pretext tasks for graph contrastive learning remains limited, resulting in
suboptimal node representation in the unsupervised setting.
  In this paper, we introduce LAC, a graph contrastive learning framework with
learnable data augmentation in an orthogonal continuous space. To capture the
representative information in the graph data during augmentation, we introduce
a continuous view augmenter, that applies both a masked topology augmentation
module and a cross-channel feature augmentation module to adaptively augment
the topological information and the feature information within an orthogonal
continuous space, respectively. The orthogonal nature of continuous space
ensures that the augmentation process avoids dimension collapse.
  To enhance the effectiveness of pretext tasks, we propose an
information-theoretic principle named InfoBal and introduce corresponding
pretext tasks. These tasks enable the continuous view augmenter to maintain
consistency in the representative information across views while maximizing
diversity between views, and allow the encoder to fully utilize the
representative information in the unsupervised setting. Our experimental
results show that LAC significantly outperforms the state-of-the-art
frameworks.",2024-10-20,"Zhenyu Lin, Hongzheng Li, Yingxia Shao, Guanhua Ye, Yawen Li, Quanqing Xu",http://arxiv.org/pdf/2410.15355v1,cs.LG
CompAct: Compressed Activations for Memory-Efficient LLM Training,"We introduce CompAct, a technique that reduces peak memory utilization on GPU
by 25-30% for pretraining and 50% for fine-tuning of LLMs. Peak device memory
is a major limiting factor in training LLMs, with various recent works aiming
to reduce model memory. However most works don't target the largest component
of allocated memory during training: the model's compute graph, which is stored
for the backward pass. By storing low-rank, compressed activations to be used
in the backward pass we greatly reduce the required memory, unlike previous
methods which only reduce optimizer overheads or the number of trained
parameters. Our compression uses random projection matrices, thus avoiding
additional memory overheads. Comparisons with previous techniques for either
pretraining or fine-tuning show that CompAct substantially improves existing
compute-performance tradeoffs. We expect CompAct's savings to scale even higher
for larger models.",2024-10-20,"Yara Shamshoum, Nitzan Hodos, Yuval Sieradzki, Assaf Schuster",http://arxiv.org/pdf/2410.15352v2,cs.LG
ConSinger: Efficient High-Fidelity Singing Voice Generation with Minimal Steps,"Singing voice synthesis (SVS) system is expected to generate high-fidelity
singing voice from given music scores (lyrics, duration and pitch). Recently,
diffusion models have performed well in this field. However, sacrificing
inference speed to exchange with high-quality sample generation limits its
application scenarios. In order to obtain high quality synthetic singing voice
more efficiently, we propose a singing voice synthesis method based on the
consistency model, ConSinger, to achieve high-fidelity singing voice synthesis
with minimal steps. The model is trained by applying consistency constraint and
the generation quality is greatly improved at the expense of a small amount of
inference speed. Our experiments show that ConSinger is highly competitive with
the baseline model in terms of generation speed and quality. Audio samples are
available at https://keylxiao.github.io/consinger.",2024-10-20,"Yulin Song, Guorui Sang, Jing Yu, Chuangbai Xiao",http://arxiv.org/pdf/2410.15342v3,cs.LG
Diffusion-PINN Sampler,"Recent success of diffusion models has inspired a surge of interest in
developing sampling techniques using reverse diffusion processes. However,
accurately estimating the drift term in the reverse stochastic differential
equation (SDE) solely from the unnormalized target density poses significant
challenges, hindering existing methods from achieving state-of-the-art
performance. In this paper, we introduce the Diffusion-PINN Sampler (DPS), a
novel diffusion-based sampling algorithm that estimates the drift term by
solving the governing partial differential equation of the log-density of the
underlying SDE marginals via physics-informed neural networks (PINN). We prove
that the error of log-density approximation can be controlled by the PINN
residual loss, enabling us to establish convergence guarantees of DPS.
Experiments on a variety of sampling tasks demonstrate the effectiveness of our
approach, particularly in accurately identifying mixing proportions when the
target contains isolated components.",2024-10-20,"Zhekun Shi, Longlin Yu, Tianyu Xie, Cheng Zhang",http://arxiv.org/pdf/2410.15336v1,cs.LG
EPIC: Efficient Position-Independent Context Caching for Serving Large Language Models,"Large Language Models (LLMs) are critical for a wide range of applications,
but serving them efficiently becomes increasingly challenging as inputs become
more complex. Context caching improves serving performance by exploiting
inter-request dependency and reusing key-value (KV) cache across requests, thus
improving time-to-first-token (TTFT). However, existing prefix-based context
caching requires exact token prefix matches, limiting cache reuse in few-shot
learning, multi-document QA, or retrieval-augmented generation, where prefixes
may vary. In this paper, we present EPIC, an LLM serving system that introduces
position-independent context caching (PIC), enabling modular KV cache reuse
regardless of token chunk position (or prefix). EPIC features two key designs:
AttnLink, which leverages static attention sparsity to minimize recomputation
for accuracy recovery, and KVSplit, a customizable chunking method that
preserves semantic coherence. Our experiments demonstrate that Epic delivers up
to 8x improvements in TTFT and 7x throughput over existing systems, with
negligible or no accuracy loss. By addressing the limitations of traditional
caching approaches, Epic enables more scalable and efficient LLM inference.",2024-10-20,"Junhao Hu, Wenrui Huang, Haoyi Wang, Weidong Wang, Tiancheng Hu, Qin Zhang, Hao Feng, Xusheng Chen, Yizhou Shan, Tao Xie",http://arxiv.org/pdf/2410.15332v2,cs.LG
Integrating Symbolic Neural Networks with Building Physics: A Study and Proposal,"Symbolic neural networks, such as Kolmogorov-Arnold Networks (KAN), offer a
promising approach for integrating prior knowledge with data-driven methods,
making them valuable for addressing inverse problems in scientific and
engineering domains. This study explores the application of KAN in building
physics, focusing on predictive modeling, knowledge discovery, and continuous
learning. Through four case studies, we demonstrate KAN's ability to rediscover
fundamental equations, approximate complex formulas, and capture time-dependent
dynamics in heat transfer. While there are challenges in extrapolation and
interpretability, we highlight KAN's potential to combine advanced modeling
methods for knowledge augmentation, which benefits energy efficiency, system
optimization, and sustainability assessments beyond the personal knowledge
constraints of the modelers. Additionally, we propose a model selection
decision tree to guide practitioners in appropriate applications for building
physics.",2024-10-20,"Xia Chen, Guoquan Lv, Xinwei Zhuang, Carlos Duarte, Stefano Schiavon, Philipp Geyer",http://arxiv.org/pdf/2411.00800v1,cs.LG
FoMo: A Foundation Model for Mobile Traffic Forecasting with Diffusion Model,"Mobile traffic forecasting allows operators to anticipate network dynamics
and performance in advance, offering substantial potential for enhancing
service quality and improving user experience. However, existing models are
often task-oriented and are trained with tailored data, which limits their
effectiveness in diverse mobile network tasks of Base Station (BS) deployment,
resource allocation, energy optimization, etc. and hinders generalization
across different urban environments. Foundation models have made remarkable
strides across various domains of NLP and CV due to their multi-tasking
adaption and zero/few-shot learning capabilities. In this paper, we propose an
innovative Foundation model for Mo}bile traffic forecasting (FoMo), aiming to
handle diverse forecasting tasks of short/long-term predictions and
distribution generation across multiple cities to support network planning and
optimization. FoMo combines diffusion models and transformers, where various
spatio-temporal masks are proposed to enable FoMo to learn intrinsic features
of different tasks, and a contrastive learning strategy is developed to capture
the correlations between mobile traffic and urban contexts, thereby improving
its transfer learning capability. Extensive experiments on 9 real-world
datasets demonstrate that FoMo outperforms current models concerning diverse
forecasting tasks and zero/few-shot learning, showcasing a strong universality.",2024-10-20,"Haoye Chai, Xiaoqian Qi, Shiyuan Zhang, Yong Li",http://arxiv.org/pdf/2410.15322v2,cs.LG
"Amortized Probabilistic Conditioning for Optimization, Simulation and Inference","Amortized meta-learning methods based on pre-training have propelled fields
like natural language processing and vision. Transformer-based neural processes
and their variants are leading models for probabilistic meta-learning with a
tractable objective. Often trained on synthetic data, these models implicitly
capture essential latent information in the data-generation process. However,
existing methods do not allow users to flexibly inject (condition on) and
extract (predict) this probabilistic latent information at runtime, which is
key to many tasks. We introduce the Amortized Conditioning Engine (ACE), a new
transformer-based meta-learning model that explicitly represents latent
variables of interest. ACE affords conditioning on both observed data and
interpretable latent variables, the inclusion of priors at runtime, and outputs
predictive distributions for discrete and continuous data and latents. We show
ACE's modeling flexibility and performance in diverse tasks such as image
completion and classification, Bayesian optimization, and simulation-based
inference.",2024-10-20,"Paul E. Chang, Nasrulloh Loka, Daolang Huang, Ulpu Remes, Samuel Kaski, Luigi Acerbi",http://arxiv.org/pdf/2410.15320v2,cs.LG
SNAP: Stopping Catastrophic Forgetting in Hebbian Learning with Sigmoidal Neuronal Adaptive Plasticity,"Artificial Neural Networks (ANNs) suffer from catastrophic forgetting, where
the learning of new tasks causes the catastrophic forgetting of old tasks.
Existing Machine Learning (ML) algorithms, including those using Stochastic
Gradient Descent (SGD) and Hebbian Learning typically update their weights
linearly with experience i.e., independently of their current strength. This
contrasts with biological neurons, which at intermediate strengths are very
plastic, but consolidate with Long-Term Potentiation (LTP) once they reach a
certain strength. We hypothesize this mechanism might help mitigate
catastrophic forgetting. We introduce Sigmoidal Neuronal Adaptive Plasticity
(SNAP) an artificial approximation to Long-Term Potentiation for ANNs by having
the weights follow a sigmoidal growth behaviour allowing the weights to
consolidate and stabilize when they reach sufficiently large or small values.
We then compare SNAP to linear weight growth and exponential weight growth and
see that SNAP completely prevents the forgetting of previous tasks for Hebbian
Learning but not for SGD-base learning.",2024-10-20,"Tianyi Xu, Patrick Zheng, Shiyan Liu, Sicheng Lyu, Isabeau Prémont-Schwarz",http://arxiv.org/pdf/2410.15318v1,cs.LG
On Cold Posteriors of Probabilistic Neural Networks: Understanding the Cold Posterior Effect and A New Way to Learn Cold Posteriors with Tight Generalization Guarantees,"Bayesian inference provides a principled probabilistic framework for
quantifying uncertainty by updating beliefs based on prior knowledge and
observed data through Bayes' theorem. In Bayesian deep learning, neural network
weights are treated as random variables with prior distributions, allowing for
a probabilistic interpretation and quantification of predictive uncertainty.
However, Bayesian methods lack theoretical generalization guarantees for unseen
data. PAC-Bayesian analysis addresses this limitation by offering a frequentist
framework to derive generalization bounds for randomized predictors, thereby
certifying the reliability of Bayesian methods in machine learning.
  Temperature $T$, or inverse-temperature $\lambda = \frac{1}{T}$, originally
from statistical mechanics in physics, naturally arises in various areas of
statistical inference, including Bayesian inference and PAC-Bayesian analysis.
In Bayesian inference, when $T < 1$ (``cold'' posteriors), the likelihood is
up-weighted, resulting in a sharper posterior distribution. Conversely, when $T
> 1$ (``warm'' posteriors), the likelihood is down-weighted, leading to a more
diffuse posterior distribution. By balancing the influence of observed data and
prior regularization, temperature adjustments can address issues of
underfitting or overfitting in Bayesian models, bringing improved predictive
performance.",2024-10-20,Yijie Zhang,http://arxiv.org/pdf/2410.15310v1,cs.LG
Symmetry Nonnegative Matrix Factorization Algorithm Based on Self-paced Learning,"A symmetric nonnegative matrix factorization algorithm based on self-paced
learning was proposed to improve the clustering performance of the model. It
could make the model better distinguish normal samples from abnormal samples in
an error-driven way. A weight variable that could measure the degree of
difficulty to all samples was assigned in this method, and the variable was
constrained by adopting both hard-weighting and soft-weighting strategies to
ensure the rationality of the model. Cluster analysis was carried out on
multiple data sets such as images and texts, and the experimental results
showed the effectiveness of the proposed algorithm.",2024-10-20,"Lei Wang, Liang Du, Peng Zhou, Peng Wu",http://arxiv.org/pdf/2410.15306v1,cs.LG
Multiple Kernel Clustering via Local Regression Integration,"Multiple kernel methods less consider the intrinsic manifold structure of
multiple kernel data and estimate the consensus kernel matrix with quadratic
number of variables, which makes it vulnerable to the noise and outliers within
multiple candidate kernels. This paper first presents the clustering method via
kernelized local regression (CKLR). It captures the local structure of kernel
data and employs kernel regression on the local region to predict the
clustering results. Moreover, this paper further extends it to perform
clustering via the multiple kernel local regression (CMKLR). We construct the
kernel level local regression sparse coefficient matrix for each candidate
kernel, which well characterizes the kernel level manifold structure. We then
aggregate all the kernel level local regression coefficients via linear weights
and generate the consensus sparse local regression coefficient, which largely
reduces the number of candidate variables and becomes more robust against
noises and outliers within multiple kernel data. Thus, the proposed method
CMKLR avoids the above two limitations. It only contains one additional
hyperparameter for tuning. Extensive experimental results show that the
clustering performance of the proposed method on benchmark datasets is better
than that of 10 state-of-the-art multiple kernel clustering methods.",2024-10-20,"Liang Du, Xin Ren, Haiying Zhang, Peng Zhou",http://arxiv.org/pdf/2410.15304v1,cs.LG
Likelihood-Free Inference and Hierarchical Data Assimilation for Geological Carbon Storage,"Data assimilation will be essential for the management and expansion of
geological carbon storage operations. In traditional data assimilation
approaches a fixed set of geological hyperparameters, such as mean and standard
deviation of log-permeability, is often assumed. Such hyperparameters, however,
may be highly uncertain in practical CO2 storage applications where
measurements are scarce. In this study, we develop a hierarchical data
assimilation framework for carbon storage that treats hyperparameters as
uncertain variables characterized by hyperprior distributions. To deal with the
computationally intractable likelihood function in hyperparameter estimation,
we apply a likelihood-free (or simulation-based) inference algorithm,
specifically sequential Monte Carlo-based approximate Bayesian computation
(SMC-ABC), to draw posterior samples of hyperparameters given dynamic
monitoring well data. In the second step we use an ensemble smoother with
multiple data assimilation (ESMDA) procedure to provide posterior realizations
of grid-block permeability. To reduce computational costs, a 3D recurrent
R-U-Net deep learning-based surrogate model is applied for forward function
evaluations. A rejection sampling (RS) procedure for data assimilation is
applied to provide reference posterior results. Detailed posterior results from
SMC-ABC-ESMDA are compared to those from the reference RS method. Close
agreement is achieved with 'converged' RS results, for two synthetic true
models, in all quantities considered. Importantly, the SMC-ABC-ESMDA procedure
provides speedup of 1-2 orders of magnitude relative to RS for the two cases. A
modified standalone ESMDA procedure is introduced for comparison purposes. For
the same number of function evaluations, the hierarchical approach is shown to
provide superior results for posterior hyperparameter distributions and
monitoring well pressure predictions.",2024-10-20,"Wenchao Teng, Louis J. Durlofsky",http://arxiv.org/pdf/2410.15302v2,cs.LG
Unsupervised feature selection algorithm framework based on neighborhood interval disturbance fusion,"Feature selection technology is a key technology of data dimensionality
reduction. Becauseof the lack of label information of collected data samples,
unsupervised feature selection has attracted more attention. The universality
and stability of many unsupervised feature selection algorithms are very low
and greatly affected by the dataset structure. For this reason, many
researchers have been keen to improve the stability of the algorithm. This
paper attempts to preprocess the data set and use an interval method to
approximate the data set, experimentally verifying the advantages and
disadvantages of the new interval data set. This paper deals with these data
sets from the global perspective and proposes a new algorithm-unsupervised
feature selection algorithm based on neighborhood interval disturbance
fusion(NIDF). This method can realize the joint learning of the final score of
the feature and the approximate data interval. By comparing with the original
unsupervised feature selection methods and several existing feature selection
frameworks, the superiority of the proposed model is verified.",2024-10-20,"Xiaolin Lv, Liang Du, Peng Zhou, Peng Wu",http://arxiv.org/pdf/2410.15294v1,cs.LG
Fractional-order spike-timing-dependent gradient descent for multi-layer spiking neural networks,"Accumulated detailed knowledge about the neuronal activities in human brains
has brought more attention to bio-inspired spiking neural networks (SNNs). In
contrast to non-spiking deep neural networks (DNNs), SNNs can encode and
transmit spatiotemporal information more efficiently by exploiting biologically
realistic and low-power event-driven neuromorphic architectures. However, the
supervised learning of SNNs still remains a challenge because the
spike-timing-dependent plasticity (STDP) of connected spiking neurons is
difficult to implement and interpret in existing backpropagation learning
schemes. This paper proposes a fractional-order spike-timing-dependent gradient
descent (FO-STDGD) learning model by considering a derived nonlinear activation
function that describes the relationship between the quasi-instantaneous firing
rate and the temporal membrane potentials of nonleaky integrate-and-fire
neurons. The training strategy can be generalized to any fractional orders
between 0 and 2 since the FO-STDGD incorporates the fractional gradient descent
method into the calculation of spike-timing-dependent loss gradients. The
proposed FO-STDGD model is tested on the MNIST and DVS128 Gesture datasets and
its accuracy under different network structure and fractional orders is
analyzed. It can be found that the classification accuracy increases as the
fractional order increases, and specifically, the case of fractional order 1.9
improves by 155% relative to the case of fractional order 1 (traditional
gradient descent). In addition, our scheme demonstrates the state-of-the-art
computational efficacy for the same SNN structure and training epochs.",2024-10-20,"Yi Yang, Richard M. Voyles, Haiyan H. Zhang, Robert A. Nawrocki",http://arxiv.org/pdf/2410.15293v1,cs.LG
LTPNet Integration of Deep Learning and Environmental Decision Support Systems for Renewable Energy Demand Forecasting,"Against the backdrop of increasingly severe global environmental changes,
accurately predicting and meeting renewable energy demands has become a key
challenge for sustainable business development. Traditional energy demand
forecasting methods often struggle with complex data processing and low
prediction accuracy. To address these issues, this paper introduces a novel
approach that combines deep learning techniques with environmental decision
support systems. The model integrates advanced deep learning techniques,
including LSTM and Transformer, and PSO algorithm for parameter optimization,
significantly enhancing predictive performance and practical applicability.
Results show that our model achieves substantial improvements across various
metrics, including a 30% reduction in MAE, a 20% decrease in MAPE, a 25% drop
in RMSE, and a 35% decline in MSE. These results validate the model's
effectiveness and reliability in renewable energy demand forecasting. This
research provides valuable insights for applying deep learning in environmental
decision support systems.",2024-10-20,"Te Li, Mengze Zhang, Yan Zhou",http://arxiv.org/pdf/2410.15286v1,cs.LG
TRIZ Method for Urban Building Energy Optimization: GWO-SARIMA-LSTM Forecasting model,"With the advancement of global climate change and sustainable development
goals, urban building energy consumption optimization and carbon emission
reduction have become the focus of research. Traditional energy consumption
prediction methods often lack accuracy and adaptability due to their inability
to fully consider complex energy consumption patterns, especially in dealing
with seasonal fluctuations and dynamic changes. This study proposes a hybrid
deep learning model that combines TRIZ innovation theory with GWO, SARIMA and
LSTM to improve the accuracy of building energy consumption prediction. TRIZ
plays a key role in model design, providing innovative solutions to achieve an
effective balance between energy efficiency, cost and comfort by systematically
analyzing the contradictions in energy consumption optimization. GWO is used to
optimize the parameters of the model to ensure that the model maintains high
accuracy under different conditions. The SARIMA model focuses on capturing
seasonal trends in the data, while the LSTM model handles short-term and
long-term dependencies in the data, further improving the accuracy of the
prediction. The main contribution of this research is the development of a
robust model that leverages the strengths of TRIZ and advanced deep learning
techniques, improving the accuracy of energy consumption predictions. Our
experiments demonstrate a significant 15% reduction in prediction error
compared to existing models. This innovative approach not only enhances urban
energy management but also provides a new framework for optimizing energy use
and reducing carbon emissions, contributing to sustainable development.",2024-10-20,"Shirong Zheng, Shaobo Liu, Zhenhong Zhang, Dian Gu, Chunqiu Xia, Huadong Pang, Enock Mintah Ampaw",http://arxiv.org/pdf/2410.15283v1,cs.LG
Neural Normalized Compression Distance and the Disconnect Between Compression and Classification,"It is generally well understood that predictive classification and
compression are intrinsically related concepts in information theory. Indeed,
many deep learning methods are explained as learning a kind of compression, and
that better compression leads to better performance. We interrogate this
hypothesis via the Normalized Compression Distance (NCD), which explicitly
relies on compression as the means of measuring similarity between sequences
and thus enables nearest-neighbor classification. By turning popular large
language models (LLMs) into lossless compressors, we develop a Neural NCD and
compare LLMs to classic general-purpose algorithms like gzip. In doing so, we
find that classification accuracy is not predictable by compression rate alone,
among other empirical aberrations not predicted by current understanding. Our
results imply that our intuition on what it means for a neural network to
``compress'' and what is needed for effective classification are not yet well
understood.",2024-10-20,"John Hurwitz, Charles Nicholas, Edward Raff",http://arxiv.org/pdf/2410.15280v1,cs.LG
Physically Guided Deep Unsupervised Inversion for 1D Magnetotelluric Models,"The global demand for unconventional energy sources such as geothermal energy
and white hydrogen requires new exploration techniques for precise subsurface
structure characterization and potential reservoir identification. The
Magnetotelluric (MT) method is crucial for these tasks, providing critical
information on the distribution of subsurface electrical resistivity at depths
ranging from hundreds to thousands of meters. However, traditional iterative
algorithm-based inversion methods require the adjustment of multiple
parameters, demanding time-consuming and exhaustive tuning processes to achieve
proper cost function minimization. Recent advances have incorporated deep
learning algorithms for MT inversion, primarily based on supervised learning,
and large labeled datasets are needed for training. This work utilizes
TensorFlow operations to create a differentiable forward MT operator,
leveraging its automatic differentiation capability. Moreover, instead of
solving for the subsurface model directly, as classical algorithms perform,
this paper presents a new deep unsupervised inversion algorithm guided by
physics to estimate 1D MT models. Instead of using datasets with the observed
data and their respective model as labels during training, our method employs a
differentiable modeling operator that physically guides the cost function
minimization, making the proposed method solely dependent on observed data.
Therefore, the optimization algorithm updates the network weights to minimize
the data misfit. We test the proposed method with field and synthetic data at
different acquisition frequencies, demonstrating that the resistivity models
obtained are more accurate than those calculated using other techniques.",2024-10-20,"Paul Goyes-Peñafiel, Umair bin Waheed, Henry Arguello",http://arxiv.org/pdf/2410.15274v3,cs.LG
Onboard Health Estimation using Distribution of Relaxation Times for Lithium-ion Batteries,"Real-life batteries tend to experience a range of operating conditions, and
undergo degradation due to a combination of both calendar and cycling aging.
Onboard health estimation models typically use cycling aging data only, and
account for at most one operating condition e.g., temperature, which can limit
the accuracy of the models for state-of-health (SOH) estimation. In this paper,
we utilize electrochemical impedance spectroscopy (EIS) data from 5
calendar-aged and 17 cycling-aged cells to perform SOH estimation under various
operating conditions. The EIS curves are deconvoluted using the distribution of
relaxation times (DRT) technique to map them onto a function $\textbf{g}$ which
consists of distinct timescales representing different resistances inside the
cell. These DRT curves, $\textbf{g}$, are then used as inputs to a long
short-term memory (LSTM)-based neural network model for SOH estimation. We
validate the model performance by testing it on ten different test sets, and
achieve an average RMSPE of 1.69% across these sets.",2024-10-20,"Muhammad Aadil Khan, Sai Thatipamula, Simona Onori",http://arxiv.org/pdf/2410.15271v1,cs.LG
TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models,"Representation learning of Text-Attributed Graphs (TAGs) has garnered
significant attention due to its applications in various domains, including
recommendation systems and social networks. Despite advancements in TAG
learning methodologies, challenges remain in explainability due to the
black-box nature of existing TAG representation learning models. This paper
presents TAGExplainer, the first method designed to generate natural language
explanations for TAG learning. TAGExplainer employs a generative language model
that maps input-output pairs to explanations reflecting the model's
decision-making process. To address the lack of annotated ground truth
explanations in real-world scenarios, we propose first generating pseudo-labels
that capture the model's decisions from saliency-based explanations, then the
pseudo-label generator is iteratively trained based on three training
objectives focusing on faithfulness and brevity via Expert Iteration, to
improve the quality of generated pseudo-labels. The high-quality pseudo-labels
are finally utilized to train an end-to-end explanation generator model.
Extensive experiments are conducted to demonstrate the effectiveness of
TAGExplainer in producing faithful and concise natural language explanations.",2024-10-20,"Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao",http://arxiv.org/pdf/2410.15268v1,cs.LG
Learning-Augmented Algorithms for the Bahncard Problem,"In this paper, we study learning-augmented algorithms for the Bahncard
problem. The Bahncard problem is a generalization of the ski-rental problem,
where a traveler needs to irrevocably and repeatedly decide between a cheap
short-term solution and an expensive long-term one with an unknown future. Even
though the problem is canonical, only a primal-dual-based learning-augmented
algorithm was explicitly designed for it. We develop a new learning-augmented
algorithm, named PFSUM, that incorporates both history and short-term future to
improve online decision making. We derive the competitive ratio of PFSUM as a
function of the prediction error and conduct extensive experiments to show that
PFSUM outperforms the primal-dual-based algorithm.",2024-10-20,"Hailiang Zhao, Xueyan Tang, Peng Chen, Shuiguang Deng",http://arxiv.org/pdf/2410.15257v1,cs.LG
Multimodal Policies with Physics-informed Representations,"In the control problems of the PDE systems, observation is important to make
the decision. However, the observation is generally sparse and missing in
practice due to the limitation and fault of sensors. The above challenges cause
observations with uncertain quantities and modalities. Therefore, how to
leverage the uncertain observations as the states in control problems of the
PDE systems has become a scientific problem. The dynamics of PDE systems rely
on the initial conditions, boundary conditions, and PDE formula. Given the
above three elements, PINNs can be used to solve the PDE systems. In this work,
we discover that the neural network can also be used to identify and represent
the PDE systems using PDE loss and sparse data loss. Inspired by the above
discovery, we propose a Physics-Informed Representation (PIR) algorithm for
multimodal policies in PDE systems' control. It leverages PDE loss to fit the
neural network and data loss calculated on the observations with random
quantities and modalities to propagate the information of initial conditions
and boundary conditions into the inputs. The inputs can be the learnable
parameters or the output of the encoders. Then, under the environments of the
PDE systems, such inputs are the representation of the current state. In our
experiments, the PIR illustrates the superior consistency with the features of
the ground truth compared with baselines, even when there are missing
modalities. Furthermore, PIR has been successfully applied in the downstream
control tasks where the robot leverages the learned state by PIR faster and
more accurately, passing through the complex vortex street from a random
starting location to reach a random target.",2024-10-20,"Haodong Feng, Peiyan Hu, Yue Wang, Dixia Fan",http://arxiv.org/pdf/2410.15250v1,cs.LG
FastSTI: A Fast Conditional Pseudo Numerical Diffusion Model for Spatio-temporal Traffic Data Imputation,"High-quality spatiotemporal traffic data is crucial for intelligent
transportation systems (ITS) and their data-driven applications. Inevitably,
the issue of missing data caused by various disturbances threatens the
reliability of data acquisition. Recent studies of diffusion probability models
have demonstrated the superiority of deep generative models in imputation tasks
by precisely capturing the spatio-temporal correlation of traffic data. One
drawback of diffusion models is their slow sampling/denoising process. In this
work, we aim to accelerate the imputation process while retaining the
performance. We propose a fast conditional diffusion model for spatiotemporal
traffic data imputation (FastSTI). To speed up the process yet, obtain better
performance, we propose the application of a high-order pseudo-numerical
solver. Our method further revs the imputation by introducing a predefined
alignment strategy of variance schedule during the sampling process. Evaluating
FastSTI on two types of real-world traffic datasets (traffic speed and flow)
with different missing data scenarios proves its ability to impute
higher-quality samples in only six sampling steps, especially under high
missing rates (60\% $\sim$ 90\%). The experimental results illustrate a
speed-up of $\textbf{8.3} \times$ faster than the current state-of-the-art
model while achieving better performance.",2024-10-20,"Shaokang Cheng, Nada Osman, Shiru Qu, Lamberto Ballan",http://arxiv.org/pdf/2410.15248v1,cs.LG
Tensor-Fused Multi-View Graph Contrastive Learning,"Graph contrastive learning (GCL) has emerged as a promising approach to
enhance graph neural networks' (GNNs) ability to learn rich representations
from unlabeled graph-structured data. However, current GCL models face
challenges with computational demands and limited feature utilization, often
relying only on basic graph properties like node degrees and edge attributes.
This constrains their capacity to fully capture the complex topological
characteristics of real-world phenomena represented by graphs. To address these
limitations, we propose Tensor-Fused Multi-View Graph Contrastive Learning
(TensorMV-GCL), a novel framework that integrates extended persistent homology
(EPH) with GCL representations and facilitates multi-scale feature extraction.
Our approach uniquely employs tensor aggregation and compression to fuse
information from graph and topological features obtained from multiple
augmented views of the same graph. By incorporating tensor concatenation and
contraction modules, we reduce computational overhead by separating feature
tensor aggregation and transformation. Furthermore, we enhance the quality of
learned topological features and model robustness through noise-injected EPH.
Experiments on molecular, bioinformatic, and social network datasets
demonstrate TensorMV-GCL's superiority, outperforming 15 state-of-the-art
methods in graph classification tasks across 9 out of 11 benchmarks while
achieving comparable results on the remaining two. The code for this paper is
publicly available at https://github.com/CS-SAIL/Tensor-MV-GCL.git.",2024-10-20,"Yujia Wu, Junyi Mo, Elynn Chen, Yuzhou Chen",http://arxiv.org/pdf/2410.15247v2,cs.LG
Conditional Uncertainty Quantification for Tensorized Topological Neural Networks,"Graph Neural Networks (GNNs) have become the de facto standard for analyzing
graph-structured data, leveraging message-passing techniques to capture both
structural and node feature information. However, recent studies have raised
concerns about the statistical reliability of uncertainty estimates produced by
GNNs. This paper addresses this crucial challenge by introducing a novel
technique for quantifying uncertainty in non-exchangeable graph-structured
data, while simultaneously reducing the size of label prediction sets in graph
classification tasks. We propose Conformalized Tensor-based Topological Neural
Networks (CF-T2NN), a new approach for rigorous prediction inference over
graphs. CF-T2NN employs tensor decomposition and topological knowledge learning
to navigate and interpret the inherent uncertainty in decision-making
processes. This method enables a more nuanced understanding and handling of
prediction uncertainties, enhancing the reliability and interpretability of
neural network outcomes. Our empirical validation, conducted across 10
real-world datasets, demonstrates the superiority of CF-T2NN over a wide array
of state-of-the-art methods on various graph benchmarks. This work not only
enhances the GNN framework with robust uncertainty quantification capabilities
but also sets a new standard for reliability and precision in graph-structured
data analysis.",2024-10-20,"Yujia Wu, Bo Yang, Yang Zhao, Elynn Chen, Yuzhou Chen, Zheshi Zheng",http://arxiv.org/pdf/2410.15241v1,cs.LG
Conditional Prediction ROC Bands for Graph Classification,"Graph classification in medical imaging and drug discovery requires accuracy
and robust uncertainty quantification. To address this need, we introduce
Conditional Prediction ROC (CP-ROC) bands, offering uncertainty quantification
for ROC curves and robustness to distributional shifts in test data. Although
developed for Tensorized Graph Neural Networks (TGNNs), CP-ROC is adaptable to
general Graph Neural Networks (GNNs) and other machine learning models. We
establish statistically guaranteed coverage for CP-ROC under a local
exchangeability condition. This addresses uncertainty challenges for ROC curves
under non-iid setting, ensuring reliability when test graph distributions
differ from training data. Empirically, to establish local exchangeability for
TGNNs, we introduce a data-driven approach to construct local calibration sets
for graphs. Comprehensive evaluations show that CP-ROC significantly improves
prediction reliability across diverse tasks. This method enhances uncertainty
quantification efficiency and reliability for ROC curves, proving valuable for
real-world applications with non-iid objects.",2024-10-20,"Yujia Wu, Bo Yang, Elynn Chen, Yuzhou Chen, Zheshi Zheng",http://arxiv.org/pdf/2410.15239v1,cs.LG
Jailbreaking and Mitigation of Vulnerabilities in Large Language Models,"Large Language Models (LLMs) have transformed artificial intelligence by
advancing natural language understanding and generation, enabling applications
across fields beyond healthcare, software engineering, and conversational
systems. Despite these advancements in the past few years, LLMs have shown
considerable vulnerabilities, particularly to prompt injection and jailbreaking
attacks. This review analyzes the state of research on these vulnerabilities
and presents available defense strategies. We roughly categorize attack
approaches into prompt-based, model-based, multimodal, and multilingual,
covering techniques such as adversarial prompting, backdoor injections, and
cross-modality exploits. We also review various defense mechanisms, including
prompt filtering, transformation, alignment techniques, multi-agent defenses,
and self-regulation, evaluating their strengths and shortcomings. We also
discuss key metrics and benchmarks used to assess LLM safety and robustness,
noting challenges like the quantification of attack success in interactive
contexts and biases in existing datasets. Identifying current research gaps, we
suggest future directions for resilient alignment strategies, advanced defenses
against evolving attacks, automation of jailbreak detection, and consideration
of ethical and societal impacts. This review emphasizes the need for continued
research and cooperation within the AI community to enhance LLM security and
ensure their safe deployment.",2024-10-20,"Benji Peng, Keyu Chen, Qian Niu, Ziqian Bi, Ming Liu, Pohsun Feng, Tianyang Wang, Lawrence K. Q. Yan, Yizhu Wen, Yichao Zhang, Caitlyn Heqi Yin",http://arxiv.org/pdf/2410.15236v2,cs.LG
A Semidefinite Relaxation Approach for Fair Graph Clustering,"Fair graph clustering is crucial for ensuring equitable representation and
treatment of diverse communities in network analysis. Traditional methods often
ignore disparities among social, economic, and demographic groups, perpetuating
biased outcomes and reinforcing inequalities. This study introduces fair graph
clustering within the framework of the disparate impact doctrine, treating it
as a joint optimization problem integrating clustering quality and fairness
constraints. Given the NP-hard nature of this problem, we employ a semidefinite
relaxation approach to approximate the underlying optimization problem. For up
to medium-sized graphs, we utilize a singular value decomposition-based
algorithm, while for larger graphs, we propose a novel algorithm based on the
alternative direction method of multipliers. Unlike existing methods, our
formulation allows for tuning the trade-off between clustering quality and
fairness. Experimental results on graphs generated from the standard stochastic
block model demonstrate the superiority of our approach in achieving an optimal
accuracy-fairness trade-off compared to state-of-the-art methods.",2024-10-19,"Sina Baharlouei, Sadra Sabouri",http://arxiv.org/pdf/2410.15233v1,cs.LG
Deep Learning-based Detection of Bacterial Swarm Motion Using a Single Image,"Distinguishing between swarming and swimming, the two principal forms of
bacterial movement, holds significant conceptual and clinical relevance. This
is because bacteria that exhibit swarming capabilities often possess unique
properties crucial to the pathogenesis of infectious diseases and may also have
therapeutic potential. Here, we report a deep learning-based swarming
classifier that rapidly and autonomously predicts swarming probability using a
single blurry image. Compared with traditional video-based, manually-processed
approaches, our method is particularly suited for high-throughput environments
and provides objective, quantitative assessments of swarming probability. The
swarming classifier demonstrated in our work was trained on Enterobacter sp.
SM3 and showed good performance when blindly tested on new swarming (positive)
and swimming (negative) test images of SM3, achieving a sensitivity of 97.44%
and a specificity of 100%. Furthermore, this classifier demonstrated robust
external generalization capabilities when applied to unseen bacterial species,
such as Serratia marcescens DB10 and Citrobacter koseri H6. It blindly achieved
a sensitivity of 97.92% and a specificity of 96.77% for DB10, and a sensitivity
of 100% and a specificity of 97.22% for H6. This competitive performance
indicates the potential to adapt our approach for diagnostic applications
through portable devices or even smartphones. This adaptation would facilitate
rapid, objective, on-site screening for bacterial swarming motility,
potentially enhancing the early detection and treatment assessment of various
diseases, including inflammatory bowel diseases (IBD) and urinary tract
infections (UTI).",2024-10-19,"Yuzhu Li, Hao Li, Weijie Chen, Keelan O'Riordan, Neha Mani, Yuxuan Qi, Tairan Liu, Sridhar Mani, Aydogan Ozcan",http://arxiv.org/pdf/2410.15229v1,cs.LG
Robust Low-rank Tensor Train Recovery,"Tensor train (TT) decomposition represents an $N$-order tensor using $O(N)$
matrices (i.e., factors) of small dimensions, achieved through products among
these factors. Due to its compact representation, TT decomposition has found
wide applications, including various tensor recovery problems in signal
processing and quantum information. In this paper, we study the problem of
reconstructing a TT format tensor from measurements that are contaminated by
outliers with arbitrary values. Given the vulnerability of smooth formulations
to corruptions, we use an $\ell_1$ loss function to enhance robustness against
outliers. We first establish the $\ell_1/\ell_2$-restricted isometry property
(RIP) for Gaussian measurement operators, demonstrating that the information in
the TT format tensor can be preserved using a number of measurements that grows
linearly with $N$. We also prove the sharpness property for the $\ell_1$ loss
function optimized over TT format tensors. Building on the $\ell_1/\ell_2$-RIP
and sharpness property, we then propose two complementary methods to recover
the TT format tensor from the corrupted measurements: the projected subgradient
method (PSubGM), which optimizes over the entire tensor, and the factorized
Riemannian subgradient method (FRSubGM), which optimizes directly over the
factors. Compared to PSubGM, the factorized approach FRSubGM significantly
reduces the memory cost at the expense of a slightly slower convergence rate.
Nevertheless, we show that both methods, with diminishing step sizes, converge
linearly to the ground-truth tensor given an appropriate initialization, which
can be obtained by a truncated spectral method.",2024-10-19,"Zhen Qin, Zhihui Zhu",http://arxiv.org/pdf/2410.15224v1,cs.LG
IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning,"Despite the popularity of multi-agent reinforcement learning (RL) in
simulated and two-player applications, its success in messy real-world
applications has been limited. A key challenge lies in its generalizability
across problem variations, a common necessity for many real-world problems.
Contextual reinforcement learning (CRL) formalizes learning policies that
generalize across problem variations. However, the lack of standardized
benchmarks for multi-agent CRL has hindered progress in the field. Such
benchmarks are desired to be based on real-world applications to naturally
capture the many open challenges of real-world problems that affect
generalization. To bridge this gap, we propose IntersectionZoo, a comprehensive
benchmark suite for multi-agent CRL through the real-world application of
cooperative eco-driving in urban road networks. The task of cooperative
eco-driving is to control a fleet of vehicles to reduce fleet-level vehicular
emissions. By grounding IntersectionZoo in a real-world application, we
naturally capture real-world problem characteristics, such as partial
observability and multiple competing objectives. IntersectionZoo is built on
data-informed simulations of 16,334 signalized intersections derived from 10
major US cities, modeled in an open-source industry-grade microscopic traffic
simulator. By modeling factors affecting vehicular exhaust emissions (e.g.,
temperature, road conditions, travel demand), IntersectionZoo provides one
million data-driven traffic scenarios. Using these traffic scenarios, we
benchmark popular multi-agent RL and human-like driving algorithms and
demonstrate that the popular multi-agent RL algorithms struggle to generalize
in CRL settings.",2024-10-19,"Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Zhongxia Yan, Cathy Wu",http://arxiv.org/pdf/2410.15221v1,cs.LG
Deep Learning Foundation and Pattern Models: Challenges in Hydrological Time Series,"There has been active investigation into deep learning approaches for time
series analysis, including foundation models. However, most studies do not
address significant scientific applications. This paper aims to identify key
features in time series by examining hydrology data. Our work advances computer
science by emphasizing critical application features and contributes to
hydrology and other scientific fields by identifying modeling approaches that
effectively capture these features. Scientific time series data are inherently
complex, involving observations from multiple locations, each with various
time-dependent data streams and exogenous factors that may be static or
time-varying and either application-dependent or purely mathematical. This
research analyzes hydrology time series from the CAMELS and Caravan global
datasets, which encompass rainfall and runoff data across catchments, featuring
up to six observed streams and 209 static parameters across approximately 8,000
locations. Our investigation assesses the impact of exogenous data through
eight different model configurations for key hydrology tasks. Results
demonstrate that integrating exogenous information enhances data
representation, reducing mean squared error by up to 40% in the largest
dataset. Additionally, we present a detailed performance comparison of over 20
state-of-the-art pattern and foundation models. The analysis is fully
open-source, facilitated by Jupyter Notebook on Google Colab for LSTM-based
modeling, data preprocessing, and model comparisons. Preliminary findings using
alternative deep learning architectures reveal that models incorporating
comprehensive observed and exogenous data outperform more limited approaches,
including foundation models. Notably, natural annual periodic exogenous time
series contribute the most significant improvements, though static and other
periodic factors are also valuable.",2024-10-19,"Junyang He, Ying-Jung Chen, Alireza Jafari, Anushka Idamekorala, Geoffrey Fox",http://arxiv.org/pdf/2410.15218v2,cs.LG
Future-Guided Learning: A Predictive Approach To Enhance Time-Series Forecasting,"Accurate time-series forecasting is crucial in various scientific and
industrial domains, yet deep learning models often struggle to capture
long-term dependencies and adapt to data distribution drifts over time. We
introduce Future-Guided Learning, an approach that enhances time-series event
forecasting through a dynamic feedback mechanism inspired by predictive coding.
Our method involves two models: a detection model that analyzes future data to
identify critical events and a forecasting model that predicts these events
based on current data. When discrepancies occur between the forecasting and
detection models, a more significant update is applied to the forecasting
model, effectively minimizing surprise and adapting to shifts in the data
distribution by aligning its predictions with actual future outcomes. This
feedback loop allows the forecasting model to dynamically adjust its
parameters, focusing on persistent features despite changes in the data. We
validate our approach on a variety of tasks, demonstrating a 44.8% increase in
AUC-ROC for seizure prediction using EEG data, and a 48.7% reduction in MSE for
forecasting in nonlinear dynamical systems. By incorporating a predictive
feedback mechanism adaptable to data drift, Future-Guided Learning advances how
deep learning is applied to time-series forecasting. Our code is publicly
available at https://github.com/SkyeGunasekaran/FutureGuidedLearning.",2024-10-19,"Skye Gunasekaran, Assel Kembay, Hugo Ladret, Rui-Jie Zhu, Laurent Perrinet, Omid Kavehei, Jason Eshraghian",http://arxiv.org/pdf/2410.15217v2,cs.LG
Boardwalk Empire: How Generative AI is Revolutionizing Economic Paradigms,"The relentless pursuit of technological advancements has ushered in a new era
where artificial intelligence (AI) is not only a powerful tool but also a
critical economic driver. At the forefront of this transformation is Generative
AI, which is catalyzing a paradigm shift across industries. Deep generative
models, an integration of generative and deep learning techniques, excel in
creating new data beyond analyzing existing ones, revolutionizing sectors from
production and manufacturing to finance. By automating design, optimization,
and innovation cycles, Generative AI is reshaping core industrial processes. In
the financial sector, it is transforming risk assessment, trading strategies,
and forecasting, demonstrating its profound impact. This paper explores the
sweeping changes driven by deep learning models like Large Language Models
(LLMs), highlighting their potential to foster innovative business models,
disruptive technologies, and novel economic landscapes. As we stand at the
threshold of an AI-driven economic era, Generative AI is emerging as a pivotal
force, driving innovation, disruption, and economic evolution on a global
scale.",2024-10-19,"Subramanyam Sahoo, Kamlesh Dutta",http://arxiv.org/pdf/2410.15212v2,cs.LG
Low-cost Robust Night-time Aerial Material Segmentation through Hyperspectral Data and Sparse Spatio-Temporal Learning,"Material segmentation is a complex task, particularly when dealing with
aerial data in poor lighting and atmospheric conditions. To address this,
hyperspectral data from specialized cameras can be very useful in addition to
RGB images. However, due to hardware constraints, high spectral data often come
with lower spatial resolution. Additionally, incorporating such data into a
learning-based segmentation framework is challenging due to the numerous data
channels involved. To overcome these difficulties, we propose an innovative
Siamese framework that uses time series-based compression to effectively and
scalably integrate the additional spectral data into the segmentation task. We
demonstrate our model's effectiveness through competitive benchmarks on aerial
datasets in various environmental conditions.",2024-10-19,"Chandrajit Bajaj, Minh Nguyen, Shubham Bhardwaj",http://arxiv.org/pdf/2410.15208v1,cs.LG
Unsupervised Domain Adaptation Approaches for Chessboard Recognition,"Chess involves extensive study and requires players to keep manual records of
their matches, a process which is time-consuming and distracting. The lack of
high-quality labeled photographs of chess boards, and the tediousness of manual
labeling, have hindered the wide application of Deep Learning (DL) to
automating this record-keeping process. This paper proposes an end-to-end
pipeline that employs domain adaptation (DA) to predict the labels of real,
top-view, unlabeled chessboard images using synthetic, labeled images. The
pipeline is composed of a pre-processing phase which detects the board, crops
the individual squares, and feeds them one at a time to a DL model. The model
then predicts the labels of the squares and passes the ordered predictions to a
post-processing pipeline which generates the Forsyth-Edwards Notation (FEN) of
the position. The three approaches considered are the following: A VGG16 model
pre-trained on ImageNet, defined here as the Base-Source model, fine-tuned to
predict source domain squares and then used to predict target domain squares
without any domain adaptation; an improved version of the Base-Source model
which applied CORAL loss to some of the final fully connected layers of the
VGG16 to implement DA; and a Domain Adversarial Neural Network (DANN) which
used the adversarial training of a domain discriminator to perform the DA.
Also, although we opted not to use the labels of the target domain for this
study, we trained a baseline with the same architecture as the Base-Source
model (Named Base-Target) directly on the target domain in order to get an
upper bound on the performance achievable through domain adaptation. The
results show that the DANN model only results in a 3% loss in accuracy when
compared to the Base-Target model while saving all the effort required to label
the data.",2024-10-19,"Wassim Jabbour, Enzo Benoit-Jeannin, Oscar Bedford, Saif Shahin",http://arxiv.org/pdf/2410.15206v1,cs.LG
Learning the Rolling Penny Dynamics,"We consider learning the dynamics of a typical nonholonomic system -- the
rolling penny. A nonholonomic system is a system subject to nonholonomic
constraints. Unlike a holonomic constraints, a nonholonomic constraint does not
define a submanifold on the configuration space. Therefore, the inverse problem
of finding the constraints has to involve the tangent space. This paper
discusses how to learn the dynamics, as well as the constraints for such a
system, given the data set of discrete trajectories on the tangent bundle $TQ$.",2024-10-19,"Baiyue Wang, Anthony Bloch",http://arxiv.org/pdf/2410.15201v2,cs.LG
Multidimensional Knowledge Graph Embeddings for International Trade Flow Analysis,"Understanding the complex dynamics of high-dimensional, contingent, and
strongly nonlinear economic data, often shaped by multiplicative processes,
poses significant challenges for traditional regression methods as such methods
offer limited capacity to capture the structural changes they feature. To
address this, we propose leveraging the potential of knowledge graph embeddings
for economic trade data, in particular, to predict international trade
relationships. We implement KonecoKG, a knowledge graph representation of
economic trade data with multidimensional relationships using SDM-RDFizer, and
transform the relationships into a knowledge graph embedding using AmpliGraph.",2024-10-19,"Durgesh Nandini, Simon Bloethner, Mirco Schoenfeld, Mario Larch",http://arxiv.org/pdf/2410.19835v1,cs.LG
Action abstractions for amortized sampling,"As trajectories sampled by policies used by reinforcement learning (RL) and
generative flow networks (GFlowNets) grow longer, credit assignment and
exploration become more challenging, and the long planning horizon hinders mode
discovery and generalization. The challenge is particularly pronounced in
entropy-seeking RL methods, such as generative flow networks, where the agent
must learn to sample from a structured distribution and discover multiple
high-reward states, each of which take many steps to reach. To tackle this
challenge, we propose an approach to incorporate the discovery of action
abstractions, or high-level actions, into the policy optimization process. Our
approach involves iteratively extracting action subsequences commonly used
across many high-reward trajectories and `chunking' them into a single action
that is added to the action space. In empirical evaluation on synthetic and
real-world environments, our approach demonstrates improved sample efficiency
performance in discovering diverse high-reward objects, especially on harder
exploration problems. We also observe that the abstracted high-order actions
are interpretable, capturing the latent structure of the reward landscape of
the action space. This work provides a cognitively motivated approach to action
abstraction in RL and is the first demonstration of hierarchical planning in
amortized sequential sampling.",2024-10-19,"Oussama Boussif, Léna Néhale Ezzine, Joseph D Viviano, Michał Koziarski, Moksh Jain, Nikolay Malkin, Emmanuel Bengio, Rim Assouel, Yoshua Bengio",http://arxiv.org/pdf/2410.15184v1,cs.LG
GUIDE: Real-Time Human-Shaped Agents,"The recent rapid advancement of machine learning has been driven by
increasingly powerful models with the growing availability of training data and
computational resources. However, real-time decision-making tasks with limited
time and sparse learning signals remain challenging. One way of improving the
learning speed and performance of these agents is to leverage human guidance.
In this work, we introduce GUIDE, a framework for real-time human-guided
reinforcement learning by enabling continuous human feedback and grounding such
feedback into dense rewards to accelerate policy learning. Additionally, our
method features a simulated feedback module that learns and replicates human
feedback patterns in an online fashion, effectively reducing the need for human
input while allowing continual training. We demonstrate the performance of our
framework on challenging tasks with sparse rewards and visual observations. Our
human study involving 50 subjects offers strong quantitative and qualitative
evidence of the effectiveness of our approach. With only 10 minutes of human
feedback, our algorithm achieves up to 30% increase in success rate compared to
its RL baseline.",2024-10-19,"Lingyu Zhang, Zhengran Ji, Nicholas R Waytowich, Boyuan Chen",http://arxiv.org/pdf/2410.15181v1,cs.LG
HACSurv: A Hierarchical Copula-Based Approach for Survival Analysis with Dependent Competing Risks,"In survival analysis, subjects often face competing risks; for example,
individuals with cancer may also suffer from heart disease or other illnesses,
which can jointly influence the prognosis of risks and censoring. Traditional
survival analysis methods often treat competing risks as independent and fail
to accommodate the dependencies between different conditions. In this paper, we
introduce HACSurv, a survival analysis method that learns Hierarchical
Archimedean Copulas structures and cause-specific survival functions from data
with competing risks. HACSurv employs a flexible dependency structure using
hierarchical Archimedean copulas to represent the relationships between
competing risks and censoring. By capturing the dependencies between risks and
censoring, HACSurv improves the accuracy of survival predictions and offers
insights into risk interactions. Experiments on synthetic dataset demonstrate
that our method can accurately identify the complex dependency structure and
precisely predict survival distributions, whereas the compared methods exhibit
significant deviations between their predictions and the true distributions.
Experiments on multiple real-world datasets also demonstrate that our method
achieves better survival prediction compared to previous state-of-the-art
methods.",2024-10-19,"Xin Liu, Weijia Zhang, Min-Ling Zhang",http://arxiv.org/pdf/2410.15180v2,cs.LG
GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments,"Autonomous vehicles performing navigation tasks in complex environments face
significant challenges due to uncertainty in state estimation. In many
scenarios, such as stealth operations or resource-constrained settings,
accessing high-precision localization comes at a significant cost, forcing
robots to rely primarily on less precise state estimates. Our key observation
is that different tasks require varying levels of precision in different
regions: a robot navigating a crowded space might need precise localization
near obstacles but can operate effectively with less precision elsewhere. In
this paper, we present a planning method for integrating task-specific
uncertainty requirements directly into navigation policies. We introduce
Task-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of
state estimation uncertainty across different regions. TSUMs align task
requirements and environmental features using a shared representation space,
generated via a domain-adapted encoder. Using TSUMs, we propose Generalized
Uncertainty Integration for Decision-Making and Execution (GUIDE), a policy
conditioning framework that incorporates these uncertainty requirements into
robot decision-making. We find that TSUMs provide an effective way to abstract
task-specific uncertainty requirements, and conditioning policies on TSUMs
enables the robot to reason about the context-dependent value of certainty and
adapt its behavior accordingly. We show how integrating GUIDE into
reinforcement learning frameworks allows the agent to learn navigation policies
that effectively balance task completion and uncertainty management without
explicit reward engineering. We evaluate GUIDE on various real-world robotic
navigation tasks and find that it demonstrates significant improvement in task
completion rates compared to baseline methods that do not explicitly consider
task-specific uncertainty.",2024-10-19,"Gokul Puthumanaillam, Paulo Padrao, Jose Fuentes, Leonardo Bobadilla, Melkior Ornik",http://arxiv.org/pdf/2410.15178v3,cs.LG
Adaptive Pruning with Module Robustness Sensitivity: Balancing Compression and Robustness,"Neural network pruning has traditionally focused on weight-based criteria to
achieve model compression, frequently overlooking the crucial balance between
adversarial robustness and accuracy. Existing approaches often fail to preserve
robustness in pruned networks, leaving them more susceptible to adversarial
attacks. This paper introduces Module Robustness Sensitivity (MRS), a novel
metric that quantifies layer-wise sensitivity to adversarial perturbations and
dynamically informs pruning decisions. Leveraging MRS, we propose Module Robust
Pruning and Fine-Tuning (MRPF), an adaptive pruning algorithm compatible with
any adversarial training method, offering both flexibility and scalability.
Extensive experiments on SVHN, CIFAR, and Tiny-ImageNet across diverse
architectures, including ResNet, VGG, and MobileViT, demonstrate that MRPF
significantly enhances adversarial robustness while maintaining competitive
accuracy and computational efficiency. Furthermore, MRPF consistently
outperforms state-of-the-art structured pruning methods in balancing
robustness, accuracy, and compression. This work establishes a practical and
generalizable framework for robust pruning, addressing the long-standing
trade-off between model compression and robustness preservation.",2024-10-19,"Lincen Bai, Hedi Tabia, Raúl Santos-Rodríguez",http://arxiv.org/pdf/2410.15176v2,cs.LG
Crafting Tomorrow: The Influence of Design Choices on Fresh Content in Social Media Recommendation,"The rise in popularity of social media platforms, has resulted in millions of
new, content pieces being created every day. This surge in content creation
underscores the need to pay attention to our design choices as they can greatly
impact how long content remains relevant. In today's landscape where regularly
recommending new content is crucial, particularly in the absence of detailed
information, a variety of factors such as UI features, algorithms and system
settings contribute to shaping the journey of content across the platform.
While previous research has focused on how new content affects users'
experiences, this study takes a different approach by analyzing these decisions
considering the content itself.
  Through a series of carefully crafted experiments we explore how seemingly
small decisions can influence the longevity of content, measured by metrics
like Content Progression (CVP) and Content Survival (CSR). We also emphasize
the importance of recognizing the stages that content goes through underscoring
the need to tailor strategies for each stage as a one size fits all approach
may not be effective. Additionally we argue for a departure from traditional
experimental setups in the study of content lifecycles, to avoid potential
misunderstandings while proposing advanced techniques, to achieve greater
precision and accuracy in the evaluation process.",2024-10-19,"Srijan Saket, Mohit Agarwal, Rishabh Mehrotra",http://arxiv.org/pdf/2410.15174v1,cs.LG
Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction,"In recent years, Graph Neural Networks (GNNs) have become successful in
molecular property prediction tasks such as toxicity analysis. However, due to
the black-box nature of GNNs, their outputs can be concerning in high-stakes
decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph
Counterfactual Explanation (GCE) has emerged as a promising approach to improve
GNN transparency. However, current GCE methods usually fail to take
domain-specific knowledge into consideration, which can result in outputs that
are not easily comprehensible by humans. To address this challenge, we propose
a novel GCE method, LLM-GCE, to unleash the power of large language models
(LLMs) in explaining GNNs for molecular property prediction. Specifically, we
utilize an autoencoder to generate the counterfactual graph topology from a set
of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also
incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which
provides intermediate feedback derived from the generated counterfactuals as an
attempt to give more faithful guidance. Extensive experiments demonstrate the
superior performance of LLM-GCE. Our code is released on
https://github.com/YinhanHe123/new\_LLM4GNNExplanation.",2024-10-19,"Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li",http://arxiv.org/pdf/2410.15165v1,cs.LG
Pipeline Gradient-based Model Training on Analog In-memory Accelerators,"Aiming to accelerate the training of large deep neural models (DNN) in an
energy-efficient way, an analog in-memory computing (AIMC) accelerator emerges
as a solution with immense potential. In AIMC accelerators, trainable weights
are kept in memory without the need to move from memory to processors during
the training, reducing a bunch of overhead. However, although the in-memory
feature enables efficient computation, it also constrains the use of data
parallelism since copying weights from one AIMC to another is expensive. To
enable parallel training using AIMC, we propose synchronous and asynchronous
pipeline parallelism for AIMC accelerators inspired by the pipeline in digital
domains. This paper provides a theoretical convergence guarantee for both
synchronous and asynchronous pipelines in terms of both sampling and clock
cycle complexity, which is non-trivial since the physical characteristic of
AIMC accelerators leads to analog updates that suffer from asymmetric bias. The
simulations of training DNN on real datasets verify the efficiency of pipeline
training.",2024-10-19,"Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Hsinyu Tsai, Kaoutar El Maghraoui, Tianyi Chen",http://arxiv.org/pdf/2410.15155v1,cs.LG
Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning,"Intermediate task transfer learning can greatly improve model performance.
If, for example, one has little training data for emotion detection, first
fine-tuning a language model on a sentiment classification dataset may improve
performance strongly. But which task to choose for transfer learning? Prior
methods producing useful task rankings are infeasible for large source pools,
as they require forward passes through all source language models. We overcome
this by introducing Embedding Space Maps (ESMs), light-weight neural networks
that approximate the effect of fine-tuning a language model. We conduct the
largest study on NLP task transferability and task selection with 12k
source-target pairs. We find that applying ESMs on a prior method reduces
execution time and disk space usage by factors of 10 and 278, respectively,
while retaining high selection performance (avg. regret@5 score of 2.95).",2024-10-19,"David Schulte, Felix Hamborg, Alan Akbik",http://arxiv.org/pdf/2410.15148v1,cs.LG
Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling,"The majority of online continual learning (CL) advocates single-epoch
training and imposes restrictions on the size of replay memory. However,
single-epoch training would incur a different amount of computations per CL
algorithm, and the additional storage cost to store logit or model in addition
to replay memory is largely ignored in calculating the storage budget. Arguing
different computational and storage budgets hinder fair comparison among CL
algorithms in practice, we propose to use floating point operations (FLOPs) and
total memory size in Byte as a metric for computational and memory budgets,
respectively, to compare and develop CL algorithms in the same 'total resource
budget.' To improve a CL method in a limited total budget, we propose adaptive
layer freezing that does not update the layers for less informative batches to
reduce computational costs with a negligible loss of accuracy. In addition, we
propose a memory retrieval method that allows the model to learn the same
amount of knowledge as using random retrieval in fewer iterations. Empirical
validations on the CIFAR-10/100, CLEAR-10/100, and ImageNet-1K datasets
demonstrate that the proposed approach outperforms the state-of-the-art methods
within the same total budget",2024-10-19,"Minhyuk Seo, Hyunseo Koh, Jonghyun Choi",http://arxiv.org/pdf/2410.15143v2,cs.LG
Conformal Predictive Portfolio Selection,"This study examines portfolio selection using predictive models for portfolio
returns. Portfolio selection is a fundamental task in finance, and a variety of
methods have been developed to achieve this goal. For instance, the
mean-variance approach constructs portfolios by balancing the trade-off between
the mean and variance of asset returns, while the quantile-based approach
optimizes portfolios by considering tail risk. These methods often depend on
distributional information estimated from historical data using predictive
models, each of which carries its own uncertainty. To address this, we propose
a framework for predictive portfolio selection via conformal prediction ,
called \emph{Conformal Predictive Portfolio Selection} (CPPS). Our approach
forecasts future portfolio returns, computes the corresponding prediction
intervals, and selects the portfolio of interest based on these intervals. The
framework is flexible and can accommodate a wide range of predictive models,
including autoregressive (AR) models, random forests, and neural networks. We
demonstrate the effectiveness of the CPPS framework by applying it to an AR
model and validate its performance through empirical studies, showing that it
delivers superior returns compared to simpler strategies.",2024-10-19,Masahiro Kato,http://arxiv.org/pdf/2410.16333v2,cs.LG
Collaborative State Fusion in Partially Known Multi-agent Environments,"In this paper, we study the collaborative state fusion problem in a
multi-agent environment, where mobile agents collaborate to track movable
targets. Due to the limited sensing range and potential errors of on-board
sensors, it is necessary to aggregate individual observations to provide target
state fusion for better target state estimation. Existing schemes do not
perform well due to (1) impractical assumption of the fully known prior target
state-space model and (2) observation outliers from individual sensors. To
address the issues, we propose a two-stage collaborative fusion framework,
namely \underline{L}earnable Weighted R\underline{o}bust \underline{F}usion
(\textsf{LoF}). \textsf{LoF} combines a local state estimator (e.g., Kalman
Filter) with a learnable weight generator to address the mismatch between the
prior state-space model and underlying patterns of moving targets. Moreover,
given observation outliers, we develop a time-series soft medoid(TSM) scheme to
perform robust fusion. We evaluate \textsf{LoF} in a collaborative detection
simulation environment with promising results. In an example setting with 4
agents and 2 targets, \textsf{LoF} leads to a 9.1\% higher fusion gain compared
to the state-of-the-art.",2024-10-19,"Tianlong Zhou, Jun Shang, Weixiong Rao",http://arxiv.org/pdf/2410.15137v1,cs.LG
Controllable RANSAC-based Anomaly Detection via Hypothesis Testing,"Detecting the presence of anomalies in regression models is a crucial task in
machine learning, as anomalies can significantly impact the accuracy and
reliability of predictions. Random Sample Consensus (RANSAC) is one of the most
popular robust regression methods for addressing this challenge. However, this
method lacks the capability to guarantee the reliability of the anomaly
detection (AD) results. In this paper, we propose a novel statistical method
for testing the AD results obtained by RANSAC, named CTRL-RANSAC (controllable
RANSAC). The key strength of the proposed method lies in its ability to control
the probability of misidentifying anomalies below a pre-specified level
$\alpha$ (e.g., $\alpha = 0.05$). By examining the selection strategy of RANSAC
and leveraging the Selective Inference (SI) framework, we prove that achieving
controllable RANSAC is indeed feasible. Furthermore, we introduce a more
strategic and computationally efficient approach to enhance the true detection
rate and overall performance of the CTRL-RANSAC. Experiments conducted on
synthetic and real-world datasets robustly support our theoretical results,
showcasing the superior performance of the proposed method.",2024-10-19,"Le Hong Phong, Ho Ngoc Luat, Vo Nguyen Le Duy",http://arxiv.org/pdf/2410.15133v1,cs.LG
Generalized Flow Matching for Transition Dynamics Modeling,"Simulating transition dynamics between metastable states is a fundamental
challenge in dynamical systems and stochastic processes with wide real-world
applications in understanding protein folding, chemical reactions and neural
activities. However, the computational challenge often lies on sampling
exponentially many paths in which only a small fraction ends in the target
metastable state due to existence of high energy barriers. To amortize the
cost, we propose a data-driven approach to warm-up the simulation by learning
nonlinear interpolations from local dynamics. Specifically, we infer a
potential energy function from local dynamics data. To find plausible paths
between two metastable states, we formulate a generalized flow matching
framework that learns a vector field to sample propable paths between the two
marginal densities under the learned energy function. Furthermore, we
iteratively refine the model by assigning importance weights to the sampled
paths and buffering more likely paths for training. We validate the
effectiveness of the proposed method to sample probable paths on both synthetic
and real-world molecular systems.",2024-10-19,"Haibo Wang, Yuxuan Qiu, Yanze Wang, Rob Brekelmans, Yuanqi Du",http://arxiv.org/pdf/2410.15128v1,cs.LG
Reinfier and Reintrainer: Verification and Interpretation-Driven Safe Deep Reinforcement Learning Frameworks,"Ensuring verifiable and interpretable safety of deep reinforcement learning
(DRL) is crucial for its deployment in real-world applications. Existing
approaches like verification-in-the-loop training, however, face challenges
such as difficulty in deployment, inefficient training, lack of
interpretability, and suboptimal performance in property satisfaction and
reward performance. In this work, we propose a novel verification-driven
interpretation-in-the-loop framework Reintrainer to develop trustworthy DRL
models, which are guaranteed to meet the expected constraint properties.
Specifically, in each iteration, this framework measures the gap between the
on-training model and predefined properties using formal verification,
interprets the contribution of each input feature to the model's output, and
then generates the training strategy derived from the on-the-fly measure
results, until all predefined properties are proven. Additionally, the low
reusability of existing verifiers and interpreters motivates us to develop
Reinfier, a general and fundamental tool within Reintrainer for DRL
verification and interpretation. Reinfier features breakpoints searching and
verification-driven interpretation, associated with a concise
constraint-encoding language DRLP. Evaluations demonstrate that Reintrainer
outperforms the state-of-the-art on six public benchmarks in both performance
and property guarantees. Our framework can be accessed at
https://github.com/Kurayuri/Reinfier.",2024-10-19,"Zixuan Yang, Jiaqi Zheng, Guihai Chen",http://arxiv.org/pdf/2410.15127v2,cs.LG
Generalizable Prediction Model of Molten Salt Mixture Density with Chemistry-Informed Transfer Learning,"Optimally designing molten salt applications requires knowledge of their
thermophysical properties, but existing databases are incomplete, and
experiments are challenging. Ideal mixing and Redlich-Kister models are
computationally cheap but lack either accuracy or generality. To address this,
a transfer learning approach using deep neural networks (DNNs) is proposed,
combining Redlich-Kister models, experimental data, and ab initio properties.
The approach predicts molten salt density with high accuracy ($r^{2}$ > 0.99,
MAPE < 1%), outperforming the alternatives.",2024-10-19,"Julian Barra, Shayan Shahbazi, Anthony Birri, Rajni Chahal, Ibrahim Isah, Muhammad Nouman Anwar, Tyler Starkus, Prasanna Balaprakash, Stephen Lam",http://arxiv.org/pdf/2410.15120v1,cs.LG
Accelerating k-Means Clustering with Cover Trees,"The k-means clustering algorithm is a popular algorithm that partitions data
into k clusters. There are many improvements to accelerate the standard
algorithm. Most current research employs upper and lower bounds on
point-to-cluster distances and the triangle inequality to reduce the number of
distance computations, with only arrays as underlying data structures. These
approaches cannot exploit that nearby points are likely assigned to the same
cluster. We propose a new k-means algorithm based on the cover tree index, that
has relatively low overhead and performs well, for a wider parameter range,
than previous approaches based on the k-d tree. By combining this with upper
and lower bounds, as in state-of-the-art approaches, we obtain a hybrid
algorithm that combines the benefits of tree aggregation and bounds-based
filtering.",2024-10-19,"Andreas Lang, Erich Schubert",http://arxiv.org/pdf/2410.15117v1,cs.LG
On Designing Effective RL Reward at Training Time for LLM Reasoning,"Reward models have been increasingly critical for improving the reasoning
capability of LLMs. Existing research has shown that a well-trained reward
model can substantially improve model performances at inference time via
search. However, the potential of reward models during RL training time still
remains largely under-explored. It is currently unclear whether these reward
models can provide additional training signals to enhance the reasoning
capabilities of LLMs in RL training that uses sparse success rewards, which
verify the correctness of solutions. In this work, we evaluate popular reward
models for RL training, including the Outcome-supervised Reward Model (ORM) and
the Process-supervised Reward Model (PRM), and train a collection of LLMs for
math problems using RL by combining these learned rewards with success rewards.
Surprisingly, even though these learned reward models have strong
inference-time performances, they may NOT help or even hurt RL training,
producing worse performances than LLMs trained with the success reward only.
Our analysis reveals that an LLM can receive high rewards from some of these
reward models by repeating correct but unnecessary reasoning steps, leading to
a severe reward hacking issue. Therefore, we introduce two novel reward
refinement techniques, including Clipping and Delta. The key idea is to ensure
the accumulative reward of any reasoning trajectory is upper-bounded to keep a
learned reward model effective without being exploited. We evaluate our
techniques with multiple reward models over a set of 1.5B and 7B LLMs on MATH
and GSM8K benchmarks and demonstrate that with a carefully designed reward
function, RL training without any additional supervised tuning can improve all
the evaluated LLMs, including the state-of-the-art 7B LLM
Qwen2.5-Math-7B-Instruct on MATH and GSM8K benchmarks.",2024-10-19,"Jiaxuan Gao, Shusheng Xu, Wenjie Ye, Weilin Liu, Chuyi He, Wei Fu, Zhiyu Mei, Guangju Wang, Yi Wu",http://arxiv.org/pdf/2410.15115v3,cs.LG
Stool Recognition for Colorectal Cancer Detection through Deep Learning,"Colorectal cancer is the most common cancer in Singapore and the third most
common cancer worldwide. Blood in a person's stool is a symptom of this
disease, and it is usually detected by the faecal occult blood test (FOBT).
However, the FOBT presents several limitations - the collection process for the
stool samples is tedious and unpleasant, the waiting period for results is
about 2 weeks and costs are involved. In this research, we propose a
simple-to-use, fast and cost-free alternative - a stool recognition neural
network that determines if there is blood in one's stool (which indicates a
possible risk of colorectal cancer) from an image of it. As this is a new
classification task, there was limited data available, hindering classifier
performance. Hence, various Generative Adversarial Networks (GANs) (DiffAugment
StyleGAN2, DCGAN, Conditional GAN) were trained to generate images of high
fidelity to supplement the dataset. Subsequently, images generated by the GAN
with the most realistic images (DiffAugment StyleGAN2) were concatenated to the
classifier's training batch on-the-fly, improving accuracy to 94%. This model
was then deployed to a mobile app - Poolice, where users can take a photo of
their stool and obtain instantaneous results if there is blood in their stool,
prompting those who do to seek medical advice. As ""early detection saves
lives"", we hope our app built on our stool recognition neural network can help
people detect colorectal cancer earlier, so they can seek treatment and have
higher chances of survival.",2024-10-19,"Glenda Hui En Tan, Goh Xin Ru Karin, Shen Bingquan",http://arxiv.org/pdf/2410.17288v1,cs.LG
The shape of the brain's connections is predictive of cognitive performance: an explainable machine learning study,"The shape of the brain's white matter connections is relatively unexplored in
diffusion MRI tractography analysis. While it is known that tract shape varies
in populations and across the human lifespan, it is unknown if the variability
in dMRI tractography-derived shape may relate to the brain's functional
variability across individuals. This work explores the potential of leveraging
tractography fiber cluster shape measures to predict subject-specific cognitive
performance. We implement machine learning models to predict individual
cognitive performance scores. We study a large-scale database from the HCP-YA
study. We apply an atlas-based fiber cluster parcellation to the dMRI
tractography of each individual. We compute 15 shape, microstructure, and
connectivity features for each fiber cluster. Using these features as input, we
train a total of 210 models to predict 7 different NIH Toolbox cognitive
performance assessments. We apply an explainable AI technique, SHAP, to assess
the importance of each fiber cluster for prediction. Our results demonstrate
that shape measures are predictive of individual cognitive performance. The
studied shape measures, such as irregularity, diameter, total surface area,
volume, and branch volume, are as effective for prediction as microstructure
and connectivity measures. The overall best-performing feature is a shape
feature, irregularity, which describes how different a cluster's shape is from
an idealized cylinder. Further interpretation using SHAP values suggest that
fiber clusters with features highly predictive of cognitive ability are
widespread throughout the brain, including fiber clusters from the superficial
association, deep association, cerebellar, striatal, and projection pathways.
This study demonstrates the strong potential of shape descriptors to enhance
the study of the brain's white matter and its relationship to cognitive
function.",2024-10-19,"Yui Lo, Yuqian Chen, Dongnan Liu, Wan Liu, Leo Zekelman, Jarrett Rushmore, Fan Zhang, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell",http://arxiv.org/pdf/2410.15108v2,cs.LG
GNNRL-Smoothing: A Prior-Free Reinforcement Learning Model for Mesh Smoothing,"Mesh smoothing methods can enhance mesh quality by eliminating distorted
elements, leading to improved convergence in simulations. To balance the
efficiency and robustness of traditional mesh smoothing process, previous
approaches have employed supervised learning and reinforcement learning to
train intelligent smoothing models. However, these methods heavily rely on
labeled dataset or prior knowledge to guide the models' learning. Furthermore,
their limited capacity to enhance mesh connectivity often restricts the
effectiveness of smoothing. In this paper, we first systematically analyze the
learning mechanisms of recent intelligent smoothing methods and propose a
prior-free reinforcement learning model for intelligent mesh smoothing. Our
proposed model integrates graph neural networks with reinforcement learning to
implement an intelligent node smoothing agent and introduces, for the first
time, a mesh connectivity improvement agent. We formalize mesh optimization as
a Markov Decision Process and successfully train both agents using Twin Delayed
Deep Deterministic Policy Gradient and Double Dueling Deep Q-Network in the
absence of any prior data or knowledge. We verified the proposed model on both
2D and 3D meshes. Experimental results demonstrate that our model achieves
feature-preserving smoothing on complex 3D surface meshes. It also achieves
state-of-the-art results among intelligent smoothing methods on 2D meshes and
is 7.16 times faster than traditional optimization-based smoothing methods.
Moreover, the connectivity improvement agent can effectively enhance the
quality distribution of the mesh.",2024-10-19,"Zhichao Wang, Xinhai Chen, Chunye Gong, Bo Yang, Liang Deng, Yufei Sun, Yufei Pang, Jie Liu",http://arxiv.org/pdf/2410.19834v1,cs.LG
CosFairNet:A Parameter-Space based Approach for Bias Free Learning,"Deep neural networks trained on biased data often inadvertently learn
unintended inference rules, particularly when labels are strongly correlated
with biased features. Existing bias mitigation methods typically involve either
a) predefining bias types and enforcing them as prior knowledge or b)
reweighting training samples to emphasize bias-conflicting samples over
bias-aligned samples. However, both strategies address bias indirectly in the
feature or sample space, with no control over learned weights, making it
difficult to control the bias propagation across different layers. Based on
this observation, we introduce a novel approach to address bias directly in the
model's parameter space, preventing its propagation across layers. Our method
involves training two models: a bias model for biased features and a debias
model for unbiased details, guided by the bias model. We enforce dissimilarity
in the debias model's later layers and similarity in its initial layers with
the bias model, ensuring it learns unbiased low-level features without adopting
biased high-level abstractions. By incorporating this explicit constraint
during training, our approach shows enhanced classification accuracy and
debiasing effectiveness across various synthetic and real-world datasets of
different sizes. Moreover, the proposed method demonstrates robustness across
different bias types and percentages of biased samples in the training data.
The code is available at: https://visdomlab.github.io/CosFairNet/",2024-10-19,"Rajeev Ranjan Dwivedi, Priyadarshini Kumari, Vinod K Kurmi",http://arxiv.org/pdf/2410.15094v1,cs.LG
DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning,"In the current era of artificial intelligence, federated learning has emerged
as a novel approach to addressing data privacy concerns inherent in centralized
learning paradigms. This decentralized learning model not only mitigates the
risk of data breaches but also enhances the system's scalability and
robustness. However, this approach introduces a new challenge: how to fairly
and accurately assess the contribution of each participant. Developing an
effective contribution evaluation mechanism is crucial for federated learning.
Such a mechanism incentivizes participants to actively contribute their data
and computational resources, thereby improving the overall performance of the
federated learning system. By allocating resources and rewards based on the
size of the contributions, it ensures that each participant receives fair
treatment, fostering sustained engagement.Currently, Shapley value-based
methods are widely used to evaluate participants' contributions, with many
researchers proposing modifications to adapt these methods to real-world
scenarios. In this paper, we introduce a component called Dynamic Pruning
Validation Set Shapley (DPVS-Shapley). This method accelerates the contribution
assessment process by dynamically pruning the original dataset without
compromising the evaluation's accuracy. Furthermore, this component can assign
different weights to various samples, thereby allowing clients capable of
distinguishing difficult examples to receive higher contribution scores.",2024-10-19,"Ketin Yin, Zonghao Guo, ZhengHan Qin",http://arxiv.org/pdf/2410.15093v1,cs.LG
Exploring Quantum Neural Networks for Demand Forecasting,"Forecasting demand for assets and services can be addressed in various
markets, providing a competitive advantage when the predictive models used
demonstrate high accuracy. However, the training of machine learning models
incurs high computational costs, which may limit the training of prediction
models based on available computational capacity. In this context, this paper
presents an approach for training demand prediction models using quantum neural
networks. For this purpose, a quantum neural network was used to forecast
demand for vehicle financing. A classical recurrent neural network was used to
compare the results, and they show a similar predictive capacity between the
classical and quantum models, with the advantage of using a lower number of
training parameters and also converging in fewer steps. Utilizing quantum
computing techniques offers a promising solution to overcome the limitations of
traditional machine learning approaches in training predictive models for
complex market dynamics.",2024-10-19,"Gleydson Fernandes de Jesus, Maria Heloísa Fraga da Silva, Otto Menegasso Pires, Lucas Cruz da Silva, Clebson dos Santos Cruz, Valéria Loureiro da Silva",http://arxiv.org/pdf/2410.16331v1,cs.LG
Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer,"Federated Learning(FL) is popular as a privacy-preserving machine learning
paradigm for generating a single model on decentralized data. However,
statistical heterogeneity poses a significant challenge for FL. As a subfield
of FL, personalized FL (pFL) has attracted attention for its ability to achieve
personalized models that perform well on non-independent and identically
distributed (Non-IID) data. However, existing pFL methods are limited in terms
of leveraging the global model's knowledge to enhance generalization while
achieving personalization on local data. To address this, we proposed a new
method personalized Federated learning with Adaptive Feature Aggregation and
Knowledge Transfer (FedAFK), to train better feature extractors while balancing
generalization and personalization for participating clients, which improves
the performance of personalized models on Non-IID data. We conduct extensive
experiments on three datasets in two widely-used heterogeneous settings and
show the superior performance of our proposed method over thirteen
state-of-the-art baselines.",2024-10-19,"Keting Yin, Jiayi Mao",http://arxiv.org/pdf/2410.15073v1,cs.LG
LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired LDR-to-HDR Image Reconstruction,"The translation of Low Dynamic Range (LDR) to High Dynamic Range (HDR) images
is an important computer vision task. There is a significant amount of research
utilizing both conventional non-learning methods and modern data-driven
approaches, focusing on using both single-exposed and multi-exposed LDR for HDR
image reconstruction. However, most current state-of-the-art methods require
high-quality paired {LDR,HDR} datasets for model training. In addition, there
is limited literature on using unpaired datasets for this task, that is, the
model learns a mapping between domains, i.e., {LDR,HDR}. This paper proposes
LLM-HDR, a method that integrates the perception of Large Language Models (LLM)
into a modified semantic- and cycle-consistent adversarial architecture that
utilizes unpaired {LDR,HDR} datasets for training. The method introduces novel
artifact- and exposure-aware generators to address visual artifact removal and
an encoder and loss to address semantic consistency, another under-explored
topic. LLM-HDR is the first to use an LLM for the {LDR,HDR} translation task in
a self-supervised setup. The method achieves state-of-the-art performance
across several benchmark datasets and reconstructs high-quality HDR images. The
official website of this work is available at:
https://github.com/HrishavBakulBarua/LLM-HDR",2024-10-19,"Hrishav Bakul Barua, Kalin Stefanov, Lemuel Lai En Che, Abhinav Dhall, KokSheik Wong, Ganesh Krishnasamy",http://arxiv.org/pdf/2410.15068v2,cs.LG
Deep Equilibrium Algorithmic Reasoning,"Neural Algorithmic Reasoning (NAR) research has demonstrated that graph
neural networks (GNNs) could learn to execute classical algorithms. However,
most previous approaches have always used a recurrent architecture, where each
iteration of the GNN matches an iteration of the algorithm. In this paper we
study neurally solving algorithms from a different perspective: since the
algorithm's solution is often an equilibrium, it is possible to find the
solution directly by solving an equilibrium equation. Our approach requires no
information on the ground-truth number of steps of the algorithm, both during
train and test time. Furthermore, the proposed method improves the performance
of GNNs on executing algorithms and is a step towards speeding up existing NAR
models. Our empirical evidence, leveraging algorithms from the CLRS-30
benchmark, validates that one can train a network to solve algorithmic problems
by directly finding the equilibrium. We discuss the practical implementation of
such models and propose regularisations to improve the performance of these
equilibrium reasoners.",2024-10-19,"Dobrik Georgiev, JJ Wilson, Davide Buffelli, Pietro Liò",http://arxiv.org/pdf/2410.15059v1,cs.LG
Asymptotic Time-Uniform Inference for Parameters in Averaged Stochastic Approximation,"We study time-uniform statistical inference for parameters in stochastic
approximation (SA), which encompasses a bunch of applications in optimization
and machine learning. To that end, we analyze the almost-sure convergence rates
of the averaged iterates to a scaled sum of Gaussians in both linear and
nonlinear SA problems. We then construct three types of asymptotic confidence
sequences that are valid uniformly across all times with coverage guarantees,
in an asymptotic sense that the starting time is sufficiently large. These
coverage guarantees remain valid if the unknown covariance matrix is replaced
by its plug-in estimator, and we conduct experiments to validate our
methodology.",2024-10-19,"Chuhan Xie, Kaicheng Jin, Jiadong Liang, Zhihua Zhang",http://arxiv.org/pdf/2410.15057v1,cs.LG
Weakly-supervised diagnosis identification from Italian discharge letters,"Objective: Recognizing diseases from discharge letters is crucial for cohort
selection and epidemiological analyses, as this is the only type of data
consistently produced across hospitals. This is a classic document
classification problem, typically requiring supervised learning. However,
manual annotation of large datasets of discharge letters is uncommon since it
is extremely time-consuming. We propose a novel weakly-supervised pipeline to
recognize diseases from Italian discharge letters. Methods: Our Natural
Language Processing pipeline is based on a fine-tuned version of the Italian
Umberto model. The pipeline extracts diagnosis-related sentences from a subset
of letters and applies a two-level clustering using the embeddings generated by
the fine-tuned Umberto model. These clusters are summarized and those mapped to
the diseases of interest are selected as weak labels. Finally, the same
BERT-based model is trained using these weak labels to detect the targeted
diseases. Results: A case study related to the identification of bronchiolitis
with 33'176 Italian discharge letters from 44 hospitals in the Veneto Region
shows the potential of our method, with an AUC of 77.7 % and an F1-Score of
75.1 % on manually annotated labels, improving compared to other non-supervised
methods and with a limited loss compared to fully supervised methods. Results
are robust to the cluster selection and the identified clusters highlight the
potential to recognize a variety of diseases. Conclusions: This study
demonstrates the feasibility of diagnosis identification from Italian discharge
letters in the absence of labelled data. Our pipeline showed strong performance
and robustness, and its flexibility allows for easy adaptation to various
diseases. This approach offers a scalable solution for clinical text
classification, reducing the need for manual annotation while maintaining good
accuracy.",2024-10-19,"Vittorio Torri, Elisa Barbieri, Anna Cantarutti, Carlo Giaquinto, Francesca Ieva",http://arxiv.org/pdf/2410.15051v1,cs.LG
Testing the Efficacy of Hyperparameter Optimization Algorithms in Short-Term Load Forecasting,"Accurate forecasting of electrical demand is essential for maintaining a
stable and reliable power grid, optimizing the allocation of energy resources,
and promoting efficient energy consumption practices. This study investigates
the effectiveness of five hyperparameter optimization (HPO) algorithms --
Random Search, Covariance Matrix Adaptation Evolution Strategy (CMA--ES),
Bayesian Optimization, Partial Swarm Optimization (PSO), and Nevergrad
Optimizer (NGOpt) across univariate and multivariate Short-Term Load
Forecasting (STLF) tasks. Using the Panama Electricity dataset (n=48,049), we
evaluate HPO algorithms' performances on a surrogate forecasting algorithm,
XGBoost, in terms of accuracy (i.e., MAPE, $R^2$) and runtime. Performance
plots visualize these metrics across varying sample sizes from 1,000 to 20,000,
and Kruskal--Wallis tests assess the statistical significance of the
performance differences. Results reveal significant runtime advantages for HPO
algorithms over Random Search. In univariate models, Bayesian optimization
exhibited the lowest accuracy among the tested methods. This study provides
valuable insights for optimizing XGBoost in the STLF context and identifies
areas for future research.",2024-10-19,"Tugrul Cabir Hakyemez, Omer Adar",http://arxiv.org/pdf/2410.15047v1,cs.LG
Adversarial Training: A Survey,"Adversarial training (AT) refers to integrating adversarial examples --
inputs altered with imperceptible perturbations that can significantly impact
model predictions -- into the training process. Recent studies have
demonstrated the effectiveness of AT in improving the robustness of deep neural
networks against diverse adversarial attacks. However, a comprehensive overview
of these developments is still missing. This survey addresses this gap by
reviewing a broad range of recent and representative studies. Specifically, we
first describe the implementation procedures and practical applications of AT,
followed by a comprehensive review of AT techniques from three perspectives:
data enhancement, network design, and training configurations. Lastly, we
discuss common challenges in AT and propose several promising directions for
future research.",2024-10-19,"Mengnan Zhao, Lihe Zhang, Jingwen Ye, Huchuan Lu, Baocai Yin, Xinchao Wang",http://arxiv.org/pdf/2410.15042v1,cs.LG
Semantic Information G Theory for Range Control with Tradeoff between Purposiveness and Efficiency,"Recent advances in deep learning suggest that we need to maximize and
minimize two different kinds of information simultaneously. The Information
Max-Min (IMM) method has been used in deep learning, reinforcement learning,
and maximum entropy control. Shannon's information rate-distortion function is
the theoretical basis of Minimizing Mutual Information (MMI) and data
compression, but it is not enough to solve the IMM problem. The author has
proposed the semantic information G theory (i.e., Shannon-Lu theory), including
the semantic information G measure and the information rate fidelity function
R(G) (R is the MMI for the given G of semantic mutual information). The
parameter solution of the R(G) function provides a general method to improve
the information efficiency, G/R. This paper briefly introduces the semantic
information G measure and the parametric solution of the R(G) function. Two
examples reveal that the parametric solution can help us optimize range control
with the tradeoff between purposiveness (i.e., semantic mutual information) and
information efficiency. It seems that the R(G) function can serve as the
theoretical basis of IMM methods, but we still need further research in
combination with deep learning, reinforcement learning, and constraint control.",2024-10-19,Chenguang Lu,http://arxiv.org/pdf/2411.05789v1,cs.LG
Statistical Inference for Feature Selection after Optimal Transport-based Domain Adaptation,"Feature Selection (FS) under domain adaptation (DA) is a critical task in
machine learning, especially when dealing with limited target data. However,
existing methods lack the capability to guarantee the reliability of FS under
DA. In this paper, we introduce a novel statistical method to statistically
test FS reliability under DA, named SFS-DA (statistical FS-DA). The key
strength of SFS-DA lies in its ability to control the false positive rate (FPR)
below a pre-specified level $\alpha$ (e.g., 0.05) while maximizing the true
positive rate. Compared to the literature on statistical FS, SFS-DA presents a
unique challenge in addressing the effect of DA to ensure the validity of the
inference on FS results. We overcome this challenge by leveraging the Selective
Inference (SI) framework. Specifically, by carefully examining the FS process
under DA whose operations can be characterized by linear and quadratic
inequalities, we prove that achieving FPR control in SFS-DA is indeed possible.
Furthermore, we enhance the true detection rate by introducing a more strategic
approach. Experiments conducted on both synthetic and real-world datasets
robustly support our theoretical results, showcasing the superior performance
of the proposed SFS-DA method.",2024-10-19,"Nguyen Thang Loi, Duong Tan Loc, Vo Nguyen Le Duy",http://arxiv.org/pdf/2410.15022v1,cs.LG
Iterative Methods via Locally Evolving Set Process,"Given the damping factor $\alpha$ and precision tolerance $\epsilon$,
\citet{andersen2006local} introduced Approximate Personalized PageRank (APPR),
the \textit{de facto local method} for approximating the PPR vector, with
runtime bounded by $\Theta(1/(\alpha\epsilon))$ independent of the graph size.
Recently, \citet{fountoulakis2022open} asked whether faster local algorithms
could be developed using $\tilde{O}(1/(\sqrt{\alpha}\epsilon))$ operations. By
noticing that APPR is a local variant of Gauss-Seidel, this paper explores the
question of \textit{whether standard iterative solvers can be effectively
localized}. We propose to use the \textit{locally evolving set process}, a
novel framework to characterize the algorithm locality, and demonstrate that
many standard solvers can be effectively localized. Let
$\overline{\operatorname{vol}}{ (S_t)}$ and $\overline{\gamma}_{t}$ be the
running average of volume and the residual ratio of active nodes $\textstyle
S_{t}$ during the process. We show $\overline{\operatorname{vol}}{
(S_t)}/\overline{\gamma}_{t} \leq 1/\epsilon$ and prove APPR admits a new
runtime bound
$\tilde{O}(\overline{\operatorname{vol}}(S_t)/(\alpha\overline{\gamma}_{t}))$
mirroring the actual performance. Furthermore, when the geometric mean of
residual reduction is $\Theta(\sqrt{\alpha})$, then there exists $c \in (0,2)$
such that the local Chebyshev method has runtime
$\tilde{O}(\overline{\operatorname{vol}}(S_{t})/(\sqrt{\alpha}(2-c)))$ without
the monotonicity assumption. Numerical results confirm the efficiency of this
novel framework and show up to a hundredfold speedup over corresponding
standard solvers on real-world graphs.",2024-10-19,"Baojian Zhou, Yifan Sun, Reza Babanezhad Harikandeh, Xingzhi Guo, Deqing Yang, Yanghua Xiao",http://arxiv.org/pdf/2410.15020v1,cs.LG
Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model,"Users of the transit system flood social networks daily with messages that
contain valuable insights crucial for improving service quality. These posts
help transit agencies quickly identify emerging issues. Parsing topics and
sentiments is key to gaining comprehensive insights to foster service
excellence. However, the volume of messages makes manual analysis impractical,
and standard NLP techniques like Term Frequency-Inverse Document Frequency
(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis
separates topics and sentiments before integrating them, often missing the
interaction between them. This incremental approach complicates classification
and reduces analytical productivity. To address these challenges, we propose a
novel approach to extracting and analyzing transit-related information,
including sentiment and sarcasm detection, identification of unusual system
problems, and location data from social media. Our method employs Large
Language Models (LLM), specifically Llama 3, for a streamlined analysis free
from pre-established topic labels. To enhance the model's domain-specific
knowledge, we utilize Retrieval-Augmented Generation (RAG), integrating
external knowledge sources into the information extraction pipeline. We
validated our method through extensive experiments comparing its performance
with traditional NLP approaches on user tweet data from the real world transit
system. Our results demonstrate the potential of LLMs to transform social media
data analysis in the public transit domain, providing actionable insights and
enhancing transit agencies' responsiveness by extracting a broader range of
information.",2024-10-19,"Jiahao Wang, Amer Shalaby",http://arxiv.org/pdf/2410.15016v1,cs.LG
DST-TransitNet: A Dynamic Spatio-Temporal Deep Learning Model for Scalable and Efficient Network-Wide Prediction of Station-Level Transit Ridership,"Accurate prediction of public transit ridership is vital for efficient
planning and management of transit in rapidly growing urban areas in Canada.
Unexpected increases in passengers can cause overcrowded vehicles, longer
boarding times, and service disruptions. Traditional time series models like
ARIMA and SARIMA face limitations, particularly in short-term predictions and
integration of spatial and temporal features. These models struggle with the
dynamic nature of ridership patterns and often ignore spatial correlations
between nearby stops. Deep Learning (DL) models present a promising
alternative, demonstrating superior performance in short-term prediction tasks
by effectively capturing both spatial and temporal features. However,
challenges such as dynamic spatial feature extraction, balancing accuracy with
computational efficiency, and ensuring scalability remain.
  This paper introduces DST-TransitNet, a hybrid DL model for system-wide
station-level ridership prediction. This proposed model uses graph neural
networks (GNN) and recurrent neural networks (RNN) to dynamically integrate the
changing temporal and spatial correlations within the stations. The model also
employs a precise time series decomposition framework to enhance accuracy and
interpretability. Tested on Bogota's BRT system data, with three distinct
social scenarios, DST-TransitNet outperformed state-of-the-art models in
precision, efficiency and robustness. Meanwhile, it maintains stability over
long prediction intervals, demonstrating practical applicability.",2024-10-19,"Jiahao Wang, Amer Shalaby",http://arxiv.org/pdf/2410.15013v1,cs.LG
FlexMol: A Flexible Toolkit for Benchmarking Molecular Relational Learning,"Molecular relational learning (MRL) is crucial for understanding the
interaction behaviors between molecular pairs, a critical aspect of drug
discovery and development. However, the large feasible model space of MRL poses
significant challenges to benchmarking, and existing MRL frameworks face
limitations in flexibility and scope. To address these challenges, avoid
repetitive coding efforts, and ensure fair comparison of models, we introduce
FlexMol, a comprehensive toolkit designed to facilitate the construction and
evaluation of diverse model architectures across various datasets and
performance metrics. FlexMol offers a robust suite of preset model components,
including 16 drug encoders, 13 protein sequence encoders, 9 protein structure
encoders, and 7 interaction layers. With its easy-to-use API and flexibility,
FlexMol supports the dynamic construction of over 70, 000 distinct combinations
of model architectures. Additionally, we provide detailed benchmark results and
code examples to demonstrate FlexMol's effectiveness in simplifying and
standardizing MRL model development and comparison.",2024-10-19,"Sizhe Liu, Jun Xia, Lecheng Zhang, Yuchen Liu, Yue Liu, Wenjie Du, Zhangyang Gao, Bozhen Hu, Cheng Tan, Hongxin Xiang, Stan Z. Li",http://arxiv.org/pdf/2410.15010v1,cs.LG
Time-Varying Convex Optimization with $O(n)$ Computational Complexity,"In this article, we consider the problem of unconstrained time-varying convex
optimization, where the cost function changes with time. We provide an in-depth
technical analysis of the problem and argue why freezing the cost at each time
step and taking finite steps toward the minimizer is not the best tracking
solution for this problem. We propose a set of algorithms that by taking into
account the temporal variation of the cost aim to reduce the tracking error of
the time-varying minimizer of the problem. The main contribution of our work is
that our proposed algorithms only require the first-order derivatives of the
cost function with respect to the decision variable. This approach
significantly reduces computational cost compared to the existing algorithms,
which use the inverse of the Hessian of the cost. Specifically, the proposed
algorithms reduce the computational cost from $O(n^3)$ to $O(n)$ per timestep,
where $n$ is the size of the decision variable. Avoiding the inverse of the
Hessian also makes our algorithms applicable to non-convex optimization
problems. We refer to these algorithms as $O(n)$-algorithms. These
$O(n)$-algorithms are designed to solve the problem for different scenarios
based on the available temporal information about the cost. We illustrate our
results through various examples, including the solution of a model predictive
control problem framed as a convex optimization problem with a streaming
time-varying cost function.",2024-10-19,"M. Rostami, S. S. Kia",http://arxiv.org/pdf/2410.15009v2,cs.LG
Achieving $\tilde{\mathcal{O}}(1/N)$ Optimality Gap in Restless Bandits through Gaussian Approximation,"We study the finite-horizon Restless Multi-Armed Bandit (RMAB) problem with
$N$ homogeneous arms. Prior work has shown that when an RMAB satisfies a
non-degeneracy condition, Linear-Programming-based (LP-based) policies derived
from the fluid approximation, which captures the mean dynamics of the system,
achieve an exponentially small optimality gap. However, it is common for RMABs
to be degenerate, in which case LP-based policies can result in a
$\Theta(1/\sqrt{N})$ optimality gap per arm. In this paper, we propose a novel
Stochastic-Programming-based (SP-based) policy that, under a uniqueness
assumption, achieves an $\tilde{\mathcal{O}}(1/N)$ optimality gap for
degenerate RMABs. Our approach is based on the construction of a Gaussian
stochastic system that captures not only the mean but also the variance of the
RMAB dynamics, resulting in a more accurate approximation than the fluid
approximation. We then solve a stochastic program for this system to obtain our
policy. This is the first result to establish an $\tilde{\mathcal{O}}(1/N)$
optimality gap for degenerate RMABs.",2024-10-19,"Chen Yan, Weina Wang, Lei Ying",http://arxiv.org/pdf/2410.15003v2,cs.LG
FIT-GNN: Faster Inference Time for GNNs Using Coarsening,"Scalability of Graph Neural Networks (GNNs) remains a significant challenge,
particularly when dealing with large-scale graphs. To tackle this,
coarsening-based methods are used to reduce the graph into a smaller graph,
resulting in faster computation. Nonetheless, prior research has not adequately
addressed the computational costs during the inference phase. This paper
presents a novel approach to improve the scalability of GNNs by reducing
computational burden during both training and inference phases. We demonstrate
two different methods (Extra-Nodes and Cluster-Nodes). Our study also proposes
a unique application of the coarsening algorithm for graph-level tasks,
including graph classification and graph regression, which have not yet been
explored. We conduct extensive experiments on multiple benchmark datasets in
the order of $100K$ nodes to evaluate the performance of our approach. The
results demonstrate that our method achieves competitive performance in tasks
involving classification and regression on nodes and graphs, compared to
traditional GNNs, while having single-node inference times that are orders of
magnitude faster. Furthermore, our approach significantly reduces memory
consumption, allowing training and inference on low-resource devices where
traditional methods struggle.",2024-10-19,"Shubhajit Roy, Hrriday Ruparel, Kishan Ved, Anirban Dasgupta",http://arxiv.org/pdf/2410.15001v2,cs.LG
A comparative study of NeuralODE and Universal ODE approaches to solving Chandrasekhar White Dwarf equation,"In this study, we apply two pillars of Scientific Machine Learning: Neural
Ordinary Differential Equations (Neural ODEs) and Universal Differential
Equations (UDEs) to the Chandrasekhar White Dwarf Equation (CWDE). The CWDE is
fundamental for understanding the life cycle of a star, and describes the
relationship between the density of the white dwarf and its distance from the
center. Despite the rise in Scientific Machine Learning frameworks, very less
attention has been paid to the systematic applications of the above SciML
pillars on astronomy based ODEs. Through robust modeling in the Julia
programming language, we show that both Neural ODEs and UDEs can be used
effectively for both prediction as well as forecasting of the CWDE. More
importantly, we introduce the forecasting breakdown point - the time at which
forecasting fails for both Neural ODEs and UDEs. Through a robust
hyperparameter optimization testing, we provide insights on the neural network
architecture, activation functions and optimizers which provide the best
results. This study provides opens a door to investigate the applicability of
Scientific Machine Learning frameworks in forecasting tasks for a wide range of
scientific domains.",2024-10-19,"Raymundo Vazquez Martinez, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat",http://arxiv.org/pdf/2410.14998v1,cs.LG
Learning Infinite-Horizon Average-Reward Linear Mixture MDPs of Bounded Span,"This paper proposes a computationally tractable algorithm for learning
infinite-horizon average-reward linear mixture Markov decision processes (MDPs)
under the Bellman optimality condition. Our algorithm for linear mixture MDPs
achieves a nearly minimax optimal regret upper bound of
$\widetilde{\mathcal{O}}(d\sqrt{\mathrm{sp}(v^*)T})$ over $T$ time steps where
$\mathrm{sp}(v^*)$ is the span of the optimal bias function $v^*$ and $d$ is
the dimension of the feature mapping. Our algorithm applies the recently
developed technique of running value iteration on a discounted-reward MDP
approximation with clipping by the span. We prove that the value iteration
procedure, even with the clipping operation, converges. Moreover, we show that
the associated variance term due to random transitions can be bounded even
under clipping. Combined with the weighted ridge regression-based parameter
estimation scheme, this leads to the nearly minimax optimal regret guarantee.",2024-10-19,"Woojin Chae, Kihyuk Hong, Yufan Zhang, Ambuj Tewari, Dabeen Lee",http://arxiv.org/pdf/2410.14992v1,cs.LG
Audio Processing using Pattern Recognition for Music Genre Classification,"This project explores the application of machine learning techniques for
music genre classification using the GTZAN dataset, which contains 100 audio
files per genre. Motivated by the growing demand for personalized music
recommendations, we focused on classifying five genres-Blues, Classical, Jazz,
Hip Hop, and Country-using a variety of algorithms including Logistic
Regression, K-Nearest Neighbors (KNN), Random Forest, and Artificial Neural
Networks (ANN) implemented via Keras. The ANN model demonstrated the best
performance, achieving a validation accuracy of 92.44%. We also analyzed key
audio features such as spectral roll-off, spectral centroid, and MFCCs, which
helped enhance the model's accuracy. Future work will expand the model to cover
all ten genres, investigate advanced methods like Long Short-Term Memory (LSTM)
networks and ensemble approaches, and develop a web application for real-time
genre classification and playlist generation. This research aims to contribute
to improving music recommendation systems and content curation.",2024-10-19,"Sivangi Chatterjee, Srishti Ganguly, Avik Bose, Hrithik Raj Prasad, Arijit Ghosal",http://arxiv.org/pdf/2410.14990v1,cs.LG
Wave (from) Polarized Light Learning (WPLL) method: high resolution spatio-temporal measurements of water surface waves in laboratory setups,"Effective spatio-temporal measurements of water surface elevation (water
waves) in laboratory experiments are crucial for scientific and engineering
research. Existing techniques are often cumbersome, computationally heavy and
generally suffer from limitations in wavenumber/frequency response. To address
these challenges, we propose Wave (from) Polarized Light Learning (WPLL), a
learning based remote sensing method for laboratory implementation, capable of
inferring surface elevation and slope maps in high resolution. The method uses
the polarization properties of light reflected from the water surface. The WPLL
uses a deep neural network (DNN) model that approximates the water surface
slopes from the polarized light intensities. Once trained on simple
monochromatic wave trains, the WPLL is capable of producing high-resolution and
accurate 2D reconstruction of the water surface slopes and elevation in a
variety of irregular wave fields. The method's robustness is demonstrated by
showcasing its high wavenumber/frequency response, its ability to reconstruct
wave fields propagating at arbitrary angles relative to the camera optical
axis, and its computational efficiency. This developed methodology is an
accurate and cost-effective near-real time remote sensing tool for laboratory
water surface waves measurements, setting the path for upscaling to open sea
application for research, monitoring, and short-time forecasting.",2024-10-19,"Noam Ginio, Michael Lindenbaum, Barak Fishbain, Dan Liberzon",http://arxiv.org/pdf/2410.14988v1,cs.LG
NeuralMAG: Fast and Generalizable Micromagnetic Simulation with Deep Neural Nets,"Micromagnetics has made significant strides, particularly due to its
wide-ranging applications in magnetic storage design. Numerical simulation is a
cornerstone of micromagnetics research, relying on first-principle rules to
compute the dynamic evolution of micromagnetic systems based on the renowned
LLG equation, named after Landau, Lifshitz, and Gilbert. However, simulations
are often hindered by their slow speed. Although Fast-Fourier transformation
(FFT) calculations reduce the computational complexity to O(NlogN), it remains
impractical for large-scale simulations. In this paper, we introduce NeuralMAG,
a deep learning approach to micromagnetic simulation. Our approach follows the
LLG iterative framework but accelerates demagnetizing field computation through
the employment of a U-shaped neural network (Unet). The Unet architecture
comprises an encoder that extracts aggregated spins at various scales and
learns the local interaction at each scale, followed by a decoder that
accumulates the local interactions at different scales to approximate the
global convolution. This divide-and-accumulate scheme achieves a time
complexity of O(N), significantly enhancing the speed and feasibility of
large-scale simulations. Unlike existing neural methods, NeuralMAG concentrates
on the core computation rather than an end-to-end approximation for a specific
task, making it inherently generalizable. To validate the new approach, we
trained a single model and evaluated it on two micromagnetics tasks with
various sample sizes, shapes, and material settings.",2024-10-19,"Yunqi Cai, Jiangnan Li, Dong Wang",http://arxiv.org/pdf/2410.14986v1,cs.LG
Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration From Cognitive Psychology,"The cognitive mechanism by which Large Language Models (LLMs) solve
mathematical problems remains a widely debated and unresolved issue. Currently,
there is little interpretable experimental evidence that connects LLMs'
problem-solving with human cognitive psychology.To determine if LLMs possess
human-like mathematical reasoning, we modified the problems used in the human
Cognitive Reflection Test (CRT). Our results show that, even with the use of
Chains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model
(noted for its reasoning capabilities), have a high error rate when solving
these modified CRT problems. Specifically, the average accuracy rate dropped by
up to 50% compared to the original questions.Further analysis of LLMs'
incorrect answers suggests that they primarily rely on pattern matching from
their training data, which aligns more with human intuition (System 1 thinking)
rather than with human-like reasoning (System 2 thinking). This finding
challenges the belief that LLMs have genuine mathematical reasoning abilities
comparable to humans. As a result, this work may adjust overly optimistic views
on LLMs' progress towards artificial general intelligence.",2024-10-19,"Wei Xie, Shuoyoucheng Ma, Zhenhua Wang, Enze Wang, Kai Chen, Xiaobing Sun, Baosheng Wang",http://arxiv.org/pdf/2410.14979v5,cs.LG
MENTOR: Mixture-of-Experts Network with Task-Oriented Perturbation for Visual Reinforcement Learning,"Visual deep reinforcement learning (RL) enables robots to acquire skills from
visual input for unstructured tasks. However, current algorithms suffer from
low sample efficiency, limiting their practical applicability. In this work, we
present MENTOR, a method that improves both the architecture and optimization
of RL agents. Specifically, MENTOR replaces the standard multi-layer perceptron
(MLP) with a mixture-of-experts (MoE) backbone and introduces a task-oriented
perturbation mechanism. MENTOR outperforms state-of-the-art methods across
three simulation benchmarks and achieves an average of 83% success rate on
three challenging real-world robotic manipulation tasks, significantly
surpassing the 32% success rate of the strongest existing model-free visual RL
algorithm. These results underscore the importance of sample efficiency in
advancing visual RL for real-world robotics. Experimental videos are available
at https://suninghuang19.github.io/mentor_page/.",2024-10-19,"Suning Huang, Zheyu Zhang, Tianhai Liang, Yihan Xu, Zhehao Kou, Chenhao Lu, Guowei Xu, Zhengrong Xue, Huazhe Xu",http://arxiv.org/pdf/2410.14972v2,cs.LG
Taming the Long Tail in Human Mobility Prediction,"With the popularity of location-based services, human mobility prediction
plays a key role in enhancing personalized navigation, optimizing
recommendation systems, and facilitating urban mobility and planning. This
involves predicting a user's next POI (point-of-interest) visit using their
past visit history. However, the uneven distribution of visitations over time
and space, namely the long-tail problem in spatial distribution, makes it
difficult for AI models to predict those POIs that are less visited by humans.
In light of this issue, we propose the Long-Tail Adjusted Next POI Prediction
(LoTNext) framework for mobility prediction, combining a Long-Tailed Graph
Adjustment module to reduce the impact of the long-tailed nodes in the user-POI
interaction graph and a novel Long-Tailed Loss Adjustment module to adjust loss
by logit score and sample weight adjustment strategy. Also, we employ the
auxiliary prediction task to enhance generalization and accuracy. Our
experiments with two real-world trajectory datasets demonstrate that LoTNext
significantly surpasses existing state-of-the-art works.",2024-10-19,"Xiaohang Xu, Renhe Jiang, Chuang Yang, Zipei Fan, Kaoru Sezaki",http://arxiv.org/pdf/2410.14970v4,cs.LG
Visual Navigation of Digital Libraries: Retrieval and Classification of Images in the National Library of Norway's Digitised Book Collection,"Digital tools for text analysis have long been essential for the
searchability and accessibility of digitised library collections. Recent
computer vision advances have introduced similar capabilities for visual
materials, with deep learning-based embeddings showing promise for analysing
visual heritage. Given that many books feature visuals in addition to text,
taking advantage of these breakthroughs is critical to making library
collections open and accessible. In this work, we present a proof-of-concept
image search application for exploring images in the National Library of
Norway's pre-1900 books, comparing Vision Transformer (ViT), Contrastive
Language-Image Pre-training (CLIP), and Sigmoid loss for Language-Image
Pre-training (SigLIP) embeddings for image retrieval and classification. Our
results show that the application performs well for exact image retrieval, with
SigLIP embeddings slightly outperforming CLIP and ViT in both retrieval and
classification tasks. Additionally, SigLIP-based image classification can aid
in cleaning image datasets from a digitisation pipeline.",2024-10-19,"Marie Roald, Magnus Breder Birkenes, Lars Gunnarsønn Bagøien Johnsen",http://arxiv.org/pdf/2410.14969v1,cs.LG
AugInsert: Learning Robust Visual-Force Policies via Data Augmentation for Object Assembly Tasks,"This paper primarily focuses on learning robust visual-force policies in the
context of high-precision object assembly tasks. Specifically, we focus on the
contact phase of the assembly task where both objects (peg and hole) have made
contact and the objective lies in maneuvering the objects to complete the
assembly. Moreover, we aim to learn contact-rich manipulation policies with
multisensory inputs on limited expert data by expanding human demonstrations
via online data augmentation. We develop a simulation environment with a
dual-arm robot manipulator to evaluate the effect of augmented expert
demonstration data. Our focus is on evaluating the robustness of our model with
respect to certain task variations: grasp pose, peg/hole shape, object body
shape, scene appearance, camera pose, and force-torque/proprioception noise. We
show that our proposed data augmentation method helps in learning a
multisensory manipulation policy that is robust to unseen instances of these
variations, particularly physical variations such as grasp pose. Additionally,
our ablative studies show the significant contribution of force-torque data to
the robustness of our model. For additional experiments and qualitative
results, we refer to the project webpage at https://bit.ly/47skWXH .",2024-10-19,"Ryan Diaz, Adam Imdieke, Vivek Veeriah, Karthik Desingh",http://arxiv.org/pdf/2410.14968v1,cs.LG
Deep Learning for Weather Forecasting: A CNN-LSTM Hybrid Model for Predicting Historical Temperature Data,"As global climate change intensifies, accurate weather forecasting has become
increasingly important, affecting agriculture, energy management, environmental
protection, and daily life. This study introduces a hybrid model combining
Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks
to predict historical temperature data. CNNs are utilized for spatial feature
extraction, while LSTMs handle temporal dependencies, resulting in
significantly improved prediction accuracy and stability. By using Mean
Absolute Error (MAE) as the loss function, the model demonstrates excellent
performance in processing complex meteorological data, addressing challenges
such as missing data and high-dimensionality. The results show a strong
alignment between the prediction curve and test data, validating the model's
potential in climate prediction. This study offers valuable insights for fields
such as agriculture, energy management, and urban planning, and lays the
groundwork for future applications in weather forecasting under the context of
global climate change.",2024-10-19,"Yuhao Gong, Yuchen Zhang, Fei Wang, Chi-Han Lee",http://arxiv.org/pdf/2410.14963v1,cs.LG
LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model,"Graph foundation models (GFMs) have recently gained significant attention.
However, the unique data processing and evaluation setups employed by different
studies hinder a deeper understanding of their progress. Additionally, current
research tends to focus on specific subsets of graph learning tasks, such as
structural tasks, node-level tasks, or classification tasks. As a result, they
often incorporate specialized modules tailored to particular task types, losing
their applicability to other graph learning tasks and contradicting the
original intent of foundation models to be universal. Therefore, to enhance
consistency, coverage, and diversity across domains, tasks, and research
interests within the graph learning community in the evaluation of GFMs, we
propose GFMBench-a systematic and comprehensive benchmark comprising 26
datasets. Moreover, we introduce LangGFM, a novel GFM that relies entirely on
large language models. By revisiting and exploring the effective graph
textualization principles, as well as repurposing successful techniques from
graph augmentation and graph self-supervised learning within the language
space, LangGFM achieves performance on par with or exceeding the state of the
art across GFMBench, which can offer us new perspectives, experiences, and
baselines to drive forward the evolution of GFMs.",2024-10-19,"Tianqianjin Lin, Pengwei Yan, Kaisong Song, Zhuoren Jiang, Yangyang Kang, Jun Lin, Weikang Yuan, Junjie Cao, Changlong Sun, Xiaozhong Liu",http://arxiv.org/pdf/2410.14961v1,cs.LG
Neural Radiance Field Image Refinement through End-to-End Sampling Point Optimization,"Neural Radiance Field (NeRF), capable of synthesizing high-quality novel
viewpoint images, suffers from issues like artifact occurrence due to its fixed
sampling points during rendering. This study proposes a method that optimizes
sampling points to reduce artifacts and produce more detailed images.",2024-10-19,"Kazuhiro Ohta, Satoshi Ono",http://arxiv.org/pdf/2410.14958v1,cs.LG
Offline-to-online Reinforcement Learning for Image-based Grasping with Scarce Demonstrations,"Offline-to-online reinforcement learning (O2O RL) aims to obtain a
continually improving policy as it interacts with the environment, while
ensuring the initial policy behaviour is satisficing. This satisficing
behaviour is necessary for robotic manipulation where random exploration can be
costly due to catastrophic failures and time. O2O RL is especially compelling
when we can only obtain a scarce amount of (potentially suboptimal)
demonstrations$\unicode{x2014}$a scenario where behavioural cloning (BC) is
known to suffer from distribution shift. Previous works have outlined the
challenges in applying O2O RL algorithms under the image-based environments. In
this work, we propose a novel O2O RL algorithm that can learn in a real-life
image-based robotic vacuum grasping task with a small number of demonstrations
where BC fails majority of the time. The proposed algorithm replaces the target
network in off-policy actor-critic algorithms with a regularization technique
inspired by neural tangent kernel. We demonstrate that the proposed algorithm
can reach above 90\% success rate in under two hours of interaction time, with
only 50 human demonstrations, while BC and existing commonly-used RL algorithms
fail to achieve similar performance.",2024-10-19,"Bryan Chan, Anson Leung, James Bergstra",http://arxiv.org/pdf/2410.14957v2,cs.LG
Accelerate Coastal Ocean Circulation Model with AI Surrogate,"Nearly 900 million people live in low-lying coastal zones around the world
and bear the brunt of impacts from more frequent and severe hurricanes and
storm surges. Oceanographers simulate ocean current circulation along the
coasts to develop early warning systems that save lives and prevent loss and
damage to property from coastal hazards. Traditionally, such simulations are
conducted using coastal ocean circulation models such as the Regional Ocean
Modeling System (ROMS), which usually runs on an HPC cluster with multiple CPU
cores. However, the process is time-consuming and energy expensive. While
coarse-grained ROMS simulations offer faster alternatives, they sacrifice
detail and accuracy, particularly in complex coastal environments. Recent
advances in deep learning and GPU architecture have enabled the development of
faster AI (neural network) surrogates. This paper introduces an AI surrogate
based on a 4D Swin Transformer to simulate coastal tidal wave propagation in an
estuary for both hindcast and forecast (up to 12 days). Our approach not only
accelerates simulations but also incorporates a physics-based constraint to
detect and correct inaccurate results, ensuring reliability while minimizing
manual intervention. We develop a fully GPU-accelerated workflow, optimizing
the model training and inference pipeline on NVIDIA DGX-2 A100 GPUs. Our
experiments demonstrate that our AI surrogate reduces the time cost of 12-day
forecasting of traditional ROMS simulations from 9,908 seconds (on 512 CPU
cores) to 22 seconds (on one A100 GPU), achieving over 450$\times$ speedup
while maintaining high-quality simulation results. This work contributes to
oceanographic modeling by offering a fast, accurate, and physically consistent
alternative to traditional simulation models, particularly for real-time
forecasting in rapid disaster response.",2024-10-19,"Zelin Xu, Jie Ren, Yupu Zhang, Jose Maria Gonzalez Ondina, Maitane Olabarrieta, Tingsong Xiao, Wenchong He, Zibo Liu, Shigang Chen, Kaleb Smith, Zhe Jiang",http://arxiv.org/pdf/2410.14952v2,cs.LG
On the Wasserstein Convergence and Straightness of Rectified Flow,"Diffusion models have emerged as a powerful tool for image generation and
denoising. Typically, generative models learn a trajectory between the starting
noise distribution and the target data distribution. Recently Liu et al.
(2023b) proposed Rectified Flow (RF), a generative model that aims to learn
straight flow trajectories from noise to data using a sequence of convex
optimization problems with close ties to optimal transport. If the trajectory
is curved, one must use many Euler discretization steps or novel strategies,
such as exponential integrators, to achieve a satisfactory generation quality.
In contrast, RF has been shown to theoretically straighten the trajectory
through successive rectifications, reducing the number of function evaluations
(NFEs) while sampling. It has also been shown empirically that RF may improve
the straightness in two rectifications if one can solve the underlying
optimization problem within a sufficiently small error. In this paper, we make
two contributions. First, we provide a theoretical analysis of the Wasserstein
distance between the sampling distribution of RF and the target distribution.
Our error rate is characterized by the number of discretization steps and a
novel formulation of straightness stronger than that in the original work.
Secondly, we present general conditions guaranteeing uniqueness and
straightness of 1-RF, which is in line with previous empirical findings. As a
byproduct of our analysis, we show that, in one dimension, RF started at the
standard Gaussian distribution yields the Monge map. Additionally, we also
present empirical results on both simulated and real datasets to validate our
theoretical findings. The code is available at
https://github.com/bansal-vansh/rectified-flow.",2024-10-19,"Vansh Bansal, Saptarshi Roy, Purnamrita Sarkar, Alessandro Rinaldo",http://arxiv.org/pdf/2410.14949v6,cs.LG
DEL-Ranking: Ranking-Correction Denoising Framework for Elucidating Molecular Affinities in DNA-Encoded Libraries,"DNA-encoded library (DEL) screening has revolutionized the detection of
protein-ligand interactions through read counts, enabling rapid exploration of
vast chemical spaces. However, noise in read counts, stemming from nonspecific
interactions, can mislead this exploration process. We present DEL-Ranking, a
novel distribution-correction denoising framework that addresses these
challenges. Our approach introduces two key innovations: (1) a novel ranking
loss that rectifies relative magnitude relationships between read counts,
enabling the learning of causal features determining activity levels, and (2)
an iterative algorithm employing self-training and consistency loss to
establish model coherence between activity label and read count predictions.
Furthermore, we contribute three new DEL screening datasets, the first to
comprehensively include multi-dimensional molecular representations,
protein-ligand enrichment values, and their activity labels. These datasets
mitigate data scarcity issues in AI-driven DEL screening research. Rigorous
evaluation on diverse DEL datasets demonstrates DEL-Ranking's superior
performance across multiple correlation metrics, with significant improvements
in binding affinity prediction accuracy. Our model exhibits zero-shot
generalization ability across different protein targets and successfully
identifies potential motifs determining compound binding affinity. This work
advances DEL screening analysis and provides valuable resources for future
research in this area.",2024-10-19,"Hanqun Cao, Mutian He, Ning Ma, Chang-yu Hsieh, Chunbin Gu, Pheng-Ann Heng",http://arxiv.org/pdf/2410.14946v2,cs.LG
ImmerseDiffusion: A Generative Spatial Audio Latent Diffusion Model,"We introduce ImmerseDiffusion, an end-to-end generative audio model that
produces 3D immersive soundscapes conditioned on the spatial, temporal, and
environmental conditions of sound objects. ImmerseDiffusion is trained to
generate first-order ambisonics (FOA) audio, which is a conventional spatial
audio format comprising four channels that can be rendered to multichannel
spatial output. The proposed generative system is composed of a spatial audio
codec that maps FOA audio to latent components, a latent diffusion model
trained based on various user input types, namely, text prompts, spatial,
temporal and environmental acoustic parameters, and optionally a spatial audio
and text encoder trained in a Contrastive Language and Audio Pretraining (CLAP)
style. We propose metrics to evaluate the quality and spatial adherence of the
generated spatial audio. Finally, we assess the model performance in terms of
generation quality and spatial conformance, comparing the two proposed modes:
``descriptive"", which uses spatial text prompts) and ``parametric"", which uses
non-spatial text prompts and spatial parameters. Our evaluations demonstrate
promising results that are consistent with the user conditions and reflect
reliable spatial fidelity.",2024-10-19,"Mojtaba Heydari, Mehrez Souden, Bruno Conejo, Joshua Atkins",http://arxiv.org/pdf/2410.14945v2,cs.LG
2D Basement Relief Inversion using Sparse Regularization,"Basement relief gravimetry is crucial in geophysics, especially for oil
exploration and mineral prospecting. It involves solving an inverse problem to
infer geological model parameters from observed data. The model represents
basement relief with constant-density prisms, and the data reflect
gravitational anomalies from these prisms. Inverse problems are often
ill-posed, meaning small data changes can lead to large solution variations. To
mitigate this, regularization techniques like Tikhonov's are used to stabilize
solutions. This study compares regularization methods applied to gravimetric
inversion, including Smoothness Constraints, Total Variation, Discrete Cosine
Transform (DCT), and Discrete Wavelet Transform (DWT) using Daubechies D4
wavelets. Optimization, particularly with Genetic Algorithms (GA), is used to
find prism depths that best match observed anomalies. GA, inspired by natural
selection, selects the best solutions to minimize the objective function. The
results, evaluated through fit metrics and error analysis, show the
effectiveness of all regularization methods and GA, with the Smoothness
constraint performing best in synthetic models. For the real data model, all
methods performed similarly.",2024-10-19,"Francisco Márcio Barboza, Arthur Anthony da Cunha Romão E Silva, Bruno Motta de Carvalho",http://arxiv.org/pdf/2410.14942v1,cs.LG
Baichuan Alignment Technical Report,"We introduce Baichuan Alignment, a detailed analysis of the alignment
techniques employed in the Baichuan series of models. This represents the
industry's first comprehensive account of alignment methodologies, offering
valuable insights for advancing AI research. We investigate the critical
components that enhance model performance during the alignment process,
including optimization methods, data strategies, capability enhancements, and
evaluation processes. The process spans three key stages: Prompt Augmentation
System(PAS), Supervised Fine-Tuning(SFT), and Preference Alignment. The
problems encountered, the solutions applied, and the improvements made are
thoroughly recorded.
  Through comparisons across well-established benchmarks, we highlight the
technological advancements enabled by Baichuan Alignment. Baichuan-Instruct is
an internal model, while Qwen2-Nova-72B and Llama3-PBM-Nova-70B are instruct
versions of the Qwen2-72B and Llama-3-70B base models, optimized through
Baichuan Alignment. Baichuan-Instruct demonstrates significant improvements in
core capabilities, with user experience gains ranging from 17% to 28%, and
performs exceptionally well on specialized benchmarks. In open-source benchmark
evaluations, both Qwen2-Nova-72B and Llama3-PBM-Nova-70B consistently
outperform their respective official instruct versions across nearly all
datasets. This report aims to clarify the key technologies behind the alignment
process, fostering a deeper understanding within the community.
Llama3-PBM-Nova-70B model is available at
https://huggingface.co/PKU-Baichuan-MLSystemLab/Llama3-PBM-Nova-70B.",2024-10-19,"Mingan Lin, Fan Yang, Yanjun Shen, Haoze Sun, Tianpeng Li, Tao Zhang, Chenzheng Zhu, Tao Zhang, Miao Zheng, Xu Li, Yijie Zhou, Mingyang Chen, Yanzhao Qin, Youquan Li, Hao Liang, Fei Li, Yadong Li, Mang Wang, Guosheng Dong, Kun Fang, Jianhua Xu, Bin Cui, Wentao Zhang, Zenan Zhou, Weipeng Chen",http://arxiv.org/pdf/2410.14940v4,cs.LG
HiPPO-KAN: Efficient KAN Model for Time Series Analysis,"In this study, we introduces a parameter-efficient model that outperforms
traditional models in time series forecasting, by integrating High-order
Polynomial Projection (HiPPO) theory into the Kolmogorov-Arnold network (KAN)
framework. This HiPPO-KAN model achieves superior performance on long sequence
data without increasing parameter count. Experimental results demonstrate that
HiPPO-KAN maintains a constant parameter count while varying window sizes and
prediction horizons, in contrast to KAN, whose parameter count increases
linearly with window size. Surprisingly, although the HiPPO-KAN model keeps a
constant parameter count as increasing window size, it significantly
outperforms KAN model at larger window sizes. These results indicate that
HiPPO-KAN offers significant parameter efficiency and scalability advantages
for time series forecasting. Additionally, we address the lagging problem
commonly encountered in time series forecasting models, where predictions fail
to promptly capture sudden changes in the data. We achieve this by modifying
the loss function to compute the MSE directly on the coefficient vectors in the
HiPPO domain. This adjustment effectively resolves the lagging problem,
resulting in predictions that closely follow the actual time series data. By
incorporating HiPPO theory into KAN, this study showcases an efficient approach
for handling long sequences with improved predictive accuracy, offering
practical contributions for applications in large-scale time series data.",2024-10-19,"SangJong Lee, Jin-Kwang Kim, JunHo Kim, TaeHan Kim, James Lee",http://arxiv.org/pdf/2410.14939v1,cs.LG
